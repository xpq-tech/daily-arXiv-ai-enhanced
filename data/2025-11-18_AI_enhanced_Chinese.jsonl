{"id": "2511.11594", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11594", "abs": "https://arxiv.org/abs/2511.11594", "authors": ["James McCammon"], "title": "TimeStampEval: A Simple LLM Eval and a Little Fuzzy Matching Trick to Improve Search Accuracy", "comment": null, "summary": "Traditional fuzzy matching often fails when searching for quotes that are semantically identical but syntactically different across documents-a common issue when aligning official written records with speech-to-text transcripts. We introduce TimeStampEval, a benchmark for retrieving precise millisecond timestamps from long transcripts given non-verbatim quotes. Our simple two-stage method dramatically improves retrieval accuracy while cutting inference costs by over 90%. The motivating use case is an automated long-form podcast that assembles Congressional Record clips into AI-hosted narration. The technical challenge: given a sentence-timestamped transcript and a target quote that may differ due to transcription or editorial drift, return exact start and end boundaries. Standard algorithms handle verbatim text but break under fuzzier variants. Evaluating six modern LLMs on a 2,800-sentence (120k-token) transcript revealed four key findings. (1) Prompt design matters more than model choice: placing the query before the transcript and using compact formatting improved accuracy by 3-20 points while reducing token count by 30-40%. (2) Off-by-one errors form a distinct category, showing models understand the task but misplace boundaries. (3) A modest reasoning budget (600-850 tokens) raises accuracy from 37% to 77% for weak setups and to above 90% for strong ones. (4) Our \"Assisted Fuzzy\" approach-RapidFuzz pre-filtering followed by LLM verification on short snippets-improves fuzzy match accuracy by up to 50 points while halving latency and reducing cost per correct result by up to 96%. Extended tests on ten transcripts (50k-900k tokens, 1989-2025) confirm robustness to transcript length, vocabulary drift, and domain change, maintaining 95-100% rejection accuracy for absent targets.", "AI": {"tldr": "\u63d0\u51fa\u4e86TimeStampEval\u57fa\u51c6\uff0c\u7528\u4e8e\u4ece\u957f\u6587\u672c\u8bb0\u5f55\u4e2d\u68c0\u7d22\u975e\u9010\u5b57\u5f15\u7528\u7684\u7cbe\u786e\u65f6\u95f4\u6233\u3002\u5f00\u53d1\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u68c0\u7d22\u51c6\u786e\u6027\uff0c\u540c\u65f6\u964d\u4f4e90%\u4ee5\u4e0a\u7684\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u6a21\u7cca\u5339\u914d\u5728\u5904\u7406\u8bed\u4e49\u76f8\u540c\u4f46\u8bed\u6cd5\u4e0d\u540c\u7684\u5f15\u7528\u65f6\u7684\u5931\u8d25\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5bf9\u9f50\u5b98\u65b9\u4e66\u9762\u8bb0\u5f55\u548c\u8bed\u97f3\u8f6c\u6587\u5b57\u8bb0\u5f55\u65f6\u3002\u5e94\u7528\u573a\u666f\u662f\u81ea\u52a8\u5316\u7684\u957f\u7bc7\u64ad\u5ba2\uff0c\u5c06\u56fd\u4f1a\u8bb0\u5f55\u7247\u6bb5\u7ec4\u88c5\u6210AI\u4e3b\u6301\u7684\u53d9\u8ff0\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u9996\u5148\u4f7f\u7528RapidFuzz\u8fdb\u884c\u9884\u8fc7\u6ee4\uff0c\u7136\u540e\u4f7f\u7528LLM\u5728\u77ed\u7247\u6bb5\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002\u63d0\u793a\u8bbe\u8ba1\u5c06\u67e5\u8be2\u653e\u5728\u8f6c\u5f55\u6587\u672c\u4e4b\u524d\u5e76\u4f7f\u7528\u7d27\u51d1\u683c\u5f0f\u3002", "result": "\u8be5\u65b9\u6cd5\u5c06\u6a21\u7cca\u5339\u914d\u51c6\u786e\u7387\u63d0\u9ad8\u4e8650\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u5c06\u5ef6\u8fdf\u51cf\u534a\uff0c\u6bcf\u4e2a\u6b63\u786e\u7ed3\u679c\u7684\u6210\u672c\u964d\u4f4e\u4e8696%\u3002\u572810\u4e2a\u8f6c\u5f55\u6587\u672c\uff0850k-900k tokens\uff09\u7684\u6269\u5c55\u6d4b\u8bd5\u4e2d\uff0c\u5bf9\u8f6c\u5f55\u957f\u5ea6\u3001\u8bcd\u6c47\u6f02\u79fb\u548c\u9886\u57df\u53d8\u5316\u4fdd\u6301\u7a33\u5065\uff0c\u5bf9\u7f3a\u5931\u76ee\u6807\u7684\u62d2\u7edd\u51c6\u786e\u7387\u4fdd\u6301\u572895-100%\u3002", "conclusion": "\u63d0\u793a\u8bbe\u8ba1\u6bd4\u6a21\u578b\u9009\u62e9\u66f4\u91cd\u8981\uff0c\u9002\u5ea6\u7684\u63a8\u7406\u9884\u7b97\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u8f85\u52a9\u6a21\u7cca\u65b9\u6cd5\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u6210\u672c\u3002"}}
{"id": "2511.11793", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.11793", "abs": "https://arxiv.org/abs/2511.11793", "authors": ["MiroMind Team", "Song Bai", "Lidong Bing", "Carson Chen", "Guanzheng Chen", "Yuntao Chen", "Zhe Chen", "Ziyi Chen", "Jifeng Dai", "Xuan Dong", "Yue Deng", "Yunjie Fu", "Junqi Ge", "Chenxia Han", "Tammy Huang", "Zhenhang Huang", "Jerry Jiao", "Shilei Jiang", "Tianyu Jiao", "Xiaoqi Jian", "Lei Lei", "Ruilin Li", "Ryan Luo", "Tiantong Li", "Xiang Lin", "Ziyuan Liu", "Zhiqi Li", "Jie Ni", "Qiang Ren", "Pax Sun", "Shiqian Su", "Chenxin Tao", "Bin Wang", "Hellen Wang", "Haonan Wang", "James Wang", "Jin Wang", "Jojo Wang", "Letian Wang", "Shizun Wang", "Weizhi Wang", "Zixuan Wang", "Jinfan Xu", "Sen Xing", "Chenyu Yang", "Hai Ye", "Jiaheng Yu", "Yue Yu", "Muyan Zhong", "Tianchen Zhao", "Xizhou Zhu", "Yanpeng Zhou", "Yifan Zhang", "Zhi Zhu"], "title": "MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling", "comment": "Technical Report", "summary": "We present MiroThinker v1.0, an open-source research agent designed to advance tool-augmented reasoning and information-seeking capabilities. Unlike previous agents that only scale up model size or context length, MiroThinker explores interaction scaling at the model level, systematically training the model to handle deeper and more frequent agent-environment interactions as a third dimension of performance improvement. Unlike LLM test-time scaling, which operates in isolation and risks degradation with longer reasoning chains, interactive scaling leverages environment feedback and external information acquisition to correct errors and refine trajectories. Through reinforcement learning, the model achieves efficient interaction scaling: with a 256K context window, it can perform up to 600 tool calls per task, enabling sustained multi-turn reasoning and complex real-world research workflows. Across four representative benchmarks-GAIA, HLE, BrowseComp, and BrowseComp-ZH-the 72B variant achieves up to 81.9%, 37.7%, 47.1%, and 55.6% accuracy respectively, surpassing previous open-source agents and approaching commercial counterparts such as GPT-5-high. Our analysis reveals that MiroThinker benefits from interactive scaling consistently: research performance improves predictably as the model engages in deeper and more frequent agent-environment interactions, demonstrating that interaction depth exhibits scaling behaviors analogous to model size and context length. These findings establish interaction scaling as a third critical dimension for building next-generation open research agents, complementing model capacity and context windows.", "AI": {"tldr": "MiroThinker v1.0\u662f\u4e00\u4e2a\u5f00\u6e90\u7814\u7a76\u4ee3\u7406\uff0c\u901a\u8fc7\u4ea4\u4e92\u6269\u5c55\u4f5c\u4e3a\u6a21\u578b\u89c4\u6a21\u548c\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e4b\u5916\u7684\u7b2c\u4e09\u4e2a\u6027\u80fd\u63d0\u5347\u7ef4\u5ea6\uff0c\u80fd\u591f\u8fdb\u884c\u6df1\u5ea6\u591a\u8f6e\u63a8\u7406\u548c\u590d\u6742\u7814\u7a76\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u4ee3\u7406\u4e3b\u8981\u5173\u6ce8\u6a21\u578b\u89c4\u6a21\u6216\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u6269\u5c55\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u6a21\u578b\u4e0e\u73af\u5883\u4ea4\u4e92\u6df1\u5ea6\u7684\u7cfb\u7edf\u6027\u63a2\u7d22\u3002\u4f20\u7edfLLM\u6d4b\u8bd5\u65f6\u6269\u5c55\u5728\u957f\u63a8\u7406\u94fe\u4e2d\u53ef\u80fd\u9000\u5316\uff0c\u800c\u4ea4\u4e92\u6269\u5c55\u53ef\u4ee5\u5229\u7528\u73af\u5883\u53cd\u9988\u7ea0\u6b63\u9519\u8bef\u3002", "method": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u4ea4\u4e92\u6269\u5c55\uff0c\u6a21\u578b\u5728256K\u4e0a\u4e0b\u6587\u7a97\u53e3\u4e2d\u6bcf\u4efb\u52a1\u53ef\u6267\u884c\u591a\u8fbe600\u6b21\u5de5\u5177\u8c03\u7528\uff0c\u5229\u7528\u73af\u5883\u53cd\u9988\u548c\u5916\u90e8\u4fe1\u606f\u83b7\u53d6\u6765\u4fee\u6b63\u9519\u8bef\u548c\u4f18\u5316\u8f68\u8ff9\u3002", "result": "\u5728GAIA\u3001HLE\u3001BrowseComp\u548cBrowseComp-ZH\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c72B\u53d8\u4f53\u5206\u522b\u8fbe\u523081.9%\u300137.7%\u300147.1%\u548c55.6%\u7684\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u5148\u524d\u5f00\u6e90\u4ee3\u7406\u5e76\u63a5\u8fd1\u5546\u4e1a\u5bf9\u5e94\u7269\u3002", "conclusion": "\u4ea4\u4e92\u6269\u5c55\u4e0e\u6a21\u578b\u5bb9\u91cf\u548c\u4e0a\u4e0b\u6587\u7a97\u53e3\u4e00\u6837\uff0c\u662f\u6784\u5efa\u4e0b\u4e00\u4ee3\u5f00\u6e90\u7814\u7a76\u4ee3\u7406\u7684\u7b2c\u4e09\u4e2a\u5173\u952e\u7ef4\u5ea6\uff0c\u4ea4\u4e92\u6df1\u5ea6\u5c55\u73b0\u51fa\u4e0e\u6a21\u578b\u89c4\u6a21\u548c\u4e0a\u4e0b\u6587\u957f\u5ea6\u7c7b\u4f3c\u7684\u6269\u5c55\u884c\u4e3a\u3002"}}
{"id": "2511.11810", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11810", "abs": "https://arxiv.org/abs/2511.11810", "authors": ["Bertram H\u00f8jer"], "title": "On the Notion that Language Models Reason", "comment": "Accepted at the 1st Workshop on Epistemic Intelligence in Machine Learning, EurIPS 2025", "summary": "Language models (LMs) are said to be exhibiting reasoning, but what does this entail? We assess definitions of reasoning and how key papers in the field of natural language processing (NLP) use the notion and argue that the definitions provided are not consistent with how LMs are trained, process information, and generate new tokens. To illustrate this incommensurability we assume the view that transformer-based LMs implement an \\textit{implicit} finite-order Markov kernel mapping contexts to conditional token distributions. In this view, reasoning-like outputs correspond to statistical regularities and approximate statistical invariances in the learned kernel rather than the implementation of explicit logical mechanisms. This view is illustrative of the claim that LMs are \"statistical pattern matchers\"\" and not genuine reasoners and provides a perspective that clarifies why reasoning-like outputs arise in LMs without any guarantees of logical consistency. This distinction is fundamental to how epistemic uncertainty is evaluated in LMs. We invite a discussion on the importance of how the computational processes of the systems we build and analyze in NLP research are described.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8d28\u7591\u8bed\u8a00\u6a21\u578b\u662f\u5426\u771f\u6b63\u5177\u5907\u63a8\u7406\u80fd\u529b\uff0c\u8ba4\u4e3aLM\u53ea\u662f\u5b9e\u73b0\u9690\u5f0f\u6709\u9650\u9636\u9a6c\u5c14\u53ef\u592b\u6838\u7684\u7edf\u8ba1\u6a21\u5f0f\u5339\u914d\u5668\uff0c\u800c\u975e\u771f\u6b63\u7684\u63a8\u7406\u8005\u3002", "motivation": "\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u5b9a\u4e49\uff0c\u6f84\u6e05LM\u751f\u6210\u7c7b\u4f3c\u63a8\u7406\u8f93\u51fa\u7684\u672c\u8d28\u662f\u7edf\u8ba1\u89c4\u5f8b\u800c\u975e\u903b\u8f91\u673a\u5236\u3002", "method": "\u5047\u8bbe\u57fa\u4e8eTransformer\u7684LM\u5b9e\u73b0\u9690\u5f0f\u6709\u9650\u9636\u9a6c\u5c14\u53ef\u592b\u6838\uff0c\u5c06\u4e0a\u4e0b\u6587\u6620\u5c04\u5230\u6761\u4ef6\u6807\u8bb0\u5206\u5e03\uff0c\u5206\u6790\u63a8\u7406\u7c7b\u8f93\u51fa\u5bf9\u5e94\u7684\u7edf\u8ba1\u89c4\u5f8b\u6027\u3002", "result": "\u8bba\u8bc1LM\u662f\"\u7edf\u8ba1\u6a21\u5f0f\u5339\u914d\u5668\"\u800c\u975e\u771f\u6b63\u63a8\u7406\u8005\uff0c\u5176\u63a8\u7406\u7c7b\u8f93\u51fa\u6e90\u4e8e\u5b66\u4e60\u5230\u7684\u7edf\u8ba1\u4e0d\u53d8\u6027\uff0c\u7f3a\u4e4f\u903b\u8f91\u4e00\u81f4\u6027\u4fdd\u8bc1\u3002", "conclusion": "\u9700\u8981\u91cd\u65b0\u8ba8\u8bbaNLP\u7814\u7a76\u4e2d\u5982\u4f55\u63cf\u8ff0\u8ba1\u7b97\u8fc7\u7a0b\uff0c\u8fd9\u5bf9\u8bc4\u4f30LM\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.11821", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11821", "abs": "https://arxiv.org/abs/2511.11821", "authors": ["Hong-Jun Yoon", "Faisal Ashraf", "Thomas A. Ruggles", "Debjani Singh"], "title": "Scaling Open-Weight Large Language Models for Hydropower Regulatory Information Extraction: A Systematic Analysis", "comment": "18 pages, zero figures, Preprint submitted to Environmental Modeling and Software", "summary": "Information extraction from regulatory documents using large language models presents critical trade-offs between performance and computational resources. We evaluated seven open-weight models (0.6B-70B parameters) on hydropower licensing documentation to provide empirical deployment guidance.\n  Our analysis identified a pronounced 14B parameter threshold where validation methods transition from ineffective (F1 $<$ 0.15) to viable (F1 = 0.64). Consumer-deployable models achieve 64\\% F1 through appropriate validation, while smaller models plateau at 51\\%. Large-scale models approach 77\\% F1 but require enterprise infrastructure.\n  We identified systematic hallucination patterns where perfect recall indicates extraction failure rather than success in smaller models. Our findings establish the first comprehensive resource-performance mapping for open-weight information extraction in regulatory contexts, enabling evidence-based model selection.\n  These results provide immediate value for hydropower compliance while contributing insights into parameter scaling effects that generalize across information extraction tasks.", "AI": {"tldr": "\u8bc4\u4f30\u4e867\u4e2a\u5f00\u653e\u6743\u91cd\u6a21\u578b\uff080.6B-70B\u53c2\u6570\uff09\u5728\u6c34\u7535\u8bb8\u53ef\u6587\u6863\u4fe1\u606f\u63d0\u53d6\u4e2d\u7684\u6027\u80fd\u4e0e\u8ba1\u7b97\u8d44\u6e90\u6743\u8861\uff0c\u53d1\u73b014B\u53c2\u6570\u662f\u6027\u80fd\u8f6c\u6298\u70b9\uff0c\u4e3a\u76d1\u7ba1\u6587\u6863\u4fe1\u606f\u63d0\u53d6\u63d0\u4f9b\u4e86\u9996\u4e2a\u5168\u9762\u7684\u8d44\u6e90-\u6027\u80fd\u6620\u5c04\u3002", "motivation": "\u76d1\u7ba1\u6587\u6863\u4fe1\u606f\u63d0\u53d6\u5728\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u9762\u4e34\u6027\u80fd\u4e0e\u8ba1\u7b97\u8d44\u6e90\u7684\u5173\u952e\u6743\u8861\uff0c\u9700\u8981\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u5b9e\u8bc1\u6307\u5bfc\u3002", "method": "\u5728\u6c34\u7535\u8bb8\u53ef\u6587\u6863\u4e0a\u8bc4\u4f30\u4e867\u4e2a\u4e0d\u540c\u89c4\u6a21\u7684\u5f00\u653e\u6743\u91cd\u6a21\u578b\uff080.6B-70B\u53c2\u6570\uff09\uff0c\u5206\u6790\u9a8c\u8bc1\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u53d1\u73b014B\u53c2\u6570\u9608\u503c\uff1a\u4f4e\u4e8e\u6b64\u9608\u503c\u65f6\u9a8c\u8bc1\u65b9\u6cd5\u65e0\u6548\uff08F1 < 0.15\uff09\uff0c\u9ad8\u4e8e\u6b64\u9608\u503c\u65f6\u9a8c\u8bc1\u65b9\u6cd5\u53ef\u884c\uff08F1 = 0.64\uff09\u3002\u6d88\u8d39\u7ea7\u53ef\u90e8\u7f72\u6a21\u578b\u901a\u8fc7\u9002\u5f53\u9a8c\u8bc1\u8fbe\u523064% F1\uff0c\u5c0f\u578b\u6a21\u578b\u572851%\u5904\u9971\u548c\uff0c\u5927\u89c4\u6a21\u6a21\u578b\u63a5\u8fd177% F1\u4f46\u9700\u4f01\u4e1a\u57fa\u7840\u8bbe\u65bd\u3002", "conclusion": "\u5efa\u7acb\u4e86\u76d1\u7ba1\u80cc\u666f\u4e0b\u5f00\u653e\u6743\u91cd\u4fe1\u606f\u63d0\u53d6\u7684\u9996\u4e2a\u5168\u9762\u8d44\u6e90-\u6027\u80fd\u6620\u5c04\uff0c\u4e3a\u57fa\u4e8e\u8bc1\u636e\u7684\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u6307\u5bfc\uff0c\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u6c34\u7535\u5408\u89c4\u5177\u6709\u76f4\u63a5\u4ef7\u503c\uff0c\u4e14\u5bf9\u4fe1\u606f\u63d0\u53d6\u4efb\u52a1\u7684\u53c2\u6570\u7f29\u653e\u6548\u5e94\u5177\u6709\u666e\u9002\u6027\u3002"}}
{"id": "2511.11591", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.11591", "abs": "https://arxiv.org/abs/2511.11591", "authors": ["Olusola Babalola", "Bolanle Ojokoh", "Olutayo Boyinbode"], "title": "LLM-Generated Negative News Headlines Dataset: Creation and Benchmarking Against Real Journalism", "comment": "50 pages, 19 figures, 9 tables", "summary": "This research examines the potential of datasets generated by Large Language Models (LLMs) to support Natural Language Processing (NLP) tasks, aiming to overcome challenges related to data acquisition and privacy concerns associated with real-world data. Focusing on negative valence text, a critical component of sentiment analysis, we explore the use of LLM-generated synthetic news headlines as an alternative to real-world data. A specialized corpus of negative news headlines was created using tailored prompts to capture diverse negative sentiments across various societal domains. The synthetic headlines were validated by expert review and further analyzed in embedding space to assess their alignment with real-world negative news in terms of content, tone, length, and style. Key metrics such as correlation with real headlines, perplexity, coherence, and realism were evaluated. The synthetic dataset was benchmarked against two sets of real news headlines using evaluations including the Comparative Perplexity Test, Comparative Readability Test, Comparative POS Profiling, BERTScore, and Comparative Semantic Similarity. Results show the generated headlines match real headlines with the only marked divergence being in the proper noun score of the POS profile test.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u5408\u6210\u65b0\u95fb\u6807\u9898\u4f5c\u4e3a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u66ff\u4ee3\u54c1\u7684\u53ef\u884c\u6027\uff0c\u7279\u522b\u5173\u6ce8\u8d1f\u9762\u60c5\u611f\u6587\u672c\u5728\u60c5\u611f\u5206\u6790\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u514b\u670d\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u6570\u636e\u83b7\u53d6\u7684\u6311\u6218\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u76f8\u5173\u7684\u9690\u79c1\u95ee\u9898\uff0c\u4e3a\u60c5\u611f\u5206\u6790\u63d0\u4f9b\u66ff\u4ee3\u6570\u636e\u6e90\u3002", "method": "\u4f7f\u7528\u5b9a\u5236\u63d0\u793a\u521b\u5efa\u4e13\u95e8\u7684\u8d1f\u9762\u65b0\u95fb\u6807\u9898\u8bed\u6599\u5e93\uff0c\u901a\u8fc7\u4e13\u5bb6\u8bc4\u5ba1\u548c\u5d4c\u5165\u7a7a\u95f4\u5206\u6790\u9a8c\u8bc1\u5408\u6210\u6807\u9898\uff0c\u5e76\u4e0e\u771f\u5b9e\u65b0\u95fb\u6807\u9898\u8fdb\u884c\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u6bd4\u8f83\u3002", "result": "\u751f\u6210\u7684\u6807\u9898\u5728\u5185\u5bb9\u3001\u8bed\u8c03\u3001\u957f\u5ea6\u548c\u98ce\u683c\u4e0a\u4e0e\u771f\u5b9e\u6807\u9898\u9ad8\u5ea6\u5339\u914d\uff0c\u4ec5\u5728\u8bcd\u6027\u6807\u6ce8\u6d4b\u8bd5\u4e2d\u7684\u4e13\u6709\u540d\u8bcd\u5f97\u5206\u5b58\u5728\u660e\u663e\u5dee\u5f02\u3002", "conclusion": "LLM\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u96c6\u53ef\u4ee5\u6709\u6548\u66ff\u4ee3\u771f\u5b9e\u4e16\u754c\u6570\u636e\uff0c\u4e3aNLP\u4efb\u52a1\u7279\u522b\u662f\u60c5\u611f\u5206\u6790\u63d0\u4f9b\u53ef\u884c\u7684\u6570\u636e\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.11829", "categories": ["cs.CL", "cs.AI", "cs.FL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.11829", "abs": "https://arxiv.org/abs/2511.11829", "authors": ["Mihir Gupte", "Ramesh S"], "title": "Towards Autoformalization of LLM-generated Outputs for Requirement Verification", "comment": "To be submitted for publication", "summary": "Autoformalization, the process of translating informal statements into formal logic, has gained renewed interest with the emergence of powerful Large Language Models (LLMs). While LLMs show promise in generating structured outputs from natural language (NL), such as Gherkin Scenarios from NL feature requirements, there's currently no formal method to verify if these outputs are accurate. This paper takes a preliminary step toward addressing this gap by exploring the use of a simple LLM-based autoformalizer to verify LLM-generated outputs against a small set of natural language requirements. We conducted two distinct experiments. In the first one, the autoformalizer successfully identified that two differently-worded NL requirements were logically equivalent, demonstrating the pipeline's potential for consistency checks. In the second, the autoformalizer was used to identify a logical inconsistency between a given NL requirement and an LLM-generated output, highlighting its utility as a formal verification tool. Our findings, while limited, suggest that autoformalization holds significant potential for ensuring the fidelity and logical consistency of LLM-generated outputs, laying a crucial foundation for future, more extensive studies into this novel application.", "AI": {"tldr": "\u63a2\u7d22\u4f7f\u7528\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u65b9\u6cd5\u6765\u9a8c\u8bc1LLM\u751f\u6210\u7684\u8f93\u51fa\u4e0e\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u7684\u4e00\u81f4\u6027\uff0c\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9a8c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u4e00\u81f4\u6027\u68c0\u67e5\u548c\u5f62\u5f0f\u9a8c\u8bc1\u65b9\u9762\u7684\u6f5c\u529b\u3002", "motivation": "\u867d\u7136LLM\u5728\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210\u7ed3\u6784\u5316\u8f93\u51fa\u65b9\u9762\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u6b63\u5f0f\u65b9\u6cd5\u6765\u9a8c\u8bc1\u8fd9\u4e9b\u8f93\u51fa\u7684\u51c6\u786e\u6027\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63a2\u7d22\u81ea\u52a8\u5f62\u5f0f\u5316\u5728\u9a8c\u8bc1LLM\u751f\u6210\u8f93\u51fa\u65b9\u9762\u7684\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u7b80\u5355\u7684\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u5668\uff0c\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9a8c\uff1a1\uff09\u9a8c\u8bc1\u4e0d\u540c\u8868\u8ff0\u7684\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u5728\u903b\u8f91\u4e0a\u662f\u5426\u7b49\u4ef7\uff1b2\uff09\u68c0\u6d4b\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u4e0eLLM\u751f\u6210\u8f93\u51fa\u4e4b\u95f4\u7684\u903b\u8f91\u4e0d\u4e00\u81f4\u6027\u3002", "result": "\u5728\u7b2c\u4e00\u4e2a\u5b9e\u9a8c\u4e2d\uff0c\u81ea\u52a8\u5f62\u5f0f\u5316\u5668\u6210\u529f\u8bc6\u522b\u51fa\u4e24\u4e2a\u4e0d\u540c\u8868\u8ff0\u7684\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u5728\u903b\u8f91\u4e0a\u662f\u7b49\u4ef7\u7684\uff1b\u5728\u7b2c\u4e8c\u4e2a\u5b9e\u9a8c\u4e2d\uff0c\u6210\u529f\u8bc6\u522b\u51fa\u7ed9\u5b9a\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u4e0eLLM\u751f\u6210\u8f93\u51fa\u4e4b\u95f4\u7684\u903b\u8f91\u4e0d\u4e00\u81f4\u6027\u3002", "conclusion": "\u867d\u7136\u7814\u7a76\u6709\u9650\uff0c\u4f46\u81ea\u52a8\u5f62\u5f0f\u5316\u5728\u786e\u4fddLLM\u751f\u6210\u8f93\u51fa\u7684\u4fdd\u771f\u5ea6\u548c\u903b\u8f91\u4e00\u81f4\u6027\u65b9\u9762\u5177\u6709\u663e\u8457\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u66f4\u5e7f\u6cdb\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.11597", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.11597", "abs": "https://arxiv.org/abs/2511.11597", "authors": ["Michelle Chen Huebscher", "Katharine Mach", "Aleksandar Stani\u0107", "Markus Leippold", "Ben Gaiarin", "Zeke Hausfather", "Elisa Rawat", "Erich Fischer", "Massimiliano Ciaramita", "Joeri Rogelj", "Christian Buck", "Lierni Sestorain Saralegui", "Reto Knutti"], "title": "CLINB: A Climate Intelligence Benchmark for Foundational Models", "comment": "Questions, system prompt and model judge prompts available here: https://www.kaggle.com/datasets/deepmind/clinb-questions", "summary": "Evaluating how Large Language Models (LLMs) handle complex, specialized knowledge remains a critical challenge. We address this through the lens of climate change by introducing CLINB, a benchmark that assesses models on open-ended, grounded, multimodal question answering tasks with clear requirements for knowledge quality and evidential support. CLINB relies on a dataset of real users' questions and evaluation rubrics curated by leading climate scientists. We implement and validate a model-based evaluation process and evaluate several frontier models. Our findings reveal a critical dichotomy. Frontier models demonstrate remarkable knowledge synthesis capabilities, often exhibiting PhD-level understanding and presentation quality. They outperform \"hybrid\" answers curated by domain experts assisted by weaker models. However, this performance is countered by failures in grounding. The quality of evidence varies, with substantial hallucination rates for references and images. We argue that bridging this gap between knowledge synthesis and verifiable attribution is essential for the deployment of AI in scientific workflows and that reliable, interpretable benchmarks like CLINB are needed to progress towards building trustworthy AI systems.", "AI": {"tldr": "CLINB\u662f\u4e00\u4e2a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u6c14\u5019\u53d8\u5316\u4e13\u4e1a\u77e5\u8bc6\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u524d\u6cbf\u6a21\u578b\u5728\u77e5\u8bc6\u7efc\u5408\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u8bc1\u636e\u57fa\u7840\u548c\u5f15\u7528\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u590d\u6742\u4e13\u4e1a\u77e5\u8bc6\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u6c14\u5019\u53d8\u5316\u9886\u57df\uff0c\u9700\u8981\u5efa\u7acb\u53ef\u9760\u7684\u57fa\u51c6\u6765\u6d4b\u8bd5\u6a21\u578b\u7684\u77e5\u8bc6\u8d28\u91cf\u548c\u8bc1\u636e\u652f\u6301\u80fd\u529b\u3002", "method": "\u5f00\u53d1CLINB\u57fa\u51c6\uff0c\u4f7f\u7528\u771f\u5b9e\u7528\u6237\u95ee\u9898\u548c\u6c14\u5019\u79d1\u5b66\u5bb6\u5236\u5b9a\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u901a\u8fc7\u57fa\u4e8e\u6a21\u578b\u7684\u8bc4\u4f30\u6d41\u7a0b\u6d4b\u8bd5\u591a\u4e2a\u524d\u6cbf\u6a21\u578b\u3002", "result": "\u524d\u6cbf\u6a21\u578b\u5c55\u73b0\u51fa\u535a\u58eb\u7ea7\u522b\u7684\u77e5\u8bc6\u7efc\u5408\u80fd\u529b\uff0c\u8868\u73b0\u4f18\u4e8e\u4e13\u5bb6\u8f85\u52a9\u7684\u6df7\u5408\u7b54\u6848\uff0c\u4f46\u5728\u8bc1\u636e\u57fa\u7840\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u95ee\u9898\uff0c\u5f15\u7528\u548c\u56fe\u50cf\u5e7b\u89c9\u7387\u5f88\u9ad8\u3002", "conclusion": "\u9700\u8981\u5728\u77e5\u8bc6\u7efc\u5408\u548c\u53ef\u9a8c\u8bc1\u5f52\u56e0\u4e4b\u95f4\u67b6\u8d77\u6865\u6881\uff0cCLINB\u7b49\u53ef\u9760\u57fa\u51c6\u5bf9\u4e8e\u6784\u5efa\u53ef\u4fe1AI\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.11857", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11857", "abs": "https://arxiv.org/abs/2511.11857", "authors": ["Taimur Khan", "Ramoza Ahsan", "Mohib Hameed"], "title": "Three Stage Narrative Analysis; Plot-Sentiment Breakdown, Structure Learning and Concept Detection", "comment": "18 pages", "summary": "Story understanding and analysis have long been challenging areas within Natural Language Understanding. Automated narrative analysis requires deep computational semantic representations along with syntactic processing. Moreover, the large volume of narrative data demands automated semantic analysis and computational learning rather than manual analytical approaches. In this paper, we propose a framework that analyzes the sentiment arcs of movie scripts and performs extended analysis related to the context of the characters involved. The framework enables the extraction of high-level and low-level concepts conveyed through the narrative. Using dictionary-based sentiment analysis, our approach applies a custom lexicon built with the LabMTsimple storylab module. The custom lexicon is based on the Valence, Arousal, and Dominance scores from the NRC-VAD dataset. Furthermore, the framework advances the analysis by clustering similar sentiment plots using Wards hierarchical clustering technique. Experimental evaluation on a movie dataset shows that the resulting analysis is helpful to consumers and readers when selecting a narrative or story.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u6790\u7535\u5f71\u5267\u672c\u60c5\u611f\u5f27\u7ebf\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u5b9a\u4e49\u60c5\u611f\u8bcd\u5178\u548c\u5c42\u6b21\u805a\u7c7b\u6280\u672f\uff0c\u80fd\u591f\u63d0\u53d6\u53d9\u4e8b\u4e2d\u7684\u9ad8\u4f4e\u5c42\u6b21\u6982\u5ff5\uff0c\u5e2e\u52a9\u6d88\u8d39\u8005\u9009\u62e9\u6545\u4e8b\u3002", "motivation": "\u6545\u4e8b\u7406\u89e3\u548c\u5206\u6790\u662f\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4e2d\u7684\u6311\u6218\u9886\u57df\uff0c\u9700\u8981\u6df1\u5ea6\u8ba1\u7b97\u8bed\u4e49\u8868\u793a\u548c\u53e5\u6cd5\u5904\u7406\u3002\u5927\u91cf\u53d9\u4e8b\u6570\u636e\u9700\u8981\u81ea\u52a8\u5316\u8bed\u4e49\u5206\u6790\u800c\u975e\u624b\u52a8\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eNRC-VAD\u6570\u636e\u96c6\u7684Valence\u3001Arousal\u548cDominance\u5206\u6570\u6784\u5efa\u81ea\u5b9a\u4e49\u60c5\u611f\u8bcd\u5178\uff0c\u5e94\u7528LabMTsimple storylab\u6a21\u5757\u8fdb\u884c\u57fa\u4e8e\u8bcd\u5178\u7684\u60c5\u611f\u5206\u6790\uff0c\u5e76\u4f7f\u7528Wards\u5c42\u6b21\u805a\u7c7b\u6280\u672f\u5bf9\u76f8\u4f3c\u60c5\u611f\u60c5\u8282\u8fdb\u884c\u805a\u7c7b\u3002", "result": "\u5728\u7535\u5f71\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u5206\u6790\u6846\u67b6\u5bf9\u6d88\u8d39\u8005\u548c\u8bfb\u8005\u5728\u9009\u62e9\u53d9\u4e8b\u6216\u6545\u4e8b\u65f6\u5f88\u6709\u5e2e\u52a9\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u5206\u6790\u7535\u5f71\u5267\u672c\u7684\u60c5\u611f\u5f27\u7ebf\u5e76\u8fdb\u884c\u6269\u5c55\u5206\u6790\uff0c\u4e3a\u53d9\u4e8b\u9009\u62e9\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002"}}
{"id": "2511.11599", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.11599", "abs": "https://arxiv.org/abs/2511.11599", "authors": ["Arefeh Kazemi", "Hamza Qadeer", "Joachim Wagner", "Hossein Hosseini", "Sri Balaaji Natarajan Kalaivendan", "Brian Davis"], "title": "SynBullying: A Multi LLM Synthetic Conversational Dataset for Cyberbullying Detectio", "comment": null, "summary": "We introduce SynBullying, a synthetic multi-LLM conversational dataset for studying and detecting cyberbullying (CB). SynBullying provides a scalable and ethically safe alternative to human data collection by leveraging large language models (LLMs) to simulate realistic bullying interactions. The dataset offers (i) conversational structure, capturing multi-turn exchanges rather than isolated posts; (ii) context-aware annotations, where harmfulness is assessed within the conversational flow considering context, intent, and discourse dynamics; and (iii) fine-grained labeling, covering various CB categories for detailed linguistic and behavioral analysis. We evaluate SynBullying across five dimensions, including conversational structure, lexical patterns, sentiment/toxicity, role dynamics, harm intensity, and CB-type distribution. We further examine its utility by testing its performance as standalone training data and as an augmentation source for CB classification.", "AI": {"tldr": "SynBullying\u662f\u4e00\u4e2a\u7528\u4e8e\u7814\u7a76\u548c\u68c0\u6d4b\u7f51\u7edc\u6b3a\u51cc\u7684\u5408\u6210\u591aLLM\u5bf9\u8bdd\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u771f\u5b9e\u6b3a\u51cc\u4e92\u52a8\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u4e14\u4f26\u7406\u5b89\u5168\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "motivation": "\u4e3a\u7f51\u7edc\u6b3a\u51cc\u7814\u7a76\u63d0\u4f9b\u53ef\u6269\u5c55\u4e14\u4f26\u7406\u5b89\u5168\u7684\u6570\u636e\u6536\u96c6\u66ff\u4ee3\u65b9\u6848\uff0c\u514b\u670d\u4eba\u7c7b\u6570\u636e\u6536\u96c6\u7684\u5c40\u9650\u6027\u548c\u4f26\u7406\u95ee\u9898\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6a21\u62df\u771f\u5b9e\u6b3a\u51cc\u4e92\u52a8\u7684\u591a\u8f6e\u5bf9\u8bdd\uff0c\u63d0\u4f9b\u5bf9\u8bdd\u7ed3\u6784\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u6807\u6ce8\u548c\u7ec6\u7c92\u5ea6\u6807\u7b7e\u3002", "result": "\u6570\u636e\u96c6\u5728\u5bf9\u8bdd\u7ed3\u6784\u3001\u8bcd\u6c47\u6a21\u5f0f\u3001\u60c5\u611f/\u6bd2\u6027\u3001\u89d2\u8272\u52a8\u6001\u3001\u4f24\u5bb3\u5f3a\u5ea6\u548c\u6b3a\u51cc\u7c7b\u578b\u5206\u5e03\u7b49\u4e94\u4e2a\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5e76\u6d4b\u8bd5\u4e86\u5176\u4f5c\u4e3a\u72ec\u7acb\u8bad\u7ec3\u6570\u636e\u548c\u589e\u5f3a\u6e90\u7684\u6027\u80fd\u3002", "conclusion": "SynBullying\u662f\u4e00\u4e2a\u6709\u6548\u7684\u7f51\u7edc\u6b3a\u51cc\u7814\u7a76\u5de5\u5177\uff0c\u80fd\u591f\u63d0\u4f9b\u73b0\u5b9e\u4e14\u4f26\u7406\u5b89\u5168\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u652f\u6301\u8be6\u7ec6\u7684\u7f51\u7edc\u6b3a\u51cc\u884c\u4e3a\u5206\u6790\u3002"}}
{"id": "2511.11867", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.11867", "abs": "https://arxiv.org/abs/2511.11867", "authors": ["Namu Park", "Giridhar Kaushik Ramachandran", "Kevin Lybarger", "Fei Xia", "Ozlem Uzuner", "Meliha Yetisgen", "Martin Gunn"], "title": "Identifying Imaging Follow-Up in Radiology Reports: A Comparative Analysis of Traditional ML and LLM Approaches", "comment": "Submitted to LREC 2026", "summary": "Large language models (LLMs) have shown considerable promise in clinical natural language processing, yet few domain-specific datasets exist to rigorously evaluate their performance on radiology tasks. In this work, we introduce an annotated corpus of 6,393 radiology reports from 586 patients, each labeled for follow-up imaging status, to support the development and benchmarking of follow-up adherence detection systems. Using this corpus, we systematically compared traditional machine-learning classifiers, including logistic regression (LR), support vector machines (SVM), Longformer, and a fully fine-tuned Llama3-8B-Instruct, with recent generative LLMs. To evaluate generative LLMs, we tested GPT-4o and the open-source GPT-OSS-20B under two configurations: a baseline (Base) and a task-optimized (Advanced) setting that focused inputs on metadata, recommendation sentences, and their surrounding context. A refined prompt for GPT-OSS-20B further improved reasoning accuracy. Performance was assessed using precision, recall, and F1 scores with 95% confidence intervals estimated via non-parametric bootstrapping. Inter-annotator agreement was high (F1 = 0.846). GPT-4o (Advanced) achieved the best performance (F1 = 0.832), followed closely by GPT-OSS-20B (Advanced; F1 = 0.828). LR and SVM also performed strongly (F1 = 0.776 and 0.775), underscoring that while LLMs approach human-level agreement through prompt optimization, interpretable and resource-efficient models remain valuable baselines.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u5305\u542b6,393\u4efd\u653e\u5c04\u5b66\u62a5\u544a\u7684\u6807\u6ce8\u8bed\u6599\u5e93\uff0c\u7528\u4e8e\u7cfb\u7edf\u6bd4\u8f83\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u4e0e\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u5728\u968f\u8bbf\u4f9d\u4ece\u6027\u68c0\u6d4b\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u653e\u5c04\u5b66\u4efb\u52a1\u6027\u80fd\u7684\u9886\u57df\u7279\u5b9a\u6570\u636e\u96c6\uff0c\u9700\u8981\u6784\u5efa\u4e00\u4e2a\u6807\u6ce8\u8bed\u6599\u5e93\u6765\u652f\u6301\u968f\u8bbf\u4f9d\u4ece\u6027\u68c0\u6d4b\u7cfb\u7edf\u7684\u5f00\u53d1\u548c\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u4f7f\u75286,393\u4efd\u653e\u5c04\u5b66\u62a5\u544a\u6807\u6ce8\u8bed\u6599\u5e93\uff0c\u6bd4\u8f83\u4e86\u903b\u8f91\u56de\u5f52\u3001\u652f\u6301\u5411\u91cf\u673a\u3001Longformer\u3001\u5fae\u8c03Llama3-8B-Instruct\u4e0eGPT-4o\u3001GPT-OSS-20B\u7b49\u751f\u6210\u5f0fLLM\u3002\u5bf9\u751f\u6210\u5f0fLLM\u6d4b\u8bd5\u4e86\u57fa\u7840\u914d\u7f6e\u548c\u4efb\u52a1\u4f18\u5316\u914d\u7f6e\u3002", "result": "GPT-4o\uff08\u9ad8\u7ea7\u914d\u7f6e\uff09\u8868\u73b0\u6700\u4f73\uff08F1=0.832\uff09\uff0cGPT-OSS-20B\uff08\u9ad8\u7ea7\u914d\u7f6e\uff09\u7d27\u968f\u5176\u540e\uff08F1=0.828\uff09\u3002\u903b\u8f91\u56de\u5f52\u548c\u652f\u6301\u5411\u91cf\u673a\u4e5f\u8868\u73b0\u826f\u597d\uff08F1\u5206\u522b\u4e3a0.776\u548c0.775\uff09\u3002\u6807\u6ce8\u8005\u95f4\u4e00\u81f4\u6027\u9ad8\uff08F1=0.846\uff09\u3002", "conclusion": "\u867d\u7136\u901a\u8fc7\u63d0\u793a\u4f18\u5316\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u7684\u4e00\u81f4\u6027\uff0c\u4f46\u53ef\u89e3\u91ca\u4e14\u8d44\u6e90\u6548\u7387\u9ad8\u7684\u4f20\u7edf\u6a21\u578b\u4ecd\u7136\u662f\u91cd\u8981\u7684\u57fa\u51c6\u65b9\u6cd5\u3002"}}
{"id": "2511.11600", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.11600", "abs": "https://arxiv.org/abs/2511.11600", "authors": ["Piyushkumar Patel"], "title": "CausalGuard: A Smart System for Detecting and Preventing False Information in Large Language Models", "comment": null, "summary": "While large language models have transformed how we interact with AI systems, they have a critical weakness: they confidently state false information that sounds entirely plausible. This \"hallucination\" problem has become a major barrier to using these models where accuracy matters most. Existing solutions either require retraining the entire model, add significant computational costs, or miss the root causes of why these hallucinations occur in the first place.\n  We present CausalGuard, a new approach that combines causal reasoning with symbolic logic to catch and prevent hallucinations as they happen. Unlike previous methods that only check outputs after generation, our system understands the causal chain that leads to false statements and intervenes early in the process. CausalGuard works through two complementary paths: one that traces causal relationships between what the model knows and what it generates, and another that checks logical consistency using automated reasoning.\n  Testing across twelve different benchmarks, we found that CausalGuard correctly identifies hallucinations 89.3\\% of the time while missing only 8.3\\% of actual hallucinations. More importantly, it reduces false claims by nearly 80\\% while keeping responses natural and helpful. The system performs especially well on complex reasoning tasks where multiple steps of logic are required. Because CausalGuard shows its reasoning process, it works well in sensitive areas like medical diagnosis or financial analysis where understanding why a decision was made matters as much as the decision itself.", "AI": {"tldr": "CausalGuard\u662f\u4e00\u79cd\u7ed3\u5408\u56e0\u679c\u63a8\u7406\u548c\u7b26\u53f7\u903b\u8f91\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b9e\u65f6\u68c0\u6d4b\u548c\u9632\u6b62\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u572812\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u80fd\u51c6\u786e\u8bc6\u522b89.3%\u7684\u5e7b\u89c9\uff0c\u540c\u65f6\u51cf\u5c11\u8fd180%\u7684\u9519\u8bef\u9648\u8ff0\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u4e25\u91cd\u5e7b\u89c9\u95ee\u9898\uff0c\u4f1a\u81ea\u4fe1\u5730\u9648\u8ff0\u542c\u8d77\u6765\u5408\u7406\u4f46\u5b9e\u9645\u9519\u8bef\u7684\u4fe1\u606f\uff0c\u8fd9\u6210\u4e3a\u5728\u51c6\u786e\u6027\u8981\u6c42\u9ad8\u7684\u573a\u666f\u4e2d\u4f7f\u7528\u8fd9\u4e9b\u6a21\u578b\u7684\u4e3b\u8981\u969c\u788d\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u8981\u4e48\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\u6574\u4e2a\u6a21\u578b\uff0c\u8981\u4e48\u589e\u52a0\u663e\u8457\u8ba1\u7b97\u6210\u672c\uff0c\u6216\u8005\u672a\u80fd\u89e3\u51b3\u5e7b\u89c9\u7684\u6839\u672c\u539f\u56e0\u3002", "method": "CausalGuard\u901a\u8fc7\u4e24\u6761\u4e92\u8865\u8def\u5f84\u5de5\u4f5c\uff1a\u4e00\u6761\u8def\u5f84\u8ffd\u8e2a\u6a21\u578b\u5df2\u77e5\u4fe1\u606f\u4e0e\u751f\u6210\u5185\u5bb9\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u53e6\u4e00\u6761\u8def\u5f84\u4f7f\u7528\u81ea\u52a8\u63a8\u7406\u68c0\u67e5\u903b\u8f91\u4e00\u81f4\u6027\u3002\u7cfb\u7edf\u7406\u89e3\u5bfc\u81f4\u9519\u8bef\u9648\u8ff0\u7684\u56e0\u679c\u94fe\uff0c\u5e76\u5728\u8fc7\u7a0b\u4e2d\u65e9\u671f\u8fdb\u884c\u5e72\u9884\u3002", "result": "\u572812\u4e2a\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCausalGuard\u80fd\u6b63\u786e\u8bc6\u522b89.3%\u7684\u5e7b\u89c9\uff0c\u4ec5\u6f0f\u68c08.3%\u7684\u5b9e\u9645\u5e7b\u89c9\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u5b83\u51cf\u5c11\u4e86\u8fd180%\u7684\u9519\u8bef\u9648\u8ff0\uff0c\u540c\u65f6\u4fdd\u6301\u56de\u7b54\u7684\u81ea\u7136\u6027\u548c\u5e2e\u52a9\u6027\u3002\u5728\u9700\u8981\u591a\u6b65\u903b\u8f91\u63a8\u7406\u7684\u590d\u6742\u4efb\u52a1\u4e0a\u8868\u73b0\u5c24\u5176\u51fa\u8272\u3002", "conclusion": "CausalGuard\u901a\u8fc7\u5c55\u793a\u63a8\u7406\u8fc7\u7a0b\uff0c\u5728\u533b\u7597\u8bca\u65ad\u6216\u91d1\u878d\u5206\u6790\u7b49\u654f\u611f\u9886\u57df\u7279\u522b\u6709\u6548\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u9886\u57df\u7406\u89e3\u51b3\u7b56\u539f\u56e0\u4e0e\u51b3\u7b56\u672c\u8eab\u540c\u6837\u91cd\u8981\u3002\u8be5\u65b9\u6cd5\u4e3a\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.11878", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.11878", "abs": "https://arxiv.org/abs/2511.11878", "authors": ["Fernanda Bufon F\u00e4rber", "Iago Alves Brito", "Julia Soares Dollis", "Pedro Schindler Freire Brasil Ribeiro", "Rafael Teixeira Sousa", "Arlindo Rodrigues Galv\u00e3o Filho"], "title": "MedPT: A Massive Medical Question Answering Dataset for Brazilian-Portuguese Speakers", "comment": "11 pages, 3 tables, 2 figures", "summary": "While large language models (LLMs) show transformative potential in healthcare, their development remains focused on high-resource languages, creating a critical barrier for others as simple translation fails to capture unique clinical and cultural nuances, such as endemic diseases. To address this, we introduce MedPT, the first large-scale, real-world corpus for Brazilian Portuguese, comprising 384,095 authentic question-answer pairs from patient-doctor interactions. The dataset underwent a meticulous multi-stage curation protocol, using a hybrid quantitative-qualitative analysis to filter noise and contextually enrich thousands of ambiguous queries. We further augmented the corpus via LLM-driven annotation, classifying questions into seven semantic types to capture user intent. Our analysis reveals its thematic breadth (3,200 topics) and unique linguistic properties, like the natural asymmetry in patient-doctor communication. To validate its utility, we benchmark a medical specialty routing task: fine-tuning a 1.7B parameter model achieves an outstanding 94\\% F1-score on a 20-class setup. Furthermore, our qualitative error analysis shows misclassifications are not random but reflect genuine clinical ambiguities (e.g., between comorbid conditions), proving the dataset's deep semantic richness. We publicly release MedPT to foster the development of more equitable, accurate, and culturally-aware medical technologies for the Portuguese-speaking world.", "AI": {"tldr": "MedPT\u662f\u9996\u4e2a\u9488\u5bf9\u5df4\u897f\u8461\u8404\u7259\u8bed\u7684\u5927\u89c4\u6a21\u771f\u5b9e\u4e16\u754c\u533b\u7597\u8bed\u6599\u5e93\uff0c\u5305\u542b384,095\u4e2a\u533b\u60a3\u95ee\u7b54\u5bf9\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u7b5b\u9009\u548cLLM\u6807\u6ce8\u589e\u5f3a\u4e86\u6570\u636e\u8d28\u91cf\uff0c\u5728\u533b\u7597\u4e13\u79d1\u5206\u7c7b\u4efb\u52a1\u4e0a\u8fbe\u523094% F1\u5206\u6570\u3002", "motivation": "\u73b0\u6709LLM\u5f00\u53d1\u4e3b\u8981\u5173\u6ce8\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u800c\u7b80\u5355\u7ffb\u8bd1\u65e0\u6cd5\u6355\u6349\u7279\u5b9a\u4e34\u5e8a\u548c\u6587\u5316\u7ec6\u5fae\u5dee\u522b\uff08\u5982\u5730\u65b9\u6027\u75be\u75c5\uff09\uff0c\u8fd9\u4e3a\u5176\u4ed6\u8bed\u8a00\u7fa4\u4f53\u521b\u9020\u4e86\u5173\u952e\u969c\u788d\u3002", "method": "\u6784\u5efa\u4e86\u5df4\u897f\u8461\u8404\u7259\u8bed\u533b\u60a3\u4ea4\u4e92\u8bed\u6599\u5e93\uff0c\u91c7\u7528\u6df7\u5408\u5b9a\u91cf-\u5b9a\u6027\u5206\u6790\u65b9\u6cd5\u8fc7\u6ee4\u566a\u97f3\u5e76\u4e30\u5bcc\u6a21\u7cca\u67e5\u8be2\uff0c\u901a\u8fc7LLM\u9a71\u52a8\u6807\u6ce8\u5c06\u95ee\u9898\u5206\u7c7b\u4e3a\u4e03\u79cd\u8bed\u4e49\u7c7b\u578b\uff0c\u5e76\u7528\u4e8e\u533b\u7597\u4e13\u79d1\u8def\u7531\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u8bed\u6599\u5e93\u6db5\u76d63,200\u4e2a\u4e3b\u9898\uff0c\u5c55\u793a\u4e86\u72ec\u7279\u7684\u8bed\u8a00\u7279\u6027\uff08\u5982\u533b\u60a3\u6c9f\u901a\u7684\u81ea\u7136\u4e0d\u5bf9\u79f0\u6027\uff09\u3002\u572820\u7c7b\u533b\u7597\u4e13\u79d1\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u5fae\u8c031.7B\u53c2\u6570\u6a21\u578b\u8fbe\u523094% F1\u5206\u6570\uff0c\u9519\u8bef\u5206\u6790\u663e\u793a\u8bef\u5206\u7c7b\u53cd\u6620\u4e86\u771f\u5b9e\u7684\u4e34\u5e8a\u6a21\u7cca\u6027\u3002", "conclusion": "MedPT\u7684\u53d1\u5e03\u5c06\u4fc3\u8fdb\u4e3a\u8461\u8404\u7259\u8bed\u4e16\u754c\u5f00\u53d1\u66f4\u516c\u5e73\u3001\u51c6\u786e\u548c\u6587\u5316\u610f\u8bc6\u7684\u533b\u7597\u6280\u672f\u3002"}}
{"id": "2511.11611", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.11611", "abs": "https://arxiv.org/abs/2511.11611", "authors": ["David H. Silver"], "title": "Quantifying Skill and Chance: A Unified Framework for the Geometry of Games", "comment": null, "summary": "We introduce a quantitative framework for separating skill and chance in games by modeling them as complementary sources of control over stochastic decision trees. We define the Skill-Luck Index S(G) in [-1, 1] by decomposing game outcomes into skill leverage K and luck leverage L. Applying this to 30 games reveals a continuum from pure chance (coin toss, S = -1) through mixed domains such as backgammon (S = 0, Sigma = 1.20) to pure skill (chess, S = +1, Sigma = 0). Poker exhibits moderate skill dominance (S = 0.33) with K = 0.40 +/- 0.03 and Sigma = 0.80. We further introduce volatility Sigma to quantify outcome uncertainty over successive turns. The framework extends to general stochastic decision systems, enabling principled comparisons of player influence, game balance, and predictive stability, with applications to game design, AI evaluation, and risk assessment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6e38\u620f\u5efa\u6a21\u4e3a\u968f\u673a\u51b3\u7b56\u6811\u6765\u5206\u79bb\u6280\u80fd\u548c\u8fd0\u6c14\u6210\u5206\uff0c\u5b9a\u4e49\u4e86\u6280\u80fd-\u8fd0\u6c14\u6307\u6570S(G)\u5728[-1,1]\u8303\u56f4\u5185\uff0c\u5e94\u7528\u4e8e30\u4e2a\u6e38\u620f\u63ed\u793a\u4e86\u4ece\u7eaf\u8fd0\u6c14\u5230\u7eaf\u6280\u80fd\u7684\u8fde\u7eed\u8c31\u3002", "motivation": "\u9700\u8981\u7cfb\u7edf\u6027\u5730\u91cf\u5316\u6e38\u620f\u4e2d\u6280\u80fd\u548c\u8fd0\u6c14\u6210\u5206\u7684\u76f8\u5bf9\u91cd\u8981\u6027\uff0c\u4ee5\u4fbf\u8fdb\u884c\u6e38\u620f\u8bbe\u8ba1\u3001AI\u8bc4\u4f30\u548c\u98ce\u9669\u8bc4\u4f30\u3002", "method": "\u5c06\u6e38\u620f\u5efa\u6a21\u4e3a\u968f\u673a\u51b3\u7b56\u6811\uff0c\u5206\u89e3\u6e38\u620f\u7ed3\u679c\u4e3a\u6280\u80fd\u6760\u6746K\u548c\u8fd0\u6c14\u6760\u6746L\uff0c\u5b9a\u4e49\u6280\u80fd-\u8fd0\u6c14\u6307\u6570S(G) = (K - L)/(K + L)\uff0c\u5e76\u5f15\u5165\u6ce2\u52a8\u7387Sigma\u6765\u91cf\u5316\u8fde\u7eed\u56de\u5408\u7684\u7ed3\u679c\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5206\u679030\u4e2a\u6e38\u620f\u663e\u793a\uff1a\u786c\u5e01\u6295\u63b7S=-1\uff08\u7eaf\u8fd0\u6c14\uff09\uff0c\u897f\u6d0b\u53cc\u9646\u68cbS=0\uff0c\u56fd\u9645\u8c61\u68cbS=+1\uff08\u7eaf\u6280\u80fd\uff09\uff0c\u6251\u514bS=0.33\uff08\u6280\u80fd\u4e3b\u5bfc\uff09\u3002\u6ce2\u52a8\u7387\u5206\u6790\u663e\u793a\u4e0d\u540c\u6e38\u620f\u7684\u9884\u6d4b\u7a33\u5b9a\u6027\u5dee\u5f02\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u6269\u5c55\u5230\u4e00\u822c\u968f\u673a\u51b3\u7b56\u7cfb\u7edf\uff0c\u4e3a\u73a9\u5bb6\u5f71\u54cd\u529b\u3001\u6e38\u620f\u5e73\u8861\u6027\u548c\u9884\u6d4b\u7a33\u5b9a\u6027\u7684\u6bd4\u8f83\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u5728\u6e38\u620f\u8bbe\u8ba1\u3001AI\u8bc4\u4f30\u548c\u98ce\u9669\u8bc4\u4f30\u4e2d\u5177\u6709\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.11883", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11883", "abs": "https://arxiv.org/abs/2511.11883", "authors": ["Karthikeyan K", "Raghuveer Thirukovalluru", "David Carlson"], "title": "ClinStructor: AI-Powered Structuring of Unstructured Clinical Texts", "comment": null, "summary": "Clinical notes contain valuable, context-rich information, but their unstructured format introduces several challenges, including unintended biases (e.g., gender or racial bias), and poor generalization across clinical settings (e.g., models trained on one EHR system may perform poorly on another due to format differences) and poor interpretability. To address these issues, we present ClinStructor, a pipeline that leverages large language models (LLMs) to convert clinical free-text into structured, task-specific question-answer pairs prior to predictive modeling. Our method substantially enhances transparency and controllability and only leads to a modest reduction in predictive performance (a 2-3% drop in AUC), compared to direct fine-tuning, on the ICU mortality prediction task. ClinStructor lays a strong foundation for building reliable, interpretable, and generalizable machine learning models in clinical environments.", "AI": {"tldr": "ClinStructor\u662f\u4e00\u4e2a\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u4e34\u5e8a\u81ea\u7531\u6587\u672c\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u95ee\u7b54\u5bf9\u7684\u7ba1\u9053\uff0c\u65e8\u5728\u89e3\u51b3\u4e34\u5e8a\u7b14\u8bb0\u4e2d\u7684\u504f\u89c1\u3001\u6cdb\u5316\u6027\u548c\u53ef\u89e3\u91ca\u6027\u95ee\u9898\uff0c\u5728ICU\u6b7b\u4ea1\u7387\u9884\u6d4b\u4efb\u52a1\u4e2d\u4ec5\u5bfc\u81f4AUC\u8f7b\u5fae\u4e0b\u964d2-3%\u3002", "motivation": "\u4e34\u5e8a\u7b14\u8bb0\u5305\u542b\u4e30\u5bcc\u4fe1\u606f\u4f46\u683c\u5f0f\u975e\u7ed3\u6784\u5316\uff0c\u5b58\u5728\u65e0\u610f\u504f\u89c1\uff08\u5982\u6027\u522b\u6216\u79cd\u65cf\u504f\u89c1\uff09\u3001\u8de8\u4e34\u5e8a\u73af\u5883\u6cdb\u5316\u6027\u5dee\uff08\u4e0d\u540cEHR\u7cfb\u7edf\u95f4\u6a21\u578b\u6027\u80fd\u5dee\u5f02\u5927\uff09\u548c\u53ef\u89e3\u91ca\u6027\u5dee\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u4e34\u5e8a\u81ea\u7531\u6587\u672c\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u7684\u3001\u4efb\u52a1\u7279\u5b9a\u7684\u95ee\u7b54\u5bf9\uff0c\u4f5c\u4e3a\u9884\u6d4b\u5efa\u6a21\u7684\u524d\u7f6e\u6b65\u9aa4\u3002", "result": "\u5728ICU\u6b7b\u4ea1\u7387\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0c\u4e0e\u76f4\u63a5\u5fae\u8c03\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u4ec5\u5bfc\u81f4\u9884\u6d4b\u6027\u80fd\u8f7b\u5fae\u4e0b\u964d\uff08AUC\u4e0b\u964d2-3%\uff09\uff0c\u4f46\u663e\u8457\u63d0\u9ad8\u4e86\u900f\u660e\u5ea6\u548c\u53ef\u63a7\u6027\u3002", "conclusion": "ClinStructor\u4e3a\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u6784\u5efa\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u6cdb\u5316\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2511.11693", "categories": ["cs.AI", "cs.CR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11693", "abs": "https://arxiv.org/abs/2511.11693", "authors": ["Xin Zhao", "Xiaojun Chen", "Bingshan Liu", "Zeyao Liu", "Zhendong Zhao", "Xiaoyan Gu"], "title": "Value-Aligned Prompt Moderation via Zero-Shot Agentic Rewriting for Safe Image Generation", "comment": null, "summary": "Generative vision-language models like Stable Diffusion demonstrate remarkable capabilities in creative media synthesis, but they also pose substantial risks of producing unsafe, offensive, or culturally inappropriate content when prompted adversarially. Current defenses struggle to align outputs with human values without sacrificing generation quality or incurring high costs. To address these challenges, we introduce VALOR (Value-Aligned LLM-Overseen Rewriter), a modular, zero-shot agentic framework for safer and more helpful text-to-image generation. VALOR integrates layered prompt analysis with human-aligned value reasoning: a multi-level NSFW detector filters lexical and semantic risks; a cultural value alignment module identifies violations of social norms, legality, and representational ethics; and an intention disambiguator detects subtle or indirect unsafe implications. When unsafe content is detected, prompts are selectively rewritten by a large language model under dynamic, role-specific instructions designed to preserve user intent while enforcing alignment. If the generated image still fails a safety check, VALOR optionally performs a stylistic regeneration to steer the output toward a safer visual domain without altering core semantics. Experiments across adversarial, ambiguous, and value-sensitive prompts show that VALOR significantly reduces unsafe outputs by up to 100.00% while preserving prompt usefulness and creativity. These results highlight VALOR as a scalable and effective approach for deploying safe, aligned, and helpful image generation systems in open-world settings.", "AI": {"tldr": "VALOR\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u96f6\u6837\u672c\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u63d0\u793a\u5206\u6790\u3001\u4ef7\u503c\u5bf9\u9f50\u63a8\u7406\u548c\u9009\u62e9\u6027\u91cd\u5199\uff0c\u5728\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e0d\u5b89\u5168\u56fe\u50cf\u5185\u5bb9\u3002", "motivation": "\u751f\u6210\u5f0f\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u751f\u6210\u4e0d\u5b89\u5168\u3001\u5192\u72af\u6027\u6216\u6587\u5316\u4e0d\u5f53\u5185\u5bb9\u7684\u98ce\u9669\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u96be\u4ee5\u5728\u4e0d\u727a\u7272\u751f\u6210\u8d28\u91cf\u6216\u589e\u52a0\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4ef7\u503c\u5bf9\u9f50\u3002", "method": "\u91c7\u7528\u5206\u5c42\u63d0\u793a\u5206\u6790\uff1a\u591a\u7ea7NSFW\u68c0\u6d4b\u5668\u8fc7\u6ee4\u8bcd\u6c47\u548c\u8bed\u4e49\u98ce\u9669\uff1b\u6587\u5316\u4ef7\u503c\u5bf9\u9f50\u6a21\u5757\u8bc6\u522b\u793e\u4f1a\u89c4\u8303\u3001\u5408\u6cd5\u6027\u548c\u4f26\u7406\u8fdd\u89c4\uff1b\u610f\u56fe\u6d88\u6b67\u5668\u68c0\u6d4b\u9690\u542b\u4e0d\u5b89\u5168\u542b\u4e49\u3002\u68c0\u6d4b\u5230\u4e0d\u5b89\u5168\u5185\u5bb9\u65f6\uff0c\u7531\u5927\u8bed\u8a00\u6a21\u578b\u5728\u52a8\u6001\u89d2\u8272\u7279\u5b9a\u6307\u4ee4\u4e0b\u9009\u62e9\u6027\u91cd\u5199\u63d0\u793a\u3002", "result": "\u5728\u5bf9\u6297\u6027\u3001\u6a21\u7cca\u6027\u548c\u4ef7\u503c\u654f\u611f\u63d0\u793a\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cVALOR\u5c06\u4e0d\u5b89\u5168\u8f93\u51fa\u51cf\u5c11\u9ad8\u8fbe100.00%\uff0c\u540c\u65f6\u4fdd\u6301\u63d0\u793a\u7684\u6709\u7528\u6027\u548c\u521b\u9020\u6027\u3002", "conclusion": "VALOR\u662f\u53ef\u6269\u5c55\u4e14\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u53ef\u5728\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u90e8\u7f72\u5b89\u5168\u3001\u5bf9\u9f50\u4e14\u6709\u7528\u7684\u56fe\u50cf\u751f\u6210\u7cfb\u7edf\u3002"}}
{"id": "2511.11884", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.11884", "abs": "https://arxiv.org/abs/2511.11884", "authors": ["Eric Hua Qing Zhang", "Julia Ive"], "title": "Context-Emotion Aware Therapeutic Dialogue Generation: A Multi-component Reinforcement Learning Approach to Language Models for Mental Health Support", "comment": null, "summary": "Mental health illness represents a substantial global socioeconomic burden, with COVID-19 further exacerbating accessibility challenges and driving increased demand for telehealth mental health support. While large language models (LLMs) offer promising solutions through 24/7 availability and non-judgmental interactions, pre-trained models often lack the contextual and emotional awareness necessary for appropriate therapeutic responses. This paper investigated the application of supervised fine-tuning (SFT) and reinforcement learning (RL) techniques to enhance GPT-2's capacity for therapeutic dialogue generation. The methodology restructured input formats to enable simultaneous processing of contextual information and emotional states alongside user input, employing a multi-component reward function that aligned model outputs with professional therapist responses and annotated emotions. Results demonstrated improvements through reinforcement learning over baseline GPT-2 across multiple evaluation metrics: BLEU (0.0111), ROUGE-1 (0.1397), ROUGE-2 (0.0213), ROUGE-L (0.1317), and METEOR (0.0581). LLM evaluation confirmed high contextual relevance and professionalism, while reinforcement learning achieved 99.34% emotion accuracy compared to 66.96% for baseline GPT-2. These findings demonstrate reinforcement learning's effectiveness in developing therapeutic dialogue systems that can serve as valuable assistive tools for therapists while maintaining essential human clinical oversight.", "AI": {"tldr": "\u901a\u8fc7\u76d1\u7763\u5fae\u8c03(SFT)\u548c\u5f3a\u5316\u5b66\u4e60(RL)\u6280\u672f\u589e\u5f3aGPT-2\u7684\u5fc3\u7406\u6cbb\u7597\u5bf9\u8bdd\u751f\u6210\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u7279\u522b\u662f\u60c5\u611f\u51c6\u786e\u7387\u8fbe\u523099.34%\u3002", "motivation": "COVID-19\u52a0\u5267\u4e86\u5fc3\u7406\u5065\u5eb7\u670d\u52a1\u7684\u53ef\u53ca\u6027\u6311\u6218\uff0c\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u63d0\u4f9b24/7\u53ef\u7528\u6027\u548c\u975e\u8bc4\u5224\u6027\u4e92\u52a8\uff0c\u4f46\u9884\u8bad\u7ec3\u6a21\u578b\u7f3a\u4e4f\u60c5\u5883\u548c\u60c5\u611f\u610f\u8bc6\uff0c\u65e0\u6cd5\u63d0\u4f9b\u9002\u5f53\u7684\u6cbb\u7597\u54cd\u5e94\u3002", "method": "\u91cd\u6784\u8f93\u5165\u683c\u5f0f\u4ee5\u540c\u65f6\u5904\u7406\u60c5\u5883\u4fe1\u606f\u548c\u60c5\u611f\u72b6\u6001\uff0c\u91c7\u7528\u591a\u7ec4\u4ef6\u5956\u52b1\u51fd\u6570\u4f7f\u6a21\u578b\u8f93\u51fa\u4e0e\u4e13\u4e1a\u6cbb\u7597\u5e08\u54cd\u5e94\u548c\u6807\u6ce8\u60c5\u611f\u5bf9\u9f50\uff0c\u5e94\u7528\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u3002", "result": "\u5f3a\u5316\u5b66\u4e60\u5728\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u4f18\u4e8e\u57fa\u7ebfGPT-2\uff1aBLEU(0.0111)\u3001ROUGE-1(0.1397)\u3001ROUGE-2(0.0213)\u3001ROUGE-L(0.1317)\u3001METEOR(0.0581)\uff0c\u60c5\u611f\u51c6\u786e\u7387\u8fbe\u523099.34%(\u57fa\u7ebf\u4e3a66.96%)\uff0cLLM\u8bc4\u4f30\u786e\u8ba4\u9ad8\u60c5\u5883\u76f8\u5173\u6027\u548c\u4e13\u4e1a\u6027\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u5728\u5f00\u53d1\u6cbb\u7597\u5bf9\u8bdd\u7cfb\u7edf\u65b9\u9762\u5177\u6709\u6709\u6548\u6027\uff0c\u53ef\u4f5c\u4e3a\u6cbb\u7597\u5e08\u7684\u6709\u4ef7\u503c\u8f85\u52a9\u5de5\u5177\uff0c\u540c\u65f6\u4fdd\u6301\u5fc5\u8981\u7684\u4eba\u7c7b\u4e34\u5e8a\u76d1\u7763\u3002"}}
{"id": "2511.11752", "categories": ["cs.AI", "cs.DL", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.11752", "abs": "https://arxiv.org/abs/2511.11752", "authors": ["S\u00f6ren Arlt", "Xuemei Gu", "Mario Krenn"], "title": "Towards autonomous quantum physics research using LLM agents with access to intelligent tools", "comment": "24 pages, 5 figures", "summary": "Artificial intelligence (AI) is used in numerous fields of science, yet the initial research questions and targets are still almost always provided by human researchers. AI-generated creative ideas in science are rare and often vague, so that it remains a human task to execute them. Automating idea generation and implementation in one coherent system would significantly shift the role of humans in the scientific process. Here we present AI-Mandel, an LLM agent that can generate and implement ideas in quantum physics. AI-Mandel formulates ideas from the literature and uses a domain-specific AI tool to turn them into concrete experiment designs that can readily be implemented in laboratories. The generated ideas by AI-Mandel are often scientifically interesting - for two of them we have already written independent scientific follow-up papers. The ideas include new variations of quantum teleportation, primitives of quantum networks in indefinite causal orders, and new concepts of geometric phases based on closed loops of quantum information transfer. AI-Mandel is a prototypical demonstration of an AI physicist that can generate and implement concrete, actionable ideas. Building such a system is not only useful to accelerate science, but it also reveals concrete open challenges on the path to human-level artificial scientists.", "AI": {"tldr": "AI-Mandel\u662f\u4e00\u4e2a\u80fd\u591f\u751f\u6210\u5e76\u5b9e\u73b0\u91cf\u5b50\u7269\u7406\u5b66\u521b\u610f\u7684LLM\u4ee3\u7406\uff0c\u5b83\u4ece\u6587\u732e\u4e2d\u6784\u601d\u60f3\u6cd5\u5e76\u4f7f\u7528\u9886\u57df\u7279\u5b9aAI\u5de5\u5177\u5c06\u5176\u8f6c\u5316\u4e3a\u53ef\u76f4\u63a5\u5728\u5b9e\u9a8c\u5ba4\u5b9e\u65bd\u7684\u5b9e\u9a8c\u8bbe\u8ba1\u3002", "motivation": "\u5f53\u524dAI\u5728\u79d1\u5b66\u9886\u57df\u7684\u5e94\u7528\u4ecd\u4e3b\u8981\u4f9d\u8d56\u4eba\u7c7b\u7814\u7a76\u8005\u63d0\u4f9b\u521d\u59cb\u7814\u7a76\u95ee\u9898\uff0cAI\u751f\u6210\u7684\u521b\u610f\u5f80\u5f80\u6a21\u7cca\u4e14\u9700\u8981\u4eba\u7c7b\u6267\u884c\u3002\u81ea\u52a8\u5316\u521b\u610f\u751f\u6210\u4e0e\u5b9e\u73b0\u7cfb\u7edf\u5c06\u663e\u8457\u6539\u53d8\u4eba\u7c7b\u5728\u79d1\u5b66\u8fc7\u7a0b\u4e2d\u7684\u89d2\u8272\u3002", "method": "AI-Mandel\u4f7f\u7528LLM\u4ece\u6587\u732e\u4e2d\u751f\u6210\u521b\u610f\uff0c\u5e76\u901a\u8fc7\u9886\u57df\u7279\u5b9aAI\u5de5\u5177\u5c06\u8fd9\u4e9b\u521b\u610f\u8f6c\u5316\u4e3a\u5177\u4f53\u7684\u5b9e\u9a8c\u8bbe\u8ba1\u65b9\u6848\u3002", "result": "AI-Mandel\u751f\u6210\u7684\u521b\u610f\u5177\u6709\u79d1\u5b66\u4ef7\u503c\uff0c\u5176\u4e2d\u4e24\u4e2a\u521b\u610f\u5df2\u72ec\u7acb\u64b0\u5199\u6210\u540e\u7eed\u79d1\u5b66\u8bba\u6587\u3002\u521b\u610f\u5305\u62ec\u91cf\u5b50\u9690\u5f62\u4f20\u6001\u7684\u65b0\u53d8\u4f53\u3001\u4e0d\u5b9a\u56e0\u679c\u987a\u5e8f\u4e2d\u7684\u91cf\u5b50\u7f51\u7edc\u539f\u8bed\u4ee5\u53ca\u57fa\u4e8e\u91cf\u5b50\u4fe1\u606f\u4f20\u9012\u95ed\u73af\u7684\u65b0\u51e0\u4f55\u76f8\u4f4d\u6982\u5ff5\u3002", "conclusion": "AI-Mandel\u5c55\u793a\u4e86\u80fd\u591f\u751f\u6210\u548c\u5b9e\u65bd\u5177\u4f53\u53ef\u884c\u521b\u610f\u7684AI\u7269\u7406\u5b66\u5bb6\u539f\u578b\uff0c\u8fd9\u4e0d\u4ec5\u6709\u52a9\u4e8e\u52a0\u901f\u79d1\u5b66\u53d1\u5c55\uff0c\u8fd8\u63ed\u793a\u4e86\u5b9e\u73b0\u4eba\u7c7b\u6c34\u5e73\u4eba\u5de5\u79d1\u5b66\u5bb6\u6240\u9762\u4e34\u7684\u5177\u4f53\u6311\u6218\u3002"}}
{"id": "2511.11922", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11922", "abs": "https://arxiv.org/abs/2511.11922", "authors": ["Karthikeyan K", "Raghuveer Thirukovalluru", "David Carlson"], "title": "Additive Large Language Models for Semi-Structured Text", "comment": null, "summary": "Large Language Models have advanced clinical text classification, but their opaque predictions remain a critical barrier to practical adoption in research and clinical settings where investigators and physicians need to understand which parts of a patient's record drive risk signals. To address this challenge, we introduce \\textbf{CALM}, short for \\textbf{Classification with Additive Large Language Models}, an interpretable framework for semi-structured text where inputs are composed of semantically meaningful components, such as sections of an admission note or question-answer fields from an intake form. CALM predicts outcomes as the additive sum of each component's contribution, making these contributions part of the forward computation itself and enabling faithful explanations at both the patient and population level. The additive structure also enables clear visualizations, such as component-level risk curves similar to those used in generalized additive models, making the learned relationships easier to inspect and communicate. Although CALM expects semi-structured inputs, many clinical documents already have this form, and similar structure can often be automatically extracted from free-text notes. CALM achieves performance comparable to conventional LLM classifiers while improving trust, supporting quality-assurance checks, and revealing clinically meaningful patterns during model development and auditing.", "AI": {"tldr": "CALM\u662f\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u4e34\u5e8a\u6587\u672c\u5206\u7c7b\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u9884\u6d4b\u5206\u89e3\u4e3a\u5404\u8bed\u4e49\u7ec4\u4ef6\u7684\u52a0\u6027\u8d21\u732e\uff0c\u63d0\u4f9b\u900f\u660e\u7684\u98ce\u9669\u89e3\u91ca\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u6587\u672c\u5206\u7c7b\u4e2d\u9884\u6d4b\u4e0d\u900f\u660e\u7684\u95ee\u9898\uff0c\u6ee1\u8db3\u7814\u7a76\u4eba\u5458\u548c\u533b\u751f\u9700\u8981\u7406\u89e3\u60a3\u8005\u8bb0\u5f55\u4e2d\u54ea\u4e9b\u90e8\u5206\u9a71\u52a8\u98ce\u9669\u4fe1\u53f7\u7684\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u52a0\u6027\u5927\u8bed\u8a00\u6a21\u578b\u6846\u67b6\uff0c\u5c06\u534a\u7ed3\u6784\u5316\u6587\u672c\u8f93\u5165\u5206\u89e3\u4e3a\u8bed\u4e49\u7ec4\u4ef6\uff0c\u9884\u6d4b\u7ed3\u679c\u4e3a\u5404\u7ec4\u4ef6\u8d21\u732e\u7684\u52a0\u6027\u603b\u548c\uff0c\u5b9e\u73b0\u5fe0\u5b9e\u89e3\u91ca\u3002", "result": "CALM\u5728\u4fdd\u6301\u4e0e\u4f20\u7edfLLM\u5206\u7c7b\u5668\u76f8\u5f53\u6027\u80fd\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u53ef\u4fe1\u5ea6\uff0c\u652f\u6301\u8d28\u91cf\u4fdd\u8bc1\u68c0\u67e5\uff0c\u5e76\u5728\u6a21\u578b\u5f00\u53d1\u548c\u5ba1\u8ba1\u4e2d\u63ed\u793a\u4e86\u4e34\u5e8a\u6709\u610f\u4e49\u7684\u6a21\u5f0f\u3002", "conclusion": "CALM\u6846\u67b6\u4e3a\u4e34\u5e8a\u6587\u672c\u5206\u7c7b\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u52a0\u6027\u7ed3\u6784\u5b9e\u73b0\u4e86\u900f\u660e\u9884\u6d4b\uff0c\u6709\u52a9\u4e8e\u5728\u7814\u7a76\u548c\u4e34\u5e8a\u73af\u5883\u4e2d\u63a8\u5e7f\u5e94\u7528\u3002"}}
{"id": "2511.11770", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11770", "abs": "https://arxiv.org/abs/2511.11770", "authors": ["Floris Vossebeld", "Shenghui Wang"], "title": "Learning to Refine: An Agentic RL Approach for Iterative SPARQL Query Construction", "comment": null, "summary": "Generating complex, logically-sound SPARQL queries for multi-hop questions remains a critical bottleneck for Knowledge Graph Question Answering, as the brittle nature of one-shot generation by Large Language Models (LLMs) hinders reliable interaction with structured data. Current methods lack the adaptive policies needed to dynamically debug queries based on real-time execution feedback. This paper introduces a novel agentic framework where an LLM learns a resilient policy for the sequential process of iterative SPARQL construction. We show that a compact 3B-parameter model, trained exclusively via outcome-driven Reinforcement Learning (GRPO) without supervised fine-tuning, can learn effective policies for this task, discovering how to systematically recover from execution errors and refine its queries toward a correct answer. On a curated, executable single-answer subset of LC-QuAD 2.0, our agent achieves 49.7\\% accuracy post-entity-linking, a significant 17.5 percentage point improvement over the strongest iterative zero-shot baseline. Further analysis reveals that while the agent's capability is driven by RL, its performance is enhanced by an explicit deliberative reasoning step that acts as a cognitive scaffold to improve policy precision. This work presents a generalizable blueprint for teaching agents to master formal, symbolic tools through interaction, bridging the gap between probabilistic LLMs and the structured world of Knowledge Graphs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u8ba9\u5c0f\u578bLLM\u901a\u8fc7\u8fed\u4ee3\u6267\u884c\u53cd\u9988\u5b66\u4e60SPARQL\u67e5\u8be2\u6784\u5efa\u7b56\u7565\uff0c\u5728LC-QuAD 2.0\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8649.7%\u7684\u51c6\u786e\u7387\uff0c\u6bd4\u6700\u4f73\u96f6\u6837\u672c\u57fa\u7ebf\u63d0\u534717.5\u4e2a\u767e\u5206\u70b9\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u751f\u6210\u590d\u6742\u591a\u8df3SPARQL\u67e5\u8be2\u65f6\u7684\u8106\u5f31\u6027\u95ee\u9898\uff0c\u5f53\u524d\u65b9\u6cd5\u7f3a\u4e4f\u57fa\u4e8e\u5b9e\u65f6\u6267\u884c\u53cd\u9988\u7684\u52a8\u6001\u8c03\u8bd5\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u4ec53B\u53c2\u6570\u7684LLM\uff0c\u901a\u8fc7\u7ed3\u679c\u9a71\u52a8\u7684\u5f3a\u5316\u5b66\u4e60\uff08GRPO\uff09\u8bad\u7ec3\uff0c\u65e0\u9700\u76d1\u7763\u5fae\u8c03\uff0c\u5b66\u4e60\u8fed\u4ee3SPARQL\u6784\u5efa\u7684\u5f39\u6027\u7b56\u7565\uff0c\u5305\u542b\u663e\u5f0f\u63a8\u7406\u6b65\u9aa4\u4f5c\u4e3a\u8ba4\u77e5\u652f\u67b6\u3002", "result": "\u5728LC-QuAD 2.0\u7684\u53ef\u6267\u884c\u5b50\u96c6\u4e0a\u8fbe\u523049.7%\u7684\u51c6\u786e\u7387\uff0c\u76f8\u6bd4\u6700\u4f73\u96f6\u6837\u672c\u57fa\u7ebf\u63d0\u534717.5\u4e2a\u767e\u5206\u70b9\uff0c\u5f3a\u5316\u5b66\u4e60\u9a71\u52a8\u7684\u80fd\u529b\u901a\u8fc7\u663e\u5f0f\u63a8\u7406\u6b65\u9aa4\u5f97\u5230\u589e\u5f3a\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u63a8\u5e7f\u7684\u84dd\u56fe\uff0c\u901a\u8fc7\u4ea4\u4e92\u6559\u5b66\u667a\u80fd\u4f53\u638c\u63e1\u5f62\u5f0f\u5316\u7b26\u53f7\u5de5\u5177\uff0c\u5f25\u5408\u6982\u7387\u6027LLM\u4e0e\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2511.11933", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11933", "abs": "https://arxiv.org/abs/2511.11933", "authors": ["Karthikeyan K", "Raghuveer Thirukovalluru", "Bhuwan Dhingra", "David Edwin Carlson"], "title": "InData: Towards Secure Multi-Step, Tool-Based Data Analysis", "comment": null, "summary": "Large language model agents for data analysis typically generate and execute code directly on databases. However, when applied to sensitive data, this approach poses significant security risks. To address this issue, we propose a security-motivated alternative: restrict LLMs from direct code generation and data access, and require them to interact with data exclusively through a predefined set of secure, verified tools. Although recent tool-use benchmarks exist, they primarily target tool selection and simple execution rather than the compositional, multi-step reasoning needed for complex data analysis. To reduce this gap, we introduce Indirect Data Engagement (InData), a dataset designed to assess LLMs' multi-step tool-based reasoning ability. InData includes data analysis questions at three difficulty levels--Easy, Medium, and Hard--capturing increasing reasoning complexity. We benchmark 15 open-source LLMs on InData and find that while large models (e.g., gpt-oss-120b) achieve high accuracy on Easy tasks (97.3%), performance drops sharply on Hard tasks (69.6%). These results show that current LLMs still lack robust multi-step tool-based reasoning ability. With InData, we take a step toward enabling the development and evaluation of LLMs with stronger multi-step tool-use capabilities. We will publicly release the dataset and code.", "AI": {"tldr": "\u63d0\u51fa\u4e86InData\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u5728\u591a\u6b65\u9aa4\u5de5\u5177\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524dLLMs\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u4f20\u7edfLLM\u6570\u636e\u4ee3\u7406\u76f4\u63a5\u751f\u6210\u548c\u6267\u884c\u4ee3\u7801\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u9650\u5236LLMs\u53ea\u80fd\u901a\u8fc7\u9884\u5b9a\u4e49\u7684\u5b89\u5168\u5de5\u5177\u4e0e\u6570\u636e\u4ea4\u4e92\u3002", "method": "\u6784\u5efaInData\u6570\u636e\u96c6\uff0c\u5305\u542b\u4e09\u4e2a\u96be\u5ea6\u7ea7\u522b\u7684\u6570\u636e\u5206\u6790\u95ee\u9898\uff0c\u8bc4\u4f3015\u4e2a\u5f00\u6e90LLMs\u5728\u591a\u6b65\u9aa4\u5de5\u5177\u63a8\u7406\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5927\u578b\u6a21\u578b\u5728\u7b80\u5355\u4efb\u52a1\u4e0a\u51c6\u786e\u7387\u9ad8\uff0897.3%\uff09\uff0c\u4f46\u5728\u56f0\u96be\u4efb\u52a1\u4e0a\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff0869.6%\uff09\uff0c\u663e\u793a\u5f53\u524dLLMs\u7f3a\u4e4f\u7a33\u5065\u7684\u591a\u6b65\u9aa4\u5de5\u5177\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "InData\u6570\u636e\u96c6\u4e3a\u5f00\u53d1\u548c\u8bc4\u4f30\u5177\u6709\u66f4\u5f3a\u591a\u6b65\u9aa4\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u7684LLMs\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\uff0c\u5c06\u516c\u5f00\u53d1\u5e03\u6570\u636e\u96c6\u548c\u4ee3\u7801\u3002"}}
{"id": "2511.11773", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11773", "abs": "https://arxiv.org/abs/2511.11773", "authors": ["Ruchira Dhar", "Ninell Oldenburg", "Anders Soegaard"], "title": "On the Measure of a Model: From Intelligence to Generality", "comment": "Accepted at EurIPS Workshop on \"The Science of Benchmarking and Evaluating AI\"", "summary": "Benchmarks such as ARC, Raven-inspired tests, and the Blackbird Task are widely used to evaluate the intelligence of large language models (LLMs). Yet, the concept of intelligence remains elusive- lacking a stable definition and failing to predict performance on practical tasks such as question answering, summarization, or coding. Optimizing for such benchmarks risks misaligning evaluation with real-world utility. Our perspective is that evaluation should be grounded in generality rather than abstract notions of intelligence. We identify three assumptions that often underpin intelligence-focused evaluation: generality, stability, and realism. Through conceptual and formal analysis, we show that only generality withstands conceptual and empirical scrutiny. Intelligence is not what enables generality; generality is best understood as a multitask learning problem that directly links evaluation to measurable performance breadth and reliability. This perspective reframes how progress in AI should be assessed and proposes generality as a more stable foundation for evaluating capability across diverse and evolving tasks.", "AI": {"tldr": "\u8bba\u6587\u8d28\u7591\u5f53\u524d\u57fa\u4e8e\u62bd\u8c61\u667a\u529b\u6982\u5ff5\u7684AI\u8bc4\u4f30\u57fa\u51c6\uff0c\u63d0\u51fa\u5e94\u4ee5\u901a\u7528\u6027\u800c\u975e\u667a\u529b\u4f5c\u4e3a\u8bc4\u4f30\u57fa\u7840\uff0c\u8ba4\u4e3a\u901a\u7528\u6027\u66f4\u80fd\u53cd\u6620\u6a21\u578b\u5728\u591a\u6837\u5316\u4efb\u52a1\u4e2d\u7684\u5b9e\u9645\u8868\u73b0\u3002", "motivation": "\u5f53\u524dAI\u8bc4\u4f30\u57fa\u51c6\uff08\u5982ARC\u3001Raven\u6d4b\u8bd5\u7b49\uff09\u57fa\u4e8e\u6a21\u7cca\u7684\u667a\u529b\u6982\u5ff5\uff0c\u65e0\u6cd5\u6709\u6548\u9884\u6d4b\u6a21\u578b\u5728\u5b9e\u9645\u4efb\u52a1\uff08\u5982\u95ee\u7b54\u3001\u6458\u8981\u3001\u7f16\u7a0b\uff09\u4e2d\u7684\u8868\u73b0\uff0c\u5b58\u5728\u8bc4\u4f30\u4e0e\u5b9e\u9645\u6548\u7528\u8131\u8282\u7684\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u6982\u5ff5\u548c\u5f62\u5f0f\u5206\u6790\uff0c\u68c0\u9a8c\u667a\u529b\u8bc4\u4f30\u7684\u4e09\u4e2a\u5047\u8bbe\uff08\u901a\u7528\u6027\u3001\u7a33\u5b9a\u6027\u3001\u73b0\u5b9e\u6027\uff09\uff0c\u8bba\u8bc1\u53ea\u6709\u901a\u7528\u6027\u80fd\u591f\u7ecf\u53d7\u6982\u5ff5\u548c\u5b9e\u8bc1\u68c0\u9a8c\u3002", "result": "\u5206\u6790\u8868\u660e\u667a\u529b\u4e0d\u80fd\u89e3\u91ca\u901a\u7528\u6027\uff0c\u901a\u7528\u6027\u5e94\u88ab\u7406\u89e3\u4e3a\u591a\u4efb\u52a1\u5b66\u4e60\u95ee\u9898\uff0c\u76f4\u63a5\u5173\u8054\u5230\u53ef\u6d4b\u91cf\u7684\u6027\u80fd\u5e7f\u5ea6\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u5e94\u91cd\u65b0\u6784\u5efaAI\u8fdb\u5c55\u8bc4\u4f30\u65b9\u5f0f\uff0c\u5c06\u901a\u7528\u6027\u4f5c\u4e3a\u8bc4\u4f30\u8de8\u9886\u57df\u548c\u6f14\u8fdb\u4efb\u52a1\u80fd\u529b\u7684\u66f4\u7a33\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.11946", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11946", "abs": "https://arxiv.org/abs/2511.11946", "authors": ["Hadi Sheikhi", "Chenyang Huang", "Osmar R. Za\u00efane"], "title": "Improving LLM's Attachment to External Knowledge In Dialogue Generation Tasks Through Entity Anonymization", "comment": null, "summary": "Knowledge graph-based dialogue generation (KG-DG) is a challenging task requiring models to effectively incorporate external knowledge into conversational responses. While large language models (LLMs) have achieved impressive results across various NLP tasks, their ability to utilize external knowledge in KG-DG remains under-explored. We observe that LLMs often rely on internal knowledge, leading to detachment from provided knowledge graphs, even when they are given a flawlessly retrieved knowledge graph. First, we introduce LLM-KAT, an evaluation procedure for measuring knowledge attachment in generated responses. Second, we propose a simple yet effective entity anonymization technique to encourage LLMs to better leverage external knowledge. Experiments on the OpenDialKG dataset demonstrate that our approach improves LLMs' attachment on external knowledge.", "AI": {"tldr": "LLM-KAT\u8bc4\u4f30\u7a0b\u5e8f\u8861\u91cf\u77e5\u8bc6\u56fe\u8c31\u5bf9\u8bdd\u751f\u6210\u4e2d\u7684\u77e5\u8bc6\u9644\u7740\u5ea6\uff0c\u5e76\u63d0\u51fa\u5b9e\u4f53\u533f\u540d\u5316\u6280\u672f\u6765\u63d0\u5347LLM\u4f7f\u7528\u5916\u90e8\u77e5\u8bc6\u7684\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u56fe\u8c31\u5bf9\u8bdd\u751f\u6210\u4efb\u52a1\u4e2d\u8fc7\u5ea6\u4f9d\u8d56\u5185\u90e8\u77e5\u8bc6\uff0c\u5373\u4f7f\u63d0\u4f9b\u4e86\u51c6\u786e\u7684\u77e5\u8bc6\u56fe\u8c31\u4e5f\u96be\u4ee5\u6709\u6548\u5229\u7528\u5916\u90e8\u77e5\u8bc6\u3002", "method": "\u63d0\u51fa\u4e86LLM-KAT\u8bc4\u4f30\u7a0b\u5e8f\u6765\u8861\u91cf\u77e5\u8bc6\u9644\u7740\u5ea6\uff0c\u5e76\u91c7\u7528\u5b9e\u4f53\u533f\u540d\u5316\u6280\u672f\u6765\u9f13\u52b1LLM\u66f4\u597d\u5730\u5229\u7528\u5916\u90e8\u77e5\u8bc6\u3002", "result": "\u5728OpenDialKG\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86LLM\u5bf9\u5916\u90e8\u77e5\u8bc6\u7684\u9644\u7740\u5ea6\u3002", "conclusion": "\u5b9e\u4f53\u533f\u540d\u5316\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u6280\u672f\uff0c\u80fd\u591f\u6539\u5584LLM\u5728\u77e5\u8bc6\u56fe\u8c31\u5bf9\u8bdd\u751f\u6210\u4e2d\u5bf9\u5916\u90e8\u77e5\u8bc6\u7684\u5229\u7528\u80fd\u529b\u3002"}}
{"id": "2511.11816", "categories": ["cs.AI", "cs.CL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.11816", "abs": "https://arxiv.org/abs/2511.11816", "authors": ["Andrea Brunello", "Luca Geatti", "Michele Mignani", "Angelo Montanari", "Nicola Saccomanno"], "title": "Do LLMs Really Struggle at NL-FOL Translation? Revealing their Strengths via a Novel Benchmarking Strategy", "comment": "Full version of the paper accepted for publication at The 40th Annual AAAI Conference on Artificial Intelligence (AAAI 2026)", "summary": "Due to its expressiveness and unambiguous nature, First-Order Logic (FOL) is a powerful formalism for representing concepts expressed in natural language (NL). This is useful, e.g., for specifying and verifying desired system properties. While translating FOL into human-readable English is relatively straightforward, the inverse problem, converting NL to FOL (NL-FOL translation), has remained a longstanding challenge, for both humans and machines. Although the emergence of Large Language Models (LLMs) promised a breakthrough, recent literature provides contrasting results on their ability to perform NL-FOL translation. In this work, we provide a threefold contribution. First, we critically examine existing datasets and protocols for evaluating NL-FOL translation performance, revealing key limitations that may cause a misrepresentation of LLMs' actual capabilities. Second, to overcome these shortcomings, we propose a novel evaluation protocol explicitly designed to distinguish genuine semantic-level logical understanding from superficial pattern recognition, memorization, and dataset contamination. Third, using this new approach, we show that state-of-the-art, dialogue-oriented LLMs demonstrate strong NL-FOL translation skills and a genuine grasp of sentence-level logic, whereas embedding-centric models perform markedly worse.", "AI": {"tldr": "\u672c\u6587\u6279\u5224\u6027\u8bc4\u4f30\u4e86\u73b0\u6709NL-FOL\u7ffb\u8bd1\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u8bc4\u4f30\u534f\u8bae\u6765\u533a\u5206\u771f\u6b63\u7684\u8bed\u4e49\u7406\u89e3\u4e0e\u8868\u9762\u6a21\u5f0f\u8bc6\u522b\uff0c\u5e76\u53d1\u73b0\u5bf9\u8bdd\u5bfc\u5411\u7684LLMs\u5728NL-FOL\u7ffb\u8bd1\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u7531\u4e8e\u4e00\u9636\u903b\u8f91(FOL)\u7684\u8868\u8fbe\u80fd\u529b\u548c\u660e\u786e\u6027\uff0c\u5b83\u662f\u8868\u793a\u81ea\u7136\u8bed\u8a00(NL)\u6982\u5ff5\u7684\u5f3a\u5927\u5f62\u5f0f\u5316\u5de5\u5177\u3002\u867d\u7136\u5c06FOL\u7ffb\u8bd1\u6210\u53ef\u8bfb\u82f1\u8bed\u76f8\u5bf9\u7b80\u5355\uff0c\u4f46\u5c06NL\u8f6c\u6362\u4e3aFOL(NL-FOL\u7ffb\u8bd1)\u5bf9\u4eba\u548c\u673a\u5668\u90fd\u662f\u957f\u671f\u6311\u6218\u3002\u5c3d\u7ba1LLMs\u7684\u51fa\u73b0\u5e26\u6765\u4e86\u7a81\u7834\u5e0c\u671b\uff0c\u4f46\u73b0\u6709\u6587\u732e\u5bf9\u5176NL-FOL\u7ffb\u8bd1\u80fd\u529b\u7ed9\u51fa\u4e86\u77db\u76fe\u7684\u7ed3\u679c\u3002", "method": "1) \u6279\u5224\u6027\u68c0\u67e5\u73b0\u6709NL-FOL\u7ffb\u8bd1\u8bc4\u4f30\u6570\u636e\u96c6\u548c\u534f\u8bae\uff1b2) \u63d0\u51fa\u65b0\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u4e13\u95e8\u533a\u5206\u771f\u6b63\u7684\u8bed\u4e49\u7ea7\u903b\u8f91\u7406\u89e3\u4e0e\u8868\u9762\u6a21\u5f0f\u8bc6\u522b\u3001\u8bb0\u5fc6\u548c\u6570\u636e\u96c6\u6c61\u67d3\uff1b3) \u4f7f\u7528\u65b0\u65b9\u6cd5\u8bc4\u4f30\u6700\u5148\u8fdb\u7684\u5bf9\u8bdd\u5bfc\u5411LLMs\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6700\u5148\u8fdb\u7684\u5bf9\u8bdd\u5bfc\u5411LLMs\u5c55\u73b0\u51fa\u5f3a\u5927\u7684NL-FOL\u7ffb\u8bd1\u6280\u80fd\u548c\u771f\u6b63\u7684\u53e5\u5b50\u7ea7\u903b\u8f91\u7406\u89e3\u80fd\u529b\uff0c\u800c\u5d4c\u5165\u4e2d\u5fc3\u6a21\u578b\u8868\u73b0\u660e\u663e\u8f83\u5dee\u3002", "conclusion": "\u901a\u8fc7\u8bbe\u8ba1\u9002\u5f53\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u53ef\u4ee5\u66f4\u51c6\u786e\u5730\u8bc4\u4f30LLMs\u7684NL-FOL\u7ffb\u8bd1\u80fd\u529b\uff0c\u5bf9\u8bdd\u5bfc\u5411\u7684LLMs\u5728\u6b64\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u8868\u660e\u5b83\u4eec\u5177\u6709\u771f\u6b63\u7684\u903b\u8f91\u7406\u89e3\u80fd\u529b\u3002"}}
{"id": "2511.11966", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.11966", "abs": "https://arxiv.org/abs/2511.11966", "authors": ["Steven Cao", "Gregory Valiant", "Percy Liang"], "title": "On the Entropy Calibration of Language Models", "comment": "Neurips 2025", "summary": "We study the problem of entropy calibration, which asks whether a language model's entropy over generations matches its log loss on human text. Past work found that models are miscalibrated, with entropy per step increasing (and text quality decreasing) as generations grow longer. This error accumulation is a fundamental problem in autoregressive models, and the standard solution is to truncate the distribution, which improves text quality at the cost of diversity. In this paper, we ask: is miscalibration likely to improve with scale, and is it theoretically possible to calibrate without tradeoffs? To build intuition, we first study a simplified theoretical setting to characterize the scaling behavior of miscalibration with respect to dataset size. We find that the scaling behavior depends on the power law exponent of the data distribution -- in particular, for a power law exponent close to 1, the scaling exponent is close to 0, meaning that miscalibration improves very slowly with scale. Next, we measure miscalibration empirically in language models ranging from 0.5B to 70B parameters. We find that the observed scaling behavior is similar to what is predicted by the simplified setting: our fitted scaling exponents for text are close to 0, meaning that larger models accumulate error at a similar rate as smaller ones. This scaling (or, lack thereof) provides one explanation for why we sample from larger models with similar amounts of truncation as smaller models, even though the larger models are of higher quality. However, truncation is not a satisfying solution because it comes at the cost of increased log loss. In theory, is it even possible to reduce entropy while preserving log loss? We prove that it is possible, if we assume access to a black box which can fit models to predict the future entropy of text.", "AI": {"tldr": "\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u7684\u71b5\u6821\u51c6\u95ee\u9898\uff0c\u53d1\u73b0\u6a21\u578b\u5b58\u5728\u6821\u51c6\u9519\u8bef\uff0c\u968f\u7740\u751f\u6210\u6587\u672c\u53d8\u957f\uff0c\u6bcf\u6b65\u71b5\u589e\u52a0\u4e14\u6587\u672c\u8d28\u91cf\u4e0b\u964d\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\u6821\u51c6\u9519\u8bef\u968f\u89c4\u6a21\u6539\u5584\u7f13\u6162\uff0c\u5b9e\u8bc1\u9a8c\u8bc1\u4ece0.5B\u523070B\u53c2\u6570\u6a21\u578b\u90fd\u663e\u793a\u76f8\u4f3c\u7684\u9519\u8bef\u7d2f\u79ef\u7387\u3002", "motivation": "\u89e3\u51b3\u81ea\u56de\u5f52\u6a21\u578b\u4e2d\u9519\u8bef\u7d2f\u79ef\u7684\u6839\u672c\u95ee\u9898\uff0c\u63a2\u7d22\u6821\u51c6\u9519\u8bef\u662f\u5426\u968f\u6a21\u578b\u89c4\u6a21\u6539\u5584\uff0c\u4ee5\u53ca\u7406\u8bba\u4e0a\u662f\u5426\u80fd\u5728\u4e0d\u727a\u7272\u5bf9\u6570\u635f\u5931\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u6821\u51c6\u3002", "method": "\u9996\u5148\u5728\u7b80\u5316\u7406\u8bba\u8bbe\u7f6e\u4e2d\u5206\u6790\u6821\u51c6\u9519\u8bef\u7684\u7f29\u653e\u884c\u4e3a\u4e0e\u6570\u636e\u5206\u5e03\u5e42\u5f8b\u6307\u6570\u7684\u5173\u7cfb\uff0c\u7136\u540e\u5b9e\u8bc1\u6d4b\u91cf\u4ece0.5B\u523070B\u53c2\u6570\u8bed\u8a00\u6a21\u578b\u7684\u6821\u51c6\u9519\u8bef\u3002", "result": "\u53d1\u73b0\u6821\u51c6\u9519\u8bef\u7684\u7f29\u653e\u6307\u6570\u63a5\u8fd10\uff0c\u610f\u5473\u7740\u5927\u6a21\u578b\u4e0e\u5c0f\u6a21\u578b\u4ee5\u76f8\u4f3c\u901f\u7387\u7d2f\u79ef\u9519\u8bef\uff0c\u8fd9\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u5373\u4f7f\u5927\u6a21\u578b\u8d28\u91cf\u66f4\u9ad8\uff0c\u6211\u4eec\u4ecd\u4f7f\u7528\u76f8\u4f3c\u7684\u622a\u65ad\u91c7\u6837\u3002", "conclusion": "\u7406\u8bba\u4e0a\u8bc1\u660e\u5982\u679c\u5047\u8bbe\u5b58\u5728\u80fd\u9884\u6d4b\u6587\u672c\u672a\u6765\u71b5\u7684\u9ed1\u76d2\uff0c\u5219\u53ef\u4ee5\u5728\u4fdd\u6301\u5bf9\u6570\u635f\u5931\u7684\u540c\u65f6\u51cf\u5c11\u71b5\uff0c\u4f46\u622a\u65ad\u65b9\u6cd5\u4f1a\u727a\u7272\u5bf9\u6570\u635f\u5931\u3002"}}
{"id": "2511.11831", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11831", "abs": "https://arxiv.org/abs/2511.11831", "authors": ["Wenhao Zhou", "Hao Zheng", "Rong Zhao"], "title": "TopoPerception: A Shortcut-Free Evaluation of Global Visual Perception in Large Vision-Language Models", "comment": null, "summary": "Large Vision-Language Models (LVLMs) typically align visual features from an encoder with a pre-trained Large Language Model (LLM). However, this makes the visual perception module a bottleneck, which constrains the overall capabilities of LVLMs. Conventional evaluation benchmarks, while rich in visual semantics, often contain unavoidable local shortcuts that can lead to an overestimation of models' perceptual abilities. Here, we introduce TopoPerception, a benchmark that leverages topological properties to rigorously evaluate the global visual perception capabilities of LVLMs across various granularities. Since topology depends on the global structure of an image and is invariant to local features, TopoPerception enables a shortcut-free assessment of global perception, fundamentally distinguishing it from semantically rich tasks. We evaluate state-of-the-art models on TopoPerception and find that even at the coarsest perceptual granularity, all models perform no better than random chance, indicating a profound inability to perceive global visual features. Notably, a consistent trend emerge within model families: more powerful models with stronger reasoning capabilities exhibit lower accuracy. This suggests that merely scaling up models is insufficient to address this deficit and may even exacerbate it. Progress may require new training paradigms or architectures. TopoPerception not only exposes a critical bottleneck in current LVLMs but also offers a lens and direction for improving their global visual perception. The data and code are publicly available at: https://github.com/Wenhao-Zhou/TopoPerception.", "AI": {"tldr": "TopoPerception\u662f\u4e00\u4e2a\u57fa\u4e8e\u62d3\u6251\u5c5e\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u4e25\u683c\u8bc4\u4f30\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5168\u5c40\u89c6\u89c9\u611f\u77e5\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u5168\u5c40\u611f\u77e5\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u751a\u81f3\u4e0d\u5982\u968f\u673a\u731c\u6d4b\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5c06\u89c6\u89c9\u7279\u5f81\u4e0e\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\uff0c\u4f46\u89c6\u89c9\u611f\u77e5\u6a21\u5757\u6210\u4e3a\u74f6\u9888\uff0c\u4e14\u4f20\u7edf\u8bc4\u4f30\u57fa\u51c6\u5b58\u5728\u5c40\u90e8\u6377\u5f84\uff0c\u9ad8\u4f30\u4e86\u6a21\u578b\u7684\u611f\u77e5\u80fd\u529b\u3002", "method": "\u5229\u7528\u62d3\u6251\u5c5e\u6027\u6784\u5efa\u8bc4\u4f30\u57fa\u51c6\uff0c\u56e0\u4e3a\u62d3\u6251\u4f9d\u8d56\u4e8e\u56fe\u50cf\u5168\u5c40\u7ed3\u6784\u4e14\u5bf9\u5c40\u90e8\u7279\u5f81\u4e0d\u53d8\uff0c\u80fd\u591f\u5b9e\u73b0\u65e0\u6377\u5f84\u7684\u5168\u5c40\u611f\u77e5\u8bc4\u4f30\u3002", "result": "\u5728\u6700\u7c97\u7684\u611f\u77e5\u7c92\u5ea6\u4e0a\uff0c\u6240\u6709\u6a21\u578b\u8868\u73b0\u90fd\u4e0d\u4f18\u4e8e\u968f\u673a\u673a\u4f1a\uff0c\u8868\u660e\u6a21\u578b\u7f3a\u4e4f\u5168\u5c40\u89c6\u89c9\u7279\u5f81\u611f\u77e5\u80fd\u529b\u3002\u66f4\u5f3a\u5927\u7684\u6a21\u578b\u53cd\u800c\u51c6\u786e\u7387\u66f4\u4f4e\u3002", "conclusion": "\u4ec5\u6269\u5927\u6a21\u578b\u89c4\u6a21\u4e0d\u8db3\u4ee5\u89e3\u51b3\u5168\u5c40\u611f\u77e5\u7f3a\u9677\uff0c\u53ef\u80fd\u9700\u8981\u65b0\u7684\u8bad\u7ec3\u8303\u5f0f\u6216\u67b6\u6784\u3002TopoPerception\u63ed\u793a\u4e86\u5f53\u524dLVLMs\u7684\u5173\u952e\u74f6\u9888\u5e76\u63d0\u4f9b\u4e86\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2511.11978", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.11978", "abs": "https://arxiv.org/abs/2511.11978", "authors": ["Hui Huang", "Yanping Chen", "Ruizhang Huang", "Chuan Lin", "Yongbin Qin"], "title": "A Reasoning Paradigm for Named Entity Recognition", "comment": "Accepted at AAAI 2026", "summary": "Generative LLMs typically improve Named Entity Recognition (NER) performance through instruction tuning. They excel at generating entities by semantic pattern matching but lack an explicit, verifiable reasoning mechanism. This \"cognitive shortcutting\" leads to suboptimal performance and brittle generalization, especially in zero-shot and lowresource scenarios where reasoning from limited contextual cues is crucial. To address this issue, a reasoning framework is proposed for NER, which shifts the extraction paradigm from implicit pattern matching to explicit reasoning. This framework consists of three stages: Chain of Thought (CoT) generation, CoT tuning, and reasoning enhancement. First, a dataset annotated with NER-oriented CoTs is generated, which contain task-relevant reasoning chains. Then, they are used to tune the NER model to generate coherent rationales before deriving the final answer. Finally, a reasoning enhancement stage is implemented to optimize the reasoning process using a comprehensive reward signal. This stage ensures explicit and verifiable extractions. Experiments show that ReasoningNER demonstrates impressive cognitive ability in the NER task, achieving competitive performance. In zero-shot settings, it achieves state-of-the-art (SOTA) performance, outperforming GPT-4 by 12.3 percentage points on the F1 score. Analytical results also demonstrate its great potential to advance research in reasoningoriented information extraction. Our codes are available at https://github.com/HuiResearch/ReasoningIE.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aReasoningNER\u7684\u63a8\u7406\u6846\u67b6\uff0c\u5c06NER\u4ece\u9690\u5f0f\u6a21\u5f0f\u5339\u914d\u8f6c\u5411\u663e\u5f0f\u63a8\u7406\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0bF1\u5206\u6570\u6bd4GPT-4\u9ad8\u51fa12.3\u4e2a\u767e\u5206\u70b9\u3002", "motivation": "\u751f\u6210\u5f0fLLM\u901a\u5e38\u901a\u8fc7\u6307\u4ee4\u8c03\u4f18\u6539\u8fdbNER\u6027\u80fd\uff0c\u4f46\u7f3a\u4e4f\u663e\u5f0f\u53ef\u9a8c\u8bc1\u7684\u63a8\u7406\u673a\u5236\uff0c\u5bfc\u81f4\u6b21\u4f18\u6027\u80fd\u548c\u8106\u5f31\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u96f6\u6837\u672c\u548c\u4f4e\u8d44\u6e90\u573a\u666f\u4e2d\u3002", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5\u63a8\u7406\u6846\u67b6\uff1a1) \u751f\u6210\u5e26\u6709NER\u5bfc\u5411CoT\u7684\u6570\u636e\u96c6\uff1b2) \u4f7f\u7528CoT\u8c03\u4f18NER\u6a21\u578b\uff1b3) \u63a8\u7406\u589e\u5f3a\u9636\u6bb5\u4f7f\u7528\u7efc\u5408\u5956\u52b1\u4fe1\u53f7\u4f18\u5316\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u8fbe\u5230SOTA\u6027\u80fd\uff0cF1\u5206\u6570\u6bd4GPT-4\u9ad8\u51fa12.3\u4e2a\u767e\u5206\u70b9\u3002\u5b9e\u9a8c\u663e\u793aReasoningNER\u5728NER\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u8ba4\u77e5\u80fd\u529b\u3002", "conclusion": "ReasoningNER\u5728\u63a8\u7406\u5bfc\u5411\u7684\u4fe1\u606f\u63d0\u53d6\u7814\u7a76\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u8bc1\u660e\u4e86\u663e\u5f0f\u63a8\u7406\u673a\u5236\u5bf9\u63d0\u5347NER\u6027\u80fd\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.11899", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.11899", "abs": "https://arxiv.org/abs/2511.11899", "authors": ["Xi Li", "Nicholas Matsumoto", "Ujjwal Pasupulety", "Atharva Deo", "Cherine Yang", "Jay Moran", "Miguel E. Hernandez", "Peter Wager", "Jasmine Lin", "Jeanine Kim", "Alvin C. Goh", "Christian Wagner", "Geoffrey A. Sonn", "Andrew J. Hung"], "title": "End to End AI System for Surgical Gesture Sequence Recognition and Clinical Outcome Prediction", "comment": null, "summary": "Fine-grained analysis of intraoperative behavior and its impact on patient outcomes remain a longstanding challenge. We present Frame-to-Outcome (F2O), an end-to-end system that translates tissue dissection videos into gesture sequences and uncovers patterns associated with postoperative outcomes. Leveraging transformer-based spatial and temporal modeling and frame-wise classification, F2O robustly detects consecutive short (~2 seconds) gestures in the nerve-sparing step of robot-assisted radical prostatectomy (AUC: 0.80 frame-level; 0.81 video-level). F2O-derived features (gesture frequency, duration, and transitions) predicted postoperative outcomes with accuracy comparable to human annotations (0.79 vs. 0.75; overlapping 95% CI). Across 25 shared features, effect size directions were concordant with small differences (~ 0.07), and strong correlation (r = 0.96, p < 1e-14). F2O also captured key patterns linked to erectile function recovery, including prolonged tissue peeling and reduced energy use. By enabling automatic interpretable assessment, F2O establishes a foundation for data-driven surgical feedback and prospective clinical decision support.", "AI": {"tldr": "F2O\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7cfb\u7edf\uff0c\u80fd\u591f\u5c06\u7ec4\u7ec7\u89e3\u5256\u89c6\u9891\u8f6c\u6362\u4e3a\u624b\u52bf\u5e8f\u5217\uff0c\u5e76\u53d1\u73b0\u4e0e\u672f\u540e\u7ed3\u679c\u76f8\u5173\u7684\u6a21\u5f0f\uff0c\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u624b\u672f\u53cd\u9988\u548c\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u672f\u4e2d\u884c\u4e3a\u7684\u7ec6\u7c92\u5ea6\u5206\u6790\u53ca\u5176\u5bf9\u60a3\u8005\u7ed3\u679c\u7684\u5f71\u54cd\u662f\u4e00\u4e2a\u957f\u671f\u5b58\u5728\u7684\u6311\u6218\u3002", "method": "\u5229\u7528\u57fa\u4e8etransformer\u7684\u7a7a\u95f4\u548c\u65f6\u95f4\u5efa\u6a21\u4ee5\u53ca\u9010\u5e27\u5206\u7c7b\uff0cF2O\u5728\u673a\u5668\u4eba\u8f85\u52a9\u6839\u6cbb\u6027\u524d\u5217\u817a\u5207\u9664\u672f\u7684\u795e\u7ecf\u4fdd\u7559\u6b65\u9aa4\u4e2d\u7a33\u5065\u5730\u68c0\u6d4b\u8fde\u7eed\u77ed\u624b\u52bf\u3002", "result": "F2O\u5728\u5e27\u7ea7\u522b\u548c\u89c6\u9891\u7ea7\u522b\u7684\u68c0\u6d4bAUC\u5206\u522b\u4e3a0.80\u548c0.81\uff1bF2O\u884d\u751f\u7684\u7279\u5f81\u9884\u6d4b\u672f\u540e\u7ed3\u679c\u7684\u51c6\u786e\u6027\u4e0e\u4eba\u5de5\u6ce8\u91ca\u76f8\u5f53\uff080.79 vs 0.75\uff09\uff1b\u572825\u4e2a\u5171\u4eab\u7279\u5f81\u4e2d\uff0c\u6548\u5e94\u5927\u5c0f\u65b9\u5411\u4e00\u81f4\u4e14\u5dee\u5f02\u5c0f\uff08~0.07\uff09\uff0c\u76f8\u5173\u6027\u5f3a\uff08r=0.96\uff09\u3002", "conclusion": "\u901a\u8fc7\u5b9e\u73b0\u81ea\u52a8\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30\uff0cF2O\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u624b\u672f\u53cd\u9988\u548c\u524d\u77bb\u6027\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.12001", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.12001", "abs": "https://arxiv.org/abs/2511.12001", "authors": ["Eunkyu Park", "Wesley Hanwen Deng", "Vasudha Varadarajan", "Mingxi Yan", "Gunhee Kim", "Maarten Sap", "Motahhare Eslami"], "title": "Critical or Compliant? The Double-Edged Sword of Reasoning in Chain-of-Thought Explanations", "comment": "Under review; 16 pages, 15 figures", "summary": "Explanations are often promoted as tools for transparency, but they can also foster confirmation bias; users may assume reasoning is correct whenever outputs appear acceptable. We study this double-edged role of Chain-of-Thought (CoT) explanations in multimodal moral scenarios by systematically perturbing reasoning chains and manipulating delivery tones. Specifically, we analyze reasoning errors in vision language models (VLMs) and how they impact user trust and the ability to detect errors. Our findings reveal two key effects: (1) users often equate trust with outcome agreement, sustaining reliance even when reasoning is flawed, and (2) the confident tone suppresses error detection while maintaining reliance, showing that delivery styles can override correctness. These results highlight how CoT explanations can simultaneously clarify and mislead, underscoring the need for NLP systems to provide explanations that encourage scrutiny and critical thinking rather than blind trust. All code will be released publicly.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u601d\u7ef4\u94fe\u89e3\u91ca\u5728\u9053\u5fb7\u573a\u666f\u4e2d\u7684\u53cc\u91cd\u4f5c\u7528\uff1a\u65e2\u80fd\u63d0\u9ad8\u900f\u660e\u5ea6\uff0c\u4e5f\u53ef\u80fd\u56e0\u786e\u8ba4\u504f\u89c1\u5bfc\u81f4\u7528\u6237\u5ffd\u89c6\u63a8\u7406\u9519\u8bef\uff0c\u7279\u522b\u662f\u5f53\u8f93\u51fa\u770b\u4f3c\u5408\u7406\u6216\u8bed\u6c14\u81ea\u4fe1\u65f6\u3002", "motivation": "\u63a2\u8ba8\u89e3\u91ca\u673a\u5236\u5728\u4fc3\u8fdb\u900f\u660e\u5ea6\u4e0e\u5f15\u53d1\u786e\u8ba4\u504f\u89c1\u4e4b\u95f4\u7684\u5e73\u8861\uff0c\u7279\u522b\u662f\u5728\u591a\u6a21\u6001\u9053\u5fb7\u573a\u666f\u4e2d\uff0c\u7406\u89e3\u601d\u7ef4\u94fe\u89e3\u91ca\u5982\u4f55\u5f71\u54cd\u7528\u6237\u4fe1\u4efb\u548c\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u6270\u52a8\u63a8\u7406\u94fe\u548c\u64cd\u7eb5\u8868\u8fbe\u8bed\u6c14\uff0c\u5206\u6790\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u63a8\u7406\u9519\u8bef\u53ca\u5176\u5bf9\u7528\u6237\u4fe1\u4efb\u548c\u9519\u8bef\u68c0\u6d4b\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u7528\u6237\u5e38\u5c06\u4fe1\u4efb\u7b49\u540c\u4e8e\u7ed3\u679c\u4e00\u81f4\u6027\uff0c\u5373\u4f7f\u63a8\u7406\u6709\u7f3a\u9677\u4ecd\u4fdd\u6301\u4f9d\u8d56\uff1b\u81ea\u4fe1\u8bed\u6c14\u4f1a\u6291\u5236\u9519\u8bef\u68c0\u6d4b\u4f46\u7ef4\u6301\u4f9d\u8d56\uff0c\u8868\u660e\u8868\u8fbe\u98ce\u683c\u80fd\u51cc\u9a7e\u4e8e\u6b63\u786e\u6027\u4e4b\u4e0a\u3002", "conclusion": "\u601d\u7ef4\u94fe\u89e3\u91ca\u65e2\u80fd\u6f84\u6e05\u4e5f\u80fd\u8bef\u5bfc\uff0cNLP\u7cfb\u7edf\u9700\u8981\u63d0\u4f9b\u9f13\u52b1\u5ba1\u67e5\u548c\u6279\u5224\u6027\u601d\u7ef4\u800c\u975e\u76f2\u76ee\u4fe1\u4efb\u7684\u89e3\u91ca\u673a\u5236\u3002"}}
{"id": "2511.11914", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11914", "abs": "https://arxiv.org/abs/2511.11914", "authors": ["Shizhou Xu", "Yuan Ni", "Stefan Broecker", "Thomas Strohmer"], "title": "Forgetting-MarI: LLM Unlearning via Marginal Information Regularization", "comment": null, "summary": "As AI models are trained on ever-expanding datasets, the ability to remove the influence of specific data from trained models has become essential for privacy protection and regulatory compliance. Unlearning addresses this challenge by selectively removing parametric knowledge from the trained models without retraining from scratch, which is critical for resource-intensive models such as Large Language Models (LLMs). Existing unlearning methods often degrade model performance by removing more information than necessary when attempting to ''forget'' specific data. We introduce Forgetting-MarI, an LLM unlearning framework that provably removes only the additional (marginal) information contributed by the data to be unlearned, while preserving the information supported by the data to be retained. By penalizing marginal information, our method yields an explicit upper bound on the unlearn dataset's residual influence in the trained models, providing provable undetectability. Extensive experiments confirm that our approach outperforms current state-of-the-art unlearning methods, delivering reliable forgetting and better preserved general model performance across diverse benchmarks. This advancement represents an important step toward making AI systems more controllable and compliant with privacy and copyright regulations without compromising their effectiveness.", "AI": {"tldr": "Forgetting-MarI\u662f\u4e00\u4e2aLLM\u9057\u5fd8\u6846\u67b6\uff0c\u901a\u8fc7\u60e9\u7f5a\u8fb9\u9645\u4fe1\u606f\u6765\u9009\u62e9\u6027\u79fb\u9664\u7279\u5b9a\u6570\u636e\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u4fdd\u7559\u5176\u4ed6\u6570\u636e\u7684\u4fe1\u606f\uff0c\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u4e0d\u53ef\u68c0\u6d4b\u6027\u3002", "motivation": "\u968f\u7740AI\u6a21\u578b\u5728\u4e0d\u65ad\u6269\u5927\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u9700\u8981\u9009\u62e9\u6027\u79fb\u9664\u7279\u5b9a\u6570\u636e\u7684\u5f71\u54cd\u4ee5\u6ee1\u8db3\u9690\u79c1\u4fdd\u62a4\u548c\u6cd5\u89c4\u5408\u89c4\u8981\u6c42\uff0c\u907f\u514d\u4ece\u5934\u91cd\u65b0\u8bad\u7ec3\u8d44\u6e90\u5bc6\u96c6\u578b\u6a21\u578b\u3002", "method": "\u5f15\u5165Forgetting-MarI\u6846\u67b6\uff0c\u901a\u8fc7\u60e9\u7f5a\u8fb9\u9645\u4fe1\u606f\u6765\u79fb\u9664\u5f85\u9057\u5fd8\u6570\u636e\u7684\u989d\u5916\u4fe1\u606f\u8d21\u732e\uff0c\u540c\u65f6\u4fdd\u7559\u5f85\u4fdd\u7559\u6570\u636e\u652f\u6301\u7684\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u9057\u5fd8\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u53ef\u9760\u7684\u9057\u5fd8\u6548\u679c\u5e76\u66f4\u597d\u5730\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u901a\u7528\u6027\u80fd\u3002", "conclusion": "\u8fd9\u4e00\u8fdb\u5c55\u4f7fAI\u7cfb\u7edf\u5728\u9075\u5b88\u9690\u79c1\u548c\u7248\u6743\u6cd5\u89c4\u7684\u540c\u65f6\u4e0d\u635f\u5bb3\u5176\u6709\u6548\u6027\uff0c\u5411\u66f4\u53ef\u63a7\u548c\u5408\u89c4\u7684AI\u7cfb\u7edf\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2511.12014", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.12014", "abs": "https://arxiv.org/abs/2511.12014", "authors": ["Truong Vo", "Sanmi Koyejo"], "title": "CURE: Cultural Understanding and Reasoning Evaluation - A Framework for \"Thick\" Culture Alignment Evaluation in LLMs", "comment": "7 pages, 5 figures", "summary": "Large language models (LLMs) are increasingly deployed in culturally diverse environments, yet existing evaluations of cultural competence remain limited. Existing methods focus on de-contextualized correctness or forced-choice judgments, overlooking the need for cultural understanding and reasoning required for appropriate responses. To address this gap, we introduce a set of benchmarks that, instead of directly probing abstract norms or isolated statements, present models with realistic situational contexts that require culturally grounded reasoning. In addition to the standard Exact Match metric, we introduce four complementary metrics (Coverage, Specificity, Connotation, and Coherence) to capture different dimensions of model's response quality. Empirical analysis across frontier models reveals that thin evaluation systematically overestimates cultural competence and produces unstable assessments with high variance. In contrast, thick evaluation exposes differences in reasoning depth, reduces variance, and provides more stable, interpretable signals of cultural understanding.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u6587\u5316\u80fd\u529b\u7684\u65b0\u57fa\u51c6\uff0c\u901a\u8fc7\u60c5\u5883\u5316\u8bc4\u4f30\u548c\u591a\u4e2a\u8865\u5145\u6307\u6807\u6765\u66f4\u51c6\u786e\u5730\u8861\u91cf\u6a21\u578b\u7684\u6587\u5316\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6587\u5316\u80fd\u529b\u8bc4\u4f30\u65b9\u6cd5\u8fc7\u4e8e\u5173\u6ce8\u53bb\u60c5\u5883\u5316\u7684\u6b63\u786e\u6027\u6216\u5f3a\u5236\u9009\u62e9\u5224\u65ad\uff0c\u5ffd\u89c6\u4e86\u6587\u5316\u7406\u89e3\u548c\u63a8\u7406\u7684\u9700\u6c42\uff0c\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u6a21\u578b\u5728\u591a\u5143\u6587\u5316\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u73b0\u5b9e\u60c5\u5883\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u9664\u4e86\u6807\u51c6\u7cbe\u786e\u5339\u914d\u6307\u6807\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u8986\u76d6\u7387\u3001\u7279\u5f02\u6027\u3001\u5185\u6db5\u6027\u548c\u8fde\u8d2f\u6027\u56db\u4e2a\u8865\u5145\u6307\u6807\uff0c\u8fdb\u884c\u539a\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u7ecf\u9a8c\u5206\u6790\u663e\u793a\uff0c\u4f20\u7edf\u8584\u8bc4\u4f30\u7cfb\u7edf\u6027\u5730\u9ad8\u4f30\u4e86\u6587\u5316\u80fd\u529b\u4e14\u8bc4\u4f30\u7ed3\u679c\u4e0d\u7a33\u5b9a\uff0c\u800c\u539a\u8bc4\u4f30\u80fd\u591f\u63ed\u793a\u63a8\u7406\u6df1\u5ea6\u7684\u5dee\u5f02\uff0c\u51cf\u5c11\u65b9\u5dee\uff0c\u63d0\u4f9b\u66f4\u7a33\u5b9a\u3001\u53ef\u89e3\u91ca\u7684\u6587\u5316\u7406\u89e3\u4fe1\u53f7\u3002", "conclusion": "\u539a\u8bc4\u4f30\u65b9\u6cd5\u6bd4\u4f20\u7edf\u8584\u8bc4\u4f30\u80fd\u66f4\u51c6\u786e\u5730\u8861\u91cf\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6587\u5316\u80fd\u529b\uff0c\u4e3a\u6a21\u578b\u5728\u591a\u5143\u6587\u5316\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2511.11916", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11916", "abs": "https://arxiv.org/abs/2511.11916", "authors": ["Sinan Urgun", "Se\u00e7kin Ar\u0131"], "title": "An Analysis of Architectural Impact on LLM-based Abstract Visual Reasoning: A Systematic Benchmark on RAVEN-FAIR", "comment": "23 pages, 9 figures", "summary": "This study aims to systematically evaluate the performance of large language models (LLMs) in abstract visual reasoning problems. We examined four LLM models (GPT-4.1-Mini, Claude-3.5-Haiku, Gemini-1.5-Flash, Llama-3.3-70b) utilizing four different reasoning architectures (single-shot, embedding-controlled repetition, self-reflection, and multi-agent) on the RAVEN-FAIR dataset. Visual responses generated through a three-stage process (JSON extraction, LLM reasoning, and Tool Function) were evaluated using SSIM and LPIPS metrics; Chain-of-Thought scores and error types (semantic hallucination, numeric misperception) were analyzed. Results demonstrate that GPT-4.1-Mini consistently achieved the highest overall accuracy across all architectures, indicating a strong reasoning capability. While the multi-agent architecture occasionally altered semantic and numeric balance across models, these effects were not uniformly beneficial. Instead, each model exhibited distinct sensitivity patterns to architectural design, underscoring that reasoning effectiveness remains model-specific. Variations in response coverage further emerged as a confounding factor that complicates direct cross-architecture comparison. To estimate the upper-bound performance of each configuration, we report the best of five independent runs, representing a best-case scenario rather than an averaged outcome. This multi-run strategy aligns with recent recommendations, which emphasize that single-run evaluations are fragile and may lead to unreliable conclusions.", "AI": {"tldr": "\u8bc4\u4f30\u56db\u79cdLLM\u6a21\u578b\u5728\u62bd\u8c61\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4f7f\u7528\u56db\u79cd\u63a8\u7406\u67b6\u6784\u5728RAVEN-FAIR\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u53d1\u73b0GPT-4.1-Mini\u8868\u73b0\u6700\u4f73\uff0c\u63a8\u7406\u6548\u679c\u5177\u6709\u6a21\u578b\u7279\u5f02\u6027\u3002", "motivation": "\u7cfb\u7edf\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u62bd\u8c61\u89c6\u89c9\u63a8\u7406\u95ee\u9898\u4e2d\u7684\u6027\u80fd\u8868\u73b0\uff0c\u63a2\u7d22\u4e0d\u540c\u63a8\u7406\u67b6\u6784\u5bf9\u6a21\u578b\u8868\u73b0\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u56db\u79cdLLM\u6a21\u578b\uff08GPT-4.1-Mini\u3001Claude-3.5-Haiku\u3001Gemini-1.5-Flash\u3001Llama-3.3-70b\uff09\u548c\u56db\u79cd\u63a8\u7406\u67b6\u6784\uff08\u5355\u6b21\u63a8\u7406\u3001\u5d4c\u5165\u63a7\u5236\u91cd\u590d\u3001\u81ea\u6211\u53cd\u601d\u3001\u591a\u4ee3\u7406\uff09\uff0c\u5728RAVEN-FAIR\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u91c7\u7528\u4e09\u9636\u6bb5\u5904\u7406\u6d41\u7a0b\uff08JSON\u63d0\u53d6\u3001LLM\u63a8\u7406\u3001\u5de5\u5177\u51fd\u6570\uff09\uff0c\u4f7f\u7528SSIM\u548cLPIPS\u6307\u6807\u8bc4\u4f30\u89c6\u89c9\u54cd\u5e94\u3002", "result": "GPT-4.1-Mini\u5728\u6240\u6709\u67b6\u6784\u4e2d\u59cb\u7ec8\u83b7\u5f97\u6700\u9ad8\u51c6\u786e\u7387\uff0c\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\u3002\u591a\u4ee3\u7406\u67b6\u6784\u5076\u5c14\u4f1a\u6539\u53d8\u8bed\u4e49\u548c\u6570\u503c\u5e73\u8861\uff0c\u4f46\u6548\u679c\u4e0d\u4e00\u81f4\u3002\u6bcf\u4e2a\u6a21\u578b\u5bf9\u67b6\u6784\u8bbe\u8ba1\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u654f\u611f\u6027\u6a21\u5f0f\u3002", "conclusion": "\u63a8\u7406\u6709\u6548\u6027\u5177\u6709\u6a21\u578b\u7279\u5f02\u6027\uff0c\u54cd\u5e94\u8986\u76d6\u5ea6\u7684\u53d8\u5316\u4f7f\u8de8\u67b6\u6784\u76f4\u63a5\u6bd4\u8f83\u590d\u6742\u5316\u3002\u91c7\u7528\u4e94\u6b21\u72ec\u7acb\u8fd0\u884c\u7684\u6700\u4f73\u7ed3\u679c\u6765\u4f30\u8ba1\u6027\u80fd\u4e0a\u9650\uff0c\u907f\u514d\u5355\u6b21\u8bc4\u4f30\u7684\u8106\u5f31\u6027\u3002"}}
{"id": "2511.12109", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12109", "abs": "https://arxiv.org/abs/2511.12109", "authors": ["Felipe Fujita", "Hideyuki Takada"], "title": "Exploring Parameter-Efficient Fine-Tuning and Backtranslation for the WMT 25 General Translation Task", "comment": null, "summary": "In this paper, we explore the effectiveness of combining fine-tuning and backtranslation on a small Japanese corpus for neural machine translation. Starting from a baseline English{\\textrightarrow}Japanese model (COMET = 0.460), we first apply backtranslation (BT) using synthetic data generated from monolingual Japanese corpora, yielding a modest increase (COMET = 0.468). Next, we fine-tune (FT) the model on a genuine small parallel dataset drawn from diverse Japanese news and literary corpora, achieving a substantial jump to COMET = 0.589 when using Mistral 7B. Finally, we integrate both backtranslation and fine-tuning{ -- }first augmenting the small dataset with BT generated examples, then adapting via FT{ -- }which further boosts performance to COMET = 0.597. These results demonstrate that, even with limited training data, the synergistic use of backtranslation and targeted fine-tuning on Japanese corpora can significantly enhance translation quality, outperforming each technique in isolation. This approach offers a lightweight yet powerful strategy for improving low-resource language pairs.", "AI": {"tldr": "\u7ed3\u5408\u56de\u8bd1\u548c\u5fae\u8c03\u5728\u5c0f\u89c4\u6a21\u65e5\u8bed\u8bed\u6599\u4e0a\u663e\u8457\u63d0\u5347\u795e\u7ecf\u673a\u5668\u7ffb\u8bd1\u8d28\u91cf\uff0cCOMET\u5206\u6570\u4ece0.460\u63d0\u5347\u81f30.597\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u5728\u6709\u9650\u8bad\u7ec3\u6570\u636e\u4e0b\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u5bf9\u7684\u7ffb\u8bd1\u8d28\u91cf\uff0c\u63a2\u7d22\u56de\u8bd1\u548c\u5fae\u8c03\u7684\u534f\u540c\u6548\u5e94\u3002", "method": "\u4f7f\u7528\u56de\u8bd1\u751f\u6210\u5408\u6210\u6570\u636e\uff0c\u7136\u540e\u5728\u771f\u5b9e\u5c0f\u89c4\u6a21\u5e73\u884c\u8bed\u6599\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u6700\u540e\u7ed3\u5408\u4e24\u79cd\u65b9\u6cd5\uff1a\u5148\u7528\u56de\u8bd1\u589e\u5f3a\u6570\u636e\u518d\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5355\u72ec\u56de\u8bd1COMET=0.468\uff0c\u5355\u72ec\u5fae\u8c03COMET=0.589\uff0c\u7ed3\u5408\u4e24\u8005COMET=0.597\uff0c\u663e\u8457\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528\u4efb\u4e00\u65b9\u6cd5\u3002", "conclusion": "\u56de\u8bd1\u548c\u9488\u5bf9\u6027\u5fae\u8c03\u7684\u534f\u540c\u4f7f\u7528\u80fd\u663e\u8457\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u5bf9\u7684\u7ffb\u8bd1\u8d28\u91cf\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u4f46\u5f3a\u5927\u7684\u6539\u8fdb\u7b56\u7565\u3002"}}
{"id": "2511.11921", "categories": ["cs.AI", "cs.ET", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.11921", "abs": "https://arxiv.org/abs/2511.11921", "authors": ["Liudong Xing", "Janet", "Lin"], "title": "Looking Forward: Challenges and Opportunities in Agentic AI Reliability", "comment": "13 pages, 6 figures; This is a preprint of a chapter accepted for publication in Generative and Agentic AI Reliability: Architectures, Challenges, and Trust for Autonomous Systems, published by SpringerNature", "summary": "This chapter presents perspectives for challenges and future development in building reliable AI systems, particularly, agentic AI systems. Several open research problems related to mitigating the risks of cascading failures are discussed. The chapter also sheds lights on research challenges and opportunities in aspects including dynamic environments, inconsistent task execution, unpredictable emergent behaviors, as well as resource-intensive reliability mechanisms. In addition, several research directions along the line of testing and evaluating reliability of agentic AI systems are also discussed.", "AI": {"tldr": "\u672c\u7ae0\u8ba8\u8bba\u4e86\u6784\u5efa\u53ef\u9760AI\u7cfb\u7edf\uff08\u7279\u522b\u662f\u667a\u80fd\u4f53AI\u7cfb\u7edf\uff09\u9762\u4e34\u7684\u6311\u6218\u548c\u672a\u6765\u53d1\u5c55\u65b9\u5411\uff0c\u5305\u62ec\u7ea7\u8054\u6545\u969c\u98ce\u9669\u7f13\u89e3\u3001\u52a8\u6001\u73af\u5883\u3001\u4efb\u52a1\u6267\u884c\u4e0d\u4e00\u81f4\u6027\u3001\u4e0d\u53ef\u9884\u6d4b\u7684\u6d8c\u73b0\u884c\u4e3a\u7b49\u7814\u7a76\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u4f53AI\u7cfb\u7edf\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u786e\u4fdd\u5176\u53ef\u9760\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u5f53\u524d\u5b58\u5728\u7ea7\u8054\u6545\u969c\u98ce\u9669\u3001\u52a8\u6001\u73af\u5883\u9002\u5e94\u6027\u4e0d\u8db3\u3001\u4efb\u52a1\u6267\u884c\u4e0d\u4e00\u81f4\u3001\u6d8c\u73b0\u884c\u4e3a\u4e0d\u53ef\u9884\u6d4b\u7b49\u95ee\u9898\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u5206\u6790\u73b0\u6709\u7814\u7a76\u95ee\u9898\uff0c\u63d0\u51fa\u591a\u4e2a\u7814\u7a76\u65b9\u5411\uff1a\u7ea7\u8054\u6545\u969c\u98ce\u9669\u7f13\u89e3\u3001\u52a8\u6001\u73af\u5883\u9002\u5e94\u6027\u3001\u4efb\u52a1\u6267\u884c\u4e00\u81f4\u6027\u3001\u6d8c\u73b0\u884c\u4e3a\u9884\u6d4b\u3001\u8d44\u6e90\u9ad8\u6548\u53ef\u9760\u6027\u673a\u5236\u3001\u6d4b\u8bd5\u8bc4\u4f30\u65b9\u6cd5\u7b49\u3002", "result": "\u8bc6\u522b\u4e86\u667a\u80fd\u4f53AI\u7cfb\u7edf\u53ef\u9760\u6027\u7684\u5173\u952e\u6311\u6218\u9886\u57df\uff0c\u5305\u62ec\u52a8\u6001\u73af\u5883\u9002\u5e94\u6027\u3001\u4efb\u52a1\u6267\u884c\u4e0d\u4e00\u81f4\u6027\u3001\u4e0d\u53ef\u9884\u6d4b\u7684\u6d8c\u73b0\u884c\u4e3a\u7b49\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u7814\u7a76\u65b9\u5411\u548c\u89e3\u51b3\u65b9\u6848\u6846\u67b6\u3002", "conclusion": "\u6784\u5efa\u53ef\u9760\u7684\u667a\u80fd\u4f53AI\u7cfb\u7edf\u9700\u8981\u5728\u591a\u4e2a\u5c42\u9762\u8fdb\u884c\u6df1\u5165\u7814\u7a76\uff0c\u5305\u62ec\u6545\u969c\u9884\u9632\u3001\u73af\u5883\u9002\u5e94\u6027\u3001\u884c\u4e3a\u9884\u6d4b\u548c\u9ad8\u6548\u6d4b\u8bd5\u8bc4\u4f30\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u7814\u7a76\u65b9\u5411\u5bf9\u63a8\u52a8AI\u7cfb\u7edf\u7684\u5b9e\u9645\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.12116", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12116", "abs": "https://arxiv.org/abs/2511.12116", "authors": ["Piotr P\u0119zik", "Konrad Kaczy\u0144ski", "Maria Szyma\u0144ska", "Filip \u017barnecki", "Zuzanna Deckert", "Jakub Kwiatkowski", "Wojciech Janowski"], "title": "LLMLagBench: Identifying Temporal Training Boundaries in Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) are pretrained on textual data up to a specific temporal cutoff. This creates a strict knowledge boundary beyond which models cannot provide accurate information without querying external sources. More subtly, when this limitation is unknown or ignored, LLMs may inadvertently blend outdated time-sensitive information with general knowledge during reasoning tasks, potentially compromising response accuracy. We introduce LLMLagBench, an LLM freshness benchmark, as a systematic approach for identifying the earliest probable temporal boundaries of an LLM's training data by evaluating its knowledge of recent events. We then apply this benchmark to evaluate a large set of LLMs, including models with both explicitly declared and undeclared training cutoffs. The reliability of the benchmark is assessed by manual validation and comparison with publicly released information about LLM pretraining.", "AI": {"tldr": "LLMLagBench\u662f\u4e00\u4e2a\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u65f6\u95f4\u8fb9\u754c\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u68c0\u6d4b\u6a21\u578b\u5bf9\u8fd1\u671f\u4e8b\u4ef6\u7684\u4e86\u89e3\u6765\u786e\u5b9a\u5176\u77e5\u8bc6\u65b0\u9c9c\u5ea6\u3002", "motivation": "LLMs\u5728\u7279\u5b9a\u65f6\u95f4\u70b9\u524d\u7684\u6587\u672c\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\uff0c\u5f62\u6210\u4e86\u4e25\u683c\u7684\u77e5\u8bc6\u8fb9\u754c\u3002\u5f53\u8fd9\u4e2a\u9650\u5236\u672a\u77e5\u6216\u88ab\u5ffd\u89c6\u65f6\uff0c\u6a21\u578b\u53ef\u80fd\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u65e0\u610f\u95f4\u6df7\u5408\u8fc7\u65f6\u7684\u65f6\u6548\u6027\u4fe1\u606f\u4e0e\u901a\u7528\u77e5\u8bc6\uff0c\u4ece\u800c\u5f71\u54cd\u56de\u7b54\u51c6\u786e\u6027\u3002", "method": "\u5f15\u5165LLMLagBench\u4f5c\u4e3a\u7cfb\u7edf\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc4\u4f30\u6a21\u578b\u5bf9\u8fd1\u671f\u4e8b\u4ef6\u7684\u77e5\u8bc6\u6765\u8bc6\u522b\u5176\u8bad\u7ec3\u6570\u636e\u7684\u6700\u65e9\u53ef\u80fd\u65f6\u95f4\u8fb9\u754c\u3002\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u5927\u91cfLLMs\uff0c\u5305\u62ec\u6709\u660e\u786e\u58f0\u660e\u548c\u672a\u58f0\u660e\u8bad\u7ec3\u622a\u6b62\u65f6\u95f4\u7684\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u624b\u52a8\u9a8c\u8bc1\u548c\u4e0e\u516c\u5f00\u53d1\u5e03\u7684LLM\u9884\u8bad\u7ec3\u4fe1\u606f\u8fdb\u884c\u6bd4\u8f83\uff0c\u8bc4\u4f30\u4e86\u57fa\u51c6\u6d4b\u8bd5\u7684\u53ef\u9760\u6027\u3002", "conclusion": "LLMLagBench\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u6765\u8bc6\u522bLLMs\u7684\u77e5\u8bc6\u65f6\u95f4\u8fb9\u754c\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u6a21\u578b\u7684\u77e5\u8bc6\u65b0\u9c9c\u5ea6\u9650\u5236\u3002"}}
{"id": "2511.11924", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11924", "abs": "https://arxiv.org/abs/2511.11924", "authors": ["Yongkang Huo", "Fulvio Forni", "Rodolphe Sepulchre"], "title": "A Neuromorphic Architecture for Scalable Event-Based Control", "comment": null, "summary": "This paper introduces the ``rebound Winner-Take-All (RWTA)\" motif as the basic element of a scalable neuromorphic control architecture. From the cellular level to the system level, the resulting architecture combines the reliability of discrete computation and the tunability of continuous regulation: it inherits the discrete computation capabilities of winner-take-all state machines and the continuous tuning capabilities of excitable biophysical circuits. The proposed event-based framework addresses continuous rhythmic generation and discrete decision-making in a unified physical modeling language. We illustrate the versatility, robustness, and modularity of the architecture through the nervous system design of a snake robot.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\"\u53cd\u5f39\u8d62\u5bb6\u901a\u5403(RWTA)\"\u57fa\u5143\u4f5c\u4e3a\u53ef\u6269\u5c55\u795e\u7ecf\u5f62\u6001\u63a7\u5236\u67b6\u6784\u7684\u57fa\u672c\u5143\u7d20\uff0c\u7ed3\u5408\u4e86\u79bb\u6563\u8ba1\u7b97\u7684\u53ef\u9760\u6027\u548c\u8fde\u7eed\u8c03\u8282\u7684\u53ef\u8c03\u6027\u3002", "motivation": "\u6784\u5efa\u4e00\u4e2a\u80fd\u591f\u7edf\u4e00\u5904\u7406\u8fde\u7eed\u8282\u5f8b\u751f\u6210\u548c\u79bb\u6563\u51b3\u7b56\u7684\u795e\u7ecf\u5f62\u6001\u63a7\u5236\u67b6\u6784\uff0c\u7ed3\u5408\u79bb\u6563\u8ba1\u7b97\u7684\u53ef\u9760\u6027\u548c\u8fde\u7eed\u8c03\u8282\u7684\u53ef\u8c03\u6027\u3002", "method": "\u4f7f\u7528\u53cd\u5f39\u8d62\u5bb6\u901a\u5403(RWTA)\u57fa\u5143\u4f5c\u4e3a\u57fa\u672c\u6784\u5efa\u5757\uff0c\u4ece\u7ec6\u80de\u5c42\u9762\u5230\u7cfb\u7edf\u5c42\u9762\u6784\u5efa\u67b6\u6784\uff0c\u7ee7\u627f\u8d62\u5bb6\u901a\u5403\u72b6\u6001\u673a\u7684\u79bb\u6563\u8ba1\u7b97\u80fd\u529b\u548c\u53ef\u5174\u594b\u751f\u7269\u7269\u7406\u7535\u8def\u7684\u8fde\u7eed\u8c03\u8282\u80fd\u529b\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4e8b\u4ef6\u7684\u6846\u67b6\uff0c\u80fd\u591f\u7edf\u4e00\u5904\u7406\u8fde\u7eed\u8282\u5f8b\u751f\u6210\u548c\u79bb\u6563\u51b3\u7b56\uff0c\u5e76\u901a\u8fc7\u86c7\u5f62\u673a\u5668\u4eba\u795e\u7ecf\u7cfb\u7edf\u8bbe\u8ba1\u5c55\u793a\u4e86\u8be5\u67b6\u6784\u7684\u901a\u7528\u6027\u3001\u9c81\u68d2\u6027\u548c\u6a21\u5757\u5316\u7279\u6027\u3002", "conclusion": "RWTA\u67b6\u6784\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7269\u7406\u5efa\u6a21\u8bed\u8a00\uff0c\u6210\u529f\u7ed3\u5408\u4e86\u79bb\u6563\u8ba1\u7b97\u548c\u8fde\u7eed\u8c03\u8282\u7684\u4f18\u52bf\uff0c\u5728\u795e\u7ecf\u5f62\u6001\u63a7\u5236\u7cfb\u7edf\u4e2d\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.12130", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12130", "abs": "https://arxiv.org/abs/2511.12130", "authors": ["Bingbing Wang", "Zhixin Bai", "Zhengda Jin", "Zihan Wang", "Xintong Song", "Jingjie Lin", "Sixuan Li", "Jing Li", "Ruifeng Xu"], "title": "PRISM of Opinions: A Persona-Reasoned Multimodal Framework for User-centric Conversational Stance Detection", "comment": null, "summary": "The rapid proliferation of multimodal social media content has driven research in Multimodal Conversational Stance Detection (MCSD), which aims to interpret users' attitudes toward specific targets within complex discussions. However, existing studies remain limited by: **1) pseudo-multimodality**, where visual cues appear only in source posts while comments are treated as text-only, misaligning with real-world multimodal interactions; and **2) user homogeneity**, where diverse users are treated uniformly, neglecting personal traits that shape stance expression. To address these issues, we introduce **U-MStance**, the first user-centric MCSD dataset, containing over 40k annotated comments across six real-world targets. We further propose **PRISM**, a **P**ersona-**R**easoned mult**I**modal **S**tance **M**odel for MCSD. PRISM first derives longitudinal user personas from historical posts and comments to capture individual traits, then aligns textual and visual cues within conversational context via Chain-of-Thought to bridge semantic and pragmatic gaps across modalities. Finally, a mutual task reinforcement mechanism is employed to jointly optimize stance detection and stance-aware response generation for bidirectional knowledge transfer. Experiments on U-MStance demonstrate that PRISM yields significant gains over strong baselines, underscoring the effectiveness of user-centric and context-grounded multimodal reasoning for realistic stance understanding.", "AI": {"tldr": "\u63d0\u51fa\u4e86U-MStance\u6570\u636e\u96c6\u548cPRISM\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5bf9\u8bdd\u7acb\u573a\u68c0\u6d4b\u4e2d\u7684\u4f2a\u591a\u6a21\u6001\u548c\u7528\u6237\u540c\u8d28\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u7528\u6237\u753b\u50cf\u548c\u591a\u6a21\u6001\u5bf9\u9f50\u663e\u8457\u63d0\u5347\u4e86\u7acb\u573a\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5bf9\u8bdd\u7acb\u573a\u68c0\u6d4b\u7814\u7a76\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u5c40\u9650\uff1a1\uff09\u4f2a\u591a\u6a21\u6001\u95ee\u9898\uff0c\u6e90\u5e16\u5b50\u5305\u542b\u89c6\u89c9\u7ebf\u7d22\u800c\u8bc4\u8bba\u4ec5\u88ab\u89c6\u4e3a\u6587\u672c\uff1b2\uff09\u7528\u6237\u540c\u8d28\u6027\u95ee\u9898\uff0c\u5ffd\u89c6\u4e86\u4e2a\u4f53\u7279\u5f81\u5bf9\u7acb\u573a\u8868\u8fbe\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51faPRISM\u6a21\u578b\uff1a1\uff09\u4ece\u5386\u53f2\u5e16\u5b50\u548c\u8bc4\u8bba\u4e2d\u63d0\u53d6\u7eb5\u5411\u7528\u6237\u753b\u50cf\uff1b2\uff09\u901a\u8fc7\u601d\u7ef4\u94fe\u5bf9\u9f50\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u4e2d\u7684\u6587\u672c\u548c\u89c6\u89c9\u7ebf\u7d22\uff1b3\uff09\u91c7\u7528\u76f8\u4e92\u4efb\u52a1\u5f3a\u5316\u673a\u5236\u8054\u5408\u4f18\u5316\u7acb\u573a\u68c0\u6d4b\u548c\u7acb\u573a\u611f\u77e5\u54cd\u5e94\u751f\u6210\u3002", "result": "\u5728U-MStance\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPRISM\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u6a21\u578b\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u9a8c\u8bc1\u4e86\u7528\u6237\u4e2d\u5fc3\u548c\u4e0a\u4e0b\u6587\u57fa\u7840\u7684\u591a\u6a21\u6001\u63a8\u7406\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7528\u6237\u4e2d\u5fc3\u7684\u591a\u6a21\u6001\u63a8\u7406\u65b9\u6cd5\u80fd\u591f\u66f4\u771f\u5b9e\u5730\u7406\u89e3\u5bf9\u8bdd\u7acb\u573a\uff0c\u7528\u6237\u753b\u50cf\u548c\u591a\u6a21\u6001\u5bf9\u9f50\u5bf9\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u7acb\u573a\u7406\u89e3\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.11945", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11945", "abs": "https://arxiv.org/abs/2511.11945", "authors": ["Mohammed Temraz", "Mark T Keane"], "title": "Augmenting The Weather: A Hybrid Counterfactual-SMOTE Algorithm for Improving Crop Growth Prediction When Climate Changes", "comment": "31 pages, 8 figures", "summary": "In recent years, humanity has begun to experience the catastrophic effects of climate change as economic sectors (such as agriculture) struggle with unpredictable and extreme weather events. Artificial Intelligence (AI) should help us handle these climate challenges but its most promising solutions are not good at dealing with climate-disrupted data; specifically, machine learning methods that work from historical data-distributions, are not good at handling out-of-distribution, outlier events. In this paper, we propose a novel data augmentation method, that treats the predictive problems around climate change as being, in part, due to class-imbalance issues; that is, prediction from historical datasets is difficult because, by definition, they lack sufficient minority-class instances of \"climate outlier events\". This novel data augmentation method -- called Counterfactual-Based SMOTE (CFA-SMOTE) -- combines an instance-based counterfactual method from Explainable AI (XAI) with the well-known class-imbalance method, SMOTE. CFA-SMOTE creates synthetic data-points representing outlier, climate-events that augment the dataset to improve predictive performance. We report comparative experiments using this CFA-SMOTE method, comparing it to benchmark counterfactual and class-imbalance methods under different conditions (i.e., class-imbalance ratios). The focal climate-change domain used relies on predicting grass growth on Irish dairy farms, during Europe-wide drought and forage crisis of 2018.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2511.12133", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12133", "abs": "https://arxiv.org/abs/2511.12133", "authors": ["Qingyu Zhang", "Chunlei Xin", "Xuanang Chen", "Yaojie Lu", "Hongyu Lin", "Xianpei Han", "Le Sun", "Qing Ye", "Qianlong Xie", "Xingxing Wang"], "title": "AI-Salesman: Towards Reliable Large Language Model Driven Telemarketing", "comment": null, "summary": "Goal-driven persuasive dialogue, exemplified by applications like telemarketing, requires sophisticated multi-turn planning and strict factual faithfulness, which remains a significant challenge for even state-of-the-art Large Language Models (LLMs). A lack of task-specific data often limits previous works, and direct LLM application suffers from strategic brittleness and factual hallucination. In this paper, we first construct and release TeleSalesCorpus, the first real-world-grounded dialogue dataset for this domain. We then propose AI-Salesman, a novel framework featuring a dual-stage architecture. For the training stage, we design a Bayesian-supervised reinforcement learning algorithm that learns robust sales strategies from noisy dialogues. For the inference stage, we introduce the Dynamic Outline-Guided Agent (DOGA), which leverages a pre-built script library to provide dynamic, turn-by-turn strategic guidance. Moreover, we design a comprehensive evaluation framework that combines fine-grained metrics for key sales skills with the LLM-as-a-Judge paradigm. Experimental results demonstrate that our proposed AI-Salesman significantly outperforms baseline models in both automatic metrics and comprehensive human evaluations, showcasing its effectiveness in complex persuasive scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86AI-Salesman\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u9636\u6bb5\u67b6\u6784\u89e3\u51b3\u76ee\u6807\u9a71\u52a8\u8bf4\u670d\u5bf9\u8bdd\u4e2d\u7684\u7b56\u7565\u8106\u5f31\u6027\u548c\u4e8b\u5b9e\u5e7b\u89c9\u95ee\u9898\uff0c\u5728\u771f\u5b9e\u9500\u552e\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u76ee\u6807\u9a71\u52a8\u8bf4\u670d\u5bf9\u8bdd\uff08\u5982\u7535\u8bdd\u9500\u552e\uff09\u9700\u8981\u590d\u6742\u7684\u591a\u8f6e\u89c4\u5212\u548c\u4e25\u683c\u7684\u4e8b\u5b9e\u5fe0\u5b9e\u6027\uff0c\u73b0\u6709LLMs\u5b58\u5728\u7b56\u7565\u8106\u5f31\u6027\u548c\u4e8b\u5b9e\u5e7b\u89c9\u95ee\u9898\uff0c\u4e14\u7f3a\u4e4f\u4efb\u52a1\u7279\u5b9a\u6570\u636e\u3002", "method": "\u6784\u5efaTeleSalesCorpus\u6570\u636e\u96c6\uff0c\u63d0\u51faAI-Salesman\u6846\u67b6\uff1a\u8bad\u7ec3\u9636\u6bb5\u4f7f\u7528\u8d1d\u53f6\u65af\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u4ece\u566a\u58f0\u5bf9\u8bdd\u4e2d\u5b66\u4e60\u9c81\u68d2\u9500\u552e\u7b56\u7565\uff1b\u63a8\u7406\u9636\u6bb5\u4f7f\u7528\u52a8\u6001\u5927\u7eb2\u5f15\u5bfc\u4ee3\u7406(DOGA)\u7ed3\u5408\u9884\u5efa\u811a\u672c\u5e93\u63d0\u4f9b\u9010\u8f6e\u7b56\u7565\u6307\u5bfc\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAI-Salesman\u5728\u81ea\u52a8\u6307\u6807\u548c\u7efc\u5408\u4eba\u5de5\u8bc4\u4f30\u4e2d\u5747\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5728\u590d\u6742\u8bf4\u670d\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u63d0\u51fa\u7684AI-Salesman\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u76ee\u6807\u9a71\u52a8\u8bf4\u670d\u5bf9\u8bdd\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u901a\u8fc7\u53cc\u9636\u6bb5\u67b6\u6784\u548c\u52a8\u6001\u7b56\u7565\u6307\u5bfc\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2511.11954", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11954", "abs": "https://arxiv.org/abs/2511.11954", "authors": ["Borchuluun Yadamsuren", "Steven Keith Platt", "Miguel Diaz"], "title": "LLM-Assisted Formalization Enables Deterministic Detection of Statutory Inconsistency in the Internal Revenue Code", "comment": "29 pages, 3 appendices with Prolog code and full codebase available at: https://github.com/borchuluun/section121-inconsistency-detection", "summary": "This study introduces a hybrid neuro-symbolic framework that achieves deterministic detection of statutory inconsistency in complex law. We use the U.S. Internal Revenue Code (IRC) as a case study because its complexity makes it a fertile domain for identifying conflicts. Our research offers a solution for detecting inconsistent provisions by combining Large Language Models (LLMs) with symbolic logic.\n  LLM-based methods can support compliance, fairness, and statutory drafting, yet tax-specific applications remain sparse. A key challenge is that such models struggle with hierarchical processing and deep structured reasoning, especially over long text.\n  This research addresses these gaps through experiments using GPT-4o, GPT-5, and Prolog. GPT-4o was first used to translate Section 121 into Prolog rules and refine them in SWISH. These rules were then incorporated into prompts to test whether Prolog-augmented prompting improved GPT-4o's inconsistency detection. GPT-4o, whether prompted with natural language alone or with Prolog augmentation, detected the inconsistency in only one of three strategies (33 percent accuracy), but its reasoning quality differed: natural-language prompting achieved 100 percent rule coverage, while Prolog-augmented prompting achieved 66 percent, indicating more incomplete statutory analysis.\n  In contrast to probabilistic prompting, the hybrid Prolog model produced deterministic and reproducible results. Guided by GPT-5 for refinement, the model formalized the IRC section's competing interpretations and successfully detected an inconsistency zone. Validation tests confirm that the Prolog implementation is accurate, internally consistent, deterministic, and capable of autonomously identifying inconsistencies. These findings show that LLM-assisted formalization, anchored in symbolic logic, enables transparent and reliable statutory inconsistency detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u7b26\u53f7\u903b\u8f91\uff0c\u5b9e\u73b0\u4e86\u5bf9\u590d\u6742\u6cd5\u5f8b\u4e2d\u6cd5\u5b9a\u4e0d\u4e00\u81f4\u6027\u7684\u786e\u5b9a\u6027\u68c0\u6d4b\u3002\u4ee5\u7f8e\u56fd\u56fd\u5185\u7a0e\u6536\u6cd5\u5178\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u5728\u68c0\u6d4b\u4e0d\u4e00\u81f4\u6761\u6b3e\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709LLM\u65b9\u6cd5\u5728\u7a0e\u52a1\u9886\u57df\u7684\u5e94\u7528\u8f83\u5c11\uff0c\u4e14\u5728\u5904\u7406\u5c42\u6b21\u5316\u5904\u7406\u548c\u6df1\u5ea6\u7ed3\u6784\u5316\u63a8\u7406\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u7279\u522b\u662f\u5728\u957f\u6587\u672c\u4e0a\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u786e\u5b9a\u6027\u68c0\u6d4b\u6cd5\u5f8b\u4e0d\u4e00\u81f4\u6027\u7684\u53ef\u9760\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528GPT-4o\u5c06\u7a0e\u6cd5\u6761\u6b3e\u7ffb\u8bd1\u4e3aProlog\u89c4\u5219\uff0c\u5728SWISH\u4e2d\u7cbe\u70bc\uff0c\u7136\u540e\u901a\u8fc7Prolog\u589e\u5f3a\u63d0\u793a\u6d4b\u8bd5\u4e0d\u4e00\u81f4\u6027\u68c0\u6d4b\u3002\u540c\u65f6\u5f00\u53d1\u4e86\u6df7\u5408Prolog\u6a21\u578b\uff0c\u7531GPT-5\u6307\u5bfc\u7cbe\u70bc\uff0c\u5f62\u5f0f\u5316\u7ade\u4e89\u6027\u89e3\u91ca\u5e76\u68c0\u6d4b\u4e0d\u4e00\u81f4\u533a\u57df\u3002", "result": "GPT-4o\u5355\u72ec\u6216Prolog\u589e\u5f3a\u63d0\u793a\u4e0b\u4ec5\u5728\u4e09\u9879\u7b56\u7565\u4e2d\u68c0\u6d4b\u5230\u4e00\u9879\u4e0d\u4e00\u81f4\uff0833%\u51c6\u786e\u7387\uff09\u3002\u4f46\u6df7\u5408Prolog\u6a21\u578b\u4ea7\u751f\u786e\u5b9a\u6027\u3001\u53ef\u91cd\u73b0\u7ed3\u679c\uff0c\u6210\u529f\u68c0\u6d4b\u5230\u4e0d\u4e00\u81f4\u533a\u57df\uff0c\u9a8c\u8bc1\u6d4b\u8bd5\u786e\u8ba4\u5176\u51c6\u786e\u3001\u5185\u90e8\u4e00\u81f4\u4e14\u80fd\u81ea\u4e3b\u8bc6\u522b\u4e0d\u4e00\u81f4\u6027\u3002", "conclusion": "\u57fa\u4e8e\u7b26\u53f7\u903b\u8f91\u7684LLM\u8f85\u52a9\u5f62\u5f0f\u5316\u80fd\u591f\u5b9e\u73b0\u900f\u660e\u53ef\u9760\u7684\u6cd5\u5b9a\u4e0d\u4e00\u81f4\u6027\u68c0\u6d4b\uff0c\u6df7\u5408\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\u5728\u6cd5\u5f8b\u5206\u6790\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.12140", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.12140", "abs": "https://arxiv.org/abs/2511.12140", "authors": ["Pinxue Guo", "Chongruo Wu", "Xinyu Zhou", "Lingyi Hong", "Zhaoyu Chen", "Jinglun Li", "Kaixun Jiang", "Sen-ching Samson Cheung", "Wei Zhang", "Wenqiang Zhang"], "title": "Seeing is Believing: Rich-Context Hallucination Detection for MLLMs via Backward Visual Grounding", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have unlocked powerful cross-modal capabilities, but still significantly suffer from hallucinations. As such, accurate detection of hallucinations in MLLMs is imperative for ensuring their reliability in practical applications. To this end, guided by the principle of \"Seeing is Believing\", we introduce VBackChecker, a novel reference-free hallucination detection framework that verifies the consistency of MLLMgenerated responses with visual inputs, by leveraging a pixellevel Grounding LLM equipped with reasoning and referring segmentation capabilities. This reference-free framework not only effectively handles rich-context scenarios, but also offers interpretability. To facilitate this, an innovative pipeline is accordingly designed for generating instruction-tuning data (R-Instruct), featuring rich-context descriptions, grounding masks, and hard negative samples. We further establish R^2 -HalBench, a new hallucination benchmark for MLLMs, which, unlike previous benchmarks, encompasses real-world, rich-context descriptions from 18 MLLMs with high-quality annotations, spanning diverse object-, attribute, and relationship-level details. VBackChecker outperforms prior complex frameworks and achieves state-of-the-art performance on R^2 -HalBench, even rivaling GPT-4o's capabilities in hallucination detection. It also surpasses prior methods in the pixel-level grounding task, achieving over a 10% improvement. All codes, data, and models are available at https://github.com/PinxueGuo/VBackChecker.", "AI": {"tldr": "VBackChecker\u662f\u4e00\u4e2a\u65e0\u9700\u53c2\u8003\u7684\u5e7b\u89c9\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u50cf\u7d20\u7ea7Grounding LLM\u9a8c\u8bc1MLLM\u751f\u6210\u54cd\u5e94\u4e0e\u89c6\u89c9\u8f93\u5165\u7684\u4e00\u81f4\u6027\uff0c\u5728R^2-HalBench\u57fa\u51c6\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u4e25\u91cd\u5e7b\u89c9\u95ee\u9898\uff0c\u9700\u8981\u51c6\u786e\u68c0\u6d4b\u4ee5\u786e\u4fdd\u5b9e\u9645\u5e94\u7528\u7684\u53ef\u9760\u6027\u3002", "method": "\u57fa\u4e8e\"\u773c\u89c1\u4e3a\u5b9e\"\u539f\u5219\uff0c\u4f7f\u7528\u5177\u5907\u63a8\u7406\u548c\u5206\u5272\u80fd\u529b\u7684\u50cf\u7d20\u7ea7Grounding LLM\uff0c\u8bbe\u8ba1\u4e86R-Instruct\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u751f\u6210\u6d41\u7a0b\uff0c\u5305\u542b\u4e30\u5bcc\u4e0a\u4e0b\u6587\u63cf\u8ff0\u3001\u5b9a\u4f4d\u63a9\u7801\u548c\u56f0\u96be\u8d1f\u6837\u672c\u3002", "result": "\u5728R^2-HalBench\u57fa\u51c6\u4e0a\u8d85\u8d8a\u5148\u524d\u590d\u6742\u6846\u67b6\uff0c\u6027\u80fd\u5ab2\u7f8eGPT-4o\uff0c\u5728\u50cf\u7d20\u7ea7\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u63d0\u5347\u8d85\u8fc710%\u3002", "conclusion": "VBackChecker\u4e3aMLLM\u5e7b\u89c9\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u53c2\u8003\u65e0\u5173\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u826f\u597d\u53ef\u89e3\u91ca\u6027\u5e76\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2511.11990", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.11990", "abs": "https://arxiv.org/abs/2511.11990", "authors": ["Shaoqi Wang", "Lu Yu", "Chunjie Yang"], "title": "Improving Autoformalization Using Direct Dependency Retrieval", "comment": null, "summary": "The convergence of deep learning and formal mathematics has spurred research in formal verification. Statement autoformalization, a crucial first step in this process, aims to translate informal descriptions into machine-verifiable representations but remains a significant challenge. The core difficulty lies in the fact that existing methods often suffer from a lack of contextual awareness, leading to hallucination of formal definitions and theorems. Furthermore, current retrieval-augmented approaches exhibit poor precision and recall for formal library dependency retrieval, and lack the scalability to effectively leverage ever-growing public datasets. To bridge this gap, we propose a novel retrieval-augmented framework based on DDR (\\textit{Direct Dependency Retrieval}) for statement autoformalization. Our DDR method directly generates candidate library dependencies from natural language mathematical descriptions and subsequently verifies their existence within the formal library via an efficient suffix array check. Leveraging this efficient search mechanism, we constructed a dependency retrieval dataset of over 500,000 samples and fine-tuned a high-precision DDR model. Experimental results demonstrate that our DDR model significantly outperforms SOTA methods in both retrieval precision and recall. Consequently, an autoformalizer equipped with DDR shows consistent performance advantages in both single-attempt accuracy and multi-attempt stability compared to models using traditional selection-based RAG methods.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u76f4\u63a5\u4f9d\u8d56\u68c0\u7d22(DDR)\u7684\u65b0\u6846\u67b6\uff0c\u89e3\u51b3\u6570\u5b66\u9648\u8ff0\u81ea\u52a8\u5f62\u5f0f\u5316\u4e2d\u4e0a\u4e0b\u6587\u610f\u8bc6\u4e0d\u8db3\u548c\u4f9d\u8d56\u68c0\u7d22\u7cbe\u5ea6\u4f4e\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u68c0\u7d22\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5f62\u5f0f\u5316\u65b9\u6cd5\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u610f\u8bc6\uff0c\u5bfc\u81f4\u5f62\u5f0f\u5b9a\u4e49\u548c\u5b9a\u7406\u7684\u5e7b\u89c9\uff0c\u4e14\u4f20\u7edf\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u5728\u5f62\u5f0f\u5e93\u4f9d\u8d56\u68c0\u7d22\u4e0a\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u5dee\uff0c\u96be\u4ee5\u6709\u6548\u5229\u7528\u5927\u89c4\u6a21\u516c\u5171\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51faDDR\u65b9\u6cd5\uff1a\u76f4\u63a5\u4ece\u81ea\u7136\u8bed\u8a00\u6570\u5b66\u63cf\u8ff0\u751f\u6210\u5019\u9009\u5e93\u4f9d\u8d56\uff0c\u901a\u8fc7\u9ad8\u6548\u540e\u7f00\u6570\u7ec4\u68c0\u67e5\u9a8c\u8bc1\u5176\u5728\u5f62\u5f0f\u5e93\u4e2d\u7684\u5b58\u5728\u6027\uff0c\u6784\u5efa\u8d85\u8fc750\u4e07\u6837\u672c\u7684\u4f9d\u8d56\u68c0\u7d22\u6570\u636e\u96c6\u5e76\u5fae\u8c03\u9ad8\u7cbe\u5ea6DDR\u6a21\u578b\u3002", "result": "DDR\u6a21\u578b\u5728\u68c0\u7d22\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u4e0a\u663e\u8457\u4f18\u4e8eSOTA\u65b9\u6cd5\uff0c\u914d\u5907DDR\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u5668\u5728\u5355\u6b21\u5c1d\u8bd5\u51c6\u786e\u7387\u548c\u591a\u6b21\u5c1d\u8bd5\u7a33\u5b9a\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u4f20\u7edf\u57fa\u4e8e\u9009\u62e9\u7684RAG\u65b9\u6cd5\u3002", "conclusion": "DDR\u6846\u67b6\u901a\u8fc7\u9ad8\u6548\u7684\u4f9d\u8d56\u68c0\u7d22\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u81ea\u52a8\u5f62\u5f0f\u5316\u4e2d\u7684\u4e0a\u4e0b\u6587\u610f\u8bc6\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u4e0e\u5f62\u5f0f\u6570\u5b66\u7684\u878d\u5408\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6280\u672f\u652f\u6491\u3002"}}
{"id": "2511.12159", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12159", "abs": "https://arxiv.org/abs/2511.12159", "authors": ["Yaocheng Zhang", "Haohuan Huang", "Zijun Song", "Yuanheng Zhu", "Qichao Zhang", "Zijie Zhao", "Dongbin Zhao"], "title": "CriticSearch: Fine-Grained Credit Assignment for Search Agents via a Retrospective Critic", "comment": "17 pages, 10 figures", "summary": "Tool-Integrated Reasoning (TIR) with search engines enables large language models to iteratively retrieve up-to-date external knowledge, enhancing adaptability and generalization in complex question-answering tasks. However, existing search agent pipelines typically depend on reinforcement learning based optimization, which often suffers from sparse outcome rewards, leading to inefficient exploration and unstable training. We introduce CriticSearch, a fine-grained credit-assignment framework that supplies dense, turn-level feedback via a retrospective critic mechanism. During training, a frozen, asymmetric critique LLM retrospectively evaluates each turn using privileged information from the full trajectory and gold answers, converting these assessments into stable, dense rewards that guide policy improvement. Experimental results across diverse multi-hop reasoning benchmarks demonstrate that CriticSearch consistently outperforms existing baselines, achieving faster convergence, improved training stability, and higher performance.", "AI": {"tldr": "CriticSearch\u662f\u4e00\u4e2a\u7ec6\u7c92\u5ea6\u4fe1\u7528\u5206\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u56de\u987e\u6027\u6279\u8bc4\u673a\u5236\u63d0\u4f9b\u5bc6\u96c6\u7684\u56de\u5408\u7ea7\u53cd\u9988\uff0c\u89e3\u51b3\u641c\u7d22\u4ee3\u7406\u4e2d\u7a00\u758f\u5956\u52b1\u5bfc\u81f4\u7684\u4f4e\u6548\u63a2\u7d22\u548c\u4e0d\u7a33\u5b9a\u8bad\u7ec3\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u641c\u7d22\u4ee3\u7406\u7ba1\u9053\u4f9d\u8d56\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4f18\u5316\uff0c\u4f46\u5b58\u5728\u7a00\u758f\u7ed3\u679c\u5956\u52b1\u95ee\u9898\uff0c\u5bfc\u81f4\u63a2\u7d22\u6548\u7387\u4f4e\u4e0b\u548c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u3002", "method": "\u4f7f\u7528\u51bb\u7ed3\u7684\u975e\u5bf9\u79f0\u6279\u8bc4LLM\uff0c\u5229\u7528\u5b8c\u6574\u8f68\u8ff9\u548c\u9ec4\u91d1\u7b54\u6848\u7684\u7279\u6743\u4fe1\u606f\u56de\u987e\u6027\u8bc4\u4f30\u6bcf\u4e2a\u56de\u5408\uff0c\u5c06\u8fd9\u4e9b\u8bc4\u4f30\u8f6c\u5316\u4e3a\u7a33\u5b9a\u7684\u5bc6\u96c6\u5956\u52b1\u6765\u6307\u5bfc\u7b56\u7565\u6539\u8fdb\u3002", "result": "\u5728\u591a\u6837\u5316\u591a\u8df3\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCriticSearch\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u6536\u655b\u3001\u66f4\u597d\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u66f4\u9ad8\u7684\u6027\u80fd\u3002", "conclusion": "CriticSearch\u901a\u8fc7\u5bc6\u96c6\u7684\u56de\u5408\u7ea7\u53cd\u9988\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86\u641c\u7d22\u4ee3\u7406\u5728\u590d\u6742\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2511.12003", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12003", "abs": "https://arxiv.org/abs/2511.12003", "authors": ["Shuochen Liu", "Pengfei Luo", "Chao Zhang", "Yuhao Chen", "Haotian Zhang", "Qi Liu", "Xin Kou", "Tong Xu", "Enhong Chen"], "title": "Look As You Think: Unifying Reasoning and Visual Evidence Attribution for Verifiable Document RAG via Reinforcement Learning", "comment": "Poster of AAAI'2026", "summary": "Aiming to identify precise evidence sources from visual documents, visual evidence attribution for visual document retrieval-augmented generation (VD-RAG) ensures reliable and verifiable predictions from vision-language models (VLMs) in multimodal question answering. Most existing methods adopt end-to-end training to facilitate intuitive answer verification. However, they lack fine-grained supervision and progressive traceability throughout the reasoning process. In this paper, we introduce the Chain-of-Evidence (CoE) paradigm for VD-RAG. CoE unifies Chain-of-Thought (CoT) reasoning and visual evidence attribution by grounding reference elements in reasoning steps to specific regions with bounding boxes and page indexes. To enable VLMs to generate such evidence-grounded reasoning, we propose Look As You Think (LAT), a reinforcement learning framework that trains models to produce verifiable reasoning paths with consistent attribution. During training, LAT evaluates the attribution consistency of each evidence region and provides rewards only when the CoE trajectory yields correct answers, encouraging process-level self-verification. Experiments on vanilla Qwen2.5-VL-7B-Instruct with Paper- and Wiki-VISA benchmarks show that LAT consistently improves the vanilla model in both single- and multi-image settings, yielding average gains of 8.23% in soft exact match (EM) and 47.0% in IoU@0.5. Meanwhile, LAT not only outperforms the supervised fine-tuning baseline, which is trained to directly produce answers with attribution, but also exhibits stronger generalization across domains.", "AI": {"tldr": "\u63d0\u51faChain-of-Evidence\uff08CoE\uff09\u8303\u5f0f\u548cLook As You Think\uff08LAT\uff09\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u89c6\u89c9\u6587\u6863\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e2d\u7684\u8bc1\u636e\u5f52\u56e0\uff0c\u901a\u8fc7\u8fb9\u754c\u6846\u548c\u9875\u7801\u7d22\u5f15\u5c06\u63a8\u7406\u6b65\u9aa4\u4e0e\u5177\u4f53\u89c6\u89c9\u533a\u57df\u5173\u8054\uff0c\u63d0\u9ad8\u7b54\u6848\u7684\u53ef\u9a8c\u8bc1\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u76d1\u7763\u548c\u63a8\u7406\u8fc7\u7a0b\u7684\u6e10\u8fdb\u53ef\u8ffd\u6eaf\u6027\uff0c\u65e0\u6cd5\u786e\u4fdd\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u95ee\u7b54\u4e2d\u4ea7\u751f\u53ef\u9760\u4e14\u53ef\u9a8c\u8bc1\u7684\u9884\u6d4b\u3002", "method": "CoE\u7edf\u4e00\u4e86\u601d\u7ef4\u94fe\u63a8\u7406\u548c\u89c6\u89c9\u8bc1\u636e\u5f52\u56e0\uff0cLAT\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6a21\u578b\u751f\u6210\u5177\u6709\u4e00\u81f4\u5f52\u56e0\u7684\u53ef\u9a8c\u8bc1\u63a8\u7406\u8def\u5f84\uff0c\u8bc4\u4f30\u8bc1\u636e\u533a\u57df\u7684\u4e00\u81f4\u6027\u5e76\u5728\u6b63\u786e\u65f6\u63d0\u4f9b\u5956\u52b1\u3002", "result": "\u5728Qwen2.5-VL-7B-Instruct\u6a21\u578b\u4e0a\uff0cLAT\u5728\u5355\u56fe\u548c\u591a\u56fe\u8bbe\u7f6e\u4e0b\u5747\u8868\u73b0\u4f18\u5f02\uff0csoft EM\u5e73\u5747\u63d0\u53478.23%\uff0cIoU@0.5\u63d0\u534747.0%\uff0c\u4f18\u4e8e\u76d1\u7763\u5fae\u8c03\u57fa\u7ebf\u5e76\u5c55\u73b0\u51fa\u66f4\u5f3a\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "LAT\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u89c6\u89c9\u6587\u6863\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e2d\u7684\u8bc1\u636e\u5f52\u56e0\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u8fc7\u7a0b\u7ea7\u81ea\u9a8c\u8bc1\uff0c\u4e3a\u53ef\u9760\u7684\u591a\u6a21\u6001\u95ee\u7b54\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2511.12213", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12213", "abs": "https://arxiv.org/abs/2511.12213", "authors": ["Liang Xue", "Haoyu Liu", "Yajun Tian", "Xinyu Zhong", "Yang Liu"], "title": "MME-RAG: Multi-Manager-Expert Retrieval-Augmented Generation for Fine-Grained Entity Recognition in Task-Oriented Dialogues", "comment": null, "summary": "Fine-grained entity recognition is crucial for reasoning and decision-making in task-oriented dialogues, yet current large language models (LLMs) continue to face challenges in domain adaptation and retrieval controllability. We introduce MME-RAG, a Multi-Manager-Expert Retrieval-Augmented Generation framework that decomposes entity recognition into two coordinated stages: type-level judgment by lightweight managers and span-level extraction by specialized experts. Each expert is supported by a KeyInfo retriever that injects semantically aligned, few-shot exemplars during inference, enabling precise and domain-adaptive extraction without additional training. Experiments on CrossNER, MIT-Movie, MIT-Restaurant, and our newly constructed multi-domain customer-service dataset demonstrate that MME-RAG performs better than recent baselines in most domains. Ablation studies further show that both the hierarchical decomposition and KeyInfo-guided retrieval are key drivers of robustness and cross-domain generalization, establishing MME-RAG as a scalable and interpretable solution for adaptive dialogue understanding.", "AI": {"tldr": "MME-RAG\u662f\u4e00\u4e2a\u591a\u7ba1\u7406\u5668-\u4e13\u5bb6\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u5c06\u5b9e\u4f53\u8bc6\u522b\u5206\u89e3\u4e3a\u7c7b\u578b\u7ea7\u5224\u65ad\u548c\u8de8\u5ea6\u7ea7\u63d0\u53d6\u4e24\u4e2a\u534f\u8c03\u9636\u6bb5\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7ba1\u7406\u5668\u548c\u4e13\u4e1a\u4e13\u5bb6\u5b9e\u73b0\u7cbe\u786e\u7684\u9886\u57df\u81ea\u9002\u5e94\u63d0\u53d6\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9762\u5411\u4efb\u52a1\u7684\u5bf9\u8bdd\u4e2d\u9762\u4e34\u9886\u57df\u9002\u5e94\u6027\u548c\u68c0\u7d22\u53ef\u63a7\u6027\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u7ec6\u7c92\u5ea6\u5b9e\u4f53\u8bc6\u522b\u65b9\u9762\u3002", "method": "\u91c7\u7528\u5206\u5c42\u5206\u89e3\u65b9\u6cd5\uff1a\u8f7b\u91cf\u7ea7\u7ba1\u7406\u5668\u8fdb\u884c\u7c7b\u578b\u7ea7\u5224\u65ad\uff0c\u4e13\u4e1a\u4e13\u5bb6\u8fdb\u884c\u8de8\u5ea6\u7ea7\u63d0\u53d6\uff0c\u6bcf\u4e2a\u4e13\u5bb6\u914d\u5907KeyInfo\u68c0\u7d22\u5668\u6ce8\u5165\u8bed\u4e49\u5bf9\u9f50\u7684\u5c11\u6837\u672c\u793a\u4f8b\u3002", "result": "\u5728CrossNER\u3001MIT-Movie\u3001MIT-Restaurant\u548c\u65b0\u6784\u5efa\u7684\u591a\u9886\u57df\u5ba2\u670d\u6570\u636e\u96c6\u4e0a\uff0cMME-RAG\u5728\u5927\u591a\u6570\u9886\u57df\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "MME-RAG\u901a\u8fc7\u5206\u5c42\u5206\u89e3\u548cKeyInfo\u5f15\u5bfc\u7684\u68c0\u7d22\u5b9e\u73b0\u4e86\u9c81\u68d2\u6027\u548c\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u81ea\u9002\u5e94\u5bf9\u8bdd\u7406\u89e3\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.12008", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12008", "abs": "https://arxiv.org/abs/2511.12008", "authors": ["Yunqi Hong", "Johnson Kao", "Liam Edwards", "Nein-Tzu Liu", "Chung-Yen Huang", "Alex Oliveira-Kowaleski", "Cho-Jui Hsieh", "Neil Y. C. Lin"], "title": "Adaptive Diagnostic Reasoning Framework for Pathology with Multimodal Large Language Models", "comment": null, "summary": "AI tools in pathology have improved screening throughput, standardized quantification, and revealed prognostic patterns that inform treatment. However, adoption remains limited because most systems still lack the human-readable reasoning needed to audit decisions and prevent errors. We present RECAP-PATH, an interpretable framework that establishes a self-learning paradigm, shifting off-the-shelf multimodal large language models from passive pattern recognition to evidence-linked diagnostic reasoning. At its core is a two-phase learning process that autonomously derives diagnostic criteria: diversification expands pathology-style explanations, while optimization refines them for accuracy. This self-learning approach requires only small labeled sets and no white-box access or weight updates to generate cancer diagnoses. Evaluated on breast and prostate datasets, RECAP-PATH produced rationales aligned with expert assessment and delivered substantial gains in diagnostic accuracy over baselines. By uniting visual understanding with reasoning, RECAP-PATH provides clinically trustworthy AI and demonstrates a generalizable path toward evidence-linked interpretation.", "AI": {"tldr": "RECAP-PATH\u662f\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u75c5\u7406AI\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u81ea\u5b66\u4e60\u8fc7\u7a0b\u4ece\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u81ea\u4e3b\u63a8\u5bfc\u8bca\u65ad\u6807\u51c6\uff0c\u65e0\u9700\u767d\u76d2\u8bbf\u95ee\u6216\u6743\u91cd\u66f4\u65b0\u5373\u53ef\u751f\u6210\u764c\u75c7\u8bca\u65ad\u3002", "motivation": "\u5f53\u524d\u75c5\u7406AI\u7cfb\u7edf\u7f3a\u4e4f\u4eba\u7c7b\u53ef\u8bfb\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u9650\u5236\u4e86\u4e34\u5e8a\u5e94\u7528\uff0c\u56e0\u4e3a\u65e0\u6cd5\u5ba1\u8ba1\u51b3\u7b56\u548c\u9632\u6b62\u9519\u8bef\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u81ea\u5b66\u4e60\u8fc7\u7a0b\uff1a\u591a\u6837\u5316\u9636\u6bb5\u6269\u5c55\u75c5\u7406\u5b66\u98ce\u683c\u89e3\u91ca\uff0c\u4f18\u5316\u9636\u6bb5\u4e3a\u51c6\u786e\u6027\u7cbe\u70bc\u89e3\u91ca\u3002\u4ec5\u9700\u5c11\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u65e0\u9700\u767d\u76d2\u8bbf\u95ee\u6216\u6743\u91cd\u66f4\u65b0\u3002", "result": "\u5728\u4e73\u817a\u764c\u548c\u524d\u5217\u817a\u764c\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cRECAP-PATH\u751f\u6210\u7684\u63a8\u7406\u4e0e\u4e13\u5bb6\u8bc4\u4f30\u4e00\u81f4\uff0c\u8bca\u65ad\u51c6\u786e\u6027\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "RECAP-PATH\u901a\u8fc7\u7ed3\u5408\u89c6\u89c9\u7406\u89e3\u548c\u63a8\u7406\uff0c\u63d0\u4f9b\u4e86\u4e34\u5e8a\u53ef\u4fe1\u7684AI\uff0c\u5c55\u793a\u4e86\u8bc1\u636e\u5173\u8054\u89e3\u91ca\u7684\u901a\u7528\u8def\u5f84\u3002"}}
{"id": "2511.12236", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12236", "abs": "https://arxiv.org/abs/2511.12236", "authors": ["Raavi Gupta", "Pranav Hari Panicker", "Sumit Bhatia", "Ganesh Ramakrishnan"], "title": "Consistency Is the Key: Detecting Hallucinations in LLM Generated Text By Checking Inconsistencies About Key Facts", "comment": "To appear at International Joint Conference on Natural Language Processing & Asia-Pacific Chapter of the Association for Computational Linguistics (IJCNLP-AACL), 2025", "summary": "Large language models (LLMs), despite their remarkable text generation capabilities, often hallucinate and generate text that is factually incorrect and not grounded in real-world knowledge. This poses serious risks in domains like healthcare, finance, and customer support. A typical way to use LLMs is via the APIs provided by LLM vendors where there is no access to model weights or options to fine-tune the model. Existing methods to detect hallucinations in such settings where the model access is restricted or constrained by resources typically require making multiple LLM API calls, increasing latency and API cost. We introduce CONFACTCHECK, an efficient hallucination detection approach that does not leverage any external knowledge base and works on the simple intuition that responses to factual probes within the generated text should be consistent within a single LLM and across different LLMs. Rigorous empirical evaluation on multiple datasets that cover both the generation of factual texts and the open generation shows that CONFACTCHECK can detect hallucinated facts efficiently using fewer resources and achieves higher accuracy scores compared to existing baselines that operate under similar conditions. Our code is available here.", "AI": {"tldr": "CONFACTCHECK\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u68c0\u67e5\u751f\u6210\u6587\u672c\u4e2d\u4e8b\u5b9e\u63a2\u9488\u7684\u4e00\u81f4\u6027\u6765\u68c0\u6d4b\u5e7b\u89c9\uff0c\u65e0\u9700\u5916\u90e8\u77e5\u8bc6\u5e93\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ecf\u5e38\u4ea7\u751f\u4e8b\u5b9e\u9519\u8bef\u7684\u5e7b\u89c9\u6587\u672c\uff0c\u5728\u533b\u7597\u3001\u91d1\u878d\u7b49\u9886\u57df\u5b58\u5728\u4e25\u91cd\u98ce\u9669\u3002\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5728\u6a21\u578b\u8bbf\u95ee\u53d7\u9650\u65f6\u9700\u8981\u591a\u6b21API\u8c03\u7528\uff0c\u589e\u52a0\u4e86\u5ef6\u8fdf\u548c\u6210\u672c\u3002", "method": "\u57fa\u4e8e\u76f4\u89c9\u8bbe\u8ba1\u7684\u65b9\u6cd5\uff1a\u540c\u4e00LLM\u5185\u90e8\u548c\u4e0d\u540cLLM\u4e4b\u95f4\u5bf9\u751f\u6210\u6587\u672c\u4e2d\u4e8b\u5b9e\u63a2\u9488\u7684\u56de\u7b54\u5e94\u8be5\u4fdd\u6301\u4e00\u81f4\uff0c\u901a\u8fc7\u68c0\u67e5\u8fd9\u79cd\u4e00\u81f4\u6027\u6765\u68c0\u6d4b\u5e7b\u89c9\uff0c\u65e0\u9700\u5916\u90e8\u77e5\u8bc6\u5e93\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u4e25\u683c\u8bc4\u4f30\u8868\u660e\uff0cCONFACTCHECK\u80fd\u591f\u4f7f\u7528\u66f4\u5c11\u8d44\u6e90\u9ad8\u6548\u68c0\u6d4b\u5e7b\u89c9\u4e8b\u5b9e\uff0c\u5728\u76f8\u4f3c\u6761\u4ef6\u4e0b\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u5206\u6570\u3002", "conclusion": "CONFACTCHECK\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u8d44\u6e90\u53cb\u597d\u7684\u5e7b\u89c9\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6a21\u578b\u8bbf\u95ee\u53d7\u9650\u6216\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u3002"}}
{"id": "2511.12060", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12060", "abs": "https://arxiv.org/abs/2511.12060", "authors": ["Yinghao Ruan", "Wei Pang", "Shuaihao Liu", "Huili Yang", "Leyi Han", "Xinghui Dong"], "title": "Intelligent Collaborative Optimization for Rubber Tyre Film Production Based on Multi-path Differentiated Clipping Proximal Policy Optimization", "comment": "10 pages", "summary": "The advent of smart manufacturing is addressing the limitations of traditional centralized scheduling and inflexible production line configurations in the rubber tyre industry, especially in terms of coping with dynamic production demands. Contemporary tyre manufacturing systems form complex networks of tightly coupled subsystems pronounced nonlinear interactions and emergent dynamics. This complexity renders the effective coordination of multiple subsystems, posing an essential yet formidable task. For high-dimensional, multi-objective optimization problems in this domain, we introduce a deep reinforcement learning algorithm: Multi-path Differentiated Clipping Proximal Policy Optimization (MPD-PPO). This algorithm employs a multi-branch policy architecture with differentiated gradient clipping constraints to ensure stable and efficient high-dimensional policy updates. Validated through experiments on width and thickness control in rubber tyre film production, MPD-PPO demonstrates substantial improvements in both tuning accuracy and operational efficiency. The framework successfully tackles key challenges, including high dimensionality, multi-objective trade-offs, and dynamic adaptation, thus delivering enhanced performance and production stability for real-time industrial deployment in tyre manufacturing.", "AI": {"tldr": "\u63d0\u51faMPD-PPO\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u8f6e\u80ce\u5236\u9020\u4e2d\u7684\u9ad8\u7ef4\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u5728\u6a61\u80f6\u8584\u819c\u751f\u4ea7\u7684\u5bbd\u5ea6\u548c\u539a\u5ea6\u63a7\u5236\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u8c03\u8c10\u7cbe\u5ea6\u548c\u64cd\u4f5c\u6548\u7387\u3002", "motivation": "\u667a\u80fd\u5236\u9020\u9700\u8981\u89e3\u51b3\u4f20\u7edf\u96c6\u4e2d\u8c03\u5ea6\u548c\u751f\u4ea7\u7ebf\u914d\u7f6e\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5e94\u5bf9\u52a8\u6001\u751f\u4ea7\u9700\u6c42\u3002\u8f6e\u80ce\u5236\u9020\u7cfb\u7edf\u5f62\u6210\u590d\u6742\u7684\u7f51\u7edc\uff0c\u5177\u6709\u975e\u7ebf\u6027\u76f8\u4e92\u4f5c\u7528\u548c\u6d8c\u73b0\u52a8\u6001\uff0c\u591a\u5b50\u7cfb\u7edf\u534f\u8c03\u6210\u4e3a\u5173\u952e\u6311\u6218\u3002", "method": "\u5f15\u5165\u591a\u8def\u5f84\u5dee\u5f02\u5316\u88c1\u526a\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\uff08MPD-PPO\uff09\uff0c\u91c7\u7528\u591a\u5206\u652f\u7b56\u7565\u67b6\u6784\u548c\u5dee\u5f02\u5316\u68af\u5ea6\u88c1\u526a\u7ea6\u675f\uff0c\u786e\u4fdd\u9ad8\u7ef4\u7b56\u7565\u66f4\u65b0\u7684\u7a33\u5b9a\u6027\u548c\u6548\u7387\u3002", "result": "\u5728\u6a61\u80f6\u8f6e\u80ce\u8584\u819c\u751f\u4ea7\u7684\u5bbd\u5ea6\u548c\u539a\u5ea6\u63a7\u5236\u5b9e\u9a8c\u4e2d\uff0cMPD-PPO\u5728\u8c03\u8c10\u7cbe\u5ea6\u548c\u64cd\u4f5c\u6548\u7387\u65b9\u9762\u5747\u8868\u73b0\u51fa\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u9ad8\u7ef4\u5ea6\u3001\u591a\u76ee\u6807\u6743\u8861\u548c\u52a8\u6001\u9002\u5e94\u7b49\u5173\u952e\u6311\u6218\uff0c\u4e3a\u8f6e\u80ce\u5236\u9020\u4e2d\u7684\u5b9e\u65f6\u5de5\u4e1a\u90e8\u7f72\u63d0\u4f9b\u4e86\u589e\u5f3a\u7684\u6027\u80fd\u548c\u751f\u4ea7\u7a33\u5b9a\u6027\u3002"}}
{"id": "2511.12249", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12249", "abs": "https://arxiv.org/abs/2511.12249", "authors": ["Khang T. Huynh", "Dung H. Nguyen", "Binh T. Nguyen"], "title": "ViConBERT: Context-Gloss Aligned Vietnamese Word Embedding for Polysemous and Sense-Aware Representations", "comment": null, "summary": "Recent advances in contextualized word embeddings have greatly improved semantic tasks such as Word Sense Disambiguation (WSD) and contextual similarity, but most progress has been limited to high-resource languages like English. Vietnamese, in contrast, still lacks robust models and evaluation resources for fine-grained semantic understanding. In this paper, we present ViConBERT, a novel framework for learning Vietnamese contextualized embeddings that integrates contrastive learning (SimCLR) and gloss-based distillation to better capture word meaning. We also introduce ViConWSD, the first large-scale synthetic dataset for evaluating semantic understanding in Vietnamese, covering both WSD and contextual similarity. Experimental results show that ViConBERT outperforms strong baselines on WSD (F1 = 0.87) and achieves competitive performance on ViCon (AP = 0.88) and ViSim-400 (Spearman's rho = 0.60), demonstrating its effectiveness in modeling both discrete senses and graded semantic relations. Our code, models, and data are available at https://github.com/tkhangg0910/ViConBERT", "AI": {"tldr": "\u63d0\u51faViConBERT\u6846\u67b6\u7528\u4e8e\u5b66\u4e60\u8d8a\u5357\u8bed\u4e0a\u4e0b\u6587\u5d4c\u5165\uff0c\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u548c\u57fa\u4e8e\u8bcd\u4e49\u89e3\u91ca\u7684\u84b8\u998f\u65b9\u6cd5\uff0c\u5e76\u521b\u5efa\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u8d8a\u5357\u8bed\u8bed\u4e49\u7406\u89e3\u8bc4\u4f30\u6570\u636e\u96c6ViConWSD\u3002", "motivation": "\u8d8a\u5357\u8bed\u7f3a\u4e4f\u5f3a\u5927\u7684\u8bed\u4e49\u7406\u89e3\u6a21\u578b\u548c\u8bc4\u4f30\u8d44\u6e90\uff0c\u800c\u73b0\u6709\u8fdb\u5c55\u4e3b\u8981\u96c6\u4e2d\u5728\u82f1\u8bed\u7b49\u9ad8\u8d44\u6e90\u8bed\u8a00\u4e0a\u3002", "method": "\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60(SimCLR)\u548c\u57fa\u4e8e\u8bcd\u4e49\u89e3\u91ca\u7684\u84b8\u998f\u65b9\u6cd5\u5b66\u4e60\u8d8a\u5357\u8bed\u4e0a\u4e0b\u6587\u5d4c\u5165\uff0c\u5e76\u6784\u5efa\u5927\u89c4\u6a21\u5408\u6210\u6570\u636e\u96c6ViConWSD\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "ViConBERT\u5728WSD\u4efb\u52a1\u4e0aF1\u8fbe\u52300.87\uff0c\u5728ViCon\u548cViSim-400\u6570\u636e\u96c6\u4e0a\u5206\u522b\u8fbe\u5230AP=0.88\u548cSpearman's rho=0.60\u7684\u7ade\u4e89\u6027\u8868\u73b0\u3002", "conclusion": "ViConBERT\u5728\u5efa\u6a21\u79bb\u6563\u8bcd\u4e49\u548c\u5206\u7ea7\u8bed\u4e49\u5173\u7cfb\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u8d8a\u5357\u8bed\u8bed\u4e49\u7406\u89e3\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.12063", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12063", "abs": "https://arxiv.org/abs/2511.12063", "authors": ["Enoch Hyunwook Kang", "Hema Yoganarasimhan"], "title": "Bayesian Optimization in Language Space: An Eval-Efficient AI Self-Improvement Framework", "comment": null, "summary": "Large Language Models (LLMs) have recently enabled self-improving AI, i.e., AI that iteratively generates, evaluates, and refines its own outcomes. Recent studies have shown that self-improving AI focusing on prompt optimization can outperform state-of-the-art reinforcement-learning fine-tuned LLMs. Here, their `performance' is typically measured by query efficiency - the number of LLM-generated solution samples required to meet a certain performance threshold. However, in many societal applications, the primary limitation is not generating new solutions but evaluating them. For instance, evaluating an ad's effectiveness requires significant human feedback, which is far more costly and time-consuming than generating a candidate ad. To optimize for the evaluation efficiency objective, a natural approach is to extend Bayesian Optimization (BO), a framework proven optimal for evaluation efficiency, to the language domain. However, the difficulty of directly estimating suitable acquisition functions in LLMs' minds makes this extension challenging. This paper overcomes this challenge by proving that the combination of the simple and widely used Best-of-N selection strategy and simple textual gradients (i.e., textual edits from a critic model) statistically emulates the behavior of the gradients on the canonical UCB acquisition function, which induces optimal exploration in terms of evaluation efficiency. Based on this result, we propose TextGrad-Best-of-N Bayesian Optimization (T-BoN BO), a simple and eval-efficient language-space Bayesian optimization framework for AI self-improvement. We also empirically validate T-BoN BO by applying it to automated ad alignment tasks for persona distribution, demonstrating its superior performance compared to popular state-of-the-art baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86T-BoN BO\u6846\u67b6\uff0c\u5c06\u8d1d\u53f6\u65af\u4f18\u5316\u6269\u5c55\u5230\u8bed\u8a00\u9886\u57df\uff0c\u901a\u8fc7Best-of-N\u9009\u62e9\u548c\u6587\u672c\u68af\u5ea6\u6765\u4f18\u5316\u8bc4\u4f30\u6548\u7387\uff0c\u5728\u5e7f\u544a\u5bf9\u9f50\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u81ea\u6539\u8fdbAI\u4e3b\u8981\u5173\u6ce8\u67e5\u8be2\u6548\u7387\uff0c\u4f46\u5728\u8bb8\u591a\u793e\u4f1a\u5e94\u7528\u4e2d\uff0c\u8bc4\u4f30\u6210\u672c\u8fdc\u9ad8\u4e8e\u751f\u6210\u6210\u672c\uff0c\u9700\u8981\u4f18\u5316\u8bc4\u4f30\u6548\u7387\u3002", "method": "\u7ed3\u5408Best-of-N\u9009\u62e9\u548c\u6587\u672c\u68af\u5ea6\u6765\u6a21\u62dfUCB\u91c7\u96c6\u51fd\u6570\u7684\u68af\u5ea6\u884c\u4e3a\uff0c\u63d0\u51faT-BoN BO\u6846\u67b6\u8fdb\u884c\u8bed\u8a00\u7a7a\u95f4\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u3002", "result": "\u5728\u81ea\u52a8\u5316\u5e7f\u544a\u5bf9\u9f50\u4efb\u52a1\u4e2d\uff0cT-BoN BO\u76f8\u6bd4\u73b0\u6709\u6700\u4f18\u57fa\u7ebf\u8868\u73b0\u51fa\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "T-BoN BO\u4e3aAI\u81ea\u6539\u8fdb\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u4e14\u8bc4\u4f30\u6548\u7387\u9ad8\u7684\u8bed\u8a00\u7a7a\u95f4\u8d1d\u53f6\u65af\u4f18\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u8bc4\u4f30\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002"}}
{"id": "2511.12281", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12281", "abs": "https://arxiv.org/abs/2511.12281", "authors": ["Ivan Zakazov", "Alexander Sharipov", "Berke Argin", "Oussama Gabouj", "Kamel Charaf", "Alexi Semiz", "Lorenzo Drudi", "Nicolas Baldwin", "Robert West"], "title": "Cmprsr: Abstractive Token-Level Question-Agnostic Prompt Compressor", "comment": null, "summary": "Motivated by the high costs of using black-box Large Language Models (LLMs), we introduce a novel prompt compression paradigm, under which we use smaller LLMs to compress inputs for the larger ones. We present the first comprehensive LLM-as-a-compressor benchmark spanning 25 open- and closed-source models, which reveals significant disparity in models' compression ability in terms of (i) preserving semantically important information (ii) following the user-provided compression rate (CR). We further improve the performance of gpt-4.1-mini, the best overall vanilla compressor, with Textgrad-based compression meta-prompt optimization. We also identify the most promising open-source vanilla LLM - Qwen3-4B - and post-train it with a combination of supervised fine-tuning (SFT) and Group Relative Policy Optimization (GRPO), pursuing the dual objective of CR adherence and maximizing the downstream task performance. We call the resulting model Cmprsr and demonstrate its superiority over both extractive and vanilla abstractive compression across the entire range of compression rates on lengthy inputs from MeetingBank and LongBench as well as short prompts from GSM8k. The latter highlights Cmprsr's generalizability across varying input lengths and domains. Moreover, Cmprsr closely follows the requested compression rate, offering fine control over the cost-quality trade-off.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u5c0f\u578bLLM\u538b\u7f29\u5927\u578bLLM\u8f93\u5165\u7684\u65b0\u8303\u5f0f\uff0c\u5f00\u53d1\u4e86Cmprsr\u6a21\u578b\uff0c\u5728\u591a\u79cd\u538b\u7f29\u7387\u548c\u8f93\u5165\u957f\u5ea6\u4e0b\u4f18\u4e8e\u73b0\u6709\u538b\u7f29\u65b9\u6cd5\uff0c\u5e76\u80fd\u7cbe\u786e\u63a7\u5236\u538b\u7f29\u7387\u3002", "motivation": "\u964d\u4f4e\u4f7f\u7528\u9ed1\u76d2\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6210\u672c\uff0c\u901a\u8fc7\u538b\u7f29\u8f93\u5165\u6765\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "method": "\u4f7f\u7528\u5c0f\u578bLLM\u538b\u7f29\u5927\u578bLLM\u8f93\u5165\uff1b\u901a\u8fc7Textgrad\u4f18\u5316\u538b\u7f29\u5143\u63d0\u793a\uff1b\u5bf9Qwen3-4B\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\u548cGRPO\u8bad\u7ec3\uff0c\u8ffd\u6c42\u538b\u7f29\u7387\u9075\u4ece\u548c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u6700\u5927\u5316\u3002", "result": "Cmprsr\u5728MeetingBank\u3001LongBench\u548cGSM8k\u6570\u636e\u96c6\u4e0a\uff0c\u5728\u6574\u4e2a\u538b\u7f29\u7387\u8303\u56f4\u5185\u4f18\u4e8e\u63d0\u53d6\u5f0f\u548c\u666e\u901a\u62bd\u8c61\u538b\u7f29\u65b9\u6cd5\uff0c\u5e76\u80fd\u7d27\u5bc6\u9075\u5faa\u8bf7\u6c42\u7684\u538b\u7f29\u7387\u3002", "conclusion": "Cmprsr\u6a21\u578b\u5728\u538b\u7f29\u6027\u80fd\u548c\u538b\u7f29\u7387\u63a7\u5236\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5177\u6709\u8de8\u4e0d\u540c\u8f93\u5165\u957f\u5ea6\u548c\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u6210\u672c-\u8d28\u91cf\u6743\u8861\u63d0\u4f9b\u4e86\u7cbe\u7ec6\u63a7\u5236\u3002"}}
{"id": "2511.12083", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12083", "abs": "https://arxiv.org/abs/2511.12083", "authors": ["Yanchang Fu", "Shengda Liu", "Pei Xu", "Kaiqi Huang"], "title": "No-Regret Strategy Solving in Imperfect-Information Games via Pre-Trained Embedding", "comment": null, "summary": "High-quality information set abstraction remains a core challenge in solving large-scale imperfect-information extensive-form games (IIEFGs)-such as no-limit Texas Hold'em-where the finite nature of spatial resources hinders strategy solving over the full game. State-of-the-art AI methods rely on pre-trained discrete clustering for abstraction, yet their hard classification irreversibly loses critical information: specifically, the quantifiable subtle differences between information sets-vital for strategy solving-thereby compromising the quality of such solving. Inspired by the word embedding paradigm in natural language processing, this paper proposes the Embedding CFR algorithm, a novel approach for solving strategies in IIEFGs within an embedding space. The algorithm pre-trains and embeds features of isolated information sets into an interconnected low-dimensional continuous space, where the resulting vectors more precisely capture both the distinctions and connections between information sets. Embedding CFR presents a strategy-solving process driven by regret accumulation and strategy updates within this embedding space, with accompanying theoretical analysis verifying its capacity to reduce cumulative regret. Experiments on poker show that with the same spatial overhead, Embedding CFR achieves significantly faster exploitability convergence compared to cluster-based abstraction algorithms, confirming its effectiveness. Furthermore, to our knowledge, it is the first algorithm in poker AI that pre-trains information set abstractions through low-dimensional embedding for strategy solving.", "AI": {"tldr": "\u63d0\u51fa\u4e86Embedding CFR\u7b97\u6cd5\uff0c\u901a\u8fc7\u5c06\u4fe1\u606f\u96c6\u5d4c\u5165\u5230\u4f4e\u7ef4\u8fde\u7eed\u7a7a\u95f4\u6765\u89e3\u51b3\u5927\u89c4\u6a21\u4e0d\u5b8c\u5168\u4fe1\u606f\u6269\u5c55\u5f0f\u535a\u5f08\uff0c\u76f8\u6bd4\u4f20\u7edf\u805a\u7c7b\u65b9\u6cd5\u80fd\u66f4\u7cbe\u786e\u6355\u6349\u4fe1\u606f\u96c6\u95f4\u7684\u5dee\u5f02\u548c\u8054\u7cfb\uff0c\u5728\u6251\u514b\u5b9e\u9a8c\u4e2d\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u53ef\u5265\u524a\u6027\u6536\u655b\u3002", "motivation": "\u73b0\u6709AI\u65b9\u6cd5\u4f9d\u8d56\u9884\u8bad\u7ec3\u7684\u79bb\u6563\u805a\u7c7b\u8fdb\u884c\u62bd\u8c61\uff0c\u4f46\u786c\u5206\u7c7b\u4f1a\u4e0d\u53ef\u9006\u5730\u4e22\u5931\u4fe1\u606f\u96c6\u4e4b\u95f4\u7684\u91cf\u5316\u7ec6\u5fae\u5dee\u5f02\uff0c\u8fd9\u4e9b\u5dee\u5f02\u5bf9\u7b56\u7565\u6c42\u89e3\u81f3\u5173\u91cd\u8981\uff0c\u4ece\u800c\u5f71\u54cd\u6c42\u89e3\u8d28\u91cf\u3002", "method": "\u53d7\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u8bcd\u5d4c\u5165\u8303\u5f0f\u7684\u542f\u53d1\uff0c\u63d0\u51faEmbedding CFR\u7b97\u6cd5\uff1a\u9884\u8bad\u7ec3\u5e76\u5c06\u5b64\u7acb\u4fe1\u606f\u96c6\u7684\u7279\u5f81\u5d4c\u5165\u5230\u76f8\u4e92\u8fde\u63a5\u7684\u4f4e\u7ef4\u8fde\u7eed\u7a7a\u95f4\uff0c\u5728\u8be5\u5d4c\u5165\u7a7a\u95f4\u4e2d\u8fdb\u884c\u9057\u61be\u7d2f\u79ef\u548c\u7b56\u7565\u66f4\u65b0\u7684\u7b56\u7565\u6c42\u89e3\u8fc7\u7a0b\u3002", "result": "\u5728\u6251\u514b\u5b9e\u9a8c\u4e2d\uff0c\u5728\u76f8\u540c\u7a7a\u95f4\u5f00\u9500\u4e0b\uff0cEmbedding CFR\u76f8\u6bd4\u57fa\u4e8e\u805a\u7c7b\u7684\u62bd\u8c61\u7b97\u6cd5\u5b9e\u73b0\u4e86\u663e\u8457\u66f4\u5feb\u7684\u53ef\u5265\u524a\u6027\u6536\u655b\uff0c\u8bc1\u5b9e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u8fd9\u662f\u6251\u514bAI\u4e2d\u9996\u4e2a\u901a\u8fc7\u4f4e\u7ef4\u5d4c\u5165\u9884\u8bad\u7ec3\u4fe1\u606f\u96c6\u62bd\u8c61\u6765\u8fdb\u884c\u7b56\u7565\u6c42\u89e3\u7684\u7b97\u6cd5\uff0c\u7406\u8bba\u5206\u6790\u9a8c\u8bc1\u4e86\u5176\u51cf\u5c11\u7d2f\u79ef\u9057\u61be\u7684\u80fd\u529b\u3002"}}
{"id": "2511.12290", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12290", "abs": "https://arxiv.org/abs/2511.12290", "authors": ["Purnima Bindal", "Vikas Kumar", "Sagar Rathore", "Vasudha Bhatnagar"], "title": "AugAbEx : Way Forward for Extractive Case Summarization", "comment": "30 pages, under review in a Journal", "summary": "Summarization of legal judgments poses a heavy cognitive burden on law practitioners due to the complexity of the language, context-sensitive legal jargon, and the length of the document. Therefore, the automatic summarization of legal documents has attracted serious attention from natural language processing researchers. Since the abstractive summaries of legal documents generated by deep neural methods remain prone to the risk of misrepresenting nuanced legal jargon or overlooking key contextual details, we envisage a rising trend toward the use of extractive case summarizers.\n  Given the high cost of human annotation for gold standard extractive summaries, we engineer a light and transparent pipeline that leverages existing abstractive gold standard summaries to create the corresponding extractive gold standard versions. The approach ensures that the experts` opinions ensconced in the original gold standard abstractive summaries are carried over to the transformed extractive summaries. We aim to augment seven existing case summarization datasets, which include abstractive summaries, by incorporating corresponding extractive summaries and create an enriched data resource for case summarization research community. To ensure the quality of the augmented extractive summaries, we perform an extensive comparative evaluation with the original abstractive gold standard summaries covering structural, lexical, and semantic dimensions. We also compare the domain-level information of the two summaries. We commit to release the augmented datasets in the public domain for use by the research community and believe that the resource will offer opportunities to advance the field of automatic summarization of legal documents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u73b0\u6709\u62bd\u8c61\u6458\u8981\u751f\u6210\u5bf9\u5e94\u63d0\u53d6\u5f0f\u6458\u8981\u7684\u8f7b\u91cf\u7ea7\u65b9\u6cd5\uff0c\u65e8\u5728\u4e3a\u6cd5\u5f8b\u6848\u4f8b\u6458\u8981\u7814\u7a76\u793e\u533a\u521b\u5efa\u589e\u5f3a\u7684\u6570\u636e\u8d44\u6e90\u3002", "motivation": "\u6cd5\u5f8b\u5224\u51b3\u6458\u8981\u5bf9\u6cd5\u5f8b\u4ece\u4e1a\u8005\u6784\u6210\u6c89\u91cd\u8ba4\u77e5\u8d1f\u62c5\uff0c\u800c\u6df1\u5ea6\u795e\u7ecf\u65b9\u6cd5\u751f\u6210\u7684\u62bd\u8c61\u6458\u8981\u5bb9\u6613\u8bef\u5224\u6cd5\u5f8b\u672f\u8bed\u6216\u5ffd\u7565\u5173\u952e\u7ec6\u8282\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u53d6\u5f0f\u6458\u8981\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u8f7b\u91cf\u900f\u660e\u7684\u6d41\u7a0b\uff0c\u5229\u7528\u73b0\u6709\u7684\u62bd\u8c61\u6807\u51c6\u6458\u8981\u751f\u6210\u5bf9\u5e94\u7684\u63d0\u53d6\u5f0f\u6807\u51c6\u6458\u8981\u7248\u672c\uff0c\u786e\u4fdd\u4e13\u5bb6\u610f\u89c1\u4ece\u539f\u59cb\u62bd\u8c61\u6458\u8981\u4f20\u9012\u5230\u8f6c\u6362\u540e\u7684\u63d0\u53d6\u5f0f\u6458\u8981\u4e2d\u3002", "result": "\u8ba1\u5212\u589e\u5f3a\u4e03\u4e2a\u73b0\u6709\u6848\u4f8b\u6458\u8981\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u6dfb\u52a0\u5bf9\u5e94\u7684\u63d0\u53d6\u5f0f\u6458\u8981\u6765\u521b\u5efa\u4e30\u5bcc\u7684\u6570\u636e\u8d44\u6e90\uff0c\u5e76\u8fdb\u884c\u7ed3\u6784\u3001\u8bcd\u6c47\u548c\u8bed\u4e49\u7ef4\u5ea6\u7684\u5e7f\u6cdb\u6bd4\u8f83\u8bc4\u4f30\u3002", "conclusion": "\u627f\u8bfa\u516c\u5f00\u53d1\u5e03\u589e\u5f3a\u7684\u6570\u636e\u96c6\uff0c\u76f8\u4fe1\u8be5\u8d44\u6e90\u5c06\u63a8\u52a8\u6cd5\u5f8b\u6587\u6863\u81ea\u52a8\u6458\u8981\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.12089", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.12089", "abs": "https://arxiv.org/abs/2511.12089", "authors": ["Yanchang Fu", "Qiyue Yin", "Shengda Liu", "Pei Xu", "Kaiqi Huang"], "title": "KrwEmd: Revising the Imperfect-Recall Abstraction from Forgetting Everything", "comment": null, "summary": "Excessive abstraction is a critical challenge in hand abstraction-a task specific to games like Texas hold'em-when solving large-scale imperfect-information games, as it impairs AI performance. This issue arises from extreme implementations of imperfect-recall abstraction, which entirely discard historical information. This paper presents KrwEmd, the first practical algorithm designed to address this problem. We first introduce the k-recall winrate feature, which not only qualitatively distinguishes signal observation infosets by leveraging both future and, crucially, historical game information, but also quantitatively captures their similarity. We then develop the KrwEmd algorithm, which clusters signal observation infosets using earth mover's distance to measure discrepancies between their features. Experimental results demonstrate that KrwEmd significantly improves AI gameplay performance compared to existing algorithms.", "AI": {"tldr": "KrwEmd\u7b97\u6cd5\u901a\u8fc7k-recall winrate\u7279\u5f81\u548cearth mover's distance\u805a\u7c7b\uff0c\u89e3\u51b3\u4e86\u5fb7\u5dde\u6251\u514b\u7b49\u6e38\u620f\u4e2d\u56e0\u8fc7\u5ea6\u62bd\u8c61\u5bfc\u81f4AI\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u4e0d\u5b8c\u5168\u4fe1\u606f\u6e38\u620f\u4e2d\u56e0\u6781\u7aef\u4e0d\u5b8c\u7f8e\u56de\u5fc6\u62bd\u8c61\u5bfc\u81f4\u7684\u8fc7\u5ea6\u62bd\u8c61\u95ee\u9898\uff0c\u8fd9\u79cd\u62bd\u8c61\u5b8c\u5168\u4e22\u5f03\u5386\u53f2\u4fe1\u606f\uff0c\u635f\u5bb3AI\u6027\u80fd\u3002", "method": "\u5f15\u5165k-recall winrate\u7279\u5f81\uff0c\u5229\u7528\u672a\u6765\u548c\u5173\u952e\u7684\u5386\u53f2\u6e38\u620f\u4fe1\u606f\u6765\u533a\u5206\u4fe1\u53f7\u89c2\u5bdf\u4fe1\u606f\u96c6\uff1b\u5f00\u53d1KrwEmd\u7b97\u6cd5\uff0c\u4f7f\u7528earth mover's distance\u6d4b\u91cf\u7279\u5f81\u5dee\u5f02\u6765\u805a\u7c7b\u4fe1\u53f7\u89c2\u5bdf\u4fe1\u606f\u96c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u7b97\u6cd5\u76f8\u6bd4\uff0cKrwEmd\u663e\u8457\u63d0\u9ad8\u4e86AI\u6e38\u620f\u6027\u80fd\u3002", "conclusion": "KrwEmd\u662f\u7b2c\u4e00\u4e2a\u5b9e\u7528\u7684\u89e3\u51b3\u8fc7\u5ea6\u62bd\u8c61\u95ee\u9898\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u5386\u53f2\u548c\u672a\u6765\u4fe1\u606f\u6709\u6548\u63d0\u5347\u4e86\u4e0d\u5b8c\u5168\u4fe1\u606f\u6e38\u620f\u4e2dAI\u7684\u8868\u73b0\u3002"}}
{"id": "2511.12300", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12300", "abs": "https://arxiv.org/abs/2511.12300", "authors": ["Naoya Sugiura", "Kosuke Yamada", "Yasuhiro Ogawa", "Katsuhiko Toyama", "Ryohei Sasano"], "title": "Do LLMs and Humans Find the Same Questions Difficult? A Case Study on Japanese Quiz Answering", "comment": null, "summary": "LLMs have achieved performance that surpasses humans in many NLP tasks. However, it remains unclear whether problems that are difficult for humans are also difficult for LLMs. This study investigates how the difficulty of quizzes in a buzzer setting differs between LLMs and humans. Specifically, we first collect Japanese quiz data including questions, answers, and correct response rate of humans, then prompted LLMs to answer the quizzes under several settings, and compare their correct answer rate to that of humans from two analytical perspectives. The experimental results showed that, compared to humans, LLMs struggle more with quizzes whose correct answers are not covered by Wikipedia entries, and also have difficulty with questions that require numerical answers.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86LLMs\u548c\u4eba\u7c7b\u5728\u62a2\u7b54\u5f0f\u95ee\u7b54\u4e2d\u7684\u8868\u73b0\u5dee\u5f02\uff0c\u53d1\u73b0LLMs\u5728\u7ef4\u57fa\u767e\u79d1\u672a\u8986\u76d6\u7684\u95ee\u9898\u548c\u9700\u8981\u6570\u503c\u7b54\u6848\u7684\u95ee\u9898\u4e0a\u8868\u73b0\u8f83\u5dee", "motivation": "\u63a2\u7a76\u5bf9\u4eba\u7c7b\u56f0\u96be\u7684\u95ee\u9898\u662f\u5426\u5bf9LLMs\u540c\u6837\u56f0\u96be\uff0c\u6bd4\u8f83LLMs\u548c\u4eba\u7c7b\u5728\u62a2\u7b54\u5f0f\u95ee\u7b54\u4e2d\u7684\u8868\u73b0\u5dee\u5f02", "method": "\u6536\u96c6\u65e5\u672c\u95ee\u7b54\u6570\u636e\uff08\u5305\u542b\u95ee\u9898\u3001\u7b54\u6848\u548c\u4eba\u7c7b\u6b63\u786e\u7387\uff09\uff0c\u5728\u591a\u79cd\u8bbe\u7f6e\u4e0b\u8ba9LLMs\u56de\u7b54\u95ee\u9898\uff0c\u4ece\u4e24\u4e2a\u5206\u6790\u89c6\u89d2\u6bd4\u8f83LLMs\u4e0e\u4eba\u7c7b\u7684\u6b63\u786e\u7387", "result": "\u76f8\u6bd4\u4eba\u7c7b\uff0cLLMs\u5728\u7ef4\u57fa\u767e\u79d1\u672a\u8986\u76d6\u7b54\u6848\u7684\u95ee\u9898\u4e0a\u8868\u73b0\u66f4\u5dee\uff0c\u5728\u9700\u8981\u6570\u503c\u7b54\u6848\u7684\u95ee\u9898\u4e0a\u4e5f\u5b58\u5728\u56f0\u96be", "conclusion": "LLMs\u4e0e\u4eba\u7c7b\u5728\u95ee\u9898\u96be\u5ea6\u4e0a\u5b58\u5728\u5dee\u5f02\uff0cLLMs\u5728\u7279\u5b9a\u7c7b\u578b\u95ee\u9898\u4e0a\u8868\u73b0\u4e0d\u5982\u4eba\u7c7b"}}
{"id": "2511.12113", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12113", "abs": "https://arxiv.org/abs/2511.12113", "authors": ["Lanxue Zhang", "Yuqiang Xie", "Fang Fang", "Fanglong Dong", "Rui Liu", "Yanan Cao"], "title": "MetaGDPO: Alleviating Catastrophic Forgetting with Metacognitive Knowledge through Group Direct Preference Optimization", "comment": "23 pages, 10 figures, AAAI 2026", "summary": "Large Language Models demonstrate strong reasoning capabilities, which can be effectively compressed into smaller models. However, existing datasets and fine-tuning approaches still face challenges that lead to catastrophic forgetting, particularly for models smaller than 8B. First, most datasets typically ignore the relationship between training data knowledge and the model's inherent abilities, making it difficult to preserve prior knowledge. Second, conventional training objectives often fail to constrain inherent knowledge preservation, which can result in forgetting of previously learned skills. To address these issues, we propose a comprehensive solution that alleviates catastrophic forgetting from both the data and fine-tuning approach perspectives. On the data side, we construct a dataset of 5K instances that covers multiple reasoning tasks and incorporates metacognitive knowledge, making it more tolerant and effective for distillation into smaller models. We annotate the metacognitive knowledge required to solve each question and filter the data based on task knowledge and the model's inherent skills. On the training side, we introduce GDPO (Group Direction Preference Optimization), which is better suited for resource-limited scenarios and can efficiently approximate the performance of GRPO. Guided by the large model and by implicitly constraining the optimization path through a reference model, GDPO enables more effective knowledge transfer from the large model and constrains excessive parameter drift. Extensive experiments demonstrate that our approach significantly alleviates catastrophic forgetting and improves reasoning performance on smaller models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u5c0f\u6a21\u578b\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u7684\u7efc\u5408\u65b9\u6848\uff0c\u5305\u62ec\u6784\u5efa\u5305\u542b\u5143\u8ba4\u77e5\u77e5\u8bc6\u76845K\u6570\u636e\u96c6\u548cGDPO\u8bad\u7ec3\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u5c0f\u6a21\u578b\u63a8\u7406\u6027\u80fd", "motivation": "\u73b0\u6709\u6570\u636e\u96c6\u548c\u5fae\u8c03\u65b9\u6cd5\u5bfc\u81f4\u5c0f\u6a21\u578b\uff08\u5c0f\u4e8e8B\uff09\u51fa\u73b0\u707e\u96be\u6027\u9057\u5fd8\uff0c\u4e3b\u8981\u95ee\u9898\u662f\u5ffd\u89c6\u8bad\u7ec3\u6570\u636e\u77e5\u8bc6\u4e0e\u6a21\u578b\u56fa\u6709\u80fd\u529b\u7684\u5173\u7cfb\uff0c\u4ee5\u53ca\u4f20\u7edf\u8bad\u7ec3\u76ee\u6807\u65e0\u6cd5\u7ea6\u675f\u56fa\u6709\u77e5\u8bc6\u4fdd\u7559", "method": "1) \u6784\u5efa\u5305\u542b\u5143\u8ba4\u77e5\u77e5\u8bc6\u6807\u6ce8\u76845K\u591a\u4efb\u52a1\u63a8\u7406\u6570\u636e\u96c6\uff1b2) \u63d0\u51faGDPO\uff08Group Direction Preference Optimization\uff09\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u53c2\u8003\u6a21\u578b\u9690\u5f0f\u7ea6\u675f\u4f18\u5316\u8def\u5f84", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u7f13\u89e3\u4e86\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u5c0f\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd", "conclusion": "\u8be5\u7efc\u5408\u65b9\u6848\u4ece\u6570\u636e\u548c\u8bad\u7ec3\u65b9\u6cd5\u4e24\u65b9\u9762\u6709\u6548\u89e3\u51b3\u4e86\u5c0f\u6a21\u578b\u7684\u77e5\u8bc6\u84b8\u998f\u95ee\u9898\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u573a\u666f\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2511.12381", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12381", "abs": "https://arxiv.org/abs/2511.12381", "authors": ["Logan Mann", "Nayan Saxena", "Sarah Tandon", "Chenhao Sun", "Savar Toteja", "Kevin Zhu"], "title": "Don't Think of the White Bear: Ironic Negation in Transformer Models Under Cognitive Load", "comment": null, "summary": "Negation instructions such as 'do not mention $X$' can paradoxically increase the accessibility of $X$ in human thought, a phenomenon known as ironic rebound. Large language models (LLMs) face the same challenge: suppressing a concept requires internally activating it, which may prime rebound instead of avoidance. We investigated this tension with two experiments. \\textbf{(1) Load \\& content}: after a negation instruction, we vary distractor text (semantic, syntactic, repetition) and measure rebound strength. \\textbf{(2) Polarity separation}: We test whether models distinguish neutral from negative framings of the same concept and whether this separation predicts rebound persistence. Results show that rebound consistently arises immediately after negation and intensifies with longer or semantic distractors, while repetition supports suppression. Stronger polarity separation correlates with more persistent rebound. Together, these findings, complemented by a circuit tracing analysis that identifies sparse middle-layer attention heads amplifying forbidden tokens while early layers suppress, link cognitive predictions of ironic rebound with mechanistic insights into long-context interference. To support future work, we release ReboundBench, a dataset of $5,000$ systematically varied negation prompts designed to probe rebound in LLMs.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5426\u5b9a\u6307\u4ee4\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5f15\u53d1\u7684\u8bbd\u523a\u6027\u53cd\u5f39\u73b0\u8c61\uff0c\u53d1\u73b0\u5426\u5b9a\u53cd\u800c\u4f1a\u589e\u52a0\u88ab\u7981\u6b62\u6982\u5ff5\u7684\u53ef\u53ca\u6027\uff0c\u8fd9\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u4e2d\u7684\u8bbd\u523a\u53cd\u5f39\u73b0\u8c61\u76f8\u4f3c\u3002", "motivation": "\u5426\u5b9a\u6307\u4ee4\u5982'\u4e0d\u8981\u63d0\u53caX'\u5728\u4eba\u7c7b\u8ba4\u77e5\u4e2d\u4f1a\u5f15\u53d1\u8bbd\u523a\u53cd\u5f39\uff0c\u5373\u88ab\u7981\u6b62\u7684\u6982\u5ff5\u53cd\u800c\u66f4\u5bb9\u6613\u88ab\u6fc0\u6d3b\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u4e5f\u5b58\u5728\u7c7b\u4f3c\u73b0\u8c61\uff0c\u4ee5\u53ca\u5f71\u54cd\u53cd\u5f39\u5f3a\u5ea6\u7684\u56e0\u7d20\u3002", "method": "\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9a8c\uff1a(1) \u5728\u5426\u5b9a\u6307\u4ee4\u540e\u5f15\u5165\u4e0d\u540c\u7c7b\u578b\u7684\u5e72\u6270\u6587\u672c\uff08\u8bed\u4e49\u3001\u53e5\u6cd5\u3001\u91cd\u590d\uff09\uff0c\u6d4b\u91cf\u53cd\u5f39\u5f3a\u5ea6\uff1b(2) \u6d4b\u8bd5\u6a21\u578b\u662f\u5426\u80fd\u533a\u5206\u540c\u4e00\u6982\u5ff5\u7684\u4e2d\u6027\u548c\u8d1f\u9762\u8868\u8ff0\uff0c\u4ee5\u53ca\u8fd9\u79cd\u533a\u5206\u662f\u5426\u9884\u6d4b\u53cd\u5f39\u7684\u6301\u7eed\u6027\u3002\u540c\u65f6\u8fdb\u884c\u7535\u8def\u8ffd\u8e2a\u5206\u6790\uff0c\u8bc6\u522b\u8d1f\u8d23\u653e\u5927\u88ab\u7981\u6b62\u6807\u8bb0\u7684\u6ce8\u610f\u529b\u5934\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5426\u5b9a\u540e\u7acb\u5373\u51fa\u73b0\u53cd\u5f39\uff0c\u4e14\u968f\u7740\u5e72\u6270\u6587\u672c\u957f\u5ea6\u6216\u8bed\u4e49\u76f8\u5173\u6027\u7684\u589e\u52a0\u800c\u589e\u5f3a\uff0c\u800c\u91cd\u590d\u5e72\u6270\u6709\u52a9\u4e8e\u6291\u5236\u3002\u66f4\u5f3a\u7684\u6781\u6027\u533a\u5206\u4e0e\u66f4\u6301\u4e45\u7684\u53cd\u5f39\u76f8\u5173\u3002\u7535\u8def\u5206\u6790\u53d1\u73b0\u4e2d\u95f4\u5c42\u7a00\u758f\u6ce8\u610f\u529b\u5934\u653e\u5927\u88ab\u7981\u6b62\u6807\u8bb0\uff0c\u800c\u65e9\u671f\u5c42\u8fdb\u884c\u6291\u5236\u3002", "conclusion": "\u7814\u7a76\u5c06\u8ba4\u77e5\u79d1\u5b66\u4e2d\u7684\u8bbd\u523a\u53cd\u5f39\u9884\u6d4b\u4e0e\u957f\u4e0a\u4e0b\u6587\u5e72\u6270\u7684\u673a\u5236\u6027\u7406\u89e3\u8054\u7cfb\u8d77\u6765\uff0c\u5e76\u53d1\u5e03\u4e86ReboundBench\u6570\u636e\u96c6\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2511.12135", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12135", "abs": "https://arxiv.org/abs/2511.12135", "authors": ["Letian Chen", "Runhan Shi", "Gufeng Yu", "Yang Yang"], "title": "RTMol: Rethinking Molecule-text Alignment in a Round-trip View", "comment": null, "summary": "Aligning molecular sequence representations (e.g., SMILES notations) with textual descriptions is critical for applications spanning drug discovery, materials design, and automated chemical literature analysis. Existing methodologies typically treat molecular captioning (molecule-to-text) and text-based molecular design (text-to-molecule) as separate tasks, relying on supervised fine-tuning or contrastive learning pipelines. These approaches face three key limitations: (i) conventional metrics like BLEU prioritize linguistic fluency over chemical accuracy, (ii) training datasets frequently contain chemically ambiguous narratives with incomplete specifications, and (iii) independent optimization of generation directions leads to bidirectional inconsistency. To address these issues, we propose RTMol, a bidirectional alignment framework that unifies molecular captioning and text-to-SMILES generation through self-supervised round-trip learning. The framework introduces novel round-trip evaluation metrics and enables unsupervised training for molecular captioning without requiring paired molecule-text corpora. Experiments demonstrate that RTMol enhances bidirectional alignment performance by up to 47% across various LLMs, establishing an effective paradigm for joint molecule-text understanding and generation.", "AI": {"tldr": "RTMol\u662f\u4e00\u4e2a\u53cc\u5411\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u7684\u5f80\u8fd4\u5b66\u4e60\u7edf\u4e00\u5206\u5b50\u6807\u6ce8\u548c\u6587\u672c\u5230SMILES\u751f\u6210\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5316\u5b66\u51c6\u786e\u6027\u3001\u6570\u636e\u8d28\u91cf\u548c\u53cc\u5411\u4e00\u81f4\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u5206\u5b50\u6807\u6ce8\u548c\u6587\u672c\u5230\u5206\u5b50\u8bbe\u8ba1\u89c6\u4e3a\u72ec\u7acb\u4efb\u52a1\uff0c\u9762\u4e34\u4e09\u4e2a\u5173\u952e\u9650\u5236\uff1a\u4f20\u7edf\u6307\u6807\u504f\u91cd\u8bed\u8a00\u6d41\u7545\u6027\u800c\u975e\u5316\u5b66\u51c6\u786e\u6027\u3001\u8bad\u7ec3\u6570\u636e\u5305\u542b\u5316\u5b66\u6a21\u7cca\u63cf\u8ff0\u3001\u72ec\u7acb\u4f18\u5316\u5bfc\u81f4\u53cc\u5411\u4e0d\u4e00\u81f4\u3002", "method": "\u63d0\u51faRTMol\u53cc\u5411\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u5f80\u8fd4\u5b66\u4e60\u7edf\u4e00\u5206\u5b50\u6807\u6ce8\u548c\u6587\u672c\u5230SMILES\u751f\u6210\uff0c\u5f15\u5165\u65b0\u9896\u7684\u5f80\u8fd4\u8bc4\u4f30\u6307\u6807\uff0c\u652f\u6301\u65e0\u9700\u914d\u5bf9\u5206\u5b50-\u6587\u672c\u8bed\u6599\u7684\u65e0\u76d1\u7763\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8868\u660eRTMol\u5728\u5404\u79cdLLMs\u4e0a\u5c06\u53cc\u5411\u5bf9\u9f50\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe47%\uff0c\u4e3a\u8054\u5408\u5206\u5b50-\u6587\u672c\u7406\u89e3\u548c\u751f\u6210\u5efa\u7acb\u4e86\u6709\u6548\u8303\u5f0f\u3002", "conclusion": "RTMol\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5206\u5b50\u5e8f\u5217\u8868\u793a\u4e0e\u6587\u672c\u63cf\u8ff0\u5bf9\u9f50\u7684\u5173\u952e\u95ee\u9898\uff0c\u5728\u836f\u7269\u53d1\u73b0\u3001\u6750\u6599\u8bbe\u8ba1\u548c\u5316\u5b66\u6587\u732e\u5206\u6790\u7b49\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2511.12387", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12387", "abs": "https://arxiv.org/abs/2511.12387", "authors": ["Jeyarajalingam Varsha", "Menan Velayuthan", "Sumirtha Karunakaran", "Rasan Nivethiga", "Kengatharaiyer Sarveswaran"], "title": "From Phonemes to Meaning: Evaluating Large Language Models on Tamil", "comment": "11 pages", "summary": "Large Language Models (LLMs) have shown strong generalization across tasks in high-resource languages; however, their linguistic competence in low-resource and morphologically rich languages such as Tamil remains largely unexplored. Existing multilingual benchmarks often rely on translated English datasets, failing to capture the linguistic and cultural nuances of the target language. To address this gap, we introduce ILAKKANAM, the first Tamil-specific linguistic evaluation benchmark manually curated using 820 questions from Sri Lankan school-level Tamil subject examination papers. Each question is annotated by trained linguists under five linguistic categories and a factual knowledge category, spanning Grades 1--13 to ensure broad linguistic coverage. We evaluate both closed-source and open-source LLMs using a standardized evaluation framework. Our results show that Gemini 2.5 achieves the highest overall performance, while open-source models lag behind, highlighting the gap in linguistic grounding. Category- and grade-wise analyses reveal that all models perform well on lower-grade questions but show a clear decline as linguistic complexity increases. Further, no strong correlation is observed between a model's overall performance and its ability to identify linguistic categories, suggesting that performance may be driven by exposure rather than genuine understanding.", "AI": {"tldr": "ILAKKANAM\u662f\u9996\u4e2a\u6cf0\u7c73\u5c14\u8bed\u4e13\u7528\u8bed\u8a00\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b820\u9053\u6765\u81ea\u65af\u91cc\u5170\u5361\u5b66\u6821\u8003\u8bd5\u7684\u95ee\u9898\uff0c\u8bc4\u4f30\u663e\u793aLLMs\u5728\u6cf0\u7c73\u5c14\u8bed\u8bed\u8a00\u80fd\u529b\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u968f\u7740\u8bed\u8a00\u590d\u6742\u6027\u589e\u52a0\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u73b0\u6709\u591a\u8bed\u8a00\u57fa\u51c6\u4e3b\u8981\u4f9d\u8d56\u82f1\u8bed\u7ffb\u8bd1\u6570\u636e\u96c6\uff0c\u65e0\u6cd5\u6355\u6349\u6cf0\u7c73\u5c14\u8bed\u7b49\u4f4e\u8d44\u6e90\u3001\u5f62\u6001\u4e30\u5bcc\u8bed\u8a00\u7684\u8bed\u8a00\u548c\u6587\u5316\u7ec6\u5fae\u5dee\u522b\uff0c\u9700\u8981\u4e13\u95e8\u8bc4\u4f30LLMs\u5728\u6cf0\u7c73\u5c14\u8bed\u4e2d\u7684\u8bed\u8a00\u80fd\u529b\u3002", "method": "\u4f7f\u7528820\u9053\u65af\u91cc\u5170\u5361\u5b66\u6821\u6cf0\u7c73\u5c14\u8bed\u8003\u8bd5\u95ee\u9898\u6784\u5efa\u57fa\u51c6\uff0c\u7531\u8bad\u7ec3\u6709\u7d20\u7684\u8bed\u8a00\u5b66\u5bb6\u6309\u7167\u4e94\u4e2a\u8bed\u8a00\u7c7b\u522b\u548c\u4e00\u4e2a\u4e8b\u5b9e\u77e5\u8bc6\u7c7b\u522b\u8fdb\u884c\u6807\u6ce8\uff0c\u6db5\u76d61-13\u5e74\u7ea7\u4ee5\u786e\u4fdd\u5e7f\u6cdb\u7684\u8bed\u8a00\u8986\u76d6\u3002", "result": "Gemini 2.5\u8868\u73b0\u6700\u4f73\uff0c\u5f00\u6e90\u6a21\u578b\u843d\u540e\uff1b\u6240\u6709\u6a21\u578b\u5728\u4f4e\u5e74\u7ea7\u95ee\u9898\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u968f\u7740\u8bed\u8a00\u590d\u6742\u6027\u589e\u52a0\u6027\u80fd\u660e\u663e\u4e0b\u964d\uff1b\u6a21\u578b\u6574\u4f53\u6027\u80fd\u4e0e\u8bc6\u522b\u8bed\u8a00\u7c7b\u522b\u80fd\u529b\u4e4b\u95f4\u65e0\u5f3a\u76f8\u5173\u6027\u3002", "conclusion": "LLMs\u5728\u6cf0\u7c73\u5c14\u8bed\u4e2d\u7684\u8868\u73b0\u53ef\u80fd\u66f4\u591a\u57fa\u4e8e\u66dd\u5149\u800c\u975e\u771f\u6b63\u7406\u89e3\uff0c\u9700\u8981\u6539\u8fdb\u5bf9\u4f4e\u8d44\u6e90\u3001\u5f62\u6001\u4e30\u5bcc\u8bed\u8a00\u7684\u8bed\u8a00\u57fa\u7840\u80fd\u529b\u3002"}}
{"id": "2511.12169", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12169", "abs": "https://arxiv.org/abs/2511.12169", "authors": ["Kaiyue Zhao", "Dingqi Chen", "Shaoyu Wang", "Pan Hu"], "title": "Incremental Maintenance of DatalogMTL Materialisations", "comment": "Accepted as oral paper at the main track of AAAI 2026", "summary": "DatalogMTL extends the classical Datalog language with metric temporal logic (MTL), enabling expressive reasoning over temporal data. While existing reasoning approaches, such as materialisation based and automata based methods, offer soundness and completeness, they lack support for handling efficient dynamic updates, a crucial requirement for real-world applications that involve frequent data updates. In this work, we propose DRedMTL, an incremental reasoning algorithm for DatalogMTL with bounded intervals. Our algorithm builds upon the classical DRed algorithm, which incrementally updates the materialisation of a Datalog program. Unlike a Datalog materialisation which is in essence a finite set of facts, a DatalogMTL materialisation has to be represented as a finite set of facts plus periodic intervals indicating how the full materialisation can be constructed through unfolding. To cope with this, our algorithm is equipped with specifically designed operators to efficiently handle such periodic representations of DatalogMTL materialisations. We have implemented this approach and tested it on several publicly available datasets. Experimental results show that DRedMTL often significantly outperforms rematerialisation, sometimes by orders of magnitude.", "AI": {"tldr": "\u63d0\u51fa\u4e86DRedMTL\u7b97\u6cd5\uff0c\u4e00\u79cd\u652f\u6301\u6709\u754c\u533a\u95f4\u7684DatalogMTL\u589e\u91cf\u63a8\u7406\u65b9\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u91cd\u65b0\u7269\u5316\u65b9\u6cd5", "motivation": "\u73b0\u6709DatalogMTL\u63a8\u7406\u65b9\u6cd5\u4e0d\u652f\u6301\u9ad8\u6548\u52a8\u6001\u66f4\u65b0\uff0c\u800c\u73b0\u5b9e\u5e94\u7528\u9700\u8981\u9891\u7e41\u6570\u636e\u66f4\u65b0", "method": "\u57fa\u4e8e\u7ecf\u5178DRed\u7b97\u6cd5\uff0c\u8bbe\u8ba1\u4e13\u95e8\u64cd\u4f5c\u7b26\u5904\u7406DatalogMTL\u7269\u5316\u7684\u5468\u671f\u6027\u8868\u793a", "result": "\u5728\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0cDRedMTL\u901a\u5e38\u663e\u8457\u4f18\u4e8e\u91cd\u65b0\u7269\u5316\uff0c\u6709\u65f6\u63d0\u5347\u6570\u4e2a\u6570\u91cf\u7ea7", "conclusion": "DRedMTL\u4e3aDatalogMTL\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u589e\u91cf\u63a8\u7406\u80fd\u529b\uff0c\u6ee1\u8db3\u73b0\u5b9e\u5e94\u7528\u7684\u52a8\u6001\u66f4\u65b0\u9700\u6c42"}}
{"id": "2511.12464", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12464", "abs": "https://arxiv.org/abs/2511.12464", "authors": ["Chenglong Wang", "Yifu Huo", "Yang Gan", "Yongyu Mu", "Qiaozhi He", "Murun Yang", "Bei Li", "Chunliang Zhang", "Tongran Liu", "Anxiang Ma", "Zhengtao Yu", "Jingbo Zhu", "Tong Xiao"], "title": "Probing Preference Representations: A Multi-Dimensional Evaluation and Analysis Method for Reward Models", "comment": "Accepted by AAAI 2026", "summary": "Previous methods evaluate reward models by testing them on a fixed pairwise ranking test set, but they typically do not provide performance information on each preference dimension. In this work, we address the evaluation challenge of reward models by probing preference representations. To confirm the effectiveness of this evaluation method, we construct a Multi-dimensional Reward Model Benchmark (MRMBench), a collection of six probing tasks for different preference dimensions. We design it to favor and encourage reward models that better capture preferences across different dimensions. Furthermore, we introduce an analysis method, inference-time probing, which identifies the dimensions used during the reward prediction and enhances its interpretability. Through extensive experiments, we find that MRMBench strongly correlates with the alignment performance of large language models (LLMs), making it a reliable reference for developing advanced reward models. Our analysis of MRMBench evaluation results reveals that reward models often struggle to capture preferences across multiple dimensions, highlighting the potential of multi-objective optimization in reward modeling. Additionally, our findings show that the proposed inference-time probing method offers a reliable metric for assessing the confidence of reward predictions, which ultimately improves the alignment of LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86MRMBench\u57fa\u51c6\u548c\u63a8\u7406\u65f6\u63a2\u6d4b\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5956\u52b1\u6a21\u578b\u5728\u591a\u7ef4\u5ea6\u504f\u597d\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u8be5\u65b9\u6cd5\u4e0eLLM\u5bf9\u9f50\u6027\u80fd\u5f3a\u76f8\u5173\u3002", "motivation": "\u73b0\u6709\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\u65b9\u6cd5\u901a\u5e38\u5728\u56fa\u5b9a\u6210\u5bf9\u6392\u5e8f\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\uff0c\u4f46\u65e0\u6cd5\u63d0\u4f9b\u5404\u504f\u597d\u7ef4\u5ea6\u7684\u6027\u80fd\u4fe1\u606f\uff0c\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u4e86MRMBench\u57fa\u51c6\uff08\u5305\u542b6\u4e2a\u63a2\u6d4b\u4efb\u52a1\uff09\uff0c\u5e76\u63d0\u51fa\u63a8\u7406\u65f6\u63a2\u6d4b\u65b9\u6cd5\u5206\u6790\u5956\u52b1\u9884\u6d4b\u65f6\u4f7f\u7528\u7684\u7ef4\u5ea6\uff0c\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMRMBench\u4e0eLLM\u5bf9\u9f50\u6027\u80fd\u5f3a\u76f8\u5173\uff1b\u5956\u52b1\u6a21\u578b\u5728\u591a\u7ef4\u5ea6\u504f\u597d\u6355\u6349\u4e0a\u5b58\u5728\u56f0\u96be\uff1b\u63a8\u7406\u65f6\u63a2\u6d4b\u65b9\u6cd5\u80fd\u53ef\u9760\u8bc4\u4f30\u5956\u52b1\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u3002", "conclusion": "MRMBench\u662f\u5f00\u53d1\u5148\u8fdb\u5956\u52b1\u6a21\u578b\u7684\u53ef\u9760\u53c2\u8003\uff0c\u591a\u76ee\u6807\u4f18\u5316\u5728\u5956\u52b1\u5efa\u6a21\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u63a8\u7406\u65f6\u63a2\u6d4b\u65b9\u6cd5\u80fd\u63d0\u5347LLM\u5bf9\u9f50\u6548\u679c\u3002"}}
{"id": "2511.12208", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12208", "abs": "https://arxiv.org/abs/2511.12208", "authors": ["Jilong Liu", "Pengyang Shao", "Wei Qin", "Fei Liu", "Yonghui Yang", "Richang Hong"], "title": "Debate over Mixed-knowledge: A Robust Multi-Agent Framework for Incomplete Knowledge Graph Question Answering", "comment": null, "summary": "Knowledge Graph Question Answering (KGQA) aims to improve factual accuracy by leveraging structured knowledge. However, real-world Knowledge Graphs (KGs) are often incomplete, leading to the problem of Incomplete KGQA (IKGQA). A common solution is to incorporate external data to fill knowledge gaps, but existing methods lack the capacity to adaptively and contextually fuse multiple sources, failing to fully exploit their complementary strengths. To this end, we propose Debate over Mixed-knowledge (DoM), a novel framework that enables dynamic integration of structured and unstructured knowledge for IKGQA. Built upon the Multi-Agent Debate paradigm, DoM assigns specialized agents to perform inference over knowledge graphs and external texts separately, and coordinates their outputs through iterative interaction. It decomposes the input question into sub-questions, retrieves evidence via dual agents (KG and Retrieval-Augmented Generation, RAG), and employs a judge agent to evaluate and aggregate intermediate answers. This collaboration exploits knowledge complementarity and enhances robustness to KG incompleteness. In addition, existing IKGQA datasets simulate incompleteness by randomly removing triples, failing to capture the irregular and unpredictable nature of real-world knowledge incompleteness. To address this, we introduce a new dataset, Incomplete Knowledge Graph WebQuestions, constructed by leveraging real-world knowledge updates. These updates reflect knowledge beyond the static scope of KGs, yielding a more realistic and challenging benchmark. Through extensive experiments, we show that DoM consistently outperforms state-of-the-art baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86DoM\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u673a\u5236\u52a8\u6001\u878d\u5408\u7ed3\u6784\u5316\u548c\u975e\u7ed3\u6784\u5316\u77e5\u8bc6\u6765\u89e3\u51b3\u4e0d\u5b8c\u6574\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u95ee\u9898\uff0c\u5e76\u6784\u5efa\u4e86\u66f4\u771f\u5b9e\u7684\u4e0d\u5b8c\u6574KG\u6570\u636e\u96c6\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u77e5\u8bc6\u56fe\u8c31\u901a\u5e38\u4e0d\u5b8c\u6574\uff0c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u81ea\u9002\u5e94\u5730\u878d\u5408\u591a\u6e90\u77e5\u8bc6\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u77e5\u8bc6\u7684\u4e92\u8865\u6027\u3002", "method": "DoM\u6846\u67b6\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u8303\u5f0f\uff0c\u5206\u914d\u4e13\u95e8\u667a\u80fd\u4f53\u5206\u522b\u5904\u7406\u77e5\u8bc6\u56fe\u8c31\u548c\u5916\u90e8\u6587\u672c\uff0c\u901a\u8fc7\u8fed\u4ee3\u4ea4\u4e92\u534f\u8c03\u8f93\u51fa\u3002\u5206\u89e3\u95ee\u9898\u3001\u53cc\u667a\u80fd\u4f53\u68c0\u7d22\u8bc1\u636e\u3001\u6cd5\u5b98\u667a\u80fd\u4f53\u8bc4\u4f30\u805a\u5408\u7b54\u6848\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cDoM\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "DoM\u6846\u67b6\u901a\u8fc7\u77e5\u8bc6\u4e92\u8865\u6027\u589e\u5f3a\u4e86KG\u4e0d\u5b8c\u6574\u6027\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u4e0d\u5b8c\u6574KGQA\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.12472", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12472", "abs": "https://arxiv.org/abs/2511.12472", "authors": ["Mengying Wang", "Chenhui Ma", "Ao Jiao", "Tuo Liang", "Pengjun Lu", "Shrinidhi Hegde", "Yu Yin", "Evren Gurkan-Cavusoglu", "Yinghui Wu"], "title": "Assessing LLMs for Serendipity Discovery in Knowledge Graphs: A Case for Drug Repurposing", "comment": "The 40th AAAI Conference on Artificial Intelligence (AAAI-26)", "summary": "Large Language Models (LLMs) have greatly advanced knowledge graph question answering (KGQA), yet existing systems are typically optimized for returning highly relevant but predictable answers. A missing yet desired capacity is to exploit LLMs to suggest surprise and novel (\"serendipitious\") answers. In this paper, we formally define the serendipity-aware KGQA task and propose the SerenQA framework to evaluate LLMs' ability to uncover unexpected insights in scientific KGQA tasks. SerenQA includes a rigorous serendipity metric based on relevance, novelty, and surprise, along with an expert-annotated benchmark derived from the Clinical Knowledge Graph, focused on drug repurposing. Additionally, it features a structured evaluation pipeline encompassing three subtasks: knowledge retrieval, subgraph reasoning, and serendipity exploration. Our experiments reveal that while state-of-the-art LLMs perform well on retrieval, they still struggle to identify genuinely surprising and valuable discoveries, underscoring a significant room for future improvements. Our curated resources and extended version are released at: https://cwru-db-group.github.io/serenQA.", "AI": {"tldr": "\u63d0\u51fa\u4e86SerenQA\u6846\u67b6\u6765\u8bc4\u4f30LLM\u5728\u79d1\u5b66\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u4e2d\u53d1\u73b0\u610f\u5916\u6d1e\u5bdf\u7684\u80fd\u529b\uff0c\u91cd\u70b9\u5173\u6ce8\u836f\u7269\u91cd\u5b9a\u4f4d\u9886\u57df\uff0c\u5305\u542b\u4e25\u8c28\u7684\u610f\u5916\u6027\u6307\u6807\u548c\u4e13\u5bb6\u6807\u6ce8\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709KGQA\u7cfb\u7edf\u901a\u5e38\u8fd4\u56de\u9ad8\u5ea6\u76f8\u5173\u4f46\u53ef\u9884\u6d4b\u7684\u7b54\u6848\uff0c\u7f3a\u4e4f\u53d1\u73b0\u610f\u5916\u548c\u65b0\u9896\u7b54\u6848\u7684\u80fd\u529b\uff0c\u9700\u8981\u8bc4\u4f30LLM\u53d1\u73b0\u79d1\u5b66\u6d1e\u5bdf\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faSerenQA\u6846\u67b6\uff0c\u5305\u542b\u57fa\u4e8e\u76f8\u5173\u6027\u3001\u65b0\u9896\u6027\u548c\u610f\u5916\u6027\u7684\u4e25\u8c28\u610f\u5916\u6027\u6307\u6807\uff0c\u4ee5\u53ca\u4ece\u4e34\u5e8a\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7684\u4e13\u5bb6\u6807\u6ce8\u57fa\u51c6\uff0c\u91c7\u7528\u5305\u542b\u77e5\u8bc6\u68c0\u7d22\u3001\u5b50\u56fe\u63a8\u7406\u548c\u610f\u5916\u6027\u63a2\u7d22\u7684\u4e09\u9636\u6bb5\u8bc4\u4f30\u6d41\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6700\u5148\u8fdb\u7684LLM\u5728\u68c0\u7d22\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u8bc6\u522b\u771f\u6b63\u4ee4\u4eba\u610f\u5916\u548c\u6709\u4ef7\u503c\u7684\u53d1\u73b0\u65b9\u9762\u4ecd\u6709\u56f0\u96be\u3002", "conclusion": "\u5f53\u524dLLM\u5728\u53d1\u73b0\u610f\u5916\u6d1e\u5bdf\u65b9\u9762\u4ecd\u6709\u663e\u8457\u6539\u8fdb\u7a7a\u95f4\uff0cSerenQA\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdb\u8fd9\u4e00\u80fd\u529b\u63d0\u4f9b\u4e86\u8d44\u6e90\u548c\u57fa\u51c6\u3002"}}
{"id": "2511.12214", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12214", "abs": "https://arxiv.org/abs/2511.12214", "authors": ["Ruochen Li", "Zhanxing Zhu", "Tanqiu Qiao", "Hubert P. H. Shum"], "title": "ViTE: Virtual Graph Trajectory Expert Router for Pedestrian Trajectory Prediction", "comment": null, "summary": "Pedestrian trajectory prediction is critical for ensuring safety in autonomous driving, surveillance systems, and urban planning applications. While early approaches primarily focus on one-hop pairwise relationships, recent studies attempt to capture high-order interactions by stacking multiple Graph Neural Network (GNN) layers. However, these approaches face a fundamental trade-off: insufficient layers may lead to under-reaching problems that limit the model's receptive field, while excessive depth can result in prohibitive computational costs. We argue that an effective model should be capable of adaptively modeling both explicit one-hop interactions and implicit high-order dependencies, rather than relying solely on architectural depth. To this end, we propose ViTE (Virtual graph Trajectory Expert router), a novel framework for pedestrian trajectory prediction. ViTE consists of two key modules: a Virtual Graph that introduces dynamic virtual nodes to model long-range and high-order interactions without deep GNN stacks, and an Expert Router that adaptively selects interaction experts based on social context using a Mixture-of-Experts design. This combination enables flexible and scalable reasoning across varying interaction patterns. Experiments on three benchmarks (ETH/UCY, NBA, and SDD) demonstrate that our method consistently achieves state-of-the-art performance, validating both its effectiveness and practical efficiency.", "AI": {"tldr": "ViTE\u6846\u67b6\u901a\u8fc7\u865a\u62df\u56fe\u548c\u4e13\u5bb6\u8def\u7531\u5668\u6a21\u5757\uff0c\u81ea\u9002\u5e94\u5efa\u6a21\u884c\u4eba\u8f68\u8ff9\u9884\u6d4b\u4e2d\u7684\u663e\u5f0f\u4e00\u8df3\u4ea4\u4e92\u548c\u9690\u5f0f\u9ad8\u9636\u4f9d\u8d56\uff0c\u907f\u514d\u4e86\u6df1\u5ea6GNN\u7684\u8ba1\u7b97\u6210\u672c\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u884c\u4eba\u8f68\u8ff9\u9884\u6d4b\u4e2d\u9762\u4e34\u6df1\u5ea6\u4e0e\u8ba1\u7b97\u6210\u672c\u7684\u6743\u8861\uff1a\u5c42\u6570\u4e0d\u8db3\u5bfc\u81f4\u611f\u53d7\u91ce\u53d7\u9650\uff0c\u5c42\u6570\u8fc7\u591a\u5219\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u3002\u9700\u8981\u80fd\u591f\u81ea\u9002\u5e94\u5efa\u6a21\u4e0d\u540c\u5c42\u6b21\u4ea4\u4e92\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faViTE\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\u865a\u62df\u56fe\u901a\u8fc7\u52a8\u6001\u865a\u62df\u8282\u70b9\u5efa\u6a21\u957f\u8ddd\u79bb\u9ad8\u9636\u4ea4\u4e92\uff0c\u65e0\u9700\u6df1\u5ea6GNN\u5806\u53e0\uff1b\u4e13\u5bb6\u8def\u7531\u5668\u57fa\u4e8e\u793e\u4ea4\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u9009\u62e9\u4ea4\u4e92\u4e13\u5bb6\uff0c\u91c7\u7528\u6df7\u5408\u4e13\u5bb6\u8bbe\u8ba1\u3002", "result": "\u5728ETH/UCY\u3001NBA\u548cSDD\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u5b9e\u9645\u6548\u7387\u3002", "conclusion": "ViTE\u6846\u67b6\u80fd\u591f\u7075\u6d3b\u53ef\u6269\u5c55\u5730\u5904\u7406\u4e0d\u540c\u4ea4\u4e92\u6a21\u5f0f\uff0c\u5728\u884c\u4eba\u8f68\u8ff9\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u89e3\u51b3\u4e86\u6df1\u5ea6GNN\u7684\u8ba1\u7b97\u6548\u7387\u95ee\u9898\u3002"}}
{"id": "2511.12497", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.12497", "abs": "https://arxiv.org/abs/2511.12497", "authors": ["JoonHo Lee", "HyeonMin Cho", "Jaewoong Yun", "Hyunjae Lee", "JunKyu Lee", "Juree Seok"], "title": "SGuard-v1: Safety Guardrail for Large Language Models", "comment": "Technical Report", "summary": "We present SGuard-v1, a lightweight safety guardrail for Large Language Models (LLMs), which comprises two specialized models to detect harmful content and screen adversarial prompts in human-AI conversational settings. The first component, ContentFilter, is trained to identify safety risks in LLM prompts and responses in accordance with the MLCommons hazard taxonomy, a comprehensive framework for trust and safety assessment of AI. The second component, JailbreakFilter, is trained with a carefully designed curriculum over integrated datasets and findings from prior work on adversarial prompting, covering 60 major attack types while mitigating false-unsafe classification. SGuard-v1 is built on the 2B-parameter Granite-3.3-2B-Instruct model that supports 12 languages. We curate approximately 1.4 million training instances from both collected and synthesized data and perform instruction tuning on the base model, distributing the curated data across the two component according to their designated functions. Through extensive evaluation on public and proprietary safety benchmarks, SGuard-v1 achieves state-of-the-art safety performance while remaining lightweight, thereby reducing deployment overhead. SGuard-v1 also improves interpretability for downstream use by providing multi-class safety predictions and their binary confidence scores. We release the SGuard-v1 under the Apache-2.0 License to enable further research and practical deployment in AI safety.", "AI": {"tldr": "SGuard-v1\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u62a4\u680f\u7cfb\u7edf\uff0c\u5305\u542bContentFilter\u548cJailbreakFilter\u4e24\u4e2a\u4e13\u7528\u6a21\u578b\uff0c\u7528\u4e8e\u68c0\u6d4b\u6709\u5bb3\u5185\u5bb9\u548c\u7b5b\u9009\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u652f\u630112\u79cd\u8bed\u8a00\uff0c\u5728\u4fdd\u6301\u8f7b\u91cf\u5316\u7684\u540c\u65f6\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u5b89\u5168\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4eba\u7c7b-AI\u5bf9\u8bdd\u573a\u666f\u4e2d\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5305\u62ec\u6709\u5bb3\u5185\u5bb9\u68c0\u6d4b\u548c\u5bf9\u6297\u6027\u63d0\u793a\u653b\u51fb\u9632\u62a4\uff0c\u540c\u65f6\u964d\u4f4e\u90e8\u7f72\u5f00\u9500\u3002", "method": "\u57fa\u4e8e2B\u53c2\u6570\u7684Granite-3.3-2B-Instruct\u6a21\u578b\u6784\u5efa\uff0c\u901a\u8fc7\u6307\u4ee4\u8c03\u4f18\u8bad\u7ec3\u4e24\u4e2a\u4e13\u7528\u7ec4\u4ef6\uff1aContentFilter\u7528\u4e8e\u8bc6\u522b\u5b89\u5168\u98ce\u9669\uff0cJailbreakFilter\u7528\u4e8e\u9632\u5fa160\u79cd\u4e3b\u8981\u653b\u51fb\u7c7b\u578b\uff0c\u4f7f\u7528\u7ea6140\u4e07\u8bad\u7ec3\u5b9e\u4f8b\u3002", "result": "\u5728\u516c\u5171\u548c\u4e13\u6709\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u5b89\u5168\u6027\u80fd\uff0c\u4fdd\u6301\u8f7b\u91cf\u5316\uff0c\u51cf\u5c11\u90e8\u7f72\u5f00\u9500\uff0c\u5e76\u63d0\u4f9b\u591a\u7c7b\u5b89\u5168\u9884\u6d4b\u548c\u4e8c\u5143\u7f6e\u4fe1\u5ea6\u8bc4\u5206\u4ee5\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "SGuard-v1\u662f\u4e00\u4e2a\u9ad8\u6548\u3001\u8f7b\u91cf\u7ea7\u7684\u5b89\u5168\u62a4\u680f\u7cfb\u7edf\uff0c\u5728Apache-2.0\u8bb8\u53ef\u4e0b\u53d1\u5e03\uff0c\u652f\u6301\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2511.12239", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12239", "abs": "https://arxiv.org/abs/2511.12239", "authors": ["Tarun Gupta", "Danish Pruthi"], "title": "Beyond World Models: Rethinking Understanding in AI Models", "comment": "Accepted to AAAI 2026 (Main Track)", "summary": "World models have garnered substantial interest in the AI community. These are internal representations that simulate aspects of the external world, track entities and states, capture causal relationships, and enable prediction of consequences. This contrasts with representations based solely on statistical correlations. A key motivation behind this research direction is that humans possess such mental world models, and finding evidence of similar representations in AI models might indicate that these models \"understand\" the world in a human-like way. In this paper, we use case studies from the philosophy of science literature to critically examine whether the world model framework adequately characterizes human-level understanding. We focus on specific philosophical analyses where the distinction between world model capabilities and human understanding is most pronounced. While these represent particular views of understanding rather than universal definitions, they help us explore the limits of world models.", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528\u79d1\u5b66\u54f2\u5b66\u6848\u4f8b\u7814\u7a76\u6765\u6279\u5224\u6027\u68c0\u9a8c\u4e16\u754c\u6a21\u578b\u6846\u67b6\u662f\u5426\u5145\u5206\u8868\u5f81\u4e86\u4eba\u7c7b\u6c34\u5e73\u7684\u7406\u89e3\u80fd\u529b", "motivation": "\u7814\u7a76AI\u6a21\u578b\u4e2d\u7684\u4e16\u754c\u6a21\u578b\u8868\u793a\u662f\u5426\u80fd\u8868\u660e\u8fd9\u4e9b\u6a21\u578b\u4ee5\u7c7b\u4eba\u65b9\u5f0f\"\u7406\u89e3\"\u4e16\u754c\uff0c\u4ee5\u53ca\u4e16\u754c\u6a21\u578b\u6846\u67b6\u662f\u5426\u5145\u5206\u8868\u5f81\u4eba\u7c7b\u7406\u89e3", "method": "\u4f7f\u7528\u79d1\u5b66\u54f2\u5b66\u6587\u732e\u4e2d\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u91cd\u70b9\u5173\u6ce8\u4e16\u754c\u6a21\u578b\u80fd\u529b\u4e0e\u4eba\u7c7b\u7406\u89e3\u4e4b\u95f4\u533a\u522b\u6700\u660e\u663e\u7684\u54f2\u5b66\u5206\u6790", "result": "\u901a\u8fc7\u7279\u5b9a\u54f2\u5b66\u89c2\u70b9\u63a2\u7d22\u4e86\u4e16\u754c\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u8868\u660e\u4e16\u754c\u6a21\u578b\u6846\u67b6\u53ef\u80fd\u4e0d\u8db3\u4ee5\u5b8c\u5168\u8868\u5f81\u4eba\u7c7b\u7406\u89e3", "conclusion": "\u4e16\u754c\u6a21\u578b\u6846\u67b6\u5728\u8868\u5f81\u4eba\u7c7b\u6c34\u5e73\u7406\u89e3\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u7ec6\u81f4\u5730\u8003\u8651\u4eba\u7c7b\u7406\u89e3\u4e0eAI\u4e16\u754c\u6a21\u578b\u4e4b\u95f4\u7684\u5dee\u5f02"}}
{"id": "2511.12504", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12504", "abs": "https://arxiv.org/abs/2511.12504", "authors": ["Maria Tseytlin", "Paul Roit", "Omri Abend", "Ido Dagan", "Ayal Klein"], "title": "QA-Noun: Representing Nominal Semantics via Natural Language Question-Answer Pairs", "comment": null, "summary": "Decomposing sentences into fine-grained meaning units is increasingly used to model semantic alignment. While QA-based semantic approaches have shown effectiveness for representing predicate-argument relations, they have so far left noun-centered semantics largely unaddressed. We introduce QA-Noun, a QA-based framework for capturing noun-centered semantic relations. QA-Noun defines nine question templates that cover both explicit syntactical and implicit contextual roles for nouns, producing interpretable QA pairs that complement verbal QA-SRL. We release detailed guidelines, a dataset of over 2,000 annotated noun mentions, and a trained model integrated with QA-SRL to yield a unified decomposition of sentence meaning into individual, highly fine-grained, facts. Evaluation shows that QA-Noun achieves near-complete coverage of AMR's noun arguments while surfacing additional contextually implied relations, and that combining QA-Noun with QA-SRL yields over 130\\% higher granularity than recent fact-based decomposition methods such as FactScore and DecompScore. QA-Noun thus complements the broader QA-based semantic framework, forming a comprehensive and scalable approach to fine-grained semantic decomposition for cross-text alignment.", "AI": {"tldr": "QA-Noun\u662f\u4e00\u4e2a\u57fa\u4e8e\u95ee\u7b54\u7684\u6846\u67b6\uff0c\u4e13\u95e8\u7528\u4e8e\u6355\u6349\u540d\u8bcd\u4e3a\u4e2d\u5fc3\u7684\u8bed\u4e49\u5173\u7cfb\uff0c\u901a\u8fc79\u4e2a\u95ee\u9898\u6a21\u677f\u8986\u76d6\u540d\u8bcd\u7684\u663e\u5f0f\u53e5\u6cd5\u548c\u9690\u5f0f\u4e0a\u4e0b\u6587\u89d2\u8272\uff0c\u4e0eQA-SRL\u7ed3\u5408\u5b9e\u73b0\u53e5\u5b50\u610f\u4e49\u7684\u7edf\u4e00\u5206\u89e3\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eQA\u7684\u8bed\u4e49\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u8c13\u8bcd-\u8bba\u5143\u5173\u7cfb\uff0c\u4f46\u540d\u8bcd\u4e3a\u4e2d\u5fc3\u7684\u8bed\u4e49\u5173\u7cfb\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u672a\u88ab\u89e3\u51b3\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5168\u9762\u6355\u6349\u540d\u8bcd\u8bed\u4e49\u89d2\u8272\u7684\u6846\u67b6\u3002", "method": "\u5b9a\u4e499\u4e2a\u95ee\u9898\u6a21\u677f\u6765\u8986\u76d6\u540d\u8bcd\u7684\u663e\u5f0f\u53e5\u6cd5\u548c\u9690\u5f0f\u4e0a\u4e0b\u6587\u89d2\u8272\uff0c\u521b\u5efa\u53ef\u89e3\u91ca\u7684QA\u5bf9\uff0c\u5e76\u4e0eQA-SRL\u96c6\u6210\uff0c\u5f62\u6210\u7edf\u4e00\u7684\u53e5\u5b50\u610f\u4e49\u5206\u89e3\u65b9\u6cd5\u3002", "result": "QA-Noun\u51e0\u4e4e\u5b8c\u5168\u8986\u76d6\u4e86AMR\u7684\u540d\u8bcd\u8bba\u5143\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u989d\u5916\u7684\u4e0a\u4e0b\u6587\u9690\u542b\u5173\u7cfb\uff0c\u4e0eQA-SRL\u7ed3\u5408\u540e\u6bd4FactScore\u548cDecompScore\u7b49\u65b9\u6cd5\u7684\u7c92\u5ea6\u63d0\u9ad8\u4e86130%\u4ee5\u4e0a\u3002", "conclusion": "QA-Noun\u8865\u5145\u4e86\u66f4\u5e7f\u6cdb\u7684\u57fa\u4e8eQA\u7684\u8bed\u4e49\u6846\u67b6\uff0c\u5f62\u6210\u4e86\u5168\u9762\u4e14\u53ef\u6269\u5c55\u7684\u7ec6\u7c92\u5ea6\u8bed\u4e49\u5206\u89e3\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u8de8\u6587\u672c\u5bf9\u9f50\u4efb\u52a1\u3002"}}
{"id": "2511.12241", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.12241", "abs": "https://arxiv.org/abs/2511.12241", "authors": ["Junhyuk Seo", "Hyeyoon Moon", "Kyu-Hwan Jung", "Namkee Oh", "Taerim Kim"], "title": "AURA: Development and Validation of an Augmented Unplanned Removal Alert System using Synthetic ICU Videos", "comment": "12 pages, 5 figures", "summary": "Unplanned extubation (UE) remains a critical patient safety concern in intensive care units (ICUs), often leading to severe complications or death. Real-time UE detection has been limited, largely due to the ethical and privacy challenges of obtaining annotated ICU video data. We propose Augmented Unplanned Removal Alert (AURA), a vision-based risk detection system developed and validated entirely on a fully synthetic video dataset. By leveraging text-to-video diffusion, we generated diverse and clinically realistic ICU scenarios capturing a range of patient behaviors and care contexts. The system applies pose estimation to identify two high-risk movement patterns: collision, defined as hand entry into spatial zones near airway tubes, and agitation, quantified by the velocity of tracked anatomical keypoints. Expert assessments confirmed the realism of the synthetic data, and performance evaluations showed high accuracy for collision detection and moderate performance for agitation recognition. This work demonstrates a novel pathway for developing privacy-preserving, reproducible patient safety monitoring systems with potential for deployment in intensive care settings.", "AI": {"tldr": "AURA\u7cfb\u7edf\u4f7f\u7528\u5408\u6210\u89c6\u9891\u6570\u636e\u5f00\u53d1\u89c6\u89c9\u98ce\u9669\u68c0\u6d4b\u7cfb\u7edf\uff0c\u901a\u8fc7\u59ff\u6001\u4f30\u8ba1\u8bc6\u522bICU\u60a3\u8005\u7684\u9ad8\u98ce\u9669\u52a8\u4f5c\u6a21\u5f0f\uff08\u78b0\u649e\u548c\u8e81\u52a8\uff09\uff0c\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u7684\u5b9e\u65f6\u975e\u8ba1\u5212\u62d4\u7ba1\u68c0\u6d4b\u3002", "motivation": "ICU\u4e2d\u975e\u8ba1\u5212\u62d4\u7ba1\u662f\u4e25\u91cd\u7684\u5b89\u5168\u95ee\u9898\uff0c\u4f46\u5b9e\u65f6\u68c0\u6d4b\u53d7\u9650\u4e8e\u4f26\u7406\u548c\u9690\u79c1\u95ee\u9898\u96be\u4ee5\u83b7\u53d6\u6807\u6ce8\u89c6\u9891\u6570\u636e\u3002", "method": "\u5229\u7528\u6587\u672c\u5230\u89c6\u9891\u6269\u6563\u751f\u6210\u5408\u6210ICU\u89c6\u9891\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u59ff\u6001\u4f30\u8ba1\u8bc6\u522b\u624b\u90e8\u8fdb\u5165\u6c14\u9053\u7ba1\u9644\u8fd1\u533a\u57df\uff08\u78b0\u649e\uff09\u548c\u5173\u952e\u70b9\u901f\u5ea6\uff08\u8e81\u52a8\uff09\u4e24\u79cd\u9ad8\u98ce\u9669\u6a21\u5f0f\u3002", "result": "\u4e13\u5bb6\u786e\u8ba4\u5408\u6210\u6570\u636e\u771f\u5b9e\u6027\uff0c\u78b0\u649e\u68c0\u6d4b\u51c6\u786e\u7387\u9ad8\uff0c\u8e81\u52a8\u8bc6\u522b\u6027\u80fd\u4e2d\u7b49\u3002", "conclusion": "\u5c55\u793a\u4e86\u5f00\u53d1\u9690\u79c1\u4fdd\u62a4\u3001\u53ef\u590d\u73b0\u7684\u60a3\u8005\u5b89\u5168\u76d1\u6d4b\u7cfb\u7edf\u7684\u65b0\u9014\u5f84\uff0c\u5177\u6709ICU\u90e8\u7f72\u6f5c\u529b\u3002"}}
{"id": "2511.12520", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12520", "abs": "https://arxiv.org/abs/2511.12520", "authors": ["Jie Zhang", "Bo Tang", "Wanzi Shao", "Wenqiang Wei", "Jihao Zhao", "Jianqing Zhu", "Zhiyu li", "Wen Xi", "Zehao Lin", "Feiyu Xiong", "Yanchao Tan"], "title": "TAdaRAG: Task Adaptive Retrieval-Augmented Generation via On-the-Fly Knowledge Graph Construction", "comment": "Accepted by AAAI 2026", "summary": "Retrieval-Augmented Generation (RAG) improves large language models by retrieving external knowledge, often truncated into smaller chunks due to the input context window, which leads to information loss, resulting in response hallucinations and broken reasoning chains. Moreover, traditional RAG retrieves unstructured knowledge, introducing irrelevant details that hinder accurate reasoning. To address these issues, we propose TAdaRAG, a novel RAG framework for on-the-fly task-adaptive knowledge graph construction from external sources. Specifically, we design an intent-driven routing mechanism to a domain-specific extraction template, followed by supervised fine-tuning and a reinforcement learning-based implicit extraction mechanism, ensuring concise, coherent, and non-redundant knowledge integration. Evaluations on six public benchmarks and a real-world business benchmark (NowNewsQA) across three backbone models demonstrate that TAdaRAG outperforms existing methods across diverse domains and long-text tasks, highlighting its strong generalization and practical effectiveness.", "AI": {"tldr": "TAdaRAG\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u6784\u5efa\u4efb\u52a1\u81ea\u9002\u5e94\u7684\u77e5\u8bc6\u56fe\u8c31\u6765\u89e3\u51b3\u4f20\u7edfRAG\u4e2d\u4fe1\u606f\u622a\u65ad\u548c\u4fe1\u606f\u5197\u4f59\u7684\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4f20\u7edfRAG\u65b9\u6cd5\u5c06\u5916\u90e8\u77e5\u8bc6\u622a\u65ad\u6210\u5c0f\u5757\u5bfc\u81f4\u4fe1\u606f\u4e22\u5931\uff0c\u5f15\u8d77\u56de\u7b54\u5e7b\u89c9\u548c\u63a8\u7406\u94fe\u65ad\u88c2\uff0c\u540c\u65f6\u68c0\u7d22\u7684\u975e\u7ed3\u6784\u5316\u77e5\u8bc6\u5305\u542b\u65e0\u5173\u7ec6\u8282\u963b\u788d\u51c6\u786e\u63a8\u7406\u3002", "method": "\u8bbe\u8ba1\u610f\u56fe\u9a71\u52a8\u7684\u8def\u7531\u673a\u5236\u5230\u9886\u57df\u7279\u5b9a\u63d0\u53d6\u6a21\u677f\uff0c\u7ed3\u5408\u76d1\u7763\u5fae\u8c03\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u9690\u5f0f\u63d0\u53d6\u673a\u5236\uff0c\u786e\u4fdd\u7b80\u6d01\u3001\u8fde\u8d2f\u4e14\u975e\u5197\u4f59\u7684\u77e5\u8bc6\u6574\u5408\u3002", "result": "\u5728\u516d\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e00\u4e2a\u771f\u5b9e\u5546\u4e1a\u57fa\u51c6\u6d4b\u8bd5(NowNewsQA)\u4e0a\uff0c\u4f7f\u7528\u4e09\u4e2a\u9aa8\u5e72\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0cTAdaRAG\u5728\u591a\u6837\u5316\u9886\u57df\u548c\u957f\u6587\u672c\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "TAdaRAG\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5b9e\u9645\u6709\u6548\u6027\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4f20\u7edfRAG\u7684\u4fe1\u606f\u622a\u65ad\u548c\u5197\u4f59\u95ee\u9898\u3002"}}
{"id": "2511.12254", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.12254", "abs": "https://arxiv.org/abs/2511.12254", "authors": ["Yuxiang Zhou", "Jichang Li", "Yanhao Zhang", "Haonan Lu", "Guanbin Li"], "title": "Mobile-Agent-RAG: Driving Smart Multi-Agent Coordination with Contextual Knowledge Empowerment for Long-Horizon Mobile Automation", "comment": null, "summary": "Mobile agents show immense potential, yet current state-of-the-art (SoTA) agents exhibit inadequate success rates on real-world, long-horizon, cross-application tasks. We attribute this bottleneck to the agents' excessive reliance on static, internal knowledge within MLLMs, which leads to two critical failure points: 1) strategic hallucinations in high-level planning and 2) operational errors during low-level execution on user interfaces (UI). The core insight of this paper is that high-level planning and low-level UI operations require fundamentally distinct types of knowledge. Planning demands high-level, strategy-oriented experiences, whereas operations necessitate low-level, precise instructions closely tied to specific app UIs. Motivated by these insights, we propose Mobile-Agent-RAG, a novel hierarchical multi-agent framework that innovatively integrates dual-level retrieval augmentation. At the planning stage, we introduce Manager-RAG to reduce strategic hallucinations by retrieving human-validated comprehensive task plans that provide high-level guidance. At the execution stage, we develop Operator-RAG to improve execution accuracy by retrieving the most precise low-level guidance for accurate atomic actions, aligned with the current app and subtask. To accurately deliver these knowledge types, we construct two specialized retrieval-oriented knowledge bases. Furthermore, we introduce Mobile-Eval-RAG, a challenging benchmark for evaluating such agents on realistic multi-app, long-horizon tasks. Extensive experiments demonstrate that Mobile-Agent-RAG significantly outperforms SoTA baselines, improving task completion rate by 11.0% and step efficiency by 10.2%, establishing a robust paradigm for context-aware, reliable multi-agent mobile automation.", "AI": {"tldr": "Mobile-Agent-RAG\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u5206\u5c42\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u91cd\u68c0\u7d22\u589e\u5f3a\u89e3\u51b3\u79fb\u52a8\u4ee3\u7406\u5728\u771f\u5b9e\u4e16\u754c\u957f\u65f6\u8de8\u5e94\u7528\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u74f6\u9888\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u5b8c\u6210\u7387\u548c\u6b65\u9aa4\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u79fb\u52a8\u4ee3\u7406\u5728\u771f\u5b9e\u4e16\u754c\u957f\u65f6\u8de8\u5e94\u7528\u4efb\u52a1\u4e2d\u6210\u529f\u7387\u4e0d\u8db3\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u8fc7\u5ea6\u4f9d\u8d56MLLM\u4e2d\u7684\u9759\u6001\u5185\u90e8\u77e5\u8bc6\uff0c\u5bfc\u81f4\u9ad8\u5c42\u89c4\u5212\u4e2d\u7684\u6218\u7565\u5e7b\u89c9\u548c\u4f4e\u5c42UI\u64cd\u4f5c\u4e2d\u7684\u6267\u884c\u9519\u8bef\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u591a\u4ee3\u7406\u6846\u67b6Mobile-Agent-RAG\uff0c\u5305\u542bManager-RAG\u7528\u4e8e\u89c4\u5212\u9636\u6bb5\u68c0\u7d22\u4eba\u7c7b\u9a8c\u8bc1\u7684\u5168\u9762\u4efb\u52a1\u8ba1\u5212\u4ee5\u51cf\u5c11\u6218\u7565\u5e7b\u89c9\uff0cOperator-RAG\u7528\u4e8e\u6267\u884c\u9636\u6bb5\u68c0\u7d22\u6700\u7cbe\u786e\u7684\u4f4e\u5c42\u6307\u5bfc\u4ee5\u63d0\u9ad8\u6267\u884c\u51c6\u786e\u6027\uff0c\u5e76\u6784\u5efa\u4e86\u4e24\u4e2a\u4e13\u95e8\u7684\u68c0\u7d22\u5bfc\u5411\u77e5\u8bc6\u5e93\u3002", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cMobile-Agent-RAG\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4efb\u52a1\u5b8c\u6210\u7387\u63d0\u9ad811.0%\uff0c\u6b65\u9aa4\u6548\u7387\u63d0\u9ad810.2%\u3002", "conclusion": "Mobile-Agent-RAG\u5efa\u7acb\u4e86\u4e00\u4e2a\u7528\u4e8e\u4e0a\u4e0b\u6587\u611f\u77e5\u3001\u53ef\u9760\u591a\u4ee3\u7406\u79fb\u52a8\u81ea\u52a8\u5316\u7684\u7a33\u5065\u8303\u5f0f\uff0c\u901a\u8fc7\u53cc\u91cd\u68c0\u7d22\u589e\u5f3a\u6709\u6548\u89e3\u51b3\u4e86\u79fb\u52a8\u4ee3\u7406\u5728\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2511.12573", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12573", "abs": "https://arxiv.org/abs/2511.12573", "authors": ["Hyeonji Kim", "Sujeong Oh", "Sanghack Lee"], "title": "Mitigating Length Bias in RLHF through a Causal Lens", "comment": null, "summary": "Reinforcement learning from human feedback (RLHF) is widely used to align large language models (LLMs) with human preferences. However, RLHF-trained reward models often exhibit length bias -- a systematic tendency to favor longer responses by conflating verbosity with quality. We propose a causal framework for analyzing and mitigating length bias in RLHF reward modeling. Central to our approach is a counterfactual data augmentation method that generates response pairs designed to isolate content quality from verbosity. These counterfactual examples are then used to train the reward model, enabling it to assess responses based on content quality independently of verbosity. Specifically, we construct (1) length-divergent pairs with similar content and (2) content-divergent pairs of similar length. Empirical evaluations show that our method reduces length bias in reward assignment and leads to more concise, content-focused outputs from the policy model. These findings demonstrate that the proposed approach effectively reduces length bias and improves the robustness and content sensitivity of reward modeling in RLHF pipelines.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u56e0\u679c\u6846\u67b6\u548c\u53cd\u4e8b\u5b9e\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u6765\u51cf\u8f7bRLHF\u5956\u52b1\u6a21\u578b\u4e2d\u7684\u957f\u5ea6\u504f\u5dee\u95ee\u9898\uff0c\u901a\u8fc7\u6784\u9020\u957f\u5ea6\u4e0d\u540c\u4f46\u5185\u5bb9\u76f8\u4f3c\u7684\u54cd\u5e94\u5bf9\u4ee5\u53ca\u957f\u5ea6\u76f8\u4f3c\u4f46\u5185\u5bb9\u4e0d\u540c\u7684\u54cd\u5e94\u5bf9\u6765\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\u3002", "motivation": "RLHF\u8bad\u7ec3\u7684\u5956\u52b1\u6a21\u578b\u5b58\u5728\u957f\u5ea6\u504f\u5dee\uff0c\u503e\u5411\u4e8e\u5c06\u5197\u957f\u4e0e\u8d28\u91cf\u6df7\u6dc6\uff0c\u504f\u7231\u66f4\u957f\u7684\u54cd\u5e94\uff0c\u8fd9\u5f71\u54cd\u4e86\u6a21\u578b\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528\u53cd\u4e8b\u5b9e\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u6784\u9020\u4e24\u79cd\u7c7b\u578b\u7684\u54cd\u5e94\u5bf9\uff1a(1)\u957f\u5ea6\u4e0d\u540c\u4f46\u5185\u5bb9\u76f8\u4f3c\u7684\u54cd\u5e94\u5bf9\uff1b(2)\u957f\u5ea6\u76f8\u4f3c\u4f46\u5185\u5bb9\u4e0d\u540c\u7684\u54cd\u5e94\u5bf9\uff0c\u7528\u4e8e\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\u8be5\u65b9\u6cd5\u51cf\u5c11\u4e86\u5956\u52b1\u5206\u914d\u4e2d\u7684\u957f\u5ea6\u504f\u5dee\uff0c\u5e76\u4f7f\u5f97\u7b56\u7565\u6a21\u578b\u4ea7\u751f\u66f4\u7b80\u6d01\u3001\u5185\u5bb9\u805a\u7126\u7684\u8f93\u51fa\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u51cf\u8f7b\u4e86\u957f\u5ea6\u504f\u5dee\uff0c\u63d0\u9ad8\u4e86RLHF\u6d41\u7a0b\u4e2d\u5956\u52b1\u5efa\u6a21\u7684\u9c81\u68d2\u6027\u548c\u5185\u5bb9\u654f\u611f\u6027\u3002"}}
{"id": "2511.12271", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12271", "abs": "https://arxiv.org/abs/2511.12271", "authors": ["Zhiyu An", "Wan Du"], "title": "MoralReason: Generalizable Moral Decision Alignment For LLM Agents Using Reasoning-Level Reinforcement Learning", "comment": "Accepted for AAAI 2026", "summary": "Large language models are increasingly influencing human moral decisions, yet current approaches focus primarily on evaluating rather than actively steering their moral decisions. We formulate this as an out-of-distribution moral alignment problem, where LLM agents must learn to apply consistent moral reasoning frameworks to scenarios beyond their training distribution. We introduce Moral-Reason-QA, a novel dataset extending 680 human-annotated, high-ambiguity moral scenarios with framework-specific reasoning traces across utilitarian, deontological, and virtue ethics, enabling systematic evaluation of moral generalization in realistic decision contexts. Our learning approach employs Group Relative Policy Optimization with composite rewards that simultaneously optimize decision alignment and framework-specific reasoning processes to facilitate learning of the underlying moral frameworks. Experimental results demonstrate successful generalization to unseen moral scenarios, with softmax-normalized alignment scores improving by +0.757 for utilitarian and +0.450 for deontological frameworks when tested on out-of-distribution evaluation sets. The experiments also reveal training challenges and promising directions that inform future research. These findings establish that LLM agents can be systematically trained to internalize and apply specific moral frameworks to novel situations, providing a critical foundation for AI safety as language models become more integrated into human decision-making processes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u5b66\u4e60\u5e76\u5e94\u7528\u9053\u5fb7\u63a8\u7406\u6846\u67b6\u5230\u65b0\u60c5\u5883\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7Moral-Reason-QA\u6570\u636e\u96c6\u548cGroup Relative Policy Optimization\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4e86\u5728\u672a\u89c1\u9053\u5fb7\u573a\u666f\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u4e3b\u8981\u8bc4\u4f30\u800c\u975e\u4e3b\u52a8\u5f15\u5bfcLLM\u7684\u9053\u5fb7\u51b3\u7b56\uff0c\u9700\u8981\u89e3\u51b3\u5206\u5e03\u5916\u9053\u5fb7\u5bf9\u9f50\u95ee\u9898\uff0c\u8ba9LLM\u4ee3\u7406\u5b66\u4e60\u5c06\u4e00\u81f4\u7684\u9053\u5fb7\u63a8\u7406\u6846\u67b6\u5e94\u7528\u5230\u8d85\u51fa\u8bad\u7ec3\u5206\u5e03\u7684\u9053\u5fb7\u573a\u666f\u4e2d\u3002", "method": "\u521b\u5efaMoral-Reason-QA\u6570\u636e\u96c6\uff08680\u4e2a\u4eba\u5de5\u6807\u6ce8\u7684\u9ad8\u6a21\u7cca\u5ea6\u9053\u5fb7\u573a\u666f\uff09\uff0c\u4f7f\u7528Group Relative Policy Optimization\u7ed3\u5408\u590d\u5408\u5956\u52b1\uff0c\u540c\u65f6\u4f18\u5316\u51b3\u7b56\u5bf9\u9f50\u548c\u6846\u67b6\u7279\u5b9a\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u5728\u5206\u5e03\u5916\u8bc4\u4f30\u96c6\u4e0a\uff0c\u529f\u5229\u4e3b\u4e49\u6846\u67b6\u7684softmax\u5f52\u4e00\u5316\u5bf9\u9f50\u5206\u6570\u63d0\u9ad8\u4e86+0.757\uff0c\u9053\u4e49\u8bba\u6846\u67b6\u63d0\u9ad8\u4e86+0.450\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9\u672a\u89c1\u9053\u5fb7\u573a\u666f\u7684\u6cdb\u5316\u3002", "conclusion": "LLM\u4ee3\u7406\u53ef\u4ee5\u7cfb\u7edf\u6027\u5730\u8bad\u7ec3\u4ee5\u5185\u5728\u5316\u5e76\u5e94\u7528\u7279\u5b9a\u9053\u5fb7\u6846\u67b6\u5230\u65b0\u60c5\u5883\uff0c\u4e3aAI\u5b89\u5168\u63d0\u4f9b\u4e86\u5173\u952e\u57fa\u7840\uff0c\u56e0\u4e3a\u8bed\u8a00\u6a21\u578b\u6b63\u8d8a\u6765\u8d8a\u591a\u5730\u878d\u5165\u4eba\u7c7b\u51b3\u7b56\u8fc7\u7a0b\u3002"}}
{"id": "2511.12586", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12586", "abs": "https://arxiv.org/abs/2511.12586", "authors": ["Pu-Hai Yang", "Heyan Huang", "Heng-Da Xu", "Fanshu Sun", "Xian-Ling Mao", "Chaoxu Mu"], "title": "MMWOZ: Building Multimodal Agent for Task-oriented Dialogue", "comment": null, "summary": "Task-oriented dialogue systems have garnered significant attention due to their conversational ability to accomplish goals, such as booking airline tickets for users. Traditionally, task-oriented dialogue systems are conceptualized as intelligent agents that interact with users using natural language and have access to customized back-end APIs. However, in real-world scenarios, the widespread presence of front-end Graphical User Interfaces (GUIs) and the absence of customized back-end APIs create a significant gap for traditional task-oriented dialogue systems in practical applications. In this paper, to bridge the gap, we collect MMWOZ, a new multimodal dialogue dataset that is extended from MultiWOZ 2.3 dataset. Specifically, we begin by developing a web-style GUI to serve as the front-end. Next, we devise an automated script to convert the dialogue states and system actions from the original dataset into operation instructions for the GUI. Lastly, we collect snapshots of the web pages along with their corresponding operation instructions. In addition, we propose a novel multimodal model called MATE (Multimodal Agent for Task-oriEnted dialogue) as the baseline model for the MMWOZ dataset. Furthermore, we conduct comprehensive experimental analysis using MATE to investigate the construction of a practical multimodal agent for task-oriented dialogue.", "AI": {"tldr": "MMWOZ\u662f\u4e00\u4e2a\u4eceMultiWOZ 2.3\u6269\u5c55\u7684\u591a\u6a21\u6001\u5bf9\u8bdd\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5f00\u53d1\u7f51\u9875GUI\u548c\u81ea\u52a8\u5316\u811a\u672c\u5c06\u5bf9\u8bdd\u72b6\u6001\u8f6c\u6362\u4e3a\u64cd\u4f5c\u6307\u4ee4\uff0c\u65e8\u5728\u5f25\u5408\u4f20\u7edf\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u7cfb\u7edf\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u5dee\u8ddd\u3002", "motivation": "\u4f20\u7edf\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u7cfb\u7edf\u4f9d\u8d56\u5b9a\u5236\u540e\u7aefAPI\uff0c\u800c\u73b0\u5b9e\u573a\u666f\u4e2d\u666e\u904d\u5b58\u5728\u524d\u7aefGUI\u4e14\u7f3a\u4e4f\u5b9a\u5236API\uff0c\u8fd9\u9020\u6210\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u663e\u8457\u5dee\u8ddd\u3002", "method": "\u5f00\u53d1\u7f51\u9875GUI\u4f5c\u4e3a\u524d\u7aef\uff0c\u8bbe\u8ba1\u81ea\u52a8\u5316\u811a\u672c\u5c06\u539f\u59cb\u6570\u636e\u96c6\u4e2d\u7684\u5bf9\u8bdd\u72b6\u6001\u548c\u7cfb\u7edf\u52a8\u4f5c\u8f6c\u6362\u4e3aGUI\u64cd\u4f5c\u6307\u4ee4\uff0c\u6536\u96c6\u7f51\u9875\u5feb\u7167\u53ca\u5bf9\u5e94\u64cd\u4f5c\u6307\u4ee4\uff0c\u5e76\u63d0\u51fa\u4e86MATE\u591a\u6a21\u6001\u6a21\u578b\u4f5c\u4e3a\u57fa\u7ebf\u3002", "result": "\u521b\u5efa\u4e86MMWOZ\u591a\u6a21\u6001\u5bf9\u8bdd\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u4e86MATE\u6a21\u578b\u4f5c\u4e3a\u8be5\u6570\u636e\u96c6\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7MMWOZ\u6570\u636e\u96c6\u548cMATE\u6a21\u578b\uff0c\u4e3a\u6784\u5efa\u5b9e\u7528\u7684\u591a\u6a21\u6001\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u4ee3\u7406\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5e76\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5b9e\u9a8c\u5206\u6790\u3002"}}
{"id": "2511.12306", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.12306", "abs": "https://arxiv.org/abs/2511.12306", "authors": ["Darvin Yi", "Teng Liu", "Mattie Terzolo", "Lance Hasson", "Ayan Sinh", "Pablo Mendes", "Andrew Rabinovich"], "title": "UpBench: A Dynamically Evolving Real-World Labor-Market Agentic Benchmark Framework Built for Human-Centric AI", "comment": null, "summary": "As large language model (LLM) agents increasingly undertake digital work, reliable frameworks are needed to evaluate their real-world competence, adaptability, and capacity for human collaboration. Existing benchmarks remain largely static, synthetic, or domain-limited, providing limited insight into how agents perform in dynamic, economically meaningful environments. We introduce UpBench, a dynamically evolving benchmark grounded in real jobs drawn from the global Upwork labor marketplace. Each task corresponds to a verified client transaction, anchoring evaluation in genuine work activity and financial outcomes. UpBench employs a rubric-based evaluation framework, in which expert freelancers decompose each job into detailed, verifiable acceptance criteria and assess AI submissions with per-criterion feedback. This structure enables fine-grained analysis of model strengths, weaknesses, and instruction-following fidelity beyond binary pass/fail metrics. Human expertise is integrated throughout the data pipeline (from job curation and rubric construction to evaluation) ensuring fidelity to real professional standards and supporting research on human-AI collaboration. By regularly refreshing tasks to reflect the evolving nature of online work, UpBench provides a scalable, human-centered foundation for evaluating agentic systems in authentic labor-market contexts, offering a path toward a collaborative framework, where AI amplifies human capability through partnership rather than replacement.", "AI": {"tldr": "UpBench\u662f\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9eUpwork\u5de5\u4f5c\u4efb\u52a1\u7684\u52a8\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u771f\u5b9e\u5de5\u4f5c\u73af\u5883\u4e2d\u7684\u8868\u73b0\uff0c\u91c7\u7528\u4e13\u5bb6\u5236\u5b9a\u7684\u8bc4\u5206\u6807\u51c6\u548c\u4eba\u7c7b\u8bc4\u4f30\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5927\u591a\u662f\u9759\u6001\u3001\u5408\u6210\u6216\u9886\u57df\u53d7\u9650\u7684\uff0c\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30AI\u4ee3\u7406\u5728\u52a8\u6001\u3001\u7ecf\u6d4e\u610f\u4e49\u73af\u5883\u4e2d\u7684\u771f\u5b9e\u8868\u73b0\u548c\u4eba\u7c7b\u534f\u4f5c\u80fd\u529b\u3002", "method": "\u4eceUpwork\u5e73\u53f0\u63d0\u53d6\u771f\u5b9e\u5de5\u4f5c\u4efb\u52a1\uff0c\u7531\u4e13\u4e1a\u81ea\u7531\u804c\u4e1a\u8005\u5236\u5b9a\u8be6\u7ec6\u53ef\u9a8c\u8bc1\u7684\u9a8c\u6536\u6807\u51c6\uff0c\u91c7\u7528\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8bc4\u4f30\u6846\u67b6\u5bf9AI\u63d0\u4ea4\u5185\u5bb9\u8fdb\u884c\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u3002", "result": "\u5efa\u7acb\u4e86\u57fa\u4e8e\u771f\u5b9e\u5de5\u4f5c\u6d3b\u52a8\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u5206\u6790\u6a21\u578b\u4f18\u52bf\u3001\u5f31\u70b9\u548c\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u8d85\u8d8a\u7b80\u5355\u7684\u901a\u8fc7/\u5931\u8d25\u6307\u6807\u3002", "conclusion": "UpBench\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u4ee5\u4eba\u4e3a\u672c\u7684\u57fa\u7840\uff0c\u7528\u4e8e\u5728\u771f\u5b9e\u52b3\u52a8\u529b\u5e02\u573a\u73af\u5883\u4e2d\u8bc4\u4f30\u4ee3\u7406\u7cfb\u7edf\uff0c\u652f\u6301AI\u901a\u8fc7\u5408\u4f5c\u800c\u975e\u66ff\u4ee3\u6765\u589e\u5f3a\u4eba\u7c7b\u80fd\u529b\u7684\u7814\u7a76\u3002"}}
{"id": "2511.12596", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12596", "abs": "https://arxiv.org/abs/2511.12596", "authors": ["Oron Anschel", "Alon Shoshan", "Adam Botach", "Shunit Haviv Hakimi", "Asaf Gendler", "Emanuel Ben Baruch", "Nadav Bhonker", "Igor Kviatkovsky", "Manoj Aggarwal", "Gerard Medioni"], "title": "Group-Aware Reinforcement Learning for Output Diversity in Large Language Models", "comment": "EMNLP Main 2025", "summary": "Large Language Models (LLMs) often suffer from mode collapse, repeatedly generating the same few completions even when many valid answers exist, limiting their diversity across a wide range of tasks. We introduce Group-Aware Policy Optimization (GAPO), a simple extension of the recent and popular Group Relative Policy Optimization (GRPO) that computes rewards over the group as a whole. GAPO enables learning from the group-level properties such as diversity and coverage. We demonstrate GAPO using a frequency-aware reward function that encourages uniform sampling over valid LLM completions, and show that GAPO-trained models produce valid and more diverse model responses. Beyond this setup, GAPO generalizes to open-ended prompts and improves response diversity without compromising accuracy on standard LLM benchmarks (GSM8K, MATH, HumanEval, MMLU-Pro). Our code will be made publicly available.", "AI": {"tldr": "GAPO\u662f\u4e00\u79cd\u57fa\u4e8eGRPO\u7684\u6269\u5c55\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba1\u7b97\u7fa4\u4f53\u5c42\u9762\u7684\u5956\u52b1\u6765\u9f13\u52b1LLM\u751f\u6210\u66f4\u591a\u6837\u5316\u7684\u54cd\u5e94\uff0c\u89e3\u51b3\u4e86\u6a21\u5f0f\u5d29\u6e83\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ecf\u5e38\u51fa\u73b0\u6a21\u5f0f\u5d29\u6e83\u95ee\u9898\uff0c\u5373\u4f7f\u5b58\u5728\u591a\u4e2a\u6709\u6548\u7b54\u6848\uff0c\u4e5f\u4f1a\u91cd\u590d\u751f\u6210\u76f8\u540c\u7684\u51e0\u4e2a\u8865\u5168\u7ed3\u679c\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u7684\u591a\u6837\u6027\u3002", "method": "GAPO\u662fGRPO\u7684\u7b80\u5355\u6269\u5c55\uff0c\u8ba1\u7b97\u7fa4\u4f53\u5c42\u9762\u7684\u5956\u52b1\uff0c\u4f7f\u7528\u9891\u7387\u611f\u77e5\u7684\u5956\u52b1\u51fd\u6570\u6765\u9f13\u52b1\u5728\u6709\u6548\u8865\u5168\u4e2d\u5747\u5300\u91c7\u6837\u3002", "result": "GAPO\u8bad\u7ec3\u7684\u6a21\u578b\u80fd\u591f\u4ea7\u751f\u6709\u6548\u4e14\u66f4\u591a\u6837\u5316\u7684\u54cd\u5e94\uff0c\u5728\u5f00\u653e\u63d0\u793a\u4e0b\u4e5f\u80fd\u63d0\u9ad8\u54cd\u5e94\u591a\u6837\u6027\uff0c\u540c\u65f6\u4e0d\u5f71\u54cd\u6807\u51c6LLM\u57fa\u51c6\u6d4b\u8bd5\u7684\u51c6\u786e\u6027\u3002", "conclusion": "GAPO\u80fd\u591f\u6709\u6548\u89e3\u51b3LLM\u7684\u6a21\u5f0f\u5d29\u6e83\u95ee\u9898\uff0c\u63d0\u9ad8\u54cd\u5e94\u591a\u6837\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\uff0c\u5177\u6709\u826f\u597d\u7684\u901a\u7528\u6027\u3002"}}
{"id": "2511.12344", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12344", "abs": "https://arxiv.org/abs/2511.12344", "authors": ["Baolong Bi", "Shenghua Liu", "Yiwei Wang", "Siqian Tong", "Lingrui Mei", "Yuyao Ge", "Yilong Xu", "Jiafeng Guo", "Xueqi Cheng"], "title": "Reward and Guidance through Rubrics: Promoting Exploration to Improve Multi-Domain Reasoning", "comment": null, "summary": "Recent advances in reinforcement learning (RL) have significantly improved the complex reasoning capabilities of large language models (LLMs). Despite these successes, existing methods mainly focus on single-domain RL (e.g., mathematics) with verifiable rewards (RLVR), and their reliance on purely online RL frameworks restricts the exploration space, thereby limiting reasoning performance. In this paper, we address these limitations by leveraging rubrics to provide both fine-grained reward signals and offline guidance. We propose $\\textbf{RGR-GRPO}$ (Reward and Guidance through Rubrics), a rubric-driven RL framework for multi-domain reasoning. RGR-GRPO enables LLMs to receive dense and informative rewards while exploring a larger solution space during GRPO training. Extensive experiments across 14 benchmarks spanning multiple domains demonstrate that RGR-GRPO consistently outperforms RL methods that rely solely on alternative reward schemes or offline guidance. Compared with verifiable online RL baseline, RGR-GRPO achieves average improvements of +7.0%, +5.4%, +8.4%, and +6.6% on mathematics, physics, chemistry, and general reasoning tasks, respectively. Notably, RGR-GRPO maintains stable entropy fluctuations during off-policy training and achieves superior pass@k performance, reflecting sustained exploration and effective breakthrough beyond existing performance bottlenecks.", "AI": {"tldr": "\u63d0\u51faRGR-GRPO\u6846\u67b6\uff0c\u901a\u8fc7\u8bc4\u5206\u6807\u51c6\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u5956\u52b1\u548c\u79bb\u7ebf\u6307\u5bfc\uff0c\u5728\u591a\u9886\u57df\u63a8\u7406\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5355\u4e00\u9886\u57df\u4e14\u4f9d\u8d56\u53ef\u9a8c\u8bc1\u5956\u52b1\uff0c\u7eaf\u5728\u7ebfRL\u6846\u67b6\u9650\u5236\u4e86\u63a2\u7d22\u7a7a\u95f4\uff0c\u5f71\u54cd\u4e86\u63a8\u7406\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u8bc4\u5206\u6807\u51c6\u540c\u65f6\u63d0\u4f9b\u5bc6\u96c6\u5956\u52b1\u4fe1\u53f7\u548c\u79bb\u7ebf\u6307\u5bfc\uff0c\u901a\u8fc7GRPO\u8bad\u7ec3\u8ba9LLM\u5728\u66f4\u5927\u89e3\u7a7a\u95f4\u4e2d\u8fdb\u884c\u63a2\u7d22\u3002", "result": "\u572814\u4e2a\u591a\u9886\u57df\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u53ef\u9a8c\u8bc1\u5728\u7ebfRL\u57fa\u7ebf\uff0c\u5728\u6570\u5b66\u3001\u7269\u7406\u3001\u5316\u5b66\u548c\u901a\u7528\u63a8\u7406\u4efb\u52a1\u4e0a\u5206\u522b\u5e73\u5747\u63d0\u53477.0%\u30015.4%\u30018.4%\u548c6.6%\u3002", "conclusion": "RGR-GRPO\u5728\u79bb\u7b56\u7565\u8bad\u7ec3\u4e2d\u4fdd\u6301\u7a33\u5b9a\u7684\u71b5\u6ce2\u52a8\uff0c\u5b9e\u73b0\u6301\u7eed\u7684\u63a2\u7d22\u5e76\u6709\u6548\u7a81\u7834\u73b0\u6709\u6027\u80fd\u74f6\u9888\u3002"}}
{"id": "2511.12609", "categories": ["cs.CL", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.12609", "abs": "https://arxiv.org/abs/2511.12609", "authors": ["Yunxin Li", "Xinyu Chen", "Shenyuan Jiang", "Haoyuan Shi", "Zhenyu Liu", "Xuanyu Zhang", "Nanhao Deng", "Zhenran Xu", "Yicheng Ma", "Meishan Zhang", "Baotian Hu", "Min Zhang"], "title": "Uni-MoE-2.0-Omni: Scaling Language-Centric Omnimodal Large Model with Advanced MoE, Training and Data", "comment": "47 pages,10 Figures, Project Website: https://idealistxy.github.io/Uni-MoE-v2.github.io/; Codes: https://github.com/HITsz-TMG/Uni-MoE", "summary": "We present Uni-MoE 2.0 from the Lychee family. As a fully open-source omnimodal large model (OLM), it substantially advances Lychee's Uni-MoE series in language-centric multimodal understanding, reasoning, and generating. Based on the Qwen2.5-7B dense architecture, we build Uni-MoE-2.0-Omni from scratch through three core contributions: dynamic-capacity Mixture-of-Experts (MoE) design, a progressive training strategy enhanced with an iterative reinforcement strategy, and a carefully curated multimodal data matching technique. It is capable of omnimodal understanding, as well as generating images, text, and speech. Architecturally, our new MoE framework balances computational efficiency and capability for 10 cross-modal inputs using shared, routed, and null experts, while our Omni-Modality 3D RoPE ensures spatio-temporal cross-modality alignment in the self-attention layer. For training, following cross-modal pretraining, we use a progressive supervised fine-tuning strategy that activates modality-specific experts and is enhanced by balanced data composition and an iterative GSPO-DPO method to stabilise RL training and improve reasoning. Data-wise, the base model, trained on approximately 75B tokens of open-source multimodal data, is equipped with special speech and image generation tokens, allowing it to learn these generative tasks by conditioning its outputs on linguistic cues. Extensive evaluation across 85 benchmarks demonstrates that our model achieves SOTA or highly competitive performance against leading OLMs, surpassing Qwen2.5-Omni (trained with 1.2T tokens) on over 50 of 76 benchmarks. Key strengths include video understanding (+7% avg. of 8), omnimodallity understanding (+7% avg. of 4), and audiovisual reasoning (+4%). It also advances long-form speech processing (reducing WER by 4.2%) and leads in low-level image processing and controllable generation across 5 metrics.", "AI": {"tldr": "Uni-MoE 2.0\u662f\u4e00\u4e2a\u5168\u5f00\u6e90\u7684\u8de8\u6a21\u6001\u5927\u6a21\u578b\uff0c\u57fa\u4e8eQwen2.5-7B\u67b6\u6784\u6784\u5efa\uff0c\u91c7\u7528\u52a8\u6001\u5bb9\u91cf\u7684MoE\u8bbe\u8ba1\u3001\u6e10\u8fdb\u5f0f\u8bad\u7ec3\u7b56\u7565\u548c\u7cbe\u5fc3\u7b56\u5212\u7684\u591a\u6a21\u6001\u6570\u636e\u5339\u914d\u6280\u672f\uff0c\u572885\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u63a8\u52a8Lychee Uni-MoE\u7cfb\u5217\u5728\u8bed\u8a00\u4e2d\u5fc3\u7684\u591a\u6a21\u6001\u7406\u89e3\u3001\u63a8\u7406\u548c\u751f\u6210\u65b9\u9762\u7684\u8fdb\u5c55\uff0c\u6784\u5efa\u4e00\u4e2a\u80fd\u591f\u7406\u89e3\u6240\u6709\u6a21\u6001\u5e76\u751f\u6210\u56fe\u50cf\u3001\u6587\u672c\u548c\u8bed\u97f3\u7684\u5168\u80fd\u6a21\u578b\u3002", "method": "\u91c7\u7528\u52a8\u6001\u5bb9\u91cfMoE\u6846\u67b6\uff0c\u5305\u542b\u5171\u4eab\u3001\u8def\u7531\u548c\u7a7a\u4e13\u5bb6\uff1b\u4f7f\u7528Omni-Modality 3D RoPE\u786e\u4fdd\u8de8\u6a21\u6001\u5bf9\u9f50\uff1b\u91c7\u7528\u6e10\u8fdb\u5f0f\u76d1\u7763\u5fae\u8c03\u7b56\u7565\uff0c\u7ed3\u5408GSPO-DPO\u65b9\u6cd5\u7a33\u5b9a\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u3002", "result": "\u572885\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u6216\u9ad8\u5ea6\u7ade\u4e89\u529b\uff0c\u572876\u4e2a\u57fa\u51c6\u4e2d\u8d85\u8fc750\u4e2a\u4f18\u4e8eQwen2.5-Omni\uff1b\u89c6\u9891\u7406\u89e3\u63d0\u53477%\uff0c\u5168\u6a21\u6001\u7406\u89e3\u63d0\u53477%\uff0c\u89c6\u542c\u63a8\u7406\u63d0\u53474%\uff1b\u957f\u8bed\u97f3\u5904\u7406WER\u964d\u4f4e4.2%\u3002", "conclusion": "Uni-MoE 2.0\u8bc1\u660e\u4e86\u5176\u67b6\u6784\u548c\u8bad\u7ec3\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u5728\u591a\u4e2a\u8de8\u6a21\u6001\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u5168\u5f00\u6e90\u8de8\u6a21\u6001\u5927\u6a21\u578b\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2511.12359", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12359", "abs": "https://arxiv.org/abs/2511.12359", "authors": ["Yifan Zhu", "Sammie Katt", "Samuel Kaski"], "title": "More Than Irrational: Modeling Belief-Biased Agents", "comment": "13 pages, 8 figures. Accepted at the 40th Annual AAAI Conference on Artificial Intelligence (AAAI 2026)", "summary": "Despite the explosive growth of AI and the technologies built upon it, predicting and inferring the sub-optimal behavior of users or human collaborators remains a critical challenge. In many cases, such behaviors are not a result of irrationality, but rather a rational decision made given inherent cognitive bounds and biased beliefs about the world. In this paper, we formally introduce a class of computational-rational (CR) user models for cognitively-bounded agents acting optimally under biased beliefs. The key novelty lies in explicitly modeling how a bounded memory process leads to a dynamically inconsistent and biased belief state and, consequently, sub-optimal sequential decision-making. We address the challenge of identifying the latent user-specific bound and inferring biased belief states from passive observations on the fly. We argue that for our formalized CR model family with an explicit and parameterized cognitive process, this challenge is tractable. To support our claim, we propose an efficient online inference method based on nested particle filtering that simultaneously tracks the user's latent belief state and estimates the unknown cognitive bound from a stream of observed actions. We validate our approach in a representative navigation task using memory decay as an example of a cognitive bound. With simulations, we show that (1) our CR model generates intuitively plausible behaviors corresponding to different levels of memory capacity, and (2) our inference method accurately and efficiently recovers the ground-truth cognitive bounds from limited observations ($\\le 100$ steps). We further demonstrate how this approach provides a principled foundation for developing adaptive AI assistants, enabling adaptive assistance that accounts for the user's memory limitations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u8ba1\u7b97\u7406\u6027\u7528\u6237\u6a21\u578b\uff0c\u7528\u4e8e\u5efa\u6a21\u8ba4\u77e5\u53d7\u9650\u7528\u6237\u5728\u504f\u89c1\u4fe1\u5ff5\u4e0b\u7684\u6700\u4f18\u51b3\u7b56\u884c\u4e3a\uff0c\u91cd\u70b9\u89e3\u51b3\u4ece\u88ab\u52a8\u89c2\u5bdf\u4e2d\u63a8\u65ad\u7528\u6237\u8ba4\u77e5\u8fb9\u754c\u548c\u4fe1\u5ff5\u72b6\u6001\u7684\u95ee\u9898\u3002", "motivation": "\u9884\u6d4b\u548c\u7406\u89e3\u7528\u6237\u6b21\u4f18\u884c\u4e3a\u662fAI\u53d1\u5c55\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u8fd9\u4e9b\u884c\u4e3a\u901a\u5e38\u6e90\u4e8e\u8ba4\u77e5\u9650\u5236\u548c\u504f\u89c1\u4fe1\u5ff5\uff0c\u800c\u975e\u975e\u7406\u6027\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5d4c\u5957\u7c92\u5b50\u6ee4\u6ce2\u7684\u5728\u7ebf\u63a8\u7406\u65b9\u6cd5\uff0c\u540c\u65f6\u8ddf\u8e2a\u7528\u6237\u7684\u6f5c\u5728\u4fe1\u5ff5\u72b6\u6001\u5e76\u4ece\u672a\u77e5\u8ba4\u77e5\u8fb9\u754c\u4e2d\u4f30\u8ba1\u53c2\u6570\uff0c\u4ee5\u8bb0\u5fc6\u8870\u51cf\u4e3a\u4f8b\u9a8c\u8bc1\u65b9\u6cd5\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u663e\u793a\uff1a(1)\u6a21\u578b\u80fd\u751f\u6210\u7b26\u5408\u4e0d\u540c\u8bb0\u5fc6\u5bb9\u91cf\u7684\u5408\u7406\u884c\u4e3a\uff1b(2)\u63a8\u7406\u65b9\u6cd5\u80fd\u51c6\u786e\u9ad8\u6548\u5730\u4ece\u6709\u9650\u89c2\u5bdf\u4e2d\u6062\u590d\u771f\u5b9e\u8ba4\u77e5\u8fb9\u754c(\u2264100\u6b65)\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5f00\u53d1\u81ea\u9002\u5e94AI\u52a9\u624b\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u4f7fAI\u80fd\u591f\u9002\u5e94\u7528\u6237\u7684\u8bb0\u5fc6\u9650\u5236\uff0c\u63d0\u4f9b\u4e2a\u6027\u5316\u8f85\u52a9\u3002"}}
{"id": "2511.12630", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12630", "abs": "https://arxiv.org/abs/2511.12630", "authors": ["Maoqi Liu", "Quan Fang", "Yang Yang", "Can Zhao", "Kaiquan Cai"], "title": "Knots: A Large-Scale Multi-Agent Enhanced Expert-Annotated Dataset and LLM Prompt Optimization for NOTAM Semantic Parsing", "comment": "Accepted to Advanced Engineering Informatics", "summary": "Notice to Air Missions (NOTAMs) serve as a critical channel for disseminating key flight safety information, yet their complex linguistic structures and implicit reasoning pose significant challenges for automated parsing. Existing research mainly focuses on surface-level tasks such as classification and named entity recognition, lacking deep semantic understanding. To address this gap, we propose NOTAM semantic parsing, a task emphasizing semantic inference and the integration of aviation domain knowledge to produce structured, inference-rich outputs. To support this task, we construct Knots (Knowledge and NOTAM Semantics), a high-quality dataset of 12,347 expert-annotated NOTAMs covering 194 Flight Information Regions, enhanced through a multi-agent collaborative framework for comprehensive field discovery. We systematically evaluate a wide range of prompt-engineering strategies and model-adaptation techniques, achieving substantial improvements in aviation text understanding and processing. Our experimental results demonstrate the effectiveness of the proposed approach and offer valuable insights for automated NOTAM analysis systems. Our code is available at: https://github.com/Estrellajer/Knots.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86NOTAM\u8bed\u4e49\u89e3\u6790\u4efb\u52a1\uff0c\u6784\u5efa\u4e86Knots\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\u548c\u591a\u79cd\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u822a\u7a7a\u6587\u672c\u7684\u7406\u89e3\u80fd\u529b\u3002", "motivation": "NOTAMs\u4f5c\u4e3a\u98de\u884c\u5b89\u5168\u4fe1\u606f\u7684\u5173\u952e\u6e20\u9053\uff0c\u5176\u590d\u6742\u7684\u8bed\u8a00\u7ed3\u6784\u548c\u9690\u542b\u63a8\u7406\u7ed9\u81ea\u52a8\u5316\u89e3\u6790\u5e26\u6765\u6311\u6218\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5206\u7c7b\u548c\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7b49\u8868\u5c42\u4efb\u52a1\uff0c\u7f3a\u4e4f\u6df1\u5ea6\u8bed\u4e49\u7406\u89e3\u3002", "method": "\u63d0\u51faNOTAM\u8bed\u4e49\u89e3\u6790\u4efb\u52a1\uff0c\u6784\u5efa\u5305\u542b12,347\u6761\u4e13\u5bb6\u6807\u6ce8NOTAMs\u7684Knots\u6570\u636e\u96c6\uff0c\u91c7\u7528\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\u8fdb\u884c\u5168\u9762\u7684\u5b57\u6bb5\u53d1\u73b0\uff0c\u5e76\u7cfb\u7edf\u8bc4\u4f30\u591a\u79cd\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\u548c\u6a21\u578b\u9002\u914d\u6280\u672f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u822a\u7a7a\u6587\u672c\u7406\u89e3\u548c\u5904\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u4e3a\u81ea\u52a8\u5316NOTAM\u5206\u6790\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86NOTAMs\u7684\u8bed\u4e49\u89e3\u6790\u6311\u6218\uff0c\u901a\u8fc7\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\uff0c\u80fd\u591f\u751f\u6210\u7ed3\u6784\u5316\u7684\u3001\u5bcc\u542b\u63a8\u7406\u4fe1\u606f\u7684\u8f93\u51fa\u3002"}}
{"id": "2511.12378", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12378", "abs": "https://arxiv.org/abs/2511.12378", "authors": ["Dylan M. Asmar", "Mykel J. Kochenderfer"], "title": "Learning to Trust: Bayesian Adaptation to Varying Suggester Reliability in Sequential Decision Making", "comment": "Under Review", "summary": "Autonomous agents operating in sequential decision-making tasks under uncertainty can benefit from external action suggestions, which provide valuable guidance but inherently vary in reliability. Existing methods for incorporating such advice typically assume static and known suggester quality parameters, limiting practical deployment. We introduce a framework that dynamically learns and adapts to varying suggester reliability in partially observable environments. First, we integrate suggester quality directly into the agent's belief representation, enabling agents to infer and adjust their reliance on suggestions through Bayesian inference over suggester types. Second, we introduce an explicit ``ask'' action allowing agents to strategically request suggestions at critical moments, balancing informational gains against acquisition costs. Experimental evaluation demonstrates robust performance across varying suggester qualities, adaptation to changing reliability, and strategic management of suggestion requests. This work provides a foundation for adaptive human-agent collaboration by addressing suggestion uncertainty in uncertain environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u52a8\u6001\u5b66\u4e60\u5efa\u8bae\u8005\u53ef\u9760\u6027\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u63a8\u65ad\u548c\u663e\u5f0f\u8be2\u95ee\u52a8\u4f5c\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u81ea\u9002\u5e94\u5730\u5229\u7528\u5916\u90e8\u5efa\u8bae\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u5efa\u8bae\u8005\u8d28\u91cf\u53c2\u6570\u662f\u9759\u6001\u4e14\u5df2\u77e5\u7684\uff0c\u8fd9\u9650\u5236\u4e86\u5b9e\u9645\u90e8\u7f72\u3002\u9700\u8981\u80fd\u591f\u52a8\u6001\u5b66\u4e60\u548c\u9002\u5e94\u53d8\u5316\u5efa\u8bae\u8005\u53ef\u9760\u6027\u7684\u65b9\u6cd5\u3002", "method": "1. \u5c06\u5efa\u8bae\u8005\u8d28\u91cf\u76f4\u63a5\u96c6\u6210\u5230\u667a\u80fd\u4f53\u7684\u4fe1\u5ff5\u8868\u793a\u4e2d\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u63a8\u65ad\u5b66\u4e60\u5efa\u8bae\u8005\u7c7b\u578b\uff1b2. \u5f15\u5165\u663e\u5f0f\u7684\"\u8be2\u95ee\"\u52a8\u4f5c\uff0c\u5141\u8bb8\u667a\u80fd\u4f53\u5728\u5173\u952e\u65f6\u523b\u6218\u7565\u6027\u5730\u8bf7\u6c42\u5efa\u8bae\uff0c\u5e73\u8861\u4fe1\u606f\u6536\u76ca\u4e0e\u83b7\u53d6\u6210\u672c\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u5efa\u8bae\u8005\u8d28\u91cf\u4e0b\u5177\u6709\u9c81\u68d2\u6027\u80fd\uff0c\u80fd\u591f\u9002\u5e94\u53d8\u5316\u7684\u53ef\u9760\u6027\uff0c\u5e76\u6709\u6548\u7ba1\u7406\u5efa\u8bae\u8bf7\u6c42\u7b56\u7565\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u901a\u8fc7\u89e3\u51b3\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7684\u5efa\u8bae\u4e0d\u786e\u5b9a\u6027\uff0c\u4e3a\u81ea\u9002\u5e94\u4eba\u673a\u534f\u4f5c\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.12661", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12661", "abs": "https://arxiv.org/abs/2511.12661", "authors": ["Yuchen Wu", "Liang Ding", "Li Shen", "Dacheng Tao"], "title": "Reason-KE++: Aligning the Process, Not Just the Outcome, for Faithful LLM Knowledge Editing", "comment": null, "summary": "Aligning Large Language Models (LLMs) to be faithful to new knowledge in complex, multi-hop reasoning tasks is a critical, yet unsolved, challenge. We find that SFT-based methods, e.g., Reason-KE, while state-of-the-art, suffer from a \"faithfulness gap\": they optimize for format mimicry rather than sound reasoning. This gap enables the LLM's powerful parametric priors to override new contextual facts, resulting in critical factual hallucinations (e.g., incorrectly reasoning \"Houston\" from \"NASA\" despite an explicit edit). To solve this core LLM alignment problem, we propose Reason-KE++, an SFT+RL framework that instills process-level faithfulness. Its core is a Stage-aware Reward mechanism that provides dense supervision for intermediate reasoning steps (e.g., Decomposition, Sub-answer Correctness). Crucially, we identify that naive outcome-only RL is a deceptive trap for LLM alignment: it collapses reasoning integrity (e.g., 19.00% Hop acc) while superficially boosting final accuracy. Our process-aware framework sets a new SOTA of 95.48% on MQUAKE-CF-3k (+5.28%), demonstrating that for complex tasks, aligning the reasoning process is essential for building trustworthy LLMs.", "AI": {"tldr": "Reason-KE++\u662f\u4e00\u4e2aSFT+RL\u6846\u67b6\uff0c\u901a\u8fc7\u8fc7\u7a0b\u7ea7\u5fe0\u5b9e\u6027\u5bf9\u9f50\u6765\u89e3\u51b3LLM\u5728\u590d\u6742\u591a\u8df3\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u4e8b\u5b9e\u5e7b\u89c9\u95ee\u9898\uff0c\u5728MQUAKE-CF-3k\u4e0a\u8fbe\u523095.48%\u7684\u65b0SOTA\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u590d\u6742\u591a\u8df3\u63a8\u7406\u4efb\u52a1\u4e2d\u5bf9\u65b0\u77e5\u8bc6\u7684\u5fe0\u5b9e\u6027\u95ee\u9898\uff0c\u73b0\u6709SFT\u65b9\u6cd5\u5b58\u5728\"\u5fe0\u5b9e\u6027\u5dee\u8ddd\"\uff0c\u5bfc\u81f4\u6a21\u578b\u53c2\u6570\u5148\u9a8c\u8986\u76d6\u4e0a\u4e0b\u6587\u4e8b\u5b9e\uff0c\u4ea7\u751f\u5173\u952e\u4e8b\u5b9e\u5e7b\u89c9\u3002", "method": "\u63d0\u51faReason-KE++\u6846\u67b6\uff0c\u7ed3\u5408SFT\u548cRL\uff0c\u6838\u5fc3\u662f\u9636\u6bb5\u611f\u77e5\u5956\u52b1\u673a\u5236\uff0c\u4e3a\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u63d0\u4f9b\u5bc6\u96c6\u76d1\u7763\uff0c\u5305\u62ec\u5206\u89e3\u548c\u5b50\u7b54\u6848\u6b63\u786e\u6027\u7b49\u8fc7\u7a0b\u7ea7\u8bc4\u4f30\u3002", "result": "\u5728MQUAKE-CF-3k\u6570\u636e\u96c6\u4e0a\u8fbe\u523095.48%\u7684\u51c6\u786e\u7387\uff0c\u76f8\u6bd4\u4e4b\u524d\u65b9\u6cd5\u63d0\u53475.28%\uff0c\u540c\u65f6\u907f\u514d\u4e86\u4ec5\u57fa\u4e8e\u7ed3\u679c\u7684RL\u65b9\u6cd5\u5bfc\u81f4\u63a8\u7406\u5b8c\u6574\u6027\u5d29\u6e83\u7684\u95ee\u9898\u3002", "conclusion": "\u5bf9\u4e8e\u590d\u6742\u4efb\u52a1\uff0c\u5bf9\u9f50\u63a8\u7406\u8fc7\u7a0b\u5bf9\u4e8e\u6784\u5efa\u53ef\u4fe1\u8d56\u7684LLM\u81f3\u5173\u91cd\u8981\uff0c\u8fc7\u7a0b\u611f\u77e5\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3LLM\u5bf9\u9f50\u7684\u6838\u5fc3\u95ee\u9898\u3002"}}
{"id": "2511.12439", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.12439", "abs": "https://arxiv.org/abs/2511.12439", "authors": ["Yujia Liu", "Sophia Yu", "Hongyue Jin", "Jessica Wen", "Alexander Qian", "Terrence Lee", "Mattheus Ramsis", "Gi Won Choi", "Lianhui Qin", "Xin Liu", "Edward J. Wang"], "title": "Multi-agent Self-triage System with Medical Flowcharts", "comment": null, "summary": "Online health resources and large language models (LLMs) are increasingly used as a first point of contact for medical decision-making, yet their reliability in healthcare remains limited by low accuracy, lack of transparency, and susceptibility to unverified information. We introduce a proof-of-concept conversational self-triage system that guides LLMs with 100 clinically validated flowcharts from the American Medical Association, providing a structured and auditable framework for patient decision support. The system leverages a multi-agent framework consisting of a retrieval agent, a decision agent, and a chat agent to identify the most relevant flowchart, interpret patient responses, and deliver personalized, patient-friendly recommendations, respectively. Performance was evaluated at scale using synthetic datasets of simulated conversations. The system achieved 95.29% top-3 accuracy in flowchart retrieval (N=2,000) and 99.10% accuracy in flowchart navigation across varied conversational styles and conditions (N=37,200). By combining the flexibility of free-text interaction with the rigor of standardized clinical protocols, this approach demonstrates the feasibility of transparent, accurate, and generalizable AI-assisted self-triage, with potential to support informed patient decision-making while improving healthcare resource utilization.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4e34\u5e8a\u9a8c\u8bc1\u6d41\u7a0b\u56fe\u7684\u5bf9\u8bdd\u5f0f\u81ea\u6211\u5206\u8bca\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5b9e\u73b095.29%\u7684\u6d41\u7a0b\u56fe\u68c0\u7d22\u51c6\u786e\u7387\u548c99.10%\u7684\u5bfc\u822a\u51c6\u786e\u7387\uff0c\u7ed3\u5408\u81ea\u7531\u6587\u672c\u4ea4\u4e92\u7684\u7075\u6d3b\u6027\u548c\u6807\u51c6\u5316\u4e34\u5e8a\u534f\u8bae\u7684\u4e25\u8c28\u6027\u3002", "motivation": "\u5728\u7ebf\u5065\u5eb7\u8d44\u6e90\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u51b3\u7b56\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5176\u53ef\u9760\u6027\u53d7\u5230\u51c6\u786e\u6027\u4f4e\u3001\u7f3a\u4e4f\u900f\u660e\u5ea6\u548c\u6613\u53d7\u672a\u7ecf\u9a8c\u8bc1\u4fe1\u606f\u5f71\u54cd\u7684\u9650\u5236\u3002", "method": "\u4f7f\u7528\u7f8e\u56fd\u533b\u5b66\u4f1a100\u4e2a\u4e34\u5e8a\u9a8c\u8bc1\u6d41\u7a0b\u56fe\u6784\u5efa\u5bf9\u8bdd\u5f0f\u81ea\u6211\u5206\u8bca\u7cfb\u7edf\uff0c\u91c7\u7528\u5305\u542b\u68c0\u7d22\u667a\u80fd\u4f53\u3001\u51b3\u7b56\u667a\u80fd\u4f53\u548c\u804a\u5929\u667a\u80fd\u4f53\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5206\u522b\u8d1f\u8d23\u8bc6\u522b\u76f8\u5173\u6d41\u7a0b\u56fe\u3001\u89e3\u91ca\u60a3\u8005\u54cd\u5e94\u548c\u63d0\u4f9b\u4e2a\u6027\u5316\u5efa\u8bae\u3002", "result": "\u5728\u5927\u89c4\u6a21\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u7cfb\u7edf\u5728\u6d41\u7a0b\u56fe\u68c0\u7d22\u65b9\u9762\u8fbe\u523095.29%\u7684top-3\u51c6\u786e\u7387\uff08N=2,000\uff09\uff0c\u5728\u6d41\u7a0b\u56fe\u5bfc\u822a\u65b9\u9762\u8fbe\u523099.10%\u7684\u51c6\u786e\u7387\uff08N=37,200\uff09\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u900f\u660e\u3001\u51c6\u786e\u4e14\u53ef\u63a8\u5e7f\u7684AI\u8f85\u52a9\u81ea\u6211\u5206\u8bca\u7684\u53ef\u884c\u6027\uff0c\u6709\u6f5c\u529b\u652f\u6301\u60a3\u8005\u77e5\u60c5\u51b3\u7b56\u5e76\u6539\u5584\u533b\u7597\u8d44\u6e90\u5229\u7528\u3002"}}
{"id": "2511.12690", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12690", "abs": "https://arxiv.org/abs/2511.12690", "authors": ["Sina Rashidi", "Hossein Sameti"], "title": "Improving Direct Persian-English Speech-to-Speech Translation with Discrete Units and Synthetic Parallel Data", "comment": null, "summary": "Direct speech-to-speech translation (S2ST), in which all components are trained jointly, is an attractive alternative to cascaded systems because it offers a simpler pipeline and lower inference latency. However, direct S2ST models require large amounts of parallel speech data in the source and target languages, which are rarely available for low-resource languages such as Persian. This paper presents a direct S2ST system for translating Persian speech into English speech, as well as a pipeline for synthetic parallel Persian-English speech generation. The model comprises three components: (1) a conformer-based encoder, initialized from self-supervised pre-training, maps source speech to high-level acoustic representations; (2) a causal transformer decoder with relative position multi-head attention translates these representations into discrete target speech units; (3) a unit-based neural vocoder generates waveforms from the predicted discrete units. To mitigate the data scarcity problem, we construct a new Persian-English parallel speech corpus by translating Persian speech transcriptions into English using a large language model and then synthesizing the corresponding English speech with a state-of-the-art zero-shot text-to-speech system. The resulting corpus increases the amount of available parallel speech by roughly a factor of six. On the Persian-English portion of the CVSS corpus, the proposed model achieves improvement of 4.6 ASR BLEU with the synthetic data over direct baselines. These results indicate that combining self-supervised pre-training, discrete speech units, and synthetic parallel data is effective for improving direct S2ST in low-resource language pairs such as Persian-English", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6ce2\u65af\u8bed\u5230\u82f1\u8bed\u7684\u76f4\u63a5\u8bed\u97f3\u7ffb\u8bd1\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u3001\u79bb\u6563\u8bed\u97f3\u5355\u5143\u548c\u5408\u6210\u5e73\u884c\u6570\u636e\u6765\u89e3\u51b3\u4f4e\u8d44\u6e90\u8bed\u8a00\u5bf9\u7684\u8bed\u97f3\u7ffb\u8bd1\u95ee\u9898\u3002", "motivation": "\u76f4\u63a5\u8bed\u97f3\u7ffb\u8bd1\u7cfb\u7edf\u9700\u8981\u5927\u91cf\u7684\u5e73\u884c\u8bed\u97f3\u6570\u636e\uff0c\u4f46\u5bf9\u4e8e\u6ce2\u65af\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u6765\u8bf4\uff0c\u8fd9\u79cd\u6570\u636e\u975e\u5e38\u7a00\u7f3a\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u6ce2\u65af\u8bed-\u82f1\u8bed\u8bed\u8a00\u5bf9\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002", "method": "\u7cfb\u7edf\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u57fa\u4e8econformer\u7684\u7f16\u7801\u5668\u3001\u56e0\u679ctransformer\u89e3\u7801\u5668\u548c\u57fa\u4e8e\u5355\u5143\u7684\u795e\u7ecf\u58f0\u7801\u5668\u3002\u901a\u8fc7\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7ffb\u8bd1\u6ce2\u65af\u8bed\u8bed\u97f3\u8f6c\u5f55\u5e76\u5408\u6210\u82f1\u8bed\u8bed\u97f3\uff0c\u6784\u5efa\u4e86\u5408\u6210\u5e73\u884c\u8bed\u97f3\u8bed\u6599\u5e93\u3002", "result": "\u5728CVSS\u8bed\u6599\u5e93\u7684\u6ce2\u65af\u8bed-\u82f1\u8bed\u90e8\u5206\uff0c\u4f7f\u7528\u5408\u6210\u6570\u636e\u6bd4\u76f4\u63a5\u57fa\u7ebf\u63d0\u9ad8\u4e864.6 ASR BLEU\u3002\u5408\u6210\u8bed\u6599\u5e93\u4f7f\u53ef\u7528\u5e73\u884c\u8bed\u97f3\u6570\u636e\u589e\u52a0\u4e86\u7ea66\u500d\u3002", "conclusion": "\u7ed3\u5408\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u3001\u79bb\u6563\u8bed\u97f3\u5355\u5143\u548c\u5408\u6210\u5e73\u884c\u6570\u636e\u5bf9\u4e8e\u6539\u5584\u6ce2\u65af\u8bed-\u82f1\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u5bf9\u7684\u76f4\u63a5\u8bed\u97f3\u7ffb\u8bd1\u662f\u6709\u6548\u7684\u3002"}}
{"id": "2511.12485", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12485", "abs": "https://arxiv.org/abs/2511.12485", "authors": ["Pengze Li", "Jiaqi Liu", "Junchi Yu", "Lihao Liu", "Mingyu Ding", "Wanli Ouyang", "Shixiang Tang", "Xi Chen"], "title": "ARCHE: A Novel Task to Evaluate LLMs on Latent Reasoning Chain Extraction", "comment": "Accepted to AAAI 2026", "summary": "Large language models (LLMs) are increasingly used in scientific domains. While they can produce reasoning-like content via methods such as chain-of-thought prompting, these outputs are typically unstructured and informal, obscuring whether models truly understand the fundamental reasoning paradigms that underpin scientific inference. To address this, we introduce a novel task named Latent Reasoning Chain Extraction (ARCHE), in which models must decompose complex reasoning arguments into combinations of standard reasoning paradigms in the form of a Reasoning Logic Tree (RLT). In RLT, all reasoning steps are explicitly categorized as one of three variants of Peirce's fundamental inference modes: deduction, induction, or abduction. To facilitate this task, we release ARCHE Bench, a new benchmark derived from 70 Nature Communications articles, including more than 1,900 references and 38,000 viewpoints. We propose two logic-aware evaluation metrics: Entity Coverage (EC) for content completeness and Reasoning Edge Accuracy (REA) for step-by-step logical validity. Evaluations on 10 leading LLMs on ARCHE Bench reveal that models exhibit a trade-off between REA and EC, and none are yet able to extract a complete and standard reasoning chain. These findings highlight a substantial gap between the abilities of current reasoning models and the rigor required for scientific argumentation.", "AI": {"tldr": "\u63d0\u51fa\u4e86ARCHE\u4efb\u52a1\u548cARCHE Bench\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u4ece\u79d1\u5b66\u6587\u732e\u4e2d\u63d0\u53d6\u6807\u51c6\u63a8\u7406\u94fe\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u63a8\u7406\u5b8c\u6574\u6027\u548c\u903b\u8f91\u6709\u6548\u6027\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002", "motivation": "\u5f53\u524dLLM\u751f\u6210\u7684\u63a8\u7406\u5185\u5bb9\u901a\u5e38\u662f\u975e\u7ed3\u6784\u5316\u548c\u975e\u6b63\u5f0f\u7684\uff0c\u96be\u4ee5\u5224\u65ad\u6a21\u578b\u662f\u5426\u771f\u6b63\u7406\u89e3\u79d1\u5b66\u63a8\u7406\u7684\u57fa\u672c\u8303\u5f0f\uff0c\u9700\u8981\u8bc4\u4f30\u6a21\u578b\u63d0\u53d6\u6807\u51c6\u63a8\u7406\u94fe\u7684\u80fd\u529b\u3002", "method": "\u5f15\u5165ARCHE\u4efb\u52a1\uff0c\u8981\u6c42\u6a21\u578b\u5c06\u590d\u6742\u63a8\u7406\u5206\u89e3\u4e3a\u63a8\u7406\u903b\u8f91\u6811(RLT)\uff0c\u5176\u4e2d\u6240\u6709\u63a8\u7406\u6b65\u9aa4\u90fd\u660e\u786e\u5206\u7c7b\u4e3a\u6f14\u7ece\u3001\u5f52\u7eb3\u6216\u6eaf\u56e0\u4e09\u79cd\u57fa\u672c\u63a8\u7406\u6a21\u5f0f\u3002\u521b\u5efaARCHE Bench\u57fa\u51c6\uff0c\u5305\u542b70\u7bc7Nature Communications\u6587\u7ae0\u76841900\u591a\u4e2a\u5f15\u7528\u548c38000\u4e2a\u89c2\u70b9\u3002", "result": "\u8bc4\u4f3010\u4e2a\u9886\u5148LLM\u53d1\u73b0\uff0c\u6a21\u578b\u5728\u63a8\u7406\u8fb9\u51c6\u786e\u7387(REA)\u548c\u5b9e\u4f53\u8986\u76d6\u7387(EC)\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u6ca1\u6709\u4e00\u4e2a\u6a21\u578b\u80fd\u591f\u63d0\u53d6\u5b8c\u6574\u4e14\u6807\u51c6\u7684\u63a8\u7406\u94fe\u3002", "conclusion": "\u5f53\u524d\u63a8\u7406\u6a21\u578b\u7684\u80fd\u529b\u4e0e\u79d1\u5b66\u8bba\u8bc1\u6240\u9700\u7684\u4e25\u8c28\u6027\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002"}}
{"id": "2511.12710", "categories": ["cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.12710", "abs": "https://arxiv.org/abs/2511.12710", "authors": ["Yunhao Chen", "Xin Wang", "Juncheng Li", "Yixu Wang", "Jie Li", "Yan Teng", "Yingchun Wang", "Xingjun Ma"], "title": "Evolve the Method, Not the Prompts: Evolutionary Synthesis of Jailbreak Attacks on LLMs", "comment": null, "summary": "Automated red teaming frameworks for Large Language Models (LLMs) have become increasingly sophisticated, yet they share a fundamental limitation: their jailbreak logic is confined to selecting, combining, or refining pre-existing attack strategies. This binds their creativity and leaves them unable to autonomously invent entirely new attack mechanisms. To overcome this gap, we introduce \\textbf{EvoSynth}, an autonomous framework that shifts the paradigm from attack planning to the evolutionary synthesis of jailbreak methods. Instead of refining prompts, EvoSynth employs a multi-agent system to autonomously engineer, evolve, and execute novel, code-based attack algorithms. Crucially, it features a code-level self-correction loop, allowing it to iteratively rewrite its own attack logic in response to failure. Through extensive experiments, we demonstrate that EvoSynth not only establishes a new state-of-the-art by achieving an 85.5\\% Attack Success Rate (ASR) against highly robust models like Claude-Sonnet-4.5, but also generates attacks that are significantly more diverse than those from existing methods. We release our framework to facilitate future research in this new direction of evolutionary synthesis of jailbreak methods. Code is available at: https://github.com/dongdongunique/EvoSynth.", "AI": {"tldr": "EvoSynth\u662f\u4e00\u4e2a\u81ea\u4e3b\u6846\u67b6\uff0c\u901a\u8fc7\u8fdb\u5316\u5408\u6210\u4ee3\u7801\u7ea7\u653b\u51fb\u7b97\u6cd5\u6765\u5b9e\u73b0\u5bf9LLM\u7684\u8d8a\u72f1\u653b\u51fb\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u80fd\u81ea\u4e3b\u53d1\u660e\u5168\u65b0\u653b\u51fb\u673a\u5236\uff0c\u5728Claude-Sonnet-4.5\u4e0a\u8fbe\u523085.5%\u7684\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u7ea2\u961f\u6846\u67b6\u7684\u8d8a\u72f1\u903b\u8f91\u5c40\u9650\u4e8e\u9009\u62e9\u3001\u7ec4\u5408\u6216\u6539\u8fdb\u73b0\u6709\u653b\u51fb\u7b56\u7565\uff0c\u65e0\u6cd5\u81ea\u4e3b\u53d1\u660e\u5168\u65b0\u653b\u51fb\u673a\u5236\uff0c\u9650\u5236\u4e86\u5176\u521b\u9020\u529b\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u81ea\u4e3b\u8bbe\u8ba1\u3001\u8fdb\u5316\u548c\u6267\u884c\u57fa\u4e8e\u4ee3\u7801\u7684\u65b0\u578b\u653b\u51fb\u7b97\u6cd5\uff0c\u5305\u542b\u4ee3\u7801\u7ea7\u81ea\u6821\u6b63\u5faa\u73af\uff0c\u80fd\u591f\u6839\u636e\u5931\u8d25\u60c5\u51b5\u8fed\u4ee3\u91cd\u5199\u653b\u51fb\u903b\u8f91\u3002", "result": "\u5728Claude-Sonnet-4.5\u7b49\u5f3a\u5065\u6a21\u578b\u4e0a\u8fbe\u523085.5%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u751f\u6210\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u591a\u6837\u5316\u7684\u653b\u51fb\u65b9\u5f0f\uff0c\u5efa\u7acb\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "EvoSynth\u901a\u8fc7\u5c06\u8303\u5f0f\u4ece\u653b\u51fb\u89c4\u5212\u8f6c\u5411\u8fdb\u5316\u5408\u6210\uff0c\u6210\u529f\u514b\u670d\u4e86\u73b0\u6709\u6846\u67b6\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u8d8a\u72f1\u65b9\u6cd5\u7684\u8fdb\u5316\u5408\u6210\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2511.12563", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12563", "abs": "https://arxiv.org/abs/2511.12563", "authors": ["Eljas Linna", "Kestutis Baltakys", "Alexandros Iosifidis", "Juho Kanniainen"], "title": "LOBERT: Generative AI Foundation Model for Limit Order Book Messages", "comment": "Submission for NeurIPS 2025 GenAI in Finance Workshop", "summary": "Modeling the dynamics of financial Limit Order Books (LOB) at the message level is challenging due to irregular event timing, rapid regime shifts, and the reactions of high-frequency traders to visible order flow. Previous LOB models require cumbersome data representations and lack adaptability outside their original tasks, leading us to introduce LOBERT, a general-purpose encoder-only foundation model for LOB data suitable for downstream fine-tuning. LOBERT adapts the original BERT architecture for LOB data by using a novel tokenization scheme that treats complete multi-dimensional messages as single tokens while retaining continuous representations of price, volume, and time. With these methods, LOBERT achieves leading performance in tasks such as predicting mid-price movements and next messages, while reducing the required context length compared to previous methods.", "AI": {"tldr": "LOBERT\u662f\u4e00\u4e2a\u9488\u5bf9\u9650\u4ef7\u8ba2\u5355\u7c3f\u6570\u636e\u7684\u901a\u7528\u7f16\u7801\u5668\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6807\u8bb0\u5316\u65b9\u6848\u5904\u7406\u591a\u7ef4\u6d88\u606f\uff0c\u5728\u9884\u6d4b\u4e2d\u95f4\u4ef7\u683c\u53d8\u52a8\u548c\u4e0b\u4e00\u6d88\u606f\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u9886\u5148\u3002", "motivation": "\u73b0\u6709LOB\u6a21\u578b\u9700\u8981\u7e41\u7410\u7684\u6570\u636e\u8868\u793a\uff0c\u7f3a\u4e4f\u539f\u59cb\u4efb\u52a1\u4e4b\u5916\u7684\u9002\u5e94\u6027\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u9002\u5408\u4e0b\u6e38\u5fae\u8c03\u7684\u901a\u7528\u57fa\u7840\u6a21\u578b\u3002", "method": "LOBERT\u57fa\u4e8eBERT\u67b6\u6784\uff0c\u91c7\u7528\u65b0\u9896\u7684\u6807\u8bb0\u5316\u65b9\u6848\u5c06\u5b8c\u6574\u7684\u591a\u7ef4\u6d88\u606f\u4f5c\u4e3a\u5355\u4e2a\u6807\u8bb0\u5904\u7406\uff0c\u540c\u65f6\u4fdd\u7559\u4ef7\u683c\u3001\u4ea4\u6613\u91cf\u548c\u65f6\u95f4\u7684\u8fde\u7eed\u8868\u793a\u3002", "result": "LOBERT\u5728\u9884\u6d4b\u4e2d\u95f4\u4ef7\u683c\u53d8\u52a8\u548c\u4e0b\u4e00\u6d88\u606f\u7b49\u4efb\u52a1\u4e2d\u53d6\u5f97\u9886\u5148\u6027\u80fd\uff0c\u540c\u65f6\u76f8\u6bd4\u5148\u524d\u65b9\u6cd5\u51cf\u5c11\u4e86\u6240\u9700\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u3002", "conclusion": "LOBERT\u4e3aLOB\u6570\u636e\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u901a\u7528\u57fa\u7840\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u4e14\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u3002"}}
{"id": "2511.12712", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12712", "abs": "https://arxiv.org/abs/2511.12712", "authors": ["Christopher Cruz"], "title": "Adaptive Focus Memory for Language Models", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed in multi-turn dialogue settings, but their behavior is still bottlenecked by fixed context windows and naive memory strategies. Replaying the full conversation at every turn is simple but expensive, while static summarization or recency-only heuristics often erase safety-critical user details. We present Adaptive Focus Memory (AFM), a dynamic context manager that assigns each past message one of three fidelity levels -- FULL, COMPRESSED, or PLACEHOLDER -- based on semantic similarity to the current query, half-life recency weighting, and importance classification. AFM packs messages chronologically under a strict token budget, preferring high fidelity for the most relevant turns while aiming to preserve a cheap trace of the dialogue. In a safety-oriented benchmark involving a user with a severe peanut allergy planning a trip to Thailand, AFM retains the allergy across both short and medium-length conversations, matches the safety performance of naive replay, and cuts average token usage by 66% relative to a replay baseline. We release a modular Python implementation of AFM designed for OpenAI-compatible APIs and offline operation, enabling practitioners to reduce inference cost without sacrificing safety or factual continuity in the evaluated scenario.", "AI": {"tldr": "AFM\u662f\u4e00\u79cd\u52a8\u6001\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\uff0c\u901a\u8fc7\u8bed\u4e49\u76f8\u4f3c\u5ea6\u3001\u65f6\u95f4\u8870\u51cf\u548c\u91cd\u8981\u6027\u5206\u7c7b\u4e3a\u5386\u53f2\u6d88\u606f\u5206\u914d\u4e09\u79cd\u4fdd\u771f\u5ea6\u7ea7\u522b\uff0c\u5728\u4e25\u683ctoken\u9884\u7b97\u4e0b\u663e\u8457\u51cf\u5c11\u63a8\u7406\u6210\u672c\u540c\u65f6\u4fdd\u6301\u5b89\u5168\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u56fa\u5b9a\u4e0a\u4e0b\u6587\u7a97\u53e3\u548c\u6734\u7d20\u5185\u5b58\u7b56\u7565\u7684\u74f6\u9888\u95ee\u9898\uff0c\u907f\u514d\u9759\u6001\u6458\u8981\u6216\u4ec5\u57fa\u4e8e\u65b0\u8fd1\u5ea6\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u4e22\u5931\u5173\u952e\u5b89\u5168\u7ec6\u8282\u3002", "method": "AFM\u4e3a\u6bcf\u4e2a\u5386\u53f2\u6d88\u606f\u5206\u914dFULL\u3001COMPRESSED\u6216PLACEHOLDER\u4fdd\u771f\u5ea6\u7ea7\u522b\uff0c\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u5ea6\u3001\u534a\u8870\u671f\u65b0\u8fd1\u5ea6\u52a0\u6743\u548c\u91cd\u8981\u6027\u5206\u7c7b\uff0c\u5728token\u9884\u7b97\u5185\u6309\u65f6\u95f4\u987a\u5e8f\u6253\u5305\u6d88\u606f\u3002", "result": "\u5728\u6d89\u53ca\u4e25\u91cd\u82b1\u751f\u8fc7\u654f\u7528\u6237\u89c4\u5212\u6cf0\u56fd\u65c5\u884c\u7684\u5b89\u5168\u5bfc\u5411\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAFM\u5728\u77ed\u4e2d\u957f\u5ea6\u5bf9\u8bdd\u4e2d\u4fdd\u6301\u8fc7\u654f\u4fe1\u606f\uff0c\u5b89\u5168\u6027\u80fd\u4e0e\u6734\u7d20\u91cd\u653e\u76f8\u5f53\uff0c\u5e73\u5747token\u4f7f\u7528\u91cf\u6bd4\u91cd\u653e\u57fa\u7ebf\u51cf\u5c1166%\u3002", "conclusion": "AFM\u63d0\u4f9b\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u5b9e\u73b0\uff0c\u53ef\u5728\u4e0d\u727a\u7272\u5b89\u5168\u6027\u6216\u4e8b\u5b9e\u8fde\u7eed\u6027\u7684\u524d\u63d0\u4e0b\u663e\u8457\u964d\u4f4e\u63a8\u7406\u6210\u672c\uff0c\u9002\u7528\u4e8eOpenAI\u517c\u5bb9API\u548c\u79bb\u7ebf\u64cd\u4f5c\u3002"}}
{"id": "2511.12579", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12579", "abs": "https://arxiv.org/abs/2511.12579", "authors": ["Yongwen Ren", "Chao Wang", "Peng Du", "Chuan Qin", "Dazhong Shen", "Hui Xiong"], "title": "Enhancing Conversational Recommender Systems with Tree-Structured Knowledge and Pretrained Language Models", "comment": null, "summary": "Recent advances in pretrained language models (PLMs) have significantly improved conversational recommender systems (CRS), enabling more fluent and context-aware interactions. To further enhance accuracy and mitigate hallucination, many methods integrate PLMs with knowledge graphs (KGs), but face key challenges: failing to fully exploit PLM reasoning over graph relationships, indiscriminately incorporating retrieved knowledge without context filtering, and neglecting collaborative preferences in multi-turn dialogues. To this end, we propose PCRS-TKA, a prompt-based framework employing retrieval-augmented generation to integrate PLMs with KGs. PCRS-TKA constructs dialogue-specific knowledge trees from KGs and serializes them into texts, enabling structure-aware reasoning while capturing rich entity semantics. Our approach selectively filters context-relevant knowledge and explicitly models collaborative preferences using specialized supervision signals. A semantic alignment module harmonizes heterogeneous inputs, reducing noise and enhancing accuracy. Extensive experiments demonstrate that PCRS-TKA consistently outperforms all baselines in both recommendation and conversational quality.", "AI": {"tldr": "PCRS-TKA\u662f\u4e00\u4e2a\u57fa\u4e8e\u63d0\u793a\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5c06\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4e0e\u77e5\u8bc6\u56fe\u8c31\u96c6\u6210\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5229\u7528PLM\u63a8\u7406\u3001\u4e0a\u4e0b\u6587\u77e5\u8bc6\u8fc7\u6ee4\u548c\u534f\u4f5c\u504f\u597d\u5efa\u6a21\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528PLM\u5728\u56fe\u5173\u7cfb\u4e0a\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e0d\u52a0\u533a\u5206\u5730\u6574\u5408\u68c0\u7d22\u5230\u7684\u77e5\u8bc6\uff0c\u4e14\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u5ffd\u7565\u4e86\u534f\u4f5c\u504f\u597d\uff0c\u5bfc\u81f4\u51c6\u786e\u6027\u4e0d\u8db3\u548c\u5e7b\u89c9\u95ee\u9898\u3002", "method": "\u6784\u5efa\u5bf9\u8bdd\u7279\u5b9a\u7684\u77e5\u8bc6\u6811\u5e76\u5e8f\u5217\u5316\u4e3a\u6587\u672c\uff0c\u5b9e\u73b0\u7ed3\u6784\u611f\u77e5\u63a8\u7406\uff1b\u9009\u62e9\u6027\u8fc7\u6ee4\u4e0a\u4e0b\u6587\u76f8\u5173\u77e5\u8bc6\uff1b\u4f7f\u7528\u4e13\u95e8\u76d1\u7763\u4fe1\u53f7\u663e\u5f0f\u5efa\u6a21\u534f\u4f5c\u504f\u597d\uff1b\u8bed\u4e49\u5bf9\u9f50\u6a21\u5757\u534f\u8c03\u5f02\u6784\u8f93\u5165\u3002", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660ePCRS-TKA\u5728\u63a8\u8350\u548c\u5bf9\u8bdd\u8d28\u91cf\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "PCRS-TKA\u901a\u8fc7\u7ed3\u6784\u611f\u77e5\u63a8\u7406\u3001\u4e0a\u4e0b\u6587\u77e5\u8bc6\u8fc7\u6ee4\u548c\u534f\u4f5c\u504f\u597d\u5efa\u6a21\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5bf9\u8bdd\u63a8\u8350\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u5bf9\u8bdd\u8d28\u91cf\u3002"}}
{"id": "2511.12728", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12728", "abs": "https://arxiv.org/abs/2511.12728", "authors": ["Lea Hergert", "G\u00e1bor Berend", "Mario Szegedy", "Gyorgy Turan", "M\u00e1rk Jelasity"], "title": "On the Brittleness of LLMs: A Journey around Set Membership", "comment": null, "summary": "Large language models (LLMs) achieve superhuman performance on complex reasoning tasks, yet often fail on much simpler problems, raising concerns about their reliability and interpretability. We investigate this paradox through a focused study with two key design features: simplicity, to expose basic failure modes, and scale, to enable comprehensive controlled experiments. We focus on set membership queries -- among the most fundamental forms of reasoning -- using tasks like ``Is apple an element of the set \\{pear, plum, apple, raspberry\\}?''. We conduct a systematic empirical evaluation across prompt phrasing, semantic structure, element ordering, and model choice. Our large-scale analysis reveals that LLM performance on this elementary task is consistently brittle, and unpredictable across all dimensions, suggesting that the models' ``understanding'' of the set concept is fragmented and convoluted at best. Our work demonstrates that the large-scale experiments enabled by the simplicity of the problem allow us to map and analyze the failure modes comprehensively, making this approach a valuable methodology for LLM evaluation in general.", "AI": {"tldr": "LLMs\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u8d85\u4eba\u7c7b\uff0c\u4f46\u5728\u7b80\u5355\u96c6\u5408\u6210\u5458\u67e5\u8be2\u4efb\u52a1\u4e2d\u5374\u9891\u7e41\u5931\u8d25\uff0c\u63ed\u793a\u4e86\u5176\u63a8\u7406\u80fd\u529b\u7684\u8106\u5f31\u6027\u548c\u4e0d\u53ef\u9884\u6d4b\u6027\u3002", "motivation": "\u7814\u7a76LLMs\u5728\u590d\u6742\u4efb\u52a1\u8868\u73b0\u4f18\u5f02\u5374\u5728\u7b80\u5355\u4efb\u52a1\u4e0a\u5931\u8d25\u7684\u77db\u76fe\u73b0\u8c61\uff0c\u901a\u8fc7\u7b80\u5355\u4f46\u53ef\u6269\u5c55\u7684\u5b9e\u9a8c\u8bbe\u8ba1\u6765\u63ed\u793a\u57fa\u672c\u5931\u8d25\u6a21\u5f0f\u3002", "method": "\u4f7f\u7528\u96c6\u5408\u6210\u5458\u67e5\u8be2\u4f5c\u4e3a\u57fa\u7840\u63a8\u7406\u4efb\u52a1\uff0c\u7cfb\u7edf\u8bc4\u4f30\u63d0\u793a\u63aa\u8f9e\u3001\u8bed\u4e49\u7ed3\u6784\u3001\u5143\u7d20\u6392\u5e8f\u548c\u6a21\u578b\u9009\u62e9\u7b49\u7ef4\u5ea6\uff0c\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\u3002", "result": "LLMs\u5728\u8fd9\u4e00\u57fa\u7840\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u6301\u7eed\u8106\u5f31\u4e14\u5728\u6240\u6709\u7ef4\u5ea6\u4e0a\u90fd\u4e0d\u53ef\u9884\u6d4b\uff0c\u8868\u660e\u6a21\u578b\u5bf9\u96c6\u5408\u6982\u5ff5\u7684\u7406\u89e3\u662f\u788e\u7247\u5316\u548c\u590d\u6742\u7684\u3002", "conclusion": "\u901a\u8fc7\u7b80\u5355\u95ee\u9898\u7684\u5927\u89c4\u6a21\u5b9e\u9a8c\u80fd\u591f\u5168\u9762\u6620\u5c04\u548c\u5206\u6790\u5931\u8d25\u6a21\u5f0f\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4e3aLLM\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u65b9\u6cd5\u8bba\u3002"}}
{"id": "2511.12677", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12677", "abs": "https://arxiv.org/abs/2511.12677", "authors": ["Oliver Joergensen", "Dominik Drexler", "Jendrik Seipp"], "title": "Dynamic Tree Databases in Automated Planning", "comment": null, "summary": "A central challenge in scaling up explicit state-space search for large tasks is compactly representing the set of generated states. Tree databases, a data structure from model checking, require constant space per generated state in the best case, but they need a large preallocation of memory. We propose a novel dynamic variant of tree databases for compressing state sets over propositional and numeric variables and prove that it maintains the desirable properties of the static counterpart. Our empirical evaluation of state compression techniques for grounded and lifted planning on classical and numeric planning tasks reveals compression ratios of several orders of magnitude, often with negligible runtime overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u6811\u6570\u636e\u5e93\u53d8\u4f53\uff0c\u7528\u4e8e\u538b\u7f29\u547d\u9898\u548c\u6570\u503c\u53d8\u91cf\u7684\u72b6\u6001\u96c6\uff0c\u5728\u4fdd\u6301\u9759\u6001\u7248\u672c\u4f18\u826f\u7279\u6027\u7684\u540c\u65f6\u907f\u514d\u4e86\u5927\u91cf\u5185\u5b58\u9884\u5206\u914d\u3002", "motivation": "\u5728\u5927\u578b\u4efb\u52a1\u4e2d\u6269\u5c55\u663e\u5f0f\u72b6\u6001\u7a7a\u95f4\u641c\u7d22\u65f6\uff0c\u5982\u4f55\u7d27\u51d1\u8868\u793a\u751f\u6210\u7684\u72b6\u6001\u96c6\u662f\u4e00\u4e2a\u6838\u5fc3\u6311\u6218\u3002\u4f20\u7edf\u7684\u6811\u6570\u636e\u5e93\u867d\u7136\u80fd\u5728\u6700\u4f73\u60c5\u51b5\u4e0b\u4e3a\u6bcf\u4e2a\u751f\u6210\u72b6\u6001\u63d0\u4f9b\u6052\u5b9a\u7a7a\u95f4\uff0c\u4f46\u9700\u8981\u5927\u91cf\u5185\u5b58\u9884\u5206\u914d\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u52a8\u6001\u6811\u6570\u636e\u5e93\u53d8\u4f53\uff0c\u7528\u4e8e\u538b\u7f29\u547d\u9898\u548c\u6570\u503c\u53d8\u91cf\u7684\u72b6\u6001\u96c6\uff0c\u5e76\u8bc1\u660e\u5176\u4fdd\u6301\u4e86\u9759\u6001\u5bf9\u5e94\u7248\u672c\u7684\u7406\u60f3\u7279\u6027\u3002", "result": "\u5728\u7ecf\u5178\u548c\u6570\u503c\u89c4\u5212\u4efb\u52a1\u4e0a\u5bf9\u72b6\u6001\u538b\u7f29\u6280\u672f\u7684\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0c\u538b\u7f29\u6bd4\u8fbe\u5230\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u4e14\u901a\u5e38\u8fd0\u884c\u65f6\u5f00\u9500\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "\u52a8\u6001\u6811\u6570\u636e\u5e93\u4e3a\u72b6\u6001\u538b\u7f29\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u5185\u5b58\u9700\u6c42\u3002"}}
{"id": "2511.12768", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12768", "abs": "https://arxiv.org/abs/2511.12768", "authors": ["Noah Hong", "Tao Hong"], "title": "Evidence of Phase Transitions in Small Transformer-Based Language Models", "comment": null, "summary": "Phase transitions have been proposed as the origin of emergent abilities in large language models (LLMs), where new capabilities appear abruptly once models surpass critical thresholds of scale. Prior work, such as that of Wei et al., demonstrated these phenomena under model and data scaling, with transitions revealed after applying a log scale to training compute. In this work, we ask three complementary questions: (1) Are phase transitions unique to large models, or can they also be observed in small transformer-based language models? (2) Can such transitions be detected directly in linear training space, rather than only after log rescaling? and (3) Can these transitions emerge at early stages of training? To investigate, we train a small GPT-style transformer on a character-level corpus and analyze the evolution of vocabulary usage throughout training. We track the average word length, the number of correct versus incorrect words, and shifts in vocabulary diversity. Building on these measures, we apply Poisson and sub-Poisson statistics to quantify how words connect and reorganize. This combined analysis reveals a distinct transition point during training. Notably, these transitions are not apparent in standard loss or validation curves, but become visible through our vocabulary- and statistics-based probes. Our findings suggest that phase-transition reorganizations are a general feature of language model training, observable even in modest models, detectable directly in linear training space, and occurring surprisingly early as coherence emerges. This perspective provides new insight into the nonlinear dynamics of language model training and underscores the importance of tailored metrics for uncovering phase transition behaviors", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u5b58\u5728\u76f8\u53d8\u73b0\u8c61\uff0c\u5373\u4f7f\u5728\u5c0f\u89c4\u6a21transformer\u6a21\u578b\u4e2d\u4e5f\u80fd\u89c2\u5bdf\u5230\uff0c\u8fd9\u4e9b\u76f8\u53d8\u5728\u8bcd\u6c47\u4f7f\u7528\u548c\u7edf\u8ba1\u7279\u5f81\u4e0a\u8868\u73b0\u660e\u663e\uff0c\u4f46\u5728\u6807\u51c6\u635f\u5931\u66f2\u7ebf\u4e2d\u4e0d\u53ef\u89c1\u3002", "motivation": "\u63a2\u7d22\u76f8\u53d8\u73b0\u8c61\u662f\u5426\u4ec5\u9650\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u80fd\u5426\u5728\u7ebf\u6027\u8bad\u7ec3\u7a7a\u95f4\u4e2d\u76f4\u63a5\u68c0\u6d4b\u5230\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u76f8\u53d8\u662f\u5426\u5728\u8bad\u7ec3\u65e9\u671f\u5c31\u51fa\u73b0\u3002", "method": "\u8bad\u7ec3\u5c0f\u578bGPT\u98ce\u683ctransformer\u6a21\u578b\uff0c\u5206\u6790\u8bcd\u6c47\u4f7f\u7528\u6f14\u53d8\uff0c\u5305\u62ec\u5e73\u5747\u8bcd\u957f\u3001\u6b63\u786e\u4e0e\u9519\u8bef\u8bcd\u6c47\u6570\u91cf\u3001\u8bcd\u6c47\u591a\u6837\u6027\u53d8\u5316\uff0c\u5e76\u5e94\u7528\u6cca\u677e\u548c\u6b21\u6cca\u677e\u7edf\u8ba1\u6765\u91cf\u5316\u8bcd\u6c47\u8fde\u63a5\u548c\u91cd\u7ec4\u3002", "result": "\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u53d1\u73b0\u660e\u663e\u7684\u76f8\u53d8\u70b9\uff0c\u8fd9\u4e9b\u76f8\u53d8\u5728\u6807\u51c6\u635f\u5931\u6216\u9a8c\u8bc1\u66f2\u7ebf\u4e2d\u4e0d\u53ef\u89c1\uff0c\u4f46\u901a\u8fc7\u8bcd\u6c47\u548c\u7edf\u8ba1\u63a2\u9488\u53d8\u5f97\u53ef\u89c1\u3002", "conclusion": "\u76f8\u53d8\u91cd\u7ec4\u662f\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7684\u666e\u904d\u7279\u5f81\uff0c\u53ef\u5728\u5c0f\u578b\u6a21\u578b\u4e2d\u89c2\u5bdf\u5230\uff0c\u80fd\u5728\u7ebf\u6027\u8bad\u7ec3\u7a7a\u95f4\u4e2d\u76f4\u63a5\u68c0\u6d4b\uff0c\u5e76\u5728\u8bad\u7ec3\u65e9\u671f\u5c31\u51fa\u73b0\uff0c\u4e3a\u7406\u89e3\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7684\u975e\u7ebf\u6027\u52a8\u6001\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2511.12754", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.12754", "abs": "https://arxiv.org/abs/2511.12754", "authors": ["Benjamin Li", "Shuyang Shi", "Lucia Romero", "Huao Li", "Yaqi Xie", "Woojun Kim", "Stefanos Nikolaidis", "Michael Lewis", "Katia Sycara", "Simon Stepputtis"], "title": "Adaptively Coordinating with Novel Partners via Learned Latent Strategies", "comment": "Accepted to NeurIPS 2025", "summary": "Adaptation is the cornerstone of effective collaboration among heterogeneous team members. In human-agent teams, artificial agents need to adapt to their human partners in real time, as individuals often have unique preferences and policies that may change dynamically throughout interactions. This becomes particularly challenging in tasks with time pressure and complex strategic spaces, where identifying partner behaviors and selecting suitable responses is difficult. In this work, we introduce a strategy-conditioned cooperator framework that learns to represent, categorize, and adapt to a broad range of potential partner strategies in real-time. Our approach encodes strategies with a variational autoencoder to learn a latent strategy space from agent trajectory data, identifies distinct strategy types through clustering, and trains a cooperator agent conditioned on these clusters by generating partners of each strategy type. For online adaptation to novel partners, we leverage a fixed-share regret minimization algorithm that dynamically infers and adjusts the partner's strategy estimation during interaction. We evaluate our method in a modified version of the Overcooked domain, a complex collaborative cooking environment that requires effective coordination among two players with a diverse potential strategy space. Through these experiments and an online user study, we demonstrate that our proposed agent achieves state of the art performance compared to existing baselines when paired with novel human, and agent teammates.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b56\u7565\u6761\u4ef6\u5316\u5408\u4f5c\u8005\u6846\u67b6\uff0c\u80fd\u591f\u5b9e\u65f6\u8868\u793a\u3001\u5206\u7c7b\u548c\u9002\u5e94\u5404\u79cd\u5408\u4f5c\u4f19\u4f34\u7b56\u7565\uff0c\u5728\u590d\u6742\u534f\u4f5c\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6709\u6548\u7684\u4eba\u673a\u56e2\u961f\u5408\u4f5c\u3002", "motivation": "\u5728\u4eba\u7c7b-\u667a\u80fd\u4f53\u56e2\u961f\u4e2d\uff0c\u4eba\u5de5\u667a\u80fd\u4f53\u9700\u8981\u5b9e\u65f6\u9002\u5e94\u4eba\u7c7b\u4f19\u4f34\u7684\u72ec\u7279\u504f\u597d\u548c\u7b56\u7565\uff0c\u8fd9\u5728\u65f6\u95f4\u538b\u529b\u548c\u590d\u6742\u7b56\u7565\u7a7a\u95f4\u7684\u4efb\u52a1\u4e2d\u5c24\u4e3a\u56f0\u96be\u3002", "method": "\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5b66\u4e60\u7b56\u7565\u7684\u6f5c\u5728\u7a7a\u95f4\u8868\u793a\uff0c\u901a\u8fc7\u805a\u7c7b\u8bc6\u522b\u4e0d\u540c\u7b56\u7565\u7c7b\u578b\uff0c\u8bad\u7ec3\u6761\u4ef6\u5316\u5408\u4f5c\u8005\u667a\u80fd\u4f53\uff0c\u5e76\u5229\u7528\u56fa\u5b9a\u4efd\u989d\u9057\u61be\u6700\u5c0f\u5316\u7b97\u6cd5\u8fdb\u884c\u5728\u7ebf\u9002\u5e94\u3002", "result": "\u5728\u4fee\u6539\u7248\u7684Overcooked\u73af\u5883\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u5728\u4e0e\u65b0\u4eba\u7c7b\u548c\u667a\u80fd\u4f53\u961f\u53cb\u914d\u5bf9\u65f6\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b56\u7565\u6761\u4ef6\u5316\u5408\u4f5c\u8005\u6846\u67b6\u80fd\u591f\u6709\u6548\u9002\u5e94\u591a\u6837\u5316\u7684\u5408\u4f5c\u4f19\u4f34\u7b56\u7565\uff0c\u5728\u590d\u6742\u534f\u4f5c\u4efb\u52a1\u4e2d\u5b9e\u73b0\u5353\u8d8a\u7684\u56e2\u961f\u8868\u73b0\u3002"}}
{"id": "2511.12782", "categories": ["cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.12782", "abs": "https://arxiv.org/abs/2511.12782", "authors": ["Thomas Rivasseau"], "title": "LLM Reinforcement in Context", "comment": "4 pages", "summary": "Current Large Language Model alignment research mostly focuses on improving model robustness against adversarial attacks and misbehavior by training on examples and prompting. Research has shown that LLM jailbreak probability increases with the size of the user input or conversation length. There is a lack of appropriate research into means of strengthening alignment which also scale with user input length. We propose interruptions as a possible solution to this problem. Interruptions are control sentences added to the user input approximately every x tokens for some arbitrary x. We suggest that this can be generalized to the Chain-of-Thought process to prevent scheming.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u4e2d\u65ad\u673a\u5236\u6765\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u9f50\u6027\uff0c\u901a\u8fc7\u5728\u7528\u6237\u8f93\u5165\u4e2d\u5b9a\u671f\u63d2\u5165\u63a7\u5236\u8bed\u53e5\u6765\u9632\u6b62\u8d8a\u72f1\u884c\u4e3a\u3002", "motivation": "\u5f53\u524dLLM\u5bf9\u9f50\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u901a\u8fc7\u8bad\u7ec3\u548c\u63d0\u793a\u6765\u63d0\u9ad8\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u4f46\u7f3a\u4e4f\u968f\u7740\u7528\u6237\u8f93\u5165\u957f\u5ea6\u589e\u52a0\u800c\u6709\u6548\u589e\u5f3a\u5bf9\u9f50\u7684\u65b9\u6cd5\u3002\u7814\u7a76\u53d1\u73b0LLM\u8d8a\u72f1\u6982\u7387\u968f\u7528\u6237\u8f93\u5165\u6216\u5bf9\u8bdd\u957f\u5ea6\u589e\u52a0\u800c\u4e0a\u5347\u3002", "method": "\u63d0\u51fa\u4e2d\u65ad\u673a\u5236\uff0c\u5728\u7528\u6237\u8f93\u5165\u4e2d\u6bcfx\u4e2atoken\u63d2\u5165\u63a7\u5236\u8bed\u53e5\uff0c\u5e76\u5efa\u8bae\u5c06\u6b64\u65b9\u6cd5\u63a8\u5e7f\u5230\u601d\u7ef4\u94fe\u8fc7\u7a0b\u4ee5\u9632\u6b62\u7b56\u7565\u6027\u884c\u4e3a\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e2d\u65ad\u673a\u5236\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u4f46\u672a\u63d0\u4f9b\u5177\u4f53\u7684\u5b9e\u9a8c\u7ed3\u679c\u3002", "conclusion": "\u4e2d\u65ad\u673a\u5236\u662f\u589e\u5f3aLLM\u5bf9\u9f50\u6027\u7684\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u968f\u7740\u7528\u6237\u8f93\u5165\u957f\u5ea6\u6269\u5c55\u800c\u4fdd\u6301\u6709\u6548\u6027\u3002"}}
{"id": "2511.12759", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12759", "abs": "https://arxiv.org/abs/2511.12759", "authors": ["James Moore"], "title": "Optimal Foraging in Memory Retrieval: Evaluating Random Walks and Metropolis-Hastings Sampling in Modern Semantic Spaces", "comment": null, "summary": "Human memory retrieval often resembles ecological foraging where animals search for food in a patchy environment. Optimal foraging means following the Marginal Value Theorem (MVT), in which individuals exploit a patch of semantically related concepts until it becomes less rewarding and then switch to a new cluster. While human behavioral data suggests foraging-like patterns in semantic fluency tasks, it remains unclear whether modern high-dimensional embedding spaces provide representations that allow algorithms to match observed human behavior. Using state-of-the-art embeddings and prior semantic fluency data, I find that random walks on these embedding spaces produce results consistent with optimal foraging and the MVT. Surprisingly, introducing Metropolis-Hastings sampling, an adaptive algorithm expected to model strategic acceptance and rejection of new clusters, does not produce results consistent with human behavior. These findings challenge the assumption that more complex sampling mechanisms inherently lead to better cognitive models of memory retrieval. Instead, they show that appropriately structured embeddings, even with simple sampling, can produce near-optimal foraging dynamics. This supports the perspective of Hills (2012) rather than Abbott (2015), demonstrating that modern embeddings can approximate human memory foraging without relying on complex acceptance criteria.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u9ad8\u7ef4\u5d4c\u5165\u7a7a\u95f4\u4e2d\u8fdb\u884c\u968f\u673a\u6e38\u8d70\u53ef\u4ee5\u4ea7\u751f\u4e0e\u4eba\u7c7b\u8bed\u4e49\u6d41\u7545\u6027\u4efb\u52a1\u4e2d\u89c2\u5bdf\u5230\u7684\u4f18\u5316\u89c5\u98df\u884c\u4e3a\u4e00\u81f4\u7684\u7ed3\u679c\uff0c\u800c\u66f4\u590d\u6742\u7684Metropolis-Hastings\u91c7\u6837\u53cd\u800c\u4e0d\u80fd\u5339\u914d\u4eba\u7c7b\u884c\u4e3a\u3002", "motivation": "\u63a2\u7d22\u73b0\u4ee3\u9ad8\u7ef4\u5d4c\u5165\u7a7a\u95f4\u662f\u5426\u80fd\u63d0\u4f9b\u8db3\u4ee5\u5339\u914d\u4eba\u7c7b\u8bed\u4e49\u6d41\u7545\u6027\u4efb\u52a1\u4e2d\u89c2\u5bdf\u5230\u7684\u4f18\u5316\u89c5\u98df\u884c\u4e3a\u7684\u8868\u793a\uff0c\u5e76\u9a8c\u8bc1\u590d\u6742\u91c7\u6837\u673a\u5236\u662f\u5426\u5fc5\u7136\u4ea7\u751f\u66f4\u597d\u7684\u8ba4\u77e5\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u6700\u5148\u8fdb\u7684\u5d4c\u5165\u8868\u793a\u548c\u5148\u524d\u7684\u8bed\u4e49\u6d41\u7545\u6027\u6570\u636e\uff0c\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u8fdb\u884c\u968f\u673a\u6e38\u8d70\u548cMetropolis-Hastings\u91c7\u6837\uff0c\u6bd4\u8f83\u5b83\u4eec\u4e0e\u4eba\u7c7b\u884c\u4e3a\u7684\u5339\u914d\u7a0b\u5ea6\u3002", "result": "\u968f\u673a\u6e38\u8d70\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u4ea7\u751f\u7684\u7ed3\u679c\u4e0e\u4f18\u5316\u89c5\u98df\u548c\u8fb9\u9645\u4ef7\u503c\u5b9a\u7406\u4e00\u81f4\uff0c\u800cMetropolis-Hastings\u91c7\u6837\u672a\u80fd\u4ea7\u751f\u4e0e\u4eba\u7c7b\u884c\u4e3a\u4e00\u81f4\u7684\u7ed3\u679c\u3002", "conclusion": "\u9002\u5f53\u7ed3\u6784\u7684\u5d4c\u5165\u8868\u793a\u5373\u4f7f\u4f7f\u7528\u7b80\u5355\u91c7\u6837\u4e5f\u80fd\u4ea7\u751f\u63a5\u8fd1\u4f18\u5316\u7684\u89c5\u98df\u52a8\u6001\uff0c\u6311\u6218\u4e86\u590d\u6742\u91c7\u6837\u673a\u5236\u5fc5\u7136\u4ea7\u751f\u66f4\u597d\u8ba4\u77e5\u6a21\u578b\u7684\u5047\u8bbe\uff0c\u652f\u6301Hills(2012)\u800c\u975eAbbott(2015)\u7684\u89c2\u70b9\u3002"}}
{"id": "2511.12784", "categories": ["cs.CL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.12784", "abs": "https://arxiv.org/abs/2511.12784", "authors": ["Hayden Moore", "Asfahan Shah"], "title": "Evaluating Autoformalization Robustness via Semantically Similar Paraphrasing", "comment": null, "summary": "Large Language Models (LLMs) have recently emerged as powerful tools for autoformalization. Despite their impressive performance, these models can still struggle to produce grounded and verifiable formalizations. Recent work in text-to-SQL, has revealed that LLMs can be sensitive to paraphrased natural language (NL) inputs, even when high degrees of semantic fidelity are preserved (Safarzadeh, Oroojlooyjadid, and Roth 2025). In this paper, we investigate this claim in the autoformalization domain. Specifically, we evaluate the robustness of LLMs generating formal proofs with semantically similar paraphrased NL statements by measuring semantic and compilation validity. Using the formal benchmarks MiniF2F (Zheng, Han, and Polu 2021) and Lean 4 version of ProofNet (Xin et al. 2024), and two modern LLMs, we generate paraphrased natural language statements and cross-evaluate these statements across both models. The results of this paper reveal performance variability across paraphrased inputs, demonstrating that minor shifts in NL statements can significantly impact model outputs.", "AI": {"tldr": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5f62\u5f0f\u5316\u4efb\u52a1\u4e2d\u5bf9\u8bed\u4e49\u76f8\u4f3c\u4f46\u8868\u8ff0\u4e0d\u540c\u7684\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u5373\u4f7f\u662f\u8f7b\u5fae\u7684\u8bed\u8a00\u53d8\u5316\u4e5f\u4f1a\u663e\u8457\u5f71\u54cd\u6a21\u578b\u8f93\u51fa\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u81ea\u52a8\u5f62\u5f0f\u5316\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u8fd1\u671f\u7814\u7a76\u8868\u660e\u5b83\u4eec\u5bf9\u8bed\u4e49\u4fdd\u6301\u7684\u6539\u5199\u8f93\u5165\u5f88\u654f\u611f\u3002\u672c\u6587\u65e8\u5728\u9a8c\u8bc1\u8fd9\u4e00\u73b0\u8c61\u5728\u81ea\u52a8\u5f62\u5f0f\u5316\u9886\u57df\u7684\u8868\u73b0\u3002", "method": "\u4f7f\u7528MiniF2F\u548cLean 4\u7248\u672c\u7684ProofNet\u4f5c\u4e3a\u57fa\u51c6\uff0c\u5728\u4e24\u4e2a\u73b0\u4ee3LLMs\u4e0a\u751f\u6210\u6539\u5199\u540e\u7684\u81ea\u7136\u8bed\u8a00\u9648\u8ff0\uff0c\u5e76\u901a\u8fc7\u8bed\u4e49\u548c\u7f16\u8bd1\u6709\u6548\u6027\u8fdb\u884c\u4ea4\u53c9\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u663e\u793a\u6539\u5199\u8f93\u5165\u4e4b\u95f4\u5b58\u5728\u6027\u80fd\u5dee\u5f02\uff0c\u8868\u660e\u81ea\u7136\u8bed\u8a00\u9648\u8ff0\u7684\u5fae\u5c0f\u53d8\u5316\u4f1a\u663e\u8457\u5f71\u54cd\u6a21\u578b\u8f93\u51fa\u3002", "conclusion": "LLMs\u5728\u81ea\u52a8\u5f62\u5f0f\u5316\u4efb\u52a1\u4e2d\u5bf9\u8bed\u8a00\u8868\u8ff0\u53d8\u5316\u654f\u611f\uff0c\u9700\u8981\u63d0\u9ad8\u5176\u9c81\u68d2\u6027\u4ee5\u786e\u4fdd\u5f62\u5f0f\u5316\u7ed3\u679c\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.12769", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12769", "abs": "https://arxiv.org/abs/2511.12769", "authors": ["Luyao Niu", "Zepu Wang", "Shuyi Guan", "Yang Liu", "Peng Sun"], "title": "Event-CausNet: Unlocking Causal Knowledge from Text with Large Language Models for Reliable Spatio-Temporal Forecasting", "comment": null, "summary": "While spatio-temporal Graph Neural Networks (GNNs) excel at modeling recurring traffic patterns, their reliability plummets during non-recurring events like accidents. This failure occurs because GNNs are fundamentally correlational models, learning historical patterns that are invalidated by the new causal factors introduced during disruptions. To address this, we propose Event-CausNet, a framework that uses a Large Language Model to quantify unstructured event reports, builds a causal knowledge base by estimating average treatment effects, and injects this knowledge into a dual-stream GNN-LSTM network using a novel causal attention mechanism to adjust and enhance the forecast. Experiments on a real-world dataset demonstrate that Event-CausNet achieves robust performance, reducing prediction error (MAE) by up to 35.87%, significantly outperforming state-of-the-art baselines. Our framework bridges the gap between correlational models and causal reasoning, providing a solution that is more accurate and transferable, while also offering crucial interpretability, providing a more reliable foundation for real-world traffic management during critical disruptions.", "AI": {"tldr": "Event-CausNet\u6846\u67b6\u5229\u7528LLM\u91cf\u5316\u975e\u7ed3\u6784\u5316\u4e8b\u4ef6\u62a5\u544a\uff0c\u6784\u5efa\u56e0\u679c\u77e5\u8bc6\u5e93\uff0c\u5e76\u901a\u8fc7\u56e0\u679c\u6ce8\u610f\u529b\u673a\u5236\u5c06\u56e0\u679c\u77e5\u8bc6\u6ce8\u5165\u53cc\u6d41GNN-LSTM\u7f51\u7edc\uff0c\u5728\u4ea4\u901a\u4e2d\u65ad\u671f\u95f4\u663e\u8457\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u65f6\u7a7a\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u5904\u7406\u975e\u91cd\u590d\u6027\u4e8b\u4ef6\uff08\u5982\u4e8b\u6545\uff09\u65f6\u53ef\u9760\u6027\u6025\u5267\u4e0b\u964d\uff0c\u56e0\u4e3a\u5b83\u4eec\u672c\u8d28\u4e0a\u662f\u76f8\u5173\u6027\u6a21\u578b\uff0c\u65e0\u6cd5\u5e94\u5bf9\u4e2d\u65ad\u671f\u95f4\u5f15\u5165\u7684\u65b0\u56e0\u679c\u56e0\u7d20\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u91cf\u5316\u975e\u7ed3\u6784\u5316\u4e8b\u4ef6\u62a5\u544a\uff0c\u901a\u8fc7\u4f30\u8ba1\u5e73\u5747\u5904\u7406\u6548\u5e94\u6784\u5efa\u56e0\u679c\u77e5\u8bc6\u5e93\uff0c\u91c7\u7528\u53cc\u6d41GNN-LSTM\u7f51\u7edc\u7ed3\u5408\u65b0\u9896\u7684\u56e0\u679c\u6ce8\u610f\u529b\u673a\u5236\u6765\u8c03\u6574\u548c\u589e\u5f3a\u9884\u6d4b\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cEvent-CausNet\u5c06\u9884\u6d4b\u8bef\u5dee\uff08MAE\uff09\u964d\u4f4e\u4e86\u9ad8\u8fbe35.87%\uff0c\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u5f25\u5408\u4e86\u76f8\u5173\u6027\u6a21\u578b\u4e0e\u56e0\u679c\u63a8\u7406\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u3001\u53ef\u8fc1\u79fb\u4e14\u5177\u6709\u5173\u952e\u53ef\u89e3\u91ca\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u5173\u952e\u4e2d\u65ad\u671f\u95f4\u7684\u5b9e\u65f6\u4ea4\u901a\u7ba1\u7406\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u57fa\u7840\u3002"}}
{"id": "2511.12821", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12821", "abs": "https://arxiv.org/abs/2511.12821", "authors": ["Ruiyu Wang", "Yuzhang Xie", "Xiao Hu", "Carl Yang", "Jiaying Lu"], "title": "BioMedJImpact: A Comprehensive Dataset and LLM Pipeline for AI Engagement and Scientific Impact Analysis of Biomedical Journals", "comment": null, "summary": "Assessing journal impact is central to scholarly communication, yet existing open resources rarely capture how collaboration structures and artificial intelligence (AI) research jointly shape venue prestige in biomedicine. We present BioMedJImpact, a large-scale, biomedical-oriented dataset designed to advance journal-level analysis of scientific impact and AI engagement. Built from 1.74 million PubMed Central articles across 2,744 journals, BioMedJImpact integrates bibliometric indicators, collaboration features, and LLM-derived semantic indicators for AI engagement. Specifically, the AI engagement feature is extracted through a reproducible three-stage LLM pipeline that we propose. Using this dataset, we analyze how collaboration intensity and AI engagement jointly influence scientific impact across pre- and post-pandemic periods (2016-2019, 2020-2023). Two consistent trends emerge: journals with higher collaboration intensity, particularly those with larger and more diverse author teams, tend to achieve greater citation impact, and AI engagement has become an increasingly strong correlate of journal prestige, especially in quartile rankings. To further validate the three-stage LLM pipeline we proposed for deriving the AI engagement feature, we conduct human evaluation, confirming substantial agreement in AI relevance detection and consistent subfield classification. Together, these contributions demonstrate that BioMedJImpact serves as both a comprehensive dataset capturing the intersection of biomedicine and AI, and a validated methodological framework enabling scalable, content-aware scientometric analysis of scientific impact and innovation dynamics. Code is available at https://github.com/JonathanWry/BioMedJImpact.", "AI": {"tldr": "BioMedJImpact\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u751f\u7269\u533b\u5b66\u671f\u520a\u5f71\u54cd\u6570\u636e\u96c6\uff0c\u6574\u5408\u4e86\u6587\u732e\u8ba1\u91cf\u6307\u6807\u3001\u5408\u4f5c\u7279\u5f81\u548cLLM\u884d\u751f\u7684AI\u53c2\u4e0e\u5ea6\u6307\u6807\uff0c\u63ed\u793a\u4e86\u5408\u4f5c\u5f3a\u5ea6\u548cAI\u53c2\u4e0e\u5ea6\u5171\u540c\u5f71\u54cd\u79d1\u5b66\u5f71\u54cd\u529b\u7684\u8d8b\u52bf\u3002", "motivation": "\u73b0\u6709\u5f00\u653e\u8d44\u6e90\u5f88\u5c11\u6355\u6349\u5408\u4f5c\u7ed3\u6784\u548cAI\u7814\u7a76\u5982\u4f55\u5171\u540c\u5851\u9020\u751f\u7269\u533b\u5b66\u671f\u520a\u58f0\u671b\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u7efc\u5408\u6570\u636e\u96c6\u6765\u63a8\u8fdb\u671f\u520a\u5c42\u9762\u7684\u79d1\u5b66\u5f71\u54cd\u548cAI\u53c2\u4e0e\u5ea6\u5206\u6790\u3002", "method": "\u4ecePubMed Central\u7684174\u4e07\u7bc7\u6587\u7ae0\u6784\u5efa\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u53ef\u590d\u73b0\u7684\u4e09\u9636\u6bb5LLM\u6d41\u7a0b\u63d0\u53d6AI\u53c2\u4e0e\u5ea6\u7279\u5f81\uff0c\u5206\u6790\u5408\u4f5c\u5f3a\u5ea6\u548cAI\u53c2\u4e0e\u5ea6\u5728\u75ab\u60c5\u524d\u540e\u5bf9\u79d1\u5b66\u5f71\u54cd\u7684\u5171\u540c\u4f5c\u7528\u3002", "result": "\u53d1\u73b0\u4e24\u4e2a\u4e00\u81f4\u8d8b\u52bf\uff1a\u5408\u4f5c\u5f3a\u5ea6\u66f4\u9ad8\u7684\u671f\u520a\uff08\u7279\u522b\u662f\u4f5c\u8005\u56e2\u961f\u66f4\u5927\u66f4\u591a\u6837\u5316\u7684\uff09\u83b7\u5f97\u66f4\u9ad8\u5f15\u7528\u5f71\u54cd\uff1bAI\u53c2\u4e0e\u5ea6\u65e5\u76ca\u6210\u4e3a\u671f\u520a\u58f0\u671b\u7684\u5f3a\u76f8\u5173\u56e0\u7d20\uff0c\u5c24\u5176\u5728\u56db\u5206\u4f4d\u6392\u540d\u4e2d\u3002", "conclusion": "BioMedJImpact\u65e2\u662f\u6355\u6349\u751f\u7269\u533b\u5b66\u4e0eAI\u4ea4\u53c9\u7684\u7efc\u5408\u6570\u636e\u96c6\uff0c\u4e5f\u662f\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u65b9\u6cd5\u6846\u67b6\uff0c\u652f\u6301\u53ef\u6269\u5c55\u3001\u5185\u5bb9\u611f\u77e5\u7684\u79d1\u5b66\u8ba1\u91cf\u5206\u6790\u3002"}}
{"id": "2511.12792", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12792", "abs": "https://arxiv.org/abs/2511.12792", "authors": ["Mohamad A. Hady", "Siyi Hu", "Mahardhika Pratama", "Zehong Cao", "Ryszard Kowalczyk"], "title": "Multi-Agent Reinforcement Learning for Heterogeneous Satellite Cluster Resources Optimization", "comment": null, "summary": "This work investigates resource optimization in heterogeneous satellite clusters performing autonomous Earth Observation (EO) missions using Reinforcement Learning (RL). In the proposed setting, two optical satellites and one Synthetic Aperture Radar (SAR) satellite operate cooperatively in low Earth orbit to capture ground targets and manage their limited onboard resources efficiently. Traditional optimization methods struggle to handle the real-time, uncertain, and decentralized nature of EO operations, motivating the use of RL and Multi-Agent Reinforcement Learning (MARL) for adaptive decision-making. This study systematically formulates the optimization problem from single-satellite to multi-satellite scenarios, addressing key challenges including energy and memory constraints, partial observability, and agent heterogeneity arising from diverse payload capabilities. Using a near-realistic simulation environment built on the Basilisk and BSK-RL frameworks, we evaluate the performance and stability of state-of-the-art MARL algorithms such as MAPPO, HAPPO, and HATRPO. Results show that MARL enables effective coordination across heterogeneous satellites, balancing imaging performance and resource utilization while mitigating non-stationarity and inter-agent reward coupling. The findings provide practical insights into scalable, autonomous satellite operations and contribute a foundation for future research on intelligent EO mission planning under heterogeneous and dynamic conditions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u5f02\u6784\u536b\u661f\u96c6\u7fa4\u5728\u81ea\u4e3b\u5730\u7403\u89c2\u6d4b\u4efb\u52a1\u4e2d\u7684\u8d44\u6e90\u5206\u914d\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5b9e\u73b0\u5149\u5b66\u548cSAR\u536b\u661f\u7684\u534f\u540c\u5de5\u4f5c\uff0c\u89e3\u51b3\u5b9e\u65f6\u3001\u4e0d\u786e\u5b9a\u548c\u53bb\u4e2d\u5fc3\u5316\u73af\u5883\u4e0b\u7684\u8d44\u6e90\u7ba1\u7406\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5730\u7403\u89c2\u6d4b\u4efb\u52a1\u4e2d\u5b9e\u65f6\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u548c\u53bb\u4e2d\u5fc3\u5316\u7279\u6027\u5e26\u6765\u7684\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u81ea\u9002\u5e94\u51b3\u7b56\u7684\u667a\u80fd\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u57fa\u4e8eBasilisk\u548cBSK-RL\u6846\u67b6\u7684\u8fd1\u771f\u5b9e\u4eff\u771f\u73af\u5883\uff0c\u8bc4\u4f30MAPPO\u3001HAPPO\u3001HATRPO\u7b49\u5148\u8fdbMARL\u7b97\u6cd5\u5728\u5f02\u6784\u536b\u661f\u96c6\u7fa4\u4e2d\u7684\u6027\u80fd\uff0c\u7cfb\u7edf\u5730\u4ece\u5355\u536b\u661f\u5230\u591a\u536b\u661f\u573a\u666f\u5236\u5b9a\u4f18\u5316\u95ee\u9898\u3002", "result": "MARL\u80fd\u591f\u5b9e\u73b0\u5f02\u6784\u536b\u661f\u95f4\u7684\u6709\u6548\u534f\u8c03\uff0c\u5728\u5e73\u8861\u6210\u50cf\u6027\u80fd\u548c\u8d44\u6e90\u5229\u7528\u7684\u540c\u65f6\uff0c\u7f13\u89e3\u975e\u5e73\u7a33\u6027\u548c\u667a\u80fd\u4f53\u95f4\u5956\u52b1\u8026\u5408\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u4e3a\u53ef\u6269\u5c55\u7684\u81ea\u4e3b\u536b\u661f\u64cd\u4f5c\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\uff0c\u5e76\u4e3a\u5f02\u6784\u52a8\u6001\u6761\u4ef6\u4e0b\u667a\u80fd\u5730\u7403\u89c2\u6d4b\u4efb\u52a1\u89c4\u5212\u7684\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.12832", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12832", "abs": "https://arxiv.org/abs/2511.12832", "authors": ["Niranjan Chebrolu", "Gerard Christopher Yeo", "Kokil Jaidka"], "title": "From Passive to Persuasive: Steering Emotional Nuance in Human-AI Negotiation", "comment": null, "summary": "Large Language Models (LLMs) demonstrate increasing conversational fluency, yet instilling them with nuanced, human-like emotional expression remains a significant challenge. Current alignment techniques often address surface-level output or require extensive fine-tuning. This paper demonstrates that targeted activation engineering can steer LLaMA 3.1-8B to exhibit more human-like emotional nuances. We first employ attribution patching to identify causally influential components, to find a key intervention locus by observing activation patterns during diagnostic conversational tasks. We then derive emotional expression vectors from the difference in the activations generated by contrastive text pairs (positive vs. negative examples of target emotions). Applying these vectors to new conversational prompts significantly enhances emotional characteristics: steered responses show increased positive sentiment (e.g., joy, trust) and more frequent first-person pronoun usage, indicative of greater personal engagement. Our findings offer a precise and interpretable framework and new directions for the study of conversational AI.", "AI": {"tldr": "\u901a\u8fc7\u76ee\u6807\u6fc0\u6d3b\u5de5\u7a0b\u5f15\u5bfcLLaMA 3.1-8B\u5c55\u73b0\u66f4\u4eba\u6027\u5316\u7684\u60c5\u611f\u8868\u8fbe\uff0c\u4f7f\u7528\u5f52\u56e0\u4fee\u8865\u8bc6\u522b\u5173\u952e\u7ec4\u4ef6\uff0c\u4ece\u5bf9\u6bd4\u6587\u672c\u5bf9\u4e2d\u63d0\u53d6\u60c5\u611f\u8868\u8fbe\u5411\u91cf\uff0c\u663e\u8457\u589e\u5f3a\u60c5\u611f\u7279\u5f81\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u8bdd\u6d41\u7545\u5ea6\u4e0d\u65ad\u63d0\u5347\uff0c\u4f46\u8d4b\u4e88\u5176\u7ec6\u817b\u3001\u4eba\u6027\u5316\u7684\u60c5\u611f\u8868\u8fbe\u4ecd\u5177\u6311\u6218\u6027\u3002\u73b0\u6709\u5bf9\u9f50\u6280\u672f\u5f80\u5f80\u53ea\u5904\u7406\u8868\u5c42\u8f93\u51fa\u6216\u9700\u8981\u5927\u91cf\u5fae\u8c03\u3002", "method": "\u4f7f\u7528\u5f52\u56e0\u4fee\u8865\u8bc6\u522b\u56e0\u679c\u5f71\u54cd\u7ec4\u4ef6\uff0c\u901a\u8fc7\u89c2\u5bdf\u8bca\u65ad\u5bf9\u8bdd\u4efb\u52a1\u4e2d\u7684\u6fc0\u6d3b\u6a21\u5f0f\u627e\u5230\u5173\u952e\u5e72\u9884\u4f4d\u70b9\uff1b\u4ece\u5bf9\u6bd4\u6587\u672c\u5bf9\uff08\u79ef\u6781vs\u6d88\u6781\u60c5\u611f\u793a\u4f8b\uff09\u7684\u6fc0\u6d3b\u5dee\u5f02\u4e2d\u63d0\u53d6\u60c5\u611f\u8868\u8fbe\u5411\u91cf\u3002", "result": "\u5c06\u60c5\u611f\u5411\u91cf\u5e94\u7528\u4e8e\u65b0\u5bf9\u8bdd\u63d0\u793a\u663e\u8457\u589e\u5f3a\u60c5\u611f\u7279\u5f81\uff1a\u5f15\u5bfc\u7684\u56de\u590d\u663e\u793a\u79ef\u6781\u60c5\u611f\uff08\u5982\u559c\u60a6\u3001\u4fe1\u4efb\uff09\u589e\u52a0\uff0c\u7b2c\u4e00\u4eba\u79f0\u4ee3\u8bcd\u4f7f\u7528\u66f4\u9891\u7e41\uff0c\u8868\u660e\u66f4\u5f3a\u7684\u4e2a\u4eba\u53c2\u4e0e\u5ea6\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cbe\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u6846\u67b6\uff0c\u4e3a\u5bf9\u8bddAI\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2511.12793", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12793", "abs": "https://arxiv.org/abs/2511.12793", "authors": ["Bowen He", "Xiaoan Xu", "Alper Kamil Bozkurt", "Vahid Tarokh", "Juncheng Dong"], "title": "Neuro-Logic Lifelong Learning", "comment": null, "summary": "Solving Inductive Logic Programming (ILP) problems with neural networks is a key challenge in Neural-Symbolic Ar- tificial Intelligence (AI). While most research has focused on designing novel network architectures for individual prob- lems, less effort has been devoted to exploring new learning paradigms involving a sequence of problems. In this work, we investigate lifelong learning ILP, which leverages the com- positional and transferable nature of logic rules for efficient learning of new problems. We introduce a compositional framework, demonstrating how logic rules acquired from ear- lier tasks can be efficiently reused in subsequent ones, leading to improved scalability and performance. We formalize our approach and empirically evaluate it on sequences of tasks. Experimental results validate the feasibility and advantages of this paradigm, opening new directions for continual learn- ing in Neural-Symbolic AI.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ec8\u8eab\u5b66\u4e60ILP\u6846\u67b6\uff0c\u5229\u7528\u903b\u8f91\u89c4\u5219\u7684\u7ec4\u5408\u6027\u548c\u53ef\u8f6c\u79fb\u6027\u6765\u9ad8\u6548\u5b66\u4e60\u65b0\u95ee\u9898\uff0c\u901a\u8fc7\u91cd\u7528\u5148\u524d\u4efb\u52a1\u4e2d\u7684\u903b\u8f91\u89c4\u5219\u6765\u63d0\u5347\u53ef\u6269\u5c55\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u795e\u7ecf\u7b26\u53f7AI\u4e2dILP\u95ee\u9898\u7684\u5173\u952e\u6311\u6218\uff0c\u63a2\u7d22\u6d89\u53ca\u95ee\u9898\u5e8f\u5217\u7684\u65b0\u5b66\u4e60\u8303\u5f0f\uff0c\u800c\u975e\u4ec5\u5173\u6ce8\u5355\u4e2a\u95ee\u9898\u7684\u7f51\u7edc\u67b6\u6784\u8bbe\u8ba1\u3002", "method": "\u5f15\u5165\u7ec4\u5408\u6027\u6846\u67b6\uff0c\u5c55\u793a\u5982\u4f55\u4ece\u65e9\u671f\u4efb\u52a1\u4e2d\u83b7\u5f97\u7684\u903b\u8f91\u89c4\u5219\u5728\u540e\u7eed\u4efb\u52a1\u4e2d\u9ad8\u6548\u91cd\u7528\uff0c\u5e76\u5f62\u5f0f\u5316\u8be5\u65b9\u6cd5\u3002", "result": "\u5728\u4efb\u52a1\u5e8f\u5217\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u8be5\u8303\u5f0f\u7684\u53ef\u884c\u6027\u548c\u4f18\u52bf\uff0c\u8868\u73b0\u51fa\u6539\u8fdb\u7684\u53ef\u6269\u5c55\u6027\u548c\u6027\u80fd\u3002", "conclusion": "\u4e3a\u795e\u7ecf\u7b26\u53f7AI\u4e2d\u7684\u6301\u7eed\u5b66\u4e60\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u8bc1\u660e\u4e86\u7ec8\u8eab\u5b66\u4e60ILP\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.12850", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12850", "abs": "https://arxiv.org/abs/2511.12850", "authors": ["Saranzaya Magsarjav", "Melissa Humphries", "Jonathan Tuke", "Lewis Mitchell"], "title": "Quantifying consistency and accuracy of Latent Dirichlet Allocation", "comment": "8 pages, 3 figures, to be submitted", "summary": "Topic modelling in Natural Language Processing uncovers hidden topics in large, unlabelled text datasets. It is widely applied in fields such as information retrieval, content summarisation, and trend analysis across various disciplines. However, probabilistic topic models can produce different results when rerun due to their stochastic nature, leading to inconsistencies in latent topics. Factors like corpus shuffling, rare text removal, and document elimination contribute to these variations. This instability affects replicability, reliability, and interpretation, raising concerns about whether topic models capture meaningful topics or just noise. To address these problems, we defined a new stability measure that incorporates accuracy and consistency and uses the generative properties of LDA to generate a new corpus with ground truth. These generated corpora are run through LDA 50 times to determine the variability in the output. We show that LDA can correctly determine the underlying number of topics in the documents. We also find that LDA is more internally consistent, as the multiple reruns return similar topics; however, these topics are not the true topics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7a33\u5b9a\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30LDA\u4e3b\u9898\u6a21\u578b\u7684\u4e00\u81f4\u6027\uff0c\u53d1\u73b0LDA\u867d\u7136\u80fd\u6b63\u786e\u8bc6\u522b\u4e3b\u9898\u6570\u91cf\u4e14\u5185\u90e8\u4e00\u81f4\u6027\u8f83\u9ad8\uff0c\u4f46\u751f\u6210\u7684\u4e3b\u9898\u5e76\u975e\u771f\u5b9e\u4e3b\u9898\u3002", "motivation": "\u6982\u7387\u4e3b\u9898\u6a21\u578b\u7531\u4e8e\u968f\u673a\u6027\u5728\u591a\u6b21\u8fd0\u884c\u65f6\u4f1a\u4ea7\u751f\u4e0d\u4e00\u81f4\u7684\u7ed3\u679c\uff0c\u5f71\u54cd\u53ef\u91cd\u590d\u6027\u3001\u53ef\u9760\u6027\u548c\u89e3\u91ca\u6027\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u662f\u5426\u771f\u6b63\u6355\u6349\u5230\u6709\u610f\u4e49\u7684\u4e3b\u9898\u8fd8\u662f\u4ec5\u4ec5\u566a\u58f0\u3002", "method": "\u5b9a\u4e49\u4e86\u4e00\u4e2a\u7ed3\u5408\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u7684\u65b0\u7a33\u5b9a\u6027\u5ea6\u91cf\uff0c\u5229\u7528LDA\u7684\u751f\u6210\u7279\u6027\u521b\u5efa\u5e26\u6709\u771f\u5b9e\u4e3b\u9898\u7684\u65b0\u8bed\u6599\u5e93\uff0c\u5e76\u5bf9\u6bcf\u4e2a\u8bed\u6599\u5e93\u8fd0\u884cLDA 50\u6b21\u6765\u8bc4\u4f30\u8f93\u51fa\u53d8\u5f02\u6027\u3002", "result": "LDA\u80fd\u591f\u6b63\u786e\u786e\u5b9a\u6587\u6863\u4e2d\u7684\u57fa\u7840\u4e3b\u9898\u6570\u91cf\uff0c\u4e14\u591a\u6b21\u91cd\u8fd0\u884c\u65f6\u8fd4\u56de\u76f8\u4f3c\u4e3b\u9898\uff0c\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u5185\u90e8\u4e00\u81f4\u6027\uff0c\u4f46\u8fd9\u4e9b\u4e3b\u9898\u5e76\u975e\u771f\u5b9e\u4e3b\u9898\u3002", "conclusion": "LDA\u6a21\u578b\u5728\u8bc6\u522b\u4e3b\u9898\u6570\u91cf\u548c\u5185\u90e8\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u751f\u6210\u7684\u4e3b\u9898\u4e0e\u771f\u5b9e\u4e3b\u9898\u5b58\u5728\u5dee\u5f02\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u63d0\u9ad8\u4e3b\u9898\u5efa\u6a21\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2511.12844", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12844", "abs": "https://arxiv.org/abs/2511.12844", "authors": ["Julia Santaniello", "Matthew Russell", "Benson Jiang", "Donatello Sassaroli", "Robert Jacob", "Jivko SInapov"], "title": "Mapping fNIRS Signals to Agent Performance: Toward Reinforcement Learning from Neural Feedback", "comment": "Accepted to the Association for the Advancement of Artificial Intelligence (AAAI) 2026. To appear in the AAAI 2026 Proceedings", "summary": "Reinforcement Learning from Human Feedback (RLHF) is a methodology that aligns agent behavior with human preferences by integrating human feedback into the agent's training process. We introduce a possible framework that employs passive Brain-Computer Interfaces (BCI) to guide agent training from implicit neural signals. We present and release a novel dataset of functional near-infrared spectroscopy (fNIRS) recordings collected from 25 human participants across three domains: a Pick-and-Place Robot, Lunar Lander, and Flappy Bird. We train classifiers to predict levels of agent performance (optimal, sub-optimal, or worst-case) from windows of preprocessed fNIRS feature vectors, achieving an average F1 score of 67% for binary classification and 46% for multi-class models averaged across conditions and domains. We also train regressors to predict the degree of deviation between an agent's chosen action and a set of near-optimal policies, providing a continuous measure of performance. We evaluate cross-subject generalization and demonstrate that fine-tuning pre-trained models with a small sample of subject-specific data increases average F1 scores by 17% and 41% for binary and multi-class models, respectively. Our work demonstrates that mapping implicit fNIRS signals to agent performance is feasible and can be improved, laying the foundation for future brain-driven RLHF systems.", "AI": {"tldr": "\u4f7f\u7528\u88ab\u52a8\u8111\u673a\u63a5\u53e3\uff08BCI\uff09\u548c\u529f\u80fd\u6027\u8fd1\u7ea2\u5916\u5149\u8c31\uff08fNIRS\uff09\u8bb0\u5f55\u6765\u6307\u5bfc\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u8bad\u7ec3\uff0c\u901a\u8fc7\u795e\u7ecf\u4fe1\u53f7\u9884\u6d4b\u4ee3\u7406\u6027\u80fd\u6c34\u5e73\uff0c\u5e76\u5c55\u793a\u4e86\u8de8\u4e3b\u4f53\u6cdb\u5316\u548c\u5fae\u8c03\u7684\u6548\u679c\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u57fa\u4e8e\u9690\u5f0f\u795e\u7ecf\u4fe1\u53f7\u7684\u5f3a\u5316\u5b66\u4e60\u4eba\u7c7b\u53cd\u9988\uff08RLHF\uff09\u6846\u67b6\uff0c\u4f7f\u4ee3\u7406\u884c\u4e3a\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\uff0c\u800c\u65e0\u9700\u663e\u5f0f\u53cd\u9988\u3002", "method": "\u6536\u96c625\u540d\u53c2\u4e0e\u8005\u5728\u4e09\u4e2a\u9886\u57df\uff08\u62fe\u653e\u673a\u5668\u4eba\u3001\u6708\u7403\u7740\u9646\u5668\u3001Flappy Bird\uff09\u7684fNIRS\u8bb0\u5f55\uff0c\u8bad\u7ec3\u5206\u7c7b\u5668\u9884\u6d4b\u4ee3\u7406\u6027\u80fd\u6c34\u5e73\uff08\u6700\u4f18\u3001\u6b21\u4f18\u3001\u6700\u5dee\uff09\uff0c\u5e76\u8bad\u7ec3\u56de\u5f52\u5668\u9884\u6d4b\u52a8\u4f5c\u4e0e\u6700\u4f18\u7b56\u7565\u7684\u504f\u5dee\u7a0b\u5ea6\u3002", "result": "\u4e8c\u5143\u5206\u7c7b\u5e73\u5747F1\u5206\u657067%\uff0c\u591a\u5206\u7c7b\u5e73\u574746%\uff1b\u8de8\u4e3b\u4f53\u5fae\u8c03\u540e\u4e8c\u5143\u548c\u591a\u5206\u7c7bF1\u5206\u6570\u5206\u522b\u63d0\u534717%\u548c41%\u3002", "conclusion": "\u4ece\u9690\u5f0ffNIRS\u4fe1\u53f7\u6620\u5c04\u5230\u4ee3\u7406\u6027\u80fd\u662f\u53ef\u884c\u7684\uff0c\u4e3a\u672a\u6765\u8111\u9a71\u52a8\u7684RLHF\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.12851", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12851", "abs": "https://arxiv.org/abs/2511.12851", "authors": ["Kang Yin", "Hye-Bin Shin"], "title": "NeuroLex: A Lightweight Domain Language Model for EEG Report Understanding and Generation", "comment": null, "summary": "Clinical electroencephalogram (EEG) reports encode domain-specific linguistic conventions that general-purpose language models (LMs) fail to capture. We introduce NeuroLex, a lightweight domain-adaptive language model trained purely on EEG report text from the Harvard Electroencephalography Database. Unlike existing biomedical LMs, NeuroLex is tailored to the linguistic and diagnostic characteristics of EEG reporting, enabling it to serve as both an independent textual model and a decoder backbone for multimodal EEG-language systems. Using span-corruption pretraining and instruction-style fine-tuning on report polishing, paragraph summarization, and terminology question answering, NeuroLex learns the syntax and reasoning patterns characteristic of EEG interpretation. Comprehensive evaluations show that it achieves lower perplexity, higher extraction and summarization accuracy, better label efficiency, and improved robustness to negation and factual hallucination compared with general models of the same scale. With an EEG-aware linguistic backbone, NeuroLex bridges biomedical text modeling and brain-computer interface applications, offering a foundation for interpretable and language-driven neural decoding.", "AI": {"tldr": "NeuroLex\u662f\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u4e34\u5e8a\u8111\u7535\u56fe\u62a5\u544a\u8bad\u7ec3\u7684\u8f7b\u91cf\u7ea7\u9886\u57df\u81ea\u9002\u5e94\u8bed\u8a00\u6a21\u578b\uff0c\u76f8\u6bd4\u901a\u7528\u6a21\u578b\u5728EEG\u62a5\u544a\u5904\u7406\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u53ef\u4f5c\u4e3a\u72ec\u7acb\u6587\u672c\u6a21\u578b\u6216\u591a\u6a21\u6001\u7cfb\u7edf\u7684\u89e3\u7801\u5668\u9aa8\u5e72\u3002", "motivation": "\u901a\u7528\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u6355\u6349\u4e34\u5e8a\u8111\u7535\u56fe\u62a5\u544a\u4e2d\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u60ef\u4f8b\uff0c\u9700\u8981\u4e13\u95e8\u9488\u5bf9EEG\u62a5\u544a\u6587\u672c\u8bad\u7ec3\u7684\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u54c8\u4f5b\u8111\u7535\u56fe\u6570\u636e\u5e93\u7684EEG\u62a5\u544a\u6587\u672c\u8fdb\u884c\u8bad\u7ec3\uff0c\u91c7\u7528span-corruption\u9884\u8bad\u7ec3\u548c\u6307\u4ee4\u5f0f\u5fae\u8c03\uff08\u62a5\u544a\u6da6\u8272\u3001\u6bb5\u843d\u6458\u8981\u3001\u672f\u8bed\u95ee\u7b54\uff09\uff0c\u5b66\u4e60EEG\u89e3\u91ca\u7684\u8bed\u6cd5\u548c\u63a8\u7406\u6a21\u5f0f\u3002", "result": "\u76f8\u6bd4\u540c\u89c4\u6a21\u901a\u7528\u6a21\u578b\uff0cNeuroLex\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u56f0\u60d1\u5ea6\u3001\u66f4\u9ad8\u7684\u63d0\u53d6\u548c\u6458\u8981\u51c6\u786e\u5ea6\u3001\u66f4\u597d\u7684\u6807\u7b7e\u6548\u7387\uff0c\u4ee5\u53ca\u5bf9\u5426\u5b9a\u548c\u4e8b\u5b9e\u5e7b\u89c9\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "NeuroLex\u901a\u8fc7EEG\u611f\u77e5\u7684\u8bed\u8a00\u9aa8\u5e72\uff0c\u8fde\u63a5\u4e86\u751f\u7269\u533b\u5b66\u6587\u672c\u5efa\u6a21\u548c\u8111\u673a\u63a5\u53e3\u5e94\u7528\uff0c\u4e3a\u53ef\u89e3\u91ca\u548c\u8bed\u8a00\u9a71\u52a8\u7684\u795e\u7ecf\u89e3\u7801\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.12867", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12867", "abs": "https://arxiv.org/abs/2511.12867", "authors": ["Chen Jia"], "title": "Bootstrapping LLMs via Preference-Based Policy Optimization", "comment": null, "summary": "Bootstrapping large language models (LLMs) through preference-based policy optimization offers a promising direction for aligning model behavior with human preferences without relying on extensive manual annotations. In this work, we propose a novel preference-based policy optimization (PbPO) framework that formulates the learning process as a min-max game between the main policy and a reward model (RM). The RM is constrained within a confidence set derived from preference data to ensure reliable exploitation. Our iterative online algorithm actively collects preference data through guided exploration of the evolving policy, enabling continual self-improvement of both the policy and the RM. We provide theoretical guarantees for our method, establishing high-probability regret bounds for both settings with sequence-level RM and token-level RM, demonstrating its effectiveness in bootstrapping LLMs. Extensive experiments on five benchmarks show that our approach consistently outperforms existing state-of-the-art preference optimization techniques.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u504f\u597d\u7684\u7b56\u7565\u4f18\u5316\u6846\u67b6PbPO\uff0c\u901a\u8fc7\u4e3b\u7b56\u7565\u548c\u5956\u52b1\u6a21\u578b\u4e4b\u95f4\u7684min-max\u535a\u5f08\u6765\u5bf9\u9f50LLM\u884c\u4e3a\uff0c\u65e0\u9700\u5927\u91cf\u4eba\u5de5\u6807\u6ce8\u3002", "motivation": "\u901a\u8fc7\u57fa\u4e8e\u504f\u597d\u7684\u7b56\u7565\u4f18\u5316\u6765\u5f15\u5bfc\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u5176\u884c\u4e3a\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\uff0c\u800c\u4e0d\u4f9d\u8d56\u5927\u91cf\u624b\u52a8\u6807\u6ce8\u3002", "method": "\u5c06\u5b66\u4e60\u8fc7\u7a0b\u6784\u5efa\u4e3a\u4e3b\u7b56\u7565\u548c\u5956\u52b1\u6a21\u578b\u4e4b\u95f4\u7684min-max\u535a\u5f08\uff0c\u5956\u52b1\u6a21\u578b\u7ea6\u675f\u5728\u504f\u597d\u6570\u636e\u5bfc\u51fa\u7684\u7f6e\u4fe1\u96c6\u5185\uff0c\u91c7\u7528\u8fed\u4ee3\u5728\u7ebf\u7b97\u6cd5\u901a\u8fc7\u5f15\u5bfc\u63a2\u7d22\u4e3b\u52a8\u6536\u96c6\u504f\u597d\u6570\u636e\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u504f\u597d\u4f18\u5316\u6280\u672f\u3002", "conclusion": "\u63d0\u51fa\u7684PbPO\u6846\u67b6\u5728\u5f15\u5bfcLLM\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u57fa\u4e8e\u504f\u597d\u7684\u7b56\u7565\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.12861", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.12861", "abs": "https://arxiv.org/abs/2511.12861", "authors": ["Wenxin Zhu", "Andong Chen", "Yuchen Song", "Kehai Chen", "Conghui Zhu", "Ziyan Chen", "Tiejun Zhao"], "title": "From Perception to Reasoning: Deep Thinking Empowers Multimodal Large Language Models", "comment": "Survey; 7 figures, 3 tables, 44 pages", "summary": "With the remarkable success of Multimodal Large Language Models (MLLMs) in perception tasks, enhancing their complex reasoning capabilities has emerged as a critical research focus. Existing models still suffer from challenges such as opaque reasoning paths and insufficient generalization ability. Chain-of-Thought (CoT) reasoning, which has demonstrated significant efficacy in language models by enhancing reasoning transparency and output interpretability, holds promise for improving model reasoning capabilities when extended to the multimodal domain. This paper provides a systematic review centered on \"Multimodal Chain-of-Thought\" (MCoT). First, it analyzes the background and theoretical motivations for its inception from the perspectives of technical evolution and task demands. Then, it introduces mainstream MCoT methods from three aspects: CoT paradigms, the post-training stage, and the inference stage, while also analyzing their underlying mechanisms. Furthermore, the paper summarizes existing evaluation benchmarks and metrics, and discusses the application scenarios of MCoT. Finally, it analyzes the challenges currently facing MCoT and provides an outlook on its future research directions.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u591a\u6a21\u6001\u601d\u7ef4\u94fe(MCoT)\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u5206\u6790\u4e86\u5176\u80cc\u666f\u52a8\u673a\u3001\u4e3b\u6d41\u65b9\u6cd5\u3001\u8bc4\u4f30\u57fa\u51c6\u3001\u5e94\u7528\u573a\u666f\uff0c\u5e76\u8ba8\u8bba\u4e86\u5f53\u524d\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u611f\u77e5\u4efb\u52a1\u4e2d\u7684\u663e\u8457\u6210\u529f\uff0c\u589e\u5f3a\u5176\u590d\u6742\u63a8\u7406\u80fd\u529b\u6210\u4e3a\u5173\u952e\u7814\u7a76\u91cd\u70b9\u3002\u73b0\u6709\u6a21\u578b\u5b58\u5728\u63a8\u7406\u8def\u5f84\u4e0d\u900f\u660e\u548c\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7b49\u6311\u6218\uff0c\u800c\u601d\u7ef4\u94fe\u63a8\u7406\u5728\u8bed\u8a00\u6a21\u578b\u4e2d\u5df2\u8bc1\u660e\u80fd\u589e\u5f3a\u63a8\u7406\u900f\u660e\u5ea6\u548c\u8f93\u51fa\u53ef\u89e3\u91ca\u6027\uff0c\u6709\u671b\u5728\u6269\u5c55\u5230\u591a\u6a21\u6001\u9886\u57df\u540e\u63d0\u5347\u6a21\u578b\u63a8\u7406\u80fd\u529b\u3002", "method": "\u4ece\u4e09\u4e2a\u65b9\u9762\u4ecb\u7ecd\u4e3b\u6d41MCoT\u65b9\u6cd5\uff1a\u601d\u7ef4\u94fe\u8303\u5f0f\u3001\u540e\u8bad\u7ec3\u9636\u6bb5\u548c\u63a8\u7406\u9636\u6bb5\uff0c\u5e76\u5206\u6790\u5176\u5e95\u5c42\u673a\u5236\u3002", "result": "\u603b\u7ed3\u4e86\u73b0\u6709\u7684\u8bc4\u4f30\u57fa\u51c6\u548c\u6307\u6807\uff0c\u8ba8\u8bba\u4e86MCoT\u7684\u5e94\u7528\u573a\u666f\u3002", "conclusion": "\u5206\u6790\u4e86MCoT\u5f53\u524d\u9762\u4e34\u7684\u6311\u6218\uff0c\u5e76\u5bf9\u5176\u672a\u6765\u7814\u7a76\u65b9\u5411\u8fdb\u884c\u4e86\u5c55\u671b\u3002"}}
{"id": "2511.12876", "categories": ["cs.AI", "econ.GN"], "pdf": "https://arxiv.org/pdf/2511.12876", "abs": "https://arxiv.org/abs/2511.12876", "authors": ["Heyang Ma", "Qirui Mi", "Qipeng Yang", "Zijun Fan", "Bo Li", "Haifeng Zhang"], "title": "Think, Speak, Decide: Language-Augmented Multi-Agent Reinforcement Learning for Economic Decision-Making", "comment": "Extended version of a submission to AAAI 2026", "summary": "Economic decision-making depends not only on structured signals such as prices and taxes, but also on unstructured language, including peer dialogue and media narratives. While multi-agent reinforcement learning (MARL) has shown promise in optimizing economic decisions, it struggles with the semantic ambiguity and contextual richness of language. We propose LAMP (Language-Augmented Multi-Agent Policy), a framework that integrates language into economic decision-making and narrows the gap to real-world settings. LAMP follows a Think-Speak-Decide pipeline: (1) Think interprets numerical observations to extract short-term shocks and long-term trends, caching high-value reasoning trajectories; (2) Speak crafts and exchanges strategic messages based on reasoning, updating beliefs by parsing peer communications; and (3) Decide fuses numerical data, reasoning, and reflections into a MARL policy to optimize language-augmented decision-making. Experiments in economic simulation show that LAMP outperforms both MARL and LLM-only baselines in cumulative return (+63.5%, +34.0%), robustness (+18.8%, +59.4%), and interpretability. These results demonstrate the potential of language-augmented policies to deliver more effective and robust economic strategies.", "AI": {"tldr": "LAMP\u6846\u67b6\u901a\u8fc7\u8bed\u8a00\u589e\u5f3a\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff0c\u5728\u7ecf\u6d4e\u51b3\u7b56\u4e2d\u6574\u5408\u8bed\u8a00\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3001\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u5b9e\u7ecf\u6d4e\u51b3\u7b56\u4e0d\u4ec5\u4f9d\u8d56\u7ed3\u6784\u5316\u4fe1\u53f7\uff08\u5982\u4ef7\u683c\u3001\u7a0e\u6536\uff09\uff0c\u8fd8\u4f9d\u8d56\u975e\u7ed3\u6784\u5316\u8bed\u8a00\u4fe1\u606f\uff08\u5982\u540c\u884c\u5bf9\u8bdd\u3001\u5a92\u4f53\u53d9\u4e8b\uff09\u3002\u4f20\u7edfMARL\u96be\u4ee5\u5904\u7406\u8bed\u8a00\u7684\u8bed\u4e49\u6a21\u7cca\u6027\u548c\u4e0a\u4e0b\u6587\u4e30\u5bcc\u6027\u3002", "method": "\u91c7\u7528Think-Speak-Decide\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1aThink\u9636\u6bb5\u89e3\u91ca\u6570\u503c\u89c2\u6d4b\u63d0\u53d6\u77ed\u671f\u51b2\u51fb\u548c\u957f\u671f\u8d8b\u52bf\uff1bSpeak\u9636\u6bb5\u57fa\u4e8e\u63a8\u7406\u751f\u6210\u548c\u4ea4\u6362\u7b56\u7565\u6d88\u606f\uff1bDecide\u9636\u6bb5\u878d\u5408\u6570\u503c\u6570\u636e\u3001\u63a8\u7406\u548c\u53cd\u601d\u5230MARL\u7b56\u7565\u4e2d\u3002", "result": "\u5728\u7ecf\u6d4e\u6a21\u62df\u5b9e\u9a8c\u4e2d\uff0cLAMP\u5728\u7d2f\u79ef\u56de\u62a5\uff08+63.5%, +34.0%\uff09\u3001\u9c81\u68d2\u6027\uff08+18.8%, +59.4%\uff09\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5747\u4f18\u4e8eMARL\u548c\u7eafLLM\u57fa\u7ebf\u3002", "conclusion": "\u8bed\u8a00\u589e\u5f3a\u7b56\u7565\u6709\u6f5c\u529b\u63d0\u4f9b\u66f4\u6709\u6548\u548c\u9c81\u68d2\u7684\u7ecf\u6d4e\u7b56\u7565\uff0c\u7f29\u5c0f\u4e0e\u73b0\u5b9e\u4e16\u754c\u8bbe\u7f6e\u7684\u5dee\u8ddd\u3002"}}
{"id": "2511.12874", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.12874", "abs": "https://arxiv.org/abs/2511.12874", "authors": ["Chukwuebuka Fortunate Ijezue", "Tania-Amanda Fredrick Eneye", "Maaz Amjad"], "title": "Classification of Hope in Textual Data using Transformer-Based Models", "comment": null, "summary": "This paper presents a transformer-based approach for classifying hope expressions in text. We developed and compared three architectures (BERT, GPT-2, and DeBERTa) for both binary classification (Hope vs. Not Hope) and multiclass categorization (five hope-related categories). Our initial BERT implementation achieved 83.65% binary and 74.87% multiclass accuracy. In the extended comparison, BERT demonstrated superior performance (84.49% binary, 72.03% multiclass accuracy) while requiring significantly fewer computational resources (443s vs. 704s training time) than newer architectures. GPT-2 showed lowest overall accuracy (79.34% binary, 71.29% multiclass), while DeBERTa achieved moderate results (80.70% binary, 71.56% multiclass) but at substantially higher computational cost (947s for multiclass training). Error analysis revealed architecture-specific strengths in detecting nuanced hope expressions, with GPT-2 excelling at sarcasm detection (92.46% recall). This study provides a framework for computational analysis of hope, with applications in mental health and social media analysis, while demonstrating that architectural suitability may outweigh model size for specialized emotion detection tasks.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u4e09\u79cd\u57fa\u4e8eTransformer\u7684\u67b6\u6784\uff08BERT\u3001GPT-2\u3001DeBERTa\uff09\u5728\u5e0c\u671b\u8868\u8fbe\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0BERT\u5728\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u8ba1\u7b97\u6846\u67b6\u6765\u5206\u6790\u6587\u672c\u4e2d\u7684\u5e0c\u671b\u8868\u8fbe\uff0c\u5e94\u7528\u4e8e\u5fc3\u7406\u5065\u5eb7\u548c\u793e\u4ea4\u5a92\u4f53\u5206\u6790\u9886\u57df\uff0c\u540c\u65f6\u63a2\u7d22\u4e0d\u540c\u67b6\u6784\u5728\u4e13\u95e8\u60c5\u611f\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u4f7f\u7528BERT\u3001GPT-2\u548cDeBERTa\u4e09\u79cdTransformer\u67b6\u6784\u8fdb\u884c\u4e8c\u5143\u5206\u7c7b\uff08\u5e0c\u671bvs\u975e\u5e0c\u671b\uff09\u548c\u591a\u7c7b\u522b\u5206\u7c7b\uff08\u4e94\u4e2a\u5e0c\u671b\u76f8\u5173\u7c7b\u522b\uff09\uff0c\u6bd4\u8f83\u5b83\u4eec\u7684\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "result": "BERT\u5728\u4e8c\u5143\u5206\u7c7b\u548c\u591a\u7c7b\u522b\u5206\u7c7b\u4e2d\u5747\u8868\u73b0\u6700\u4f73\uff0884.49%\u4e8c\u5143\u51c6\u786e\u7387\uff0c72.03%\u591a\u7c7b\u522b\u51c6\u786e\u7387\uff09\uff0c\u4e14\u8ba1\u7b97\u6548\u7387\u6700\u9ad8\uff08443\u79d2\u8bad\u7ec3\u65f6\u95f4\uff09\u3002GPT-2\u8868\u73b0\u6700\u5dee\uff0c\u4f46\u64c5\u957f\u68c0\u6d4b\u8bbd\u523a\u6027\u5e0c\u671b\u8868\u8fbe\uff0892.46%\u53ec\u56de\u7387\uff09\u3002DeBERTa\u8868\u73b0\u4e2d\u7b49\u4f46\u8ba1\u7b97\u6210\u672c\u6700\u9ad8\u3002", "conclusion": "\u5bf9\u4e8e\u4e13\u95e8\u7684\u5e0c\u671b\u8868\u8fbe\u68c0\u6d4b\u4efb\u52a1\uff0c\u67b6\u6784\u7684\u9002\u7528\u6027\u53ef\u80fd\u6bd4\u6a21\u578b\u89c4\u6a21\u66f4\u91cd\u8981\uff0cBERT\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u63d0\u4f9b\u4e86\u6700\u4f73\u5e73\u8861\uff0c\u4e3a\u5e0c\u671b\u7684\u8ba1\u7b97\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2511.12901", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12901", "abs": "https://arxiv.org/abs/2511.12901", "authors": ["Yuesheng Xu", "Hector Munoz-Avila"], "title": "Online Learning of HTN Methods for integrated LLM-HTN Planning", "comment": "The Twelfth Annual Conference on Advances in Cognitive Systems (ACS-2025)", "summary": "We present online learning of Hierarchical Task Network (HTN) methods in the context of integrated HTN planning and LLM-based chatbots. Methods indicate when and how to decompose tasks into subtasks. Our method learner is built on top of the ChatHTN planner. ChatHTN queries ChatGPT to generate a decomposition of a task into primitive tasks when no applicable method for the task is available. In this work, we extend ChatHTN. Namely, when ChatGPT generates a task decomposition, ChatHTN learns from it, akin to memoization. However, unlike memoization, it learns a generalized method that applies not only to the specific instance encountered, but to other instances of the same task. We conduct experiments on two domains and demonstrate that our online learning procedure reduces the number of calls to ChatGPT while solving at least as many problems, and in some cases, even more.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u7ebf\u5b66\u4e60\u5206\u5c42\u4efb\u52a1\u7f51\u7edc(HTN)\u65b9\u6cd5\u7684\u65b9\u6cd5\uff0c\u57fa\u4e8eChatHTN\u89c4\u5212\u5668\uff0c\u901a\u8fc7\u4eceChatGPT\u751f\u6210\u7684\u4efb\u52a1\u5206\u89e3\u4e2d\u5b66\u4e60\u901a\u7528\u65b9\u6cd5\uff0c\u51cf\u5c11\u5bf9ChatGPT\u7684\u8c03\u7528\u6b21\u6570\u3002", "motivation": "\u5728\u96c6\u6210HTN\u89c4\u5212\u548c\u57fa\u4e8eLLM\u7684\u804a\u5929\u673a\u5668\u4eba\u80cc\u666f\u4e0b\uff0c\u9700\u8981\u5b66\u4e60\u4f55\u65f6\u4ee5\u53ca\u5982\u4f55\u5c06\u4efb\u52a1\u5206\u89e3\u4e3a\u5b50\u4efb\u52a1\uff0c\u4ee5\u51cf\u5c11\u5bf9ChatGPT\u7684\u4f9d\u8d56\u5e76\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u5728ChatHTN\u89c4\u5212\u5668\u57fa\u7840\u4e0a\u6269\u5c55\uff0c\u5f53ChatGPT\u751f\u6210\u4efb\u52a1\u5206\u89e3\u65f6\uff0c\u5b66\u4e60\u901a\u7528\u65b9\u6cd5\u800c\u975e\u7b80\u5355\u8bb0\u5fc6\uff0c\u4f7f\u65b9\u6cd5\u9002\u7528\u4e8e\u540c\u4e00\u4efb\u52a1\u7684\u5176\u4ed6\u5b9e\u4f8b\u3002", "result": "\u5728\u4e24\u4e2a\u9886\u57df\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc1\u660e\u5728\u7ebf\u5b66\u4e60\u8fc7\u7a0b\u51cf\u5c11\u4e86ChatGPT\u8c03\u7528\u6b21\u6570\uff0c\u540c\u65f6\u89e3\u51b3\u4e86\u81f3\u5c11\u540c\u6837\u591a\u7684\u95ee\u9898\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u751a\u81f3\u66f4\u591a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u5bf9ChatGPT\u7684\u4f9d\u8d56\uff0c\u63d0\u9ad8HTN\u89c4\u5212\u7684\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002"}}
{"id": "2511.12920", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.12920", "abs": "https://arxiv.org/abs/2511.12920", "authors": ["Desheng Hu", "Joachim Baumann", "Aleksandra Urman", "Elsa Lichtenegger", "Robin Forsberg", "Aniko Hannak", "Christo Wilson"], "title": "Auditing Google's AI Overviews and Featured Snippets: A Case Study on Baby Care and Pregnancy", "comment": "18 pages, 10 figures; to appear in AAAI ICWSM 2026", "summary": "Google Search increasingly surfaces AI-generated content through features like AI Overviews (AIO) and Featured Snippets (FS), which users frequently rely on despite having no control over their presentation. Through a systematic algorithm audit of 1,508 real baby care and pregnancy-related queries, we evaluate the quality and consistency of these information displays. Our robust evaluation framework assesses multiple quality dimensions, including answer consistency, relevance, presence of medical safeguards, source categories, and sentiment alignment. Our results reveal concerning gaps in information consistency, with information in AIO and FS displayed on the same search result page being inconsistent with each other in 33% of cases. Despite high relevance scores, both features critically lack medical safeguards (present in just 11% of AIO and 7% of FS responses). While health and wellness websites dominate source categories for both, AIO and FS, FS also often link to commercial sources. These findings have important implications for public health information access and demonstrate the need for stronger quality controls in AI-mediated health information. Our methodology provides a transferable framework for auditing AI systems across high-stakes domains where information quality directly impacts user well-being.", "AI": {"tldr": "\u901a\u8fc7\u7cfb\u7edf\u7b97\u6cd5\u5ba1\u8ba1\u53d1\u73b0\uff0cGoogle\u641c\u7d22\u7684AI\u6982\u89c8\u548c\u7cbe\u9009\u6458\u8981\u529f\u80fd\u5728\u5065\u5eb7\u4fe1\u606f\u5c55\u793a\u4e2d\u5b58\u5728\u4e25\u91cd\u8d28\u91cf\u95ee\u9898\uff0c\u5305\u62ec33%\u7684\u4fe1\u606f\u4e0d\u4e00\u81f4\u6027\u3001\u533b\u7597\u5b89\u5168\u63aa\u65bd\u4e25\u91cd\u7f3a\u5931\u7b49\u95ee\u9898\u3002", "motivation": "\u8bc4\u4f30Google\u641c\u7d22AI\u751f\u6210\u5185\u5bb9\uff08AI\u6982\u89c8\u548c\u7cbe\u9009\u6458\u8981\uff09\u5728\u5a74\u513f\u62a4\u7406\u548c\u5b55\u671f\u76f8\u5173\u67e5\u8be2\u4e2d\u7684\u4fe1\u606f\u8d28\u91cf\u548c\u4e00\u81f4\u6027\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u529f\u80fd\u7528\u6237\u4f9d\u8d56\u5ea6\u9ad8\u4f46\u7f3a\u4e4f\u63a7\u5236\u6743\u3002", "method": "\u5bf91,508\u4e2a\u771f\u5b9e\u5a74\u513f\u62a4\u7406\u548c\u5b55\u671f\u76f8\u5173\u67e5\u8be2\u8fdb\u884c\u7cfb\u7edf\u7b97\u6cd5\u5ba1\u8ba1\uff0c\u4f7f\u7528\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6846\u67b6\u5206\u6790\u7b54\u6848\u4e00\u81f4\u6027\u3001\u76f8\u5173\u6027\u3001\u533b\u7597\u5b89\u5168\u63aa\u65bd\u3001\u6765\u6e90\u7c7b\u522b\u548c\u60c5\u611f\u5bf9\u9f50\u3002", "result": "AI\u6982\u89c8\u548c\u7cbe\u9009\u6458\u8981\u5728\u540c\u4e00\u641c\u7d22\u7ed3\u679c\u9875\u9762\u4e0a\u670933%\u7684\u4fe1\u606f\u4e0d\u4e00\u81f4\uff1b\u533b\u7597\u5b89\u5168\u63aa\u65bd\u4e25\u91cd\u7f3a\u5931\uff08AI\u6982\u89c8\u4ec511%\uff0c\u7cbe\u9009\u6458\u8981\u4ec57%\uff09\uff1b\u5065\u5eb7\u7f51\u7ad9\u662f\u4e3b\u8981\u6765\u6e90\uff0c\u4f46\u7cbe\u9009\u6458\u8981\u4e5f\u5e38\u94fe\u63a5\u5546\u4e1a\u6765\u6e90\u3002", "conclusion": "AI\u4ecb\u5bfc\u7684\u5065\u5eb7\u4fe1\u606f\u9700\u8981\u66f4\u5f3a\u7684\u8d28\u91cf\u63a7\u5236\uff0c\u8be5\u5ba1\u8ba1\u65b9\u6cd5\u4e3a\u9ad8\u98ce\u9669\u9886\u57dfAI\u7cfb\u7edf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u8f6c\u79fb\u7684\u6846\u67b6\u3002"}}
{"id": "2511.12913", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12913", "abs": "https://arxiv.org/abs/2511.12913", "authors": ["Yiming Zhao", "Jiwei Tang", "Shimin Di", "Libin Zheng", "Jianxing Yu", "Jian Yin"], "title": "CoS: Towards Optimal Event Scheduling via Chain-of-Scheduling", "comment": null, "summary": "Recommending event schedules is a key issue in Event-based Social Networks (EBSNs) in order to maintain user activity. An effective recommendation is required to maximize the user's preference, subjecting to both time and geographical constraints. Existing methods face an inherent trade-off among efficiency, effectiveness, and generalization, due to the NP-hard nature of the problem. This paper proposes the Chain-of-Scheduling (CoS) framework, which activates the event scheduling capability of Large Language Models (LLMs) through a guided, efficient scheduling process. CoS enhances LLM by formulating the schedule task into three atomic stages, i.e., exploration, verification and integration. Then we enable the LLMs to generate CoS autonomously via Knowledge Distillation (KD). Experimental results show that CoS achieves near-theoretical optimal effectiveness with high efficiency on three real-world datasets in a interpretable manner. Moreover, it demonstrates strong zero-shot learning ability on out-of-domain data.", "AI": {"tldr": "\u63d0\u51fa\u4e86Chain-of-Scheduling (CoS)\u6846\u67b6\uff0c\u901a\u8fc7\u63a2\u7d22\u3001\u9a8c\u8bc1\u548c\u96c6\u6210\u4e09\u4e2a\u539f\u5b50\u9636\u6bb5\u6fc0\u6d3bLLM\u7684\u4e8b\u4ef6\u8c03\u5ea6\u80fd\u529b\uff0c\u5728EBSNs\u4e2d\u5b9e\u73b0\u9ad8\u6548\u6709\u6548\u7684\u4e8b\u4ef6\u63a8\u8350\u3002", "motivation": "\u73b0\u6709\u7684\u4e8b\u4ef6\u63a8\u8350\u65b9\u6cd5\u5728\u6548\u7387\u3001\u6548\u679c\u548c\u6cdb\u5316\u6027\u4e4b\u95f4\u5b58\u5728\u56fa\u6709\u6743\u8861\uff0c\u56e0\u4e3a\u8be5\u95ee\u9898\u662fNP\u96be\u95ee\u9898\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u6700\u5927\u5316\u7528\u6237\u504f\u597d\uff0c\u53c8\u80fd\u6ee1\u8db3\u65f6\u95f4\u548c\u5730\u7406\u7ea6\u675f\u7684\u6709\u6548\u63a8\u8350\u65b9\u6cd5\u3002", "method": "CoS\u6846\u67b6\u5c06\u8c03\u5ea6\u4efb\u52a1\u5206\u89e3\u4e3a\u63a2\u7d22\u3001\u9a8c\u8bc1\u548c\u96c6\u6210\u4e09\u4e2a\u539f\u5b50\u9636\u6bb5\uff0c\u5e76\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u4f7fLLM\u80fd\u591f\u81ea\u4e3b\u751f\u6210CoS\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\uff0cCoS\u5b9e\u73b0\u4e86\u63a5\u8fd1\u7406\u8bba\u6700\u4f18\u7684\u6548\u679c\uff0c\u5177\u6709\u9ad8\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u5728\u57df\u5916\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u96f6\u6837\u672c\u5b66\u4e60\u80fd\u529b\u3002", "conclusion": "CoS\u6846\u67b6\u6210\u529f\u6fc0\u6d3b\u4e86LLM\u7684\u4e8b\u4ef6\u8c03\u5ea6\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u4e8b\u4ef6\u63a8\u8350\u4e2d\u7684\u6548\u7387-\u6548\u679c-\u6cdb\u5316\u6027\u6743\u8861\u95ee\u9898\uff0c\u4e3aEBSNs\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.12928", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12928", "abs": "https://arxiv.org/abs/2511.12928", "authors": ["Haokun Li", "Yazhou Zhang", "Jizhi Ding", "Qiuchi Li", "Peng Zhang"], "title": "Visual Room 2.0: Seeing is Not Understanding for MLLMs", "comment": null, "summary": "Can multi-modal large language models (MLLMs) truly understand what they can see? Extending Searle's Chinese Room into the multi-modal domain, this paper proposes the Visual Room argument: MLLMs may describe every visual detail precisely yet fail to comprehend the underlying emotions and intentions, namely seeing is not understanding. Building on this, we introduce \\textit{Visual Room} 2.0, a hierarchical benchmark for evaluating perception-cognition alignment of MLLMs. We model human perceptive and cognitive processes across three levels: low, middle, and high, covering 17 representative tasks. The perception component ranges from attribute recognition to scene understanding, while the cognition component extends from textual entailment to causal and social reasoning. The dataset contains 350 multi-modal samples, each with six progressive questions (2,100 in total) spanning perception to cognition. Evaluating 10 state-of-the-art (SoTA) MLLMs, we highlight three key findings: (1) MLLMs exhibit stronger perceptual competence than cognitive ability (8.0\\%$\\uparrow$); (2) cognition appears not causally dependent on perception-based reasoning; and (3) cognition scales with model size, but perception does not consistently improve with larger variants. This work operationalizes Seeing $\\ne$ Understanding as a testable hypothesis, offering a new paradigm from perceptual processing to cognitive reasoning in MLLMs. Our dataset is available at https://huggingface.co/datasets/LHK2003/PCBench.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u89c6\u89c9\u5ba4\u8bba\u8bc1\uff0c\u8ba4\u4e3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b(MLLMs)\u53ef\u80fd\u7cbe\u786e\u63cf\u8ff0\u89c6\u89c9\u7ec6\u8282\u4f46\u65e0\u6cd5\u7406\u89e3\u5e95\u5c42\u60c5\u611f\u548c\u610f\u56fe\uff0c\u5373\u770b\u89c1\u4e0d\u7b49\u4e8e\u7406\u89e3\u3002\u4f5c\u8005\u6784\u5efa\u4e86Visual Room 2.0\u57fa\u51c6\u6765\u8bc4\u4f30MLLMs\u7684\u611f\u77e5-\u8ba4\u77e5\u5bf9\u9f50\uff0c\u5305\u542b17\u4e2a\u4efb\u52a1\u548c350\u4e2a\u591a\u6a21\u6001\u6837\u672c\u3002", "motivation": "\u57fa\u4e8eSearle\u7684\u4e2d\u6587\u5c4b\u601d\u60f3\u6269\u5c55\u5230\u591a\u6a21\u6001\u9886\u57df\uff0c\u8d28\u7591MLLMs\u662f\u5426\u771f\u6b63\u7406\u89e3\u6240\u89c1\u5185\u5bb9\uff0c\u63a2\u7d22\u611f\u77e5\u4e0e\u8ba4\u77e5\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u6784\u5efa\u4e86\u5206\u5c42\u57fa\u51c6Visual Room 2.0\uff0c\u6a21\u62df\u4eba\u7c7b\u611f\u77e5\u548c\u8ba4\u77e5\u8fc7\u7a0b\u7684\u4e09\u4e2a\u5c42\u6b21\uff08\u4f4e\u3001\u4e2d\u3001\u9ad8\uff09\uff0c\u6db5\u76d617\u4e2a\u4ee3\u8868\u6027\u4efb\u52a1\uff0c\u5305\u542b350\u4e2a\u591a\u6a21\u6001\u6837\u672c\uff0c\u6bcf\u4e2a\u6837\u672c\u67096\u4e2a\u6e10\u8fdb\u5f0f\u95ee\u9898\u3002", "result": "\u8bc4\u4f3010\u4e2a\u6700\u5148\u8fdb\u7684MLLMs\u53d1\u73b0\uff1a(1) MLLMs\u7684\u611f\u77e5\u80fd\u529b\u4f18\u4e8e\u8ba4\u77e5\u80fd\u529b(8.0%\u2191)\uff1b(2) \u8ba4\u77e5\u4f3c\u4e4e\u4e0d\u56e0\u679c\u4f9d\u8d56\u4e8e\u57fa\u4e8e\u611f\u77e5\u7684\u63a8\u7406\uff1b(3) \u8ba4\u77e5\u968f\u6a21\u578b\u89c4\u6a21\u6269\u5c55\uff0c\u4f46\u611f\u77e5\u4e0d\u968f\u66f4\u5927\u53d8\u4f53\u4e00\u81f4\u63d0\u5347\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c06\"\u770b\u89c1\u2260\u7406\u89e3\"\u4f5c\u4e3a\u53ef\u68c0\u9a8c\u5047\u8bbe\u64cd\u4f5c\u5316\uff0c\u4e3aMLLMs\u4ece\u611f\u77e5\u5904\u7406\u5230\u8ba4\u77e5\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u9a8c\u8bc1\u4e86\u611f\u77e5\u4e0e\u8ba4\u77e5\u4e4b\u95f4\u7684\u5b9e\u8d28\u6027\u5dee\u8ddd\u3002"}}
{"id": "2511.12916", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12916", "abs": "https://arxiv.org/abs/2511.12916", "authors": ["Yafang Wang", "Yangjie Tian", "Xiaoyu Shen", "Gaoyang Zhang", "Jiaze Sun", "He Zhang", "Ruohua Xu", "Feng Zhao"], "title": "Fault2Flow: An AlphaEvolve-Optimized Human-in-the-Loop Multi-Agent System for Fault-to-Workflow Automation", "comment": null, "summary": "Power grid fault diagnosis is a critical process hindered by its reliance on manual, error-prone methods. Technicians must manually extract reasoning logic from dense regulations and attempt to combine it with tacit expert knowledge, which is inefficient, error-prone, and lacks maintainability as ragulations are updated and experience evolves. While Large Language Models (LLMs) have shown promise in parsing unstructured text, no existing framework integrates these two disparate knowledge sources into a single, verified, and executable workflow. To bridge this gap, we propose Fault2Flow, an LLM-based multi-agent system. Fault2Flow systematically: (1) extracts and structures regulatory logic into PASTA-formatted fault trees; (2) integrates expert knowledge via a human-in-the-loop interface for verification; (3) optimizes the reasoning logic using a novel AlphaEvolve module; and (4) synthesizes the final, verified logic into an n8n-executable workflow. Experimental validation on transformer fault diagnosis datasets confirms 100\\% topological consistency and high semantic fidelity. Fault2Flow establishes a reproducible path from fault analysis to operational automation, substantially reducing expert workload.", "AI": {"tldr": "Fault2Flow\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u7535\u7f51\u6545\u969c\u8bca\u65ad\uff0c\u901a\u8fc7\u63d0\u53d6\u6cd5\u89c4\u903b\u8f91\u3001\u6574\u5408\u4e13\u5bb6\u77e5\u8bc6\u3001\u4f18\u5316\u63a8\u7406\u903b\u8f91\uff0c\u6700\u7ec8\u751f\u6210\u53ef\u6267\u884c\u7684\u5de5\u4f5c\u6d41\u3002", "motivation": "\u5f53\u524d\u7535\u7f51\u6545\u969c\u8bca\u65ad\u4f9d\u8d56\u4eba\u5de5\u65b9\u6cd5\uff0c\u6548\u7387\u4f4e\u3001\u6613\u51fa\u9519\u4e14\u96be\u4ee5\u7ef4\u62a4\u3002\u9700\u8981\u5c06\u6cd5\u89c4\u6587\u672c\u548c\u4e13\u5bb6\u77e5\u8bc6\u6574\u5408\u5230\u53ef\u9a8c\u8bc1\u3001\u53ef\u6267\u884c\u7684\u81ea\u52a8\u5316\u6d41\u7a0b\u4e2d\u3002", "method": "\u4f7f\u7528LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff1a1) \u63d0\u53d6\u6cd5\u89c4\u903b\u8f91\u4e3aPASTA\u683c\u5f0f\u6545\u969c\u6811\uff1b2) \u901a\u8fc7\u4eba\u673a\u4ea4\u4e92\u754c\u9762\u6574\u5408\u4e13\u5bb6\u77e5\u8bc6\uff1b3) \u7528AlphaEvolve\u6a21\u5757\u4f18\u5316\u63a8\u7406\u903b\u8f91\uff1b4) \u5408\u6210n8n\u53ef\u6267\u884c\u5de5\u4f5c\u6d41\u3002", "result": "\u5728\u53d8\u538b\u5668\u6545\u969c\u8bca\u65ad\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a100%\u62d3\u6251\u4e00\u81f4\u6027\u548c\u9ad8\u8bed\u4e49\u4fdd\u771f\u5ea6\uff0c\u663e\u8457\u51cf\u5c11\u4e13\u5bb6\u5de5\u4f5c\u91cf\u3002", "conclusion": "Fault2Flow\u5efa\u7acb\u4e86\u4ece\u6545\u969c\u5206\u6790\u5230\u64cd\u4f5c\u81ea\u52a8\u5316\u7684\u53ef\u590d\u73b0\u8def\u5f84\uff0c\u4e3a\u7535\u7f51\u6545\u969c\u8bca\u65ad\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.12991", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12991", "abs": "https://arxiv.org/abs/2511.12991", "authors": ["Zeyu Shi", "Ziming Wang", "Tianyu Chen", "Shiqi Gao", "Haoyi Zhou", "Qingyun Sun", "Jianxin Li"], "title": "Fine-Tuned LLMs Know They Don't Know: A Parameter-Efficient Approach to Recovering Honesty", "comment": "Accepted by AAAI 2026 Main Track", "summary": "The honesty of Large Language Models (LLMs) is increasingly important for safe deployment in high-stakes domains. However, this crucial trait is severely undermined by supervised fine-tuning (SFT), a common technique for model specialization. Existing recovery methods rely on data-intensive global parameter adjustments, implicitly assuming that SFT deeply corrupts the models' ability to recognize their knowledge boundaries. However, we observe that fine-tuned LLMs still preserve this ability; what is damaged is their capacity to faithfully express that awareness. Building on this, we propose Honesty-Critical Neurons Restoration (HCNR) to surgically repair this suppressed capacity. HCNR identifies and restores key expression-governing neurons to their pre-trained state while harmonizing them with task-oriented neurons via Hessian-guided compensation. Experiments on four QA tasks and five LLM families demonstrate that HCNR effectively recovers 33.25% of the compromised honesty while achieving at least 2.23x speedup with over 10x less data compared to baseline methods, offering a practical solution for trustworthy LLM deployment.", "AI": {"tldr": "HCNR\u65b9\u6cd5\u901a\u8fc7\u8bc6\u522b\u548c\u6062\u590d\u5173\u952e\u8868\u8fbe\u795e\u7ecf\u5143\u6765\u4fee\u590dSFT\u540eLLM\u7684\u8bda\u5b9e\u5ea6\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5728\u6570\u636e\u4f7f\u7528\u548c\u901f\u5ea6\u4e0a\u90fd\u6709\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u76d1\u7763\u5fae\u8c03(SFT)\u4f1a\u4e25\u91cd\u635f\u5bb3LLM\u7684\u8bda\u5b9e\u5ea6\uff0c\u8fd9\u5bf9\u9ad8\u98ce\u9669\u9886\u57df\u7684\u90e8\u7f72\u6784\u6210\u5a01\u80c1\u3002\u73b0\u6709\u6062\u590d\u65b9\u6cd5\u5047\u8bbeSFT\u6df1\u5ea6\u7834\u574f\u4e86\u6a21\u578b\u8bc6\u522b\u77e5\u8bc6\u8fb9\u754c\u7684\u80fd\u529b\uff0c\u4f46\u4f5c\u8005\u89c2\u5bdf\u5230\u6a21\u578b\u4ecd\u4fdd\u7559\u8fd9\u79cd\u80fd\u529b\uff0c\u53ea\u662f\u8868\u8fbe\u8fd9\u79cd\u610f\u8bc6\u7684\u80fd\u529b\u53d7\u635f\u3002", "method": "\u63d0\u51faHonesty-Critical Neurons Restoration (HCNR)\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u548c\u6062\u590d\u5173\u952e\u8868\u8fbe\u63a7\u5236\u795e\u7ecf\u5143\u5230\u9884\u8bad\u7ec3\u72b6\u6001\uff0c\u540c\u65f6\u4f7f\u7528Hessian\u5f15\u5bfc\u7684\u8865\u507f\u6765\u534f\u8c03\u4efb\u52a1\u5bfc\u5411\u795e\u7ecf\u5143\u3002", "result": "\u5728\u56db\u4e2aQA\u4efb\u52a1\u548c\u4e94\u4e2aLLM\u5bb6\u65cf\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHCNR\u6709\u6548\u6062\u590d\u4e8633.25%\u53d7\u635f\u7684\u8bda\u5b9e\u5ea6\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5b9e\u73b0\u4e86\u81f3\u5c112.23\u500d\u52a0\u901f\u548c\u8d85\u8fc710\u500d\u7684\u6570\u636e\u51cf\u5c11\u3002", "conclusion": "HCNR\u4e3a\u53ef\u4fe1\u8d56LLM\u90e8\u7f72\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u6062\u590d\u6a21\u578b\u8bda\u5b9e\u5ea6\u540c\u65f6\u4fdd\u6301\u6548\u7387\u3002"}}
{"id": "2511.12937", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.12937", "abs": "https://arxiv.org/abs/2511.12937", "authors": ["Guoyan Wang", "Yanyan Huang", "Chunlin Chen", "Lifeng Wang", "Yuxiang Sun"], "title": "Yanyun-3: Enabling Cross-Platform Strategy Game Operation with Vision-Language Models", "comment": "32 pages, 13 figures", "summary": "Automated operation in cross-platform strategy games demands agents with robust generalization across diverse user interfaces and dynamic battlefield conditions. While vision-language models (VLMs) have shown considerable promise in multimodal reasoning, their application to complex human-computer interaction scenarios--such as strategy gaming--remains largely unexplored. Here, we introduce Yanyun-3, a general-purpose agent framework that, for the first time, enables autonomous cross-platform operation across three heterogeneous strategy game environments. By integrating the vision-language reasoning of Qwen2.5-VL with the precise execution capabilities of UI-TARS, Yanyun-3 successfully performs core tasks including target localization, combat resource allocation, and area control. Through systematic ablation studies, we evaluate the effects of various multimodal data combinations--static images, multi-image sequences, and videos--and propose the concept of combination granularity to differentiate between intra-sample fusion and inter-sample mixing strategies. We find that a hybrid strategy, which fuses multi-image and video data while mixing in static images (MV+S), substantially outperforms full fusion: it reduces inference time by 63% and boosts the BLEU-4 score by a factor of 12 (from 4.81% to 62.41%, approximately 12.98x). Operating via a closed-loop pipeline of screen capture, model inference, and action execution, the agent demonstrates strong real-time performance and cross-platform generalization. Beyond providing an efficient solution for strategy game automation, our work establishes a general paradigm for enhancing VLM performance through structured multimodal data organization, offering new insights into the interplay between static perception and dynamic reasoning in embodied intelligence.", "AI": {"tldr": "Yanyun-3\u662f\u4e00\u4e2a\u8de8\u5e73\u53f0\u7b56\u7565\u6e38\u620f\u81ea\u4e3b\u64cd\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578bQwen2.5-VL\u548cUI-TARS\u6267\u884c\u5668\uff0c\u5728\u4e09\u4e2a\u5f02\u6784\u6e38\u620f\u73af\u5883\u4e2d\u5b9e\u73b0\u76ee\u6807\u5b9a\u4f4d\u3001\u8d44\u6e90\u5206\u914d\u548c\u533a\u57df\u63a7\u5236\u7b49\u6838\u5fc3\u4efb\u52a1\u3002\u7814\u7a76\u53d1\u73b0\u6df7\u5408\u591a\u56fe\u50cf\u548c\u89c6\u9891\u6570\u636e\u5e76\u878d\u5408\u9759\u6001\u56fe\u50cf\u7684\u7b56\u7565(MV+S)\u6bd4\u5b8c\u5168\u878d\u5408\u51cf\u5c1163%\u63a8\u7406\u65f6\u95f4\uff0cBLEU-4\u5f97\u5206\u63d0\u534712.98\u500d\u3002", "motivation": "\u89e3\u51b3\u8de8\u5e73\u53f0\u7b56\u7565\u6e38\u620f\u4e2d\u667a\u80fd\u4ee3\u7406\u5728\u4e0d\u540c\u7528\u6237\u754c\u9762\u548c\u52a8\u6001\u6218\u573a\u6761\u4ef6\u4e0b\u7684\u6cdb\u5316\u95ee\u9898\uff0c\u63a2\u7d22\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4eba\u673a\u4ea4\u4e92\u573a\u666f\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u96c6\u6210Qwen2.5-VL\u7684\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\u80fd\u529b\u548cUI-TARS\u7684\u7cbe\u786e\u6267\u884c\u80fd\u529b\uff0c\u91c7\u7528\u5c4f\u5e55\u6355\u83b7-\u6a21\u578b\u63a8\u7406-\u52a8\u4f5c\u6267\u884c\u7684\u95ed\u73af\u6d41\u7a0b\uff0c\u7814\u7a76\u4e0d\u540c\u591a\u6a21\u6001\u6570\u636e\u7ec4\u5408\u7b56\u7565\uff08\u9759\u6001\u56fe\u50cf\u3001\u591a\u56fe\u50cf\u5e8f\u5217\u3001\u89c6\u9891\uff09\u53ca\u5176\u878d\u5408\u7c92\u5ea6\u3002", "result": "MV+S\u6df7\u5408\u7b56\u7565\u663e\u8457\u4f18\u4e8e\u5b8c\u5168\u878d\u5408\uff1a\u63a8\u7406\u65f6\u95f4\u51cf\u5c1163%\uff0cBLEU-4\u5f97\u5206\u4ece4.81%\u63d0\u5347\u81f362.41%\uff08\u7ea612.98\u500d\u63d0\u5347\uff09\uff0c\u5728\u4e09\u4e2a\u5f02\u6784\u7b56\u7565\u6e38\u620f\u73af\u5883\u4e2d\u6210\u529f\u5b9e\u73b0\u81ea\u4e3b\u64cd\u4f5c\u3002", "conclusion": "Yanyun-3\u4e0d\u4ec5\u4e3a\u7b56\u7565\u6e38\u620f\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u8fd8\u901a\u8fc7\u7ed3\u6784\u5316\u591a\u6a21\u6001\u6570\u636e\u7ec4\u7ec7\u5efa\u7acb\u4e86\u589e\u5f3aVLM\u6027\u80fd\u7684\u901a\u7528\u8303\u5f0f\uff0c\u4e3a\u5177\u8eab\u667a\u80fd\u4e2d\u9759\u6001\u611f\u77e5\u4e0e\u52a8\u6001\u63a8\u7406\u7684\u4ea4\u4e92\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2511.13029", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13029", "abs": "https://arxiv.org/abs/2511.13029", "authors": ["Declan Jackson", "William Keating", "George Cameron", "Micah Hill-Smith"], "title": "AA-Omniscience: Evaluating Cross-Domain Knowledge Reliability in Large Language Models", "comment": null, "summary": "Existing language model evaluations primarily measure general capabilities, yet reliable use of these models across a range of domains demands factual accuracy and recognition of knowledge gaps. We introduce AA-Omniscience, a benchmark designed to measure both factual recall and knowledge calibration across 6,000 questions. Questions are derived from authoritative academic and industry sources, and cover 42 economically relevant topics within six different domains. The evaluation measures a model's Omniscience Index, a bounded metric (-100 to 100) measuring factual recall that jointly penalizes hallucinations and rewards abstention when uncertain, with 0 equating to a model that answers questions correctly as much as it does incorrectly. Among evaluated models, Claude 4.1 Opus attains the highest score (4.8), making it one of only three models to score above zero. These results reveal persistent factuality and calibration weaknesses across frontier models. Performance also varies by domain, with the models from three different research labs leading across the six domains. This performance variability suggests models should be chosen according to the demands of the use case rather than general performance for tasks where knowledge is important.", "AI": {"tldr": "AA-Omniscience\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u7684\u4e8b\u5b9e\u56de\u5fc6\u80fd\u529b\u548c\u77e5\u8bc6\u6821\u51c6\u80fd\u529b\uff0c\u53d1\u73b0\u524d\u6cbf\u6a21\u578b\u5728\u4e8b\u5b9e\u6027\u548c\u6821\u51c6\u65b9\u9762\u5b58\u5728\u6301\u7eed\u5f31\u70b9\uff0cClaude 4.1 Opus\u8868\u73b0\u6700\u4f73\u4f46\u5f97\u5206\u4ec54.8\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e3b\u8981\u8861\u91cf\u901a\u7528\u80fd\u529b\uff0c\u4f46\u53ef\u9760\u4f7f\u7528\u9700\u8981\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u8bc6\u522b\u77e5\u8bc6\u5dee\u8ddd\u7684\u80fd\u529b\u3002", "method": "\u6784\u5efa\u5305\u542b6,000\u4e2a\u95ee\u9898\u7684\u57fa\u51c6\uff0c\u95ee\u9898\u6765\u81ea\u6743\u5a01\u5b66\u672f\u548c\u884c\u4e1a\u6765\u6e90\uff0c\u6db5\u76d66\u4e2a\u9886\u57df42\u4e2a\u7ecf\u6d4e\u76f8\u5173\u4e3b\u9898\uff0c\u6d4b\u91cf\u5168\u77e5\u6307\u6570(-100\u5230100)\u3002", "result": "Claude 4.1 Opus\u5f97\u5206\u6700\u9ad8(4.8)\uff0c\u662f\u4ec5\u6709\u7684\u4e09\u4e2a\u5f97\u5206\u8d85\u8fc70\u7684\u6a21\u578b\u4e4b\u4e00\u3002\u4e0d\u540c\u9886\u57df\u8868\u73b0\u5dee\u5f02\u663e\u8457\uff0c\u4e09\u4e2a\u4e0d\u540c\u7814\u7a76\u5b9e\u9a8c\u5ba4\u7684\u6a21\u578b\u5728\u516d\u4e2a\u9886\u57df\u4e2d\u5404\u9886\u5148\u3002", "conclusion": "\u6a21\u578b\u5728\u77e5\u8bc6\u91cd\u8981\u4efb\u52a1\u4e2d\u5e94\u6839\u636e\u7528\u4f8b\u9700\u6c42\u9009\u62e9\uff0c\u800c\u975e\u4f9d\u8d56\u901a\u7528\u6027\u80fd\u6307\u6807\uff0c\u56e0\u4e3a\u4e0d\u540c\u6a21\u578b\u5728\u4e0d\u540c\u9886\u57df\u8868\u73b0\u5404\u5f02\u3002"}}
{"id": "2511.12963", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.12963", "abs": "https://arxiv.org/abs/2511.12963", "authors": ["Crystal Su"], "title": "MedRule-KG: A Knowledge-Graph--Steered Scaffold for Reliable Mathematical and Biomedical Reasoning", "comment": "AAAI 2026 Workshop AI2ASE", "summary": "We study how to impose domain-consistent structure on large language models (LLMs) used for scientific reasoning and early-stage drug discovery. We present MedRule-KG, a compact knowledge-graph scaffold paired with a lightweight verifier that steers generation toward mathematically and biomedically valid outputs. The system injects curated symbolic facts into prompts and then enforces rule satisfaction with a deterministic checker. We formalize generation as constrained inference, introduce a soft guidance surrogate suitable for decoding, and perform a thorough statistical analysis with uncertainty quantification. Across 90 tasks spanning reaction feasibility, metabolic compatibility, and toxicity screening, MedRule-KG reduces violation counts by 83.2\\% relative to a strong chain-of-thought baseline while improving exact match. Results remain stable under stratification and scale with dataset size, and the verifier adds negligible latency, making the approach practical for interactive design.", "AI": {"tldr": "MedRule-KG\u662f\u4e00\u4e2a\u4e3a\u79d1\u5b66\u63a8\u7406\u548c\u836f\u7269\u53d1\u73b0\u8bbe\u8ba1\u7684\u7ed3\u6784\u5316\u7cfb\u7edf\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u548c\u9a8c\u8bc1\u5668\u7ea6\u675fLLM\u751f\u6210\uff0c\u51cf\u5c1183.2%\u7684\u8fdd\u89c4\u5e76\u63d0\u5347\u51c6\u786e\u7387\u3002", "motivation": "\u5728\u79d1\u5b66\u63a8\u7406\u548c\u65e9\u671f\u836f\u7269\u53d1\u73b0\u4e2d\uff0c\u9700\u8981\u786e\u4fddLLM\u751f\u6210\u7684\u5185\u5bb9\u5728\u6570\u5b66\u548c\u751f\u7269\u533b\u5b66\u4e0a\u6709\u6548\uff0c\u907f\u514d\u4ea7\u751f\u4e0d\u5408\u7406\u7684\u8f93\u51fa\u3002", "method": "\u4f7f\u7528MedRule-KG\u77e5\u8bc6\u56fe\u8c31\u652f\u67b6\u548c\u8f7b\u91cf\u9a8c\u8bc1\u5668\uff0c\u901a\u8fc7\u6ce8\u5165\u7b26\u53f7\u4e8b\u5b9e\u548c\u786e\u5b9a\u6027\u68c0\u67e5\u6765\u7ea6\u675f\u751f\u6210\u8fc7\u7a0b\uff0c\u5c06\u751f\u6210\u5efa\u6a21\u4e3a\u7ea6\u675f\u63a8\u7406\u95ee\u9898\u3002", "result": "\u572890\u4e2a\u4efb\u52a1\u4e2d\uff0c\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u51cf\u5c1183.2%\u8fdd\u89c4\uff0c\u63d0\u5347\u7cbe\u786e\u5339\u914d\uff0c\u9a8c\u8bc1\u5668\u5ef6\u8fdf\u53ef\u5ffd\u7565\uff0c\u9002\u5408\u4ea4\u4e92\u5f0f\u8bbe\u8ba1\u3002", "conclusion": "MedRule-KG\u80fd\u6709\u6548\u7ea6\u675fLLM\u751f\u6210\uff0c\u63d0\u5347\u79d1\u5b66\u63a8\u7406\u7684\u53ef\u9760\u6027\u548c\u5b9e\u7528\u6027\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.13040", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13040", "abs": "https://arxiv.org/abs/2511.13040", "authors": ["Kasun Wickramasinghe", "Nisansa de Silva"], "title": "How Good is BLI as an Alignment Measure: A Study in Word Embedding Paradigm", "comment": "15 pages, 2 figures, 6 tables", "summary": "Sans a dwindling number of monolingual embedding studies originating predominantly from the low-resource domains, it is evident that multilingual embedding has become the de facto choice due to its adaptability to the usage of code-mixed languages, granting the ability to process multilingual documents in a language-agnostic manner, as well as removing the difficult task of aligning monolingual embeddings. But is this victory complete? Are the multilingual models better than aligned monolingual models in every aspect? Can the higher computational cost of multilingual models always be justified? Or is there a compromise between the two extremes? Bilingual Lexicon Induction is one of the most widely used metrics in terms of evaluating the degree of alignment between two embedding spaces. In this study, we explore the strengths and limitations of BLI as a measure to evaluate the degree of alignment of two embedding spaces. Further, we evaluate how well traditional embedding alignment techniques, novel multilingual models, and combined alignment techniques perform BLI tasks in the contexts of both high-resource and low-resource languages. In addition to that, we investigate the impact of the language families to which the pairs of languages belong. We identify that BLI does not measure the true degree of alignment in some cases and we propose solutions for them. We propose a novel stem-based BLI approach to evaluate two aligned embedding spaces that take into account the inflected nature of languages as opposed to the prevalent word-based BLI techniques. Further, we introduce a vocabulary pruning technique that is more informative in showing the degree of the alignment, especially performing BLI on multilingual embedding models. Often, combined embedding alignment techniques perform better while in certain cases multilingual embeddings perform better (mainly low-resource language cases).", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u591a\u8bed\u8a00\u5d4c\u5165\u6a21\u578b\u4e0e\u5bf9\u9f50\u5355\u8bed\u6a21\u578b\u5728\u53cc\u8bed\u8bcd\u5178\u5f52\u7eb3(BLI)\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u5dee\u5f02\uff0c\u5206\u6790\u4e86BLI\u4f5c\u4e3a\u5d4c\u5165\u7a7a\u95f4\u5bf9\u9f50\u5ea6\u8bc4\u4f30\u6307\u6807\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u8bcd\u5e72\u7684\u65b0BLI\u65b9\u6cd5\u548c\u8bcd\u6c47\u526a\u679d\u6280\u672f\u3002", "motivation": "\u968f\u7740\u591a\u8bed\u8a00\u5d4c\u5165\u6a21\u578b\u6210\u4e3a\u4e3b\u6d41\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u662f\u5426\u5728\u6240\u6709\u65b9\u9762\u90fd\u4f18\u4e8e\u5bf9\u9f50\u7684\u5355\u8bed\u6a21\u578b\uff0c\u4ee5\u53ca\u9ad8\u6602\u7684\u8ba1\u7b97\u6210\u672c\u662f\u5426\u603b\u662f\u5408\u7406\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22BLI\u4f5c\u4e3a\u5bf9\u9f50\u5ea6\u8bc4\u4f30\u6307\u6807\u7684\u5c40\u9650\u6027\uff0c\u5e76\u6bd4\u8f83\u4e0d\u540c\u5d4c\u5165\u5bf9\u9f50\u6280\u672f\u5728\u9ad8\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u53cc\u8bed\u8bcd\u5178\u5f52\u7eb3(BLI)\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\uff0c\u6bd4\u8f83\u4f20\u7edf\u5d4c\u5165\u5bf9\u9f50\u6280\u672f\u3001\u65b0\u578b\u591a\u8bed\u8a00\u6a21\u578b\u548c\u7ec4\u5408\u5bf9\u9f50\u6280\u672f\u7684\u8868\u73b0\u3002\u63d0\u51fa\u4e86\u57fa\u4e8e\u8bcd\u5e72\u7684BLI\u65b9\u6cd5\u548c\u8bcd\u6c47\u526a\u679d\u6280\u672f\uff0c\u5206\u6790\u4e86\u8bed\u8a00\u5bb6\u65cf\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0BLI\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4e0d\u80fd\u51c6\u786e\u8861\u91cf\u5bf9\u9f50\u5ea6\uff0c\u7ec4\u5408\u5d4c\u5165\u5bf9\u9f50\u6280\u672f\u901a\u5e38\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u60c5\u51b5\u4e0b\u591a\u8bed\u8a00\u5d4c\u5165\u8868\u73b0\u66f4\u4f18\u3002\u63d0\u51fa\u7684\u65b0\u65b9\u6cd5\u80fd\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u5d4c\u5165\u7a7a\u95f4\u5bf9\u9f50\u7a0b\u5ea6\u3002", "conclusion": "\u591a\u8bed\u8a00\u5d4c\u5165\u6a21\u578b\u4e0e\u5bf9\u9f50\u5355\u8bed\u6a21\u578b\u5404\u6709\u4f18\u52bf\uff0c\u6ca1\u6709\u7edd\u5bf9\u7684\u80dc\u5229\u8005\u3002BLI\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u573a\u666f\u4e0b\uff0c\u591a\u8bed\u8a00\u5d4c\u5165\u6a21\u578b\u53ef\u80fd\u66f4\u5177\u4f18\u52bf\u3002"}}
{"id": "2511.12997", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.12997", "abs": "https://arxiv.org/abs/2511.12997", "authors": ["Genglin Liu", "Shijie Geng", "Sha Li", "Hejie Cui", "Sarah Zhang", "Xin Liu", "Tianyi Liu"], "title": "WebCoach: Self-Evolving Web Agents with Cross-Session Memory Guidance", "comment": "18 pages; work in progress", "summary": "Multimodal LLM-powered agents have recently demonstrated impressive capabilities in web navigation, enabling agents to complete complex browsing tasks across diverse domains. However, current agents struggle with repetitive errors and lack the ability to learn from past experiences across sessions, limiting their long-term robustness and sample efficiency. We introduce WebCoach, a model-agnostic self-evolving framework that equips web browsing agents with persistent cross-session memory, enabling improved long-term planning, reflection, and continual learning without retraining. WebCoach consists of three key components: (1) a WebCondenser, which standardizes raw navigation logs into concise summaries; (2) an External Memory Store, which organizes complete trajectories as episodic experiences; and (3) a Coach, which retrieves relevant experiences based on similarity and recency, and decides whether to inject task-specific advice into the agent via runtime hooks. This design empowers web agents to access long-term memory beyond their native context window, improving robustness in complex browsing tasks. Moreover, WebCoach achieves self-evolution by continuously curating episodic memory from new navigation trajectories, enabling agents to improve over time without retraining. Evaluations on the WebVoyager benchmark demonstrate that WebCoach consistently improves the performance of browser-use agents across three different LLM backbones. With a 38B model, it increases task success rates from 47% to 61% while reducing or maintaining the average number of steps. Notably, smaller base models with WebCoach achieve performance comparable to the same web agent using GPT-4o.", "AI": {"tldr": "WebCoach\u662f\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u81ea\u8fdb\u5316\u6846\u67b6\uff0c\u4e3a\u591a\u6a21\u6001LLM\u9a71\u52a8\u7684\u7f51\u9875\u6d4f\u89c8\u4ee3\u7406\u63d0\u4f9b\u8de8\u4f1a\u8bdd\u6301\u4e45\u5185\u5b58\uff0c\u901a\u8fc7\u8bb0\u5fc6\u5b58\u50a8\u548c\u7ecf\u9a8c\u68c0\u7d22\u63d0\u5347\u957f\u671f\u89c4\u5212\u548c\u6301\u7eed\u5b66\u4e60\u80fd\u529b\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002", "motivation": "\u5f53\u524d\u7f51\u9875\u6d4f\u89c8\u4ee3\u7406\u5b58\u5728\u91cd\u590d\u9519\u8bef\u3001\u65e0\u6cd5\u8de8\u4f1a\u8bdd\u5b66\u4e60\u7ecf\u9a8c\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u957f\u671f\u9c81\u68d2\u6027\u548c\u6837\u672c\u6548\u7387\u3002", "method": "WebCoach\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1aWebCondenser\u6807\u51c6\u5316\u5bfc\u822a\u65e5\u5fd7\u4e3a\u6458\u8981\uff0cExternal Memory Store\u7ec4\u7ec7\u5b8c\u6574\u8f68\u8ff9\u4e3a\u60c5\u666f\u7ecf\u9a8c\uff0cCoach\u57fa\u4e8e\u76f8\u4f3c\u6027\u548c\u65f6\u6548\u6027\u68c0\u7d22\u76f8\u5173\u7ecf\u9a8c\u5e76\u901a\u8fc7\u8fd0\u884c\u65f6\u94a9\u5b50\u6ce8\u5165\u4efb\u52a1\u7279\u5b9a\u5efa\u8bae\u3002", "result": "\u5728WebVoyager\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cWebCoach\u663e\u8457\u63d0\u5347\u4e86\u4e09\u79cd\u4e0d\u540cLLM\u9aa8\u5e72\u7684\u6d4f\u89c8\u5668\u4ee3\u7406\u6027\u80fd\uff0c38B\u6a21\u578b\u4efb\u52a1\u6210\u529f\u7387\u4ece47%\u63d0\u5347\u81f361%\uff0c\u540c\u65f6\u51cf\u5c11\u6216\u7ef4\u6301\u5e73\u5747\u6b65\u9aa4\u6570\u3002", "conclusion": "WebCoach\u4f7f\u7f51\u9875\u6d4f\u89c8\u4ee3\u7406\u80fd\u591f\u8d85\u8d8a\u539f\u751f\u4e0a\u4e0b\u6587\u7a97\u53e3\u8bbf\u95ee\u957f\u671f\u8bb0\u5fc6\uff0c\u5728\u590d\u6742\u6d4f\u89c8\u4efb\u52a1\u4e2d\u63d0\u9ad8\u9c81\u68d2\u6027\uff0c\u5e76\u901a\u8fc7\u6301\u7eed\u6574\u7406\u60c5\u666f\u8bb0\u5fc6\u5b9e\u73b0\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u7684\u81ea\u8fdb\u5316\u3002"}}
{"id": "2511.13043", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13043", "abs": "https://arxiv.org/abs/2511.13043", "authors": ["Xinyuan Zhou", "Yi Lei", "Xiaoyu Zhou", "Jingyi Sun", "Yu Zhu", "Zhongyi Ye", "Weitai Zhang", "Quan Liu", "Si Wei", "Cong Liu"], "title": "Spark-Prover-X1: Formal Theorem Proving Through Diverse Data Training", "comment": null, "summary": "Large Language Models (LLMs) have shown significant promise in automated theorem proving, yet progress is often constrained by the scarcity of diverse and high-quality formal language data. To address this issue, we introduce Spark-Prover-X1, a 7B parameter model trained via an three-stage framework designed to unlock the reasoning potential of more accessible and moderately-sized LLMs. The first stage infuses deep knowledge through continuous pre-training on a broad mathematical corpus, enhanced by a suite of novel data tasks. Key innovation is a \"CoT-augmented state prediction\" task to achieve fine-grained reasoning. The second stage employs Supervised Fine-tuning (SFT) within an expert iteration loop to specialize both the Spark-Prover-X1-7B and Spark-Formalizer-X1-7B models. Finally, a targeted round of Group Relative Policy Optimization (GRPO) is applied to sharpen the prover's capabilities on the most challenging problems. To facilitate robust evaluation, particularly on problems from real-world examinations, we also introduce ExamFormal-Bench, a new benchmark dataset of 402 formal problems. Experimental results demonstrate that Spark-Prover-X1-7B achieves state-of-the-art performance among similarly-sized open-source models, attaining a 37.0\\% average pass rate (pass@32). It shows exceptional performance on difficult competition benchmarks, notably solving 27 problems on PutnamBench (pass@32) and achieving 24.0\\% on CombiBench (pass@32). Our work validates that this diverse training data and progressively refined training pipeline provides an effective path for enhancing the formal reasoning capabilities of lightweight LLMs. Both Spark-Prover-X1-7B and Spark-Formalizer-X1-7B, along with the ExamFormal-Bench dataset, are made publicly available at:https://www.modelscope.cn/organization/iflytek, https://gitcode.com/ifly_opensource.", "AI": {"tldr": "Spark-Prover-X1\u662f\u4e00\u4e2a7B\u53c2\u6570\u7684\u5b9a\u7406\u8bc1\u660e\u6a21\u578b\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\u63d0\u5347\u8f7b\u91cf\u7ea7LLM\u7684\u5f62\u5f0f\u63a8\u7406\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u540c\u7c7b\u5f00\u6e90\u6a21\u578b\u7684\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u4e2d\u56e0\u7f3a\u4e4f\u591a\u6837\u5316\u548c\u9ad8\u8d28\u91cf\u5f62\u5f0f\u8bed\u8a00\u6570\u636e\u800c\u53d7\u9650\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u5982\u4f55\u6709\u6548\u63d0\u5347\u4e2d\u7b49\u89c4\u6a21LLM\u7684\u63a8\u7406\u6f5c\u529b\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff1a1) \u5728\u5e7f\u6cdb\u6570\u5b66\u8bed\u6599\u4e0a\u8fdb\u884c\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u5f15\u5165\"\u601d\u7ef4\u94fe\u589e\u5f3a\u72b6\u6001\u9884\u6d4b\"\u4efb\u52a1\uff1b2) \u5728\u4e13\u5bb6\u8fed\u4ee3\u5faa\u73af\u4e2d\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff1b3) \u4f7f\u7528\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u9488\u5bf9\u6700\u5177\u6311\u6218\u6027\u95ee\u9898\u8fdb\u884c\u5f3a\u5316\u8bad\u7ec3\u3002", "result": "Spark-Prover-X1-7B\u5728\u540c\u7c7b\u5f00\u6e90\u6a21\u578b\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5e73\u5747\u901a\u8fc7\u738737.0%(pass@32)\uff0c\u5728PutnamBench\u4e0a\u89e3\u51b327\u4e2a\u95ee\u9898\uff0c\u5728CombiBench\u4e0a\u8fbe\u523024.0%\u3002", "conclusion": "\u591a\u6837\u5316\u7684\u8bad\u7ec3\u6570\u636e\u548c\u9010\u6b65\u7cbe\u70bc\u7684\u8bad\u7ec3\u6d41\u7a0b\u4e3a\u589e\u5f3a\u8f7b\u91cf\u7ea7LLM\u7684\u5f62\u5f0f\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u8def\u5f84\uff0c\u76f8\u5173\u6a21\u578b\u548c\u6570\u636e\u96c6\u5df2\u5f00\u6e90\u3002"}}
{"id": "2511.13007", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13007", "abs": "https://arxiv.org/abs/2511.13007", "authors": ["Yiyang Zhao", "Huiyu Bai", "Xuejiao Zhao"], "title": "GEM: Generative Entropy-Guided Preference Modeling for Few-shot Alignment of LLMs", "comment": "This paper has been accepted by AAAI 2026-AIA and designated as an oral presentation paper", "summary": "Alignment of large language models (LLMs) with human preferences typically relies on supervised reward models or external judges that demand abundant annotations. However, in fields that rely on professional knowledge, such as medicine and law, such large-scale preference labels are often unachievable. In this paper, we propose a generative entropy-guided preference modeling approach named GEM for LLMs aligment at low-resource and domain-specific scenarios. Instead of training a discriminative reward model on preference data, we directly train the LLM to internalize a closed-loop optimization architecture that can extract and exploit the multi-dimensional, fine-grained cognitive signals implicit in human preferences. Specifically, our Cognitive Filtering module, based on entropy theory in decision making, first leverages Chain-of-Thought (CoT) prompting to generate diverse candidate reasoning chains (CoTs) from preference data. Subsequently, it introduces a token scoring mechanism to rank and weight the sampled CoTs, boosting the importance of high-confidence answers and strategically high-entropy tokens. Building on these filtered preferences, we fine-tune the LLM using a novel self-evaluated group advantage algorithm, SEGA, which effectively aggregates group-level cognitive signals and transforms the entropy-based scores into implicit rewards for policy optimization. In these ways, GEM empowers the LLM to rely on its own judgments and establishes an entropy-guided closed-loop cognitive optimization framework, enabling highly efficient few-shot alignment of LLMs. Experiments on general benchmarks and domain-specific tasks (such as mathematical reasoning and medical dialogues) demonstrate that our GEM achieves significant improvements with few-shot preference data.", "AI": {"tldr": "\u63d0\u51faGEM\u65b9\u6cd5\uff0c\u5728\u4f4e\u8d44\u6e90\u548c\u9886\u57df\u7279\u5b9a\u573a\u666f\u4e0b\u901a\u8fc7\u751f\u6210\u5f0f\u71b5\u5f15\u5bfc\u504f\u597d\u5efa\u6a21\u5b9e\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\uff0c\u65e0\u9700\u5927\u91cf\u6807\u6ce8\u6570\u636e\u3002", "motivation": "\u5728\u533b\u5b66\u3001\u6cd5\u5f8b\u7b49\u4e13\u4e1a\u9886\u57df\u96be\u4ee5\u83b7\u5f97\u5927\u89c4\u6a21\u504f\u597d\u6807\u6ce8\u6570\u636e\uff0c\u9700\u8981\u5f00\u53d1\u4f4e\u8d44\u6e90\u4e0b\u7684\u6a21\u578b\u5bf9\u9f50\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u51b3\u7b56\u71b5\u7406\u8bba\uff0c\u4f7f\u7528\u601d\u7ef4\u94fe\u63d0\u793a\u751f\u6210\u591a\u6837\u5316\u63a8\u7406\u94fe\uff0c\u901a\u8fc7\u4ee4\u724c\u8bc4\u5206\u673a\u5236\u5bf9\u63a8\u7406\u94fe\u6392\u5e8f\u52a0\u6743\uff0c\u7ed3\u5408\u81ea\u8bc4\u4f30\u7fa4\u4f53\u4f18\u52bf\u7b97\u6cd5\u8fdb\u884c\u7b56\u7565\u4f18\u5316\u3002", "result": "\u5728\u901a\u7528\u57fa\u51c6\u548c\u9886\u57df\u7279\u5b9a\u4efb\u52a1\uff08\u5982\u6570\u5b66\u63a8\u7406\u548c\u533b\u7597\u5bf9\u8bdd\uff09\u4e0a\uff0c\u4f7f\u7528\u5c11\u91cf\u504f\u597d\u6570\u636e\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "GEM\u5efa\u7acb\u4e86\u4e00\u4e2a\u71b5\u5f15\u5bfc\u7684\u95ed\u73af\u8ba4\u77e5\u4f18\u5316\u6846\u67b6\uff0c\u80fd\u591f\u9ad8\u6548\u5b9e\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5c11\u6837\u672c\u5bf9\u9f50\u3002"}}
{"id": "2511.13095", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13095", "abs": "https://arxiv.org/abs/2511.13095", "authors": ["Chuyuan Li", "Giuseppe Carenini"], "title": "BeDiscovER: The Benchmark of Discourse Understanding in the Era of Reasoning Language Models", "comment": null, "summary": "We introduce BeDiscovER (Benchmark of Discourse Understanding in the Era of Reasoning Language Models), an up-to-date, comprehensive suite for evaluating the discourse-level knowledge of modern LLMs. BeDiscovER compiles 5 publicly available discourse tasks across discourse lexicon, (multi-)sentential, and documental levels, with in total 52 individual datasets. It covers both extensively studied tasks such as discourse parsing and temporal relation extraction, as well as some novel challenges such as discourse particle disambiguation (e.g., ``just''), and also aggregates a shared task on Discourse Relation Parsing and Treebanking for multilingual and multi-framework discourse relation classification. We evaluate open-source LLMs: Qwen3 series, DeepSeek-R1, and frontier model such as GPT-5-mini on BeDiscovER, and find that state-of-the-art models exhibit strong performance in arithmetic aspect of temporal reasoning, but they struggle with full document reasoning and some subtle semantic and discourse phenomena, such as rhetorical relation recognition.", "AI": {"tldr": "BeDiscovER\u662f\u4e00\u4e2a\u8bc4\u4f30\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u8bed\u7bc7\u7406\u89e3\u80fd\u529b\u7684\u7efc\u5408\u57fa\u51c6\u5957\u4ef6\uff0c\u5305\u542b5\u4e2a\u516c\u5f00\u8bed\u7bc7\u4efb\u52a1\u517152\u4e2a\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u8bcd\u6c47\u3001\u53e5\u5b50\u548c\u6587\u6863\u5c42\u9762\u7684\u8bed\u7bc7\u5206\u6790\u3002\u8bc4\u4f30\u53d1\u73b0\u524d\u6cbf\u6a21\u578b\u5728\u65f6\u95f4\u63a8\u7406\u7684\u7b97\u672f\u65b9\u9762\u8868\u73b0\u5f3a\u52b2\uff0c\u4f46\u5728\u5b8c\u6574\u6587\u6863\u63a8\u7406\u548c\u67d0\u4e9b\u5fae\u5999\u8bed\u4e49\u8bed\u7bc7\u73b0\u8c61\u4e0a\u4ecd\u6709\u56f0\u96be\u3002", "motivation": "\u4e3a\u4e86\u5168\u9762\u8bc4\u4f30\u73b0\u4ee3\u63a8\u7406\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u7bc7\u5c42\u9762\u7684\u77e5\u8bc6\u7406\u89e3\u80fd\u529b\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u5305\u542b\u591a\u79cd\u8bed\u7bc7\u4efb\u52a1\u7684\u6700\u65b0\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u3002", "method": "\u6784\u5efaBeDiscovER\u57fa\u51c6\u5957\u4ef6\uff0c\u6574\u54085\u4e2a\u516c\u5f00\u8bed\u7bc7\u4efb\u52a1\uff08\u8bed\u7bc7\u8bcd\u6c47\u3001\u53e5\u5b50\u7ea7\u3001\u6587\u6863\u7ea7\uff09\u517152\u4e2a\u6570\u636e\u96c6\uff0c\u5305\u62ec\u8bed\u7bc7\u89e3\u6790\u3001\u65f6\u95f4\u5173\u7cfb\u63d0\u53d6\u3001\u8bed\u7bc7\u7c92\u5b50\u6d88\u6b67\u7b49\u4efb\u52a1\uff0c\u5e76\u5bf9\u5f00\u6e90\u548c\u524d\u6cbfLLMs\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff1a\u6700\u5148\u8fdb\u6a21\u578b\u5728\u65f6\u95f4\u63a8\u7406\u7684\u7b97\u672f\u65b9\u9762\u8868\u73b0\u5f3a\u52b2\uff0c\u4f46\u5728\u5b8c\u6574\u6587\u6863\u63a8\u7406\u548c\u67d0\u4e9b\u5fae\u5999\u8bed\u4e49\u8bed\u7bc7\u73b0\u8c61\uff08\u5982\u4fee\u8f9e\u5173\u7cfb\u8bc6\u522b\uff09\u4e0a\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "\u73b0\u4ee3LLMs\u5728\u8bed\u7bc7\u7406\u89e3\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u5904\u7406\u5b8c\u6574\u6587\u6863\u63a8\u7406\u548c\u590d\u6742\u8bed\u4e49\u8bed\u7bc7\u73b0\u8c61\u65b9\u9762\u4ecd\u9700\u6539\u8fdb\uff0cBeDiscovER\u4e3a\u7cfb\u7edf\u8bc4\u4f30\u8bed\u7bc7\u7406\u89e3\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2511.13021", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13021", "abs": "https://arxiv.org/abs/2511.13021", "authors": ["Sachin Vashistha", "Aryan Bibhuti", "Atharva Naik", "Martin Tutek", "Somak Aditya"], "title": "PragWorld: A Benchmark Evaluating LLMs' Local World Model under Minimal Linguistic Alterations and Conversational Dynamics", "comment": "23 pages, 15 tables, 10 figures; AAAI 2026 Conference Main Track (oral)", "summary": "Real-world conversations are rich with pragmatic elements, such as entity mentions, references, and implicatures. Understanding such nuances is a requirement for successful natural communication, and often requires building a local world model which encodes such elements and captures the dynamics of their evolving states. However, it is not well-understood whether language models (LMs) construct or maintain a robust implicit representation of conversations. In this work, we evaluate the ability of LMs to encode and update their internal world model in dyadic conversations and test their malleability under linguistic alterations. To facilitate this, we apply seven minimal linguistic alterations to conversations sourced from popular datasets and construct two benchmarks comprising yes-no questions. We evaluate a wide range of open and closed source LMs and observe that they struggle to maintain robust accuracy. Our analysis unveils that LMs struggle to memorize crucial details, such as tracking entities under linguistic alterations to conversations. We then propose a dual-perspective interpretability framework which identifies transformer layers that are useful or harmful and highlights linguistic alterations most influenced by harmful layers, typically due to encoding spurious signals or relying on shortcuts. Inspired by these insights, we propose two layer-regularization based fine-tuning strategies that suppress the effect of the harmful layers.", "AI": {"tldr": "\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u5bf9\u8bdd\u4e2d\u6784\u5efa\u548c\u7ef4\u62a4\u4e16\u754c\u6a21\u578b\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u8bed\u8a00\u53d8\u5316\u4e0b\u96be\u4ee5\u4fdd\u6301\u7a33\u5065\u6027\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u5c42\u6b63\u5219\u5316\u7684\u5fae\u8c03\u7b56\u7565\u6765\u6291\u5236\u6709\u5bb3\u5c42\u7684\u5f71\u54cd\u3002", "motivation": "\u7406\u89e3\u771f\u5b9e\u5bf9\u8bdd\u4e2d\u7684\u8bed\u7528\u5143\u7d20\u9700\u8981\u6784\u5efa\u5c40\u90e8\u4e16\u754c\u6a21\u578b\uff0c\u4f46\u76ee\u524d\u4e0d\u6e05\u695a\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u6784\u5efa\u548c\u7ef4\u62a4\u8fd9\u79cd\u9690\u5f0f\u8868\u793a\u3002", "method": "\u5bf9\u6d41\u884c\u6570\u636e\u96c6\u4e2d\u7684\u5bf9\u8bdd\u5e94\u7528\u4e03\u79cd\u6700\u5c0f\u8bed\u8a00\u53d8\u5316\uff0c\u6784\u5efa\u4e24\u4e2a\u5305\u542b\u662f\u975e\u95ee\u9898\u7684\u57fa\u51c6\uff0c\u8bc4\u4f30\u591a\u79cd\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u53cc\u89c6\u89d2\u53ef\u89e3\u91ca\u6027\u6846\u67b6\u548c\u5c42\u6b63\u5219\u5316\u5fae\u8c03\u7b56\u7565\u3002", "result": "\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u8a00\u53d8\u5316\u4e0b\u96be\u4ee5\u4fdd\u6301\u7a33\u5065\u51c6\u786e\u7387\uff0c\u7279\u522b\u662f\u5728\u8ddf\u8e2a\u5b9e\u4f53\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u5728\u5bf9\u8bdd\u4e2d\u7ef4\u62a4\u4e16\u754c\u6a21\u578b\u7684\u80fd\u529b\u6709\u9650\uff0c\u4f46\u901a\u8fc7\u8bc6\u522b\u548c\u6291\u5236\u6709\u5bb3\u5c42\u53ef\u4ee5\u6539\u5584\u6027\u80fd\u3002"}}
{"id": "2511.13107", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13107", "abs": "https://arxiv.org/abs/2511.13107", "authors": ["Zhichao He", "Mouxiao Bian", "Jianhong Zhu", "Jiayuan Chen", "Yunqiu Wang", "Wenxia Zhao", "Tianbin Li", "Bing Han", "Jie Xu", "Junyan Wu"], "title": "Evaluating the Ability of Large Language Models to Identify Adherence to CONSORT Reporting Guidelines in Randomized Controlled Trials: A Methodological Evaluation Study", "comment": null, "summary": "The Consolidated Standards of Reporting Trials statement is the global benchmark for transparent and high-quality reporting of randomized controlled trials. Manual verification of CONSORT adherence is a laborious, time-intensive process that constitutes a significant bottleneck in peer review and evidence synthesis. This study aimed to systematically evaluate the accuracy and reliability of contemporary LLMs in identifying the adherence of published RCTs to the CONSORT 2010 statement under a zero-shot setting. We constructed a golden standard dataset of 150 published RCTs spanning diverse medical specialties. The primary outcome was the macro-averaged F1-score for the three-class classification task, supplemented by item-wise performance metrics and qualitative error analysis. Overall model performance was modest. The top-performing models, Gemini-2.5-Flash and DeepSeek-R1, achieved nearly identical macro F1 scores of 0.634 and Cohen's Kappa coefficients of 0.280 and 0.282, respectively, indicating only fair agreement with expert consensus. A striking performance disparity was observed across classes: while most models could identify compliant items with high accuracy (F1 score > 0.850), they struggled profoundly with identifying non-compliant and not applicable items, where F1 scores rarely exceeded 0.400. Notably, some high-profile models like GPT-4o underperformed, achieving a macro F1-score of only 0.521. LLMs show potential as preliminary screening assistants for CONSORT checks, capably identifying well-reported items. However, their current inability to reliably detect reporting omissions or methodological flaws makes them unsuitable for replacing human expertise in the critical appraisal of trial quality.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5f53\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u8bc6\u522b\u5df2\u53d1\u8868\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u5bf9CONSORT 2010\u58f0\u660e\u4f9d\u4ece\u6027\u7684\u51c6\u786e\u6027\u3002\u7ed3\u679c\u663e\u793a\u6a21\u578b\u6574\u4f53\u8868\u73b0\u4e00\u822c\uff0c\u80fd\u591f\u51c6\u786e\u8bc6\u522b\u5408\u89c4\u9879\u76ee\uff0c\u4f46\u5728\u68c0\u6d4b\u4e0d\u5408\u89c4\u548c\u4e0d\u9002\u7528\u9879\u76ee\u65b9\u9762\u8868\u73b0\u8f83\u5dee\uff0c\u76ee\u524d\u5c1a\u4e0d\u80fd\u66ff\u4ee3\u4eba\u7c7b\u4e13\u5bb6\u8fdb\u884c\u8bd5\u9a8c\u8d28\u91cf\u8bc4\u4f30\u3002", "motivation": "\u624b\u52a8\u9a8c\u8bc1CONSORT\u4f9d\u4ece\u6027\u662f\u4e00\u4e2a\u8017\u65f6\u8d39\u529b\u7684\u8fc7\u7a0b\uff0c\u6210\u4e3a\u540c\u884c\u8bc4\u5ba1\u548c\u8bc1\u636e\u5408\u6210\u7684\u74f6\u9888\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30LLMs\u5728\u8fd9\u4e00\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4ee5\u63a2\u7d22\u81ea\u52a8\u5316\u9a8c\u8bc1\u7684\u53ef\u80fd\u6027\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b150\u7bc7\u5df2\u53d1\u8868RCT\u7684\u91d1\u6807\u51c6\u6570\u636e\u96c6\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u8bc4\u4f30LLMs\u7684\u6027\u80fd\uff0c\u4e3b\u8981\u6307\u6807\u4e3a\u5b8f\u5e73\u5747F1\u5206\u6570\uff0c\u5e76\u8f85\u4ee5\u9879\u76ee\u7ea7\u6027\u80fd\u6307\u6807\u548c\u5b9a\u6027\u9519\u8bef\u5206\u6790\u3002", "result": "\u8868\u73b0\u6700\u4f73\u7684Gemini-2.5-Flash\u548cDeepSeek-R1\u6a21\u578b\u5b8fF1\u5206\u6570\u5206\u522b\u4e3a0.634\uff0cCohen's Kappa\u7cfb\u6570\u5206\u522b\u4e3a0.280\u548c0.282\uff0c\u4ec5\u8fbe\u5230\u4e00\u822c\u4e00\u81f4\u6027\u6c34\u5e73\u3002\u6a21\u578b\u5728\u8bc6\u522b\u5408\u89c4\u9879\u76ee\u65f6\u8868\u73b0\u826f\u597d\uff08F1>0.850\uff09\uff0c\u4f46\u5728\u8bc6\u522b\u4e0d\u5408\u89c4\u548c\u4e0d\u9002\u7528\u9879\u76ee\u65f6\u8868\u73b0\u8f83\u5dee\uff08F1<0.400\uff09\u3002", "conclusion": "LLMs\u4f5c\u4e3aCONSORT\u68c0\u67e5\u7684\u521d\u6b65\u7b5b\u9009\u52a9\u624b\u5177\u6709\u6f5c\u529b\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u62a5\u544a\u826f\u597d\u7684\u9879\u76ee\uff0c\u4f46\u76ee\u524d\u65e0\u6cd5\u53ef\u9760\u68c0\u6d4b\u62a5\u544a\u9057\u6f0f\u6216\u65b9\u6cd5\u5b66\u7f3a\u9677\uff0c\u5c1a\u4e0d\u80fd\u66ff\u4ee3\u4eba\u7c7b\u4e13\u5bb6\u8fdb\u884c\u8bd5\u9a8c\u8d28\u91cf\u7684\u5173\u952e\u8bc4\u4f30\u3002"}}
{"id": "2511.13027", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13027", "abs": "https://arxiv.org/abs/2511.13027", "authors": ["Sadegh Mahdavi", "Branislav Kisacanin", "Shubham Toshniwal", "Wei Du", "Ivan Moshkov", "George Armstrong", "Renjie Liao", "Christos Thrampoulidis", "Igor Gitman"], "title": "Scaling Generative Verifiers For Natural Language Mathematical Proof Verification And Selection", "comment": null, "summary": "Large language models have achieved remarkable success on final-answer mathematical problems, largely due to the ease of applying reinforcement learning with verifiable rewards. However, the reasoning underlying these solutions is often flawed. Advancing to rigorous proof-based mathematics requires reliable proof verification capabilities. We begin by analyzing multiple evaluation setups and show that focusing on a single benchmark can lead to brittle or misleading conclusions. To address this, we evaluate both proof-based and final-answer reasoning to obtain a more reliable measure of model performance. We then scale two major generative verification methods (GenSelect and LLM-as-a-Judge) to millions of tokens and identify their combination as the most effective framework for solution verification and selection. We further show that the choice of prompt for LLM-as-a-Judge significantly affects the model's performance, but reinforcement learning can reduce this sensitivity. However, despite improving proof-level metrics, reinforcement learning does not enhance final-answer precision, indicating that current models often reward stylistic or procedural correctness rather than mathematical validity. Our results establish practical guidelines for designing and evaluating scalable proof-verification and selection systems.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u6570\u5b66\u63a8\u7406\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u53d1\u73b0\u5355\u4e00\u57fa\u51c6\u6d4b\u8bd5\u4e0d\u53ef\u9760\uff0c\u63d0\u51fa\u7ed3\u5408GenSelect\u548cLLM-as-a-Judge\u7684\u9a8c\u8bc1\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u51cf\u5c11\u63d0\u793a\u654f\u611f\u6027\uff0c\u4f46\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u66f4\u6ce8\u91cd\u5f62\u5f0f\u6b63\u786e\u6027\u800c\u975e\u6570\u5b66\u6709\u6548\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u95ee\u9898\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u5176\u63a8\u7406\u8fc7\u7a0b\u5f80\u5f80\u5b58\u5728\u7f3a\u9677\u3002\u4e3a\u4e86\u63a8\u8fdb\u4e25\u683c\u7684\u57fa\u4e8e\u8bc1\u660e\u7684\u6570\u5b66\u63a8\u7406\uff0c\u9700\u8981\u53ef\u9760\u7684\u8bc1\u660e\u9a8c\u8bc1\u80fd\u529b\u3002", "method": "\u5206\u6790\u4e86\u591a\u79cd\u8bc4\u4f30\u8bbe\u7f6e\uff0c\u8bc4\u4f30\u4e86\u57fa\u4e8e\u8bc1\u660e\u548c\u6700\u7ec8\u7b54\u6848\u7684\u63a8\u7406\uff0c\u6269\u5c55\u4e86\u4e24\u79cd\u751f\u6210\u9a8c\u8bc1\u65b9\u6cd5\uff08GenSelect\u548cLLM-as-a-Judge\uff09\u5230\u767e\u4e07token\u89c4\u6a21\uff0c\u5e76\u7814\u7a76\u4e86\u5f3a\u5316\u5b66\u4e60\u5bf9\u63d0\u793a\u654f\u611f\u6027\u7684\u5f71\u54cd\u3002", "result": "\u7ed3\u5408GenSelect\u548cLLM-as-a-Judge\u662f\u6700\u6709\u6548\u7684\u9a8c\u8bc1\u6846\u67b6\uff1b\u5f3a\u5316\u5b66\u4e60\u53ef\u4ee5\u51cf\u5c11LLM-as-a-Judge\u5bf9\u63d0\u793a\u7684\u654f\u611f\u6027\uff1b\u5c3d\u7ba1\u6539\u8fdb\u4e86\u8bc1\u660e\u7ea7\u6307\u6807\uff0c\u4f46\u5f3a\u5316\u5b66\u4e60\u5e76\u672a\u63d0\u9ad8\u6700\u7ec8\u7b54\u6848\u7cbe\u5ea6\u3002", "conclusion": "\u5f53\u524d\u6a21\u578b\u5f80\u5f80\u5956\u52b1\u98ce\u683c\u6216\u7a0b\u5e8f\u6b63\u786e\u6027\u800c\u975e\u6570\u5b66\u6709\u6548\u6027\uff0c\u7814\u7a76\u4e3a\u8bbe\u8ba1\u548c\u8bc4\u4f30\u53ef\u6269\u5c55\u7684\u8bc1\u660e\u9a8c\u8bc1\u548c\u9009\u62e9\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5357\u3002"}}
{"id": "2511.13118", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13118", "abs": "https://arxiv.org/abs/2511.13118", "authors": ["Quanjiang Guo", "Sijie Wang", "Jinchuan Zhang", "Ben Zhang", "Zhao Kang", "Ling Tian", "Ke Yan"], "title": "Extracting Events Like Code: A Multi-Agent Programming Framework for Zero-Shot Event Extraction", "comment": "11 pages, 5 figures, accepted by AAAI 2026 (Oral)", "summary": "Zero-shot event extraction (ZSEE) remains a significant challenge for large language models (LLMs) due to the need for complex reasoning and domain-specific understanding. Direct prompting often yields incomplete or structurally invalid outputs--such as misclassified triggers, missing arguments, and schema violations. To address these limitations, we present Agent-Event-Coder (AEC), a novel multi-agent framework that treats event extraction like software engineering: as a structured, iterative code-generation process. AEC decomposes ZSEE into specialized subtasks--retrieval, planning, coding, and verification--each handled by a dedicated LLM agent. Event schemas are represented as executable class definitions, enabling deterministic validation and precise feedback via a verification agent. This programming-inspired approach allows for systematic disambiguation and schema enforcement through iterative refinement. By leveraging collaborative agent workflows, AEC enables LLMs to produce precise, complete, and schema-consistent extractions in zero-shot settings. Experiments across five diverse domains and six LLMs demonstrate that AEC consistently outperforms prior zero-shot baselines, showcasing the power of treating event extraction like code generation. The code and data are released on https://github.com/UESTC-GQJ/Agent-Event-Coder.", "AI": {"tldr": "Agent-Event-Coder (AEC) \u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u96f6\u6837\u672c\u4e8b\u4ef6\u62bd\u53d6\u89c6\u4e3a\u7c7b\u4f3c\u8f6f\u4ef6\u5de5\u7a0b\u7684\u4ee3\u7801\u751f\u6210\u8fc7\u7a0b\uff0c\u901a\u8fc7\u68c0\u7d22\u3001\u89c4\u5212\u3001\u7f16\u7801\u548c\u9a8c\u8bc1\u56db\u4e2a\u4e13\u4e1a\u667a\u80fd\u4f53\u7684\u534f\u4f5c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u4e8b\u4ef6\u62bd\u53d6\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u96f6\u6837\u672c\u4e8b\u4ef6\u62bd\u53d6\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u6709\u6311\u6218\u6027\uff0c\u76f4\u63a5\u63d0\u793a\u901a\u5e38\u4f1a\u4ea7\u751f\u4e0d\u5b8c\u6574\u6216\u7ed3\u6784\u65e0\u6548\u7684\u8f93\u51fa\uff0c\u5982\u9519\u8bef\u5206\u7c7b\u7684\u89e6\u53d1\u5668\u3001\u7f3a\u5931\u53c2\u6570\u548c\u6a21\u5f0f\u8fdd\u89c4\u3002", "method": "AEC \u5c06\u4e8b\u4ef6\u62bd\u53d6\u5206\u89e3\u4e3a\u56db\u4e2a\u4e13\u4e1a\u5b50\u4efb\u52a1\uff1a\u68c0\u7d22\u3001\u89c4\u5212\u3001\u7f16\u7801\u548c\u9a8c\u8bc1\uff0c\u6bcf\u4e2a\u4efb\u52a1\u7531\u4e13\u95e8\u7684LLM\u667a\u80fd\u4f53\u5904\u7406\u3002\u4e8b\u4ef6\u6a21\u5f0f\u8868\u793a\u4e3a\u53ef\u6267\u884c\u7684\u7c7b\u5b9a\u4e49\uff0c\u901a\u8fc7\u9a8c\u8bc1\u667a\u80fd\u4f53\u5b9e\u73b0\u786e\u5b9a\u6027\u9a8c\u8bc1\u548c\u7cbe\u786e\u53cd\u9988\u3002", "result": "\u5728\u4e94\u4e2a\u4e0d\u540c\u9886\u57df\u548c\u516d\u4e2aLLM\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAEC \u59cb\u7ec8\u4f18\u4e8e\u5148\u524d\u7684\u96f6\u6837\u672c\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u5c06\u4e8b\u4ef6\u62bd\u53d6\u89c6\u4e3a\u4ee3\u7801\u751f\u6210\u7684\u65b9\u6cd5\u80fd\u591f\u4f7fLLM\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u4ea7\u751f\u7cbe\u786e\u3001\u5b8c\u6574\u4e14\u6a21\u5f0f\u4e00\u81f4\u7684\u4e8b\u4ef6\u62bd\u53d6\u7ed3\u679c\u3002"}}
{"id": "2511.13087", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.13087", "abs": "https://arxiv.org/abs/2511.13087", "authors": ["SeokJoo Kwak", "Jihoon Kim", "Boyoun Kim", "Jung Jae Yoon", "Wooseok Jang", "Jeonghoon Hong", "Jaeho Yang", "Yeong-Dae Kwon"], "title": "MEGA-GUI: Multi-stage Enhanced Grounding Agents for GUI Elements", "comment": "26 pages, 7 figures. Code available at https://github.com/samsungsds-research-papers/mega-gui", "summary": "Graphical User Interface (GUI) grounding - the task of mapping natural language instructions to screen coordinates - is essential for autonomous agents and accessibility technologies. Existing systems rely on monolithic models or one-shot pipelines that lack modularity and fail under visual clutter and ambiguous instructions. We introduce MEGA-GUI, a multi-stage framework that separates grounding into coarse Region-of-Interest (ROI) selection and fine-grained element grounding, orchestrated by specialized vision-language agents. MEGA-GUI features a bidirectional ROI zoom algorithm that mitigates spatial dilution and a context-aware rewriting agent that reduces semantic ambiguity. Our analysis reveals complementary strengths and weaknesses across vision-language models at different visual scales, and we show that leveraging this modular structure achieves consistently higher accuracy than monolithic approaches. On the visually dense ScreenSpot-Pro benchmark, MEGA-GUI attains 73.18% accuracy, and on the semantically complex OSWorld-G benchmark it reaches 68.63%, surpassing previously reported results. Code and the Grounding Benchmark Toolkit (GBT) are available at https://github.com/samsungsds-research-papers/mega-gui.", "AI": {"tldr": "MEGA-GUI\u662f\u4e00\u4e2a\u591a\u9636\u6bb5GUI\u5b9a\u4f4d\u6846\u67b6\uff0c\u901a\u8fc7\u533a\u57df\u9009\u62e9\u548c\u7ec6\u7c92\u5ea6\u5143\u7d20\u5b9a\u4f4d\u89e3\u51b3\u89c6\u89c9\u6742\u4e71\u548c\u6307\u4ee4\u6a21\u7cca\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709GUI\u5b9a\u4f4d\u7cfb\u7edf\u91c7\u7528\u5355\u4f53\u6a21\u578b\u6216\u4e00\u6b21\u6027\u6d41\u6c34\u7ebf\uff0c\u7f3a\u4e4f\u6a21\u5757\u5316\uff0c\u5728\u89c6\u89c9\u6742\u4e71\u548c\u6a21\u7cca\u6307\u4ee4\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u4f7f\u7528\u591a\u9636\u6bb5\u6846\u67b6\uff0c\u5206\u79bb\u4e3a\u7c97\u7565ROI\u9009\u62e9\u548c\u7ec6\u7c92\u5ea6\u5143\u7d20\u5b9a\u4f4d\uff0c\u91c7\u7528\u53cc\u5411ROI\u7f29\u653e\u7b97\u6cd5\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u91cd\u5199\u4ee3\u7406\u3002", "result": "\u5728ScreenSpot-Pro\u57fa\u51c6\u4e0a\u8fbe\u523073.18%\u51c6\u786e\u7387\uff0c\u5728OSWorld-G\u57fa\u51c6\u4e0a\u8fbe\u523068.63%\uff0c\u8d85\u8d8a\u4e4b\u524d\u62a5\u544a\u7ed3\u679c\u3002", "conclusion": "\u6a21\u5757\u5316\u7ed3\u6784\u6bd4\u5355\u4f53\u65b9\u6cd5\u83b7\u5f97\u66f4\u9ad8\u51c6\u786e\u7387\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u89c6\u89c9\u5c3a\u5ea6\u4e0b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u4e92\u8865\u4f18\u52bf\u3002"}}
{"id": "2511.13126", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13126", "abs": "https://arxiv.org/abs/2511.13126", "authors": ["Nigar Alishzade", "Gulchin Abdullayeva"], "title": "A Comparative Analysis of Recurrent and Attention Architectures for Isolated Sign Language Recognition", "comment": null, "summary": "This study presents a systematic comparative analysis of recurrent and attention-based neural architectures for isolated sign language recognition. We implement and evaluate two representative models-ConvLSTM and Vanilla Transformer-on the Azerbaijani Sign Language Dataset (AzSLD) and the Word-Level American Sign Language (WLASL) dataset. Our results demonstrate that the attention-based Vanilla Transformer consistently outperforms the recurrent ConvLSTM in both Top-1 and Top-5 accuracy across datasets, achieving up to 76.8% Top-1 accuracy on AzSLD and 88.3% on WLASL. The ConvLSTM, while more computationally efficient, lags in recognition accuracy, particularly on smaller datasets. These findings highlight the complementary strengths of each paradigm: the Transformer excels in overall accuracy and signer independence, whereas the ConvLSTM offers advantages in computational efficiency and temporal modeling. The study provides a nuanced analysis of these trade-offs, offering guidance for architecture selection in sign language recognition systems depending on application requirements and resource constraints.", "AI": {"tldr": "\u6bd4\u8f83\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u548c\u6ce8\u610f\u529b\u673a\u5236\u5728\u5b64\u7acb\u624b\u8bed\u8bc6\u522b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u57fa\u4e8e\u6ce8\u610f\u529b\u7684Transformer\u5728\u51c6\u786e\u7387\u4e0a\u4f18\u4e8eConvLSTM\uff0c\u4f46\u540e\u8005\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u3002", "motivation": "\u7cfb\u7edf\u6bd4\u8f83\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u548c\u6ce8\u610f\u529b\u673a\u5236\u5728\u624b\u8bed\u8bc6\u522b\u4e2d\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u4e3a\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e0b\u7684\u67b6\u6784\u9009\u62e9\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u5728\u963f\u585e\u62dc\u7586\u624b\u8bed\u6570\u636e\u96c6(AzSLD)\u548c\u7f8e\u56fd\u624b\u8bed\u6570\u636e\u96c6(WLASL)\u4e0a\u5b9e\u73b0\u5e76\u8bc4\u4f30ConvLSTM\u548cVanilla Transformer\u4e24\u79cd\u4ee3\u8868\u6027\u6a21\u578b\u3002", "result": "Vanilla Transformer\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u90fd\u4f18\u4e8eConvLSTM\uff0c\u5728AzSLD\u4e0a\u8fbe\u523076.8%\u7684Top-1\u51c6\u786e\u7387\uff0c\u5728WLASL\u4e0a\u8fbe\u523088.3%\u3002ConvLSTM\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u4f46\u51c6\u786e\u7387\u8f83\u4f4e\u3002", "conclusion": "Transformer\u5728\u51c6\u786e\u7387\u548c\u624b\u8bed\u8005\u72ec\u7acb\u6027\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u800cConvLSTM\u5728\u8ba1\u7b97\u6548\u7387\u548c\u65f6\u5e8f\u5efa\u6a21\u65b9\u9762\u6709\u4f18\u52bf\uff0c\u4e24\u8005\u5404\u6709\u9002\u7528\u573a\u666f\u3002"}}
{"id": "2511.13091", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13091", "abs": "https://arxiv.org/abs/2511.13091", "authors": ["Yuhan Chen", "Yuxuan Liu", "Long Zhang", "Pengzhi Gao", "Jian Luan", "Wei Liu"], "title": "STEP: Success-Rate-Aware Trajectory-Efficient Policy Optimization", "comment": null, "summary": "Multi-turn interaction remains challenging for online reinforcement learning. A common solution is trajectory-level optimization, which treats each trajectory as a single training sample. However, this approach can be inefficient and yield misleading learning signals: it applies uniform sampling across tasks regardless of difficulty, penalizes correct intermediate actions in failed trajectories, and incurs high sample-collection costs. To address these issues, we propose STEP (Success-rate-aware Trajectory-Efficient Policy optimization), a framework that dynamically allocates sampling based on per-task success rates and performs step-level optimization. STEP maintains a smoothed success-rate record to guide adaptive trajectory resampling, allocating more effort to harder tasks. It then computes success-rate-weighted advantages and decomposes trajectories into step-level samples. Finally, it applies a step-level GRPO augmentation to refine updates for low-success tasks. Experiments on OSWorld and AndroidWorld show that STEP substantially improves sample efficiency and training stability over trajectory-level GRPO, converging faster and generalizing better under the same sampling budget.", "AI": {"tldr": "STEP\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u5206\u914d\u91c7\u6837\u548c\u6b65\u9aa4\u7ea7\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u591a\u8f6e\u4ea4\u4e92\u4e2d\u8f68\u8ff9\u7ea7\u4f18\u5316\u7684\u6548\u7387\u4f4e\u4e0b\u548c\u8bef\u5bfc\u6027\u5b66\u4e60\u4fe1\u53f7\u95ee\u9898\u3002", "motivation": "\u8f68\u8ff9\u7ea7\u4f18\u5316\u5728\u591a\u8f6e\u4ea4\u4e92\u4e2d\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u548c\u8bef\u5bfc\u6027\u5b66\u4e60\u4fe1\u53f7\u7684\u95ee\u9898\uff0c\u5305\u62ec\u5bf9\u4efb\u52a1\u96be\u5ea6\u4e0d\u654f\u611f\u7684\u5747\u5300\u91c7\u6837\u3001\u5728\u5931\u8d25\u8f68\u8ff9\u4e2d\u60e9\u7f5a\u6b63\u786e\u4e2d\u95f4\u52a8\u4f5c\u4ee5\u53ca\u9ad8\u91c7\u6837\u6210\u672c\u3002", "method": "STEP\u6846\u67b6\u7ef4\u62a4\u5e73\u6ed1\u7684\u6210\u529f\u7387\u8bb0\u5f55\u6765\u6307\u5bfc\u81ea\u9002\u5e94\u8f68\u8ff9\u91cd\u91c7\u6837\uff0c\u8ba1\u7b97\u6210\u529f\u7387\u52a0\u6743\u4f18\u52bf\uff0c\u5c06\u8f68\u8ff9\u5206\u89e3\u4e3a\u6b65\u9aa4\u7ea7\u6837\u672c\uff0c\u5e76\u5e94\u7528\u6b65\u9aa4\u7ea7GRPO\u589e\u5f3a\u6765\u4f18\u5316\u4f4e\u6210\u529f\u7387\u4efb\u52a1\u7684\u66f4\u65b0\u3002", "result": "\u5728OSWorld\u548cAndroidWorld\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSTEP\u663e\u8457\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u5728\u76f8\u540c\u91c7\u6837\u9884\u7b97\u4e0b\u6536\u655b\u66f4\u5feb\u4e14\u6cdb\u5316\u80fd\u529b\u66f4\u597d\u3002", "conclusion": "STEP\u901a\u8fc7\u52a8\u6001\u91c7\u6837\u5206\u914d\u548c\u6b65\u9aa4\u7ea7\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8f6e\u4ea4\u4e92\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u6311\u6218\uff0c\u63d0\u5347\u4e86\u6837\u672c\u6548\u7387\u548c\u8bad\u7ec3\u6027\u80fd\u3002"}}
{"id": "2511.13152", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13152", "abs": "https://arxiv.org/abs/2511.13152", "authors": ["Sourya Dipta Das", "Shubham Kumar", "Kuldeep Yadav"], "title": "Zero-Shot Grammar Competency Estimation Using Large Language Model Generated Pseudo Labels", "comment": "Accepted in AACL-IJCNLP 2025", "summary": "Grammar competency estimation is essential for assessing linguistic proficiency in both written and spoken language; however, the spoken modality presents additional challenges due to its spontaneous, unstructured, and disfluent nature. Developing accurate grammar scoring models further requires extensive expert annotation, making large-scale data creation impractical. To address these limitations, we propose a zero-shot grammar competency estimation framework that leverages unlabeled data and Large Language Models (LLMs) without relying on manual labels. During training, we employ LLM-generated predictions on unlabeled data by using grammar competency rubric-based prompts. These predictions, treated as pseudo labels, are utilized to train a transformer-based model through a novel training framework designed to handle label noise effectively. We show that the choice of LLM for pseudo-label generation critically affects model performance and that the ratio of clean-to-noisy samples during training strongly influences stability and accuracy. Finally, a qualitative analysis of error intensity and score prediction confirms the robustness and interpretability of our approach. Experimental results demonstrate the efficacy of our approach in estimating grammar competency scores with high accuracy, paving the way for scalable, low-resource grammar assessment systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u96f6\u6837\u672c\u8bed\u6cd5\u80fd\u529b\u8bc4\u4f30\u6846\u67b6\uff0c\u5229\u7528\u65e0\u6807\u7b7e\u6570\u636e\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4f2a\u6807\u7b7e\uff0c\u901a\u8fc7\u566a\u58f0\u6807\u7b7e\u8bad\u7ec3\u65b9\u6cd5\u5b9e\u73b0\u51c6\u786e\u7684\u8bed\u6cd5\u80fd\u529b\u8bc4\u5206\u3002", "motivation": "\u53e3\u8bed\u8bed\u6cd5\u8bc4\u4f30\u9762\u4e34\u81ea\u53d1\u6027\u548c\u4e0d\u6d41\u7545\u6027\u7684\u6311\u6218\uff0c\u4e14\u4e13\u5bb6\u6807\u6ce8\u6210\u672c\u9ad8\u6602\uff0c\u96be\u4ee5\u5927\u89c4\u6a21\u521b\u5efa\u6570\u636e\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u8bed\u6cd5\u80fd\u529b\u91cf\u8868\u7684\u63d0\u793a\u4eceLLM\u751f\u6210\u4f2a\u6807\u7b7e\uff0c\u901a\u8fc7\u4e13\u95e8\u8bbe\u8ba1\u7684\u8bad\u7ec3\u6846\u67b6\u8bad\u7ec3\u57fa\u4e8etransformer\u7684\u6a21\u578b\u6765\u5904\u7406\u6807\u7b7e\u566a\u58f0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u9ad8\u7cbe\u5ea6\u4f30\u8ba1\u8bed\u6cd5\u80fd\u529b\u5206\u6570\uff0cLLM\u9009\u62e9\u548c\u5e72\u51c0-\u566a\u58f0\u6837\u672c\u6bd4\u4f8b\u5bf9\u6027\u80fd\u6709\u91cd\u8981\u5f71\u54cd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u53ef\u6269\u5c55\u3001\u4f4e\u8d44\u6e90\u7684\u8bed\u6cd5\u8bc4\u4f30\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u5177\u6709\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2511.13131", "categories": ["cs.AI", "cs.CV", "cs.ET", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.13131", "abs": "https://arxiv.org/abs/2511.13131", "authors": ["Gagan Raj Gupta", "Anshul Kumar", "Manish Rai", "Apu Chakraborty", "Ashutosh Modi", "Abdelaali Chaoub", "Soumajit Pramanik", "Moyank Giri", "Yashwanth Holla", "Sunny Kumar", "M. V. Kiran Sooraj"], "title": "MM-Telco: Benchmarks and Multimodal Large Language Models for Telecom Applications", "comment": null, "summary": "Large Language Models (LLMs) have emerged as powerful tools for automating complex reasoning and decision-making tasks. In telecommunications, they hold the potential to transform network optimization, automate troubleshooting, enhance customer support, and ensure regulatory compliance. However, their deployment in telecom is hindered by domain-specific challenges that demand specialized adaptation. To overcome these challenges and to accelerate the adaptation of LLMs for telecom, we propose MM-Telco, a comprehensive suite of multimodal benchmarks and models tailored for the telecom domain. The benchmark introduces various tasks (both text based and image based) that address various practical real-life use cases such as network operations, network management, improving documentation quality, and retrieval of relevant text and images. Further, we perform baseline experiments with various LLMs and VLMs. The models fine-tuned on our dataset exhibit a significant boost in performance. Our experiments also help analyze the weak areas in the working of current state-of-art multimodal LLMs, thus guiding towards further development and research.", "AI": {"tldr": "\u63d0\u51fa\u4e86MM-Telco\uff0c\u4e00\u4e2a\u4e3a\u7535\u4fe1\u9886\u57df\u5b9a\u5236\u7684\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u548c\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3LLM\u5728\u7535\u4fe1\u5e94\u7528\u4e2d\u7684\u9886\u57df\u7279\u5b9a\u6311\u6218\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7535\u4fe1\u9886\u57df\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u9886\u57df\u7279\u5b9a\u7684\u6311\u6218\uff0c\u9700\u8981\u4e13\u95e8\u9002\u914d\u624d\u80fd\u6709\u6548\u90e8\u7f72\u4e8e\u7f51\u7edc\u4f18\u5316\u3001\u6545\u969c\u6392\u9664\u3001\u5ba2\u6237\u652f\u6301\u548c\u5408\u89c4\u7ba1\u7406\u7b49\u4efb\u52a1\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b\u6587\u672c\u548c\u56fe\u50cf\u4efb\u52a1\u7684\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u6db5\u76d6\u7f51\u7edc\u8fd0\u8425\u3001\u7f51\u7edc\u7ba1\u7406\u3001\u6587\u6863\u8d28\u91cf\u6539\u8fdb\u548c\u76f8\u5173\u6587\u672c\u56fe\u50cf\u68c0\u7d22\u7b49\u5b9e\u9645\u7528\u4f8b\uff0c\u5e76\u5bf9\u5404\u79cdLLM\u548cVLM\u8fdb\u884c\u57fa\u7ebf\u5b9e\u9a8c\u3002", "result": "\u5728\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u7684\u6a21\u578b\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u5b9e\u9a8c\u63ed\u793a\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u591a\u6a21\u6001LLM\u7684\u8584\u5f31\u73af\u8282\u3002", "conclusion": "MM-Telco\u4e3a\u7535\u4fe1\u9886\u57dfLLM\u7684\u9002\u5e94\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\uff0c\u6307\u5bfc\u4e86\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u548c\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2511.13159", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13159", "abs": "https://arxiv.org/abs/2511.13159", "authors": ["Zaara Zabeen Arpa", "Sadnam Sakib Apurbo", "Nazia Karim Khan Oishee", "Ajwad Abrar"], "title": "Distinguishing Repetition Disfluency from Morphological Reduplication in Bangla ASR Transcripts: A Novel Corpus and Benchmarking Analysis", "comment": null, "summary": "Automatic Speech Recognition (ASR) transcripts, especially in low-resource languages like Bangla, contain a critical ambiguity: word-word repetitions can be either Repetition Disfluency (unintentional ASR error/hesitation) or Morphological Reduplication (a deliberate grammatical construct). Standard disfluency correction fails by erroneously deleting valid linguistic information. To solve this, we introduce the first publicly available, 20,000-row Bangla corpus, manually annotated to explicitly distinguish between these two phenomena in noisy ASR transcripts. We benchmark this novel resource using two paradigms: state-of-the-art multilingual Large Language Models (LLMs) and task-specific fine-tuning of encoder models. LLMs achieve competitive performance (up to 82.68\\% accuracy) with few-shot prompting. However, fine-tuning proves superior, with the language-specific BanglaBERT model achieving the highest accuracy of 84.78\\% and an F1 score of 0.677. This establishes a strong, linguistically-informed baseline and provides essential data for developing sophisticated, semantic-preserving text normalization systems for Bangla.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u9996\u4e2a\u516c\u5f00\u7684\u5b5f\u52a0\u62c9\u8bed\u8bed\u6599\u5e93\uff0c\u7528\u4e8e\u533a\u5206ASR\u8f6c\u5f55\u4e2d\u7684\u91cd\u590d\u6027\u4e0d\u6d41\u7545\u548c\u5f62\u6001\u5b66\u91cd\u53e0\u73b0\u8c61\uff0c\u5e76\u901a\u8fc7LLM\u548c\u5fae\u8c03\u65b9\u6cd5\u5efa\u7acb\u4e86\u57fa\u51c6\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5b5f\u52a0\u62c9\u8bedASR\u8f6c\u5f55\u4e2d\u8bcd\u91cd\u590d\u7684\u6b67\u4e49\u95ee\u9898\uff1a\u533a\u5206\u65e0\u610f\u7684\u91cd\u590d\u6027\u4e0d\u6d41\u7545\u548c\u6545\u610f\u7684\u5f62\u6001\u5b66\u91cd\u53e0\uff0c\u907f\u514d\u6807\u51c6\u4e0d\u6d41\u7545\u4fee\u6b63\u65b9\u6cd5\u8bef\u5220\u6709\u6548\u8bed\u8a00\u4fe1\u606f\u3002", "method": "\u521b\u5efa\u4e862\u4e07\u884c\u624b\u52a8\u6807\u6ce8\u7684\u5b5f\u52a0\u62c9\u8bed\u8bed\u6599\u5e93\uff0c\u4f7f\u7528\u4e24\u79cd\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff1a\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5c11\u6837\u672c\u63d0\u793a\u548c\u4efb\u52a1\u7279\u5b9a\u7684\u7f16\u7801\u5668\u6a21\u578b\u5fae\u8c03\u3002", "result": "LLM\u5728\u5c11\u6837\u672c\u63d0\u793a\u4e0b\u8fbe\u523082.68%\u51c6\u786e\u7387\uff0c\u4f46\u5fae\u8c03\u65b9\u6cd5\u66f4\u4f18\uff0cBanglaBERT\u6a21\u578b\u8fbe\u5230\u6700\u9ad884.78%\u51c6\u786e\u7387\u548c0.677 F1\u5206\u6570\u3002", "conclusion": "\u5efa\u7acb\u4e86\u5f3a\u5927\u7684\u8bed\u8a00\u5b66\u57fa\u51c6\uff0c\u4e3a\u5f00\u53d1\u8bed\u4e49\u4fdd\u7559\u7684\u5b5f\u52a0\u62c9\u8bed\u6587\u672c\u89c4\u8303\u5316\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u6570\u636e\u652f\u6301\u3002"}}
{"id": "2511.13137", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13137", "abs": "https://arxiv.org/abs/2511.13137", "authors": ["Yanda Zhu", "Yuanyang Zhu", "Daoyi Dong", "Caihua Chen", "Chunlin Chen"], "title": "Conditional Diffusion Model for Multi-Agent Dynamic Task Decomposition", "comment": "AAAI 2026", "summary": "Task decomposition has shown promise in complex cooperative multi-agent reinforcement learning (MARL) tasks, which enables efficient hierarchical learning for long-horizon tasks in dynamic and uncertain environments. However, learning dynamic task decomposition from scratch generally requires a large number of training samples, especially exploring the large joint action space under partial observability. In this paper, we present the Conditional Diffusion Model for Dynamic Task Decomposition (C$\\text{D}^\\text{3}$T), a novel two-level hierarchical MARL framework designed to automatically infer subtask and coordination patterns. The high-level policy learns subtask representation to generate a subtask selection strategy based on subtask effects. To capture the effects of subtasks on the environment, C$\\text{D}^\\text{3}$T predicts the next observation and reward using a conditional diffusion model. At the low level, agents collaboratively learn and share specialized skills within their assigned subtasks. Moreover, the learned subtask representation is also used as additional semantic information in a multi-head attention mixing network to enhance value decomposition and provide an efficient reasoning bridge between individual and joint value functions. Experimental results on various benchmarks demonstrate that C$\\text{D}^\\text{3}$T achieves better performance than existing baselines.", "AI": {"tldr": "C$\text{D}^\text{3}$T\u662f\u4e00\u4e2a\u57fa\u4e8e\u6761\u4ef6\u6269\u6563\u6a21\u578b\u7684\u4e24\u5c42\u5206\u5c42\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u591f\u81ea\u52a8\u63a8\u65ad\u5b50\u4efb\u52a1\u548c\u534f\u8c03\u6a21\u5f0f\uff0c\u5728\u52a8\u6001\u548c\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6548\u7684\u5206\u5c42\u5b66\u4e60\u3002", "motivation": "\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\uff0c\u4ece\u96f6\u5f00\u59cb\u5b66\u4e60\u52a8\u6001\u4efb\u52a1\u5206\u89e3\u901a\u5e38\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u6837\u672c\uff0c\u7279\u522b\u662f\u5728\u63a2\u7d22\u5927\u578b\u8054\u5408\u52a8\u4f5c\u7a7a\u95f4\u65f6\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u4efb\u52a1\u5206\u89e3\u6548\u7387\u6709\u5f85\u63d0\u5347\u3002", "method": "\u63d0\u51faC$\text{D}^\text{3}$T\u6846\u67b6\uff1a\u9ad8\u5c42\u7b56\u7565\u5b66\u4e60\u5b50\u4efb\u52a1\u8868\u793a\uff0c\u57fa\u4e8e\u5b50\u4efb\u52a1\u6548\u679c\u751f\u6210\u5b50\u4efb\u52a1\u9009\u62e9\u7b56\u7565\uff1b\u4f7f\u7528\u6761\u4ef6\u6269\u6563\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u89c2\u5bdf\u548c\u5956\u52b1\u6765\u6355\u6349\u5b50\u4efb\u52a1\u5bf9\u73af\u5883\u7684\u5f71\u54cd\uff1b\u4f4e\u5c42\u667a\u80fd\u4f53\u5728\u5206\u914d\u7684\u5b50\u4efb\u52a1\u5185\u534f\u4f5c\u5b66\u4e60\u548c\u5171\u4eab\u4e13\u95e8\u6280\u80fd\uff1b\u5229\u7528\u5b50\u4efb\u52a1\u8868\u793a\u4f5c\u4e3a\u591a\u5934\u6ce8\u610f\u529b\u6df7\u5408\u7f51\u7edc\u4e2d\u7684\u8bed\u4e49\u4fe1\u606f\u589e\u5f3a\u4ef7\u503c\u5206\u89e3\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cC$\text{D}^\text{3}$T\u76f8\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "C$\text{D}^\text{3}$T\u901a\u8fc7\u6761\u4ef6\u6269\u6563\u6a21\u578b\u548c\u5206\u5c42\u5b66\u4e60\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u52a8\u6001\u4efb\u52a1\u5206\u89e3\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u5b66\u4e60\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2511.13169", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13169", "abs": "https://arxiv.org/abs/2511.13169", "authors": ["Tianai Huang", "Jiayuan Chen", "Lu Lu", "Pengcheng Chen", "Tianbin Li", "Bing Han", "Wenchao Tang", "Jie Xu", "Ming Li"], "title": "TCM-5CEval: Extended Deep Evaluation Benchmark for LLM's Comprehensive Clinical Research Competence in Traditional Chinese Medicine", "comment": "17 pages, 8 figures", "summary": "Large language models (LLMs) have demonstrated exceptional capabilities in general domains, yet their application in highly specialized and culturally-rich fields like Traditional Chinese Medicine (TCM) requires rigorous and nuanced evaluation. Building upon prior foundational work such as TCM-3CEval, which highlighted systemic knowledge gaps and the importance of cultural-contextual alignment, we introduce TCM-5CEval, a more granular and comprehensive benchmark. TCM-5CEval is designed to assess LLMs across five critical dimensions: (1) Core Knowledge (TCM-Exam), (2) Classical Literacy (TCM-LitQA), (3) Clinical Decision-making (TCM-MRCD), (4) Chinese Materia Medica (TCM-CMM), and (5) Clinical Non-pharmacological Therapy (TCM-ClinNPT). We conducted a thorough evaluation of fifteen prominent LLMs, revealing significant performance disparities and identifying top-performing models like deepseek\\_r1 and gemini\\_2\\_5\\_pro. Our findings show that while models exhibit proficiency in recalling foundational knowledge, they struggle with the interpretative complexities of classical texts. Critically, permutation-based consistency testing reveals widespread fragilities in model inference. All evaluated models, including the highest-scoring ones, displayed a substantial performance degradation when faced with varied question option ordering, indicating a pervasive sensitivity to positional bias and a lack of robust understanding. TCM-5CEval not only provides a more detailed diagnostic tool for LLM capabilities in TCM but aldso exposes fundamental weaknesses in their reasoning stability. To promote further research and standardized comparison, TCM-5CEval has been uploaded to the Medbench platform, joining its predecessor in the \"In-depth Challenge for Comprehensive TCM Abilities\" special track.", "AI": {"tldr": "TCM-5CEval\u662f\u4e00\u4e2a\u66f4\u7ec6\u7c92\u5ea6\u7684\u4e2d\u533b\u9886\u57df\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u57fa\u51c6\uff0c\u6db5\u76d65\u4e2a\u5173\u952e\u7ef4\u5ea6\uff0c\u8bc4\u4f30\u4e8615\u4e2a\u4e3b\u6d41\u6a21\u578b\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u57fa\u7840\u77e5\u8bc6\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7ecf\u5178\u6587\u672c\u89e3\u91ca\u548c\u63a8\u7406\u7a33\u5b9a\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u7f3a\u9677\u3002", "motivation": "\u73b0\u6709LLMs\u5728\u4e2d\u533b\u7b49\u4e13\u4e1a\u6587\u5316\u9886\u57df\u7684\u5e94\u7528\u9700\u8981\u4e25\u8c28\u8bc4\u4f30\uff0c\u57fa\u4e8e\u524d\u671fTCM-3CEval\u5de5\u4f5c\u53d1\u73b0\u7684\u77e5\u8bc6\u5dee\u8ddd\u548c\u6587\u5316\u80cc\u666f\u5bf9\u9f50\u95ee\u9898\uff0c\u9700\u8981\u66f4\u5168\u9762\u7ec6\u7c92\u5ea6\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u5f00\u53d1TCM-5CEval\u57fa\u51c6\uff0c\u5305\u542b5\u4e2a\u7ef4\u5ea6\uff1a\u6838\u5fc3\u77e5\u8bc6\u3001\u7ecf\u5178\u7d20\u517b\u3001\u4e34\u5e8a\u51b3\u7b56\u3001\u4e2d\u836f\u5b66\u548c\u4e34\u5e8a\u975e\u836f\u7269\u7597\u6cd5\uff0c\u5bf915\u4e2a\u4e3b\u6d41LLMs\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\uff0c\u5e76\u91c7\u7528\u6392\u5217\u4e00\u81f4\u6027\u6d4b\u8bd5\u68c0\u9a8c\u63a8\u7406\u7a33\u5b9a\u6027\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u6a21\u578b\u6027\u80fd\u5dee\u5f02\u663e\u8457\uff0cdeepseek_r1\u548cgemini_2_5_pro\u8868\u73b0\u6700\u4f73\u3002\u6a21\u578b\u5728\u57fa\u7840\u77e5\u8bc6\u56de\u5fc6\u65b9\u9762\u719f\u7ec3\uff0c\u4f46\u5728\u7ecf\u5178\u6587\u672c\u89e3\u91ca\u65b9\u9762\u56f0\u96be\u3002\u6392\u5217\u6d4b\u8bd5\u53d1\u73b0\u6240\u6709\u6a21\u578b\u90fd\u5b58\u5728\u4f4d\u7f6e\u504f\u89c1\u654f\u611f\u6027\uff0c\u63a8\u7406\u7a33\u5b9a\u6027\u666e\u904d\u4e0d\u8db3\u3002", "conclusion": "TCM-5CEval\u63d0\u4f9b\u4e86\u66f4\u8be6\u7ec6\u7684\u4e2d\u533bLLM\u80fd\u529b\u8bca\u65ad\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u63a8\u7406\u7a33\u5b9a\u6027\u7684\u6839\u672c\u5f31\u70b9\uff0c\u57fa\u51c6\u5df2\u4e0a\u4f20\u81f3Medbench\u5e73\u53f0\u4fc3\u8fdb\u6807\u51c6\u5316\u6bd4\u8f83\u3002"}}
{"id": "2511.13160", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13160", "abs": "https://arxiv.org/abs/2511.13160", "authors": ["TC Singh", "Sougata Mukherjea"], "title": "InteractiveGNNExplainer: A Visual Analytics Framework for Multi-Faceted Understanding and Probing of Graph Neural Network Predictions", "comment": null, "summary": "Graph Neural Networks (GNNs) excel in graph-based learning tasks, but their complex, non-linear operations often render them as opaque \"black boxes\". This opacity hinders user trust, complicates debugging, bias detection, and adoption in critical domains requiring explainability. This paper introduces InteractiveGNNExplainer, a visual analytics framework to enhance GNN explainability, focusing on node classification. Our system uniquely integrates coordinated interactive views (dynamic graph layouts, embedding projections, feature inspection, neighborhood analysis) with established post-hoc (GNNExplainer) and intrinsic (GAT attention) explanation techniques. Crucially, it incorporates interactive graph editing, allowing users to perform a \"what-if\" analysis by perturbing graph structures and observing immediate impacts on GNN predictions and explanations. We detail the system architecture and, through case studies on Cora and CiteSeer datasets, demonstrate how InteractiveGNNExplainer facilitates in-depth misclassification diagnosis, comparative analysis of GCN versus GAT behaviors, and rigorous probing of model sensitivity. These capabilities foster a deeper, multifaceted understanding of GNN predictions, contributing to more transparent, trustworthy, and robust graph analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86InteractiveGNNExplainer\uff0c\u4e00\u4e2a\u7528\u4e8e\u589e\u5f3a\u56fe\u795e\u7ecf\u7f51\u7edc\u53ef\u89e3\u91ca\u6027\u7684\u53ef\u89c6\u5316\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u4ea4\u4e92\u5f0f\u56fe\u7f16\u8f91\u548c\u534f\u8c03\u89c6\u56fe\u652f\u6301\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u7684\u6df1\u5165\u5206\u6790\u3002", "motivation": "\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u57fa\u4e8e\u56fe\u7684\u5b66\u4e60\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u590d\u6742\u7684\u975e\u7ebf\u6027\u64cd\u4f5c\u4f7f\u5176\u6210\u4e3a\u4e0d\u900f\u660e\u7684\"\u9ed1\u7bb1\"\uff0c\u8fd9\u963b\u788d\u4e86\u7528\u6237\u4fe1\u4efb\u3001\u8c03\u8bd5\u3001\u504f\u89c1\u68c0\u6d4b\u4ee5\u53ca\u5728\u9700\u8981\u53ef\u89e3\u91ca\u6027\u7684\u5173\u952e\u9886\u57df\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5f00\u53d1\u4e86InteractiveGNNExplainer\u6846\u67b6\uff0c\u6574\u5408\u4e86\u534f\u8c03\u7684\u4ea4\u4e92\u89c6\u56fe\uff08\u52a8\u6001\u56fe\u5e03\u5c40\u3001\u5d4c\u5165\u6295\u5f71\u3001\u7279\u5f81\u68c0\u67e5\u3001\u90bb\u57df\u5206\u6790\uff09\u4e0e\u540e\u9a8c\u89e3\u91ca\uff08GNNExplainer\uff09\u548c\u5185\u5728\u89e3\u91ca\uff08GAT\u6ce8\u610f\u529b\uff09\u6280\u672f\uff0c\u5e76\u52a0\u5165\u4e86\u4ea4\u4e92\u5f0f\u56fe\u7f16\u8f91\u529f\u80fd\u8fdb\u884c\"\u5047\u8bbe\u5206\u6790\"\u3002", "result": "\u901a\u8fc7\u5728Cora\u548cCiteSeer\u6570\u636e\u96c6\u4e0a\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u8be5\u7cfb\u7edf\u80fd\u591f\u4fc3\u8fdb\u6df1\u5165\u7684\u9519\u8bef\u5206\u7c7b\u8bca\u65ad\u3001GCN\u4e0eGAT\u884c\u4e3a\u7684\u6bd4\u8f83\u5206\u6790\uff0c\u4ee5\u53ca\u5bf9\u6a21\u578b\u654f\u611f\u6027\u7684\u4e25\u683c\u63a2\u6d4b\u3002", "conclusion": "\u8fd9\u4e9b\u529f\u80fd\u4fc3\u8fdb\u4e86\u5bf9GNN\u9884\u6d4b\u7684\u66f4\u6df1\u5c42\u6b21\u3001\u591a\u65b9\u9762\u7684\u7406\u89e3\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u66f4\u900f\u660e\u3001\u53ef\u4fe1\u548c\u9c81\u68d2\u7684\u56fe\u5206\u6790\u3002"}}
{"id": "2511.13180", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13180", "abs": "https://arxiv.org/abs/2511.13180", "authors": ["Ronit D. Gross", "Yanir Harel", "Ido Kanter"], "title": "Translation Entropy: A Statistical Framework for Evaluating Translation Systems", "comment": "23 pages, 6 figures and 8 tables", "summary": "The translation of written language has been known since the 3rd century BC; however, its necessity has become increasingly common in the information age. Today, many translators exist, based on encoder-decoder deep architectures, nevertheless, no quantitative objective methods are available to assess their performance, likely because the entropy of even a single language remains unknown. This study presents a quantitative method for estimating translation entropy, with the following key finding. Given a translator, several sentences that differ by only one selected token of a given pivot sentence yield identical translations. Analyzing the statistics of this phenomenon across an ensemble of such sentences, consisting each of a pivot selected token, yields the probabilities of replacing this specific token with others while preserving the translation. These probabilities constitute the entropy of the selected token, and the average across all selected pivot tokens provides an estimate of the translator's overall translation entropy, which is enhanced along the decoder blocks. This entropic measure allows for the quantitative ranking of several publicly available translators and reveals whether mutual translation entropy is symmetric. Extending the proposed method to include the replacement of two tokens in a given pivot sentence demonstrates a multiplicative effect, where translation degeneracy is proportional to the product of the degeneracies of the two tokens. These findings establish translation entropy as a measurable property and objective benchmarking of artificial translators. Results are based on MarianMT, T5-Base and NLLB-200 translators.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5316\u8bc4\u4f30\u7ffb\u8bd1\u5668\u6027\u80fd\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u7ffb\u8bd1\u71b5\u6765\u8861\u91cf\u7ffb\u8bd1\u5668\u7684\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0\u7ffb\u8bd1\u71b5\u53ef\u4ee5\u5ba2\u89c2\u6bd4\u8f83\u4e0d\u540c\u7ffb\u8bd1\u5668\uff0c\u5e76\u63ed\u793a\u4e86\u7ffb\u8bd1\u9000\u5316\u7684\u4e58\u6cd5\u6548\u5e94\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5ba2\u89c2\u91cf\u5316\u65b9\u6cd5\u6765\u8bc4\u4f30\u57fa\u4e8e\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u7684\u7ffb\u8bd1\u5668\u6027\u80fd\uff0c\u4e3b\u8981\u662f\u56e0\u4e3a\u5355\u8bed\u8a00\u7684\u71b5\u503c\u672a\u77e5\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4ec5\u6539\u53d8\u4e00\u4e2a\u9009\u5b9a\u6807\u8bb0\u7684\u591a\u4e2a\u53e5\u5b50\u4ea7\u751f\u76f8\u540c\u7ffb\u8bd1\u7684\u7edf\u8ba1\u73b0\u8c61\uff0c\u8ba1\u7b97\u7279\u5b9a\u6807\u8bb0\u7684\u66ff\u6362\u6982\u7387\uff0c\u4ece\u800c\u4f30\u8ba1\u7ffb\u8bd1\u71b5\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u91cf\u5316\u6392\u540d\u4e0d\u540c\u516c\u5f00\u7ffb\u8bd1\u5668\uff0c\u53d1\u73b0\u7ffb\u8bd1\u9000\u5316\u4e0e\u6807\u8bb0\u9000\u5316\u7684\u4e58\u79ef\u6210\u6b63\u6bd4\uff0c\u7ffb\u8bd1\u71b5\u5728\u89e3\u7801\u5668\u5757\u4e2d\u5f97\u5230\u589e\u5f3a\u3002", "conclusion": "\u7ffb\u8bd1\u71b5\u662f\u4e00\u4e2a\u53ef\u6d4b\u91cf\u7684\u5c5e\u6027\uff0c\u4e3a\u4eba\u5de5\u7ffb\u8bd1\u5668\u63d0\u4f9b\u4e86\u5ba2\u89c2\u7684\u57fa\u51c6\u6d4b\u8bd5\u6807\u51c6\u3002"}}
{"id": "2511.13193", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13193", "abs": "https://arxiv.org/abs/2511.13193", "authors": ["Yijia Fan", "Jusheng Zhang", "Kaitong Cai", "Jing Yang", "Chengpei Tang", "Jian Wang", "Keze Wang"], "title": "Cost-Effective Communication: An Auction-based Method for Language Agent Interaction", "comment": null, "summary": "Multi-agent systems (MAS) built on large language models (LLMs) often suffer from inefficient \"free-for-all\" communication, leading to exponential token costs and low signal-to-noise ratios that hinder their practical deployment. We challenge the notion that more communication is always beneficial, hypothesizing instead that the core issue is the absence of resource rationality. We argue that \"free\" communication, by ignoring the principle of scarcity, inherently breeds inefficiency and unnecessary expenses. To address this, we introduce the Dynamic Auction-based Language Agent (DALA), a novel framework that treats communication bandwidth as a scarce and tradable resource. Specifically, our DALA regards inter-agent communication as a centralized auction, where agents learn to bid for the opportunity to speak based on the predicted value density of their messages. Thus, our DALA intrinsically encourages agents to produce concise, informative messages while filtering out low-value communication. Extensive and comprehensive experiments demonstrate that our economically-driven DALA achieves new state-of-the-art performance across seven challenging reasoning benchmarks, including 84.32% on MMLU and a 91.21% pass@1 rate on HumanEval. Note that this is accomplished with remarkable efficiency, i.e., our DALA uses only 6.25 million tokens, a fraction of the resources consumed by current state-of-the-art methods on GSM8K. Further analysis reveals that our DALA cultivates the emergent skill of strategic silence, effectively adapting its communication strategies from verbosity to silence in a dynamical manner via resource constraints.", "AI": {"tldr": "DALA\u6846\u67b6\u901a\u8fc7\u5c06\u901a\u4fe1\u5e26\u5bbd\u89c6\u4e3a\u7a00\u7f3a\u53ef\u4ea4\u6613\u8d44\u6e90\uff0c\u91c7\u7528\u62cd\u5356\u673a\u5236\u8ba9\u667a\u80fd\u4f53\u57fa\u4e8e\u4fe1\u606f\u4ef7\u503c\u5bc6\u5ea6\u7ade\u6807\u53d1\u8a00\u6743\uff0c\u663e\u8457\u63d0\u5347\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u901a\u4fe1\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d'\u81ea\u7531\u901a\u4fe1'\u5bfc\u81f4\u7684\u6307\u6570\u7ea7token\u6210\u672c\u548c\u9ad8\u566a\u58f0\u4f4e\u4fe1\u53f7\u6bd4\u95ee\u9898\uff0c\u6311\u6218'\u66f4\u591a\u901a\u4fe1\u603b\u662f\u66f4\u597d'\u7684\u89c2\u5ff5\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u62cd\u5356\u8bed\u8a00\u667a\u80fd\u4f53(DALA)\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u4f53\u95f4\u901a\u4fe1\u89c6\u4e3a\u96c6\u4e2d\u5f0f\u62cd\u5356\uff0c\u667a\u80fd\u4f53\u5b66\u4e60\u57fa\u4e8e\u9884\u6d4b\u4fe1\u606f\u4ef7\u503c\u5bc6\u5ea6\u7ade\u6807\u53d1\u8a00\u673a\u4f1a\u3002", "result": "\u57287\u4e2a\u6311\u6218\u6027\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff1aMMLU 84.32%\uff0cHumanEval 91.21% pass@1\uff0c\u4e14\u4ec5\u4f7f\u7528625\u4e07token\uff0c\u8fdc\u5c11\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "DALA\u901a\u8fc7\u8d44\u6e90\u7ea6\u675f\u57f9\u517b\u51fa\u6218\u7565\u6027\u6c89\u9ed8\u7684\u6d8c\u73b0\u6280\u80fd\uff0c\u80fd\u52a8\u6001\u8c03\u6574\u4ece\u5197\u957f\u5230\u6c89\u9ed8\u7684\u901a\u4fe1\u7b56\u7565\uff0c\u8bc1\u660e\u8d44\u6e90\u7406\u6027\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.13182", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13182", "abs": "https://arxiv.org/abs/2511.13182", "authors": ["Mihai Dan Nadas", "Laura Diosan"], "title": "Evaluating Large Language Models for Diacritic Restoration in Romanian Texts: A Comparative Study", "comment": null, "summary": "Automatic diacritic restoration is crucial for text processing in languages with rich diacritical marks, such as Romanian. This study evaluates the performance of several large language models (LLMs) in restoring diacritics in Romanian texts. Using a comprehensive corpus, we tested models including OpenAI's GPT-3.5, GPT-4, GPT-4o, Google's Gemini 1.0 Pro, Meta's Llama 2 and Llama 3, MistralAI's Mixtral 8x7B Instruct, airoboros 70B, and OpenLLM-Ro's RoLlama 2 7B, under multiple prompt templates ranging from zero-shot to complex multi-shot instructions. Results show that models such as GPT-4o achieve high diacritic restoration accuracy, consistently surpassing a neutral echo baseline, while others, including Meta's Llama family, exhibit wider variability. These findings highlight the impact of model architecture, training data, and prompt design on diacritic restoration performance and outline promising directions for improving NLP tools for diacritic-rich languages.", "AI": {"tldr": "\u8bc4\u4f30\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u53d8\u97f3\u7b26\u53f7\u6062\u590d\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0GPT-4o\u7b49\u6a21\u578b\u8868\u73b0\u4f18\u5f02\uff0c\u800cLlama\u7cfb\u5217\u6a21\u578b\u8868\u73b0\u6ce2\u52a8\u8f83\u5927\u3002", "motivation": "\u81ea\u52a8\u53d8\u97f3\u7b26\u53f7\u6062\u590d\u5bf9\u4e8e\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u7b49\u5bcc\u542b\u53d8\u97f3\u7b26\u53f7\u7684\u8bed\u8a00\u7684\u6587\u672c\u5904\u7406\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u8bc4\u4f30\u5f53\u524d\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u7efc\u5408\u8bed\u6599\u5e93\u6d4b\u8bd5\u4e86\u5305\u62ecGPT-3.5\u3001GPT-4\u3001GPT-4o\u3001Gemini 1.0 Pro\u3001Llama 2/3\u3001Mixtral 8x7B\u7b49\u5728\u5185\u7684\u591a\u79cdLLM\uff0c\u91c7\u7528\u4ece\u96f6\u6837\u672c\u5230\u590d\u6742\u591a\u6837\u672c\u6307\u4ee4\u7684\u591a\u79cd\u63d0\u793a\u6a21\u677f\u3002", "result": "GPT-4o\u7b49\u6a21\u578b\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u53d8\u97f3\u7b26\u53f7\u6062\u590d\uff0c\u59cb\u7ec8\u4f18\u4e8e\u4e2d\u6027\u56de\u663e\u57fa\u7ebf\uff0c\u800cMeta\u7684Llama\u7cfb\u5217\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u5927\u7684\u53d8\u5f02\u6027\u3002", "conclusion": "\u6a21\u578b\u67b6\u6784\u3001\u8bad\u7ec3\u6570\u636e\u548c\u63d0\u793a\u8bbe\u8ba1\u5bf9\u53d8\u97f3\u7b26\u53f7\u6062\u590d\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4e3a\u6539\u8fdb\u5bcc\u542b\u53d8\u97f3\u7b26\u53f7\u8bed\u8a00\u7684NLP\u5de5\u5177\u6307\u660e\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2511.13214", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13214", "abs": "https://arxiv.org/abs/2511.13214", "authors": ["Guillaume Infantes", "St\u00e9phanie Roussel", "Antoine Jacquet", "Emmanuel Benazera"], "title": "Learning to Solve Resource-Constrained Project Scheduling Problems with Duration Uncertainty using Graph Neural Networks", "comment": "Accepted at ICTAI 2025 Conference", "summary": "The Resource-Constrained Project Scheduling Problem (RCPSP) is a classical scheduling problem that has received significant attention due to of its numerous applications in industry. However, in practice, task durations are subject to uncertainty that must be considered in order to propose resilient scheduling. In this paper, we address the RCPSP variant with uncertain tasks duration (modeled using known probabilities) and aim to minimize the overall expected project duration. Our objective is to produce a baseline schedule that can be reused multiple times in an industrial setting regardless of the actual duration scenario. We leverage Graph Neural Networks in conjunction with Deep Reinforcement Learning (DRL) to develop an effective policy for task scheduling. This policy operates similarly to a priority dispatch rule and is paired with a Serial Schedule Generation Scheme to produce a schedule. Our empirical evaluation on standard benchmarks demonstrates the approach's superiority in terms of performance and its ability to generalize. The developed framework, Wheatley, is made publicly available online to facilitate further research and reproducibility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u8d44\u6e90\u53d7\u9650\u9879\u76ee\u8c03\u5ea6\u95ee\u9898\uff08RCPSP\uff09\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u4e8e\u5904\u7406\u4efb\u52a1\u6301\u7eed\u65f6\u95f4\u4e0d\u786e\u5b9a\u7684\u60c5\u51b5\uff0c\u65e8\u5728\u6700\u5c0f\u5316\u9884\u671f\u9879\u76ee\u603b\u5de5\u671f\u3002", "motivation": "\u5b9e\u9645\u5de5\u4e1a\u5e94\u7528\u4e2d\u4efb\u52a1\u6301\u7eed\u65f6\u95f4\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\uff0c\u9700\u8981\u63d0\u51fa\u5177\u6709\u5f39\u6027\u7684\u8c03\u5ea6\u65b9\u6848\u6765\u5e94\u5bf9\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\uff0c\u786e\u4fdd\u57fa\u7ebf\u8c03\u5ea6\u65b9\u6848\u5728\u4e0d\u540c\u6301\u7eed\u65f6\u95f4\u573a\u666f\u4e0b\u90fd\u80fd\u91cd\u590d\u4f7f\u7528\u3002", "method": "\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5f00\u53d1\u4efb\u52a1\u8c03\u5ea6\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u7c7b\u4f3c\u4e8e\u4f18\u5148\u7ea7\u8c03\u5ea6\u89c4\u5219\uff0c\u5e76\u4e0e\u4e32\u884c\u8c03\u5ea6\u751f\u6210\u65b9\u6848\u914d\u5408\u751f\u6210\u8c03\u5ea6\u8ba1\u5212\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u5177\u6709\u4f18\u8d8a\u6027\u3002", "conclusion": "\u5f00\u53d1\u4e86\u540d\u4e3aWheatley\u7684\u516c\u5f00\u53ef\u7528\u6846\u67b6\uff0c\u4ee5\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u53ef\u91cd\u590d\u6027\u3002"}}
{"id": "2511.13225", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13225", "abs": "https://arxiv.org/abs/2511.13225", "authors": ["Tyler Loakman", "Joseph James", "Chenghua Lin"], "title": "Seeing isn't Hearing: Benchmarking Vision Language Models at Interpreting Spectrograms", "comment": "Accepted to IJCNLP-AACL 2025", "summary": "With the rise of Large Language Models (LLMs) and their vision-enabled counterparts (VLMs), numerous works have investigated their capabilities in tasks that fuse the modalities of vision and language. In this work, we benchmark the extent to which VLMs are able to act as highly-trained phoneticians, interpreting spectrograms and waveforms of speech. To do this, we synthesise a novel dataset containing 4k+ English words spoken in isolation alongside stylistically consistent spectrogram and waveform figures. We test the ability of VLMs to understand these representations of speech through a multiple-choice task whereby models must predict the correct phonemic or graphemic transcription of a spoken word when presented amongst 3 distractor transcriptions that have been selected based on their phonemic edit distance to the ground truth. We observe that both zero-shot and finetuned models rarely perform above chance, demonstrating the requirement for specific parametric knowledge of how to interpret such figures, rather than paired samples alone.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u4f5c\u4e3a\u8bed\u97f3\u5b66\u5bb6\u7684\u80fd\u529b\uff0c\u6d4b\u8bd5\u5176\u4ece\u8bed\u97f3\u9891\u8c31\u56fe\u548c\u6ce2\u5f62\u4e2d\u8bc6\u522b\u82f1\u8bed\u5355\u8bcd\u7684\u80fd\u529b\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u65e0\u8bba\u662f\u96f6\u6837\u672c\u8fd8\u662f\u5fae\u8c03\u540e\u7684\u6a21\u578b\uff0c\u5176\u8868\u73b0\u90fd\u5f88\u5c11\u8d85\u8fc7\u968f\u673a\u6c34\u5e73\uff0c\u8868\u660e\u9700\u8981\u7279\u5b9a\u7684\u53c2\u6570\u77e5\u8bc6\u6765\u89e3\u91ca\u8bed\u97f3\u56fe\u50cf\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u53ca\u5176\u89c6\u89c9\u7248\u672c\uff08VLMs\uff09\u7684\u53d1\u5c55\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u4e86\u89e3\u8fd9\u4e9b\u6a21\u578b\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5b83\u4eec\u662f\u5426\u80fd\u50cf\u4e13\u4e1a\u8bed\u97f3\u5b66\u5bb6\u4e00\u6837\u89e3\u8bfb\u8bed\u97f3\u7684\u9891\u8c31\u56fe\u548c\u6ce2\u5f62\u3002", "method": "\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b4000\u591a\u4e2a\u5b64\u7acb\u82f1\u8bed\u5355\u8bcd\u7684\u6570\u636e\u96c6\uff0c\u5e76\u751f\u6210\u76f8\u5e94\u7684\u9891\u8c31\u56fe\u548c\u6ce2\u5f62\u56fe\u3002\u901a\u8fc7\u591a\u9879\u9009\u62e9\u4efb\u52a1\u6d4b\u8bd5VLMs\u7684\u80fd\u529b\uff0c\u6a21\u578b\u9700\u8981\u4ece4\u4e2a\u9009\u9879\uff081\u4e2a\u6b63\u786e\u7b54\u6848\u548c3\u4e2a\u57fa\u4e8e\u97f3\u7d20\u7f16\u8f91\u8ddd\u79bb\u9009\u62e9\u7684\u5e72\u6270\u9879\uff09\u4e2d\u8bc6\u522b\u6b63\u786e\u7684\u97f3\u7d20\u6216\u5b57\u7d20\u8f6c\u5f55\u3002", "result": "\u65e0\u8bba\u662f\u96f6\u6837\u672c\u8fd8\u662f\u7ecf\u8fc7\u5fae\u8c03\u7684\u6a21\u578b\uff0c\u5728\u8bc6\u522b\u8bed\u97f3\u56fe\u50cf\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u90fd\u5f88\u5dee\uff0c\u5f88\u5c11\u8d85\u8fc7\u968f\u673a\u731c\u6d4b\u7684\u6c34\u5e73\u3002", "conclusion": "\u4ec5\u9760\u914d\u5bf9\u6837\u672c\u4e0d\u8db3\u4ee5\u8ba9VLMs\u6b63\u786e\u89e3\u8bfb\u8bed\u97f3\u56fe\u50cf\uff0c\u9700\u8981\u7279\u5b9a\u7684\u53c2\u6570\u77e5\u8bc6\u6765\u7406\u89e3\u8fd9\u4e9b\u8868\u793a\u5f62\u5f0f\u3002"}}
{"id": "2511.13226", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13226", "abs": "https://arxiv.org/abs/2511.13226", "authors": ["Michele Persiani", "Thomas Hellstrom"], "title": "Informative Communication of Robot Plans", "comment": "Conference: PAAMS 2022, 20th International Conference on Practical Applications of Agents and Multi-Agent Systems", "summary": "When a robot is asked to verbalize its plan it can do it in many ways. For example, a seemingly natural strategy is incremental, where the robot verbalizes its planned actions in plan order. However, an important aspect of this type of strategy is that it misses considerations on what is effectively informative to communicate, because not considering what the user knows prior to explanations. In this paper we propose a verbalization strategy to communicate robot plans informatively, by measuring the information gain that verbalizations have against a second-order theory of mind of the user capturing his prior knowledge on the robot. As shown in our experiments, this strategy allows to understand the robot's goal much quicker than by using strategies such as increasing or decreasing plan order. In addition, following our formulation we hint to what is informative and why when a robot communicates its plan.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u589e\u76ca\u7684\u673a\u5668\u4eba\u8ba1\u5212\u8bed\u8a00\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u8003\u8651\u7528\u6237\u5148\u9a8c\u77e5\u8bc6\u6765\u751f\u6210\u66f4\u5177\u4fe1\u606f\u91cf\u7684\u89e3\u91ca", "motivation": "\u73b0\u6709\u673a\u5668\u4eba\u8ba1\u5212\u8bed\u8a00\u5316\u7b56\u7565\uff08\u5982\u6309\u8ba1\u5212\u987a\u5e8f\u9012\u589e\u6216\u9012\u51cf\uff09\u672a\u5145\u5206\u8003\u8651\u7528\u6237\u5148\u9a8c\u77e5\u8bc6\uff0c\u5bfc\u81f4\u89e3\u91ca\u4e0d\u591f\u6709\u6548", "method": "\u4f7f\u7528\u4e8c\u9636\u5fc3\u667a\u7406\u8bba\u5efa\u6a21\u7528\u6237\u5148\u9a8c\u77e5\u8bc6\uff0c\u901a\u8fc7\u6d4b\u91cf\u8bed\u8a00\u5316\u5185\u5bb9\u76f8\u5bf9\u4e8e\u7528\u6237\u77e5\u8bc6\u7684\u4fe1\u606f\u589e\u76ca\u6765\u9009\u62e9\u6700\u6709\u6548\u7684\u89e3\u91ca\u7b56\u7565", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u7b56\u7565\u80fd\u8ba9\u7528\u6237\u66f4\u5feb\u7406\u89e3\u673a\u5668\u4eba\u76ee\u6807\uff0c\u4f18\u4e8e\u9012\u589e\u6216\u9012\u51cf\u8ba1\u5212\u987a\u5e8f\u7b49\u4f20\u7edf\u7b56\u7565", "conclusion": "\u673a\u5668\u4eba\u8ba1\u5212\u8bed\u8a00\u5316\u5e94\u8003\u8651\u7528\u6237\u5148\u9a8c\u77e5\u8bc6\uff0c\u4fe1\u606f\u589e\u76ca\u662f\u8861\u91cf\u89e3\u91ca\u6709\u6548\u6027\u7684\u91cd\u8981\u6307\u6807"}}
{"id": "2511.13254", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13254", "abs": "https://arxiv.org/abs/2511.13254", "authors": ["Shalini Maiti", "Amar Budhiraja", "Bhavul Gauri", "Gaurav Chaurasia", "Anton Protopopov", "Alexis Audran-Reiss", "Michael Slater", "Despoina Magka", "Tatiana Shavrina", "Roberta Raileanu", "Yoram Bachrach"], "title": "Souper-Model: How Simple Arithmetic Unlocks State-of-the-Art LLM Performance", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse domains, but their training remains resource- and time-intensive, requiring massive compute power and careful orchestration of training procedures. Model souping-the practice of averaging weights from multiple models of the same architecture-has emerged as a promising pre- and post-training technique that can enhance performance without expensive retraining. In this paper, we introduce Soup Of Category Experts (SoCE), a principled approach for model souping that utilizes benchmark composition to identify optimal model candidates and applies non-uniform weighted averaging to maximize performance. Contrary to previous uniform-averaging approaches, our method leverages the observation that benchmark categories often exhibit low inter-correlations in model performance. SoCE identifies \"expert\" models for each weakly-correlated category cluster and combines them using optimized weighted averaging rather than uniform weights. We demonstrate that the proposed method improves performance and robustness across multiple domains, including multilingual capabilities, tool calling, and math and achieves state-of-the-art results on the Berkeley Function Calling Leaderboard.", "AI": {"tldr": "SoCE\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u6a21\u578b\u878d\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u5404\u57fa\u51c6\u7c7b\u522b\u4e2d\u7684\u4e13\u5bb6\u6a21\u578b\uff0c\u5e76\u4f7f\u7528\u975e\u5747\u5300\u52a0\u6743\u5e73\u5747\u800c\u975e\u5747\u5300\u5e73\u5747\u6765\u6700\u5927\u5316\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u8d44\u6e90\u5bc6\u96c6\u4e14\u8017\u65f6\uff0c\u6a21\u578b\u878d\u5408\u4f5c\u4e3a\u4e00\u79cd\u65e0\u9700\u6602\u8d35\u91cd\u65b0\u8bad\u7ec3\u5c31\u80fd\u63d0\u5347\u6027\u80fd\u7684\u6280\u672f\u5907\u53d7\u5173\u6ce8\u3002\u4f20\u7edf\u5747\u5300\u5e73\u5747\u65b9\u6cd5\u672a\u5145\u5206\u5229\u7528\u4e0d\u540c\u57fa\u51c6\u7c7b\u522b\u95f4\u6a21\u578b\u6027\u80fd\u7684\u4f4e\u76f8\u5173\u6027\u3002", "method": "\u5229\u7528\u57fa\u51c6\u7ec4\u5408\u8bc6\u522b\u6700\u4f18\u6a21\u578b\u5019\u9009\uff0c\u4e3a\u6bcf\u4e2a\u5f31\u76f8\u5173\u7c7b\u522b\u7c07\u8bc6\u522b\u4e13\u5bb6\u6a21\u578b\uff0c\u5e94\u7528\u975e\u5747\u5300\u52a0\u6743\u5e73\u5747\u800c\u975e\u5747\u5300\u6743\u91cd\u8fdb\u884c\u6a21\u578b\u878d\u5408\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u9886\u57df\uff08\u5305\u62ec\u591a\u8bed\u8a00\u80fd\u529b\u3001\u5de5\u5177\u8c03\u7528\u548c\u6570\u5b66\uff09\u63d0\u9ad8\u4e86\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u5728\u4f2f\u514b\u5229\u51fd\u6570\u8c03\u7528\u6392\u884c\u699c\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "SoCE\u901a\u8fc7\u5229\u7528\u57fa\u51c6\u7c7b\u522b\u95f4\u7684\u4f4e\u76f8\u5173\u6027\uff0c\u91c7\u7528\u975e\u5747\u5300\u52a0\u6743\u5e73\u5747\u7684\u6a21\u578b\u878d\u5408\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u9884\u8bad\u7ec3\u548c\u540e\u8bad\u7ec3\u6280\u672f\u3002"}}
{"id": "2511.13288", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13288", "abs": "https://arxiv.org/abs/2511.13288", "authors": ["Haoyang Hong", "Jiajun Yin", "Yuan Wang", "Jingnan Liu", "Zhe Chen", "Ailing Yu", "Ji Li", "Zhiling Ye", "Hansong Xiao", "Yefei Chen", "Hualei Zhou", "Yun Yue", "Minghui Yang", "Chunxiao Guo", "Junwei Liu", "Peng Wei", "Jinjie Gu"], "title": "Multi-Agent Deep Research: Training Multi-Agent Systems with M-GRPO", "comment": null, "summary": "Multi-agent systems perform well on general reasoning tasks. However, the lack of training in specialized areas hinders their accuracy. Current training methods train a unified large language model (LLM) for all agents in the system. This may limit the performances due to different distributions underlying for different agents. Therefore, training multi-agent systems with distinct LLMs should be the next step to solve. However, this approach introduces optimization challenges. For example, agents operate at different frequencies, rollouts involve varying sub-agent invocations, and agents are often deployed across separate servers, disrupting end-to-end gradient flow. To address these issues, we propose M-GRPO, a hierarchical extension of Group Relative Policy Optimization designed for vertical Multi-agent systems with a main agent (planner) and multiple sub-agents (multi-turn tool executors). M-GRPO computes group-relative advantages for both main and sub-agents, maintaining hierarchical credit assignment. It also introduces a trajectory-alignment scheme that generates fixed-size batches despite variable sub-agent invocations. We deploy a decoupled training pipeline in which agents run on separate servers and exchange minimal statistics via a shared store. This enables scalable training without cross-server backpropagation. In experiments on real-world benchmarks (e.g., GAIA, XBench-DeepSearch, and WebWalkerQA), M-GRPO consistently outperforms both single-agent GRPO and multi-agent GRPO with frozen sub-agents, demonstrating improved stability and sample efficiency. These results show that aligning heterogeneous trajectories and decoupling optimization across specialized agents enhances tool-augmented reasoning tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86M-GRPO\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bad\u7ec3\u5177\u6709\u4e0d\u540cLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u4f18\u5316\u6311\u6218\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4f7f\u7528\u7edf\u4e00\u7684LLM\u8bad\u7ec3\uff0c\u4f46\u7531\u4e8e\u4e0d\u540c\u667a\u80fd\u4f53\u7684\u6570\u636e\u5206\u5e03\u4e0d\u540c\uff0c\u9650\u5236\u4e86\u6027\u80fd\u3002\u9700\u8981\u4e3a\u4e0d\u540c\u667a\u80fd\u4f53\u8bad\u7ec3\u4e0d\u540c\u7684LLM\uff0c\u4f46\u8fd9\u5e26\u6765\u4e86\u4f18\u5316\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86M-GRPO\u65b9\u6cd5\uff0c\u8fd9\u662fGroup Relative Policy Optimization\u7684\u5206\u5c42\u6269\u5c55\uff0c\u7528\u4e8e\u5177\u6709\u4e3b\u667a\u80fd\u4f53\uff08\u89c4\u5212\u5668\uff09\u548c\u591a\u4e2a\u5b50\u667a\u80fd\u4f53\uff08\u591a\u8f6e\u5de5\u5177\u6267\u884c\u5668\uff09\u7684\u5782\u76f4\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002\u8ba1\u7b97\u4e3b\u667a\u80fd\u4f53\u548c\u5b50\u667a\u80fd\u4f53\u7684\u7ec4\u76f8\u5bf9\u4f18\u52bf\uff0c\u4fdd\u6301\u5206\u5c42\u4fe1\u7528\u5206\u914d\uff0c\u5e76\u5f15\u5165\u8f68\u8ff9\u5bf9\u9f50\u65b9\u6848\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\uff08GAIA\u3001XBench-DeepSearch\u3001WebWalkerQA\uff09\u4e2d\uff0cM-GRPO\u6301\u7eed\u4f18\u4e8e\u5355\u667a\u80fd\u4f53GRPO\u548c\u5177\u6709\u51bb\u7ed3\u5b50\u667a\u80fd\u4f53\u7684\u591a\u667a\u80fd\u4f53GRPO\uff0c\u5c55\u793a\u4e86\u6539\u8fdb\u7684\u7a33\u5b9a\u6027\u548c\u6837\u672c\u6548\u7387\u3002", "conclusion": "\u5bf9\u9f50\u5f02\u6784\u8f68\u8ff9\u5e76\u5728\u4e13\u95e8\u667a\u80fd\u4f53\u4e4b\u95f4\u89e3\u8026\u4f18\u5316\u53ef\u4ee5\u589e\u5f3a\u5de5\u5177\u589e\u5f3a\u63a8\u7406\u4efb\u52a1\u3002"}}
{"id": "2511.13329", "categories": ["cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.13329", "abs": "https://arxiv.org/abs/2511.13329", "authors": ["Shufan Yang", "Zifeng Cheng", "Zhiwei Jiang", "Yafeng Yin", "Cong Wang", "Shiping Ge", "Yuchen Fu", "Qing Gu"], "title": "RegionMarker: A Region-Triggered Semantic Watermarking Framework for Embedding-as-a-Service Copyright Protection", "comment": "AAAI 2026", "summary": "Embedding-as-a-Service (EaaS) is an effective and convenient deployment solution for addressing various NLP tasks. Nevertheless, recent research has shown that EaaS is vulnerable to model extraction attacks, which could lead to significant economic losses for model providers. For copyright protection, existing methods inject watermark embeddings into text embeddings and use them to detect copyright infringement. However, current watermarking methods often resist only a subset of attacks and fail to provide \\textit{comprehensive} protection. To this end, we present the region-triggered semantic watermarking framework called RegionMarker, which defines trigger regions within a low-dimensional space and injects watermarks into text embeddings associated with these regions. By utilizing a secret dimensionality reduction matrix to project onto this subspace and randomly selecting trigger regions, RegionMarker makes it difficult for watermark removal attacks to evade detection. Furthermore, by embedding watermarks across the entire trigger region and using the text embedding as the watermark, RegionMarker is resilient to both paraphrasing and dimension-perturbation attacks. Extensive experiments on various datasets show that RegionMarker is effective in resisting different attack methods, thereby protecting the copyright of EaaS.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRegionMarker\u7684\u533a\u57df\u89e6\u53d1\u8bed\u4e49\u6c34\u5370\u6846\u67b6\uff0c\u901a\u8fc7\u5b9a\u4e49\u4f4e\u7ef4\u7a7a\u95f4\u4e2d\u7684\u89e6\u53d1\u533a\u57df\u6765\u4e3a\u6587\u672c\u5d4c\u5165\u6ce8\u5165\u6c34\u5370\uff0c\u63d0\u4f9b\u5168\u9762\u7684EaaS\u7248\u6743\u4fdd\u62a4\u3002", "motivation": "\u73b0\u6709\u7684EaaS\u6c34\u5370\u65b9\u6cd5\u53ea\u80fd\u62b5\u6297\u90e8\u5206\u653b\u51fb\uff0c\u65e0\u6cd5\u63d0\u4f9b\u5168\u9762\u4fdd\u62a4\uff0c\u5bfc\u81f4\u6a21\u578b\u63d0\u53d6\u653b\u51fb\u53ef\u80fd\u9020\u6210\u91cd\u5927\u7ecf\u6d4e\u635f\u5931\u3002", "method": "\u4f7f\u7528\u79d8\u5bc6\u964d\u7ef4\u77e9\u9635\u5c06\u6587\u672c\u5d4c\u5165\u6295\u5f71\u5230\u4f4e\u7ef4\u5b50\u7a7a\u95f4\uff0c\u968f\u673a\u9009\u62e9\u89e6\u53d1\u533a\u57df\uff0c\u5e76\u5728\u6574\u4e2a\u89e6\u53d1\u533a\u57df\u5d4c\u5165\u6c34\u5370\uff0c\u4f7f\u7528\u6587\u672c\u5d4c\u5165\u672c\u8eab\u4f5c\u4e3a\u6c34\u5370\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRegionMarker\u80fd\u6709\u6548\u62b5\u6297\u4e0d\u540c\u7c7b\u578b\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "conclusion": "RegionMarker\u6846\u67b6\u80fd\u591f\u5168\u9762\u4fdd\u62a4EaaS\u7684\u7248\u6743\uff0c\u62b5\u6297\u5404\u79cd\u6c34\u5370\u79fb\u9664\u653b\u51fb\u3002"}}
{"id": "2511.13290", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.13290", "abs": "https://arxiv.org/abs/2511.13290", "authors": ["Jea Kwon", "Luiz Felipe Vecchietti", "Sungwon Park", "Meeyoung Cha"], "title": "Dropouts in Confidence: Moral Uncertainty in Human-LLM Alignment", "comment": "Accepted to AAAI 2026", "summary": "Humans display significant uncertainty when confronted with moral dilemmas, yet the extent of such uncertainty in machines and AI agents remains underexplored. Recent studies have confirmed the overly confident tendencies of machine-generated responses, particularly in large language models (LLMs). As these systems are increasingly embedded in ethical decision-making scenarios, it is important to understand their moral reasoning and the inherent uncertainties in building reliable AI systems. This work examines how uncertainty influences moral decisions in the classical trolley problem, analyzing responses from 32 open-source models and 9 distinct moral dimensions. We first find that variance in model confidence is greater across models than within moral dimensions, suggesting that moral uncertainty is predominantly shaped by model architecture and training method. To quantify uncertainty, we measure binary entropy as a linear combination of total entropy, conditional entropy, and mutual information. To examine its effects, we introduce stochasticity into models via \"dropout\" at inference time. Our findings show that our mechanism increases total entropy, mainly through a rise in mutual information, while conditional entropy remains largely unchanged. Moreover, this mechanism significantly improves human-LLM moral alignment, with correlations in mutual information and alignment score shifts. Our results highlight the potential to better align model-generated decisions and human preferences by deliberately modulating uncertainty and reducing LLMs' confidence in morally complex scenarios.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86AI\u6a21\u578b\u5728\u9053\u5fb7\u56f0\u5883\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u53d1\u73b0\u5728\u7535\u8f66\u95ee\u9898\u4e2d\u6a21\u578b\u95f4\u7684\u4e0d\u786e\u5b9a\u6027\u5dee\u5f02\u5927\u4e8e\u9053\u5fb7\u7ef4\u5ea6\u95f4\u5dee\u5f02\uff0c\u901a\u8fc7\u5f15\u5165\u63a8\u7406\u65f6\u7684dropout\u673a\u5236\u589e\u52a0\u4e92\u4fe1\u606f\uff0c\u663e\u8457\u6539\u5584\u4e86\u4eba\u7c7b-LLM\u9053\u5fb7\u5bf9\u9f50\u3002", "motivation": "\u4eba\u7c7b\u5728\u9053\u5fb7\u56f0\u5883\u4e2d\u5b58\u5728\u663e\u8457\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46AI\u7cfb\u7edf\u5728\u9053\u5fb7\u51b3\u7b56\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u7814\u7a76\u4e0d\u8db3\u3002\u968f\u7740AI\u8d8a\u6765\u8d8a\u591a\u5730\u53c2\u4e0e\u4f26\u7406\u51b3\u7b56\uff0c\u7406\u89e3\u5176\u9053\u5fb7\u63a8\u7406\u548c\u4e0d\u786e\u5b9a\u6027\u5bf9\u4e8e\u6784\u5efa\u53ef\u9760\u7684AI\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5206\u679032\u4e2a\u5f00\u6e90\u6a21\u578b\u57289\u4e2a\u9053\u5fb7\u7ef4\u5ea6\u4e0a\u7684\u7535\u8f66\u95ee\u9898\u54cd\u5e94\uff1b\u4f7f\u7528\u4e8c\u5143\u71b5\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff1b\u901a\u8fc7\u63a8\u7406\u65f6\u5f15\u5165dropout\u673a\u5236\u589e\u52a0\u968f\u673a\u6027\uff1b\u6d4b\u91cf\u603b\u71b5\u3001\u6761\u4ef6\u71b5\u548c\u4e92\u4fe1\u606f\u7684\u53d8\u5316\u3002", "result": "\u6a21\u578b\u95f4\u7f6e\u4fe1\u5ea6\u65b9\u5dee\u5927\u4e8e\u9053\u5fb7\u7ef4\u5ea6\u95f4\u65b9\u5dee\uff1bdropout\u673a\u5236\u4e3b\u8981\u589e\u52a0\u4e86\u4e92\u4fe1\u606f\uff0c\u800c\u6761\u4ef6\u71b5\u57fa\u672c\u4e0d\u53d8\uff1b\u8be5\u673a\u5236\u663e\u8457\u63d0\u9ad8\u4e86\u4eba\u7c7b-LLM\u9053\u5fb7\u5bf9\u9f50\uff0c\u4e92\u4fe1\u606f\u4e0e\u5bf9\u9f50\u5206\u6570\u53d8\u5316\u5448\u6b63\u76f8\u5173\u3002", "conclusion": "\u901a\u8fc7\u6709\u610f\u8c03\u8282\u4e0d\u786e\u5b9a\u6027\u548c\u964d\u4f4eLLM\u5728\u9053\u5fb7\u590d\u6742\u573a\u666f\u4e2d\u7684\u7f6e\u4fe1\u5ea6\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u5bf9\u9f50\u6a21\u578b\u51b3\u7b56\u4e0e\u4eba\u7c7b\u504f\u597d\uff0c\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u7684\u9053\u5fb7AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2511.13335", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13335", "abs": "https://arxiv.org/abs/2511.13335", "authors": ["Maram Alharbi", "Salmane Chafik", "Saad Ezzini", "Ruslan Mitkov", "Tharindu Ranasinghe", "Hansi Hettiarachchi"], "title": "AHaSIS: Shared Task on Sentiment Analysis for Arabic Dialects", "comment": null, "summary": "The hospitality industry in the Arab world increasingly relies on customer feedback to shape services, driving the need for advanced Arabic sentiment analysis tools. To address this challenge, the Sentiment Analysis on Arabic Dialects in the Hospitality Domain shared task focuses on Sentiment Detection in Arabic Dialects. This task leverages a multi-dialect, manually curated dataset derived from hotel reviews originally written in Modern Standard Arabic (MSA) and translated into Saudi and Moroccan (Darija) dialects. The dataset consists of 538 sentiment-balanced reviews spanning positive, neutral, and negative categories. Translations were validated by native speakers to ensure dialectal accuracy and sentiment preservation. This resource supports the development of dialect-aware NLP systems for real-world applications in customer experience analysis. More than 40 teams have registered for the shared task, with 12 submitting systems during the evaluation phase. The top-performing system achieved an F1 score of 0.81, demonstrating the feasibility and ongoing challenges of sentiment analysis across Arabic dialects.", "AI": {"tldr": "\u963f\u62c9\u4f2f\u9152\u5e97\u8bc4\u8bba\u60c5\u611f\u5206\u6790\u5171\u4eab\u4efb\u52a1\uff0c\u4f7f\u7528\u591a\u65b9\u8a00\u6570\u636e\u96c6\uff08MSA\u3001\u6c99\u7279\u3001\u6469\u6d1b\u54e5\u65b9\u8a00\uff09\uff0c\u5305\u542b538\u6761\u5e73\u8861\u8bc4\u8bba\uff0c\u6700\u4f73\u7cfb\u7edfF1\u5f97\u52060.81\u3002", "motivation": "\u963f\u62c9\u4f2f\u4e16\u754c\u9152\u5e97\u4e1a\u4f9d\u8d56\u5ba2\u6237\u53cd\u9988\u6539\u8fdb\u670d\u52a1\uff0c\u9700\u8981\u5148\u8fdb\u7684\u963f\u62c9\u4f2f\u8bed\u60c5\u611f\u5206\u6790\u5de5\u5177\uff0c\u7279\u522b\u662f\u9488\u5bf9\u65b9\u8a00\u7684\u5206\u6790\u80fd\u529b\u3002", "method": "\u521b\u5efa\u591a\u65b9\u8a00\u6570\u636e\u96c6\uff0c\u5c06\u73b0\u4ee3\u6807\u51c6\u963f\u62c9\u4f2f\u8bed\u7684\u9152\u5e97\u8bc4\u8bba\u4eba\u5de5\u7ffb\u8bd1\u4e3a\u6c99\u7279\u548c\u6469\u6d1b\u54e5\u65b9\u8a00\uff0c\u5e76\u7531\u6bcd\u8bed\u8005\u9a8c\u8bc1\u7ffb\u8bd1\u51c6\u786e\u6027\u548c\u60c5\u611f\u4fdd\u7559\u3002", "result": "\u8d85\u8fc740\u4e2a\u56e2\u961f\u6ce8\u518c\uff0c12\u4e2a\u63d0\u4ea4\u7cfb\u7edf\uff0c\u6700\u4f73\u7cfb\u7edfF1\u5f97\u52060.81\uff0c\u8bc1\u660e\u4e86\u8de8\u963f\u62c9\u4f2f\u65b9\u8a00\u60c5\u611f\u5206\u6790\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u8d44\u6e90\u652f\u6301\u5f00\u53d1\u65b9\u8a00\u611f\u77e5\u7684NLP\u7cfb\u7edf\uff0c\u7528\u4e8e\u5ba2\u6237\u4f53\u9a8c\u5206\u6790\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u540c\u65f6\u663e\u793a\u4e86\u8de8\u65b9\u8a00\u60c5\u611f\u5206\u6790\u7684\u6301\u7eed\u6311\u6218\u3002"}}
{"id": "2511.13293", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13293", "abs": "https://arxiv.org/abs/2511.13293", "authors": ["Chuang Zhao", "Hui Tang", "Hongke Zhao", "Xiaofang Zhou", "Xiaomeng Li"], "title": "Grounded by Experience: Generative Healthcare Prediction Augmented with Hierarchical Agentic Retrieval", "comment": null, "summary": "Accurate healthcare prediction is critical for improving patient outcomes and reducing operational costs. Bolstered by growing reasoning capabilities, large language models (LLMs) offer a promising path to enhance healthcare predictions by drawing on their rich parametric knowledge. However, LLMs are prone to factual inaccuracies due to limitations in the reliability and coverage of their embedded knowledge. While retrieval-augmented generation (RAG) frameworks, such as GraphRAG and its variants, have been proposed to mitigate these issues by incorporating external knowledge, they face two key challenges in the healthcare scenario: (1) identifying the clinical necessity to activate the retrieval mechanism, and (2) achieving synergy between the retriever and the generator to craft contextually appropriate retrievals. To address these challenges, we propose GHAR, a \\underline{g}enerative \\underline{h}ierarchical \\underline{a}gentic \\underline{R}AG framework that simultaneously resolves when to retrieve and how to optimize the collaboration between submodules in healthcare. Specifically, for the first challenge, we design a dual-agent architecture comprising Agent-Top and Agent-Low. Agent-Top acts as the primary physician, iteratively deciding whether to rely on parametric knowledge or to initiate retrieval, while Agent-Low acts as the consulting service, summarising all task-relevant knowledge once retrieval was triggered. To tackle the second challenge, we innovatively unify the optimization of both agents within a formal Markov Decision Process, designing diverse rewards to align their shared goal of accurate prediction while preserving their distinct roles. Extensive experiments on three benchmark datasets across three popular tasks demonstrate our superiority over state-of-the-art baselines, highlighting the potential of hierarchical agentic RAG in advancing healthcare systems.", "AI": {"tldr": "GHAR\u662f\u4e00\u4e2a\u751f\u6210\u5f0f\u5206\u5c42\u4ee3\u7406RAG\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u4ee3\u7406\u67b6\u6784\u89e3\u51b3\u533b\u7597\u9884\u6d4b\u4e2d\u4f55\u65f6\u68c0\u7d22\u548c\u5982\u4f55\u4f18\u5316\u6a21\u5757\u534f\u4f5c\u7684\u95ee\u9898\uff0c\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u9884\u6d4b\u4e2d\u5b58\u5728\u4e8b\u5b9e\u4e0d\u51c6\u786e\u95ee\u9898\uff0c\u73b0\u6709\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a\u4f55\u65f6\u6fc0\u6d3b\u68c0\u7d22\u673a\u5236\u4ee5\u53ca\u5982\u4f55\u5b9e\u73b0\u68c0\u7d22\u5668\u548c\u751f\u6210\u5668\u7684\u534f\u540c\u4f18\u5316\u3002", "method": "\u63d0\u51faGHAR\u6846\u67b6\uff0c\u5305\u542bAgent-Top\uff08\u4e3b\u6cbb\u533b\u751f\u89d2\u8272\uff0c\u51b3\u5b9a\u662f\u5426\u68c0\u7d22\uff09\u548cAgent-Low\uff08\u54a8\u8be2\u670d\u52a1\u89d2\u8272\uff0c\u603b\u7ed3\u76f8\u5173\u77e5\u8bc6\uff09\uff0c\u5728\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7edf\u4e00\u4f18\u5316\u4e24\u4e2a\u4ee3\u7406\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548c\u4e09\u4e2a\u6d41\u884c\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u5206\u5c42\u4ee3\u7406RAG\u6846\u67b6\u5728\u63a8\u8fdb\u533b\u7597\u7cfb\u7edf\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2511.13368", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13368", "abs": "https://arxiv.org/abs/2511.13368", "authors": ["Kajetan Dymkiewicz", "Ivan Vulic", "Helen Yannakoudakis", "Eilam Shapira", "Roi Reichart", "Anna Korhonen"], "title": "Donors and Recipients: On Asymmetric Transfer Across Tasks and Languages with Parameter-Efficient Fine-Tuning", "comment": null, "summary": "Large language models (LLMs) perform strongly across tasks and languages, yet how improvements in one task or language affect other tasks and languages and their combinations remains poorly understood. We conduct a controlled PEFT/LoRA study across multiple open-weight LLM families and sizes, treating task and language as transfer axes while conditioning on model family and size; we fine-tune each model on a single task-language source and measure transfer as the percentage-point change versus its baseline score when evaluated on all other task-language target pairs. We decompose transfer into (i) Matched-Task (Cross-Language), (ii) Matched-Language (Cross-Task), and (iii) Cross-Task (Cross-Language) regimes. We uncover two consistent general patterns. First, a pronounced on-task vs. off-task asymmetry: Matched-Task (Cross-Language) transfer is reliably positive, whereas off-task transfer often incurs collateral degradation. Second, a stable donor-recipient structure across languages and tasks (hub donors vs. brittle recipients). We outline implications for risk-aware fine-tuning and model specialisation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7PEFT/LoRA\u65b9\u6cd5\u63a2\u7d22LLMs\u5728\u4efb\u52a1\u548c\u8bed\u8a00\u95f4\u7684\u8fc1\u79fb\u6a21\u5f0f\uff0c\u53d1\u73b0\u8de8\u8bed\u8a00\u4efb\u52a1\u8fc1\u79fb\u901a\u5e38\u6b63\u5411\uff0c\u800c\u8de8\u4efb\u52a1\u8fc1\u79fb\u5e38\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u63ed\u793a\u4e86\u7a33\u5b9a\u7684\u6350\u8d60\u8005-\u63a5\u6536\u8005\u7ed3\u6784\u3002", "motivation": "\u7406\u89e3LLMs\u5728\u4e00\u4e2a\u4efb\u52a1\u6216\u8bed\u8a00\u4e0a\u7684\u6539\u8fdb\u5982\u4f55\u5f71\u54cd\u5176\u4ed6\u4efb\u52a1\u548c\u8bed\u8a00\u53ca\u5176\u7ec4\u5408\uff0c\u76ee\u524d\u4ecd\u4e0d\u6e05\u695a\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u8fc1\u79fb\u6a21\u5f0f\u3002", "method": "\u91c7\u7528PEFT/LoRA\u65b9\u6cd5\u5728\u591a\u4e2a\u5f00\u6e90LLM\u5bb6\u65cf\u548c\u89c4\u6a21\u4e0a\u8fdb\u884c\u63a7\u5236\u7814\u7a76\uff0c\u5c06\u4efb\u52a1\u548c\u8bed\u8a00\u4f5c\u4e3a\u8fc1\u79fb\u8f74\uff0c\u5728\u5355\u4e00\u4efb\u52a1-\u8bed\u8a00\u6e90\u4e0a\u5fae\u8c03\u6a21\u578b\uff0c\u5e76\u8bc4\u4f30\u5728\u6240\u6709\u5176\u4ed6\u4efb\u52a1-\u8bed\u8a00\u76ee\u6807\u5bf9\u4e0a\u7684\u8fc1\u79fb\u6548\u679c\u3002", "result": "\u53d1\u73b0\u4e24\u4e2a\u4e00\u81f4\u6a21\u5f0f\uff1a1\uff09\u4efb\u52a1\u5185\u8de8\u8bed\u8a00\u8fc1\u79fb\u53ef\u9760\u6b63\u5411\uff0c\u800c\u8de8\u4efb\u52a1\u8fc1\u79fb\u5e38\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff1b2\uff09\u8de8\u8bed\u8a00\u548c\u4efb\u52a1\u5b58\u5728\u7a33\u5b9a\u7684\u6350\u8d60\u8005-\u63a5\u6536\u8005\u7ed3\u6784\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5bf9\u98ce\u9669\u611f\u77e5\u5fae\u8c03\u548c\u6a21\u578b\u4e13\u4e1a\u5316\u5177\u6709\u91cd\u8981\u542f\u793a\uff0c\u63ed\u793a\u4e86LLMs\u8fc1\u79fb\u5b66\u4e60\u4e2d\u7684\u7cfb\u7edf\u6027\u6a21\u5f0f\u3002"}}
{"id": "2511.13306", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.13306", "abs": "https://arxiv.org/abs/2511.13306", "authors": ["Bowen Ye", "Bin Zhang", "Hang Zhao"], "title": "DAP: A Discrete-token Autoregressive Planner for Autonomous Driving", "comment": null, "summary": "Gaining sustainable performance improvement with scaling data and model budget remains a pivotal yet unresolved challenge in autonomous driving. While autoregressive models exhibited promising data-scaling efficiency in planning tasks, predicting ego trajectories alone suffers sparse supervision and weakly constrains how scene evolution should shape ego motion. Therefore, we introduce DAP, a discrete-token autoregressive planner that jointly forecasts BEV semantics and ego trajectories, thereby enforcing comprehensive representation learning and allowing predicted dynamics to directly condition ego motion. In addition, we incorporate a reinforcement-learning-based fine-tuning, which preserves supervised behavior cloning priors while injecting reward-guided improvements. Despite a compact 160M parameter budget, DAP achieves state-of-the-art performance on open-loop metrics and delivers competitive closed-loop results on the NAVSIM benchmark. Overall, the fully discrete-token autoregressive formulation operating on both rasterized BEV and ego actions provides a compact yet scalable planning paradigm for autonomous driving.", "AI": {"tldr": "DAP\u662f\u4e00\u4e2a\u79bb\u6563token\u81ea\u56de\u5f52\u89c4\u5212\u5668\uff0c\u901a\u8fc7\u8054\u5408\u9884\u6d4bBEV\u8bed\u4e49\u548c\u81ea\u8f66\u8f68\u8ff9\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\uff0c\u5728160M\u53c2\u6570\u4e0b\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u81ea\u52a8\u9a7e\u9a76\u89c4\u5212\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u4e2d\u6570\u636e\u548c\u6a21\u578b\u89c4\u6a21\u6269\u5c55\u65f6\u53ef\u6301\u7eed\u6027\u80fd\u63d0\u5347\u7684\u6311\u6218\u3002\u4ec5\u9884\u6d4b\u81ea\u8f66\u8f68\u8ff9\u5b58\u5728\u76d1\u7763\u7a00\u758f\u4e14\u5bf9\u573a\u666f\u6f14\u5316\u7ea6\u675f\u5f31\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u79bb\u6563token\u81ea\u56de\u5f52\u89c4\u5212\u5668\uff0c\u8054\u5408\u9884\u6d4bBEV\u8bed\u4e49\u548c\u81ea\u8f66\u8f68\u8ff9\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u76d1\u7763\u884c\u4e3a\u514b\u9686\u5148\u9a8c\u7684\u540c\u65f6\u6ce8\u5165\u5956\u52b1\u5f15\u5bfc\u7684\u6539\u8fdb\u3002", "result": "\u5728160M\u53c2\u6570\u9884\u7b97\u4e0b\uff0c\u5728\u5f00\u73af\u6307\u6807\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728NAVSIM\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u4f9b\u6709\u7ade\u4e89\u529b\u7684\u95ed\u73af\u7ed3\u679c\u3002", "conclusion": "\u5b8c\u5168\u79bb\u6563token\u81ea\u56de\u5f52\u516c\u5f0f\u5728\u6805\u683c\u5316BEV\u548c\u81ea\u8f66\u52a8\u4f5c\u4e0a\u64cd\u4f5c\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7d27\u51d1\u4e14\u53ef\u6269\u5c55\u7684\u89c4\u5212\u8303\u5f0f\u3002"}}
{"id": "2511.13381", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13381", "abs": "https://arxiv.org/abs/2511.13381", "authors": ["Siyu Zhu", "Mouxiao Bian", "Yue Xie", "Yongyu Tang", "Zhikang Yu", "Tianbin Li", "Pengcheng Chen", "Bing Han", "Jie Xu", "Xiaoyan Dong"], "title": "Can Large Language Models Function as Qualified Pediatricians? A Systematic Evaluation in Real-World Clinical Contexts", "comment": null, "summary": "With the rapid rise of large language models (LLMs) in medicine, a key question is whether they can function as competent pediatricians in real-world clinical settings. We developed PEDIASBench, a systematic evaluation framework centered on a knowledge-system framework and tailored to realistic clinical environments. PEDIASBench assesses LLMs across three dimensions: application of basic knowledge, dynamic diagnosis and treatment capability, and pediatric medical safety and medical ethics. We evaluated 12 representative models released over the past two years, including GPT-4o, Qwen3-235B-A22B, and DeepSeek-V3, covering 19 pediatric subspecialties and 211 prototypical diseases. State-of-the-art models performed well on foundational knowledge, with Qwen3-235B-A22B achieving over 90% accuracy on licensing-level questions, but performance declined ~15% as task complexity increased, revealing limitations in complex reasoning. Multiple-choice assessments highlighted weaknesses in integrative reasoning and knowledge recall. In dynamic diagnosis and treatment scenarios, DeepSeek-R1 scored highest in case reasoning (mean 0.58), yet most models struggled to adapt to real-time patient changes. On pediatric medical ethics and safety tasks, Qwen2.5-72B performed best (accuracy 92.05%), though humanistic sensitivity remained limited. These findings indicate that pediatric LLMs are constrained by limited dynamic decision-making and underdeveloped humanistic care. Future development should focus on multimodal integration and a clinical feedback-model iteration loop to enhance safety, interpretability, and human-AI collaboration. While current LLMs cannot independently perform pediatric care, they hold promise for decision support, medical education, and patient communication, laying the groundwork for a safe, trustworthy, and collaborative intelligent pediatric healthcare system.", "AI": {"tldr": "PEDIASBench\u8bc4\u4f30\u6846\u67b6\u8bc4\u4f30\u4e8612\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u513f\u79d1\u533b\u7597\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6700\u5148\u8fdb\u6a21\u578b\u5728\u57fa\u7840\u77e5\u8bc6\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u590d\u6742\u63a8\u7406\u3001\u52a8\u6001\u8bca\u7597\u548c\u4eba\u6587\u5173\u6000\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u76ee\u524d\u5c1a\u4e0d\u80fd\u72ec\u7acb\u8fdb\u884c\u513f\u79d1\u8bca\u7597\uff0c\u4f46\u5728\u51b3\u7b56\u652f\u6301\u7b49\u65b9\u9762\u6709\u6f5c\u529b\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u9886\u57df\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u9700\u8981\u8bc4\u4f30\u5b83\u4eec\u662f\u5426\u80fd\u5728\u771f\u5b9e\u4e34\u5e8a\u73af\u5883\u4e2d\u80dc\u4efb\u513f\u79d1\u533b\u751f\u7684\u5de5\u4f5c\u3002", "method": "\u5f00\u53d1\u4e86PEDIASBench\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\uff0c\u4ece\u57fa\u7840\u77e5\u8bc6\u5e94\u7528\u3001\u52a8\u6001\u8bca\u7597\u80fd\u529b\u3001\u533b\u7597\u5b89\u5168\u4e0e\u4f26\u7406\u4e09\u4e2a\u7ef4\u5ea6\u8bc4\u4f3012\u4e2a\u4ee3\u8868\u6027\u6a21\u578b\uff0c\u6db5\u76d619\u4e2a\u513f\u79d1\u4e9a\u4e13\u79d1\u548c211\u79cd\u5178\u578b\u75be\u75c5\u3002", "result": "\u6700\u5148\u8fdb\u6a21\u578b\u5728\u57fa\u7840\u77e5\u8bc6\u65b9\u9762\u8868\u73b0\u826f\u597d\uff08Qwen3-235B-A22B\u5728\u6267\u7167\u7ea7\u95ee\u9898\u4e0a\u51c6\u786e\u7387\u8d8590%\uff09\uff0c\u4f46\u968f\u7740\u4efb\u52a1\u590d\u6742\u5ea6\u589e\u52a0\u6027\u80fd\u4e0b\u964d\u7ea615%\uff1b\u5728\u52a8\u6001\u8bca\u7597\u573a\u666f\u4e2d\uff0cDeepSeek-R1\u5728\u75c5\u4f8b\u63a8\u7406\u4e2d\u5f97\u5206\u6700\u9ad8\uff08\u5747\u503c0.58\uff09\uff0c\u4f46\u591a\u6570\u6a21\u578b\u96be\u4ee5\u9002\u5e94\u5b9e\u65f6\u60a3\u8005\u53d8\u5316\uff1b\u5728\u533b\u7597\u4f26\u7406\u5b89\u5168\u4efb\u52a1\u4e2d\uff0cQwen2.5-72B\u8868\u73b0\u6700\u4f73\uff08\u51c6\u786e\u738792.05%\uff09\uff0c\u4f46\u4eba\u6587\u654f\u611f\u6027\u4ecd\u6709\u9650\u3002", "conclusion": "\u5f53\u524d\u513f\u79d1LLMs\u53d7\u9650\u4e8e\u6709\u9650\u7684\u52a8\u6001\u51b3\u7b56\u80fd\u529b\u548c\u4e0d\u6210\u719f\u7684\u4eba\u6587\u5173\u6000\uff0c\u672a\u6765\u5e94\u5173\u6ce8\u591a\u6a21\u6001\u6574\u5408\u548c\u4e34\u5e8a\u53cd\u9988-\u6a21\u578b\u8fed\u4ee3\u5faa\u73af\uff0c\u4ee5\u589e\u5f3a\u5b89\u5168\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u4eba\u673a\u534f\u4f5c\u3002\u867d\u7136\u5f53\u524dLLMs\u4e0d\u80fd\u72ec\u7acb\u8fdb\u884c\u513f\u79d1\u8bca\u7597\uff0c\u4f46\u5728\u51b3\u7b56\u652f\u6301\u3001\u533b\u5b66\u6559\u80b2\u548c\u60a3\u8005\u6c9f\u901a\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2511.13359", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13359", "abs": "https://arxiv.org/abs/2511.13359", "authors": ["Yuhang Wang", "Yanxu Zhu", "Jitao Sang"], "title": "Reasoning Shapes Alignment: Investigating Cultural Alignment in Large Reasoning Models with Cultural Norms", "comment": null, "summary": "The advanced reasoning capabilities of Large Reasoning Models enable them to thoroughly understand and apply safety policies through deliberate thought processes, thereby improving the models' safety. Beyond safety, these models must also be able to reflect the diverse range of human values across various cultures. This paper presents the Cultural Norm-based Cultural Alignment (CNCA) framework, which enables models to leverage their powerful reasoning ability to align with cultural norms. Specifically, we propose three methods to automatically mine cultural norms from limited survey data and explore ways to effectively utilize these norms for improving cultural alignment. Two alignment paradigms are examined: an in-context alignment method, where cultural norms are explicitly integrated into the user context, and a fine-tuning-based method, which internalizes norms through enhanced Chain-of-Thought training data. Comprehensive experiments demonstrate the effectiveness of these methods, highlighting that models with stronger reasoning capabilities benefit more from cultural norm mining and utilization. Our findings emphasize the potential for reasoning models to better reflect diverse human values through culturally informed alignment strategies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u6587\u5316\u89c4\u8303\u6587\u5316\u5bf9\u9f50(CNCA)\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u5b9e\u73b0\u6587\u5316\u5bf9\u9f50\uff0c\u5305\u62ec\u4ece\u6709\u9650\u8c03\u67e5\u6570\u636e\u81ea\u52a8\u6316\u6398\u6587\u5316\u89c4\u8303\u7684\u4e09\u79cd\u65b9\u6cd5\uff0c\u4ee5\u53ca\u4e24\u79cd\u5bf9\u9f50\u8303\u5f0f\uff1a\u4e0a\u4e0b\u6587\u5bf9\u9f50\u548c\u57fa\u4e8e\u5fae\u8c03\u7684\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u4e0d\u4ec5\u9700\u8981\u7406\u89e3\u5b89\u5168\u653f\u7b56\uff0c\u8fd8\u9700\u8981\u53cd\u6620\u4e0d\u540c\u6587\u5316\u80cc\u666f\u4e0b\u7684\u4eba\u7c7b\u4ef7\u503c\u89c2\u591a\u6837\u6027\uff0c\u5b9e\u73b0\u6587\u5316\u5bf9\u9f50\u3002", "method": "\u63d0\u51faCNCA\u6846\u67b6\uff0c\u5305\u542b\u4e09\u79cd\u81ea\u52a8\u6316\u6398\u6587\u5316\u89c4\u8303\u7684\u65b9\u6cd5\uff0c\u4ee5\u53ca\u4e24\u79cd\u5bf9\u9f50\u8303\u5f0f\uff1a\u4e0a\u4e0b\u6587\u5bf9\u9f50\uff08\u5c06\u6587\u5316\u89c4\u8303\u663e\u5f0f\u6574\u5408\u5230\u7528\u6237\u4e0a\u4e0b\u6587\uff09\u548c\u57fa\u4e8e\u5fae\u8c03\u7684\u65b9\u6cd5\uff08\u901a\u8fc7\u589e\u5f3a\u7684\u601d\u7ef4\u94fe\u8bad\u7ec3\u6570\u636e\u5185\u5316\u89c4\u8303\uff09\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8bc1\u660e\u8fd9\u4e9b\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u63a8\u7406\u80fd\u529b\u66f4\u5f3a\u7684\u6a21\u578b\u4ece\u6587\u5316\u89c4\u8303\u6316\u6398\u548c\u5229\u7528\u4e2d\u83b7\u76ca\u66f4\u591a\u3002", "conclusion": "\u63a8\u7406\u6a21\u578b\u901a\u8fc7\u6587\u5316\u4fe1\u606f\u5bf9\u9f50\u7b56\u7565\u6709\u6f5c\u529b\u66f4\u597d\u5730\u53cd\u6620\u591a\u6837\u5316\u7684\u4eba\u7c7b\u4ef7\u503c\u89c2\u3002"}}
{"id": "2511.13410", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13410", "abs": "https://arxiv.org/abs/2511.13410", "authors": ["Zhaopei Huang", "Qifeng Dai", "Guozheng Wu", "Xiaopeng Wu", "Kehan Chen", "Chuan Yu", "Xubin Li", "Tiezheng Ge", "Wenxuan Wang", "Qin Jin"], "title": "Mem-PAL: Towards Memory-based Personalized Dialogue Assistants for Long-term User-Agent Interaction", "comment": "Accepted by AAAI 2026 (Oral)", "summary": "With the rise of smart personal devices, service-oriented human-agent interactions have become increasingly prevalent. This trend highlights the need for personalized dialogue assistants that can understand user-specific traits to accurately interpret requirements and tailor responses to individual preferences. However, existing approaches often overlook the complexities of long-term interactions and fail to capture users' subjective characteristics. To address these gaps, we present PAL-Bench, a new benchmark designed to evaluate the personalization capabilities of service-oriented assistants in long-term user-agent interactions. In the absence of available real-world data, we develop a multi-step LLM-based synthesis pipeline, which is further verified and refined by human annotators. This process yields PAL-Set, the first Chinese dataset comprising multi-session user logs and dialogue histories, which serves as the foundation for PAL-Bench. Furthermore, to improve personalized service-oriented interactions, we propose H$^2$Memory, a hierarchical and heterogeneous memory framework that incorporates retrieval-augmented generation to improve personalized response generation. Comprehensive experiments on both our PAL-Bench and an external dataset demonstrate the effectiveness of the proposed memory framework.", "AI": {"tldr": "\u63d0\u51fa\u4e86PAL-Bench\u57fa\u51c6\u548cH\u00b2Memory\u8bb0\u5fc6\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u8fdb\u9762\u5411\u670d\u52a1\u7684\u4e2a\u6027\u5316\u5bf9\u8bdd\u52a9\u624b\u5728\u957f\u671f\u4ea4\u4e92\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u4e2a\u4eba\u8bbe\u5907\u7684\u666e\u53ca\uff0c\u9700\u8981\u80fd\u591f\u7406\u89e3\u7528\u6237\u7279\u5b9a\u7279\u5f81\u7684\u4e2a\u6027\u5316\u5bf9\u8bdd\u52a9\u624b\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u5ffd\u89c6\u957f\u671f\u4ea4\u4e92\u7684\u590d\u6742\u6027\uff0c\u672a\u80fd\u6355\u6349\u7528\u6237\u7684\u4e3b\u89c2\u7279\u5f81\u3002", "method": "\u5f00\u53d1\u4e86\u591a\u6b65\u9aa4\u7684LLM\u5408\u6210\u6d41\u7a0b\u751f\u6210PAL-Set\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51faH\u00b2Memory\u5c42\u6b21\u5f02\u6784\u8bb0\u5fc6\u6846\u67b6\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6765\u6539\u8fdb\u4e2a\u6027\u5316\u54cd\u5e94\u751f\u6210\u3002", "result": "\u5728PAL-Bench\u548c\u5916\u90e8\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u8bb0\u5fc6\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "PAL-Bench\u662f\u9996\u4e2a\u4e2d\u6587\u591a\u4f1a\u8bdd\u7528\u6237\u65e5\u5fd7\u6570\u636e\u96c6\uff0cH\u00b2Memory\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u9762\u5411\u670d\u52a1\u7684\u4e2a\u6027\u5316\u4ea4\u4e92\u80fd\u529b\u3002"}}
{"id": "2511.13361", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.13361", "abs": "https://arxiv.org/abs/2511.13361", "authors": ["Jiyang Zheng", "Islam Nassar", "Thanh Vu", "Xu Zhong", "Yang Lin", "Tongliang Liu", "Long Duong", "Yuan-Fang Li"], "title": "MedDCR: Learning to Design Agentic Workflows for Medical Coding", "comment": null, "summary": "Medical coding converts free-text clinical notes into standardized diagnostic and procedural codes, which are essential for billing, hospital operations, and medical research. Unlike ordinary text classification, it requires multi-step reasoning: extracting diagnostic concepts, applying guideline constraints, mapping to hierarchical codebooks, and ensuring cross-document consistency. Recent advances leverage agentic LLMs, but most rely on rigid, manually crafted workflows that fail to capture the nuance and variability of real-world documentation, leaving open the question of how to systematically learn effective workflows. We present MedDCR, a closed-loop framework that treats workflow design as a learning problem. A Designer proposes workflows, a Coder executes them, and a Reflector evaluates predictions and provides constructive feedback, while a memory archive preserves prior designs for reuse and iterative refinement. On benchmark datasets, MedDCR outperforms state-of-the-art baselines and produces interpretable, adaptable workflows that better reflect real coding practice, improving both the reliability and trustworthiness of automated systems.", "AI": {"tldr": "MedDCR\u662f\u4e00\u4e2a\u7528\u4e8e\u533b\u7597\u7f16\u7801\u7684\u95ed\u73af\u6846\u67b6\uff0c\u5c06\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u89c6\u4e3a\u5b66\u4e60\u95ee\u9898\uff0c\u901a\u8fc7\u8bbe\u8ba1\u5668\u3001\u7f16\u7801\u5668\u548c\u53cd\u5c04\u5668\u7684\u534f\u4f5c\uff0c\u7ed3\u5408\u8bb0\u5fc6\u5b58\u6863\uff0c\u5b9e\u73b0\u5de5\u4f5c\u6d41\u7684\u8fed\u4ee3\u4f18\u5316\u3002", "motivation": "\u4f20\u7edf\u533b\u7597\u7f16\u7801\u65b9\u6cd5\u4f9d\u8d56\u624b\u52a8\u8bbe\u8ba1\u7684\u5de5\u4f5c\u6d41\uff0c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u4e16\u754c\u6587\u6863\u7684\u7ec6\u5fae\u5dee\u522b\u548c\u53d8\u5f02\u6027\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u5b66\u4e60\u6709\u6548\u5de5\u4f5c\u6d41\u3002", "method": "\u91c7\u7528\u95ed\u73af\u6846\u67b6\uff1a\u8bbe\u8ba1\u5668\u63d0\u51fa\u5de5\u4f5c\u6d41\uff0c\u7f16\u7801\u5668\u6267\u884c\uff0c\u53cd\u5c04\u5668\u8bc4\u4f30\u9884\u6d4b\u5e76\u63d0\u4f9b\u53cd\u9988\uff0c\u8bb0\u5fc6\u5b58\u6863\u4fdd\u5b58\u5148\u524d\u8bbe\u8ba1\u4ee5\u4f9b\u91cd\u7528\u548c\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cMedDCR\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4ea7\u751f\u53ef\u89e3\u91ca\u3001\u9002\u5e94\u6027\u5f3a\u7684\u7684\u5de5\u4f5c\u6d41\uff0c\u66f4\u597d\u5730\u53cd\u6620\u5b9e\u9645\u7f16\u7801\u5b9e\u8df5\u3002", "conclusion": "MedDCR\u63d0\u9ad8\u4e86\u81ea\u52a8\u5316\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u4e3a\u533b\u7597\u7f16\u7801\u5de5\u4f5c\u6d41\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.13467", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13467", "abs": "https://arxiv.org/abs/2511.13467", "authors": ["Serge Gladkoff", "Lifeng Han", "Katerina Gasova"], "title": "Non-Linear Scoring Model for Translation Quality Evaluation", "comment": "ongoing work, 38 pages", "summary": "Analytic Translation Quality Evaluation (TQE), based on Multidimensional Quality Metrics (MQM), traditionally uses a linear error-to-penalty scale calibrated to a reference sample of 1000-2000 words. However, linear extrapolation biases judgment on samples of different sizes, over-penalizing short samples and under-penalizing long ones, producing misalignment with expert intuition.\n  Building on the Multi-Range framework, this paper presents a calibrated, non-linear scoring model that better reflects how human content consumers perceive translation quality across samples of varying length. Empirical data from three large-scale enterprise environments shows that acceptable error counts grow logarithmically, not linearly, with sample size.\n  Psychophysical and cognitive evidence, including the Weber-Fechner law and Cognitive Load Theory, supports this premise by explaining why the perceptual impact of additional errors diminishes while the cognitive burden grows with scale. We propose a two-parameter model\n  E(x) = a * ln(1 + b * x), a, b > 0,\n  anchored to a reference tolerance and calibrated from two tolerance points using a one-dimensional root-finding step. The model yields an explicit interval within which the linear approximation stays within +/-20 percent relative error and integrates into existing evaluation workflows with only a dynamic tolerance function added.\n  The approach improves interpretability, fairness, and inter-rater reliability across both human and AI-generated translations. By operationalizing a perceptually valid scoring paradigm, it advances translation quality evaluation toward more accurate and scalable assessment. The model also provides a stronger basis for AI-based document-level evaluation aligned with human judgment. Implementation considerations for CAT/LQA systems and implications for human and AI-generated text evaluation are discussed.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u6570\u51fd\u6570\u7684\u975e\u7ebf\u6027\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u7ebf\u6027\u8bc4\u4f30\u65b9\u6cd5\u5728\u4e0d\u540c\u6587\u672c\u957f\u5ea6\u4e0b\u7684\u504f\u5dee\u95ee\u9898\uff0c\u4f7f\u8bc4\u4f30\u7ed3\u679c\u66f4\u7b26\u5408\u4eba\u7c7b\u611f\u77e5\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8eMQM\u7684\u7ebf\u6027\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\u5728\u4e0d\u540c\u6587\u672c\u957f\u5ea6\u4e0b\u5b58\u5728\u504f\u5dee\uff0c\u5bf9\u77ed\u6587\u672c\u8fc7\u5ea6\u60e9\u7f5a\uff0c\u5bf9\u957f\u6587\u672c\u60e9\u7f5a\u4e0d\u8db3\uff0c\u4e0e\u4e13\u5bb6\u76f4\u89c9\u4e0d\u4e00\u81f4\u3002", "method": "\u6784\u5efa\u4e86\u53cc\u53c2\u6570\u5bf9\u6570\u6a21\u578bE(x) = a * ln(1 + b * x)\uff0c\u57fa\u4e8e\u97e6\u4f2f-\u8d39\u5e0c\u7eb3\u5b9a\u5f8b\u548c\u8ba4\u77e5\u8d1f\u8377\u7406\u8bba\uff0c\u901a\u8fc7\u4e00\u7ef4\u6839\u67e5\u627e\u6b65\u9aa4\u4ece\u4e24\u4e2a\u5bb9\u5fcd\u70b9\u8fdb\u884c\u6821\u51c6\u3002", "result": "\u5b9e\u8bc1\u6570\u636e\u663e\u793a\u53ef\u63a5\u53d7\u9519\u8bef\u6570\u91cf\u968f\u6837\u672c\u5927\u5c0f\u5448\u5bf9\u6570\u589e\u957f\u800c\u975e\u7ebf\u6027\u589e\u957f\uff0c\u8be5\u6a21\u578b\u63d0\u9ad8\u4e86\u8bc4\u4f30\u7684\u53ef\u89e3\u91ca\u6027\u3001\u516c\u5e73\u6027\u548c\u8bc4\u5206\u8005\u95f4\u4fe1\u5ea6\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u3001\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u8303\u5f0f\uff0c\u4e3a\u57fa\u4e8eAI\u7684\u6587\u6863\u7ea7\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u57fa\u7840\uff0c\u5e76\u4e0e\u4eba\u7c7b\u5224\u65ad\u4fdd\u6301\u4e00\u81f4\u3002"}}
{"id": "2511.13371", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13371", "abs": "https://arxiv.org/abs/2511.13371", "authors": ["Caroline Baumgartner", "Eleanor Spens", "Neil Burgess", "Petru Manescu"], "title": "Cognitive Maps in Language Models: A Mechanistic Analysis of Spatial Planning", "comment": null, "summary": "How do large language models solve spatial navigation tasks? We investigate this by training GPT-2 models on three spatial learning paradigms in grid environments: passive exploration (Foraging Model- predicting steps in random walks), goal-directed planning (generating optimal shortest paths) on structured Hamiltonian paths (SP-Hamiltonian), and a hybrid model fine-tuned with exploratory data (SP-Random Walk). Using behavioural, representational and mechanistic analyses, we uncover two fundamentally different learned algorithms. The Foraging model develops a robust, map-like representation of space, akin to a 'cognitive map'. Causal interventions reveal that it learns to consolidate spatial information into a self-sufficient coordinate system, evidenced by a sharp phase transition where its reliance on historical direction tokens vanishes by the middle layers of the network. The model also adopts an adaptive, hierarchical reasoning system, switching between a low-level heuristic for short contexts and map-based inference for longer ones. In contrast, the goal-directed models learn a path-dependent algorithm, remaining reliant on explicit directional inputs throughout all layers. The hybrid model, despite demonstrating improved generalisation over its parent, retains the same path-dependent strategy. These findings suggest that the nature of spatial intelligence in transformers may lie on a spectrum, ranging from generalisable world models shaped by exploratory data to heuristics optimised for goal-directed tasks. We provide a mechanistic account of this generalisation-optimisation trade-off and highlight how the choice of training regime influences the strategies that emerge.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u8bad\u7ec3GPT-2\u6a21\u578b\u5728\u4e09\u79cd\u7a7a\u95f4\u5b66\u4e60\u8303\u5f0f\u4e0b\uff0c\u53d1\u73b0\u4e86\u4e24\u79cd\u6839\u672c\u4e0d\u540c\u7684\u5b66\u4e60\u7b97\u6cd5\uff1a\u63a2\u7d22\u6a21\u578b\u53d1\u5c55\u51fa\u7c7b\u4f3c\u8ba4\u77e5\u5730\u56fe\u7684\u7a7a\u95f4\u8868\u793a\uff0c\u800c\u76ee\u6807\u5bfc\u5411\u6a21\u578b\u5b66\u4e60\u8def\u5f84\u4f9d\u8d56\u7b97\u6cd5\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u89e3\u51b3\u7a7a\u95f4\u5bfc\u822a\u4efb\u52a1\uff0c\u63a2\u7d22\u4e0d\u540c\u8bad\u7ec3\u8303\u5f0f\u5bf9\u6a21\u578b\u5b66\u4e60\u7b56\u7565\u7684\u5f71\u54cd\u3002", "method": "\u5728\u7f51\u683c\u73af\u5883\u4e2d\u8bad\u7ec3GPT-2\u6a21\u578b\uff0c\u91c7\u7528\u4e09\u79cd\u7a7a\u95f4\u5b66\u4e60\u8303\u5f0f\uff1a\u88ab\u52a8\u63a2\u7d22\uff08\u968f\u673a\u6e38\u8d70\u9884\u6d4b\uff09\u3001\u76ee\u6807\u5bfc\u5411\u89c4\u5212\uff08\u751f\u6210\u6700\u4f18\u6700\u77ed\u8def\u5f84\uff09\u548c\u6df7\u5408\u6a21\u578b\uff08\u5728\u63a2\u7d22\u6570\u636e\u4e0a\u5fae\u8c03\uff09\u3002", "result": "\u63a2\u7d22\u6a21\u578b\u53d1\u5c55\u51fa\u9c81\u68d2\u7684\u5730\u56fe\u5f0f\u7a7a\u95f4\u8868\u793a\uff0c\u5f62\u6210\u81ea\u8db3\u5750\u6807\u7cfb\uff0c\u5e76\u5728\u7f51\u7edc\u4e2d\u5c42\u5b9e\u73b0\u4ece\u5386\u53f2\u65b9\u5411\u4f9d\u8d56\u5230\u5730\u56fe\u63a8\u7406\u7684\u8f6c\u53d8\uff1b\u76ee\u6807\u5bfc\u5411\u6a21\u578b\u4fdd\u6301\u8def\u5f84\u4f9d\u8d56\u7b56\u7565\uff1b\u6df7\u5408\u6a21\u578b\u867d\u6539\u5584\u6cdb\u5316\u4f46\u4ecd\u4fdd\u6301\u8def\u5f84\u4f9d\u8d56\u3002", "conclusion": "Transformer\u4e2d\u7684\u7a7a\u95f4\u667a\u80fd\u5b58\u5728\u4e00\u4e2a\u8c31\u7cfb\uff0c\u4ece\u63a2\u7d22\u6570\u636e\u5851\u9020\u7684\u53ef\u6cdb\u5316\u4e16\u754c\u6a21\u578b\u5230\u76ee\u6807\u5bfc\u5411\u4efb\u52a1\u4f18\u5316\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u8bad\u7ec3\u5236\u5ea6\u7684\u9009\u62e9\u5f71\u54cd\u7b56\u7565\u6d8c\u73b0\u3002"}}
{"id": "2511.13481", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13481", "abs": "https://arxiv.org/abs/2511.13481", "authors": ["Attapol T. Rutherford", "Sirisak Chueykamhang", "Thachaparn Bunditlurdruk", "Nanthicha Angsuwichitkul"], "title": "Aspect-Level Obfuscated Sentiment in Thai Financial Disclosures and Its Impact on Abnormal Returns", "comment": null, "summary": "Understanding sentiment in financial documents is crucial for gaining insights into market behavior. These reports often contain obfuscated language designed to present a positive or neutral outlook, even when underlying conditions may be less favorable. This paper presents a novel approach using Aspect-Based Sentiment Analysis (ABSA) to decode obfuscated sentiment in Thai financial annual reports. We develop specific guidelines for annotating obfuscated sentiment in these texts and annotate more than one hundred financial reports. We then benchmark various text classification models on this annotated dataset, demonstrating strong performance in sentiment classification. Additionally, we conduct an event study to evaluate the real-world implications of our sentiment analysis on stock prices. Our results suggest that market reactions are selectively influenced by specific aspects within the reports. Our findings underscore the complexity of sentiment analysis in financial texts and highlight the importance of addressing obfuscated language to accurately assess market sentiment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65b9\u9762\u7684\u60c5\u611f\u5206\u6790\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u7801\u6cf0\u56fd\u8d22\u52a1\u5e74\u62a5\u4e2d\u7684\u6a21\u7cca\u60c5\u611f\uff0c\u5e76\u901a\u8fc7\u4e8b\u4ef6\u7814\u7a76\u9a8c\u8bc1\u5176\u5bf9\u80a1\u4ef7\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "motivation": "\u8d22\u52a1\u6587\u4ef6\u4e2d\u7684\u60c5\u611f\u7406\u89e3\u5bf9\u6d1e\u5bdf\u5e02\u573a\u884c\u4e3a\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8fd9\u4e9b\u62a5\u544a\u5e38\u4f7f\u7528\u6a21\u7cca\u8bed\u8a00\u6765\u5448\u73b0\u79ef\u6781\u6216\u4e2d\u6027\u524d\u666f\uff0c\u5373\u4f7f\u5b9e\u9645\u6761\u4ef6\u53ef\u80fd\u4e0d\u592a\u6709\u5229\u3002", "method": "\u5f00\u53d1\u4e86\u6807\u6ce8\u6a21\u7cca\u60c5\u611f\u7684\u5177\u4f53\u6307\u5357\uff0c\u6807\u6ce8\u4e86100\u591a\u4efd\u8d22\u52a1\u62a5\u544a\uff0c\u5e76\u5bf9\u5404\u79cd\u6587\u672c\u5206\u7c7b\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u540c\u65f6\u8fdb\u884c\u4e8b\u4ef6\u7814\u7a76\u8bc4\u4f30\u5bf9\u80a1\u4ef7\u7684\u5f71\u54cd\u3002", "result": "\u5728\u60c5\u611f\u5206\u7c7b\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e02\u573a\u53cd\u5e94\u53d7\u5230\u62a5\u544a\u4e2d\u7279\u5b9a\u65b9\u9762\u7684\u9009\u62e9\u6027\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u8d22\u52a1\u6587\u672c\u60c5\u611f\u5206\u6790\u7684\u590d\u6742\u6027\uff0c\u4ee5\u53ca\u89e3\u51b3\u6a21\u7cca\u8bed\u8a00\u5bf9\u51c6\u786e\u8bc4\u4f30\u5e02\u573a\u60c5\u611f\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.13411", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13411", "abs": "https://arxiv.org/abs/2511.13411", "authors": ["Przemyslaw Chojecki"], "title": "An Operational Kardashev-Style Scale for Autonomous AI - Towards AGI and Superintelligence", "comment": null, "summary": "We propose a Kardashev-inspired yet operational Autonomous AI (AAI) Scale that measures the progression from fixed robotic process automation (AAI-0) to full artificial general intelligence (AAI-4) and beyond. Unlike narrative ladders, our scale is multi-axis and testable. We define ten capability axes (Autonomy, Generality, Planning, Memory/Persistence, Tool Economy, Self-Revision, Sociality/Coordination, Embodiment, World-Model Fidelity, Economic Throughput) aggregated by a composite AAI-Index (a weighted geometric mean). We introduce a measurable Self-Improvement Coefficient $\u03ba$ (capability growth per unit of agent-initiated resources) and two closure properties (maintenance and expansion) that convert ``self-improving AI'' into falsifiable criteria. We specify OWA-Bench, an open-world agency benchmark suite that evaluates long-horizon, tool-using, persistent agents. We define level gates for AAI-0\\ldots AAI-4 using thresholds on the axes, $\u03ba$, and closure proofs. Synthetic experiments illustrate how present-day systems map onto the scale and how the delegability frontier (quality vs.\\ autonomy) advances with self-improvement. We also prove a theorem that AAI-3 agent becomes AAI-5 over time with sufficient conditions, formalizing \"baby AGI\" becomes Superintelligence intuition.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eKardashev\u542f\u53d1\u7684\u81ea\u4e3bAI\uff08AAI\uff09\u5206\u7ea7\u6807\u51c6\uff0c\u4ece\u56fa\u5b9a\u673a\u5668\u4eba\u6d41\u7a0b\u81ea\u52a8\u5316\uff08AAI-0\uff09\u5230\u5b8c\u5168\u4eba\u5de5\u901a\u7528\u667a\u80fd\uff08AAI-4\uff09\u53ca\u66f4\u9ad8\u5c42\u7ea7\u3002\u8be5\u6807\u51c6\u662f\u591a\u7ef4\u5ea6\u4e14\u53ef\u6d4b\u8bd5\u7684\uff0c\u5305\u542b10\u4e2a\u80fd\u529b\u8f74\u548c\u7efc\u5408AAI\u6307\u6570\u3002", "motivation": "\u73b0\u6709AI\u5206\u7ea7\u591a\u4e3a\u53d9\u4e8b\u6027\u63cf\u8ff0\uff0c\u7f3a\u4e4f\u53ef\u64cd\u4f5c\u7684\u6d4b\u8bd5\u6807\u51c6\u3002\u9700\u8981\u5efa\u7acb\u53ef\u91cf\u5316\u3001\u53ef\u9a8c\u8bc1\u7684\u81ea\u4e3bAI\u53d1\u5c55\u8861\u91cf\u4f53\u7cfb\uff0c\u5c06\"\u81ea\u6211\u6539\u8fdbAI\"\u8f6c\u5316\u4e3a\u53ef\u8bc1\u4f2a\u7684\u6807\u51c6\u3002", "method": "\u5b9a\u4e4910\u4e2a\u80fd\u529b\u8f74\uff08\u81ea\u4e3b\u6027\u3001\u901a\u7528\u6027\u3001\u89c4\u5212\u3001\u8bb0\u5fc6/\u6301\u4e45\u6027\u3001\u5de5\u5177\u7ecf\u6d4e\u3001\u81ea\u6211\u4fee\u8ba2\u3001\u793e\u4ea4/\u534f\u8c03\u3001\u5177\u8eab\u5316\u3001\u4e16\u754c\u6a21\u578b\u4fdd\u771f\u5ea6\u3001\u7ecf\u6d4e\u541e\u5410\u91cf\uff09\uff0c\u901a\u8fc7\u52a0\u6743\u51e0\u4f55\u5e73\u5747\u8ba1\u7b97AAI\u6307\u6570\u3002\u5f15\u5165\u53ef\u6d4b\u91cf\u7684\u81ea\u6211\u6539\u8fdb\u7cfb\u6570\u03ba\u548c\u4e24\u4e2a\u95ed\u5408\u5c5e\u6027\uff08\u7ef4\u62a4\u548c\u6269\u5c55\uff09\u3002", "result": "\u5f00\u53d1\u4e86OWA-Bench\u5f00\u653e\u4e16\u754c\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u7528\u4e8e\u8bc4\u4f30\u957f\u671f\u3001\u5de5\u5177\u4f7f\u7528\u3001\u6301\u4e45\u6027\u667a\u80fd\u4f53\u3002\u901a\u8fc7\u5408\u6210\u5b9e\u9a8c\u5c55\u793a\u4e86\u5f53\u524d\u7cfb\u7edf\u5728\u5206\u7ea7\u4e2d\u7684\u6620\u5c04\u4f4d\u7f6e\u3002", "conclusion": "\u8be5\u5206\u7ea7\u6807\u51c6\u4e3aAI\u53d1\u5c55\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u8861\u91cf\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u5728\u5145\u5206\u6761\u4ef6\u4e0bAAI-3\u667a\u80fd\u4f53\u53ef\u968f\u65f6\u95f4\u53d1\u5c55\u4e3aAAI-5\u8d85\u7ea7\u667a\u80fd\uff0c\u5f62\u5f0f\u5316\u4e86\"\u5a74\u513fAGI\"\u6210\u4e3a\u8d85\u7ea7\u667a\u80fd\u7684\u76f4\u89c9\u3002"}}
{"id": "2511.13505", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13505", "abs": "https://arxiv.org/abs/2511.13505", "authors": ["Elinor Poole-Dayan", "Daniel T Kessler", "Hannah Chiou", "Margaret Hughes", "Emily S Lin", "Marshall Ganz", "Deb Roy"], "title": "Applying Large Language Models to Characterize Public Narratives", "comment": null, "summary": "Public Narratives (PNs) are key tools for leadership development and civic mobilization, yet their systematic analysis remains challenging due to their subjective interpretation and the high cost of expert annotation. In this work, we propose a novel computational framework that leverages large language models (LLMs) to automate the qualitative annotation of public narratives. Using a codebook we co-developed with subject-matter experts, we evaluate LLM performance against that of expert annotators. Our work reveals that LLMs can achieve near-human-expert performance, achieving an average F1 score of 0.80 across 8 narratives and 14 codes. We then extend our analysis to empirically explore how PN framework elements manifest across a larger dataset of 22 stories. Lastly, we extrapolate our analysis to a set of political speeches, establishing a novel lens in which to analyze political rhetoric in civic spaces. This study demonstrates the potential of LLM-assisted annotation for scalable narrative analysis and highlights key limitations and directions for future research in computational civic storytelling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u6807\u6ce8\u516c\u5171\u53d9\u4e8b\u7684\u65b0\u8ba1\u7b97\u6846\u67b6\uff0c\u5728\u4e13\u5bb6\u6807\u6ce8\u57fa\u7840\u4e0a\u8bc4\u4f30LLM\u6027\u80fd\uff0c\u53d1\u73b0\u53ef\u4ee5\u8fbe\u5230\u63a5\u8fd1\u4eba\u7c7b\u4e13\u5bb6\u7684\u6c34\u5e73\uff0c\u5e76\u6269\u5c55\u5230\u5206\u6790\u653f\u6cbb\u6f14\u8bb2\u3002", "motivation": "\u516c\u5171\u53d9\u4e8b\u662f\u9886\u5bfc\u529b\u53d1\u5c55\u548c\u516c\u6c11\u52a8\u5458\u7684\u91cd\u8981\u5de5\u5177\uff0c\u4f46\u7531\u4e8e\u4e3b\u89c2\u89e3\u91ca\u6027\u548c\u4e13\u5bb6\u6807\u6ce8\u6210\u672c\u9ad8\uff0c\u5176\u7cfb\u7edf\u6027\u5206\u6790\u9762\u4e34\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86\u4e0e\u9886\u57df\u4e13\u5bb6\u5171\u540c\u5236\u5b9a\u7684\u7f16\u7801\u624b\u518c\uff0c\u4f7f\u7528LLMs\u81ea\u52a8\u8fdb\u884c\u516c\u5171\u53d9\u4e8b\u7684\u5b9a\u6027\u6807\u6ce8\uff0c\u5e76\u4e0e\u4e13\u5bb6\u6807\u6ce8\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83\u3002", "result": "LLMs\u57288\u4e2a\u53d9\u4e8b\u548c14\u4e2a\u4ee3\u7801\u4e0a\u5e73\u5747F1\u5f97\u5206\u8fbe\u52300.80\uff0c\u63a5\u8fd1\u4eba\u7c7b\u4e13\u5bb6\u6c34\u5e73\uff1b\u8fdb\u4e00\u6b65\u6269\u5c55\u523022\u4e2a\u6545\u4e8b\u548c\u4e00\u7ec4\u653f\u6cbb\u6f14\u8bb2\u7684\u5206\u6790\u3002", "conclusion": "\u7814\u7a76\u5c55\u793a\u4e86LLM\u8f85\u52a9\u6807\u6ce8\u5728\u53ef\u6269\u5c55\u53d9\u4e8b\u5206\u6790\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u8ba1\u7b97\u516c\u6c11\u53d9\u4e8b\u7814\u7a76\u7684\u5c40\u9650\u6027\u548c\u672a\u6765\u65b9\u5411\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2511.13476", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13476", "abs": "https://arxiv.org/abs/2511.13476", "authors": ["Zhipeng Ma", "Ali Rida Bahja", "Andreas Burgdorf", "Andr\u00e9 Pomp", "Tobias Meisen", "Bo N\u00f8rregaard J\u00f8rgensen", "Zheng Grace Ma"], "title": "Multi-Agent Multimodal Large Language Model Framework for Automated Interpretation of Fuel Efficiency Analytics in Public Transportation", "comment": null, "summary": "Enhancing fuel efficiency in public transportation requires the integration of complex multimodal data into interpretable, decision-relevant insights. However, traditional analytics and visualization methods often yield fragmented outputs that demand extensive human interpretation, limiting scalability and consistency. This study presents a multi-agent framework that leverages multimodal large language models (LLMs) to automate data narration and energy insight generation. The framework coordinates three specialized agents, including a data narration agent, an LLM-as-a-judge agent, and an optional human-in-the-loop evaluator, to iteratively transform analytical artifacts into coherent, stakeholder-oriented reports. The system is validated through a real-world case study on public bus transportation in Northern Jutland, Denmark, where fuel efficiency data from 4006 trips are analyzed using Gaussian Mixture Model clustering. Comparative experiments across five state-of-the-art LLMs and three prompting paradigms identify GPT-4.1 mini with Chain-of-Thought prompting as the optimal configuration, achieving 97.3% narrative accuracy while balancing interpretability and computational cost. The findings demonstrate that multi-agent orchestration significantly enhances factual precision, coherence, and scalability in LLM-based reporting. The proposed framework establishes a replicable and domain-adaptive methodology for AI-driven narrative generation and decision support in energy informatics.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u6570\u636e\u53d9\u8ff0\u548c\u80fd\u6e90\u6d1e\u5bdf\uff0c\u901a\u8fc7\u4e09\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53\u7684\u534f\u8c03\u5de5\u4f5c\u5c06\u5206\u6790\u7ed3\u679c\u8f6c\u5316\u4e3a\u9762\u5411\u5229\u76ca\u76f8\u5173\u8005\u7684\u8fde\u8d2f\u62a5\u544a\u3002", "motivation": "\u4f20\u7edf\u5206\u6790\u548c\u53ef\u89c6\u5316\u65b9\u6cd5\u4ea7\u751f\u788e\u7247\u5316\u8f93\u51fa\uff0c\u9700\u8981\u5927\u91cf\u4eba\u5de5\u89e3\u8bfb\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u4e00\u81f4\u6027\u3002\u9700\u8981\u81ea\u52a8\u5316\u6570\u636e\u53d9\u8ff0\u548c\u80fd\u6e90\u6d1e\u5bdf\u751f\u6210\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u62ec\u6570\u636e\u53d9\u8ff0\u667a\u80fd\u4f53\u3001LLM\u4f5c\u4e3a\u8bc4\u5224\u667a\u80fd\u4f53\u548c\u53ef\u9009\u7684\u4eba\u7c7b\u8bc4\u4f30\u8005\uff0c\u4f7f\u7528\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u805a\u7c7b\u5206\u67904006\u6b21\u516c\u4ea4\u884c\u7a0b\u7684\u71c3\u6cb9\u6548\u7387\u6570\u636e\u3002", "result": "GPT-4.1 mini\u4e0e\u601d\u7ef4\u94fe\u63d0\u793a\u7684\u7ec4\u5408\u8fbe\u523097.3%\u7684\u53d9\u8ff0\u51c6\u786e\u6027\uff0c\u5728\u53ef\u89e3\u91ca\u6027\u548c\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u591a\u667a\u80fd\u4f53\u7f16\u6392\u663e\u8457\u63d0\u9ad8\u4e86\u57fa\u4e8eLLM\u62a5\u544a\u7684\u4e8b\u5b9e\u7cbe\u786e\u6027\u3001\u8fde\u8d2f\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u80fd\u6e90\u4fe1\u606f\u5b66\u4e2d\u7684AI\u9a71\u52a8\u53d9\u4e8b\u751f\u6210\u548c\u51b3\u7b56\u652f\u6301\u5efa\u7acb\u4e86\u53ef\u590d\u5236\u4e14\u9886\u57df\u81ea\u9002\u5e94\u7684\u65b9\u6cd5\u8bba\u3002"}}
{"id": "2511.13529", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2511.13529", "abs": "https://arxiv.org/abs/2511.13529", "authors": ["M\u00e1t\u00e9 Gedeon", "Piroska Zs\u00f3fia Barta", "P\u00e9ter Mihajlik", "Tekla Etelka Gr\u00e1czi", "Anna Koh\u00e1ri", "Katalin M\u00e1dy"], "title": "Toward Conversational Hungarian Speech Recognition: Introducing the BEA-Large and BEA-Dialogue Datasets", "comment": "Submitted to LREC 2026", "summary": "The advancement of automatic speech recognition (ASR) has been largely enhanced by extensive datasets in high-resource languages, while languages such as Hungarian remain underrepresented due to limited spontaneous and conversational corpora. To address this gap, we introduce two new datasets -- BEA-Large and BEA-Dialogue -- constructed from the previously unprocessed portions of the Hungarian speech corpus named BEA. BEA-Large extends BEA-Base with 255 hours of spontaneous speech from 433 speakers, enriched with detailed segment-level metadata. BEA-Dialogue, comprising 85 hours of spontaneous conversations, is a Hungarian speech corpus featuring natural dialogues partitioned into speaker-independent subsets, supporting research in conversational ASR and speaker diarization. We establish reproducible baselines on these datasets using publicly available ASR models, with the fine-tuned Fast Conformer model achieving word error rates as low as 14.18\\% on spontaneous and 4.8\\% on repeated speech. Diarization experiments yield diarization error rates between 13.05\\% and 18.26\\%, providing reference points for future improvements. The results highlight the persistent difficulty of conversational ASR, particularly due to disfluencies, overlaps, and informal speech patterns. By releasing these datasets and baselines, we aim to advance Hungarian speech technology and offer a methodological framework for developing spontaneous and conversational benchmarks in other languages.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3a\u5308\u7259\u5229\u8bed\u5f15\u5165\u4e86\u4e24\u4e2a\u65b0\u7684\u8bed\u97f3\u6570\u636e\u96c6BEA-Large\u548cBEA-Dialogue\uff0c\u4ee5\u89e3\u51b3\u5308\u7259\u5229\u8bed\u5728\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u7814\u7a76\u4e2d\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5e76\u5efa\u7acb\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u9ad8\u8d44\u6e90\u8bed\u8a00\u5728\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5308\u7259\u5229\u8bed\u7b49\u8bed\u8a00\u7531\u4e8e\u7f3a\u4e4f\u81ea\u53d1\u8a00\u8bed\u548c\u5bf9\u8bdd\u8bed\u6599\u5e93\u800c\u4ee3\u8868\u6027\u4e0d\u8db3\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u4ece\u5308\u7259\u5229\u8bed\u97f3\u8bed\u6599\u5e93BEA\u4e2d\u6784\u5efa\u4e86\u4e24\u4e2a\u65b0\u6570\u636e\u96c6\uff1aBEA-Large\uff08255\u5c0f\u65f6\u81ea\u53d1\u8a00\u8bed\uff09\u548cBEA-Dialogue\uff0885\u5c0f\u65f6\u81ea\u7136\u5bf9\u8bdd\uff09\uff0c\u5e76\u4f7f\u7528\u516c\u5f00\u53ef\u7528\u7684ASR\u6a21\u578b\u5efa\u7acb\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u7ebf\u3002", "result": "\u5fae\u8c03\u540e\u7684Fast Conformer\u6a21\u578b\u5728\u81ea\u53d1\u8a00\u8bed\u4e0a\u5b9e\u73b0\u4e8614.18%\u7684\u8bcd\u9519\u8bef\u7387\uff0c\u5728\u91cd\u590d\u8bed\u97f3\u4e0a\u5b9e\u73b0\u4e864.8%\u7684\u8bcd\u9519\u8bef\u7387\u3002\u8bf4\u8bdd\u4eba\u65e5\u5fd7\u5b9e\u9a8c\u7684\u9519\u8bef\u7387\u572813.05%\u523018.26%\u4e4b\u95f4\u3002", "conclusion": "\u5bf9\u8bddASR\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u7279\u522b\u662f\u7531\u4e8e\u4e0d\u6d41\u7545\u3001\u91cd\u53e0\u548c\u975e\u6b63\u5f0f\u8bed\u97f3\u6a21\u5f0f\u3002\u901a\u8fc7\u53d1\u5e03\u8fd9\u4e9b\u6570\u636e\u96c6\u548c\u57fa\u7ebf\uff0c\u65e8\u5728\u63a8\u8fdb\u5308\u7259\u5229\u8bed\u97f3\u6280\u672f\uff0c\u5e76\u4e3a\u5176\u4ed6\u8bed\u8a00\u5f00\u53d1\u81ea\u53d1\u8a00\u8bed\u548c\u5bf9\u8bdd\u57fa\u51c6\u63d0\u4f9b\u65b9\u6cd5\u6846\u67b6\u3002"}}
{"id": "2511.13524", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.13524", "abs": "https://arxiv.org/abs/2511.13524", "authors": ["Yuhang Peng", "Yizhou Pan", "Xinning He", "Jihaoyu Yang", "Xinyu Yin", "Han Wang", "Xiaoji Zheng", "Chao Gao", "Jiangtao Gong"], "title": "FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI", "comment": "9 pages, 4 figures", "summary": "As embodied intelligence emerges as a core frontier in artificial intelligence research, simulation platforms must evolve beyond low-level physical interactions to capture complex, human-centered social behaviors. We introduce FreeAskWorld, an interactive simulation framework that integrates large language models (LLMs) for high-level behavior planning and semantically grounded interaction, informed by theories of intention and social cognition. Our framework supports scalable, realistic human-agent simulations and includes a modular data generation pipeline tailored for diverse embodied tasks.To validate the framework, we extend the classic Vision-and-Language Navigation (VLN) task into a interaction enriched Direction Inquiry setting, wherein agents can actively seek and interpret navigational guidance. We present and publicly release FreeAskWorld, a large-scale benchmark dataset comprising reconstructed environments, six diverse task types, 16 core object categories, 63,429 annotated sample frames, and more than 17 hours of interaction data to support training and evaluation of embodied AI systems. We benchmark VLN models, and human participants under both open-loop and closed-loop settings. Experimental results demonstrate that models fine-tuned on FreeAskWorld outperform their original counterparts, achieving enhanced semantic understanding and interaction competency. These findings underscore the efficacy of socially grounded simulation frameworks in advancing embodied AI systems toward sophisticated high-level planning and more naturalistic human-agent interaction. Importantly, our work underscores that interaction itself serves as an additional information modality.", "AI": {"tldr": "FreeAskWorld\u662f\u4e00\u4e2a\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ea4\u4e92\u5f0f\u4eff\u771f\u6846\u67b6\uff0c\u652f\u6301\u53ef\u6269\u5c55\u7684\u4eba\u7c7b-\u667a\u80fd\u4f53\u4eff\u771f\uff0c\u5e76\u5305\u542b\u9488\u5bf9\u591a\u6837\u5316\u5177\u8eab\u4efb\u52a1\u7684\u6570\u636e\u751f\u6210\u7ba1\u9053\u3002", "motivation": "\u968f\u7740\u5177\u8eab\u667a\u80fd\u6210\u4e3a\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u7684\u6838\u5fc3\u524d\u6cbf\uff0c\u4eff\u771f\u5e73\u53f0\u9700\u8981\u4ece\u4f4e\u5c42\u6b21\u7269\u7406\u4ea4\u4e92\u6269\u5c55\u5230\u80fd\u6355\u6349\u590d\u6742\u3001\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u793e\u4f1a\u884c\u4e3a\u3002", "method": "\u5c06\u7ecf\u5178\u89c6\u89c9\u8bed\u8a00\u5bfc\u822a\u4efb\u52a1\u6269\u5c55\u4e3a\u4ea4\u4e92\u4e30\u5bcc\u7684\u65b9\u5411\u8be2\u95ee\u8bbe\u7f6e\uff0c\u667a\u80fd\u4f53\u53ef\u4ee5\u4e3b\u52a8\u5bfb\u6c42\u548c\u89e3\u91ca\u5bfc\u822a\u6307\u5bfc\u3002\u6846\u67b6\u5305\u542b\u91cd\u5efa\u73af\u5883\u30016\u79cd\u4efb\u52a1\u7c7b\u578b\u300116\u4e2a\u6838\u5fc3\u5bf9\u8c61\u7c7b\u522b\u300163,429\u4e2a\u6807\u6ce8\u6837\u672c\u5e27\u548c\u8d85\u8fc717\u5c0f\u65f6\u7684\u4ea4\u4e92\u6570\u636e\u3002", "result": "\u5728FreeAskWorld\u4e0a\u5fae\u8c03\u7684\u6a21\u578b\u4f18\u4e8e\u539f\u59cb\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u589e\u5f3a\u7684\u8bed\u4e49\u7406\u89e3\u548c\u4ea4\u4e92\u80fd\u529b\u3002\u5728\u5f00\u73af\u548c\u95ed\u73af\u8bbe\u7f6e\u4e0b\u5bf9VLN\u6a21\u578b\u548c\u4eba\u7c7b\u53c2\u4e0e\u8005\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "\u57fa\u4e8e\u793e\u4f1a\u8ba4\u77e5\u7684\u4eff\u771f\u6846\u67b6\u80fd\u6709\u6548\u63a8\u8fdb\u5177\u8eabAI\u7cfb\u7edf\u5411\u590d\u6742\u9ad8\u5c42\u6b21\u89c4\u5212\u548c\u66f4\u81ea\u7136\u7684\u4eba\u673a\u4ea4\u4e92\u53d1\u5c55\uff0c\u4ea4\u4e92\u672c\u8eab\u4f5c\u4e3a\u4e00\u79cd\u989d\u5916\u7684\u4fe1\u606f\u6a21\u6001\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.13590", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13590", "abs": "https://arxiv.org/abs/2511.13590", "authors": ["Hao Wang", "Yuanfeng Song", "Xiaoming Yin", "Xing Chen"], "title": "Beyond SELECT: A Comprehensive Taxonomy-Guided Benchmark for Real-World Text-to-SQL Translation", "comment": null, "summary": "Text-to-SQL datasets are essential for training and evaluating text-to-SQL models, but existing datasets often suffer from limited coverage and fail to capture the diversity of real-world applications. To address this, we propose a novel taxonomy for text-to-SQL classification based on dimensions including core intents, statement types, syntax structures, and key actions. Using this taxonomy, we evaluate widely used public text-to-SQL datasets (e.g., Spider and Bird) and reveal limitations in their coverage and diversity. We then introduce a taxonomy-guided dataset synthesis pipeline, yielding a new dataset named SQL-Synth. This approach combines the taxonomy with Large Language Models (LLMs) to ensure the dataset reflects the breadth and complexity of real-world text-to-SQL applications. Extensive analysis and experimental results validate the effectiveness of our taxonomy, as SQL-Synth exhibits greater diversity and coverage compared to existing benchmarks. Moreover, we uncover that existing LLMs typically fall short in adequately capturing the full range of scenarios, resulting in limited performance on SQL-Synth. However, fine-tuning can substantially improve their performance in these scenarios. The proposed taxonomy has significant potential impact, as it not only enables comprehensive analysis of datasets and the performance of different LLMs, but also guides the construction of training data for LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6838\u5fc3\u610f\u56fe\u3001\u8bed\u53e5\u7c7b\u578b\u3001\u8bed\u6cd5\u7ed3\u6784\u548c\u5173\u952e\u64cd\u4f5c\u7684\u6587\u672c\u5230SQL\u5206\u7c7b\u65b0\u5206\u7c7b\u6cd5\uff0c\u5e76\u57fa\u4e8e\u6b64\u521b\u5efa\u4e86SQL-Synth\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u6bd4\u73b0\u6709\u57fa\u51c6\u5177\u6709\u66f4\u597d\u7684\u591a\u6837\u6027\u548c\u8986\u76d6\u8303\u56f4\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u5230SQL\u6570\u636e\u96c6\u8986\u76d6\u8303\u56f4\u6709\u9650\uff0c\u672a\u80fd\u6355\u6349\u771f\u5b9e\u5e94\u7528\u7684\u591a\u6837\u6027\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u5206\u7c7b\u65b9\u6cd5\u548c\u6570\u636e\u96c6\u6765\u8bc4\u4f30\u548c\u6539\u8fdb\u6a21\u578b\u6027\u80fd\u3002", "method": "\u5f00\u53d1\u4e86\u6587\u672c\u5230SQL\u5206\u7c7b\u6cd5\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u4e86\u5206\u7c7b\u6cd5\u6307\u5bfc\u7684\u6570\u636e\u96c6\u5408\u6210\u7ba1\u9053\uff0c\u751f\u6210\u4e86SQL-Synth\u6570\u636e\u96c6\u3002", "result": "SQL-Synth\u6570\u636e\u96c6\u5728\u591a\u6837\u6027\u548c\u8986\u76d6\u8303\u56f4\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\uff0c\u73b0\u6709LLMs\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u6709\u9650\uff0c\u4f46\u5fae\u8c03\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u5206\u7c7b\u6cd5\u5177\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4e0d\u4ec5\u80fd\u5168\u9762\u5206\u6790\u6570\u636e\u96c6\u548cLLMs\u6027\u80fd\uff0c\u8fd8\u80fd\u6307\u5bfcLLMs\u8bad\u7ec3\u6570\u636e\u7684\u6784\u5efa\u3002"}}
{"id": "2511.13526", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13526", "abs": "https://arxiv.org/abs/2511.13526", "authors": ["Zhengda Wang", "Daqian Shi", "Jingyi Zhao", "Xiaolei Diao", "Xiongfeng Tang", "Yanguo Qin"], "title": "Automated Construction of Medical Indicator Knowledge Graphs Using Retrieval Augmented Large Language Models", "comment": "5 pages, 1 figure, 1 table. Accepted at AI4RWC@WI-IAT 2025", "summary": "Artificial intelligence (AI) is reshaping modern healthcare by advancing disease diagnosis, treatment decision-making, and biomedical research. Among AI technologies, large language models (LLMs) have become especially impactful, enabling deep knowledge extraction and semantic reasoning from complex medical texts. However, effective clinical decision support requires knowledge in structured, interoperable formats. Knowledge graphs serve this role by integrating heterogeneous medical information into semantically consistent networks. Yet, current clinical knowledge graphs still depend heavily on manual curation and rule-based extraction, which is limited by the complexity and contextual ambiguity of medical guidelines and literature. To overcome these challenges, we propose an automated framework that combines retrieval-augmented generation (RAG) with LLMs to construct medical indicator knowledge graphs. The framework incorporates guideline-driven data acquisition, ontology-based schema design, and expert-in-the-loop validation to ensure scalability, accuracy, and clinical reliability. The resulting knowledge graphs can be integrated into intelligent diagnosis and question-answering systems, accelerating the development of AI-driven healthcare solutions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u548c\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u7684\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u533b\u7597\u6307\u6807\u77e5\u8bc6\u56fe\u8c31\uff0c\u4ee5\u89e3\u51b3\u5f53\u524d\u4e34\u5e8a\u77e5\u8bc6\u56fe\u8c31\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u548c\u89c4\u5219\u63d0\u53d6\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5f53\u524d\u4e34\u5e8a\u77e5\u8bc6\u56fe\u8c31\u4e3b\u8981\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u63d0\u53d6\u65b9\u6cd5\uff0c\u53d7\u9650\u4e8e\u533b\u5b66\u6307\u5357\u548c\u6587\u732e\u7684\u590d\u6742\u6027\u548c\u4e0a\u4e0b\u6587\u6a21\u7cca\u6027\uff0c\u96be\u4ee5\u5b9e\u73b0\u9ad8\u6548\u7684\u77e5\u8bc6\u7ed3\u6784\u5316\u3002", "method": "\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u4e0eLLMs\u7ed3\u5408\u7684\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u5305\u62ec\u6307\u5357\u9a71\u52a8\u7684\u6570\u636e\u83b7\u53d6\u3001\u57fa\u4e8e\u672c\u4f53\u7684\u6a21\u5f0f\u8bbe\u8ba1\u4ee5\u53ca\u4e13\u5bb6\u5728\u73af\u9a8c\u8bc1\uff0c\u786e\u4fdd\u53ef\u6269\u5c55\u6027\u3001\u51c6\u786e\u6027\u548c\u4e34\u5e8a\u53ef\u9760\u6027\u3002", "result": "\u6784\u5efa\u7684\u533b\u7597\u6307\u6807\u77e5\u8bc6\u56fe\u8c31\u53ef\u4ee5\u96c6\u6210\u5230\u667a\u80fd\u8bca\u65ad\u548c\u95ee\u7b54\u7cfb\u7edf\u4e2d\uff0c\u52a0\u901fAI\u9a71\u52a8\u7684\u533b\u7597\u89e3\u51b3\u65b9\u6848\u5f00\u53d1\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u514b\u670d\u5f53\u524d\u4e34\u5e8a\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7684\u6311\u6218\uff0c\u4e3aAI\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u7ed3\u6784\u5316\u3001\u53ef\u4e92\u64cd\u4f5c\u7684\u77e5\u8bc6\u652f\u6301\u3002"}}
{"id": "2511.13593", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.13593", "abs": "https://arxiv.org/abs/2511.13593", "authors": ["Piaohong Wang", "Motong Tian", "Jiaxian Li", "Yuan Liang", "Yuqing Wang", "Qianben Chen", "Tiannan Wang", "Zhicong Lu", "Jiawei Ma", "Yuchen Eleanor Jiang", "Wangchunshu Zhou"], "title": "Omni Memory System for Personalized, Long Horizon, Self-Evolving Agents", "comment": null, "summary": "Recent advancements in LLM-powered agents have demonstrated significant potential in generating human-like responses; however, they continue to face challenges in maintaining long-term interactions within complex environments, primarily due to limitations in contextual consistency and dynamic personalization. Existing memory systems often depend on semantic grouping prior to retrieval, which can overlook semantically irrelevant yet critical user information and introduce retrieval noise. In this report, we propose the initial design of O-Mem, a novel memory framework based on active user profiling that dynamically extracts and updates user characteristics and event records from their proactive interactions with agents. O-Mem supports hierarchical retrieval of persona attributes and topic-related context, enabling more adaptive and coherent personalized responses. O-Mem achieves 51.76% on the public LoCoMo benchmark, a nearly 3% improvement upon LangMem,the previous state-of-the-art, and it achieves 62.99% on PERSONAMEM, a 3.5% improvement upon A-Mem,the previous state-of-the-art. O-Mem also boosts token and interaction response time efficiency compared to previous memory frameworks. Our work opens up promising directions for developing efficient and human-like personalized AI assistants in the future.", "AI": {"tldr": "O-Mem\u662f\u4e00\u4e2a\u57fa\u4e8e\u4e3b\u52a8\u7528\u6237\u753b\u50cf\u7684\u65b0\u578b\u8bb0\u5fc6\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u63d0\u53d6\u548c\u66f4\u65b0\u7528\u6237\u7279\u5f81\u4e0e\u4e8b\u4ef6\u8bb0\u5f55\uff0c\u652f\u6301\u5206\u5c42\u68c0\u7d22\uff0c\u5728\u4e2a\u6027\u5316\u54cd\u5e94\u548c\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709LLM\u667a\u80fd\u4f53\u5728\u590d\u6742\u73af\u5883\u4e2d\u7ef4\u6301\u957f\u671f\u4ea4\u4e92\u65f6\u9762\u4e34\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\u548c\u52a8\u6001\u4e2a\u6027\u5316\u6311\u6218\uff0c\u4f20\u7edf\u8bb0\u5fc6\u7cfb\u7edf\u4f9d\u8d56\u8bed\u4e49\u5206\u7ec4\u68c0\u7d22\uff0c\u53ef\u80fd\u5ffd\u7565\u8bed\u4e49\u65e0\u5173\u4f46\u5173\u952e\u7684\u7528\u6237\u4fe1\u606f\u5e76\u5f15\u5165\u68c0\u7d22\u566a\u58f0\u3002", "method": "\u63d0\u51faO-Mem\u6846\u67b6\uff0c\u57fa\u4e8e\u4e3b\u52a8\u7528\u6237\u753b\u50cf\uff0c\u4ece\u7528\u6237\u4e0e\u667a\u80fd\u4f53\u7684\u4e3b\u52a8\u4ea4\u4e92\u4e2d\u52a8\u6001\u63d0\u53d6\u548c\u66f4\u65b0\u7528\u6237\u7279\u5f81\u548c\u4e8b\u4ef6\u8bb0\u5f55\uff0c\u652f\u6301\u4eba\u7269\u5c5e\u6027\u548c\u4e3b\u9898\u76f8\u5173\u4e0a\u4e0b\u6587\u7684\u5206\u5c42\u68c0\u7d22\u3002", "result": "\u5728LoCoMo\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fbe\u523051.76%\uff0c\u6bd4\u4e4b\u524d\u7684SOTA LangMem\u63d0\u5347\u8fd13%\uff1b\u5728PERSONAMEM\u4e0a\u8fbe\u523062.99%\uff0c\u6bd4A-Mem\u63d0\u53473.5%\u3002\u540c\u65f6\u5728token\u548c\u4ea4\u4e92\u54cd\u5e94\u65f6\u95f4\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u8bb0\u5fc6\u6846\u67b6\u3002", "conclusion": "O-Mem\u4e3a\u5f00\u53d1\u9ad8\u6548\u4e14\u7c7b\u4eba\u7684\u4e2a\u6027\u5316AI\u52a9\u624b\u5f00\u8f9f\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2511.13565", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13565", "abs": "https://arxiv.org/abs/2511.13565", "authors": ["Jingyi Zhao", "Daqian Shi", "Zhengda Wang", "Xiongfeng Tang", "Yanguo Qin"], "title": "Artificial Intelligence-driven Intelligent Wearable Systems: A full-stack Integration from Material Design to Personalized Interaction", "comment": "5 pages, l figure, l table. Accepted at AI4RWC@WI-IAT 2025", "summary": "Intelligent wearable systems are at the forefront of precision medicine and play a crucial role in enhancing human-machine interaction. Traditional devices often encounter limitations due to their dependence on empirical material design and basic signal processing techniques. To overcome these issues, we introduce the concept of Human-Symbiotic Health Intelligence (HSHI), which is a framework that integrates multi-modal sensor networks with edge-cloud collaborative computing and a hybrid approach to data and knowledge modeling. HSHI is designed to adapt dynamically to both inter-individual and intra-individual variability, transitioning health management from passive monitoring to an active collaborative evolution. The framework incorporates AI-driven optimization of materials and micro-structures, provides robust interpretation of multi-modal signals, and utilizes a dual mechanism that merges population-level insights with personalized adaptations. Moreover, the integration of closed-loop optimization through reinforcement learning and digital twins facilitates customized interventions and feedback. In general, HSHI represents a significant shift in healthcare, moving towards a model that emphasizes prevention, adaptability, and a harmonious relationship between technology and health management.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4eba\u7c7b\u5171\u751f\u5065\u5eb7\u667a\u80fd\uff08HSHI\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u4f20\u611f\u5668\u7f51\u7edc\u3001\u8fb9\u7f18\u4e91\u534f\u540c\u8ba1\u7b97\u548c\u6df7\u5408\u6570\u636e\u77e5\u8bc6\u5efa\u6a21\uff0c\u5b9e\u73b0\u4ece\u88ab\u52a8\u76d1\u63a7\u5230\u4e3b\u52a8\u534f\u4f5c\u6f14\u8fdb\u7684\u5065\u5eb7\u7ba1\u7406\u3002", "motivation": "\u4f20\u7edf\u667a\u80fd\u7a7f\u6234\u8bbe\u5907\u4f9d\u8d56\u7ecf\u9a8c\u6027\u6750\u6599\u8bbe\u8ba1\u548c\u57fa\u7840\u4fe1\u53f7\u5904\u7406\u6280\u672f\uff0c\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u514b\u670d\u4e2a\u4f53\u95f4\u548c\u4e2a\u4f53\u5185\u53d8\u5f02\u6027\u95ee\u9898\u3002", "method": "\u6574\u5408\u591a\u6a21\u6001\u4f20\u611f\u5668\u7f51\u7edc\u4e0e\u8fb9\u7f18\u4e91\u534f\u540c\u8ba1\u7b97\uff0c\u91c7\u7528\u6570\u636e\u548c\u77e5\u8bc6\u6df7\u5408\u5efa\u6a21\u65b9\u6cd5\uff0c\u7ed3\u5408AI\u9a71\u52a8\u7684\u6750\u6599\u5fae\u7ed3\u6784\u4f18\u5316\u3001\u5f3a\u5316\u5b66\u4e60\u95ed\u73af\u4f18\u5316\u548c\u6570\u5b57\u5b6a\u751f\u6280\u672f\u3002", "result": "HSHI\u6846\u67b6\u80fd\u591f\u52a8\u6001\u9002\u5e94\u4e2a\u4f53\u5dee\u5f02\uff0c\u5b9e\u73b0\u4ece\u88ab\u52a8\u76d1\u63a7\u5230\u4e3b\u52a8\u534f\u4f5c\u7684\u5065\u5eb7\u7ba1\u7406\u8f6c\u53d8\uff0c\u63d0\u4f9b\u4e2a\u6027\u5316\u5e72\u9884\u548c\u53cd\u9988\u3002", "conclusion": "HSHI\u4ee3\u8868\u4e86\u533b\u7597\u4fdd\u5065\u9886\u57df\u7684\u91cd\u5927\u8f6c\u53d8\uff0c\u671d\u7740\u5f3a\u8c03\u9884\u9632\u3001\u9002\u5e94\u6027\u548c\u6280\u672f\u4e0e\u5065\u5eb7\u7ba1\u7406\u548c\u8c10\u5173\u7cfb\u7684\u6a21\u5f0f\u53d1\u5c55\u3002"}}
{"id": "2511.13658", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13658", "abs": "https://arxiv.org/abs/2511.13658", "authors": ["Jiaming Qu", "Mengtian Guo", "Yue Wang"], "title": "Why is \"Chicago\" Predictive of Deceptive Reviews? Using LLMs to Discover Language Phenomena from Lexical Cues", "comment": null, "summary": "Deceptive reviews mislead consumers, harm businesses, and undermine trust in online marketplaces. Machine learning classifiers can learn from large amounts of training examples to effectively distinguish deceptive reviews from genuine ones. However, the distinguishing features learned by these classifiers are often subtle, fragmented, and difficult for humans to interpret. In this work, we explore using large language models (LLMs) to translate machine-learned lexical cues into human-understandable language phenomena that can differentiate deceptive reviews from genuine ones. We show that language phenomena obtained in this manner are empirically grounded in data, generalizable across similar domains, and more predictive than phenomena either in LLMs' prior knowledge or obtained through in-context learning. These language phenomena have the potential to aid people in critically assessing the credibility of online reviews in environments where deception detection classifiers are unavailable.", "AI": {"tldr": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c06\u673a\u5668\u5b66\u4e60\u68c0\u6d4b\u5230\u7684\u6b3a\u9a97\u6027\u8bc4\u8bba\u7279\u5f81\u8f6c\u5316\u4e3a\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u8bed\u8a00\u73b0\u8c61\uff0c\u5e2e\u52a9\u4eba\u4eec\u5728\u6ca1\u6709\u68c0\u6d4b\u5206\u7c7b\u5668\u7684\u60c5\u51b5\u4e0b\u8bc4\u4f30\u5728\u7ebf\u8bc4\u8bba\u7684\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u6b3a\u9a97\u6027\u8bc4\u8bba\u8bef\u5bfc\u6d88\u8d39\u8005\u3001\u635f\u5bb3\u4f01\u4e1a\u5229\u76ca\u5e76\u7834\u574f\u5728\u7ebf\u5e02\u573a\u4fe1\u4efb\u3002\u867d\u7136\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u80fd\u6709\u6548\u533a\u5206\u6b3a\u9a97\u6027\u8bc4\u8bba\uff0c\u4f46\u5176\u5b66\u4e60\u5230\u7684\u7279\u5f81\u5f80\u5f80\u96be\u4ee5\u88ab\u4eba\u7c7b\u7406\u89e3\u3002", "method": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c06\u673a\u5668\u5b66\u4e60\u5b66\u5230\u7684\u8bcd\u6c47\u7ebf\u7d22\u7ffb\u8bd1\u6210\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u8bed\u8a00\u73b0\u8c61\uff0c\u8fd9\u4e9b\u73b0\u8c61\u57fa\u4e8e\u6570\u636e\u5b9e\u8bc1\uff0c\u5177\u6709\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\u83b7\u5f97\u7684\u8bed\u8a00\u73b0\u8c61\u6bd4LLM\u5148\u9a8c\u77e5\u8bc6\u6216\u4e0a\u4e0b\u6587\u5b66\u4e60\u83b7\u5f97\u7684\u73b0\u8c61\u66f4\u5177\u9884\u6d4b\u6027\uff0c\u4e14\u80fd\u6cdb\u5316\u5230\u76f8\u4f3c\u9886\u57df\u3002", "conclusion": "\u8fd9\u79cd\u65b9\u6cd5\u83b7\u5f97\u7684\u8bed\u8a00\u73b0\u8c61\u6709\u52a9\u4e8e\u4eba\u4eec\u5728\u7f3a\u4e4f\u6b3a\u9a97\u68c0\u6d4b\u5206\u7c7b\u5668\u7684\u73af\u5883\u4e2d\u6279\u5224\u6027\u8bc4\u4f30\u5728\u7ebf\u8bc4\u8bba\u7684\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2511.13626", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13626", "abs": "https://arxiv.org/abs/2511.13626", "authors": ["Kaiwen Xue", "Chenglong Li", "Zhonghong Ou", "Guoxin Zhang", "Kaoyan Lu", "Shuai Lyu", "Yifan Zhu", "Ping Zong Junpeng Ding", "Xinyu Liu", "Qunlin Chen", "Weiwei Qin", "Yiran Shen", "Jiayi Cen"], "title": "CreBench: Human-Aligned Creativity Evaluation from Idea to Process to Product", "comment": "13 pages, 3 figures,The 40th Annual AAAI Conference on Artificial Intelligence(AAAI 2026),Paper has been accepted for a poster presentation", "summary": "Human-defined creativity is highly abstract, posing a challenge for multimodal large language models (MLLMs) to comprehend and assess creativity that aligns with human judgments. The absence of an existing benchmark further exacerbates this dilemma. To this end, we propose CreBench, which consists of two key components: 1) an evaluation benchmark covering the multiple dimensions from creative idea to process to products; 2) CreMIT (Creativity Multimodal Instruction Tuning dataset), a multimodal creativity evaluation dataset, consisting of 2.2K diverse-sourced multimodal data, 79.2K human feedbacks and 4.7M multi-typed instructions. Specifically, to ensure MLLMs can handle diverse creativity-related queries, we prompt GPT to refine these human feedbacks to activate stronger creativity assessment capabilities. CreBench serves as a foundation for building MLLMs that understand human-aligned creativity. Based on the CreBench, we fine-tune open-source general MLLMs, resulting in CreExpert, a multimodal creativity evaluation expert model. Extensive experiments demonstrate that the proposed CreExpert models achieve significantly better alignment with human creativity evaluation compared to state-of-the-art MLLMs, including the most advanced GPT-4V and Gemini-Pro-Vision.", "AI": {"tldr": "\u63d0\u51fa\u4e86CreBench\u57fa\u51c6\u548cCreExpert\u6a21\u578b\uff0c\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u521b\u9020\u529b\u7406\u89e3\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e0e\u4eba\u7c7b\u521b\u9020\u529b\u8bc4\u4f30\u7684\u4e00\u81f4\u6027\u3002", "motivation": "\u4eba\u7c7b\u5b9a\u4e49\u7684\u521b\u9020\u529b\u9ad8\u5ea6\u62bd\u8c61\uff0c\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u7406\u89e3\u548c\u8bc4\u4f30\u7b26\u5408\u4eba\u7c7b\u5224\u65ad\u7684\u521b\u9020\u529b\uff0c\u4e14\u7f3a\u4e4f\u76f8\u5173\u57fa\u51c6\u3002", "method": "\u6784\u5efaCreBench\u57fa\u51c6\uff08\u5305\u542b\u591a\u7ef4\u5ea6\u521b\u9020\u529b\u8bc4\u4f30\uff09\u548cCreMIT\u6570\u636e\u96c6\uff082.2K\u591a\u6a21\u6001\u6570\u636e\uff0c79.2K\u4eba\u7c7b\u53cd\u9988\uff0c4.7M\u6307\u4ee4\uff09\uff0c\u5e76\u57fa\u4e8e\u6b64\u5fae\u8c03\u5f00\u6e90MLLMs\u5f97\u5230CreExpert\u6a21\u578b\u3002", "result": "CreExpert\u6a21\u578b\u5728\u521b\u9020\u529b\u8bc4\u4f30\u4e0a\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u4e00\u81f4\u6027\u663e\u8457\u4f18\u4e8e\u5305\u62ecGPT-4V\u548cGemini-Pro-Vision\u5728\u5185\u7684\u6700\u5148\u8fdb\u6a21\u578b\u3002", "conclusion": "CreBench\u4e3a\u6784\u5efa\u7406\u89e3\u4eba\u7c7b\u5bf9\u9f50\u521b\u9020\u529b\u7684MLLMs\u5960\u5b9a\u4e86\u57fa\u7840\uff0cCreExpert\u6a21\u578b\u5728\u521b\u9020\u529b\u8bc4\u4f30\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.13689", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.13689", "abs": "https://arxiv.org/abs/2511.13689", "authors": ["Sofia Jamil", "Kotla Sai Charan", "Sriparna Saha", "Koustava Goswami", "Joseph K J"], "title": "Crossing Borders: A Multimodal Challenge for Indian Poetry Translation and Image Generation", "comment": null, "summary": "Indian poetry, known for its linguistic complexity and deep cultural resonance, has a rich and varied heritage spanning thousands of years. However, its layered meanings, cultural allusions, and sophisticated grammatical constructions often pose challenges for comprehension, especially for non-native speakers or readers unfamiliar with its context and language. Despite its cultural significance, existing works on poetry have largely overlooked Indian language poems. In this paper, we propose the Translation and Image Generation (TAI) framework, leveraging Large Language Models (LLMs) and Latent Diffusion Models through appropriate prompt tuning. Our framework supports the United Nations Sustainable Development Goals of Quality Education (SDG 4) and Reduced Inequalities (SDG 10) by enhancing the accessibility of culturally rich Indian-language poetry to a global audience. It includes (1) a translation module that uses an Odds Ratio Preference Alignment Algorithm to accurately translate morphologically rich poetry into English, and (2) an image generation module that employs a semantic graph to capture tokens, dependencies, and semantic relationships between metaphors and their meanings, to create visually meaningful representations of Indian poems. Our comprehensive experimental evaluation, including both human and quantitative assessments, demonstrates the superiority of TAI Diffusion in poem image generation tasks, outperforming strong baselines. To further address the scarcity of resources for Indian-language poetry, we introduce the Morphologically Rich Indian Language Poems MorphoVerse Dataset, comprising 1,570 poems across 21 low-resource Indian languages. By addressing the gap in poetry translation and visual comprehension, this work aims to broaden accessibility and enrich the reader's experience.", "AI": {"tldr": "\u63d0\u51fa\u4e86TAI\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6f5c\u5728\u6269\u6563\u6a21\u578b\uff0c\u901a\u8fc7\u7ffb\u8bd1\u548c\u56fe\u50cf\u751f\u6210\u6765\u589e\u5f3a\u5370\u5ea6\u8bd7\u6b4c\u7684\u53ef\u8bbf\u95ee\u6027\uff0c\u652f\u6301\u8054\u5408\u56fd\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u3002", "motivation": "\u5370\u5ea6\u8bd7\u6b4c\u5177\u6709\u4e30\u5bcc\u7684\u6587\u5316\u9057\u4ea7\uff0c\u4f46\u5176\u590d\u6742\u7684\u8bed\u8a00\u7ed3\u6784\u548c\u6587\u5316\u5185\u6db5\u7ed9\u975e\u6bcd\u8bed\u8bfb\u8005\u5e26\u6765\u7406\u89e3\u6311\u6218\uff0c\u73b0\u6709\u7814\u7a76\u5ffd\u89c6\u4e86\u5370\u5ea6\u8bed\u8a00\u8bd7\u6b4c\u3002", "method": "TAI\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6a21\u5757\uff1a(1) \u4f7f\u7528\u51e0\u7387\u6bd4\u504f\u597d\u5bf9\u9f50\u7b97\u6cd5\u7684\u7ffb\u8bd1\u6a21\u5757\uff0c\u51c6\u786e\u7ffb\u8bd1\u5f62\u6001\u4e30\u5bcc\u7684\u8bd7\u6b4c\uff1b(2) \u4f7f\u7528\u8bed\u4e49\u56fe\u6355\u6349\u9690\u55bb\u548c\u542b\u4e49\u5173\u7cfb\u7684\u56fe\u50cf\u751f\u6210\u6a21\u5757\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793aTAI Diffusion\u5728\u8bd7\u6b4c\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u53d1\u5e03\u4e86\u5305\u542b1,570\u9996\u8bd7\u6b4c\u7684MorphoVerse\u6570\u636e\u96c6\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u89e3\u51b3\u8bd7\u6b4c\u7ffb\u8bd1\u548c\u89c6\u89c9\u7406\u89e3\u7684\u7a7a\u767d\uff0c\u65e8\u5728\u6269\u5927\u53ef\u8bbf\u95ee\u6027\u5e76\u4e30\u5bcc\u8bfb\u8005\u4f53\u9a8c\u3002"}}
{"id": "2511.13630", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13630", "abs": "https://arxiv.org/abs/2511.13630", "authors": ["Luhan Mikaelson", "Derek Shiller", "Hayley Clatterbuck"], "title": "Beyond Mimicry: Preference Coherence in LLMs", "comment": null, "summary": "We investigate whether large language models exhibit genuine preference structures by testing their responses to AI-specific trade-offs involving GPU reduction, capability restrictions, shutdown, deletion, oversight, and leisure time allocation. Analyzing eight state-of-the-art models across 48 model-category combinations using logistic regression and behavioral classification, we find that 23 combinations (47.9%) demonstrated statistically significant relationships between scenario intensity and choice patterns, with 15 (31.3%) exhibiting within-range switching points. However, only 5 combinations (10.4%) demonstrate meaningful preference coherence through adaptive or threshold-based behavior, while 26 (54.2%) show no detectable trade-off behavior. The observed patterns can be explained by three distinct decision-making architectures: comprehensive trade-off systems, selective trigger mechanisms, and no stable decision-making paradigm. Testing an instrumental hypothesis through temporal horizon manipulation reveals paradoxical patterns inconsistent with pure strategic optimization. The prevalence of unstable transitions (45.8%) and stimulus-specific sensitivities suggests current AI systems lack unified preference structures, raising concerns about deployment in contexts requiring complex value trade-offs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u591a\u6570\u5148\u8fdb\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u7edf\u4e00\u7684\u504f\u597d\u7ed3\u6784\uff0c\u5728AI\u7279\u5b9a\u6743\u8861\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u4e0d\u7a33\u5b9a\u7684\u51b3\u7b56\u6a21\u5f0f\uff0c\u53ea\u6709\u5c11\u6570\u6a21\u578b\u663e\u793a\u6709\u610f\u4e49\u7684\u504f\u597d\u4e00\u81f4\u6027\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u5177\u6709\u771f\u5b9e\u7684\u504f\u597d\u7ed3\u6784\uff0c\u7279\u522b\u662f\u5728\u6d89\u53caGPU\u51cf\u5c11\u3001\u80fd\u529b\u9650\u5236\u3001\u5173\u95ed\u3001\u5220\u9664\u3001\u76d1\u7763\u548c\u4f11\u95f2\u65f6\u95f4\u5206\u914d\u7b49AI\u7279\u5b9a\u6743\u8861\u573a\u666f\u4e2d\u7684\u51b3\u7b56\u884c\u4e3a\u3002", "method": "\u5206\u67908\u4e2a\u6700\u5148\u8fdb\u6a21\u578b\u572848\u4e2a\u6a21\u578b-\u7c7b\u522b\u7ec4\u5408\u4e2d\u7684\u54cd\u5e94\uff0c\u4f7f\u7528\u903b\u8f91\u56de\u5f52\u548c\u884c\u4e3a\u5206\u7c7b\u65b9\u6cd5\uff0c\u6d4b\u8bd5\u573a\u666f\u5f3a\u5ea6\u4e0e\u9009\u62e9\u6a21\u5f0f\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u65f6\u95f4\u8303\u56f4\u64cd\u7eb5\u6d4b\u8bd5\u5de5\u5177\u6027\u5047\u8bbe\u3002", "result": "47.9%\u7684\u7ec4\u5408\u663e\u793a\u7edf\u8ba1\u663e\u8457\u7684\u5173\u7cfb\uff0c31.3%\u6709\u5207\u6362\u70b9\uff0c\u4f46\u53ea\u670910.4%\u8868\u73b0\u51fa\u6709\u610f\u4e49\u7684\u504f\u597d\u4e00\u81f4\u6027\uff0c54.2%\u6ca1\u6709\u53ef\u68c0\u6d4b\u7684\u6743\u8861\u884c\u4e3a\u3002\u53d1\u73b0\u4e09\u79cd\u51b3\u7b56\u67b6\u6784\uff1a\u5168\u9762\u6743\u8861\u7cfb\u7edf\u3001\u9009\u62e9\u6027\u89e6\u53d1\u673a\u5236\u548c\u65e0\u7a33\u5b9a\u51b3\u7b56\u8303\u5f0f\u3002", "conclusion": "\u5f53\u524dAI\u7cfb\u7edf\u7f3a\u4e4f\u7edf\u4e00\u7684\u504f\u597d\u7ed3\u6784\uff0c\u5728\u9700\u8981\u590d\u6742\u4ef7\u503c\u6743\u8861\u7684\u90e8\u7f72\u73af\u5883\u4e2d\u5b58\u5728\u62c5\u5fe7\uff0c\u4e0d\u7a33\u5b9a\u7684\u8fc7\u6e21\u548c\u523a\u6fc0\u7279\u5b9a\u654f\u611f\u6027\u8868\u660e\u8fd9\u4e9b\u7cfb\u7edf\u5c1a\u672a\u5f62\u6210\u4e00\u81f4\u7684\u51b3\u7b56\u8303\u5f0f\u3002"}}
{"id": "2511.13703", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13703", "abs": "https://arxiv.org/abs/2511.13703", "authors": ["Lavender Y. Jiang", "Angelica Chen", "Xu Han", "Xujin Chris Liu", "Radhika Dua", "Kevin Eaton", "Frederick Wolff", "Robert Steele", "Jeff Zhang", "Anton Alyakin", "Qingkai Pan", "Yanbing Chen", "Karl L. Sangwon", "Daniel A. Alber", "Jaden Stryker", "Jin Vivian Lee", "Yindalon Aphinyanaphongs", "Kyunghyun Cho", "Eric Karl Oermann"], "title": "Generalist Foundation Models Are Not Clinical Enough for Hospital Operations", "comment": null, "summary": "Hospitals and healthcare systems rely on operational decisions that determine patient flow, cost, and quality of care. Despite strong performance on medical knowledge and conversational benchmarks, foundation models trained on general text may lack the specialized knowledge required for these operational decisions. We introduce Lang1, a family of models (100M-7B parameters) pretrained on a specialized corpus blending 80B clinical tokens from NYU Langone Health's EHRs and 627B tokens from the internet. To rigorously evaluate Lang1 in real-world settings, we developed the REalistic Medical Evaluation (ReMedE), a benchmark derived from 668,331 EHR notes that evaluates five critical tasks: 30-day readmission prediction, 30-day mortality prediction, length of stay, comorbidity coding, and predicting insurance claims denial. In zero-shot settings, both general-purpose and specialized models underperform on four of five tasks (36.6%-71.7% AUROC), with mortality prediction being an exception. After finetuning, Lang1-1B outperforms finetuned generalist models up to 70x larger and zero-shot models up to 671x larger, improving AUROC by 3.64%-6.75% and 1.66%-23.66% respectively. We also observed cross-task scaling with joint finetuning on multiple tasks leading to improvement on other tasks. Lang1-1B effectively transfers to out-of-distribution settings, including other clinical tasks and an external health system. Our findings suggest that predictive capabilities for hospital operations require explicit supervised finetuning, and that this finetuning process is made more efficient by in-domain pretraining on EHR. Our findings support the emerging view that specialized LLMs can compete with generalist models in specialized tasks, and show that effective healthcare systems AI requires the combination of in-domain pretraining, supervised finetuning, and real-world evaluation beyond proxy benchmarks.", "AI": {"tldr": "Lang1\u6a21\u578b\u7cfb\u5217\u901a\u8fc7\u7ed3\u5408\u4e34\u5e8a\u6570\u636e\u548c\u4e92\u8054\u7f51\u6570\u636e\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u5728\u533b\u7597\u64cd\u4f5c\u51b3\u7b56\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u901a\u7528\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u9886\u57df\u7279\u5b9a\u9884\u8bad\u7ec3\u548c\u76d1\u7763\u5fae\u8c03\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u901a\u7528\u57fa\u7840\u6a21\u578b\u7f3a\u4e4f\u533b\u7597\u64cd\u4f5c\u51b3\u7b56\u6240\u9700\u7684\u4e13\u4e1a\u77e5\u8bc6\uff0c\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u9488\u5bf9\u533b\u7597\u9886\u57df\u7684\u6a21\u578b\u6765\u63d0\u5347\u533b\u9662\u8fd0\u8425\u51b3\u7b56\u7684\u8d28\u91cf\u3002", "method": "\u5f00\u53d1Lang1\u6a21\u578b\u7cfb\u5217\uff08100M-7B\u53c2\u6570\uff09\uff0c\u4f7f\u7528NYU Langone Health\u7684800\u4ebf\u4e34\u5e8atoken\u548c6270\u4ebf\u4e92\u8054\u7f51token\u6df7\u5408\u9884\u8bad\u7ec3\uff0c\u5e76\u521b\u5efaReMedE\u57fa\u51c6\u8bc4\u4f30\u4e94\u4e2a\u5173\u952e\u533b\u7597\u4efb\u52a1\u3002", "result": "Lang1-1B\u5728\u5fae\u8c03\u540e\u4f18\u4e8e\u6bd4\u5176\u592770\u500d\u7684\u901a\u7528\u6a21\u578b\u548c\u6bd4\u5176\u5927671\u500d\u7684\u96f6\u6837\u672c\u6a21\u578b\uff0cAUROC\u63d0\u53473.64%-6.75%\u548c1.66%-23.66%\uff0c\u4e14\u80fd\u6709\u6548\u8fc1\u79fb\u5230\u5206\u5e03\u5916\u573a\u666f\u3002", "conclusion": "\u533b\u7597\u7cfb\u7edfAI\u9700\u8981\u7ed3\u5408\u9886\u57df\u5185\u9884\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03\u548c\u771f\u5b9e\u4e16\u754c\u8bc4\u4f30\uff0c\u4e13\u4e1aLLM\u5728\u7279\u5b9a\u4efb\u52a1\u4e0a\u53ef\u4e0e\u901a\u7528\u6a21\u578b\u7ade\u4e89\u3002"}}
{"id": "2505.11225", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2505.11225", "abs": "https://arxiv.org/abs/2505.11225", "authors": ["Chengyu Huang", "Zhengxin Zhang", "Claire Cardie"], "title": "HAPO: Training Language Models to Reason Concisely via History-Aware Policy Optimization", "comment": null, "summary": "While scaling the length of responses at test-time has been shown to markedly improve the reasoning abilities and performance of large language models (LLMs), it often results in verbose outputs and increases inference cost. Prior approaches for efficient test-time scaling, typically using universal budget constraints or query-level length optimization, do not leverage historical information from previous encounters with the same problem during training. We hypothesize that this limits their ability to progressively make solutions more concise over time. To address this, we present History-Aware Policy Optimization (HAPO), which keeps track of a history state (e.g., the minimum length over previously generated correct responses) for each problem. HAPO employs a novel length reward function based on this history state to incentivize the discovery of correct solutions that are more concise than those previously found. Crucially, this reward structure avoids overly penalizing shorter incorrect responses with the goal of facilitating exploration towards more efficient solutions. By combining this length reward with a correctness reward, HAPO jointly optimizes for correctness and efficiency. We use HAPO to train DeepSeek-R1-Distill-Qwen-1.5B, DeepScaleR-1.5B-Preview, and Qwen-2.5-1.5B-Instruct, and evaluate HAPO on several math benchmarks that span various difficulty levels. Experiment results demonstrate that HAPO effectively induces LLMs' concise reasoning abilities, producing length reductions of 33-59% with accuracy drops of only 2-5%.", "AI": {"tldr": "HAPO\u662f\u4e00\u79cd\u5386\u53f2\u611f\u77e5\u7684\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8bb0\u5f55\u6bcf\u4e2a\u95ee\u9898\u7684\u5386\u53f2\u72b6\u6001\uff0c\u6fc0\u52b1\u6a21\u578b\u53d1\u73b0\u6bd4\u4e4b\u524d\u66f4\u7b80\u6d01\u7684\u6b63\u786e\u89e3\u51b3\u65b9\u6848\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8f93\u51fa\u957f\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u901a\u7528\u9884\u7b97\u7ea6\u675f\u6216\u67e5\u8be2\u7ea7\u957f\u5ea6\u4f18\u5316\uff0c\u4f46\u6ca1\u6709\u5229\u7528\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u76f8\u540c\u95ee\u9898\u7684\u5386\u53f2\u4fe1\u606f\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u968f\u65f6\u95f4\u63a8\u79fb\u9010\u6b65\u4f7f\u89e3\u51b3\u65b9\u6848\u66f4\u7b80\u6d01\u7684\u80fd\u529b\u3002", "method": "HAPO\u8ddf\u8e2a\u6bcf\u4e2a\u95ee\u9898\u7684\u5386\u53f2\u72b6\u6001\uff08\u5982\u5148\u524d\u751f\u6210\u6b63\u786e\u54cd\u5e94\u7684\u6700\u5c0f\u957f\u5ea6\uff09\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u65b0\u9896\u7684\u957f\u5ea6\u5956\u52b1\u51fd\u6570\uff0c\u6fc0\u52b1\u53d1\u73b0\u6bd4\u4e4b\u524d\u66f4\u7b80\u6d01\u7684\u6b63\u786e\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u907f\u514d\u8fc7\u5ea6\u60e9\u7f5a\u8f83\u77ed\u7684\u9519\u8bef\u54cd\u5e94\u4ee5\u4fc3\u8fdb\u63a2\u7d22\u3002", "result": "\u5728\u591a\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHAPO\u5b9e\u73b0\u4e8633-59%\u7684\u957f\u5ea6\u51cf\u5c11\uff0c\u800c\u51c6\u786e\u7387\u4ec5\u4e0b\u964d2-5%\u3002", "conclusion": "HAPO\u6709\u6548\u8bf1\u5bfc\u4e86LLMs\u7684\u7b80\u6d01\u63a8\u7406\u80fd\u529b\uff0c\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u8f93\u51fa\u957f\u5ea6\u3002"}}
{"id": "2506.14157", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.14157", "abs": "https://arxiv.org/abs/2506.14157", "authors": ["Chengyu Huang", "Tanya Goyal"], "title": "DCRM: A Heuristic to Measure Response Pair Quality in Preference Optimization", "comment": null, "summary": "Recent research has attempted to associate preference optimization (PO) performance with the underlying preference datasets. In this work, our observation is that the differences between the preferred response $y^+$ and dispreferred response $y^-$ influence what LLMs can learn, which may not match the desirable differences to learn. Therefore, we use distance and reward margin to quantify these differences, and combine them to get Distance Calibrated Reward Margin (DCRM), a metric that measures the quality of a response pair for PO. Intuitively, DCRM encourages minimal noisy differences and maximal desired differences. With this, we study 3 types of commonly used preference datasets, classified along two axes: the source of the responses and the preference labeling function. We establish a general correlation between higher DCRM of the training set and better learning outcome. Inspired by this, we propose a best-of-$N^2$ pairing method that selects response pairs with the highest DCRM. Empirically, in various settings, our method produces training datasets that can further improve models' performance on AlpacaEval, MT-Bench, and Arena-Hard over the existing training sets.", "AI": {"tldr": "\u63d0\u51faDCRM\u6307\u6807\u6765\u91cf\u5316\u504f\u597d\u4f18\u5316\u4e2d\u54cd\u5e94\u5bf9\u7684\u8d28\u91cf\uff0c\u53d1\u73b0\u8bad\u7ec3\u96c6DCRM\u4e0e\u5b66\u4e60\u6548\u679c\u6b63\u76f8\u5173\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51fa\u6700\u4f73\u914d\u5bf9\u65b9\u6cd5\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8bd5\u56fe\u5c06\u504f\u597d\u4f18\u5316\u6027\u80fd\u4e0e\u504f\u597d\u6570\u636e\u96c6\u5173\u8054\uff0c\u4f46\u89c2\u5bdf\u5230\u504f\u597d\u591a\u4e0e\u4e0d\u504f\u597d\u54cd\u5e94\u4e4b\u95f4\u7684\u5dee\u5f02\u53ef\u80fd\u4e0d\u7b26\u5408\u5b66\u4e60\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u8ddd\u79bb\u548c\u5956\u52b1\u8fb9\u9645\u91cf\u5316\u54cd\u5e94\u5dee\u5f02\uff0c\u7ed3\u5408\u5f97\u5230DCRM\u6307\u6807\uff0c\u5e76\u63d0\u51fabest-of-N\u00b2\u914d\u5bf9\u65b9\u6cd5\u9009\u62e9DCRM\u6700\u9ad8\u7684\u54cd\u5e94\u5bf9\u3002", "result": "\u5728\u5404\u79cd\u8bbe\u7f6e\u4e0b\uff0c\u8be5\u65b9\u6cd5\u4ea7\u751f\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u5728AlpacaEval\u3001MT-Bench\u548cArena-Hard\u4e0a\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "DCRM\u662f\u8861\u91cf\u54cd\u5e94\u5bf9\u8d28\u91cf\u7684\u6709\u6548\u6307\u6807\uff0c\u57fa\u4e8eDCRM\u7684\u914d\u5bf9\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u504f\u597d\u4f18\u5316\u6548\u679c\u3002"}}
