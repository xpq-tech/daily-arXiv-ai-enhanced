{"id": "2511.19648", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19648", "abs": "https://arxiv.org/abs/2511.19648", "authors": ["Manil Shrestha", "Edward Kim"], "title": "Efficient Multi-Hop Question Answering over Knowledge Graphs via LLM Planning and Embedding-Guided Search", "comment": null, "summary": "Multi-hop question answering over knowledge graphs remains computationally challenging due to the combinatorial explosion of possible reasoning paths. Recent approaches rely on expensive Large Language Model (LLM) inference for both entity linking and path ranking, limiting their practical deployment. Additionally, LLM-generated answers often lack verifiable grounding in structured knowledge. We present two complementary hybrid algorithms that address both efficiency and verifiability: (1) LLM-Guided Planning that uses a single LLM call to predict relation sequences executed via breadth-first search, achieving near-perfect accuracy (micro-F1 > 0.90) while ensuring all answers are grounded in the knowledge graph, and (2) Embedding-Guided Neural Search that eliminates LLM calls entirely by fusing text and graph embeddings through a lightweight 6.7M-parameter edge scorer, achieving over 100 times speedup with competitive accuracy. Through knowledge distillation, we compress planning capability into a 4B-parameter model that matches large-model performance at zero API cost. Evaluation on MetaQA demonstrates that grounded reasoning consistently outperforms ungrounded generation, with structured planning proving more transferable than direct answer generation. Our results show that verifiable multi-hop reasoning does not require massive models at inference time, but rather the right architectural inductive biases combining symbolic structure with learned representations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cd\u6df7\u5408\u7b97\u6cd5\u6765\u89e3\u51b3\u77e5\u8bc6\u56fe\u8c31\u591a\u8df3\u95ee\u7b54\u4e2d\u7684\u6548\u7387\u548c\u53ef\u9a8c\u8bc1\u6027\u95ee\u9898\uff1aLLM\u5f15\u5bfc\u89c4\u5212\u4f7f\u7528\u5355\u6b21LLM\u8c03\u7528\u9884\u6d4b\u5173\u7cfb\u5e8f\u5217\uff0c\u5d4c\u5165\u5f15\u5bfc\u795e\u7ecf\u641c\u7d22\u5b8c\u5168\u6d88\u9664LLM\u8c03\u7528\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8fb9\u8bc4\u5206\u5668\u878d\u5408\u6587\u672c\u548c\u56fe\u5d4c\u5165\u3002", "motivation": "\u89e3\u51b3\u77e5\u8bc6\u56fe\u8c31\u591a\u8df3\u95ee\u7b54\u4e2d\u7684\u7ec4\u5408\u7206\u70b8\u95ee\u9898\uff0c\u51cf\u5c11\u6602\u8d35\u7684LLM\u63a8\u7406\u6210\u672c\uff0c\u786e\u4fdd\u7b54\u6848\u5728\u7ed3\u6784\u5316\u77e5\u8bc6\u4e2d\u7684\u53ef\u9a8c\u8bc1\u6027\u3002", "method": "1) LLM\u5f15\u5bfc\u89c4\u5212\uff1a\u5355\u6b21LLM\u8c03\u7528\u9884\u6d4b\u5173\u7cfb\u5e8f\u5217\uff0c\u901a\u8fc7\u5e7f\u5ea6\u4f18\u5148\u641c\u7d22\u6267\u884c\uff1b2) \u5d4c\u5165\u5f15\u5bfc\u795e\u7ecf\u641c\u7d22\uff1a\u4f7f\u75286.7M\u53c2\u6570\u7684\u8f7b\u91cf\u7ea7\u8fb9\u8bc4\u5206\u5668\u878d\u5408\u6587\u672c\u548c\u56fe\u5d4c\u5165\uff0c\u5b8c\u5168\u907f\u514dLLM\u8c03\u7528\uff1b\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u5c06\u89c4\u5212\u80fd\u529b\u538b\u7f29\u52304B\u53c2\u6570\u6a21\u578b\u3002", "result": "LLM\u5f15\u5bfc\u89c4\u5212\u5b9e\u73b0\u63a5\u8fd1\u5b8c\u7f8e\u7684\u51c6\u786e\u7387\uff08micro-F1 > 0.90\uff09\uff0c\u6240\u6709\u7b54\u6848\u90fd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\uff1b\u5d4c\u5165\u5f15\u5bfc\u795e\u7ecf\u641c\u7d22\u5b9e\u73b0100\u500d\u4ee5\u4e0a\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u529b\u51c6\u786e\u7387\uff1b\u5728MetaQA\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\u57fa\u4e8e\u7ed3\u6784\u7684\u63a8\u7406\u59cb\u7ec8\u4f18\u4e8e\u65e0\u57fa\u7840\u751f\u6210\u3002", "conclusion": "\u53ef\u9a8c\u8bc1\u7684\u591a\u8df3\u63a8\u7406\u4e0d\u9700\u8981\u5728\u63a8\u7406\u65f6\u4f7f\u7528\u5927\u89c4\u6a21\u6a21\u578b\uff0c\u800c\u662f\u9700\u8981\u7ed3\u5408\u7b26\u53f7\u7ed3\u6784\u548c\u5b66\u4e60\u8868\u793a\u7684\u9002\u5f53\u67b6\u6784\u5f52\u7eb3\u504f\u5dee\u3002"}}
{"id": "2511.19719", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19719", "abs": "https://arxiv.org/abs/2511.19719", "authors": ["Mobina Mehrazar", "Mohammad Amin Yousefi", "Parisa Abolfath Beygi", "Behnam Bahrak"], "title": "Can LLMs Faithfully Explain Themselves in Low-Resource Languages? A Case Study on Emotion Detection in Persian", "comment": null, "summary": "Large language models (LLMs) are increasingly used to generate self-explanations alongside their predictions, a practice that raises concerns about the faithfulness of these explanations, especially in low-resource languages. This study evaluates the faithfulness of LLM-generated explanations in the context of emotion classification in Persian, a low-resource language, by comparing the influential words identified by the model against those identified by human annotators. We assess faithfulness using confidence scores derived from token-level log-probabilities. Two prompting strategies, differing in the order of explanation and prediction (Predict-then-Explain and Explain-then-Predict), are tested for their impact on explanation faithfulness. Our results reveal that while LLMs achieve strong classification performance, their generated explanations often diverge from faithful reasoning, showing greater agreement with each other than with human judgments. These results highlight the limitations of current explanation methods and metrics, emphasizing the need for more robust approaches to ensure LLM reliability in multilingual and low-resource contexts.", "AI": {"tldr": "\u8bc4\u4f30LLM\u5728\u6ce2\u65af\u8bed\u60c5\u611f\u5206\u7c7b\u4e2d\u751f\u6210\u89e3\u91ca\u7684\u5fe0\u5b9e\u6027\uff0c\u53d1\u73b0\u6a21\u578b\u89e3\u91ca\u4e0e\u4eba\u7c7b\u5224\u65ad\u5b58\u5728\u5dee\u5f02\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u53ef\u9760\u7684\u591a\u8bed\u8a00\u89e3\u91ca\u65b9\u6cd5\u3002", "motivation": "LLM\u751f\u6210\u81ea\u89e3\u91ca\u65f6\u5b58\u5728\u5fe0\u5b9e\u6027\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u89e3\u91ca\u662f\u5426\u53cd\u6620\u771f\u5b9e\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83LLM\u8bc6\u522b\u7684\u5f71\u54cd\u8bcd\u4e0e\u4eba\u7c7b\u6807\u6ce8\uff0c\u4f7f\u7528token\u7ea7\u5bf9\u6570\u6982\u7387\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u5fe0\u5b9e\u6027\uff0c\u6d4b\u8bd5\u4e24\u79cd\u63d0\u793a\u7b56\u7565\uff08\u9884\u6d4b-\u89e3\u91ca\u548c\u89e3\u91ca-\u9884\u6d4b\uff09\u3002", "result": "LLM\u5206\u7c7b\u6027\u80fd\u5f3a\u4f46\u751f\u6210\u89e3\u91ca\u4e0d\u5fe0\u5b9e\uff0c\u6a21\u578b\u95f4\u4e00\u81f4\u6027\u9ad8\u4e8e\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "\u5f53\u524d\u89e3\u91ca\u65b9\u6cd5\u548c\u6307\u6807\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u66f4\u7a33\u5065\u7684\u65b9\u6cd5\u786e\u4fddLLM\u5728\u591a\u8bed\u8a00\u548c\u4f4e\u8d44\u6e90\u73af\u5883\u4e2d\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.19739", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19739", "abs": "https://arxiv.org/abs/2511.19739", "authors": ["Richard J. Young", "Alice M. Matthews"], "title": "Comparative Analysis of LoRA-Adapted Embedding Models for Clinical Cardiology Text Representation", "comment": "25 pages, 13 figures, 5 tables", "summary": "Domain-specific text embeddings are critical for clinical natural language processing, yet systematic comparisons across model architectures remain limited. This study evaluates ten transformer-based embedding models adapted for cardiology through Low-Rank Adaptation (LoRA) fine-tuning on 106,535 cardiology text pairs derived from authoritative medical textbooks. Results demonstrate that encoder-only architectures, particularly BioLinkBERT, achieve superior domain-specific performance (separation score: 0.510) compared to larger decoder-based models, while requiring significantly fewer computational resources. The findings challenge the assumption that larger language models necessarily produce better domain-specific embeddings and provide practical guidance for clinical NLP system development. All models, training code, and evaluation datasets are publicly available to support reproducible research in medical informatics.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e8610\u79cd\u57fa\u4e8eTransformer\u7684\u5d4c\u5165\u6a21\u578b\u5728\u5fc3\u810f\u75c5\u5b66\u9886\u57df\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u7f16\u7801\u5668\u67b6\u6784\uff08\u7279\u522b\u662fBioLinkBERT\uff09\u5728\u9886\u57df\u7279\u5b9a\u6027\u80fd\u4e0a\u4f18\u4e8e\u66f4\u5927\u7684\u89e3\u7801\u5668\u6a21\u578b\uff0c\u4e14\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u66f4\u5c11\u3002", "motivation": "\u4e34\u5e8a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9700\u8981\u9886\u57df\u7279\u5b9a\u7684\u6587\u672c\u5d4c\u5165\uff0c\u4f46\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u95f4\u7684\u7cfb\u7edf\u6bd4\u8f83\u4ecd\u7136\u6709\u9650\u3002", "method": "\u4f7f\u7528Low-Rank Adaptation (LoRA) \u5fae\u8c03\u65b9\u6cd5\uff0c\u5728106,535\u5bf9\u5fc3\u810f\u75c5\u5b66\u6587\u672c\u5bf9\u4e0a\u9002\u914d10\u79cdTransformer\u6a21\u578b\u3002", "result": "\u7f16\u7801\u5668\u67b6\u6784\uff08\u7279\u522b\u662fBioLinkBERT\uff09\u83b7\u5f97\u6700\u4f73\u9886\u57df\u7279\u5b9a\u6027\u80fd\uff08\u5206\u79bb\u5206\u6570\uff1a0.510\uff09\uff0c\u4e14\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u663e\u8457\u66f4\u5c11\u3002", "conclusion": "\u7814\u7a76\u6311\u6218\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5fc5\u7136\u4ea7\u751f\u66f4\u597d\u9886\u57df\u7279\u5b9a\u5d4c\u5165\u7684\u5047\u8bbe\uff0c\u4e3a\u4e34\u5e8aNLP\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\uff0c\u6240\u6709\u6a21\u578b\u548c\u6570\u636e\u96c6\u5df2\u516c\u5f00\u3002"}}
{"id": "2511.19757", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19757", "abs": "https://arxiv.org/abs/2511.19757", "authors": ["Colton Casto", "Anna Ivanova", "Evelina Fedorenko", "Nancy Kanwisher"], "title": "What does it mean to understand language?", "comment": null, "summary": "Language understanding entails not just extracting the surface-level meaning of the linguistic input, but constructing rich mental models of the situation it describes. Here we propose that because processing within the brain's core language system is fundamentally limited, deeply understanding language requires exporting information from the language system to other brain regions that compute perceptual and motor representations, construct mental models, and store our world knowledge and autobiographical memories. We review the existing evidence for this hypothesis, and argue that recent progress in cognitive neuroscience provides both the conceptual foundation and the methods to directly test it, thus opening up a new strategy to reveal what it means, cognitively and neurally, to understand language.", "AI": {"tldr": "\u8bed\u8a00\u7406\u89e3\u9700\u8981\u5c06\u4fe1\u606f\u4ece\u8bed\u8a00\u7cfb\u7edf\u5bfc\u51fa\u5230\u5176\u4ed6\u5927\u8111\u533a\u57df\u8fdb\u884c\u8ba1\u7b97\uff0c\u6784\u5efa\u4e30\u5bcc\u7684\u5fc3\u667a\u6a21\u578b\u3002", "motivation": "\u8bed\u8a00\u7406\u89e3\u4e0d\u4ec5\u4ec5\u662f\u63d0\u53d6\u8bed\u8a00\u8f93\u5165\u7684\u8868\u5c42\u610f\u4e49\uff0c\u8fd8\u9700\u8981\u6784\u5efa\u63cf\u8ff0\u60c5\u5883\u7684\u4e30\u5bcc\u5fc3\u667a\u6a21\u578b\u3002\u7531\u4e8e\u5927\u8111\u6838\u5fc3\u8bed\u8a00\u7cfb\u7edf\u7684\u5904\u7406\u80fd\u529b\u6709\u9650\uff0c\u6df1\u5ea6\u7406\u89e3\u8bed\u8a00\u9700\u8981\u5c06\u4fe1\u606f\u5bfc\u51fa\u5230\u5176\u4ed6\u8111\u533a\u3002", "method": "\u56de\u987e\u73b0\u6709\u8bc1\u636e\u652f\u6301\u8fd9\u4e00\u5047\u8bbe\uff0c\u5e76\u5229\u7528\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u7684\u6700\u65b0\u8fdb\u5c55\u63d0\u4f9b\u6982\u5ff5\u57fa\u7840\u548c\u65b9\u6cd5\u6765\u76f4\u63a5\u9a8c\u8bc1\u8be5\u5047\u8bbe\u3002", "result": "\u63d0\u51fa\u4e86\u63ed\u793a\u8bed\u8a00\u7406\u89e3\u5728\u8ba4\u77e5\u548c\u795e\u7ecf\u5c42\u9762\u542b\u4e49\u7684\u65b0\u7b56\u7565\u3002", "conclusion": "\u6df1\u5ea6\u8bed\u8a00\u7406\u89e3\u9700\u8981\u5c06\u4fe1\u606f\u4ece\u8bed\u8a00\u7cfb\u7edf\u5bfc\u51fa\u5230\u5176\u4ed6\u8111\u533a\uff0c\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u7684\u8fdb\u5c55\u4e3a\u76f4\u63a5\u9a8c\u8bc1\u8fd9\u4e00\u5047\u8bbe\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002"}}
{"id": "2511.19577", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.19577", "abs": "https://arxiv.org/abs/2511.19577", "authors": ["Abhay Goyal", "Navin Kumar", "Kimberly DiMeola", "Rafael Trujillo", "Soorya Ram Shimgekar", "Christian Poellabauer", "Pi Zonooz", "Ermonda Gjoni-Markaj", "Declan Barry", "Lynn Madden"], "title": "Using Wearable Devices to Improve Chronic PainTreatment among Patients with Opioid Use Disorder", "comment": null, "summary": "Chronic pain (CP) and opioid use disorder (OUD) are common and interrelated chronic medical conditions. Currently, there is a paucity of evidence-based integrated treatments for CP and OUD among individuals receiving medication for opioid use disorder (MOUD). Wearable devices have the potential to monitor complex patient information and inform treatment development for persons with OUD and CP, including pain variability (e.g., exacerbations of pain or pain spikes) and clinical correlates (e.g., perceived stress). However, the application of large language models (LLMs) with wearable data for understanding pain spikes, remains unexplored. Consequently, the aim of this pilot study was to examine the clinical correlates of pain spikes using a range of AI approaches. We found that machine learning models achieved relatively high accuracy (>0.7) in predicting pain spikes, while LLMs were limited in providing insights on pain spikes. Real-time monitoring through wearable devices, combined with advanced AI models, could facilitate early detection of pain spikes and support personalized interventions that may help mitigate the risk of opioid relapse, improve adherence to MOUD, and enhance the integration of CP and OUD care. Given overall limited LLM performance, these findings highlight the need to develop LLMs which can provide actionable insights in the OUD/CP context.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u7ed3\u5408\u53ef\u7a7f\u6234\u8bbe\u5907\u548cAI\u6280\u672f\u6765\u76d1\u6d4b\u6162\u6027\u75bc\u75db\u548c\u963f\u7247\u7c7b\u836f\u7269\u4f7f\u7528\u969c\u788d\u60a3\u8005\u7684\u75bc\u75db\u53d1\u4f5c\uff0c\u53d1\u73b0\u673a\u5668\u5b66\u4e60\u6a21\u578b\u80fd\u6709\u6548\u9884\u6d4b\u75bc\u75db\u53d1\u4f5c\uff0c\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u9886\u57df\u8868\u73b0\u6709\u9650\u3002", "motivation": "\u6162\u6027\u75bc\u75db\u548c\u963f\u7247\u7c7b\u836f\u7269\u4f7f\u7528\u969c\u788d\u662f\u76f8\u4e92\u5173\u8054\u7684\u6162\u6027\u75be\u75c5\uff0c\u76ee\u524d\u7f3a\u4e4f\u9488\u5bf9\u63a5\u53d7MOUD\u6cbb\u7597\u7684\u60a3\u8005\u7684\u5faa\u8bc1\u7efc\u5408\u6cbb\u7597\u65b9\u6848\u3002\u53ef\u7a7f\u6234\u8bbe\u5907\u6709\u6f5c\u529b\u76d1\u6d4b\u590d\u6742\u60a3\u8005\u4fe1\u606f\uff0c\u4f46LLMs\u5728\u7406\u89e3\u75bc\u75db\u53d1\u4f5c\u65b9\u9762\u7684\u5e94\u7528\u5c1a\u672a\u63a2\u7d22\u3002", "method": "\u4f7f\u7528\u53ef\u7a7f\u6234\u8bbe\u5907\u6536\u96c6\u60a3\u8005\u6570\u636e\uff0c\u91c7\u7528\u591a\u79cdAI\u65b9\u6cd5\uff08\u5305\u62ec\u673a\u5668\u5b66\u4e60\u548cLLMs\uff09\u5206\u6790\u75bc\u75db\u53d1\u4f5c\u7684\u4e34\u5e8a\u76f8\u5173\u6027\u3002", "result": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u9884\u6d4b\u75bc\u75db\u53d1\u4f5c\u65b9\u9762\u8fbe\u5230\u8f83\u9ad8\u51c6\u786e\u7387\uff08>0.7\uff09\uff0c\u4f46LLMs\u5728\u63d0\u4f9b\u75bc\u75db\u53d1\u4f5c\u6d1e\u5bdf\u65b9\u9762\u8868\u73b0\u6709\u9650\u3002", "conclusion": "\u53ef\u7a7f\u6234\u8bbe\u5907\u7ed3\u5408\u5148\u8fdbAI\u6a21\u578b\u53ef\u5b9e\u73b0\u75bc\u75db\u53d1\u4f5c\u7684\u65e9\u671f\u68c0\u6d4b\uff0c\u652f\u6301\u4e2a\u6027\u5316\u5e72\u9884\u3002\u9274\u4e8eLLMs\u6574\u4f53\u8868\u73b0\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u5728OUD/CP\u80cc\u666f\u4e0b\u63d0\u4f9b\u53ef\u64cd\u4f5c\u6d1e\u5bdf\u7684LLMs\u3002"}}
{"id": "2511.19785", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.19785", "abs": "https://arxiv.org/abs/2511.19785", "authors": ["Maureen Herbert", "Katie Sun", "Angelica Lim", "Yasaman Etesam"], "title": "Gender Bias in Emotion Recognition by Large Language Models", "comment": "Accepted at AAAI 2026 Workshop (WS37)", "summary": "The rapid advancement of large language models (LLMs) and their growing integration into daily life underscore the importance of evaluating and ensuring their fairness. In this work, we examine fairness within the domain of emotional theory of mind, investigating whether LLMs exhibit gender biases when presented with a description of a person and their environment and asked, \"How does this person feel?\". Furthermore, we propose and evaluate several debiasing strategies, demonstrating that achieving meaningful reductions in bias requires training based interventions rather than relying solely on inference-time prompt-based approaches such as prompt engineering.", "AI": {"tldr": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u60c5\u611f\u5fc3\u667a\u7406\u8bba\u4e2d\u7684\u6027\u522b\u504f\u89c1\uff0c\u5e76\u6bd4\u8f83\u4e0d\u540c\u53bb\u504f\u7b56\u7565\u7684\u6548\u679c\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65e5\u5e38\u751f\u6d3b\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u8bc4\u4f30\u548c\u786e\u4fdd\u5176\u516c\u5e73\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u672c\u7814\u7a76\u5173\u6ce8\u60c5\u611f\u5fc3\u667a\u7406\u8bba\u9886\u57df\u7684\u6027\u522b\u504f\u89c1\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5411\u6a21\u578b\u63cf\u8ff0\u4eba\u7269\u53ca\u5176\u73af\u5883\uff0c\u8be2\u95ee\"\u8fd9\u4e2a\u4eba\u611f\u89c9\u5982\u4f55\uff1f\"\u6765\u8bc4\u4f30\u6027\u522b\u504f\u89c1\u3002\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u591a\u79cd\u53bb\u504f\u7b56\u7565\uff0c\u5305\u62ec\u8bad\u7ec3\u5e72\u9884\u548c\u63a8\u7406\u65f6\u63d0\u793a\u5de5\u7a0b\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5b9e\u73b0\u6709\u610f\u4e49\u7684\u504f\u89c1\u51cf\u5c11\u9700\u8981\u57fa\u4e8e\u8bad\u7ec3\u5e72\u9884\u7684\u65b9\u6cd5\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u4f9d\u8d56\u63a8\u7406\u65f6\u7684\u63d0\u793a\u5de5\u7a0b\u65b9\u6cd5\u3002", "conclusion": "\u5728\u60c5\u611f\u5fc3\u667a\u7406\u8bba\u9886\u57df\uff0c\u6709\u6548\u51cf\u5c11\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u522b\u504f\u89c1\u9700\u8981\u8bad\u7ec3\u5c42\u9762\u7684\u5e72\u9884\u63aa\u65bd\uff0c\u63d0\u793a\u5de5\u7a0b\u7b49\u63a8\u7406\u65f6\u65b9\u6cd5\u7684\u53bb\u504f\u6548\u679c\u6709\u9650\u3002"}}
{"id": "2511.19663", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.19663", "abs": "https://arxiv.org/abs/2511.19663", "authors": ["Ahmed Awadallah", "Yash Lara", "Raghav Magazine", "Hussein Mozannar", "Akshay Nambi", "Yash Pandya", "Aravind Rajeswaran", "Corby Rosset", "Alexey Taymanov", "Vibhav Vineet", "Spencer Whitehead", "Andrew Zhao"], "title": "Fara-7B: An Efficient Agentic Model for Computer Use", "comment": null, "summary": "Progress in computer use agents (CUAs) has been constrained by the absence of large and high-quality datasets that capture how humans interact with a computer. While LLMs have thrived on abundant textual data, no comparable corpus exists for CUA trajectories. To address these gaps, we introduce FaraGen, a novel synthetic data generation system for multi-step web tasks. FaraGen can propose diverse tasks from frequently used websites, generate multiple solution attempts, and filter successful trajectories using multiple verifiers. It achieves high throughput, yield, and diversity for multi-step web tasks, producing verified trajectories at approximately $1 each. We use this data to train Fara-7B, a native CUA model that perceives the computer using only screenshots, executes actions via predicted coordinates, and is small enough to run on-device. We find that Fara-7B outperforms other CUA models of comparable size on benchmarks like WebVoyager, Online-Mind2Web, and WebTailBench -- our novel benchmark that better captures under-represented web tasks in pre-existing benchmarks. Furthermore, Fara-7B is competitive with much larger frontier models, illustrating key benefits of scalable data generation systems in advancing small efficient agentic models. We are making Fara-7B open-weight on Microsoft Foundry and HuggingFace, and we are releasing WebTailBench.", "AI": {"tldr": "FaraGen\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u6b65\u7f51\u9875\u4efb\u52a1\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u7cfb\u7edf\uff0c\u80fd\u591f\u751f\u6210\u591a\u6837\u5316\u7684\u4efb\u52a1\u548c\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4ee5\u4f4e\u6210\u672c\u4ea7\u751f\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u8f68\u8ff9\u3002\u57fa\u4e8e\u8fd9\u4e9b\u6570\u636e\u8bad\u7ec3\u7684Fara-7B\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u751a\u81f3\u80fd\u4e0e\u66f4\u5927\u7684\u524d\u6cbf\u6a21\u578b\u7ade\u4e89\u3002", "motivation": "\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\uff08CUA\uff09\u7684\u53d1\u5c55\u53d7\u5230\u7f3a\u4e4f\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u4eba\u7c7b\u4e0e\u8ba1\u7b97\u673a\u4ea4\u4e92\u6570\u636e\u7684\u9650\u5236\uff0c\u800cLLMs\u7684\u6210\u529f\u4f9d\u8d56\u4e8e\u4e30\u5bcc\u7684\u6587\u672c\u6570\u636e\uff0c\u56e0\u6b64\u9700\u8981\u89e3\u51b3CUA\u8f68\u8ff9\u6570\u636e\u7684\u7a00\u7f3a\u95ee\u9898\u3002", "method": "\u5f00\u53d1FaraGen\u7cfb\u7edf\uff0c\u4ece\u5e38\u7528\u7f51\u7ad9\u751f\u6210\u591a\u6837\u4efb\u52a1\uff0c\u4ea7\u751f\u591a\u4e2a\u89e3\u51b3\u65b9\u6848\u5c1d\u8bd5\uff0c\u5e76\u4f7f\u7528\u591a\u4e2a\u9a8c\u8bc1\u5668\u8fc7\u6ee4\u6210\u529f\u8f68\u8ff9\u3002\u5229\u7528\u8fd9\u4e9b\u6570\u636e\u8bad\u7ec3Fara-7B\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u4ec5\u901a\u8fc7\u622a\u56fe\u611f\u77e5\u8ba1\u7b97\u673a\uff0c\u901a\u8fc7\u9884\u6d4b\u5750\u6807\u6267\u884c\u52a8\u4f5c\uff0c\u4e14\u8db3\u591f\u5c0f\u53ef\u5728\u8bbe\u5907\u4e0a\u8fd0\u884c\u3002", "result": "Fara-7B\u5728WebVoyager\u3001Online-Mind2Web\u548cWebTailBench\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u540c\u7c7b\u89c4\u6a21\u7684CUA\u6a21\u578b\uff0c\u5e76\u4e14\u4e0e\u66f4\u5927\u7684\u524d\u6cbf\u6a21\u578b\u5177\u6709\u7ade\u4e89\u529b\u3002FaraGen\u80fd\u4ee5\u7ea61\u7f8e\u5143\u7684\u6210\u672c\u751f\u6210\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u8f68\u8ff9\u3002", "conclusion": "\u53ef\u6269\u5c55\u7684\u6570\u636e\u751f\u6210\u7cfb\u7edf\u5728\u63a8\u8fdb\u5c0f\u578b\u9ad8\u6548\u4ee3\u7406\u6a21\u578b\u65b9\u9762\u5177\u6709\u5173\u952e\u4f18\u52bf\uff0cFara-7B\u7684\u5f00\u653e\u6743\u91cd\u548cWebTailBench\u7684\u53d1\u5e03\u5c06\u4fc3\u8fdb\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.19816", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19816", "abs": "https://arxiv.org/abs/2511.19816", "authors": ["Saif M. Mohammad"], "title": "Breaking Bad: Norms for Valence, Arousal, and Dominance for over 10k English Multiword Expressions", "comment": null, "summary": "Factor analysis studies have shown that the primary dimensions of word meaning are Valence (V), Arousal (A), and Dominance (D). Existing lexicons such as the NRC VAD Lexicon, published in 2018, include VAD association ratings for words. Here, we present a complement to it, which has human ratings of valence, arousal, and dominance for 10k English Multiword Expressions (MWEs) and their constituent words. We also increase the coverage of unigrams, especially words that have become more common since 2018. In all, the new NRC VAD Lexicon v2 now has entries for 10k MWEs and 25k words, in addition to the entries in v1. We show that the associations are highly reliable. We use the lexicon to examine emotional characteristics of MWEs, including: 1. The degree to which MWEs (idioms, noun compounds, and verb particle constructions) exhibit strong emotionality; 2. The degree of emotional compositionality in MWEs. The lexicon enables a wide variety of research in NLP, Psychology, Public Health, Digital Humanities, and Social Sciences. The NRC VAD Lexicon v2 is freely available through the project webpage: http://saifmohammad.com/WebPages/nrc-vad.html", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86NRC VAD\u8bcd\u5178v2\u7248\u672c\uff0c\u589e\u52a0\u4e8610,000\u4e2a\u82f1\u8bed\u591a\u8bcd\u8868\u8fbe\u53ca\u5176\u7ec4\u6210\u8bcd\u7684VAD\u8bc4\u5206\uff0c\u5e76\u5c06\u5355\u8bed\u8bcd\u8986\u76d6\u6269\u5c55\u523025,000\u4e2a\u8bcd\uff0c\u9a8c\u8bc1\u4e86\u8bc4\u5206\u7684\u53ef\u9760\u6027\uff0c\u5e76\u5206\u6790\u4e86\u591a\u8bcd\u8868\u8fbe\u7684\u60c5\u611f\u7279\u5f81\u3002", "motivation": "\u73b0\u6709\u8bcd\u5178\u59822018\u5e74\u53d1\u5e03\u7684NRC VAD\u8bcd\u5178\u4ec5\u5305\u542b\u5355\u8bcd\u7684VAD\u5173\u8054\u8bc4\u5206\uff0c\u7f3a\u4e4f\u5bf9\u591a\u8bcd\u8868\u8fbe\u7684\u5206\u6790\uff0c\u4e14\u9700\u8981\u66f4\u65b0\u66f4\u5e38\u89c1\u7684\u8bcd\u6c47\u3002", "method": "\u6269\u5c55\u4e86NRC VAD\u8bcd\u5178\uff0c\u589e\u52a0\u4e8610,000\u4e2a\u591a\u8bcd\u8868\u8fbe\u53ca\u5176\u7ec4\u6210\u8bcd\u7684\u4eba\u7c7bVAD\u8bc4\u5206\uff0c\u5e76\u589e\u52a0\u4e862018\u5e74\u4ee5\u6765\u66f4\u5e38\u89c1\u8bcd\u6c47\u7684\u8986\u76d6\u3002", "result": "\u65b0\u7684NRC VAD\u8bcd\u5178v2\u5305\u542b10,000\u4e2a\u591a\u8bcd\u8868\u8fbe\u548c25,000\u4e2a\u5355\u8bcd\u7684\u6761\u76ee\uff0c\u8bc4\u5206\u9ad8\u5ea6\u53ef\u9760\uff0c\u53ef\u7528\u4e8e\u5206\u6790\u591a\u8bcd\u8868\u8fbe\u7684\u60c5\u611f\u5f3a\u5ea6\u548c\u60c5\u611f\u7ec4\u5408\u6027\u3002", "conclusion": "\u8be5\u8bcd\u5178\u4e3aNLP\u3001\u5fc3\u7406\u5b66\u3001\u516c\u5171\u536b\u751f\u3001\u6570\u5b57\u4eba\u6587\u548c\u793e\u4f1a\u79d1\u5b66\u7b49\u9886\u57df\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\uff0c\u652f\u6301\u5bf9\u591a\u8bcd\u8868\u8fbe\u60c5\u611f\u7279\u5f81\u7684\u6df1\u5165\u5206\u6790\u3002"}}
{"id": "2511.19669", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19669", "abs": "https://arxiv.org/abs/2511.19669", "authors": ["Souradip Poddar", "Chia-Tung Ho", "Ziming Wei", "Weidong Cao", "Haoxing Ren", "David Z. Pan"], "title": "HeaRT: A Hierarchical Circuit Reasoning Tree-Based Agentic Framework for AMS Design Optimization", "comment": null, "summary": "Conventional AI-driven AMS design automation algorithms remain constrained by their reliance on high-quality datasets to capture underlying circuit behavior, coupled with poor transferability across architectures, and a lack of adaptive mechanisms. This work proposes HeaRT, a foundational reasoning engine for automation loops and a first step toward intelligent, adaptive, human-style design optimization. HeaRT consistently demonstrates reasoning accuracy >97% and Pass@1 performance >98% across our 40-circuit benchmark repository, even as circuit complexity increases, while operating at <0.5x real-time token budget of SOTA baselines. Our experiments show that HeaRT yields >3x faster convergence in both sizing and topology design adaptation tasks across diverse optimization approaches, while preserving prior design intent.", "AI": {"tldr": "HeaRT\u662f\u4e00\u4e2a\u57fa\u7840\u63a8\u7406\u5f15\u64ce\uff0c\u7528\u4e8eAMS\u8bbe\u8ba1\u81ea\u52a8\u5316\u5faa\u73af\uff0c\u572840\u7535\u8def\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0>97%\u7684\u63a8\u7406\u51c6\u786e\u7387\u548c>98%\u7684Pass@1\u6027\u80fd\uff0c\u540c\u65f6\u4ec5\u9700SOTA\u57fa\u7ebf0.5x\u7684\u5b9e\u65f6token\u9884\u7b97\uff0c\u5728\u5c3a\u5bf8\u548c\u62d3\u6251\u8bbe\u8ba1\u9002\u5e94\u4efb\u52a1\u4e2d\u5b9e\u73b03\u500d\u4ee5\u4e0a\u7684\u6536\u655b\u52a0\u901f\u3002", "motivation": "\u4f20\u7edfAI\u9a71\u52a8\u7684AMS\u8bbe\u8ba1\u81ea\u52a8\u5316\u7b97\u6cd5\u53d7\u9650\u4e8e\u5bf9\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u7684\u4f9d\u8d56\u3001\u8de8\u67b6\u6784\u53ef\u79fb\u690d\u6027\u5dee\u4ee5\u53ca\u7f3a\u4e4f\u81ea\u9002\u5e94\u673a\u5236\u3002", "method": "\u63d0\u51faHeaRT\u57fa\u7840\u63a8\u7406\u5f15\u64ce\uff0c\u4f5c\u4e3a\u667a\u80fd\u3001\u81ea\u9002\u5e94\u3001\u7c7b\u4eba\u8bbe\u8ba1\u4f18\u5316\u7684\u7b2c\u4e00\u6b65\u3002", "result": "\u572840\u7535\u8def\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5373\u4f7f\u7535\u8def\u590d\u6742\u5ea6\u589e\u52a0\uff0cHeaRT\u4ecd\u4fdd\u6301>97%\u7684\u63a8\u7406\u51c6\u786e\u7387\u548c>98%\u7684Pass@1\u6027\u80fd\uff0c\u4ec5\u9700SOTA\u57fa\u7ebf0.5x\u7684\u5b9e\u65f6token\u9884\u7b97\uff0c\u5728\u5c3a\u5bf8\u548c\u62d3\u6251\u8bbe\u8ba1\u9002\u5e94\u4efb\u52a1\u4e2d\u5b9e\u73b0>3\u500d\u7684\u6536\u655b\u52a0\u901f\u3002", "conclusion": "HeaRT\u662f\u8fc8\u5411\u667a\u80fd\u81ea\u9002\u5e94AMS\u8bbe\u8ba1\u81ea\u52a8\u5316\u7684\u6709\u6548\u7b2c\u4e00\u6b65\uff0c\u5728\u4fdd\u6301\u5148\u524d\u8bbe\u8ba1\u610f\u56fe\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8bbe\u8ba1\u6548\u7387\u3002"}}
{"id": "2511.19818", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19818", "abs": "https://arxiv.org/abs/2511.19818", "authors": ["Koena Ronny Mabokela", "Tim Schlippe", "Mpho Raborife", "Turgay Celik"], "title": "Language-Independent Sentiment Labelling with Distant Supervision: A Case Study for English, Sepedi and Setswana", "comment": "Published in the The Fourth Workshop on Processing Emotions, Decisions and Opinions (EDO 2023) at 10th Language & Technology Conference: Human Language Technologies as a Challenge for Computer Science and Linguistics (LTC 2023), Pozna\u0144, Poland, 21-23 April 2023. ISBN: 978-83-232-4176-8", "summary": "Sentiment analysis is a helpful task to automatically analyse opinions and emotions on various topics in areas such as AI for Social Good, AI in Education or marketing. While many of the sentiment analysis systems are developed for English, many African languages are classified as low-resource languages due to the lack of digital language resources like text labelled with corresponding sentiment classes. One reason for that is that manually labelling text data is time-consuming and expensive. Consequently, automatic and rapid processes are needed to reduce the manual effort as much as possible making the labelling process as efficient as possible. In this paper, we present and analyze an automatic language-independent sentiment labelling method that leverages information from sentiment-bearing emojis and words. Our experiments are conducted with tweets in the languages English, Sepedi and Setswana from SAfriSenti, a multilingual sentiment corpus for South African languages. We show that our sentiment labelling approach is able to label the English tweets with an accuracy of 66%, the Sepedi tweets with 69%, and the Setswana tweets with 63%, so that on average only 34% of the automatically generated labels remain to be corrected.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u8868\u60c5\u7b26\u53f7\u548c\u60c5\u611f\u8bcd\u6c47\u7684\u81ea\u52a8\u8bed\u8a00\u65e0\u5173\u60c5\u611f\u6807\u6ce8\u65b9\u6cd5\uff0c\u5728\u82f1\u8bed\u3001Sepedi\u548cSetswana\u63a8\u6587\u4e0a\u5206\u522b\u8fbe\u523066%\u300169%\u548c63%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u975e\u6d32\u8bed\u8a00\u56e0\u7f3a\u4e4f\u6807\u6ce8\u6570\u636e\u800c\u88ab\u5f52\u7c7b\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\uff0c\u624b\u52a8\u6807\u6ce8\u8017\u65f6\u4e14\u6602\u8d35\uff0c\u9700\u8981\u81ea\u52a8\u5316\u6d41\u7a0b\u6765\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\u3002", "method": "\u5229\u7528\u5305\u542b\u60c5\u611f\u7684\u8868\u60c5\u7b26\u53f7\u548c\u8bcd\u6c47\u4fe1\u606f\u8fdb\u884c\u81ea\u52a8\u8bed\u8a00\u65e0\u5173\u7684\u60c5\u611f\u6807\u6ce8\u3002", "result": "\u5728SAfriSenti\u591a\u8bed\u8a00\u60c5\u611f\u8bed\u6599\u5e93\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u82f1\u8bed\u63a8\u6587\u51c6\u786e\u738766%\uff0cSepedi\u63a8\u658769%\uff0cSetswana\u63a8\u658763%\uff0c\u5e73\u5747\u53ea\u9700\u4fee\u6b6334%\u7684\u81ea\u52a8\u751f\u6210\u6807\u7b7e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u60c5\u611f\u6807\u6ce8\u7684\u4eba\u5de5\u5de5\u4f5c\u91cf\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u60c5\u611f\u5206\u6790\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19671", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19671", "abs": "https://arxiv.org/abs/2511.19671", "authors": ["Rishab Sharma", "Iman Saberi", "Elham Alipour", "Jie JW Wu", "Fatemeh Fard"], "title": "FISCAL: Financial Synthetic Claim-document Augmented Learning for Efficient Fact-Checking", "comment": "3 tables, 11 pages, 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Generative AI in Finance", "summary": "Financial applications of large language models (LLMs) require factual reliability and computational efficiency, yet current systems often hallucinate details and depend on prohibitively large models. We propose FISCAL (Financial Synthetic Claim-Document Augmented Learning), a modular framework for generating synthetic data tailored to financial fact-checking. Using FISCAL, we generate a dataset called FISCAL-data and use it to train MiniCheck-FISCAL, a lightweight verifier for numerical financial claims. MiniCheck-FISCAL outperforms its baseline, surpasses GPT-3.5 Turbo and other open-source peers of similar size, and approaches the accuracy of much larger systems (20x), such as Mixtral-8x22B and Command R+. On external datasets FinDVer and Fin-Fact, it rivals GPT-4o and Claude-3.5 while outperforming Gemini-1.5 Flash. These results show that domain-specific synthetic data, combined with efficient fine-tuning, enables compact models to achieve state-of-the-art accuracy, robustness, and scalability for practical financial AI. The dataset and scripts are available in the project repository (link provided in the paper).", "AI": {"tldr": "FISCAL\u6846\u67b6\u901a\u8fc7\u751f\u6210\u91d1\u878d\u9886\u57df\u7279\u5b9a\u7684\u5408\u6210\u6570\u636e\uff0c\u8bad\u7ec3\u51fa\u8f7b\u91cf\u7ea7\u9a8c\u8bc1\u5668MiniCheck-FISCAL\uff0c\u5728\u91d1\u878d\u4e8b\u5b9e\u6838\u67e5\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8d85\u8d8aGPT-3.5 Turbo\u7b49\u6a21\u578b\uff0c\u63a5\u8fd1\u66f4\u5927\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u91d1\u878d\u9886\u57df\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u4e8b\u5b9e\u53ef\u9760\u6027\u4e0d\u8db3\u548c\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u65e2\u51c6\u786e\u53c8\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faFISCAL\u6846\u67b6\u751f\u6210\u91d1\u878d\u5408\u6210\u6570\u636e\uff0c\u7528\u4e8e\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u9a8c\u8bc1\u5668MiniCheck-FISCAL\u8fdb\u884c\u91d1\u878d\u4e8b\u5b9e\u6838\u67e5\u3002", "result": "MiniCheck-FISCAL\u5728\u591a\u4e2a\u91d1\u878d\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8aGPT-3.5 Turbo\u7b49\u6a21\u578b\uff0c\u63a5\u8fd1Mixtral-8x22B\u7b49\u5927\u6a21\u578b\u7684\u51c6\u786e\u6027\uff0c\u5728\u5916\u90e8\u6570\u636e\u96c6\u4e0a\u53ef\u4e0eGPT-4o\u548cClaude-3.5\u76f8\u5ab2\u7f8e\u3002", "conclusion": "\u9886\u57df\u7279\u5b9a\u7684\u5408\u6210\u6570\u636e\u4e0e\u9ad8\u6548\u5fae\u8c03\u76f8\u7ed3\u5408\uff0c\u53ef\u4f7f\u7d27\u51d1\u6a21\u578b\u5728\u91d1\u878dAI\u5e94\u7528\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.19852", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19852", "abs": "https://arxiv.org/abs/2511.19852", "authors": ["Shi-Wei Dai", "Yan-Wei Shie", "Tsung-Huan Yang", "Lun-Wei Ku", "Yung-Hui Li"], "title": "Profile-LLM: Dynamic Profile Optimization for Realistic Personality Expression in LLMs", "comment": null, "summary": "Personalized Large Language Models (LLMs) have been shown to be an effective way to create more engaging and enjoyable user-AI interactions. While previous studies have explored using prompts to elicit specific personality traits in LLMs, they have not optimized these prompts to maximize personality expression. To address this limitation, we propose PersonaPulse: Dynamic Profile Optimization for Realistic Personality Expression in LLMs, a framework that leverages LLMs' inherent knowledge of personality traits to iteratively enhance role-play prompts while integrating a situational response benchmark as a scoring tool, ensuring a more realistic and contextually grounded evaluation to guide the optimization process. Quantitative evaluations demonstrate that the prompts generated by PersonaPulse outperform those of prior work, which were designed based on personality descriptions from psychological studies. Additionally, we explore the relationship between model size and personality modeling through extensive experiments. Finally, we find that, for certain personality traits, the extent of personality evocation can be partially controlled by pausing the optimization process. These findings underscore the importance of prompt optimization in shaping personality expression within LLMs, offering valuable insights for future research on adaptive AI interactions.", "AI": {"tldr": "\u63d0\u51fa\u4e86PersonaPulse\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u4f18\u5316\u89d2\u8272\u626e\u6f14\u63d0\u793a\u8bcd\u6765\u6700\u5927\u5316LLM\u7684\u4e2a\u6027\u8868\u8fbe\uff0c\u4f7f\u7528\u60c5\u5883\u54cd\u5e94\u57fa\u51c6\u4f5c\u4e3a\u8bc4\u5206\u5de5\u5177\u8fdb\u884c\u66f4\u73b0\u5b9e\u7684\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u867d\u7136\u63a2\u7d22\u4e86\u4f7f\u7528\u63d0\u793a\u8bcd\u6765\u6fc0\u53d1LLM\u7684\u7279\u5b9a\u4e2a\u6027\u7279\u5f81\uff0c\u4f46\u672a\u4f18\u5316\u8fd9\u4e9b\u63d0\u793a\u8bcd\u4ee5\u6700\u5927\u5316\u4e2a\u6027\u8868\u8fbe\u3002", "method": "\u5229\u7528LLM\u5bf9\u4e2a\u6027\u7279\u5f81\u7684\u56fa\u6709\u77e5\u8bc6\u8fed\u4ee3\u589e\u5f3a\u89d2\u8272\u626e\u6f14\u63d0\u793a\u8bcd\uff0c\u540c\u65f6\u6574\u5408\u60c5\u5883\u54cd\u5e94\u57fa\u51c6\u4f5c\u4e3a\u8bc4\u5206\u5de5\u5177\uff0c\u786e\u4fdd\u66f4\u73b0\u5b9e\u548c\u60c5\u5883\u5316\u7684\u8bc4\u4f30\u6765\u6307\u5bfc\u4f18\u5316\u8fc7\u7a0b\u3002", "result": "\u5b9a\u91cf\u8bc4\u4f30\u663e\u793aPersonaPulse\u751f\u6210\u7684\u63d0\u793a\u8bcd\u4f18\u4e8e\u5148\u524d\u57fa\u4e8e\u5fc3\u7406\u5b66\u7814\u7a76\u8bbe\u8ba1\u7684\u65b9\u6cd5\uff1b\u63a2\u7d22\u4e86\u6a21\u578b\u5927\u5c0f\u4e0e\u4e2a\u6027\u5efa\u6a21\u7684\u5173\u7cfb\uff1b\u53d1\u73b0\u67d0\u4e9b\u4e2a\u6027\u7279\u5f81\u7684\u6fc0\u53d1\u7a0b\u5ea6\u53ef\u4ee5\u901a\u8fc7\u6682\u505c\u4f18\u5316\u8fc7\u7a0b\u6765\u90e8\u5206\u63a7\u5236\u3002", "conclusion": "\u63d0\u793a\u8bcd\u4f18\u5316\u5728\u5851\u9020LLM\u4e2a\u6027\u8868\u8fbe\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u672a\u6765\u81ea\u9002\u5e94AI\u4ea4\u4e92\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\u3002"}}
{"id": "2511.19749", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19749", "abs": "https://arxiv.org/abs/2511.19749", "authors": ["Farzan Karimi-Malekabadi", "Pooya Razavi", "Sonya Powers"], "title": "Scaling Item-to-Standard Alignment with Large Language Models: Accuracy, Limits, and Solutions", "comment": null, "summary": "As educational systems evolve, ensuring that assessment items remain aligned with content standards is essential for maintaining fairness and instructional relevance. Traditional human alignment reviews are accurate but slow and labor-intensive, especially across large item banks. This study examines whether Large Language Models (LLMs) can accelerate this process without sacrificing accuracy. Using over 12,000 item-skill pairs in grades K-5, we tested three LLMs (GPT-3.5 Turbo, GPT-4o-mini, and GPT-4o) across three tasks that mirror real-world challenges: identifying misaligned items, selecting the correct skill from the full set of standards, and narrowing candidate lists prior to classification. In Study 1, GPT-4o-mini correctly identified alignment status in approximately 83-94% of cases, including subtle misalignments. In Study 2, performance remained strong in mathematics but was lower for reading, where standards are more semantically overlapping. Study 3 demonstrated that pre-filtering candidate skills substantially improved results, with the correct skill appearing among the top five suggestions more than 95% of the time. These findings suggest that LLMs, particularly when paired with candidate filtering strategies, can significantly reduce the manual burden of item review while preserving alignment accuracy. We recommend the development of hybrid pipelines that combine LLM-based screening with human review in ambiguous cases, offering a scalable solution for ongoing item validation and instructional alignment.", "AI": {"tldr": "LLMs can accelerate educational assessment alignment review with 83-94% accuracy, significantly reducing manual workload while maintaining alignment quality.", "motivation": "\u4f20\u7edf\u4eba\u5de5\u5bf9\u9f50\u8bc4\u5ba1\u51c6\u786e\u4f46\u8017\u65f6\u8d39\u529b\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u9898\u5e93\u4e2d\u3002\u9700\u8981\u63a2\u7d22LLM\u80fd\u5426\u5728\u4e0d\u727a\u7272\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\u52a0\u901f\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "\u4f7f\u752812,000\u591a\u4e2aK-5\u5e74\u7ea7\u9898\u76ee-\u6280\u80fd\u5bf9\uff0c\u6d4b\u8bd5\u4e86\u4e09\u79cdLLM\uff08GPT-3.5 Turbo\u3001GPT-4o-mini\u3001GPT-4o\uff09\u5728\u4e09\u4e2a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff1a\u8bc6\u522b\u672a\u5bf9\u9f50\u9898\u76ee\u3001\u4ece\u5b8c\u6574\u6807\u51c6\u96c6\u4e2d\u9009\u62e9\u6b63\u786e\u6280\u80fd\u3001\u5728\u5206\u7c7b\u524d\u7f29\u5c0f\u5019\u9009\u5217\u8868\u3002", "result": "GPT-4o-mini\u572883-94%\u7684\u60c5\u51b5\u4e0b\u6b63\u786e\u8bc6\u522b\u5bf9\u9f50\u72b6\u6001\uff1b\u6570\u5b66\u8868\u73b0\u5f3a\u52b2\uff0c\u9605\u8bfb\u8868\u73b0\u8f83\u4f4e\uff1b\u9884\u8fc7\u6ee4\u5019\u9009\u6280\u80fd\u53ef\u5c06\u6b63\u786e\u6280\u80fd\u51fa\u73b0\u5728\u524d5\u5efa\u8bae\u7684\u6982\u7387\u63d0\u5347\u81f395%\u4ee5\u4e0a\u3002", "conclusion": "LLM\u7279\u522b\u662f\u7ed3\u5408\u5019\u9009\u8fc7\u6ee4\u7b56\u7565\uff0c\u80fd\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u8bc4\u5ba1\u8d1f\u62c5\u5e76\u4fdd\u6301\u5bf9\u9f50\u51c6\u786e\u6027\u3002\u5efa\u8bae\u5f00\u53d1\u6df7\u5408\u6d41\u7a0b\uff0c\u5c06\u57fa\u4e8eLLM\u7684\u7b5b\u9009\u4e0e\u4eba\u5de5\u8bc4\u5ba1\u76f8\u7ed3\u5408\uff0c\u4e3a\u6301\u7eed\u9898\u76ee\u9a8c\u8bc1\u548c\u6559\u5b66\u5bf9\u9f50\u63d0\u4f9b\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19858", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19858", "abs": "https://arxiv.org/abs/2511.19858", "authors": ["Farzad Ahmed", "Joniel Augustine Jerome", "Meliha Yetisgen", "\u00d6zlem Uzuner"], "title": "A Systematic Analysis of Large Language Models with RAG-enabled Dynamic Prompting for Medical Error Detection and Correction", "comment": null, "summary": "Objective: Clinical documentation contains factual, diagnostic, and management errors that can compromise patient safety. Large language models (LLMs) may help detect and correct such errors, but their behavior under different prompting strategies remains unclear. We evaluate zero-shot prompting, static prompting with random exemplars (SPR), and retrieval-augmented dynamic prompting (RDP) for three subtasks of medical error processing: error flag detection, error sentence detection, and error correction.\n  Methods: Using the MEDEC dataset, we evaluated nine instruction-tuned LLMs (GPT, Claude, Gemini, and OpenAI o-series models). We measured performance using accuracy, recall, false-positive rate (FPR), and an aggregate score of ROUGE-1, BLEURT, and BERTScore for error correction. We also analyzed example outputs to identify failure modes and differences between LLM and clinician reasoning.\n  Results: Zero-shot prompting showed low recall in both detection tasks, often missing abbreviation-heavy or atypical errors. SPR improved recall but increased FPR. Across all nine LLMs, RDP reduced FPR by about 15 percent, improved recall by 5 to 10 percent in error sentence detection, and generated more contextually accurate corrections.\n  Conclusion: Across diverse LLMs, RDP outperforms zero-shot and SPR prompting. Using retrieved exemplars improves detection accuracy, reduces false positives, and enhances the reliability of medical error correction.", "AI": {"tldr": "\u8bc4\u4f30\u4e09\u79cd\u63d0\u793a\u7b56\u7565\uff08\u96f6\u6837\u672c\u63d0\u793a\u3001\u9759\u6001\u968f\u673a\u793a\u4f8b\u63d0\u793a\u3001\u68c0\u7d22\u589e\u5f3a\u52a8\u6001\u63d0\u793a\uff09\u5728\u533b\u7597\u9519\u8bef\u5904\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u68c0\u7d22\u589e\u5f3a\u52a8\u6001\u63d0\u793a\u5728\u591a\u4e2aLLM\u4e2d\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u4e34\u5e8a\u6587\u6863\u4e2d\u5b58\u5728\u4e8b\u5b9e\u3001\u8bca\u65ad\u548c\u7ba1\u7406\u9519\u8bef\uff0c\u53ef\u80fd\u5371\u53ca\u60a3\u8005\u5b89\u5168\u3002LLM\u53ef\u80fd\u5e2e\u52a9\u68c0\u6d4b\u548c\u7ea0\u6b63\u8fd9\u4e9b\u9519\u8bef\uff0c\u4f46\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u4e0b\u7684\u884c\u4e3a\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u4f7f\u7528MEDEC\u6570\u636e\u96c6\u8bc4\u4f309\u4e2a\u6307\u4ee4\u8c03\u4f18\u7684LLM\uff0c\u6bd4\u8f83\u4e09\u79cd\u63d0\u793a\u7b56\u7565\u5728\u9519\u8bef\u6807\u8bb0\u68c0\u6d4b\u3001\u9519\u8bef\u53e5\u5b50\u68c0\u6d4b\u548c\u9519\u8bef\u7ea0\u6b63\u4e09\u4e2a\u5b50\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4f7f\u7528\u51c6\u786e\u7387\u3001\u53ec\u56de\u7387\u3001\u5047\u9633\u6027\u7387\u548c\u7efc\u5408\u8bc4\u5206\u6307\u6807\u3002", "result": "\u68c0\u7d22\u589e\u5f3a\u52a8\u6001\u63d0\u793a\u5c06\u5047\u9633\u6027\u7387\u964d\u4f4e\u7ea615%\uff0c\u5728\u9519\u8bef\u53e5\u5b50\u68c0\u6d4b\u4e2d\u53ec\u56de\u7387\u63d0\u9ad85-10%\uff0c\u5e76\u751f\u6210\u66f4\u7b26\u5408\u4e0a\u4e0b\u6587\u7684\u7ea0\u6b63\u3002", "conclusion": "\u68c0\u7d22\u589e\u5f3a\u52a8\u6001\u63d0\u793a\u4f18\u4e8e\u96f6\u6837\u672c\u548c\u9759\u6001\u968f\u673a\u793a\u4f8b\u63d0\u793a\uff0c\u4f7f\u7528\u68c0\u7d22\u793a\u4f8b\u63d0\u9ad8\u4e86\u68c0\u6d4b\u51c6\u786e\u6027\uff0c\u51cf\u5c11\u4e86\u5047\u9633\u6027\uff0c\u589e\u5f3a\u4e86\u533b\u7597\u9519\u8bef\u7ea0\u6b63\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.19773", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.19773", "abs": "https://arxiv.org/abs/2511.19773", "authors": ["Meng Lu", "Ran Xu", "Yi Fang", "Wenxuan Zhang", "Yue Yu", "Gaurav Srivastava", "Yuchen Zhuang", "Mohamed Elhoseiny", "Charles Fleming", "Carl Yang", "Zhengzhong Tu", "Yang Xie", "Guanghua Xiao", "Hanrui Wang", "Di Jin", "Wenqi Shi", "Xuan Wang"], "title": "Scaling Agentic Reinforcement Learning for Tool-Integrated Reasoning in VLMs", "comment": "17 pages, 9 figures, work in progress", "summary": "While recent vision-language models (VLMs) demonstrate strong image understanding, their ability to \"think with images\", i.e., to reason through multi-step visual interactions, remains limited. We introduce VISTA-Gym, a scalable training environment for incentivizing tool-integrated visual reasoning capabilities in VLMs. VISTA-Gym unifies diverse real-world multimodal reasoning tasks (7 tasks from 13 datasets in total) with a standardized interface for visual tools (e.g., grounding, parsing), executable interaction loops, verifiable feedback signals, and efficient trajectory logging, enabling visual agentic reinforcement learning at scale. While recent VLMs exhibit strong text-only reasoning, both proprietary and open-source models still struggle with tool selection, invocation, and coordination. With VISTA-Gym, we train VISTA-R1 to interleave tool-use with agentic reasoning via multi-turn trajectory sampling and end-to-end reinforcement learning. Extensive experiments across 11 public reasoning-intensive VQA benchmarks show that VISTA-R1-8B outperforms state-of-the-art baselines with similar sizes by 9.51%-18.72%, demonstrating VISTA-Gym as an effective training ground to unlock the tool-integrated reasoning capabilities for VLMs.", "AI": {"tldr": "VISTA-Gym\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u8bad\u7ec3\u73af\u5883\uff0c\u7528\u4e8e\u589e\u5f3a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6b65\u9aa4\u89c6\u89c9\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u7edf\u4e00\u591a\u6a21\u6001\u4efb\u52a1\u63a5\u53e3\u548c\u5de5\u5177\u96c6\u6210\uff0c\u8bad\u7ec3\u51fa\u7684VISTA-R1\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u540c\u7c7b\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u50cf\u7406\u89e3\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u591a\u6b65\u9aa4\u89c6\u89c9\u63a8\u7406\u548c\u5de5\u5177\u96c6\u6210\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u9700\u8981\u4e13\u95e8\u7684\u8bad\u7ec3\u73af\u5883\u6765\u63d0\u5347\u8fd9\u4e9b\u80fd\u529b\u3002", "method": "\u5f00\u53d1VISTA-Gym\u8bad\u7ec3\u73af\u5883\uff0c\u7edf\u4e007\u4e2a\u4efb\u52a113\u4e2a\u6570\u636e\u96c6\u7684\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\uff0c\u63d0\u4f9b\u6807\u51c6\u5316\u89c6\u89c9\u5de5\u5177\u63a5\u53e3\u3001\u53ef\u6267\u884c\u4ea4\u4e92\u5faa\u73af\u548c\u53cd\u9988\u4fe1\u53f7\uff0c\u901a\u8fc7\u591a\u8f6e\u8f68\u8ff9\u91c7\u6837\u548c\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3VISTA-R1\u6a21\u578b\u3002", "result": "VISTA-R1-8B\u572811\u4e2a\u63a8\u7406\u5bc6\u96c6\u578bVQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6bd4\u540c\u7c7b\u6700\u4f18\u57fa\u7ebf\u6a21\u578b\u6027\u80fd\u63d0\u53479.51%-18.72%\u3002", "conclusion": "VISTA-Gym\u662f\u89e3\u9501\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5de5\u5177\u96c6\u6210\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u8bad\u7ec3\u5e73\u53f0\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u590d\u6742\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2511.19957", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19957", "abs": "https://arxiv.org/abs/2511.19957", "authors": ["Tianyi Chen", "Michael Solodko", "Sen Wang", "Jongwoo Ko", "Junheng Hao", "Colby Banbury", "Sara Abdali", "Saeed Amizadeh", "Qing Xiao", "Yinheng Li", "Tianyu Ding", "Kamran Ghasedi Dizaji", "Suzhen Zheng", "Hao Fan", "Justin Wagle", "Pashmina Cameron", "Kazuhito Koishida"], "title": "AppSelectBench: Application-Level Tool Selection Benchmark", "comment": null, "summary": "Computer Using Agents (CUAs) are increasingly equipped with external tools, enabling them to perform complex and realistic tasks. For CUAs to operate effectively, application selection, which refers to deciding which application to use before invoking fine-grained tools such as APIs, is a fundamental capability. It determines whether the agent initializes the correct environment, avoids orchestration confusion, and efficiently focuses on relevant context. However, existing benchmarks primarily assess fine-grained API selection, offering limited insight into whether models can reason across and choose between different applications. To fill this gap, we introduce AppSelectBench, a comprehensive benchmark for evaluating application selection in CUAs. AppSelectBench contains a novel user task generation pipeline that produces realistic, diverse, and semantically grounded user intents at scale, together with unified evaluation protocols covering random, heuristic, zero-shot, few-shot, and retrieval-augmented-settings. AppSelectBench covers one hundred widely used desktop applications and includes more than one hundred thousand realistic, diverse, and semantically grounded user tasks. Extensive experiments across both closed-source and open-source large language models reveal systematic strengths and weaknesses in inter-application reasoning, showing that even the most capable models still struggle to make consistent application choices. Together, these results establish AppSelectBench as a foundation for studying and advancing application level reasoning, an essential yet underexplored capability of intelligent CUAs. The source is available at https://github.com/microsoft/appselectbench.", "AI": {"tldr": "\u63d0\u51fa\u4e86AppSelectBench\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\uff08CUAs\uff09\u5728\u5e94\u7528\u9009\u62e9\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5305\u542b10\u4e07\u4e2a\u771f\u5b9e\u7528\u6237\u4efb\u52a1\u548c100\u4e2a\u684c\u9762\u5e94\u7528\uff0c\u586b\u8865\u4e86\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u7ec6\u7c92\u5ea6API\u9009\u62e9\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u7ec6\u7c92\u5ea6API\u9009\u62e9\uff0c\u65e0\u6cd5\u8861\u91cf\u6a21\u578b\u5728\u4e0d\u540c\u5e94\u7528\u95f4\u8fdb\u884c\u63a8\u7406\u548c\u9009\u62e9\u7684\u80fd\u529b\uff0c\u800c\u5e94\u7528\u9009\u62e9\u662fCUAs\u6709\u6548\u8fd0\u884c\u7684\u57fa\u672c\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u4e86\u7528\u6237\u4efb\u52a1\u751f\u6210\u6d41\u6c34\u7ebf\uff0c\u521b\u5efa\u771f\u5b9e\u3001\u591a\u6837\u4e14\u8bed\u4e49\u57fa\u7840\u7684\u7528\u6237\u610f\u56fe\uff0c\u5e76\u8bbe\u8ba1\u4e86\u7edf\u4e00\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u5305\u62ec\u968f\u673a\u3001\u542f\u53d1\u5f0f\u3001\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u548c\u68c0\u7d22\u589e\u5f3a\u8bbe\u7f6e\u3002", "result": "\u5bf9\u95ed\u6e90\u548c\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u63ed\u793a\u4e86\u5728\u8de8\u5e94\u7528\u63a8\u7406\u65b9\u9762\u7684\u7cfb\u7edf\u6027\u4f18\u52bf\u548c\u5f31\u70b9\uff0c\u5373\u4f7f\u6700\u5f3a\u5927\u7684\u6a21\u578b\u4e5f\u96be\u4ee5\u505a\u51fa\u4e00\u81f4\u7684\u5e94\u7528\u9009\u62e9\u3002", "conclusion": "AppSelectBench\u4e3a\u7814\u7a76\u548c\u63a8\u8fdb\u5e94\u7528\u7ea7\u63a8\u7406\u80fd\u529b\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u8fd9\u662f\u667a\u80fdCUAs\u91cd\u8981\u4f46\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u7684\u80fd\u529b\u3002"}}
{"id": "2511.19780", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19780", "abs": "https://arxiv.org/abs/2511.19780", "authors": ["Ioannis Tzachristas", "Aifen Sui"], "title": "NOEM$^{3}$A: A Neuro-Symbolic Ontology-Enhanced Method for Multi-Intent Understanding in Mobile Agents", "comment": null, "summary": "We introduce a neuro-symbolic framework for multi-intent understanding in mobile AI agents by integrating a structured intent ontology with compact language models. Our method leverages retrieval-augmented prompting, logit biasing and optional classification heads to inject symbolic intent structure into both input and output representations. We formalize a new evaluation metric-Semantic Intent Similarity (SIS)-based on hierarchical ontology depth, capturing semantic proximity even when predicted intents differ lexically. Experiments on a subset of ambiguous/demanding dialogues of MultiWOZ 2.3 (with oracle labels from GPT-o3) demonstrate that a 3B Llama model with ontology augmentation approaches GPT-4 accuracy (85% vs 90%) at a tiny fraction of the energy and memory footprint. Qualitative comparisons show that ontology-augmented models produce more grounded, disambiguated multi-intent interpretations. Our results validate symbolic alignment as an effective strategy for enabling accurate and efficient on-device NLU.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u7ed3\u6784\u5316\u610f\u56fe\u672c\u4f53\u4e0e\u7d27\u51d1\u8bed\u8a00\u6a21\u578b\u96c6\u6210\uff0c\u5b9e\u73b0\u79fb\u52a8AI\u4ee3\u7406\u7684\u591a\u610f\u56fe\u7406\u89e3\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u68c0\u7d22\u589e\u5f3a\u63d0\u793a\u3001logit\u504f\u7f6e\u548c\u53ef\u9009\u5206\u7c7b\u5934\uff0c\u5c06\u7b26\u53f7\u610f\u56fe\u7ed3\u6784\u6ce8\u5165\u8f93\u5165\u548c\u8f93\u51fa\u8868\u793a\u4e2d\u3002", "motivation": "\u89e3\u51b3\u79fb\u52a8AI\u4ee3\u7406\u4e2d\u591a\u610f\u56fe\u7406\u89e3\u7684\u6311\u6218\uff0c\u901a\u8fc7\u7b26\u53f7\u5bf9\u9f50\u7b56\u7565\u5b9e\u73b0\u51c6\u786e\u9ad8\u6548\u7684\u8bbe\u5907\u7aef\u81ea\u7136\u8bed\u8a00\u7406\u89e3\uff0c\u51cf\u5c11\u5bf9\u5927\u578b\u6a21\u578b\u7684\u4f9d\u8d56\u3002", "method": "\u96c6\u6210\u7ed3\u6784\u5316\u610f\u56fe\u672c\u4f53\u4e0e\u7d27\u51d1\u8bed\u8a00\u6a21\u578b\uff0c\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u63d0\u793a\u3001logit\u504f\u7f6e\u548c\u53ef\u9009\u5206\u7c7b\u5934\uff0c\u5c06\u7b26\u53f7\u610f\u56fe\u7ed3\u6784\u6ce8\u5165\u8f93\u5165\u548c\u8f93\u51fa\u8868\u793a\u3002", "result": "\u5728MultiWOZ 2.3\u7684\u6a21\u7cca/\u590d\u6742\u5bf9\u8bdd\u5b50\u96c6\u4e0a\uff0c3B\u53c2\u6570\u7684Llama\u6a21\u578b\u901a\u8fc7\u672c\u4f53\u589e\u5f3a\u63a5\u8fd1GPT-4\u7684\u51c6\u786e\u7387\uff0885% vs 90%\uff09\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u80fd\u8017\u548c\u5185\u5b58\u5360\u7528\u3002", "conclusion": "\u7b26\u53f7\u5bf9\u9f50\u662f\u5b9e\u73b0\u5728\u8bbe\u5907\u7aef\u51c6\u786e\u9ad8\u6548\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u7684\u6709\u6548\u7b56\u7565\uff0c\u672c\u4f53\u589e\u5f3a\u7684\u6a21\u578b\u80fd\u4ea7\u751f\u66f4\u63a5\u5730\u6c14\u3001\u6d88\u6b67\u7684\u591a\u610f\u56fe\u89e3\u91ca\u3002"}}
{"id": "2511.19987", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.19987", "abs": "https://arxiv.org/abs/2511.19987", "authors": ["Xinyu Wang", "Hanwei Wu", "Qingchen Hu", "Zhenghan Tai", "Jingrui Tian", "Lei Ding", "Jijun Chi", "Hailin He", "Tung Sum Thomas Kwok", "Yufei Cui", "Sicheng Lyu", "Muzhi Li", "Mingze Li", "Xinyue Yu", "Ling Zhou", "Peng Lu"], "title": "$\\text{R}^2\\text{R}$: A Route-to-Rerank Post-Training Framework for Multi-Domain Decoder-Only Rerankers", "comment": "13 pages, including 3 figures and 3 tables", "summary": "Decoder-only rerankers are central to Retrieval-Augmented Generation (RAG). However, generalist models miss domain-specific nuances in high-stakes fields like finance and law, and naive fine-tuning causes surface-form overfitting and catastrophic forgetting. To address this challenge, we introduce R2R, a domain-aware framework that combines dynamic expert routing with a two-stage training strategy, Entity Abstraction for Generalization (EAG). EAG introduces a counter-shortcut mechanism by masking the most predictive surface cues, forcing the reranker to learn domain-invariant relevance patterns rather than memorizing dataset-specific entities. To efficiently activate domain experts, R2R employs a lightweight Latent Semantic Router that probes internal representations from the frozen backbone decoder to select the optimal LoRA expert per query. Extensive experiments across different reranker backbones and diverse domains (legal, medical, and financial) demonstrate that R2R consistently surpasses generalist and single-domain fine-tuned baselines. Our results confirm that R2R is a model-agnostic and modular approach to domain specialization with strong cross-domain robustness.", "AI": {"tldr": "R2R\u662f\u4e00\u4e2a\u9886\u57df\u611f\u77e5\u7684\u91cd\u65b0\u6392\u5e8f\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u4e13\u5bb6\u8def\u7531\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u89e3\u51b3\u9886\u57df\u4e13\u4e1a\u5316\u95ee\u9898\uff0c\u5728\u91d1\u878d\u3001\u6cd5\u5f8b\u7b49\u9ad8\u8981\u6c42\u9886\u57df\u8868\u73b0\u4f18\u4e8e\u901a\u7528\u6a21\u578b\u3002", "motivation": "\u901a\u7528\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u9886\u57df\uff08\u5982\u91d1\u878d\u3001\u6cd5\u5f8b\uff09\u4e2d\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\uff0c\u800c\u7b80\u5355\u5fae\u8c03\u4f1a\u5bfc\u81f4\u8868\u9762\u5f62\u5f0f\u8fc7\u62df\u5408\u548c\u707e\u96be\u6027\u9057\u5fd8\u3002", "method": "\u91c7\u7528\u52a8\u6001\u4e13\u5bb6\u8def\u7531\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff08EAG\uff09\uff0c\u901a\u8fc7\u5c4f\u853d\u6700\u5177\u9884\u6d4b\u6027\u7684\u8868\u9762\u7ebf\u7d22\uff0c\u8feb\u4f7f\u91cd\u65b0\u6392\u5e8f\u5668\u5b66\u4e60\u9886\u57df\u4e0d\u53d8\u7684\u76f8\u5173\u6027\u6a21\u5f0f\u3002\u4f7f\u7528\u8f7b\u91cf\u7ea7\u6f5c\u5728\u8bed\u4e49\u8def\u7531\u5668\u9009\u62e9\u6700\u4f18LoRA\u4e13\u5bb6\u3002", "result": "\u5728\u591a\u4e2a\u91cd\u65b0\u6392\u5e8f\u5668\u9aa8\u5e72\u548c\u4e0d\u540c\u9886\u57df\uff08\u6cd5\u5f8b\u3001\u533b\u7597\u3001\u91d1\u878d\uff09\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cR2R\u59cb\u7ec8\u4f18\u4e8e\u901a\u7528\u6a21\u578b\u548c\u5355\u9886\u57df\u5fae\u8c03\u57fa\u7ebf\u3002", "conclusion": "R2R\u662f\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u4e14\u6a21\u5757\u5316\u7684\u9886\u57df\u4e13\u4e1a\u5316\u65b9\u6cd5\uff0c\u5177\u6709\u5f3a\u5927\u7684\u8de8\u9886\u57df\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.19798", "categories": ["cs.AI", "cs.HC", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.19798", "abs": "https://arxiv.org/abs/2511.19798", "authors": ["Weizhi Liu", "Xi Chen", "Zekun Jiang", "Liang Zhao", "Kunyuan Jiang", "Ruisi Tang", "Li Wang", "Mingke You", "Hanyu Zhou", "Hongyu Chen", "Qiankun Xiong", "Yong Nie", "Kang Li", "Jian Li"], "title": "KOM: A Multi-Agent Artificial Intelligence System for Precision Management of Knee Osteoarthritis (KOA)", "comment": null, "summary": "Knee osteoarthritis (KOA) affects more than 600 million individuals globally and is associated with significant pain, functional impairment, and disability. While personalized multidisciplinary interventions have the potential to slow disease progression and enhance quality of life, they typically require substantial medical resources and expertise, making them difficult to implement in resource-limited settings. To address this challenge, we developed KOM, a multi-agent system designed to automate KOA evaluation, risk prediction, and treatment prescription. This system assists clinicians in performing essential tasks across the KOA care pathway and supports the generation of tailored management plans based on individual patient profiles, disease status, risk factors, and contraindications. In benchmark experiments, KOM demonstrated superior performance compared to several general-purpose large language models in imaging analysis and prescription generation. A randomized three-arm simulation study further revealed that collaboration between KOM and clinicians reduced total diagnostic and planning time by 38.5% and resulted in improved treatment quality compared to each approach used independently. These findings indicate that KOM could help facilitate automated KOA management and, when integrated into clinical workflows, has the potential to enhance care efficiency. The modular architecture of KOM may also offer valuable insights for developing AI-assisted management systems for other chronic conditions.", "AI": {"tldr": "KOM\u662f\u4e00\u4e2a\u7528\u4e8e\u819d\u9aa8\u5173\u8282\u708e(KOA)\u7ba1\u7406\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u80fd\u591f\u81ea\u52a8\u5316\u8bc4\u4f30\u3001\u98ce\u9669\u9884\u6d4b\u548c\u6cbb\u7597\u5904\u65b9\uff0c\u5728\u4e34\u5e8a\u534f\u4f5c\u4e2d\u663e\u8457\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u819d\u9aa8\u5173\u8282\u708e\u5f71\u54cd\u5168\u74036\u4ebf\u591a\u4eba\uff0c\u4e2a\u6027\u5316\u591a\u5b66\u79d1\u5e72\u9884\u867d\u7136\u6709\u6548\u4f46\u8d44\u6e90\u9700\u6c42\u5927\uff0c\u96be\u4ee5\u5728\u8d44\u6e90\u6709\u9650\u73af\u5883\u4e2d\u5b9e\u65bd\u3002", "method": "\u5f00\u53d1KOM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u81ea\u52a8\u5316KOA\u8bc4\u4f30\u3001\u98ce\u9669\u9884\u6d4b\u548c\u6cbb\u7597\u5904\u65b9\u751f\u6210\uff0c\u652f\u6301\u57fa\u4e8e\u60a3\u8005\u4e2a\u4f53\u7279\u5f81\u7684\u5b9a\u5236\u7ba1\u7406\u8ba1\u5212\u3002", "result": "\u57fa\u51c6\u5b9e\u9a8c\u663e\u793aKOM\u5728\u5f71\u50cf\u5206\u6790\u548c\u5904\u65b9\u751f\u6210\u65b9\u9762\u4f18\u4e8e\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff1b\u4e09\u81c2\u6a21\u62df\u7814\u7a76\u8868\u660eKOM\u4e0e\u4e34\u5e8a\u533b\u751f\u534f\u4f5c\u53ef\u5c06\u8bca\u65ad\u548c\u89c4\u5212\u65f6\u95f4\u51cf\u5c1138.5%\uff0c\u5e76\u63d0\u9ad8\u6cbb\u7597\u8d28\u91cf\u3002", "conclusion": "KOM\u6709\u52a9\u4e8e\u5b9e\u73b0KOA\u81ea\u52a8\u5316\u7ba1\u7406\uff0c\u96c6\u6210\u5230\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u53ef\u63d0\u9ad8\u62a4\u7406\u6548\u7387\uff0c\u5176\u6a21\u5757\u5316\u67b6\u6784\u4e3a\u5f00\u53d1\u5176\u4ed6\u6162\u6027\u75c5AI\u8f85\u52a9\u7ba1\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\u3002"}}
{"id": "2511.19997", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19997", "abs": "https://arxiv.org/abs/2511.19997", "authors": ["Mihir Sahasrabudhe"], "title": "Directional Optimization Asymmetry in Transformers: A Synthetic Stress Test", "comment": "19 pages, 4 figures. Code available at https://github.com/mihirs-0/synass", "summary": "Transformers are theoretically reversal-invariant: their function class does not prefer left-to-right over right-to-left mappings. Yet empirical studies on natural language repeatedly report a \"reversal curse,\" and recent work on temporal asymmetry in LLMs suggests that real-world corpora carry their own arrow of time. This leaves an unresolved question: do directional failures stem from linguistic statistics, or from the architecture itself? We cut through this ambiguity with a fully synthetic, entropy-controlled benchmark designed as a clean-room stress test for directional learning. Using random string mappings with tunable branching factor K, we construct forward tasks with zero conditional entropy and inverse tasks with analytically determined entropy floors. Excess loss above these floors reveals that even scratch-trained GPT-2 models exhibit a strong, reproducible directional optimization gap (e.g., 1.16 nats at K=5), far larger than that of an MLP trained on the same data. Pre-trained initializations shift optimization behavior but do not eliminate this gap, while LoRA encounters a sharp capacity wall on high-entropy inverse mappings. Together, these results isolate a minimal, semantics-free signature of directional friction intrinsic to causal Transformer training-one that persists even when linguistic priors, token frequencies, and corpus-level temporal asymmetries are removed. Our benchmark provides a controlled instrument for dissecting directional biases in modern sequence models and motivates deeper mechanistic study of why inversion remains fundamentally harder for Transformers.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u53d1\u73b0\uff0c\u5373\u4f7f\u5728\u6ca1\u6709\u8bed\u8a00\u7edf\u8ba1\u504f\u89c1\u7684\u6761\u4ef6\u4e0b\uff0c\u56e0\u679cTransformer\u6a21\u578b\u5728\u53cd\u5411\u6620\u5c04\u4efb\u52a1\u4e0a\u4ecd\u5b58\u5728\u663e\u8457\u7684\u65b9\u5411\u6027\u4f18\u5316\u5dee\u8ddd\uff0c\u8fd9\u63ed\u793a\u4e86Transformer\u67b6\u6784\u672c\u8eab\u56fa\u6709\u7684\u65b9\u5411\u6027\u6469\u64e6\u3002", "motivation": "\u89e3\u51b3Transformer\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u8868\u73b0\u51fa\u7684\u65b9\u5411\u6027\u5931\u8d25\uff08\u5982\u53cd\u8f6c\u8bc5\u5492\uff09\u95ee\u9898\uff0c\u533a\u5206\u8fd9\u79cd\u5931\u8d25\u662f\u6e90\u4e8e\u8bed\u8a00\u7edf\u8ba1\u7279\u6027\u8fd8\u662f\u6a21\u578b\u67b6\u6784\u672c\u8eab\u3002", "method": "\u6784\u5efa\u5b8c\u5168\u5408\u6210\u7684\u3001\u71b5\u53ef\u63a7\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f7f\u7528\u968f\u673a\u5b57\u7b26\u4e32\u6620\u5c04\u548c\u53ef\u8c03\u5206\u652f\u56e0\u5b50K\uff0c\u521b\u5efa\u96f6\u6761\u4ef6\u71b5\u7684\u524d\u5411\u4efb\u52a1\u548c\u5177\u6709\u5206\u6790\u786e\u5b9a\u71b5\u4e0b\u9650\u7684\u9006\u4efb\u52a1\uff0c\u8bad\u7ec3GPT-2\u6a21\u578b\u5e76\u6bd4\u8f83\u5176\u6027\u80fd\u3002", "result": "\u5373\u4f7f\u4ece\u5934\u8bad\u7ec3\u7684GPT-2\u6a21\u578b\u4e5f\u8868\u73b0\u51fa\u5f3a\u70c8\u4e14\u53ef\u590d\u73b0\u7684\u65b9\u5411\u6027\u4f18\u5316\u5dee\u8ddd\uff08\u5982K=5\u65f61.16\u7eb3\u7279\uff09\uff0c\u8fdc\u5927\u4e8e\u5728\u76f8\u540c\u6570\u636e\u4e0a\u8bad\u7ec3\u7684MLP\u3002\u9884\u8bad\u7ec3\u521d\u59cb\u5316\u6539\u53d8\u4e86\u4f18\u5316\u884c\u4e3a\u4f46\u672a\u6d88\u9664\u5dee\u8ddd\uff0cLoRA\u5728\u9ad8\u71b5\u9006\u6620\u5c04\u4e0a\u9047\u5230\u5bb9\u91cf\u5899\u3002", "conclusion": "\u7814\u7a76\u5206\u79bb\u51fa\u4e86\u4e00\u4e2a\u6700\u5c0f\u5316\u7684\u3001\u65e0\u8bed\u4e49\u7684\u65b9\u5411\u6027\u6469\u64e6\u7279\u5f81\uff0c\u8fd9\u662f\u56e0\u679cTransformer\u8bad\u7ec3\u56fa\u6709\u7684\u7279\u6027\uff0c\u5373\u4f7f\u5728\u79fb\u9664\u8bed\u8a00\u5148\u9a8c\u3001\u8bcd\u9891\u548c\u8bed\u6599\u7ea7\u65f6\u95f4\u4e0d\u5bf9\u79f0\u6027\u540e\u4ecd\u7136\u5b58\u5728\u3002"}}
{"id": "2511.19829", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19829", "abs": "https://arxiv.org/abs/2511.19829", "authors": ["Ke Chen", "Yifeng Wang", "Hassan Almosapeeh", "Haohan Wang"], "title": "A Unified Evaluation-Instructed Framework for Query-Dependent Prompt Optimization", "comment": null, "summary": "Most prompt-optimization methods refine a single static template, making them ineffective in complex and dynamic user scenarios. Existing query-dependent approaches rely on unstable textual feedback or black-box reward models, providing weak and uninterpretable optimization signals. More fundamentally, prompt quality itself lacks a unified, systematic definition, resulting in fragmented and unreliable evaluation signals. Our approach first establishes a performance-oriented, systematic, and comprehensive prompt evaluation framework. Furthermore, we develop and finetune an execution-free evaluator that predicts multi-dimensional quality scores directly from text. The evaluator then instructs a metric-aware optimizer that diagnoses failure modes and rewrites prompts in an interpretable, query-dependent manner. Our evaluator achieves the strongest accuracy in predicting prompt performance, and the evaluation-instructed optimization consistently surpass both static-template and query-dependent baselines across eight datasets and on three backbone models. Overall, we propose a unified, metric-grounded perspective on prompt quality, and demonstrated that our evaluation-instructed optimization pipeline delivers stable, interpretable, and model-agnostic improvements across diverse tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8bc4\u4f30\u6307\u5bfc\u7684\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u7acb\u7cfb\u7edf\u5316\u7684\u63d0\u793a\u8d28\u91cf\u8bc4\u4f30\u6807\u51c6\u548c\u6267\u884c\u65e0\u5173\u7684\u8bc4\u4f30\u5668\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u67e5\u8be2\u76f8\u5173\u63d0\u793a\u4f18\u5316\u3002", "motivation": "\u73b0\u6709\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u4e3b\u8981\u4f18\u5316\u9759\u6001\u6a21\u677f\uff0c\u5728\u590d\u6742\u52a8\u6001\u573a\u666f\u4e2d\u6548\u679c\u6709\u9650\uff1b\u67e5\u8be2\u76f8\u5173\u65b9\u6cd5\u4f9d\u8d56\u4e0d\u7a33\u5b9a\u7684\u6587\u672c\u53cd\u9988\u6216\u9ed1\u76d2\u5956\u52b1\u6a21\u578b\uff0c\u4f18\u5316\u4fe1\u53f7\u5f31\u4e14\u4e0d\u53ef\u89e3\u91ca\uff1b\u63d0\u793a\u8d28\u91cf\u7f3a\u4e4f\u7edf\u4e00\u7cfb\u7edf\u5b9a\u4e49\u3002", "method": "\u9996\u5148\u5efa\u7acb\u6027\u80fd\u5bfc\u5411\u7684\u7cfb\u7edf\u5316\u63d0\u793a\u8bc4\u4f30\u6846\u67b6\uff0c\u5f00\u53d1\u5e76\u5fae\u8c03\u6267\u884c\u65e0\u5173\u7684\u8bc4\u4f30\u5668\u76f4\u63a5\u9884\u6d4b\u591a\u7ef4\u8d28\u91cf\u5206\u6570\uff0c\u7136\u540e\u4f7f\u7528\u8bc4\u4f30\u5668\u6307\u5bfc\u6307\u6807\u611f\u77e5\u7684\u4f18\u5316\u5668\u8fdb\u884c\u53ef\u89e3\u91ca\u7684\u67e5\u8be2\u76f8\u5173\u63d0\u793a\u91cd\u5199\u3002", "result": "\u8bc4\u4f30\u5668\u5728\u9884\u6d4b\u63d0\u793a\u6027\u80fd\u65b9\u9762\u8fbe\u5230\u6700\u9ad8\u51c6\u786e\u7387\uff0c\u8bc4\u4f30\u6307\u5bfc\u7684\u4f18\u5316\u57288\u4e2a\u6570\u636e\u96c6\u548c3\u4e2a\u9aa8\u5e72\u6a21\u578b\u4e0a\u6301\u7eed\u8d85\u8d8a\u9759\u6001\u6a21\u677f\u548c\u67e5\u8be2\u76f8\u5173\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u57fa\u4e8e\u6307\u6807\u7684\u63d0\u793a\u8d28\u91cf\u89c6\u89d2\uff0c\u8bc1\u660e\u8bc4\u4f30\u6307\u5bfc\u7684\u4f18\u5316\u7ba1\u9053\u80fd\u5728\u591a\u6837\u5316\u4efb\u52a1\u4e2d\u63d0\u4f9b\u7a33\u5b9a\u3001\u53ef\u89e3\u91ca\u548c\u6a21\u578b\u65e0\u5173\u7684\u6539\u8fdb\u3002"}}
{"id": "2511.20001", "categories": ["cs.CL", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.20001", "abs": "https://arxiv.org/abs/2511.20001", "authors": ["Edward Ajayi", "Martha Kachweka", "Mawuli Deku", "Emily Aiken"], "title": "A Machine Learning Approach for Detection of Mental Health Conditions and Cyberbullying from Social Media", "comment": "Accepted for Oral Presentation at the AAAI-26 Bridge Program on AI for Medicine and Healthcare (AIMedHealth). To appear in Proceedings of Machine Learning Research (PMLR)", "summary": "Mental health challenges and cyberbullying are increasingly prevalent in digital spaces, necessitating scalable and interpretable detection systems. This paper introduces a unified multiclass classification framework for detecting ten distinct mental health and cyberbullying categories from social media data. We curate datasets from Twitter and Reddit, implementing a rigorous \"split-then-balance\" pipeline to train on balanced data while evaluating on a realistic, held-out imbalanced test set. We conducted a comprehensive evaluation comparing traditional lexical models, hybrid approaches, and several end-to-end fine-tuned transformers. Our results demonstrate that end-to-end fine-tuning is critical for performance, with the domain-adapted MentalBERT emerging as the top model, achieving an accuracy of 0.92 and a Macro F1 score of 0.76, surpassing both its generic counterpart and a zero-shot LLM baseline. Grounded in a comprehensive ethical analysis, we frame the system as a human-in-the-loop screening aid, not a diagnostic tool. To support this, we introduce a hybrid SHAPLLM explainability framework and present a prototype dashboard (\"Social Media Screener\") designed to integrate model predictions and their explanations into a practical workflow for moderators. Our work provides a robust baseline, highlighting future needs for multi-label, clinically-validated datasets at the critical intersection of online safety and computational mental health.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u7c7b\u522b\u5206\u7c7b\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u4e2d\u68c0\u6d4b10\u79cd\u4e0d\u540c\u7684\u5fc3\u7406\u5065\u5eb7\u548c\u7f51\u7edc\u9738\u51cc\u7c7b\u522b\u3002\u901a\u8fc7\u6bd4\u8f83\u591a\u79cd\u6a21\u578b\uff0c\u53d1\u73b0\u7aef\u5230\u7aef\u5fae\u8c03\u81f3\u5173\u91cd\u8981\uff0c\u5176\u4e2d\u9886\u57df\u9002\u5e94\u7684MentalBERT\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u6570\u5b57\u7a7a\u95f4\u4e2d\u65e5\u76ca\u4e25\u91cd\u7684\u5fc3\u7406\u5065\u5eb7\u6311\u6218\u548c\u7f51\u7edc\u9738\u51cc\u95ee\u9898\u9700\u8981\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684\u68c0\u6d4b\u7cfb\u7edf\u3002", "method": "\u4eceTwitter\u548cReddit\u6536\u96c6\u6570\u636e\u96c6\uff0c\u91c7\u7528\"\u5206\u5272\u540e\u5e73\u8861\"\u6d41\u7a0b\uff0c\u5728\u5e73\u8861\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u5728\u73b0\u5b9e\u4e0d\u5e73\u8861\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\u3002\u6bd4\u8f83\u4e86\u4f20\u7edf\u8bcd\u6c47\u6a21\u578b\u3001\u6df7\u5408\u65b9\u6cd5\u548c\u591a\u79cd\u7aef\u5230\u7aef\u5fae\u8c03\u8f6c\u6362\u5668\u3002", "result": "\u9886\u57df\u9002\u5e94\u7684MentalBERT\u6210\u4e3a\u6700\u4f73\u6a21\u578b\uff0c\u51c6\u786e\u7387\u8fbe0.92\uff0c\u5b8fF1\u5206\u6570\u4e3a0.76\uff0c\u8d85\u8d8a\u4e86\u901a\u7528\u6a21\u578b\u548c\u96f6\u6837\u672cLLM\u57fa\u7ebf\u3002", "conclusion": "\u5c06\u7cfb\u7edf\u5b9a\u4f4d\u4e3a\u4eba\u5de5\u53c2\u4e0e\u5faa\u73af\u7684\u7b5b\u67e5\u8f85\u52a9\u5de5\u5177\u800c\u975e\u8bca\u65ad\u5de5\u5177\uff0c\u5f15\u5165\u4e86\u6df7\u5408SHAPLLM\u53ef\u89e3\u91ca\u6027\u6846\u67b6\u548c\u539f\u578b\u4eea\u8868\u677f\uff0c\u4e3a\u5728\u7ebf\u5b89\u5168\u548c\u8ba1\u7b97\u5fc3\u7406\u5065\u5eb7\u7684\u4ea4\u53c9\u9886\u57df\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2511.19849", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19849", "abs": "https://arxiv.org/abs/2511.19849", "authors": ["Dominik Wagner", "Leon Witzman", "Luke Ong"], "title": "Reinforcement Learning with $\u03c9$-Regular Objectives and Constraints", "comment": null, "summary": "Reinforcement learning (RL) commonly relies on scalar rewards with limited ability to express temporal, conditional, or safety-critical goals, and can lead to reward hacking. Temporal logic expressible via the more general class of $\u03c9$-regular objectives addresses this by precisely specifying rich behavioural properties. Even still, measuring performance by a single scalar (be it reward or satisfaction probability) masks safety-performance trade-offs that arise in settings with a tolerable level of risk.\n  We address both limitations simultaneously by combining $\u03c9$-regular objectives with explicit constraints, allowing safety requirements and optimisation targets to be treated separately. We develop a model-based RL algorithm based on linear programming, which in the limit produces a policy maximising the probability of satisfying an $\u03c9$-regular objective while also adhering to $\u03c9$-regular constraints within specified thresholds. Furthermore, we establish a translation to constrained limit-average problems with optimality-preserving guarantees.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u03c9-\u6b63\u5219\u76ee\u6807\u548c\u663e\u5f0f\u7ea6\u675f\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6807\u91cf\u5956\u52b1\u5728\u8868\u8fbe\u65f6\u5e8f\u3001\u6761\u4ef6\u548c\u5b89\u5168\u5173\u952e\u76ee\u6807\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u540c\u65f6\u5904\u7406\u5b89\u5168-\u6027\u80fd\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u4f9d\u8d56\u6807\u91cf\u5956\u52b1\uff0c\u96be\u4ee5\u8868\u8fbe\u590d\u6742\u7684\u65f6\u5e8f\u3001\u6761\u4ef6\u548c\u5b89\u5168\u5173\u952e\u76ee\u6807\uff0c\u4e14\u5bb9\u6613\u5bfc\u81f4\u5956\u52b1\u7834\u89e3\u3002\u03c9-\u6b63\u5219\u76ee\u6807\u80fd\u7cbe\u786e\u6307\u5b9a\u4e30\u5bcc\u7684\u884c\u4e3a\u5c5e\u6027\uff0c\u4f46\u5355\u4e00\u6807\u91cf\u6027\u80fd\u5ea6\u91cf\u63a9\u76d6\u4e86\u5b89\u5168-\u6027\u80fd\u6743\u8861\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u7ebf\u6027\u89c4\u5212\u7684\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u5c06\u03c9-\u6b63\u5219\u76ee\u6807\u4e0e\u663e\u5f0f\u7ea6\u675f\u76f8\u7ed3\u5408\uff0c\u5b89\u5168\u8981\u6c42\u548c\u4f18\u5316\u76ee\u6807\u5206\u522b\u5904\u7406\u3002\u5efa\u7acb\u4e86\u5230\u7ea6\u675f\u6781\u9650\u5e73\u5747\u95ee\u9898\u7684\u8f6c\u6362\uff0c\u5e76\u4fdd\u6301\u6700\u4f18\u6027\u4fdd\u8bc1\u3002", "result": "\u8be5\u7b97\u6cd5\u5728\u6781\u9650\u60c5\u51b5\u4e0b\u4ea7\u751f\u4e00\u4e2a\u7b56\u7565\uff0c\u6700\u5927\u5316\u6ee1\u8db3\u03c9-\u6b63\u5219\u76ee\u6807\u7684\u6982\u7387\uff0c\u540c\u65f6\u9075\u5b88\u6307\u5b9a\u9608\u503c\u5185\u7684\u03c9-\u6b63\u5219\u7ea6\u675f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u540c\u65f6\u89e3\u51b3\u4e86\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5728\u76ee\u6807\u8868\u8fbe\u548c\u5b89\u5168-\u6027\u80fd\u6743\u8861\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u590d\u6742\u73af\u5883\u4e2d\u7684\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20056", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20056", "abs": "https://arxiv.org/abs/2511.20056", "authors": ["Huiyu Bai", "Runze Wang", "Zhuoyun Du", "Yiyang Zhao", "Fengji Zhang", "Haoyu Chen", "Xiaoyong Zhu", "Bo Zheng", "Xuejiao Zhao"], "title": "Online-PVLM: Advancing Personalized VLMs with Online Concept Learning", "comment": "Work in Progress", "summary": "Personalized Visual Language Models (VLMs) are gaining increasing attention for their formidable ability in user-specific concepts aligned interactions (e.g., identifying a user's bike). Existing methods typically require the learning of separate embeddings for each new concept, which fails to support real-time adaptation during testing. This limitation becomes particularly pronounced in large-scale scenarios, where efficient retrieval of concept embeddings is not achievable. To alleviate this gap, we propose Online-PVLM, a framework for online concept learning by leveraging hyperbolic representations. Our approach makes a train-free paradigm for concept embeddings generation at test time, making the use of personalized VLMs both scalable and efficient. In addition, we develop OP-Eval, a comprehensive and large-scale benchmark comprising 1,292 concepts and over 30K high-quality instances with diverse question types, designed to rigorously assess online concept learning in realistic scenarios. Extensive experiments demonstrate the state-of-the-art performance of our proposed framework. Our source code and dataset will be made available.", "AI": {"tldr": "\u63d0\u51fa\u4e86Online-PVLM\u6846\u67b6\uff0c\u4f7f\u7528\u53cc\u66f2\u8868\u793a\u5b9e\u73b0\u4e2a\u6027\u5316\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5728\u7ebf\u6982\u5ff5\u5b66\u4e60\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u5728\u6d4b\u8bd5\u65f6\u751f\u6210\u6982\u5ff5\u5d4c\u5165\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u652f\u6301\u5b9e\u65f6\u9002\u5e94\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u4e2a\u6027\u5316\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u9700\u8981\u4e3a\u6bcf\u4e2a\u65b0\u6982\u5ff5\u5b66\u4e60\u5355\u72ec\u7684\u5d4c\u5165\uff0c\u65e0\u6cd5\u5728\u6d4b\u8bd5\u65f6\u8fdb\u884c\u5b9e\u65f6\u9002\u5e94\uff0c\u5728\u5927\u89c4\u6a21\u573a\u666f\u4e0b\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u5229\u7528\u53cc\u66f2\u8868\u793a\u5b9e\u73b0\u514d\u8bad\u7ec3\u7684\u6982\u5ff5\u5d4c\u5165\u751f\u6210\uff0c\u5728\u6d4b\u8bd5\u65f6\u8fdb\u884c\u5728\u7ebf\u6982\u5ff5\u5b66\u4e60\u3002", "result": "\u5728\u5305\u542b1,292\u4e2a\u6982\u5ff5\u548c3\u4e07\u591a\u4e2a\u5b9e\u4f8b\u7684OP-Eval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "Online-PVLM\u6846\u67b6\u4f7f\u4e2a\u6027\u5316\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u5927\u89c4\u6a21\u573a\u666f\u4e0b\u65e2\u5177\u6709\u53ef\u6269\u5c55\u6027\u53c8\u4fdd\u6301\u9ad8\u6548\u6027\u3002"}}
{"id": "2511.19864", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19864", "abs": "https://arxiv.org/abs/2511.19864", "authors": ["Valerie Lockhart", "Dan McCreary", "Troy A. Peterson"], "title": "MicroSims: A Framework for AI-Generated, Scalable Educational Simulations with Universal Embedding and Adaptive Learning Support", "comment": "42 pages, 4 figures", "summary": "Educational simulations have long been recognized as powerful tools for enhancing learning outcomes, yet their creation has traditionally required substantial resources and technical expertise. This paper introduces MicroSims a novel framework for creating lightweight, interactive educational simulations that can be rapidly generated using artificial intelligence, universally embedded across digital learning platforms, and easily customized without programming knowledge. MicroSims occupy a unique position at the intersection of three key innovations: (1) standardized design patterns that enable AI-assisted generation, (2) iframe-based architecture that provides universal embedding and sandboxed security, and (3) transparent, modifiable code that supports customization and pedagogical transparency. We present a comprehensive framework encompassing design principles, technical architecture, metadata standards, and development workflows. Drawing on empirical research from physics education studies and meta-analyses across STEM disciplines, we demonstrate that interactive simulations can improve conceptual understanding by up to 30-40\\% compared to traditional instruction. MicroSims extend these benefits while addressing persistent barriers of cost, technical complexity, and platform dependence. This work has significant implications for educational equity, and low-cost intelligent interactive textbooks that enabling educators worldwide to create customized, curriculum-aligned simulations on demand. We discuss implementation considerations, present evidence of effectiveness, and outline future directions for AI-powered adaptive learning systems built on the MicroSim foundation.", "AI": {"tldr": "MicroSims\u662f\u4e00\u4e2a\u7528\u4e8e\u5feb\u901f\u521b\u5efa\u8f7b\u91cf\u7ea7\u4ea4\u4e92\u5f0f\u6559\u80b2\u6a21\u62df\u7684AI\u9a71\u52a8\u6846\u67b6\uff0c\u901a\u8fc7\u6807\u51c6\u5316\u8bbe\u8ba1\u6a21\u5f0f\u3001iframe\u67b6\u6784\u548c\u900f\u660e\u4ee3\u7801\u5b9e\u73b0\u4f4e\u6210\u672c\u3001\u6613\u5b9a\u5236\u548c\u8de8\u5e73\u53f0\u5d4c\u5165\u3002", "motivation": "\u4f20\u7edf\u6559\u80b2\u6a21\u62df\u521b\u5efa\u9700\u8981\u5927\u91cf\u8d44\u6e90\u548c\u6280\u672f\u4e13\u957f\uff0c\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002MicroSims\u65e8\u5728\u89e3\u51b3\u6210\u672c\u3001\u6280\u672f\u590d\u6742\u6027\u548c\u5e73\u53f0\u4f9d\u8d56\u7b49\u969c\u788d\uff0c\u4fc3\u8fdb\u6559\u80b2\u516c\u5e73\u3002", "method": "\u91c7\u7528\u6807\u51c6\u5316\u8bbe\u8ba1\u6a21\u5f0f\u652f\u6301AI\u8f85\u52a9\u751f\u6210\uff0ciframe\u67b6\u6784\u5b9e\u73b0\u901a\u7528\u5d4c\u5165\u548c\u5b89\u5168\u6c99\u7bb1\uff0c\u900f\u660e\u53ef\u4fee\u6539\u4ee3\u7801\u652f\u6301\u5b9a\u5236\u548c\u6559\u5b66\u900f\u660e\u5ea6\u3002", "result": "\u57fa\u4e8e\u7269\u7406\u6559\u80b2\u7814\u7a76\u548cSTEM\u5143\u5206\u6790\uff0c\u4ea4\u4e92\u6a21\u62df\u53ef\u5c06\u6982\u5ff5\u7406\u89e3\u63d0\u534730-40%\u3002MicroSims\u5728\u4fdd\u6301\u8fd9\u4e9b\u4f18\u52bf\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u521b\u5efa\u95e8\u69db\u3002", "conclusion": "MicroSims\u4e3a\u6559\u80b2\u516c\u5e73\u548c\u4f4e\u6210\u672c\u667a\u80fd\u4ea4\u4e92\u6559\u79d1\u4e66\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\uff0c\u4f7f\u5168\u7403\u6559\u80b2\u5de5\u4f5c\u8005\u80fd\u591f\u6309\u9700\u521b\u5efa\u5b9a\u5236\u5316\u3001\u4e0e\u8bfe\u7a0b\u5bf9\u9f50\u7684\u6a21\u62df\u3002"}}
{"id": "2511.20072", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20072", "abs": "https://arxiv.org/abs/2511.20072", "authors": ["Xiaopeng Li", "Yuanjin Zheng", "Wanyu Wang", "wenlin zhang", "Pengyue Jia", "Yiqi Wang", "Maolin Wang", "Xuetao Wei", "Xiangyu Zhao"], "title": "MTA: A Merge-then-Adapt Framework for Personalized Large Language Model", "comment": null, "summary": "Personalized Large Language Models (PLLMs) aim to align model outputs with individual user preferences, a crucial capability for user-centric applications. However, the prevalent approach of fine-tuning a separate module for each user faces two major limitations: (1) storage costs scale linearly with the number of users, rendering the method unscalable; and (2) fine-tuning a static model from scratch often yields suboptimal performance for users with sparse data. To address these challenges, we propose MTA, a Merge-then-Adapt framework for PLLMs. MTA comprises three key stages. First, we construct a shared Meta-LoRA Bank by selecting anchor users and pre-training meta-personalization traits within meta-LoRA modules. Second, to ensure scalability and enable dynamic personalization combination beyond static models, we introduce an Adaptive LoRA Fusion stage. This stage retrieves and dynamically merges the most relevant anchor meta-LoRAs to synthesize a user-specific one, thereby eliminating the need for user-specific storage and supporting more flexible personalization. Third, we propose a LoRA Stacking for Few-Shot Personalization stage, which applies an additional ultra-low-rank, lightweight LoRA module on top of the merged LoRA. Fine-tuning this module enables effective personalization under few-shot settings. Extensive experiments on the LaMP benchmark demonstrate that our approach outperforms existing SOTA methods across multiple tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86MTA\u6846\u67b6\uff0c\u901a\u8fc7\u5408\u5e76-\u9002\u5e94\u65b9\u6cd5\u89e3\u51b3\u4e2a\u6027\u5316\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u6269\u5c55\u6027\u548c\u6570\u636e\u7a00\u758f\u95ee\u9898\uff0c\u5305\u542b\u5143LoRA\u5e93\u6784\u5efa\u3001\u81ea\u9002\u5e94LoRA\u878d\u5408\u548c\u5c11\u6837\u672cLoRA\u5806\u53e0\u4e09\u4e2a\u9636\u6bb5\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u4e2a\u6027\u5316\u5927\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\u4e2d\u5b58\u50a8\u6210\u672c\u968f\u7528\u6237\u6570\u91cf\u7ebf\u6027\u589e\u957f\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u4ee5\u53ca\u6570\u636e\u7a00\u758f\u7528\u6237\u6027\u80fd\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "MTA\u6846\u67b6\uff1a1\uff09\u6784\u5efa\u5171\u4eab\u5143LoRA\u5e93\uff1b2\uff09\u81ea\u9002\u5e94LoRA\u878d\u5408\u52a8\u6001\u5408\u6210\u7528\u6237\u7279\u5b9a\u6a21\u5757\uff1b3\uff09LoRA\u5806\u53e0\u7528\u4e8e\u5c11\u6837\u672c\u4e2a\u6027\u5316\u3002", "result": "\u5728LaMP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "MTA\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86PLLMs\u7684\u53ef\u6269\u5c55\u6027\u548c\u5c11\u6837\u672c\u4e2a\u6027\u5316\u95ee\u9898\uff0c\u4e3a\u4e2a\u6027\u5316\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19865", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19865", "abs": "https://arxiv.org/abs/2511.19865", "authors": ["Mingkai Chen", "Zijie Feng", "Lei Wang", "Yaser Khamayseh"], "title": "Agentic AI-Empowered Conversational Embodied Intelligence Networks in 6G", "comment": "7 pages, 8 figures. Preprint submitted to IEEE Vehicle Technology Magazine", "summary": "In the 6G era, semantic collaboration among multiple embodied intelligent devices (MEIDs) becomes crucial for complex task execution. However, existing systems face challenges in multimodal information fusion, adaptive communication, and decision interpretability. To address these limitations, we propose a collaborative Conversational Embodied Intelligence Network (CC-EIN) integrating multimodal feature fusion, adaptive semantic communication, task coordination, and interpretability. PerceptiNet performs cross-modal fusion of image and radar data to generate unified semantic representations. An adaptive semantic communication strategy dynamically adjusts coding schemes and transmission power according to task urgency and channel quality. A semantic-driven collaboration mechanism further supports task decomposition and conflict-free coordination among heterogeneous devices. Finally, the InDec module enhances decision transparency through Grad-CAM visualization. Simulation results in post-earthquake rescue scenarios demonstrate that CC-EIN achieves 95.4% task completion rate and 95% transmission efficiency while maintaining strong semantic consistency and energy efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u534f\u4f5c\u5f0f\u5bf9\u8bdd\u5177\u8eab\u667a\u80fd\u7f51\u7edc\uff08CC-EIN\uff09\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u7279\u5f81\u878d\u5408\u3001\u81ea\u9002\u5e94\u8bed\u4e49\u901a\u4fe1\u3001\u4efb\u52a1\u534f\u8c03\u548c\u53ef\u89e3\u91ca\u6027\u6a21\u5757\uff0c\u89e3\u51b36G\u65f6\u4ee3\u591a\u5177\u8eab\u667a\u80fd\u8bbe\u5907\u5728\u590d\u6742\u4efb\u52a1\u6267\u884c\u4e2d\u7684\u534f\u4f5c\u6311\u6218\u3002", "motivation": "6G\u65f6\u4ee3\u591a\u5177\u8eab\u667a\u80fd\u8bbe\u5907\u5728\u6267\u884c\u590d\u6742\u4efb\u52a1\u65f6\u9700\u8981\u8bed\u4e49\u534f\u4f5c\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u5728\u591a\u6a21\u6001\u4fe1\u606f\u878d\u5408\u3001\u81ea\u9002\u5e94\u901a\u4fe1\u548c\u51b3\u7b56\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "method": "CC-EIN\u5305\u542bPerceptiNet\u8fdb\u884c\u56fe\u50cf\u548c\u96f7\u8fbe\u6570\u636e\u7684\u8de8\u6a21\u6001\u878d\u5408\u751f\u6210\u7edf\u4e00\u8bed\u4e49\u8868\u793a\uff1b\u81ea\u9002\u5e94\u8bed\u4e49\u901a\u4fe1\u7b56\u7565\u6839\u636e\u4efb\u52a1\u7d27\u6025\u6027\u548c\u4fe1\u9053\u8d28\u91cf\u52a8\u6001\u8c03\u6574\u7f16\u7801\u65b9\u6848\u548c\u4f20\u8f93\u529f\u7387\uff1b\u8bed\u4e49\u9a71\u52a8\u534f\u4f5c\u673a\u5236\u652f\u6301\u4efb\u52a1\u5206\u89e3\u548c\u5f02\u6784\u8bbe\u5907\u95f4\u7684\u65e0\u51b2\u7a81\u534f\u8c03\uff1bInDec\u6a21\u5757\u901a\u8fc7Grad-CAM\u53ef\u89c6\u5316\u589e\u5f3a\u51b3\u7b56\u900f\u660e\u5ea6\u3002", "result": "\u5728\u5730\u9707\u540e\u6551\u63f4\u573a\u666f\u7684\u4eff\u771f\u4e2d\uff0cCC-EIN\u5b9e\u73b0\u4e8695.4%\u7684\u4efb\u52a1\u5b8c\u6210\u7387\u548c95%\u7684\u4f20\u8f93\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5f3a\u5927\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u80fd\u6548\u3002", "conclusion": "CC-EIN\u6709\u6548\u89e3\u51b3\u4e86\u591a\u5177\u8eab\u667a\u80fd\u8bbe\u5907\u534f\u4f5c\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a6G\u65f6\u4ee3\u7684\u667a\u80fd\u534f\u4f5c\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20086", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20086", "abs": "https://arxiv.org/abs/2511.20086", "authors": ["Duc Anh Vu", "Thong Nguyen", "Cong-Duy Nguyen", "Viet Anh Nguyen", "Anh Tuan Luu"], "title": "More Bias, Less Bias: BiasPrompting for Enhanced Multiple-Choice Question Answering", "comment": "Accepted at the 41st ACM/SIGAPP Symposium On Applied Computing (SAC 2026), Main Conference", "summary": "With the advancement of large language models (LLMs), their performance on multiple-choice question (MCQ) tasks has improved significantly. However, existing approaches face key limitations: answer choices are typically presented to LLMs without contextual grounding or explanation. This absence of context can lead to incomplete exploration of all possible answers, ultimately degrading the models' reasoning capabilities. To address these challenges, we introduce BiasPrompting, a novel inference framework that guides LLMs to generate and critically evaluate reasoning across all plausible answer options before reaching a final prediction. It consists of two components: first, a reasoning generation stage, where the model is prompted to produce supportive reasonings for each answer option, and then, a reasoning-guided agreement stage, where the generated reasonings are synthesized to select the most plausible answer. Through comprehensive evaluations, BiasPrompting demonstrates significant improvements in five widely used multiple-choice question answering benchmarks. Our experiments showcase that BiasPrompting enhances the reasoning capabilities of LLMs and provides a strong foundation for tackling complex and challenging questions, particularly in settings where existing methods underperform.", "AI": {"tldr": "BiasPrompting\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5bfcLLMs\u4e3a\u6240\u6709\u53ef\u80fd\u7684\u7b54\u6848\u9009\u9879\u751f\u6210\u63a8\u7406\u5e76\u8fdb\u884c\u6279\u5224\u6027\u8bc4\u4f30\uff0c\u4ece\u800c\u63d0\u5347\u591a\u9879\u9009\u62e9\u9898\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u9879\u9009\u62e9\u9898\u4efb\u52a1\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u901a\u5e38\u5728\u6ca1\u6709\u4e0a\u4e0b\u6587\u80cc\u666f\u6216\u89e3\u91ca\u7684\u60c5\u51b5\u4e0b\u5411LLMs\u5448\u73b0\u7b54\u6848\u9009\u9879\uff0c\u8fd9\u5bfc\u81f4\u65e0\u6cd5\u5145\u5206\u63a2\u7d22\u6240\u6709\u53ef\u80fd\u7684\u7b54\u6848\uff0c\u4ece\u800c\u964d\u4f4e\u4e86\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "BiasPrompting\u5305\u542b\u4e24\u4e2a\u7ec4\u4ef6\uff1a1) \u63a8\u7406\u751f\u6210\u9636\u6bb5\uff0c\u6a21\u578b\u88ab\u63d0\u793a\u4e3a\u6bcf\u4e2a\u7b54\u6848\u9009\u9879\u751f\u6210\u652f\u6301\u6027\u63a8\u7406\uff1b2) \u63a8\u7406\u5f15\u5bfc\u7684\u4e00\u81f4\u6027\u9636\u6bb5\uff0c\u7efc\u5408\u751f\u6210\u7684\u63a8\u7406\u6765\u9009\u62e9\u6700\u5408\u7406\u7684\u7b54\u6848\u3002", "result": "\u5728\u4e94\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u591a\u9879\u9009\u62e9\u9898\u56de\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBiasPrompting\u8868\u73b0\u51fa\u663e\u8457\u6539\u8fdb\uff0c\u7279\u522b\u662f\u5728\u73b0\u6709\u65b9\u6cd5\u8868\u73b0\u4e0d\u4f73\u7684\u590d\u6742\u548c\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\u8bbe\u7f6e\u4e2d\u3002", "conclusion": "BiasPrompting\u589e\u5f3a\u4e86LLMs\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u4e3a\u5904\u7406\u590d\u6742\u548c\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2511.19872", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19872", "abs": "https://arxiv.org/abs/2511.19872", "authors": ["Daniel I Jackson", "Emma L Jensen", "Syed-Amad Hussain", "Emre Sezgin"], "title": "Simulated Self-Assessment in Large Language Models: A Psychometric Approach to AI Self-Efficacy", "comment": "25 pages,5 tables, 3 figures", "summary": "Self-assessment is a key aspect of reliable intelligence, yet evaluations of large language models (LLMs) focus mainly on task accuracy. We adapted the 10-item General Self-Efficacy Scale (GSES) to elicit simulated self-assessments from ten LLMs across four conditions: no task, computational reasoning, social reasoning, and summarization. GSES responses were highly stable across repeated administrations and randomized item orders. However, models showed significantly different self-efficacy levels across conditions, with aggregate scores lower than human norms. All models achieved perfect accuracy on computational and social questions, whereas summarization performance varied widely. Self-assessment did not reliably reflect ability: several low-scoring models performed accurately, while some high-scoring models produced weaker summaries. Follow-up confidence prompts yielded modest, mostly downward revisions, suggesting mild overestimation in first-pass assessments. Qualitative analysis showed that higher self-efficacy corresponded to more assertive, anthropomorphic reasoning styles, whereas lower scores reflected cautious, de-anthropomorphized explanations. Psychometric prompting provides structured insight into LLM communication behavior but not calibrated performance estimates.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c06\u901a\u7528\u81ea\u6211\u6548\u80fd\u611f\u91cf\u8868\u5e94\u7528\u4e8e10\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u5728\u4e0d\u540c\u4efb\u52a1\u6761\u4ef6\u4e0b\u6a21\u578b\u8868\u73b0\u51fa\u663e\u8457\u4e0d\u540c\u7684\u81ea\u6211\u6548\u80fd\u6c34\u5e73\uff0c\u4e14\u81ea\u6211\u8bc4\u4f30\u4e0e\u771f\u5b9e\u80fd\u529b\u4e0d\u5339\u914d\u3002", "motivation": "\u5f53\u524d\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u4efb\u52a1\u51c6\u786e\u6027\uff0c\u800c\u5ffd\u89c6\u4e86\u81ea\u6211\u8bc4\u4f30\u8fd9\u4e00\u53ef\u9760\u667a\u80fd\u7684\u5173\u952e\u65b9\u9762\u3002", "method": "\u5c0610\u9879\u901a\u7528\u81ea\u6211\u6548\u80fd\u611f\u91cf\u8868\u5e94\u7528\u4e8e10\u4e2aLLM\uff0c\u5728\u56db\u79cd\u6761\u4ef6\u4e0b\u6d4b\u8bd5\uff1a\u65e0\u4efb\u52a1\u3001\u8ba1\u7b97\u63a8\u7406\u3001\u793e\u4f1a\u63a8\u7406\u548c\u6458\u8981\u4efb\u52a1\u3002", "result": "\u6a21\u578b\u81ea\u6211\u6548\u80fd\u611f\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u5dee\u5f02\u663e\u8457\uff0c\u603b\u4f53\u4f4e\u4e8e\u4eba\u7c7b\u6807\u51c6\uff1b\u81ea\u6211\u8bc4\u4f30\u4e0e\u771f\u5b9e\u80fd\u529b\u4e0d\u76f8\u5173\uff1b\u81ea\u4fe1\u63d0\u793a\u4ec5\u4ea7\u751f\u9002\u5ea6\u4fee\u6b63\u3002", "conclusion": "\u5fc3\u7406\u6d4b\u91cf\u63d0\u793a\u80fd\u63d0\u4f9bLLM\u6c9f\u901a\u884c\u4e3a\u7684\u7ed3\u6784\u5316\u6d1e\u5bdf\uff0c\u4f46\u4e0d\u80fd\u63d0\u4f9b\u6821\u51c6\u7684\u6027\u80fd\u4f30\u8ba1\u3002"}}
{"id": "2511.20102", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20102", "abs": "https://arxiv.org/abs/2511.20102", "authors": ["Zhenyi Shen", "Junru Lu", "Lin Gui", "Jiazheng Li", "Yulan He", "Di Yin", "Xing Sun"], "title": "SSA: Sparse Sparse Attention by Aligning Full and Sparse Attention Outputs in Feature Space", "comment": "28 pages", "summary": "The quadratic complexity of full attention limits efficient long-context processing in large language models (LLMs). Sparse attention mitigates this cost by restricting each query to attend to a subset of previous tokens; however, training-free approaches often lead to severe performance degradation. Native sparse-attention methods (e.g., NSA, MoBA) alleviate this issue, yet exhibit a critical paradox: they produce lower attention sparsity than full-attention models, despite aiming to approximate full attention, which may constrain their effectiveness. We attribute this paradox to gradient update deficiency: low-ranked key-value pairs excluded during sparse training receive neither forward contribution nor backward gradients, and thus never learn proper suppression. To overcome this limitation, we propose SSA (Sparse Sparse Attention), a unified training framework that considers both sparse and full attention and enforces bidirectional alignment at every layer. This design preserves gradient flow to all tokens while explicitly encouraging sparse-attention outputs to align with their full-attention counterparts, thereby promoting stronger sparsity. As a result, SSA achieves state-of-the-art performance under both sparse and full attention inference across multiple commonsense benchmarks. Furthermore, SSA enables models to adapt smoothly to varying sparsity budgets; performance improves consistently as more tokens are allowed to attend, supporting flexible compute-performance trade-offs at inference time. Finally, we show that native sparse-attention training surprisingly improves long-context extrapolation by mitigating the over-allocation of attention values in sink areas, with SSA demonstrating the strongest extrapolation capability.", "AI": {"tldr": "SSA\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u7a00\u758f\u6ce8\u610f\u529b\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u5411\u5bf9\u9f50\u7a00\u758f\u548c\u5168\u6ce8\u610f\u529b\uff0c\u5728\u4fdd\u6301\u68af\u5ea6\u6d41\u5411\u6240\u6709token\u7684\u540c\u65f6\u4fc3\u8fdb\u66f4\u5f3a\u7684\u7a00\u758f\u6027\uff0c\u5b9e\u73b0\u4e86\u5728\u7a00\u758f\u548c\u5168\u6ce8\u610f\u529b\u63a8\u7406\u4e0b\u7684\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\u7684\u5173\u952e\u6096\u8bba\uff1a\u867d\u7136\u65e8\u5728\u8fd1\u4f3c\u5168\u6ce8\u610f\u529b\uff0c\u4f46\u4ea7\u751f\u7684\u6ce8\u610f\u529b\u7a00\u758f\u6027\u53cd\u800c\u4f4e\u4e8e\u5168\u6ce8\u610f\u529b\u6a21\u578b\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u6709\u6548\u6027\u3002\u4f5c\u8005\u5c06\u6b64\u5f52\u56e0\u4e8e\u68af\u5ea6\u66f4\u65b0\u4e0d\u8db3\u95ee\u9898\u3002", "method": "\u63d0\u51faSSA\uff08\u7a00\u758f\u7a00\u758f\u6ce8\u610f\u529b\uff09\u8bad\u7ec3\u6846\u67b6\uff0c\u540c\u65f6\u8003\u8651\u7a00\u758f\u548c\u5168\u6ce8\u610f\u529b\uff0c\u5728\u6bcf\u4e00\u5c42\u5f3a\u5236\u6267\u884c\u53cc\u5411\u5bf9\u9f50\u3002\u8be5\u8bbe\u8ba1\u4fdd\u6301\u6240\u6709token\u7684\u68af\u5ea6\u6d41\uff0c\u540c\u65f6\u660e\u786e\u9f13\u52b1\u7a00\u758f\u6ce8\u610f\u529b\u8f93\u51fa\u4e0e\u5176\u5168\u6ce8\u610f\u529b\u5bf9\u5e94\u7269\u5bf9\u9f50\u3002", "result": "SSA\u5728\u591a\u4e2a\u5e38\u8bc6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728\u7a00\u758f\u548c\u5168\u6ce8\u610f\u529b\u63a8\u7406\u4e0b\u90fd\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u6a21\u578b\u80fd\u591f\u5e73\u6ed1\u9002\u5e94\u4e0d\u540c\u7684\u7a00\u758f\u9884\u7b97\uff0c\u6027\u80fd\u968f\u7740\u5141\u8bb8\u5173\u6ce8\u66f4\u591atoken\u800c\u6301\u7eed\u63d0\u5347\u3002", "conclusion": "SSA\u4e0d\u4ec5\u89e3\u51b3\u4e86\u7a00\u758f\u6ce8\u610f\u529b\u8bad\u7ec3\u4e2d\u7684\u68af\u5ea6\u66f4\u65b0\u4e0d\u8db3\u95ee\u9898\uff0c\u8fd8\u610f\u5916\u5730\u6539\u5584\u4e86\u957f\u4e0a\u4e0b\u6587\u5916\u63a8\u80fd\u529b\uff0c\u901a\u8fc7\u51cf\u8f7b\u6ce8\u610f\u529b\u503c\u5728sink\u533a\u57df\u7684\u8fc7\u5ea6\u5206\u914d\uff0cSSA\u5c55\u793a\u4e86\u6700\u5f3a\u7684\u5916\u63a8\u80fd\u529b\u3002"}}
{"id": "2511.19895", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19895", "abs": "https://arxiv.org/abs/2511.19895", "authors": ["Yuanyuan Lin", "Xiangyu Ouyang", "Teng Zhang", "Kaixin Sui"], "title": "RPM-MCTS: Knowledge-Retrieval as Process Reward Model with Monte Carlo Tree Search for Code Generation", "comment": "Accepted at AAAI 2026", "summary": "Tree search-based methods have made significant progress in enhancing the code generation capabilities of large language models. However, due to the difficulty in effectively evaluating intermediate algorithmic steps and the inability to locate and timely correct erroneous steps, these methods often generate incorrect code and incur increased computational costs. To tackle these problems, we propose RPM-MCTS, an effective method that utilizes Knowledge-Retrieval as Process Reward Model based on Monte Carlo Tree Search to evaluate intermediate algorithmic steps. By utilizing knowledge base retrieval, RPM-MCTS avoids the complex training of process reward models. During the expansion phase, similarity filtering is employed to remove redundant nodes, ensuring diversity in reasoning paths. Furthermore, our method utilizes sandbox execution feedback to locate erroneous algorithmic steps during generation, enabling timely and targeted corrections. Extensive experiments on four public code generation benchmarks demonstrate that RPM-MCTS outperforms current state-of-the-art methods while achieving an approximately 15% reduction in token consumption. Furthermore, full fine-tuning of the base model using the data constructed by RPM-MCTS significantly enhances its code capabilities.", "AI": {"tldr": "RPM-MCTS\u662f\u4e00\u79cd\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7684\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u77e5\u8bc6\u68c0\u7d22\u4f5c\u4e3a\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u6765\u8bc4\u4f30\u4e2d\u95f4\u7b97\u6cd5\u6b65\u9aa4\uff0c\u65e0\u9700\u590d\u6742\u8bad\u7ec3\uff0c\u540c\u65f6\u4f7f\u7528\u6c99\u7bb1\u6267\u884c\u53cd\u9988\u5b9a\u4f4d\u548c\u7ea0\u6b63\u9519\u8bef\u6b65\u9aa4\uff0c\u5728\u51cf\u5c1115%token\u6d88\u8017\u7684\u540c\u65f6\u63d0\u5347\u4ee3\u7801\u751f\u6210\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6811\u641c\u7d22\u7684\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u8bc4\u4f30\u4e2d\u95f4\u7b97\u6cd5\u6b65\u9aa4\uff0c\u65e0\u6cd5\u53ca\u65f6\u5b9a\u4f4d\u548c\u7ea0\u6b63\u9519\u8bef\u6b65\u9aa4\uff0c\u5bfc\u81f4\u751f\u6210\u9519\u8bef\u4ee3\u7801\u548c\u8ba1\u7b97\u6210\u672c\u589e\u52a0\u3002", "method": "\u63d0\u51faRPM-MCTS\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u77e5\u8bc6\u68c0\u7d22\u4f5c\u4e3a\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\u4e2d\u95f4\u6b65\u9aa4\uff1b2) \u5728\u6269\u5c55\u9636\u6bb5\u4f7f\u7528\u76f8\u4f3c\u6027\u8fc7\u6ee4\u53bb\u9664\u5197\u4f59\u8282\u70b9\uff1b3) \u5229\u7528\u6c99\u7bb1\u6267\u884c\u53cd\u9988\u5b9a\u4f4d\u548c\u7ea0\u6b63\u9519\u8bef\u7b97\u6cd5\u6b65\u9aa4\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5171\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRPM-MCTS\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u540c\u65f6\u5b9e\u73b0\u7ea615%\u7684token\u6d88\u8017\u51cf\u5c11\u3002\u4f7f\u7528RPM-MCTS\u6784\u5efa\u7684\u6570\u636e\u5bf9\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u5168\u5fae\u8c03\u663e\u8457\u63d0\u5347\u4e86\u5176\u4ee3\u7801\u80fd\u529b\u3002", "conclusion": "RPM-MCTS\u901a\u8fc7\u7ed3\u5408\u77e5\u8bc6\u68c0\u7d22\u548c\u6c99\u7bb1\u6267\u884c\u53cd\u9988\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4e2d\u95f4\u6b65\u9aa4\u8bc4\u4f30\u548c\u9519\u8bef\u7ea0\u6b63\u95ee\u9898\uff0c\u5728\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2511.20106", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20106", "abs": "https://arxiv.org/abs/2511.20106", "authors": ["Xingfeng Li", "Xiaohan Shi", "Junjie Li", "Yongwei Li", "Masashi Unoki", "Tomoki Toda", "Masato Akagi"], "title": "EM2LDL: A Multilingual Speech Corpus for Mixed Emotion Recognition through Label Distribution Learning", "comment": "Submitted to IEEE Transactions on Affective computing", "summary": "This study introduces EM2LDL, a novel multilingual speech corpus designed to advance mixed emotion recognition through label distribution learning. Addressing the limitations of predominantly monolingual and single-label emotion corpora \\textcolor{black}{that restrict linguistic diversity, are unable to model mixed emotions, and lack ecological validity}, EM2LDL comprises expressive utterances in English, Mandarin, and Cantonese, capturing the intra-utterance code-switching prevalent in multilingual regions like Hong Kong and Macao. The corpus integrates spontaneous emotional expressions from online platforms, annotated with fine-grained emotion distributions across 32 categories. Experimental baselines using self-supervised learning models demonstrate robust performance in speaker-independent gender-, age-, and personality-based evaluations, with HuBERT-large-EN achieving optimal results. By incorporating linguistic diversity and ecological validity, EM2LDL enables the exploration of complex emotional dynamics in multilingual settings. This work provides a versatile testbed for developing adaptive, empathetic systems for applications in affective computing, including mental health monitoring and cross-cultural communication. The dataset, annotations, and baseline codes are publicly available at https://github.com/xingfengli/EM2LDL.", "AI": {"tldr": "EM2LDL\u662f\u4e00\u4e2a\u591a\u8bed\u8a00\u8bed\u97f3\u8bed\u6599\u5e93\uff0c\u901a\u8fc7\u6807\u7b7e\u5206\u5e03\u5b66\u4e60\u63a8\u8fdb\u6df7\u5408\u60c5\u611f\u8bc6\u522b\uff0c\u5305\u542b\u82f1\u8bed\u3001\u666e\u901a\u8bdd\u548c\u7ca4\u8bed\u8868\u8fbe\uff0c\u652f\u6301\u8bed\u7801\u8f6c\u6362\uff0c\u6807\u6ce8\u4e8632\u4e2a\u60c5\u611f\u7c7b\u522b\u7684\u7ec6\u7c92\u5ea6\u5206\u5e03\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u8bed\u6599\u5e93\u4e3b\u8981\u4e3a\u5355\u8bed\u8a00\u3001\u5355\u6807\u7b7e\u60c5\u611f\u8bc6\u522b\u7684\u95ee\u9898\uff0c\u8fd9\u4e9b\u8bed\u6599\u5e93\u9650\u5236\u4e86\u8bed\u8a00\u591a\u6837\u6027\uff0c\u65e0\u6cd5\u5efa\u6a21\u6df7\u5408\u60c5\u611f\uff0c\u4e14\u7f3a\u4e4f\u751f\u6001\u6548\u5ea6\u3002", "method": "\u6784\u5efa\u5305\u542b\u82f1\u8bed\u3001\u666e\u901a\u8bdd\u548c\u7ca4\u8bed\u7684\u591a\u8bed\u8a00\u8bed\u6599\u5e93\uff0c\u6574\u5408\u6765\u81ea\u5728\u7ebf\u5e73\u53f0\u7684\u81ea\u53d1\u60c5\u611f\u8868\u8fbe\uff0c\u4f7f\u7528\u6807\u7b7e\u5206\u5e03\u5b66\u4e60\u8fdb\u884c\u7ec6\u7c92\u5ea6\u60c5\u611f\u6807\u6ce8\u3002", "result": "\u57fa\u4e8e\u81ea\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u7684\u5b9e\u9a8c\u57fa\u7ebf\u5728\u8bf4\u8bdd\u4eba\u65e0\u5173\u7684\u6027\u522b\u3001\u5e74\u9f84\u548c\u4e2a\u6027\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u7a33\u5065\u6027\u80fd\uff0cHuBERT-large-EN\u6a21\u578b\u53d6\u5f97\u6700\u4f18\u7ed3\u679c\u3002", "conclusion": "EM2LDL\u901a\u8fc7\u6574\u5408\u8bed\u8a00\u591a\u6837\u6027\u548c\u751f\u6001\u6548\u5ea6\uff0c\u4e3a\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u590d\u6742\u60c5\u611f\u52a8\u6001\u7684\u63a2\u7d22\u63d0\u4f9b\u4e86\u53ef\u80fd\uff0c\u4e3a\u5f00\u53d1\u9002\u5e94\u6027\u5f3a\u7684\u5171\u60c5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u591a\u529f\u80fd\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2511.19925", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19925", "abs": "https://arxiv.org/abs/2511.19925", "authors": ["Qiyao Wei", "Edward Morrell", "Lea Goetz", "Mihaela van der Schaar"], "title": "Semantic-KG: Using Knowledge Graphs to Construct Benchmarks for Measuring Semantic Similarity", "comment": null, "summary": "Evaluating the open-form textual responses generated by Large Language Models (LLMs) typically requires measuring the semantic similarity of the response to a (human generated) reference. However, there is evidence that current semantic similarity methods may capture syntactic or lexical forms over semantic content. While benchmarks exist for semantic equivalence, they often suffer from high generation costs due to reliance on subjective human judgment, limited availability for domain-specific applications, and unclear definitions of equivalence. This paper introduces a novel method for generating benchmarks to evaluate semantic similarity methods for LLM outputs, specifically addressing these limitations. Our approach leverages knowledge graphs (KGs) to generate pairs of natural-language statements that are semantically similar or dissimilar, with dissimilar pairs categorized into one of four sub-types. We generate benchmark datasets in four different domains (general knowledge, biomedicine, finance, biology), and conduct a comparative study of semantic similarity methods including traditional natural language processing scores and LLM-as-a-judge predictions. We observe that the sub-type of semantic variation, as well as the domain of the benchmark impact the performance of semantic similarity methods, with no method being consistently superior. Our results present important implications for the use of LLM-as-a-judge in detecting the semantic content of text. Code is available at https://github.com/QiyaoWei/semantic-kg and the dataset is available at https://huggingface.co/datasets/QiyaoWei/Semantic-KG.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u57fa\u51c6\u6570\u636e\u96c6\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u8f93\u51fa\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u3001\u6210\u672c\u9ad8\u3001\u9886\u57df\u9002\u7528\u6027\u6709\u9650\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30LLM\u6587\u672c\u8f93\u51fa\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u65b9\u6cd5\u5b58\u5728\u7f3a\u9677\uff0c\u53ef\u80fd\u66f4\u5173\u6ce8\u53e5\u6cd5\u6216\u8bcd\u6c47\u5f62\u5f0f\u800c\u975e\u8bed\u4e49\u5185\u5bb9\uff0c\u4e14\u73b0\u6709\u57fa\u51c6\u4f9d\u8d56\u4e3b\u89c2\u4eba\u5de5\u5224\u65ad\u3001\u751f\u6210\u6210\u672c\u9ad8\u3001\u9886\u57df\u9002\u7528\u6027\u6709\u9650\u3001\u7b49\u4ef7\u5b9a\u4e49\u4e0d\u660e\u786e\u3002", "method": "\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u8bed\u4e49\u76f8\u4f3c\u6216\u4e0d\u76f8\u4f3c\u7684\u81ea\u7136\u8bed\u8a00\u9648\u8ff0\u5bf9\uff0c\u4e0d\u76f8\u4f3c\u5bf9\u5206\u4e3a\u56db\u79cd\u5b50\u7c7b\u578b\uff0c\u5728\u56db\u4e2a\u4e0d\u540c\u9886\u57df\uff08\u5e38\u8bc6\u3001\u751f\u7269\u533b\u5b66\u3001\u91d1\u878d\u3001\u751f\u7269\u5b66\uff09\u751f\u6210\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u6bd4\u8f83\u4f20\u7edfNLP\u8bc4\u5206\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8bed\u4e49\u53d8\u5316\u7684\u5b50\u7c7b\u578b\u548c\u57fa\u51c6\u9886\u57df\u90fd\u4f1a\u5f71\u54cd\u8bed\u4e49\u76f8\u4f3c\u6027\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u6ca1\u6709\u54ea\u79cd\u65b9\u6cd5\u59cb\u7ec8\u8868\u73b0\u6700\u4f18\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5bf9\u4f7f\u7528LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u68c0\u6d4b\u6587\u672c\u8bed\u4e49\u5185\u5bb9\u5177\u6709\u91cd\u8981\u542f\u793a\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u751f\u6210\u4f4e\u6210\u672c\u3001\u9ad8\u8d28\u91cf\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u8bc4\u4f30\u57fa\u51c6\u3002"}}
{"id": "2511.20107", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2511.20107", "abs": "https://arxiv.org/abs/2511.20107", "authors": ["Huu Tuong Tu", "Ha Viet Khanh", "Tran Tien Dat", "Vu Huan", "Thien Van Luong", "Nguyen Tien Cuong", "Nguyen Thi Thu Trang"], "title": "Mispronunciation Detection and Diagnosis Without Model Training: A Retrieval-Based Approach", "comment": null, "summary": "Mispronunciation Detection and Diagnosis (MDD) is crucial for language learning and speech therapy. Unlike conventional methods that require scoring models or training phoneme-level models, we propose a novel training-free framework that leverages retrieval techniques with a pretrained Automatic Speech Recognition model. Our method avoids phoneme-specific modeling or additional task-specific training, while still achieving accurate detection and diagnosis of pronunciation errors. Experiments on the L2-ARCTIC dataset show that our method achieves a superior F1 score of 69.60% while avoiding the complexity of model training.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u68c0\u7d22\u6280\u672f\u7684\u514d\u8bad\u7ec3MDD\u6846\u67b6\uff0c\u5229\u7528\u9884\u8bad\u7ec3ASR\u6a21\u578b\u5b9e\u73b0\u53d1\u97f3\u9519\u8bef\u68c0\u6d4b\u548c\u8bca\u65ad\uff0c\u65e0\u9700\u97f3\u7d20\u7ea7\u5efa\u6a21\u6216\u989d\u5916\u8bad\u7ec3", "motivation": "\u4f20\u7edfMDD\u65b9\u6cd5\u9700\u8981\u8bc4\u5206\u6a21\u578b\u6216\u97f3\u7d20\u7ea7\u6a21\u578b\u8bad\u7ec3\uff0c\u8fc7\u7a0b\u590d\u6742\u4e14\u8d44\u6e90\u6d88\u8017\u5927\uff0c\u9700\u8981\u66f4\u7b80\u5355\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u4f7f\u7528\u68c0\u7d22\u6280\u672f\u4e0e\u9884\u8bad\u7ec3ASR\u6a21\u578b\u7ed3\u5408\u7684\u8bad\u7ec3\u514d\u8d39\u6846\u67b6\uff0c\u907f\u514d\u97f3\u7d20\u7279\u5b9a\u5efa\u6a21\u548c\u4efb\u52a1\u7279\u5b9a\u8bad\u7ec3", "result": "\u5728L2-ARCTIC\u6570\u636e\u96c6\u4e0a\u8fbe\u523069.60%\u7684F1\u5206\u6570\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u907f\u514d\u6a21\u578b\u8bad\u7ec3\u590d\u6742\u6027\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u51c6\u786e\u7684\u53d1\u97f3\u9519\u8bef\u68c0\u6d4b\u548c\u8bca\u65ad"}}
{"id": "2511.19933", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19933", "abs": "https://arxiv.org/abs/2511.19933", "authors": ["Vaishali Vinay"], "title": "A System-Level Taxonomy of Failure Modes in Large Language Model Applications", "comment": null, "summary": "Large language models (LLMs) are being rapidly integrated into decision-support tools, automation workflows, and AI-enabled software systems. However, their behavior in production environments remains poorly understood, and their failure patterns differ fundamentally from those of traditional machine learning models. This paper presents a system-level taxonomy of fifteen hidden failure modes that arise in real-world LLM applications, including multi-step reasoning drift, latent inconsistency, context-boundary degradation, incorrect tool invocation, version drift, and cost-driven performance collapse. Using this taxonomy, we analyze the growing gap in evaluation and monitoring practices: existing benchmarks measure knowledge or reasoning but provide little insight into stability, reproducibility, drift, or workflow integration. We further examine the production challenges associated with deploying LLMs - including observability limitations, cost constraints, and update-induced regressions - and outline high-level design principles for building reliable, maintainable, and cost-aware LLM systems. Finally, we outline high-level design principles for building reliable, maintainable, and cost-aware LLM-based systems. By framing LLM reliability as a system-engineering problem rather than a purely model-centric one, this work provides an analytical foundation for future research on evaluation methodology, AI system robustness, and dependable LLM deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u7ea7\u7684LLM\u9690\u85cf\u6545\u969c\u6a21\u5f0f\u5206\u7c7b\u6cd5\uff0c\u5206\u6790\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u6784\u5efa\u53ef\u9760LLM\u7cfb\u7edf\u7684\u8bbe\u8ba1\u539f\u5219\u3002", "motivation": "\u968f\u7740LLM\u88ab\u5feb\u901f\u96c6\u6210\u5230\u51b3\u7b56\u652f\u6301\u5de5\u5177\u548c\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u4e2d\uff0c\u5176\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u884c\u4e3a\u4ecd\u672a\u88ab\u5145\u5206\u7406\u89e3\uff0c\u4e14\u6545\u969c\u6a21\u5f0f\u4e0e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6709\u6839\u672c\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u4e86\u5305\u542b15\u79cd\u771f\u5b9e\u4e16\u754cLLM\u5e94\u7528\u6545\u969c\u6a21\u5f0f\u7684\u7cfb\u7edf\u7ea7\u5206\u7c7b\u6cd5\uff0c\u5305\u62ec\u591a\u6b65\u63a8\u7406\u6f02\u79fb\u3001\u6f5c\u5728\u4e0d\u4e00\u81f4\u6027\u3001\u4e0a\u4e0b\u6587\u8fb9\u754c\u9000\u5316\u7b49\uff0c\u5e76\u5206\u6790\u4e86\u8bc4\u4f30\u548c\u76d1\u63a7\u5b9e\u8df5\u7684\u5dee\u8ddd\u3002", "result": "\u8bc6\u522b\u4e86\u90e8\u7f72LLM\u7684\u751f\u4ea7\u6311\u6218\uff0c\u5305\u62ec\u53ef\u89c2\u6d4b\u6027\u9650\u5236\u3001\u6210\u672c\u7ea6\u675f\u548c\u66f4\u65b0\u5f15\u53d1\u7684\u56de\u5f52\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u5206\u6790\u57fa\u7840\u3002", "conclusion": "\u901a\u8fc7\u5c06LLM\u53ef\u9760\u6027\u89c6\u4e3a\u7cfb\u7edf\u5de5\u7a0b\u95ee\u9898\u800c\u975e\u7eaf\u6a21\u578b\u4e2d\u5fc3\u95ee\u9898\uff0c\u4e3a\u8bc4\u4f30\u65b9\u6cd5\u3001AI\u7cfb\u7edf\u9c81\u68d2\u6027\u548c\u53ef\u9760LLM\u90e8\u7f72\u7684\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6846\u67b6\u3002"}}
{"id": "2511.20120", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20120", "abs": "https://arxiv.org/abs/2511.20120", "authors": ["Somsubhra De", "Harsh Kumar", "Arun Prakash A"], "title": "\"When Data is Scarce, Prompt Smarter\"... Approaches to Grammatical Error Correction in Low-Resource Settings", "comment": "10 pages, 5 figures, 5 tables; Accept-demonstration at BHASHA Workshop, IJCNLP-AACL 2025", "summary": "Grammatical error correction (GEC) is an important task in Natural Language Processing that aims to automatically detect and correct grammatical mistakes in text. While recent advances in transformer-based models and large annotated datasets have greatly improved GEC performance for high-resource languages such as English, the progress has not extended equally. For most Indic languages, GEC remains a challenging task due to limited resources, linguistic diversity and complex morphology. In this work, we explore prompting-based approaches using state-of-the-art large language models (LLMs), such as GPT-4.1, Gemini-2.5 and LLaMA-4, combined with few-shot strategy to adapt them to low-resource settings. We observe that even basic prompting strategies, such as zero-shot and few-shot approaches, enable these LLMs to substantially outperform fine-tuned Indic-language models like Sarvam-22B, thereby illustrating the exceptional multilingual generalization capabilities of contemporary LLMs for GEC. Our experiments show that carefully designed prompts and lightweight adaptation significantly enhance correction quality across multiple Indic languages. We achieved leading results in the shared task--ranking 1st in Tamil (GLEU: 91.57) and Hindi (GLEU: 85.69), 2nd in Telugu (GLEU: 85.22), 4th in Bangla (GLEU: 92.86), and 5th in Malayalam (GLEU: 92.97). These findings highlight the effectiveness of prompt-driven NLP techniques and underscore the potential of large-scale LLMs to bridge resource gaps in multilingual GEC.", "AI": {"tldr": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08GPT-4.1\u3001Gemini-2.5\u3001LLaMA-4\uff09\u7ed3\u5408\u5c11\u91cf\u6837\u672c\u63d0\u793a\u7b56\u7565\uff0c\u5728\u4f4e\u8d44\u6e90\u5370\u5ea6\u8bed\u8a00\u4e2d\u5b9e\u73b0\u8bed\u6cd5\u9519\u8bef\u6821\u6b63\u7684\u9886\u5148\u6027\u80fd\u3002", "motivation": "\u5370\u5ea6\u8bed\u8a00\u7684\u8bed\u6cd5\u9519\u8bef\u6821\u6b63\u9762\u4e34\u8d44\u6e90\u6709\u9650\u3001\u8bed\u8a00\u591a\u6837\u6027\u548c\u590d\u6742\u5f62\u6001\u5b66\u7684\u6311\u6218\uff0c\u800c\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u5728\u9ad8\u8d44\u6e90\u8bed\u8a00\uff08\u5982\u82f1\u8bed\uff09\u4e2d\u8868\u73b0\u826f\u597d\u4f46\u672a\u5e73\u7b49\u6269\u5c55\u5230\u5370\u5ea6\u8bed\u8a00\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u96f6\u6837\u672c\u548c\u5c11\u91cf\u6837\u672c\u7b56\u7565\uff0c\u7ed3\u5408\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u548c\u8f7b\u91cf\u7ea7\u9002\u5e94\u6280\u672f\u3002", "result": "\u5728\u5171\u4eab\u4efb\u52a1\u4e2d\u53d6\u5f97\u9886\u5148\u7ed3\u679c\uff1a\u6cf0\u7c73\u5c14\u8bed\u7b2c1\u540d\uff08GLEU: 91.57\uff09\u3001\u5370\u5730\u8bed\u7b2c1\u540d\uff08GLEU: 85.69\uff09\u3001\u6cf0\u5362\u56fa\u8bed\u7b2c2\u540d\uff08GLEU: 85.22\uff09\u3001\u5b5f\u52a0\u62c9\u8bed\u7b2c4\u540d\uff08GLEU: 92.86\uff09\u3001\u9a6c\u62c9\u96c5\u62c9\u59c6\u8bed\u7b2c5\u540d\uff08GLEU: 92.97\uff09\u3002", "conclusion": "\u63d0\u793a\u9a71\u52a8\u7684NLP\u6280\u672f\u6709\u6548\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u6709\u5353\u8d8a\u7684\u591a\u8bed\u8a00\u6cdb\u5316\u80fd\u529b\uff0c\u80fd\u591f\u5f25\u5408\u591a\u8bed\u8a00\u8bed\u6cd5\u9519\u8bef\u6821\u6b63\u4e2d\u7684\u8d44\u6e90\u5dee\u8ddd\u3002"}}
{"id": "2511.19969", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19969", "abs": "https://arxiv.org/abs/2511.19969", "authors": ["Weizi Shao", "Taolin Zhang", "Zijie Zhou", "Chen Chen", "Chengyu Wang", "Xiaofeng He"], "title": "M$^3$Prune: Hierarchical Communication Graph Pruning for Efficient Multi-Modal Multi-Agent Retrieval-Augmented Generation", "comment": null, "summary": "Recent advancements in multi-modal retrieval-augmented generation (mRAG), which enhance multi-modal large language models (MLLMs) with external knowledge, have demonstrated that the collective intelligence of multiple agents can significantly outperform a single model through effective communication. Despite impressive performance, existing multi-agent systems inherently incur substantial token overhead and increased computational costs, posing challenges for large-scale deployment. To address these issues, we propose a novel Multi-Modal Multi-agent hierarchical communication graph PRUNING framework, termed M$^3$Prune. Our framework eliminates redundant edges across different modalities, achieving an optimal balance between task performance and token overhead. Specifically, M$^3$Prune first applies intra-modal graph sparsification to textual and visual modalities, identifying the edges most critical for solving the task. Subsequently, we construct a dynamic communication topology using these key edges for inter-modal graph sparsification. Finally, we progressively prune redundant edges to obtain a more efficient and hierarchical topology. Extensive experiments on both general and domain-specific mRAG benchmarks demonstrate that our method consistently outperforms both single-agent and robust multi-agent mRAG systems while significantly reducing token consumption.", "AI": {"tldr": "\u63d0\u51faM\u00b3Prune\u6846\u67b6\uff0c\u901a\u8fc7\u526a\u679d\u591a\u6a21\u6001\u591a\u4ee3\u7406\u901a\u4fe1\u56fe\u4e2d\u7684\u5197\u4f59\u8fb9\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4etoken\u5f00\u9500", "motivation": "\u73b0\u6709\u591a\u4ee3\u7406\u7cfb\u7edf\u5b58\u5728\u5927\u91cftoken\u5f00\u9500\u548c\u8ba1\u7b97\u6210\u672c\u95ee\u9898\uff0c\u96be\u4ee5\u5927\u89c4\u6a21\u90e8\u7f72", "method": "\u5148\u8fdb\u884c\u6a21\u6001\u5185\u56fe\u7a00\u758f\u5316\u8bc6\u522b\u5173\u952e\u8fb9\uff0c\u7136\u540e\u6784\u5efa\u52a8\u6001\u901a\u4fe1\u62d3\u6251\u8fdb\u884c\u6a21\u6001\u95f4\u56fe\u7a00\u758f\u5316\uff0c\u6700\u540e\u6e10\u8fdb\u526a\u679d\u5197\u4f59\u8fb9", "result": "\u5728\u901a\u7528\u548c\u9886\u57df\u7279\u5b9amRAG\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u5355\u4ee3\u7406\u548c\u73b0\u6709\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11token\u6d88\u8017", "conclusion": "M\u00b3Prune\u6846\u67b6\u80fd\u6709\u6548\u5e73\u8861\u4efb\u52a1\u6027\u80fd\u548ctoken\u5f00\u9500\uff0c\u4e3a\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2511.20143", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.20143", "abs": "https://arxiv.org/abs/2511.20143", "authors": ["Wen-Fang Su", "Hsiao-Wei Chou", "Wen-Yang Lin"], "title": "SEDA: A Self-Adapted Entity-Centric Data Augmentation for Boosting Gird-based Discontinuous NER Models", "comment": "9 pages, 5 figures", "summary": "Named Entity Recognition (NER) is a critical task in natural language processing, yet it remains particularly challenging for discontinuous entities. The primary difficulty lies in text segmentation, as traditional methods often missegment or entirely miss cross-sentence discontinuous entities, significantly affecting recognition accuracy. Therefore, we aim to address the segmentation and omission issues associated with such entities. Recent studies have shown that grid-tagging methods are effective for information extraction due to their flexible tagging schemes and robust architectures. Building on this, we integrate image data augmentation techniques, such as cropping, scaling, and padding, into grid-based models to enhance their ability to recognize discontinuous entities and handle segmentation challenges. Experimental results demonstrate that traditional segmentation methods often fail to capture cross-sentence discontinuous entities, leading to decreased performance. In contrast, our augmented grid models achieve notable improvements. Evaluations on the CADEC, ShARe13, and ShARe14 datasets show F1 score gains of 1-2.5% overall and 3.7-8.4% for discontinuous entities, confirming the effectiveness of our approach.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u56fe\u50cf\u6570\u636e\u589e\u5f3a\u6280\u672f\u7684\u7f51\u683c\u6807\u6ce8\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdb\u4e0d\u8fde\u7eed\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u8de8\u53e5\u5b50\u4e0d\u8fde\u7eed\u5b9e\u4f53\u4e0a\u7684\u5206\u5272\u548c\u9057\u6f0f\u95ee\u9898\u3002", "motivation": "\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4e2d\u4e0d\u8fde\u7eed\u5b9e\u4f53\u8bc6\u522b\u5177\u6709\u6311\u6218\u6027\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u6587\u672c\u5206\u5272\u65f6\u5bb9\u6613\u9519\u8bef\u5206\u5272\u6216\u5b8c\u5168\u9057\u6f0f\u8de8\u53e5\u5b50\u7684\u4e0d\u8fde\u7eed\u5b9e\u4f53\uff0c\u4e25\u91cd\u5f71\u54cd\u8bc6\u522b\u51c6\u786e\u6027\u3002", "method": "\u57fa\u4e8e\u7f51\u683c\u6807\u6ce8\u65b9\u6cd5\uff0c\u6574\u5408\u56fe\u50cf\u6570\u636e\u589e\u5f3a\u6280\u672f\uff08\u5982\u88c1\u526a\u3001\u7f29\u653e\u548c\u586b\u5145\uff09\u5230\u7f51\u683c\u6a21\u578b\u4e2d\uff0c\u589e\u5f3a\u5bf9\u4e0d\u8fde\u7eed\u5b9e\u4f53\u7684\u8bc6\u522b\u80fd\u529b\u548c\u5904\u7406\u5206\u5272\u6311\u6218\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u4f20\u7edf\u5206\u5272\u65b9\u6cd5\u5728\u8de8\u53e5\u5b50\u4e0d\u8fde\u7eed\u5b9e\u4f53\u8bc6\u522b\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u589e\u5f3a\u7684\u7f51\u683c\u6a21\u578b\u5728CADEC\u3001ShARe13\u548cShARe14\u6570\u636e\u96c6\u4e0aF1\u5206\u6570\u6574\u4f53\u63d0\u53471-2.5%\uff0c\u4e0d\u8fde\u7eed\u5b9e\u4f53\u8bc6\u522b\u63d0\u53473.7-8.4%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u589e\u5f3a\u7f51\u683c\u6a21\u578b\u6709\u6548\u89e3\u51b3\u4e86\u4e0d\u8fde\u7eed\u5b9e\u4f53\u8bc6\u522b\u4e2d\u7684\u5206\u5272\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bc6\u522b\u6027\u80fd\u3002"}}
{"id": "2511.20048", "categories": ["cs.AI", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.20048", "abs": "https://arxiv.org/abs/2511.20048", "authors": ["Zixiao Huang", "Wen Zeng", "Tianyu Fu", "Tengxuan Liu", "Yizhou Sun", "Ke Hong", "Xinhao Yang", "Chengchun Liu", "Yan Li", "Quanlu Zhang", "Guohao Dai", "Zhenhua Zhu", "Yu Wang"], "title": "Reducing Latency of LLM Search Agent via Speculation-based Algorithm-System Co-Design", "comment": null, "summary": "LLM-based search agents achieve strong performance but suffer from severe latency, as each step requires serialized LLM reasoning followed by action of tool execution. We revisit this bottleneck through the lens of speculation. While traditional predict-verify speculation paradigm can break serial execution, its benefit remains limited, as it retains the full original workload and adds extra inference overhead. We observe that early agent steps often involve simple evidence-gathering, where correct actions can often be predicted without full reasoning. Building on these observations, we present SPAgent, an algorithm-system co-design framework that expands the role of speculation in search agents to reduce latency. Algorithmically, SPAgent introduces a two-phase adaptive speculation mechanism that selectively omits verification when safe. System-wise, a two-level scheduler regulates speculative requests based on engine load to ensure speculation remains beneficial. We implement SPAgent in real-world systems. Across extensive experimental settings, SPAgent achieves up to $1.65\\times$ end-to-end speedup while maintaining same or even achieving higher accuracy, enabling practical deployment of multi-step search agents.", "AI": {"tldr": "SPAgent\u662f\u4e00\u4e2a\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u81ea\u9002\u5e94\u63a8\u6d4b\u673a\u5236\u548c\u4e24\u7ea7\u8c03\u5ea6\u5668\uff0c\u663e\u8457\u964d\u4f4e\u57fa\u4e8eLLM\u7684\u641c\u7d22\u4ee3\u7406\u7684\u5ef6\u8fdf\uff0c\u5b9e\u73b0\u6700\u9ad81.65\u500d\u7684\u7aef\u5230\u7aef\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u57fa\u4e8eLLM\u7684\u641c\u7d22\u4ee3\u7406\u867d\u7136\u6027\u80fd\u5f3a\u5927\u4f46\u5ef6\u8fdf\u4e25\u91cd\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u6b65\u9aa4\u90fd\u9700\u8981\u4e32\u884c\u5316\u7684LLM\u63a8\u7406\u548c\u5de5\u5177\u6267\u884c\u3002\u4f20\u7edf\u63a8\u6d4b\u8303\u5f0f\u867d\u7136\u80fd\u6253\u7834\u4e32\u884c\u6267\u884c\uff0c\u4f46\u6536\u76ca\u6709\u9650\uff0c\u56e0\u4e3a\u5b83\u4fdd\u7559\u4e86\u5b8c\u6574\u7684\u5de5\u4f5c\u8d1f\u8f7d\u5e76\u589e\u52a0\u4e86\u989d\u5916\u7684\u63a8\u7406\u5f00\u9500\u3002", "method": "SPAgent\u91c7\u7528\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\uff1a\u7b97\u6cd5\u5c42\u9762\u5f15\u5165\u4e24\u9636\u6bb5\u81ea\u9002\u5e94\u63a8\u6d4b\u673a\u5236\uff0c\u5728\u5b89\u5168\u65f6\u9009\u62e9\u6027\u5730\u7701\u7565\u9a8c\u8bc1\uff1b\u7cfb\u7edf\u5c42\u9762\u4f7f\u7528\u4e24\u7ea7\u8c03\u5ea6\u5668\u6839\u636e\u5f15\u64ce\u8d1f\u8f7d\u8c03\u8282\u63a8\u6d4b\u8bf7\u6c42\uff0c\u786e\u4fdd\u63a8\u6d4b\u4fdd\u6301\u6709\u76ca\u3002", "result": "\u5728\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bbe\u7f6e\u4e2d\uff0cSPAgent\u5b9e\u73b0\u4e86\u6700\u9ad81.65\u500d\u7684\u7aef\u5230\u7aef\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u540c\u751a\u81f3\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u4f7f\u591a\u6b65\u9aa4\u641c\u7d22\u4ee3\u7406\u7684\u5b9e\u9645\u90e8\u7f72\u6210\u4e3a\u53ef\u80fd\u3002", "conclusion": "SPAgent\u901a\u8fc7\u6269\u5c55\u63a8\u6d4b\u5728\u641c\u7d22\u4ee3\u7406\u4e2d\u7684\u4f5c\u7528\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u641c\u7d22\u4ee3\u7406\u7684\u5ef6\u8fdf\u74f6\u9888\uff0c\u4e3a\u591a\u6b65\u9aa4\u641c\u7d22\u4ee3\u7406\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20182", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20182", "abs": "https://arxiv.org/abs/2511.20182", "authors": ["Adilet Metinov", "Gulida M. Kudakeeva", "Gulnara D. Kabaeva"], "title": "KyrgyzBERT: A Compact, Efficient Language Model for Kyrgyz NLP", "comment": "3 pages, 1 figure, 2 tables. Preprint", "summary": "Kyrgyz remains a low-resource language with limited foundational NLP tools. To address this gap, we introduce KyrgyzBERT, the first publicly available monolingual BERT-based language model for Kyrgyz. The model has 35.9M parameters and uses a custom tokenizer designed for the language's morphological structure. To evaluate performance, we create kyrgyz-sst2, a sentiment analysis benchmark built by translating the Stanford Sentiment Treebank and manually annotating the full test set. KyrgyzBERT fine-tuned on this dataset achieves an F1-score of 0.8280, competitive with a fine-tuned mBERT model five times larger. All models, data, and code are released to support future research in Kyrgyz NLP.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u516c\u5f00\u53ef\u7528\u7684\u5409\u5c14\u5409\u65af\u8bed\u5355\u8bedBERT\u6a21\u578bKyrgyzBERT\uff0c\u5305\u542b35.9M\u53c2\u6570\u548c\u5b9a\u5236\u5206\u8bcd\u5668\uff0c\u5728\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0e5\u500d\u5927\u7684mBERT\u6a21\u578b\u76f8\u5f53\u3002", "motivation": "\u5409\u5c14\u5409\u65af\u8bed\u4f5c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u7f3a\u4e4f\u57fa\u7840NLP\u5de5\u5177\uff0c\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u7684\u8bed\u8a00\u6a21\u578b\u6765\u652f\u6301\u8be5\u8bed\u8a00\u7684NLP\u7814\u7a76\u3002", "method": "\u5f00\u53d1\u4e86KyrgyzBERT\u6a21\u578b\uff0c\u4f7f\u7528\u5b9a\u5236\u5206\u8bcd\u5668\u9002\u5e94\u5409\u5c14\u5409\u65af\u8bed\u7684\u5f62\u6001\u7ed3\u6784\uff0c\u5e76\u901a\u8fc7\u7ffb\u8bd1\u548c\u624b\u52a8\u6807\u6ce8\u521b\u5efa\u4e86kyrgyz-sst2\u60c5\u611f\u5206\u6790\u57fa\u51c6\u6570\u636e\u96c6\u3002", "result": "KyrgyzBERT\u5728\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e0a\u8fbe\u52300.8280\u7684F1\u5206\u6570\uff0c\u4e0e\u53c2\u6570\u91cf5\u500d\u5927\u7684mBERT\u6a21\u578b\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "KyrgyzBERT\u586b\u8865\u4e86\u5409\u5c14\u5409\u65af\u8bedNLP\u5de5\u5177\u7684\u7a7a\u767d\uff0c\u6240\u6709\u6a21\u578b\u3001\u6570\u636e\u548c\u4ee3\u7801\u90fd\u5df2\u516c\u5f00\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2511.20067", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.20067", "abs": "https://arxiv.org/abs/2511.20067", "authors": ["Marta Sumyk", "Oleksandr Kosovan"], "title": "\"Are We Done Yet?\": A Vision-Based Judge for Autonomous Task Completion of Computer Use Agents", "comment": "This work has been accepted to appear at the AAAI 2026 Workshop on Trust and Control in Agentic AI (TrustAgent)", "summary": "Computer Use Agents (CUAs) are designed to autonomously operate digital interfaces, yet they often fail to reliably determine whether a given task has been completed. We present an autonomous evaluation and feedback framework that uses vision-language models to assess task completion directly from screenshots and task descriptions. Our dataset covers 42 built-in macOS applications and 1,260 human-labeled tasks across a wide range of scenarios. Our framework achieves up to 73 percent accuracy in task success detection and yields an average relative improvement of 27 percent in overall task success when evaluator feedback is applied. These results show that vision-based evaluation can serve as an effective feedback mechanism that improves the reliability and self-correction of autonomous computer-use agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u4e3b\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u622a\u56fe\u76f4\u63a5\u8bc4\u4f30\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u4efb\u52a1\u5b8c\u6210\u60c5\u51b5\uff0c\u5728macOS\u5e94\u7528\u4e2d\u8fbe\u523073%\u7684\u51c6\u786e\u7387\uff0c\u4f7f\u4efb\u52a1\u6210\u529f\u7387\u76f8\u5bf9\u63d0\u534727%\u3002", "motivation": "\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u5728\u81ea\u4e3b\u64cd\u4f5c\u6570\u5b57\u754c\u9762\u65f6\uff0c\u5f80\u5f80\u96be\u4ee5\u53ef\u9760\u5224\u65ad\u4efb\u52a1\u662f\u5426\u5b8c\u6210\uff0c\u9700\u8981\u6709\u6548\u7684\u8bc4\u4f30\u548c\u53cd\u9988\u673a\u5236\u6765\u63d0\u9ad8\u53ef\u9760\u6027\u3002", "method": "\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u4ece\u622a\u56fe\u548c\u4efb\u52a1\u63cf\u8ff0\u4e2d\u8bc4\u4f30\u4efb\u52a1\u5b8c\u6210\u60c5\u51b5\uff0c\u6784\u5efa\u4e86\u5305\u542b42\u4e2amacOS\u5e94\u7528\u548c1260\u4e2a\u4eba\u5de5\u6807\u6ce8\u4efb\u52a1\u7684\u6570\u636e\u96c6\u3002", "result": "\u4efb\u52a1\u6210\u529f\u68c0\u6d4b\u51c6\u786e\u7387\u8fbe\u523073%\uff0c\u5e94\u7528\u8bc4\u4f30\u5668\u53cd\u9988\u540e\u6574\u4f53\u4efb\u52a1\u6210\u529f\u7387\u76f8\u5bf9\u63d0\u534727%\u3002", "conclusion": "\u57fa\u4e8e\u89c6\u89c9\u7684\u8bc4\u4f30\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u7684\u53cd\u9988\u673a\u5236\uff0c\u63d0\u9ad8\u81ea\u4e3b\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u53ef\u9760\u6027\u548c\u81ea\u6211\u7ea0\u6b63\u80fd\u529b\u3002"}}
{"id": "2511.20233", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20233", "abs": "https://arxiv.org/abs/2511.20233", "authors": ["Chuyi Kong", "Gao Wei", "Jing Ma", "Hongzhan Lin", "Zhiyuan Fan"], "title": "REFLEX: Self-Refining Explainable Fact-Checking via Disentangling Truth into Style and Substance", "comment": null, "summary": "The prevalence of misinformation on social media threatens public trust, demanding automated fact-checking systems that provide accurate verdicts with interpretable explanations. However, existing large language model-based (LLM-based) approaches often rely heavily on external knowledge sources, introducing substantial latency and even hallucinations that undermine reliability, interpretability, and responsiveness, which is crucial for real-time use. To address these challenges, we propose REason-guided Fact-checking with Latent EXplanations REFLEX paradigm, a plug-and-play, self-refining paradigm that leverages the internal knowledge in backbone model to improve both verdict accuracy and explanation quality. REFLEX reformulates fact-checking as a role-play dialogue and jointly trains verdict prediction and explanation generation. It adaptively extracts contrastive activation pairs between the backbone model and its fine-tuned variant to construct steering vectors that disentangle truth into style and substance naturally. These activation-level signals guide inference and suppress noisy explanations, enabling more faithful and efficient reasoning. Experiments on real-world datasets show that REFLEX outperforms previous methods that steer toward a single truth direction and underscores the challenge traditional approaches face when handling the subtle, human-unknown truth in fact-checking tasks. Remarkably, with only 465 self-refined training samples, RELFEX achieves state-of-the-art performance. Furthermore, models trained with explanatory objectives can effectively guide those without them, yielding up to a 7.57% improvement, highlighting that internal explanation signals play a dual role in both interpreting and enhancing factual reasoning.", "AI": {"tldr": "REFLEX\u662f\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u8303\u5f0f\uff0c\u901a\u8fc7\u89d2\u8272\u626e\u6f14\u5bf9\u8bdd\u8054\u5408\u8bad\u7ec3\u88c1\u51b3\u9884\u6d4b\u548c\u89e3\u91ca\u751f\u6210\uff0c\u5229\u7528\u5bf9\u6bd4\u6fc0\u6d3b\u5bf9\u6784\u5efa\u8f6c\u5411\u5411\u91cf\u6765\u5206\u79bb\u771f\u76f8\u7684\u98ce\u683c\u548c\u5b9e\u8d28\uff0c\u5728\u5c11\u91cf\u8bad\u7ec3\u6837\u672c\u4e0b\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u4e8b\u5b9e\u6838\u67e5\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u5916\u90e8\u77e5\u8bc6\u6e90\uff0c\u5bfc\u81f4\u5ef6\u8fdf\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u5f71\u54cd\u53ef\u9760\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u65f6\u6027\u3002", "method": "\u5c06\u4e8b\u5b9e\u6838\u67e5\u91cd\u65b0\u5b9a\u4e49\u4e3a\u89d2\u8272\u626e\u6f14\u5bf9\u8bdd\uff0c\u8054\u5408\u8bad\u7ec3\u88c1\u51b3\u9884\u6d4b\u548c\u89e3\u91ca\u751f\u6210\u3002\u81ea\u9002\u5e94\u63d0\u53d6\u9aa8\u5e72\u6a21\u578b\u4e0e\u5176\u5fae\u8c03\u53d8\u4f53\u4e4b\u95f4\u7684\u5bf9\u6bd4\u6fc0\u6d3b\u5bf9\uff0c\u6784\u5efa\u8f6c\u5411\u5411\u91cf\u6765\u81ea\u7136\u5206\u79bb\u771f\u76f8\u7684\u98ce\u683c\u548c\u5b9e\u8d28\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\uff0cREFLEX\u4f18\u4e8e\u5148\u524d\u5411\u5355\u4e00\u771f\u76f8\u65b9\u5411\u5f15\u5bfc\u7684\u65b9\u6cd5\uff0c\u4ec5\u7528465\u4e2a\u81ea\u7cbe\u70bc\u8bad\u7ec3\u6837\u672c\u5c31\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002\u5177\u6709\u89e3\u91ca\u76ee\u6807\u7684\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u6307\u5bfc\u6ca1\u6709\u8be5\u76ee\u6807\u7684\u6a21\u578b\uff0c\u63d0\u5347\u8fbe7.57%\u3002", "conclusion": "\u5185\u90e8\u89e3\u91ca\u4fe1\u53f7\u5728\u4e8b\u5b9e\u63a8\u7406\u4e2d\u65e2\u8d77\u89e3\u91ca\u4f5c\u7528\u53c8\u8d77\u589e\u5f3a\u4f5c\u7528\uff0cREFLEX\u8303\u5f0f\u901a\u8fc7\u5229\u7528\u9aa8\u5e72\u6a21\u578b\u7684\u5185\u90e8\u77e5\u8bc6\uff0c\u63d0\u9ad8\u4e86\u88c1\u51b3\u51c6\u786e\u6027\u548c\u89e3\u91ca\u8d28\u91cf\u3002"}}
{"id": "2511.20085", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.20085", "abs": "https://arxiv.org/abs/2511.20085", "authors": ["Chujie Wang", "Zhiyuan Luo", "Ruiqi Liu", "Can Ran", "Shenghua Fan", "Xi Chen", "Chu He"], "title": "VICoT-Agent: A Vision-Interleaved Chain-of-Thought Framework for Interpretable Multimodal Reasoning and Scalable Remote Sensing Analysis", "comment": null, "summary": "The current remote sensing image analysis task is increasingly evolving from traditional object recognition to complex intelligence reasoning, which places higher requirements on the model's reasoning ability and the flexibility of tool invocation. To this end, we propose a new multimodal agent framework, Vision-Interleaved Chain-of-Thought Framework (VICoT), which implements explicit multi-round reasoning by dynamically incorporating visual tools into the chain of thought. Through a stack-based reasoning structure and a modular MCP-compatible tool suite, VICoT enables LLMs to efficiently perform multi-round, interleaved vision-language reasoning tasks with strong generalization and flexibility.We also propose the Reasoning Stack distillation method to migrate complex Agent behaviors to small, lightweight models, which ensures the reasoning capability while significantly reducing complexity. Experiments on multiple remote sensing benchmarks demonstrate that VICoT significantly outperforms existing SOTA frameworks in reasoning transparency, execution efficiency, and generation quality.", "AI": {"tldr": "\u63d0\u51faVICoT\u591a\u6a21\u6001\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u6574\u5408\u89c6\u89c9\u5de5\u5177\u5230\u601d\u7ef4\u94fe\u4e2d\u5b9e\u73b0\u663e\u5f0f\u591a\u8f6e\u63a8\u7406\uff0c\u5728\u9065\u611f\u56fe\u50cf\u5206\u6790\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709SOTA\u65b9\u6cd5\u3002", "motivation": "\u9065\u611f\u56fe\u50cf\u5206\u6790\u4efb\u52a1\u6b63\u4ece\u4f20\u7edf\u76ee\u6807\u8bc6\u522b\u5411\u590d\u6742\u667a\u80fd\u63a8\u7406\u6f14\u8fdb\uff0c\u9700\u8981\u66f4\u5f3a\u7684\u63a8\u7406\u80fd\u529b\u548c\u7075\u6d3b\u7684\u5de5\u5177\u8c03\u7528\u80fd\u529b\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5806\u6808\u7684\u63a8\u7406\u7ed3\u6784\u548c\u6a21\u5757\u5316MCP\u517c\u5bb9\u5de5\u5177\u5957\u4ef6\uff0c\u5b9e\u73b0\u591a\u8f6e\u4ea4\u9519\u7684\u89c6\u89c9\u8bed\u8a00\u63a8\u7406\uff1b\u63d0\u51fa\u63a8\u7406\u5806\u6808\u84b8\u998f\u65b9\u6cd5\u5c06\u590d\u6742\u4ee3\u7406\u884c\u4e3a\u8fc1\u79fb\u5230\u8f7b\u91cf\u6a21\u578b\u3002", "result": "\u5728\u591a\u4e2a\u9065\u611f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cVICoT\u5728\u63a8\u7406\u900f\u660e\u5ea6\u3001\u6267\u884c\u6548\u7387\u548c\u751f\u6210\u8d28\u91cf\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709SOTA\u6846\u67b6\u3002", "conclusion": "VICoT\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u5de5\u5177\u6574\u5408\u548c\u5806\u6808\u63a8\u7406\u7ed3\u6784\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u84b8\u998f\u65b9\u6cd5\u5b9e\u73b0\u4e86\u63a8\u7406\u80fd\u529b\u7684\u8f7b\u91cf\u5316\u8fc1\u79fb\u3002"}}
{"id": "2511.20340", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20340", "abs": "https://arxiv.org/abs/2511.20340", "authors": ["Luohe Shi", "Zuchao Li", "Lefei Zhang", "Baoyuan Qi", "Guoming Liu", "Hai Zhao"], "title": "Scaling LLM Speculative Decoding: Non-Autoregressive Forecasting in Large-Batch Scenarios", "comment": "accepted by AAAI-2026", "summary": "Speculative decoding accelerates LLM inference by utilizing otherwise idle computational resources during memory-to-chip data transfer. Current speculative decoding methods typically assume a considerable amount of available computing power, then generate a complex and massive draft tree using a small autoregressive language model to improve overall prediction accuracy. However, methods like batching have been widely applied in mainstream model inference systems as a superior alternative to speculative decoding, as they compress the available idle computing power. Therefore, performing speculative decoding with low verification resources and low scheduling costs has become an important research problem. We believe that more capable models that allow for parallel generation on draft sequences are what we truly need. Recognizing the fundamental nature of draft models to only generate sequences of limited length, we propose SpecFormer, a novel architecture that integrates unidirectional and bidirectional attention mechanisms. SpecFormer combines the autoregressive model's ability to extract information from the entire input sequence with the parallel generation benefits of non-autoregressive models. This design eliminates the reliance on large prefix trees and achieves consistent acceleration, even in large-batch scenarios. Through lossless speculative decoding experiments across models of various scales, we demonstrate that SpecFormer sets a new standard for scaling LLM inference with lower training demands and reduced computational costs.", "AI": {"tldr": "SpecFormer\u662f\u4e00\u79cd\u65b0\u9896\u7684\u67b6\u6784\uff0c\u901a\u8fc7\u6574\u5408\u5355\u5411\u548c\u53cc\u5411\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7ed3\u5408\u81ea\u56de\u5f52\u6a21\u578b\u7684\u5e8f\u5217\u4fe1\u606f\u63d0\u53d6\u80fd\u529b\u548c\u975e\u81ea\u56de\u5f52\u6a21\u578b\u7684\u5e76\u884c\u751f\u6210\u4f18\u52bf\uff0c\u5728\u4f4e\u9a8c\u8bc1\u8d44\u6e90\u548c\u8c03\u5ea6\u6210\u672c\u4e0b\u5b9e\u73b0LLM\u63a8\u7406\u52a0\u901f\u3002", "motivation": "\u73b0\u6709\u7684\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\u5047\u8bbe\u6709\u5927\u91cf\u53ef\u7528\u8ba1\u7b97\u8d44\u6e90\uff0c\u4f46\u5728\u6279\u5904\u7406\u7b49\u4e3b\u6d41\u63a8\u7406\u7cfb\u7edf\u4e2d\uff0c\u8fd9\u4e9b\u8d44\u6e90\u5df2\u88ab\u538b\u7f29\u3002\u56e0\u6b64\uff0c\u9700\u8981\u5728\u4f4e\u9a8c\u8bc1\u8d44\u6e90\u548c\u4f4e\u8c03\u5ea6\u6210\u672c\u4e0b\u8fdb\u884c\u63a8\u6d4b\u89e3\u7801\u3002", "method": "\u63d0\u51faSpecFormer\u67b6\u6784\uff0c\u6574\u5408\u5355\u5411\u548c\u53cc\u5411\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7ed3\u5408\u81ea\u56de\u5f52\u6a21\u578b\u7684\u5168\u5e8f\u5217\u4fe1\u606f\u63d0\u53d6\u80fd\u529b\u4e0e\u975e\u81ea\u56de\u5f52\u6a21\u578b\u7684\u5e76\u884c\u751f\u6210\u4f18\u52bf\uff0c\u6d88\u9664\u5bf9\u5927\u524d\u7f00\u6811\u7684\u4f9d\u8d56\u3002", "result": "\u5728\u5404\u79cd\u89c4\u6a21\u6a21\u578b\u7684\u635f\u5931\u63a8\u6d4b\u89e3\u7801\u5b9e\u9a8c\u4e2d\uff0cSpecFormer\u4e3aLLM\u63a8\u7406\u6269\u5c55\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\uff0c\u5177\u6709\u66f4\u4f4e\u7684\u8bad\u7ec3\u9700\u6c42\u548c\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "SpecFormer\u80fd\u591f\u5728\u5927\u578b\u6279\u5904\u7406\u573a\u666f\u4e2d\u5b9e\u73b0\u4e00\u81f4\u7684\u52a0\u901f\u6548\u679c\uff0c\u4e3aLLM\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20138", "categories": ["cs.AI", "cs.DM", "cs.LG", "math.CO"], "pdf": "https://arxiv.org/pdf/2511.20138", "abs": "https://arxiv.org/abs/2511.20138", "authors": ["Jason Lo", "Mohammadnima Jafari"], "title": "From data to concepts via wiring diagrams", "comment": "19 pages", "summary": "A wiring diagram is a labeled directed graph that represents an abstract concept such as a temporal process. In this article, we introduce the notion of a quasi-skeleton wiring diagram graph, and prove that quasi-skeleton wiring diagram graphs correspond to Hasse diagrams. Using this result, we designed algorithms that extract wiring diagrams from sequential data. We used our algorithms in analyzing the behavior of an autonomous agent playing a computer game, and the algorithms correctly identified the winning strategies. We compared the performance of our main algorithm with two other algorithms based on standard clustering techniques (DBSCAN and agglomerative hierarchical), including when some of the data was perturbed. Overall, this article brings together techniques in category theory, graph theory, clustering, reinforcement learning, and data engineering.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u51c6\u9aa8\u67b6\u63a5\u7ebf\u56fe\u7684\u6982\u5ff5\uff0c\u8bc1\u660e\u4e86\u51c6\u9aa8\u67b6\u63a5\u7ebf\u56fe\u4e0eHasse\u56fe\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4ece\u65f6\u5e8f\u6570\u636e\u4e2d\u63d0\u53d6\u63a5\u7ebf\u56fe\u7684\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u5728\u5206\u6790\u81ea\u4e3b\u4ee3\u7406\u73a9\u7535\u8111\u6e38\u620f\u7684\u884c\u4e3a\u65f6\u6210\u529f\u8bc6\u522b\u4e86\u83b7\u80dc\u7b56\u7565\u3002", "motivation": "\u63a5\u7ebf\u56fe\u662f\u8868\u793a\u62bd\u8c61\u6982\u5ff5\uff08\u5982\u65f6\u5e8f\u8fc7\u7a0b\uff09\u7684\u6807\u8bb0\u6709\u5411\u56fe\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4ece\u65f6\u5e8f\u6570\u636e\u4e2d\u81ea\u52a8\u63d0\u53d6\u63a5\u7ebf\u56fe\u7684\u65b9\u6cd5\uff0c\u4ee5\u7406\u89e3\u590d\u6742\u7cfb\u7edf\u7684\u884c\u4e3a\u6a21\u5f0f\u3002", "method": "\u5f15\u5165\u51c6\u9aa8\u67b6\u63a5\u7ebf\u56fe\u6982\u5ff5\uff0c\u8bc1\u660e\u5176\u4e0eHasse\u56fe\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u6b64\u7684\u7b97\u6cd5\u4ece\u65f6\u5e8f\u6570\u636e\u4e2d\u63d0\u53d6\u63a5\u7ebf\u56fe\u3002\u4e0eDBSCAN\u548c\u51dd\u805a\u5c42\u6b21\u805a\u7c7b\u7b97\u6cd5\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83\u3002", "result": "\u7b97\u6cd5\u5728\u5206\u6790\u81ea\u4e3b\u4ee3\u7406\u6e38\u620f\u884c\u4e3a\u65f6\u6b63\u786e\u8bc6\u522b\u4e86\u83b7\u80dc\u7b56\u7565\u3002\u4e0e\u6807\u51c6\u805a\u7c7b\u65b9\u6cd5\u76f8\u6bd4\u8868\u73b0\u826f\u597d\uff0c\u5373\u4f7f\u5728\u6570\u636e\u53d7\u5230\u6270\u52a8\u7684\u60c5\u51b5\u4e0b\u3002", "conclusion": "\u672c\u6587\u7efc\u5408\u4e86\u8303\u7574\u8bba\u3001\u56fe\u8bba\u3001\u805a\u7c7b\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u6570\u636e\u5de5\u7a0b\u6280\u672f\uff0c\u4e3a\u4ece\u65f6\u5e8f\u6570\u636e\u4e2d\u63d0\u53d6\u548c\u7406\u89e3\u590d\u6742\u7cfb\u7edf\u7684\u884c\u4e3a\u6a21\u5f0f\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2511.20344", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20344", "abs": "https://arxiv.org/abs/2511.20344", "authors": ["Taewhoo Lee", "Minju Song", "Chanwoong Yoon", "Jungwoo Park", "Jaewoo Kang"], "title": "The Curious Case of Analogies: Investigating Analogical Reasoning in Large Language Models", "comment": "AAAI 2026", "summary": "Analogical reasoning is at the core of human cognition, serving as an important foundation for a variety of intellectual activities. While prior work has shown that LLMs can represent task patterns and surface-level concepts, it remains unclear whether these models can encode high-level relational concepts and apply them to novel situations through structured comparisons. In this work, we explore this fundamental aspect using proportional and story analogies, and identify three key findings. First, LLMs effectively encode the underlying relationships between analogous entities; both attributive and relational information propagate through mid-upper layers in correct cases, whereas reasoning failures reflect missing relational information within these layers. Second, unlike humans, LLMs often struggle not only when relational information is missing, but also when attempting to apply it to new entities. In such cases, strategically patching hidden representations at critical token positions can facilitate information transfer to a certain extent. Lastly, successful analogical reasoning in LLMs is marked by strong structural alignment between analogous situations, whereas failures often reflect degraded or misplaced alignment. Overall, our findings reveal that LLMs exhibit emerging but limited capabilities in encoding and applying high-level relational concepts, highlighting both parallels and gaps with human cognition.", "AI": {"tldr": "LLMs\u80fd\u591f\u7f16\u7801\u7c7b\u6bd4\u5b9e\u4f53\u95f4\u7684\u5173\u7cfb\uff0c\u4f46\u5728\u5e94\u7528\u5173\u7cfb\u4fe1\u606f\u5230\u65b0\u5b9e\u4f53\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u901a\u8fc7\u7b56\u7565\u6027\u5730\u4fee\u8865\u9690\u85cf\u8868\u793a\u53ef\u4ee5\u90e8\u5206\u6539\u5584\uff0c\u6210\u529f\u7684\u7c7b\u6bd4\u63a8\u7406\u9700\u8981\u7ed3\u6784\u5bf9\u9f50\u3002", "motivation": "\u63a2\u7d22LLMs\u662f\u5426\u80fd\u591f\u7f16\u7801\u9ad8\u5c42\u6b21\u5173\u7cfb\u6982\u5ff5\u5e76\u5c06\u5176\u5e94\u7528\u5230\u65b0\u60c5\u5883\u4e2d\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6bd4\u8f83\u6765\u7406\u89e3\u8fd9\u4e00\u57fa\u672c\u8ba4\u77e5\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u6bd4\u4f8b\u7c7b\u6bd4\u548c\u6545\u4e8b\u7c7b\u6bd4\uff0c\u5206\u6790LLMs\u5728\u4e0d\u540c\u5c42\u4e2d\u7684\u4fe1\u606f\u4f20\u64ad\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u7b56\u7565\u6027\u4fee\u8865\u9690\u85cf\u8868\u793a\u6765\u6d4b\u8bd5\u4fe1\u606f\u4f20\u9012\u6548\u679c\u3002", "result": "LLMs\u80fd\u591f\u6709\u6548\u7f16\u7801\u7c7b\u6bd4\u5b9e\u4f53\u95f4\u7684\u5173\u7cfb\uff0c\u4f46\u5728\u5e94\u7528\u5173\u7cfb\u4fe1\u606f\u5230\u65b0\u5b9e\u4f53\u65f6\u5b58\u5728\u56f0\u96be\uff1b\u6210\u529f\u7684\u63a8\u7406\u9700\u8981\u7ed3\u6784\u5bf9\u9f50\uff0c\u5931\u8d25\u5219\u53cd\u6620\u5bf9\u9f50\u9000\u5316\u6216\u9519\u4f4d\u3002", "conclusion": "LLMs\u5728\u7f16\u7801\u548c\u5e94\u7528\u9ad8\u5c42\u6b21\u5173\u7cfb\u6982\u5ff5\u65b9\u9762\u5c55\u73b0\u51fa\u521d\u6b65\u4f46\u6709\u9650\u7684\u80fd\u529b\uff0c\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u5b58\u5728\u76f8\u4f3c\u6027\u548c\u5dee\u8ddd\u3002"}}
{"id": "2511.20196", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20196", "abs": "https://arxiv.org/abs/2511.20196", "authors": ["Zhen Zeng", "Leijiang Gu", "Zhangling Duan", "Feng Li", "Zenglin Shi", "Cees G. M. Snoek", "Meng Wang"], "title": "Towards Benign Memory Forgetting for Selective Multimodal Large Language Model Unlearning", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) achieve remarkable capabilities but can inadvertently memorize privacy-sensitive information. Although existing unlearning methods can remove such knowledge, they fail to achieve benign forgetting because they often degrade the model's general image understanding performance. To address this, we propose the Sculpted Memory Forgetting Adapter (SMFA), which confines forgetting to targeted memory regions while preserving overall capabilities. SMFA first fine-tunes the model to replace sensitive responses with refusals, yielding a memory forgetting adapter, and then applies a retaining anchor-guided masking mechanism to prevent interference with unrelated knowledge and understanding ability. To systematically evaluate selective MLLM unlearning, we introduce S-MLLMUn Bench, the first benchmark designed to jointly assess the removal of sensitive knowledge and retention of general visual understanding. Extensive experiments show that, unlike prior methods, SMFA achieves precise and controllable unlearning while maintaining the model's foundational image understanding.", "AI": {"tldr": "\u63d0\u51fa\u4e86SMFA\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bb0\u5fc6\u9057\u5fd8\u9002\u914d\u5668\u548c\u4fdd\u7559\u951a\u70b9\u5f15\u5bfc\u7684\u63a9\u7801\u673a\u5236\uff0c\u5b9e\u73b0\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9690\u79c1\u654f\u611f\u4fe1\u606f\u7684\u7cbe\u786e\u53ef\u63a7\u9057\u5fd8\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u901a\u7528\u56fe\u50cf\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u9057\u5fd8\u65b9\u6cd5\u5728\u79fb\u9664\u9690\u79c1\u654f\u611f\u4fe1\u606f\u65f6\u5f80\u5f80\u4f1a\u635f\u5bb3\u6a21\u578b\u7684\u901a\u7528\u56fe\u50cf\u7406\u89e3\u6027\u80fd\uff0c\u65e0\u6cd5\u5b9e\u73b0\u826f\u6027\u9057\u5fd8\u3002", "method": "SMFA\u9996\u5148\u5fae\u8c03\u6a21\u578b\u5c06\u654f\u611f\u54cd\u5e94\u66ff\u6362\u4e3a\u62d2\u7edd\u56de\u7b54\uff0c\u5f97\u5230\u8bb0\u5fc6\u9057\u5fd8\u9002\u914d\u5668\uff0c\u7136\u540e\u5e94\u7528\u4fdd\u7559\u951a\u70b9\u5f15\u5bfc\u7684\u63a9\u7801\u673a\u5236\u9632\u6b62\u5bf9\u65e0\u5173\u77e5\u8bc6\u548c\u7406\u89e3\u80fd\u529b\u7684\u5e72\u6270\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSMFA\u80fd\u591f\u5b9e\u73b0\u7cbe\u786e\u53ef\u63a7\u7684\u9057\u5fd8\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u57fa\u7840\u56fe\u50cf\u7406\u89e3\u80fd\u529b\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SMFA\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u9690\u79c1\u654f\u611f\u4fe1\u606f\u9057\u5fd8\u7684\u95ee\u9898\uff0c\u5728\u79fb\u9664\u654f\u611f\u77e5\u8bc6\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u901a\u7528\u89c6\u89c9\u7406\u89e3\u80fd\u529b\u3002"}}
{"id": "2511.20399", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20399", "abs": "https://arxiv.org/abs/2511.20399", "authors": ["Abdullah Al Sefat"], "title": "BengaliFig: A Low-Resource Challenge for Figurative and Culturally Grounded Reasoning in Bengali", "comment": null, "summary": "Large language models excel on broad multilingual benchmarks but remain to be evaluated extensively in figurative and culturally grounded reasoning, especially in low-resource contexts. We present BengaliFig, a compact yet richly annotated challenge set that targets this gap in Bengali, a widely spoken low-resourced language. The dataset contains 435 unique riddles drawn from Bengali oral and literary traditions. Each item is annotated along five orthogonal dimensions capturing reasoning type, trap type, cultural depth, answer category, and difficulty, and is automatically converted to multiple-choice format through a constraint-aware, AI-assisted pipeline. We evaluate eight frontier LLMs from major providers under zero-shot and few-shot chain-of-thought prompting, revealing consistent weaknesses in metaphorical and culturally specific reasoning. BengaliFig thus contributes both a diagnostic probe for evaluating LLM robustness in low-resource cultural contexts and a step toward inclusive and heritage-aware NLP evaluation.", "AI": {"tldr": "BengaliFig\u662f\u4e00\u4e2a\u9488\u5bf9\u5b5f\u52a0\u62c9\u8bed\u7684\u7d27\u51d1\u578b\u6311\u6218\u6570\u636e\u96c6\uff0c\u5305\u542b435\u4e2a\u6765\u81ea\u5b5f\u52a0\u62c9\u53e3\u8ff0\u548c\u6587\u5b66\u4f20\u7edf\u7684\u8c1c\u8bed\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u4f4e\u8d44\u6e90\u6587\u5316\u80cc\u666f\u4e0b\u7684\u6bd4\u55bb\u548c\u6587\u5316\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5e7f\u6cdb\u7684\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u6bd4\u55bb\u548c\u6587\u5316\u57fa\u7840\u63a8\u7406\u65b9\u9762\uff0c\u5c24\u5176\u662f\u5728\u4f4e\u8d44\u6e90\u8bed\u5883\u4e0b\u7684\u8bc4\u4f30\u4ecd\u7136\u4e0d\u8db3\u3002", "method": "\u6784\u5efa\u5305\u542b435\u4e2a\u72ec\u7279\u8c1c\u8bed\u7684BengaliFig\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u9879\u76ee\u6cbf\u4e94\u4e2a\u6b63\u4ea4\u7ef4\u5ea6\u8fdb\u884c\u6807\u6ce8\uff0c\u5e76\u901a\u8fc7\u7ea6\u675f\u611f\u77e5\u7684AI\u8f85\u52a9\u6d41\u7a0b\u81ea\u52a8\u8f6c\u6362\u4e3a\u591a\u9879\u9009\u62e9\u683c\u5f0f\u3002\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u601d\u7ef4\u94fe\u63d0\u793a\u4e0b\u8bc4\u4f30\u516b\u4e2a\u524d\u6cbfLLM\u3002", "result": "\u8bc4\u4f30\u663e\u793aLLM\u5728\u9690\u55bb\u548c\u6587\u5316\u7279\u5b9a\u63a8\u7406\u65b9\u9762\u5b58\u5728\u4e00\u81f4\u7684\u5f31\u70b9\u3002", "conclusion": "BengaliFig\u65e2\u4e3a\u8bc4\u4f30LLM\u5728\u4f4e\u8d44\u6e90\u6587\u5316\u80cc\u666f\u4e0b\u7684\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u8bca\u65ad\u5de5\u5177\uff0c\u4e5f\u671d\u7740\u5305\u5bb9\u6027\u548c\u9057\u4ea7\u611f\u77e5\u7684NLP\u8bc4\u4f30\u8fc8\u51fa\u4e86\u4e00\u6b65\u3002"}}
{"id": "2511.20200", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20200", "abs": "https://arxiv.org/abs/2511.20200", "authors": ["Yitian Huang", "Yuxuan Lei", "Jianxun Lian", "Hao Liao"], "title": "Interactive AI NPCs Powered by LLMs: Technical Report for the CPDC Challenge 2025", "comment": null, "summary": "This report presents the solution and results of our team MSRA\\_SC in the Commonsense Persona-Grounded Dialogue Challenge (CPDC 2025). We propose a simple yet effective framework that unifies improvements across both GPU Track and API Track. Our method centers on two key components. First, Context Engineering applies dynamic tool pruning and persona clipping for input compression, combined with post-processing techniques such as parameter normalization and function merging. Together with manually refined prompts, this design improves tool call stability, execution reliability, and role-playing guidance. Second, in the GPU Track, we further adopt GRPO training, replacing supervised fine-tuning with reinforcement learning directly optimized by reward signals. This mitigates small-sample overfitting and significantly enhances task-oriented dialogue performance. In the final evaluation, our team ranks 1st in Task 2 API, 2nd in Task 1 API, and 3rd in both Task 3 API and GPU track, demonstrating the effectiveness of our approach. Our code is publicly available at https://gitlab.aicrowd.com/nikoo_yu/cpdc-2025-winning-solution", "AI": {"tldr": "\u56e2\u961fMSRA_SC\u5728CPDC 2025\u7ade\u8d5b\u4e2d\u63d0\u51fa\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u5de5\u7a0b\u548cGRPO\u8bad\u7ec3\u5728API\u548cGPU\u8d5b\u9053\u5747\u53d6\u5f97\u4f18\u5f02\u6210\u7ee9\u3002", "motivation": "\u89e3\u51b3\u5e38\u8bc6\u4eba\u7269\u5bf9\u8bdd\u4e2d\u7684\u5de5\u5177\u8c03\u7528\u7a33\u5b9a\u6027\u3001\u6267\u884c\u53ef\u9760\u6027\u548c\u89d2\u8272\u626e\u6f14\u6307\u5bfc\u95ee\u9898\uff0c\u540c\u65f6\u907f\u514d\u5c0f\u6837\u672c\u8fc7\u62df\u5408\u3002", "method": "1. \u4e0a\u4e0b\u6587\u5de5\u7a0b\uff1a\u52a8\u6001\u5de5\u5177\u526a\u679d\u3001\u4eba\u7269\u4fe1\u606f\u88c1\u526a\u3001\u53c2\u6570\u5f52\u4e00\u5316\u3001\u51fd\u6570\u5408\u5e76\uff1b2. GPU\u8d5b\u9053\u91c7\u7528GRPO\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u66ff\u4ee3\u76d1\u7763\u5fae\u8c03\u3002", "result": "\u6700\u7ec8\u6392\u540d\uff1aTask 2 API\u7b2c1\u540d\uff0cTask 1 API\u7b2c2\u540d\uff0cTask 3 API\u548cGPU\u8d5b\u9053\u5747\u7b2c3\u540d\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b80\u5355\u6709\u6548\u6846\u67b6\u5728\u5e38\u8bc6\u4eba\u7269\u5bf9\u8bdd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u9a8c\u8bc1\u4e86\u4e0a\u4e0b\u6587\u5de5\u7a0b\u548c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.20409", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20409", "abs": "https://arxiv.org/abs/2511.20409", "authors": ["Md Abdullah Al Kafi", "Raka Moni", "Sumit Kumar Banshal"], "title": "A Task-Oriented Evaluation Framework for Text Normalization in Modern NLP Pipelines", "comment": null, "summary": "Text normalization is an essential preprocessing step in many natural language processing (NLP) tasks, and stemming is one such normalization technique that reduces words to their base or root form. However, evaluating stemming methods is challenging because current evaluation approaches are limited and do not capture the potential harm caused by excessive stemming; therefore, it is essential to develop new approaches to evaluate stemming methods. To address this issue, this study propose a novel, task-oriented approach to evaluate stemming methods, which considers three aspects: (1) the utility of stemming using Stemming Effectiveness Score (SES), (2) the impact of stemming on downstream tasks using Model Performance Delta (MPD), and (3) the semantic similarity between stemmed and original words using Average Normalized Levenshtein Distance (ANLD), thus providing a comprehensive evaluation framework. We apply our evaluation framework to compare two stemmers for Bangla (BNLTK) and English (Snowball), and our results reveal a significant issue, prompting us to analyze their performance in detail. While the Bangla stemmer achieves the highest SES (1.67) due to effective word reduction (CR = 1.90), SES alone is insufficient because our proposed safety measure, ANLD, reveals that this high SES is due to harmful over-stemming (ANLD = 0.26), which correlates with the observed decrease in downstream performance.In contrast, the English stemmer achieves a moderate SES (1.31) with a safe meaning distance (ANLD = 0.14), allowing its word reduction to contribute positively to downstream performance; therefore, it is a more reliable stemmer. Our study provides a valuable tool for distinguishing between potential efficiency gains (high SES) and meaning preservation (low ANLD).", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9762\u5411\u4efb\u52a1\u7684\u8bcd\u5e72\u63d0\u53d6\u65b9\u6cd5\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u8bcd\u5e72\u63d0\u53d6\u6709\u6548\u6027\u8bc4\u5206(SES)\u3001\u6a21\u578b\u6027\u80fd\u5dee\u5f02(MPD)\u548c\u5e73\u5747\u5f52\u4e00\u5316\u7f16\u8f91\u8ddd\u79bb(ANLD)\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u80fd\u591f\u533a\u5206\u6548\u7387\u63d0\u5347\u548c\u8bed\u4e49\u4fdd\u7559\u3002", "motivation": "\u5f53\u524d\u8bcd\u5e72\u63d0\u53d6\u65b9\u6cd5\u7684\u8bc4\u4f30\u65b9\u6cd5\u6709\u9650\uff0c\u65e0\u6cd5\u6355\u6349\u8fc7\u5ea6\u8bcd\u5e72\u63d0\u53d6\u53ef\u80fd\u9020\u6210\u7684\u5371\u5bb3\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u5168\u9762\u8bc4\u4f30\u8bcd\u5e72\u63d0\u53d6\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5305\u542b\u4e09\u4e2a\u65b9\u9762\u7684\u7efc\u5408\u8bc4\u4f30\u6846\u67b6\uff1a1)\u4f7f\u7528SES\u8bc4\u4f30\u8bcd\u5e72\u63d0\u53d6\u6548\u7528\uff1b2)\u4f7f\u7528MPD\u8bc4\u4f30\u8bcd\u5e72\u63d0\u53d6\u5bf9\u4e0b\u6e38\u4efb\u52a1\u7684\u5f71\u54cd\uff1b3)\u4f7f\u7528ANLD\u8bc4\u4f30\u8bcd\u5e72\u63d0\u53d6\u8bcd\u4e0e\u539f\u8bcd\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6\u3002", "result": "\u5e94\u7528\u8be5\u6846\u67b6\u6bd4\u8f83\u5b5f\u52a0\u62c9\u8bed(BNLTK)\u548c\u82f1\u8bed(Snowball)\u8bcd\u5e72\u63d0\u53d6\u5668\uff0c\u53d1\u73b0\u5b5f\u52a0\u62c9\u8bed\u8bcd\u5e72\u63d0\u53d6\u5668\u867d\u7136SES\u6700\u9ad8(1.67)\uff0c\u4f46ANLD\u663e\u793a\u5b58\u5728\u6709\u5bb3\u7684\u8fc7\u5ea6\u8bcd\u5e72\u63d0\u53d6(0.26)\uff0c\u5bfc\u81f4\u4e0b\u6e38\u6027\u80fd\u4e0b\u964d\uff1b\u800c\u82f1\u8bed\u8bcd\u5e72\u63d0\u53d6\u5668\u5728\u4e2d\u7b49SES(1.31)\u4e0b\u4fdd\u6301\u5b89\u5168\u7684\u8bed\u4e49\u8ddd\u79bb(ANLD=0.14)\uff0c\u5bf9\u4e0b\u6e38\u4efb\u52a1\u6709\u79ef\u6781\u8d21\u732e\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u4ef7\u503c\u7684\u5de5\u5177\uff0c\u80fd\u591f\u533a\u5206\u8bcd\u5e72\u63d0\u53d6\u7684\u6f5c\u5728\u6548\u7387\u63d0\u5347(\u9ad8SES)\u548c\u8bed\u4e49\u4fdd\u7559(\u4f4eANLD)\uff0c\u6709\u52a9\u4e8e\u9009\u62e9\u66f4\u53ef\u9760\u7684\u8bcd\u5e72\u63d0\u53d6\u65b9\u6cd5\u3002"}}
{"id": "2511.20216", "categories": ["cs.AI", "cs.CE", "cs.CV", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20216", "abs": "https://arxiv.org/abs/2511.20216", "authors": ["Haebin Seong", "Sungmin Kim", "Minchan Kim", "Yongjun Cho", "Myunchul Joe", "Suhwan Choi", "Jaeyoon Jung", "Jiyong Youn", "Yoonshik Kim", "Samwoo Seong", "Yubeen Park", "Youngjae Yu", "Yunsung Lee"], "title": "CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents", "comment": null, "summary": "Existing navigation benchmarks focus on task success metrics while overlooking economic viability -- critical for commercial deployment of autonomous delivery robots. We introduce \\emph{CostNav}, a \\textbf{Micro-Navigation Economic Testbed} that evaluates embodied agents through comprehensive cost-revenue analysis aligned with real-world business operations. CostNav models the complete economic lifecycle including hardware, training, energy, maintenance costs, and delivery revenue with service-level agreements, using industry-derived parameters. \\textbf{To our knowledge, CostNav is the first work to quantitatively expose the gap between navigation research metrics and commercial viability}, revealing that optimizing for task success fundamentally differs from optimizing for economic deployment. Our cost model uses parameters derived from industry data sources (energy rates, delivery service pricing), and we project from a reduced-scale simulation to realistic deliveries. Under this projection, the baseline achieves 43.0\\% SLA compliance but is \\emph{not} commercially viable: yielding a loss of \\$30.009 per run with no finite break-even point, because operating costs are dominated by collision-induced maintenance, which accounts for 99.7\\% of per-run costs and highlights collision avoidance as a key optimization target. We demonstrate a learning-based on-device navigation baseline and establish a foundation for evaluating rule-based navigation, imitation learning, and cost-aware RL training. CostNav bridges the gap between navigation research and commercial deployment, enabling data-driven decisions about economic trade-offs across navigation paradigms.", "AI": {"tldr": "CostNav\u662f\u9996\u4e2a\u8bc4\u4f30\u81ea\u4e3b\u9001\u8d27\u673a\u5668\u4eba\u7ecf\u6d4e\u53ef\u884c\u6027\u7684\u5fae\u5bfc\u822a\u7ecf\u6d4e\u6d4b\u8bd5\u5e73\u53f0\uff0c\u901a\u8fc7\u6210\u672c-\u6536\u76ca\u5206\u6790\u63ed\u793a\u5bfc\u822a\u7814\u7a76\u6307\u6807\u4e0e\u5546\u4e1a\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u5bfc\u822a\u57fa\u51c6\u53ea\u5173\u6ce8\u4efb\u52a1\u6210\u529f\u7387\uff0c\u5ffd\u89c6\u4e86\u7ecf\u6d4e\u53ef\u884c\u6027\u8fd9\u4e00\u5546\u4e1a\u90e8\u7f72\u7684\u5173\u952e\u56e0\u7d20\u3002", "method": "CostNav\u5efa\u6a21\u5b8c\u6574\u7ecf\u6d4e\u751f\u547d\u5468\u671f\uff0c\u5305\u62ec\u786c\u4ef6\u3001\u8bad\u7ec3\u3001\u80fd\u6e90\u3001\u7ef4\u62a4\u6210\u672c\u548c\u914d\u9001\u6536\u5165\uff0c\u4f7f\u7528\u884c\u4e1a\u53c2\u6570\uff0c\u4ece\u7f29\u5c0f\u89c4\u6a21\u6a21\u62df\u6269\u5c55\u5230\u5b9e\u9645\u914d\u9001\u573a\u666f\u3002", "result": "\u57fa\u7ebf\u6a21\u578b\u8fbe\u523043.0%\u7684\u670d\u52a1\u6c34\u5e73\u534f\u8bae\u5408\u89c4\u7387\uff0c\u4f46\u4e0d\u53ef\u884c\uff1a\u6bcf\u6b21\u8fd0\u884c\u635f\u593130.009\u7f8e\u5143\uff0c\u65e0\u76c8\u4e8f\u5e73\u8861\u70b9\uff0c\u78b0\u649e\u5bfc\u81f4\u7684\u7ef4\u62a4\u6210\u672c\u5360\u8fd0\u884c\u6210\u672c\u768499.7%\u3002", "conclusion": "CostNav\u586b\u8865\u4e86\u5bfc\u822a\u7814\u7a76\u4e0e\u5546\u4e1a\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u8bc4\u4f30\u57fa\u4e8e\u89c4\u5219\u7684\u5bfc\u822a\u3001\u6a21\u4eff\u5b66\u4e60\u548c\u6210\u672c\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.20459", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20459", "abs": "https://arxiv.org/abs/2511.20459", "authors": ["Mosab Rezaei", "Mina Rajaei Moghadam", "Abdul Rahman Shaikh", "Hamed Alhoori", "Reva Freedman"], "title": "Generation, Evaluation, and Explanation of Novelists' Styles with Single-Token Prompts", "comment": null, "summary": "Recent advances in large language models have created new opportunities for stylometry, the study of writing styles and authorship. Two challenges, however, remain central: training generative models when no paired data exist, and evaluating stylistic text without relying only on human judgment. In this work, we present a framework for both generating and evaluating sentences in the style of 19th-century novelists. Large language models are fine-tuned with minimal, single-token prompts to produce text in the voices of authors such as Dickens, Austen, Twain, Alcott, and Melville. To assess these generative models, we employ a transformer-based detector trained on authentic sentences, using it both as a classifier and as a tool for stylistic explanation. We complement this with syntactic comparisons and explainable AI methods, including attention-based and gradient-based analyses, to identify the linguistic cues that drive stylistic imitation. Our findings show that the generated text reflects the authors' distinctive patterns and that AI-based evaluation offers a reliable alternative to human assessment. All artifacts of this work are published online.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u751f\u6210\u548c\u8bc4\u4f3019\u4e16\u7eaa\u5c0f\u8bf4\u5bb6\u98ce\u683c\u53e5\u5b50\u7684\u6846\u67b6\uff0c\u4f7f\u7528\u5fae\u8c03\u7684\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u672c\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8etransformer\u7684\u68c0\u6d4b\u5668\u8fdb\u884c\u98ce\u683c\u8bc4\u4f30\u548c\u89e3\u91ca\u3002", "motivation": "\u89e3\u51b3\u751f\u6210\u6a21\u578b\u5728\u65e0\u914d\u5bf9\u6570\u636e\u65f6\u7684\u8bad\u7ec3\u95ee\u9898\uff0c\u4ee5\u53ca\u4e0d\u4f9d\u8d56\u4eba\u7c7b\u5224\u65ad\u7684\u6587\u672c\u98ce\u683c\u8bc4\u4f30\u6311\u6218\u3002", "method": "\u4f7f\u7528\u5355token\u63d0\u793a\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7279\u5b9a\u4f5c\u8005\u98ce\u683c\u7684\u6587\u672c\uff0c\u8bad\u7ec3\u57fa\u4e8etransformer\u7684\u68c0\u6d4b\u5668\u8fdb\u884c\u98ce\u683c\u5206\u7c7b\u548c\u89e3\u91ca\uff0c\u8f85\u4ee5\u53e5\u6cd5\u6bd4\u8f83\u548c\u53ef\u89e3\u91caAI\u65b9\u6cd5\u3002", "result": "\u751f\u6210\u7684\u6587\u672c\u53cd\u6620\u4e86\u4f5c\u8005\u7684\u72ec\u7279\u98ce\u683c\u6a21\u5f0f\uff0cAI\u8bc4\u4f30\u4e3a\u4eba\u7c7b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u9760\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u98ce\u683c\u6587\u672c\u7684\u751f\u6210\u548c\u8bc4\u4f30\uff0c\u6240\u6709\u5de5\u4f5c\u6210\u679c\u5df2\u5728\u7ebf\u53d1\u5e03\u3002"}}
{"id": "2511.20236", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20236", "abs": "https://arxiv.org/abs/2511.20236", "authors": ["Szymon Bobek", "\u0141ukasz Ba\u0142ec", "Grzegorz J. Nalepa"], "title": "Actionable and diverse counterfactual explanations incorporating domain knowledge and causal constraints", "comment": null, "summary": "Counterfactual explanations enhance the actionable interpretability of machine learning models by identifying the minimal changes required to achieve a desired outcome of the model. However, existing methods often ignore the complex dependencies in real-world datasets, leading to unrealistic or impractical modifications. Motivated by cybersecurity applications in the email marketing domain, we propose a method for generating Diverse, Actionable, and kNowledge-Constrained Explanations (DANCE), which incorporates feature dependencies and causal constraints to ensure plausibility and real-world feasibility of counterfactuals. Our method learns linear and nonlinear constraints from data or integrates expert-provided dependency graphs, ensuring counterfactuals are plausible and actionable. By maintaining consistency with feature relationships, the method produces explanations that align with real-world constraints. Additionally, it balances plausibility, diversity, and sparsity, effectively addressing key limitations in existing algorithms. The work is developed based on a real-life case study with Freshmail, the largest email marketing company in Poland and supported by a joint R&D project Sendguard. Furthermore, we provide an extensive evaluation using 140 public datasets, which highlights its ability to generate meaningful, domain-relevant counterfactuals that outperform other existing approaches based on widely used metrics. The source code for reproduction of the results can be found in a GitHub repository we provide.", "AI": {"tldr": "\u63d0\u51fa\u4e86DANCE\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u7279\u5f81\u4f9d\u8d56\u5173\u7cfb\u548c\u56e0\u679c\u7ea6\u675f\u6765\u751f\u6210\u591a\u6837\u5316\u3001\u53ef\u64cd\u4f5c\u4e14\u77e5\u8bc6\u7ea6\u675f\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff0c\u786e\u4fdd\u53cd\u4e8b\u5b9e\u7684\u5408\u7406\u6027\u548c\u73b0\u5b9e\u53ef\u884c\u6027\u3002", "motivation": "\u73b0\u6709\u53cd\u4e8b\u5b9e\u89e3\u91ca\u65b9\u6cd5\u5f80\u5f80\u5ffd\u7565\u73b0\u5b9e\u6570\u636e\u96c6\u4e2d\u7684\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\uff0c\u5bfc\u81f4\u4e0d\u73b0\u5b9e\u6216\u4e0d\u5207\u5b9e\u9645\u7684\u4fee\u6539\u3002\u53d7\u7f51\u7edc\u5b89\u5168\u5728\u7535\u5b50\u90ae\u4ef6\u8425\u9500\u9886\u57df\u5e94\u7528\u7684\u542f\u53d1\uff0c\u9700\u8981\u786e\u4fdd\u53cd\u4e8b\u5b9e\u7684\u5408\u7406\u6027\u548c\u73b0\u5b9e\u53ef\u884c\u6027\u3002", "method": "\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u7ea6\u675f\uff0c\u6216\u6574\u5408\u4e13\u5bb6\u63d0\u4f9b\u7684\u4f9d\u8d56\u56fe\uff0c\u786e\u4fdd\u53cd\u4e8b\u5b9e\u5408\u7406\u4e14\u53ef\u64cd\u4f5c\u3002\u901a\u8fc7\u4fdd\u6301\u4e0e\u7279\u5f81\u5173\u7cfb\u7684\u4e00\u81f4\u6027\uff0c\u751f\u6210\u7b26\u5408\u73b0\u5b9e\u7ea6\u675f\u7684\u89e3\u91ca\u3002\u540c\u65f6\u5e73\u8861\u5408\u7406\u6027\u3001\u591a\u6837\u6027\u548c\u7a00\u758f\u6027\u3002", "result": "\u5728140\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u6709\u610f\u4e49\u3001\u9886\u57df\u76f8\u5173\u7684\u53cd\u4e8b\u5b9e\uff0c\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u6307\u6807\u4e0a\u4f18\u4e8e\u5176\u4ed6\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "DANCE\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u7b97\u6cd5\u5728\u7279\u5f81\u4f9d\u8d56\u5173\u7cfb\u5904\u7406\u65b9\u9762\u7684\u5173\u952e\u9650\u5236\uff0c\u80fd\u591f\u751f\u6210\u66f4\u5408\u7406\u548c\u5b9e\u7528\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u3002"}}
{"id": "2511.20494", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20494", "abs": "https://arxiv.org/abs/2511.20494", "authors": ["Jakub Hoscilowicz", "Artur Janicki"], "title": "Adversarial Confusion Attack: Disrupting Multimodal Large Language Models", "comment": null, "summary": "We introduce the Adversarial Confusion Attack, a new class of threats against multimodal large language models (MLLMs). Unlike jailbreaks or targeted misclassification, the goal is to induce systematic disruption that makes the model generate incoherent or confidently incorrect outputs. Applications include embedding adversarial images into websites to prevent MLLM-powered agents from operating reliably. The proposed attack maximizes next-token entropy using a small ensemble of open-source MLLMs. In the white-box setting, we show that a single adversarial image can disrupt all models in the ensemble, both in the full-image and adversarial CAPTCHA settings. Despite relying on a basic adversarial technique (PGD), the attack generates perturbations that transfer to both unseen open-source (e.g., Qwen3-VL) and proprietary (e.g., GPT-5.1) models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u578b\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\u2014\u2014\u5bf9\u6297\u6027\u6df7\u6dc6\u653b\u51fb\uff0c\u65e8\u5728\u901a\u8fc7\u5bf9\u6297\u56fe\u50cf\u4f7f\u6a21\u578b\u4ea7\u751f\u4e0d\u8fde\u8d2f\u6216\u81ea\u4fe1\u9519\u8bef\u7684\u8f93\u51fa\uff0c\u4ece\u800c\u7834\u574fMLLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u653b\u51fb\u4e3b\u8981\u5173\u6ce8\u8d8a\u72f1\u6216\u5b9a\u5411\u9519\u8bef\u5206\u7c7b\uff0c\u800c\u672c\u6587\u65e8\u5728\u5f00\u53d1\u80fd\u7cfb\u7edf\u6027\u7834\u574fMLLM\u53ef\u9760\u6027\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u9632\u6b62MLLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u53ef\u9760\u8fd0\u4f5c\u3002", "method": "\u4f7f\u7528\u5c0f\u578b\u5f00\u6e90MLLM\u96c6\u5408\uff0c\u901a\u8fc7\u6700\u5927\u5316\u4e0b\u4e00\u6807\u8bb0\u71b5\u7684\u65b9\u6cd5\u751f\u6210\u5bf9\u6297\u56fe\u50cf\uff0c\u91c7\u7528\u57fa\u7840\u7684PGD\u5bf9\u6297\u6280\u672f\uff0c\u5728\u5b8c\u6574\u56fe\u50cf\u548c\u5bf9\u6297\u9a8c\u8bc1\u7801\u4e24\u79cd\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u653b\u51fb\u3002", "result": "\u5355\u4e2a\u5bf9\u6297\u56fe\u50cf\u80fd\u591f\u7834\u574f\u96c6\u5408\u4e2d\u7684\u6240\u6709\u6a21\u578b\uff0c\u4e14\u751f\u6210\u7684\u6270\u52a8\u80fd\u591f\u8fc1\u79fb\u5230\u672a\u89c1\u8fc7\u7684\u5f00\u6e90\u6a21\u578b\uff08\u5982Qwen3-VL\uff09\u548c\u4e13\u6709\u6a21\u578b\uff08\u5982GPT-5.1\uff09\u3002", "conclusion": "\u5bf9\u6297\u6027\u6df7\u6dc6\u653b\u51fb\u662f\u4e00\u79cd\u6709\u6548\u7684MLLM\u5a01\u80c1\uff0c\u80fd\u591f\u901a\u8fc7\u7b80\u5355\u7684\u5bf9\u6297\u6280\u672f\u5b9e\u73b0\u8de8\u6a21\u578b\u8fc1\u79fb\uff0c\u63ed\u793a\u4e86MLLM\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u7684\u8106\u5f31\u6027\u3002"}}
{"id": "2511.20285", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20285", "abs": "https://arxiv.org/abs/2511.20285", "authors": ["Mingyu Jeon", "Jaeyoung Suh", "Suwan Cho"], "title": "SMoG: Schema Matching on Graph", "comment": null, "summary": "Schema matching is a critical task in data integration, particularly in the medical domain where disparate Electronic Health Record (EHR) systems must be aligned to standard models like OMOP CDM. While Large Language Models (LLMs) have shown promise in schema matching, they suffer from hallucination and lack of up-to-date domain knowledge. Knowledge Graphs (KGs) offer a solution by providing structured, verifiable knowledge. However, existing KG-augmented LLM approaches often rely on inefficient complex multi-hop queries or storage-intensive vector-based retrieval methods. This paper introduces SMoG (Schema Matching on Graph), a novel framework that leverages iterative execution of simple 1-hop SPARQL queries, inspired by successful strategies in Knowledge Graph Question Answering (KGQA). SMoG enhances explainability and reliability by generating human-verifiable query paths while significantly reducing storage requirements by directly querying SPARQL endpoints. Experimental results on real-world medical datasets demonstrate that SMoG achieves performance comparable to state-of-the-art baselines, validating its effectiveness and efficiency in KG-augmented schema matching.", "AI": {"tldr": "SMoG\u662f\u4e00\u4e2a\u7528\u4e8e\u533b\u7597\u9886\u57df\u6a21\u5f0f\u5339\u914d\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u6267\u884c\u7b80\u5355\u76841\u8df3SPARQL\u67e5\u8be2\uff0c\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3aLLM\uff0c\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5b58\u50a8\u9700\u6c42\u3002", "motivation": "\u533b\u7597\u6570\u636e\u96c6\u6210\u4e2d\u9700\u8981\u5c06\u4e0d\u540c\u7684\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7cfb\u7edf\u4e0e\u6807\u51c6\u6a21\u578b\u5bf9\u9f50\uff0c\u73b0\u6709LLM\u65b9\u6cd5\u5b58\u5728\u5e7b\u89c9\u548c\u7f3a\u4e4f\u6700\u65b0\u9886\u57df\u77e5\u8bc6\u7684\u95ee\u9898\uff0c\u800c\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u65b9\u6cd5\u53c8\u5b58\u5728\u67e5\u8be2\u590d\u6742\u6216\u5b58\u50a8\u5bc6\u96c6\u7684\u7f3a\u70b9\u3002", "method": "\u63d0\u51faSMoG\u6846\u67b6\uff0c\u91c7\u7528\u8fed\u4ee3\u6267\u884c\u7b80\u53551\u8df3SPARQL\u67e5\u8be2\u7684\u7b56\u7565\uff0c\u76f4\u63a5\u4eceSPARQL\u7aef\u70b9\u67e5\u8be2\uff0c\u65e0\u9700\u5411\u91cf\u68c0\u7d22\uff0c\u751f\u6210\u53ef\u9a8c\u8bc1\u7684\u67e5\u8be2\u8def\u5f84\u3002", "result": "\u5728\u771f\u5b9e\u533b\u7597\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSMoG\u8fbe\u5230\u4e86\u4e0e\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u6a21\u5f0f\u5339\u914d\u4e2d\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "conclusion": "SMoG\u901a\u8fc7\u7b80\u5355\u76841\u8df3SPARQL\u67e5\u8be2\u8fed\u4ee3\u7b56\u7565\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u9760\u6027\u548c\u5b58\u50a8\u6548\u7387\u65b9\u9762\u7684\u6311\u6218\uff0c\u4e3a\u533b\u7597\u6570\u636e\u96c6\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20507", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20507", "abs": "https://arxiv.org/abs/2511.20507", "authors": ["Nathan Roll", "Jill Kries", "Flora Jin", "Catherine Wang", "Ann Marie Finley", "Meghan Sumner", "Cory Shain", "Laura Gwilliams"], "title": "The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models", "comment": null, "summary": "Large language models (LLMs) have emerged as a candidate \"model organism\" for human language, offering an unprecedented opportunity to study the computational basis of linguistic disorders like aphasia. However, traditional clinical assessments are ill-suited for LLMs, as they presuppose human-like pragmatic pressures and probe cognitive processes not inherent to artificial architectures. We introduce the Text Aphasia Battery (TAB), a text-only benchmark adapted from the Quick Aphasia Battery (QAB) to assess aphasic-like deficits in LLMs. The TAB comprises four subtests: Connected Text, Word Comprehension, Sentence Comprehension, and Repetition. This paper details the TAB's design, subtests, and scoring criteria. To facilitate large-scale use, we validate an automated evaluation protocol using Gemini 2.5 Flash, which achieves reliability comparable to expert human raters (prevalence-weighted Cohen's kappa = 0.255 for model--consensus agreement vs. 0.286 for human--human agreement). We release TAB as a clinically-grounded, scalable framework for analyzing language deficits in artificial systems.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6587\u672c\u7684\u5931\u8bed\u75c7\u8bc4\u4f30\u57fa\u51c6TAB\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5931\u8bed\u75c7\u6837\u7f3a\u9677\uff0c\u5e76\u9a8c\u8bc1\u4e86\u81ea\u52a8\u5316\u8bc4\u4f30\u534f\u8bae\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u4f20\u7edf\u4e34\u5e8a\u8bc4\u4f30\u4e0d\u9002\u5408LLMs\uff0c\u56e0\u4e3a\u5b83\u4eec\u9884\u8bbe\u4e86\u7c7b\u4f3c\u4eba\u7c7b\u7684\u8bed\u7528\u538b\u529b\u5e76\u63a2\u6d4b\u4eba\u5de5\u67b6\u6784\u4e2d\u4e0d\u5b58\u5728\u7684\u8ba4\u77e5\u8fc7\u7a0b\u3002\u9700\u8981\u4e13\u95e8\u9488\u5bf9LLMs\u7684\u5931\u8bed\u75c7\u8bc4\u4f30\u5de5\u5177\u3002", "method": "\u4ece\u5feb\u901f\u5931\u8bed\u75c7\u7535\u6c60(QAB)\u6539\u7f16\u5f00\u53d1\u4e86\u6587\u672c\u5931\u8bed\u75c7\u7535\u6c60(TAB)\uff0c\u5305\u542b\u56db\u4e2a\u5b50\u6d4b\u8bd5\uff1a\u8fde\u63a5\u6587\u672c\u3001\u5355\u8bcd\u7406\u89e3\u3001\u53e5\u5b50\u7406\u89e3\u548c\u91cd\u590d\u3002\u4f7f\u7528Gemini 2.5 Flash\u9a8c\u8bc1\u81ea\u52a8\u5316\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u81ea\u52a8\u5316\u8bc4\u4f30\u534f\u8bae\u8fbe\u5230\u4e86\u4e0e\u4e13\u5bb6\u4eba\u7c7b\u8bc4\u5206\u8005\u76f8\u5f53\u7684\u53ef\u9760\u6027\uff08\u6a21\u578b-\u5171\u8bc6\u4e00\u81f4\u6027Cohen's kappa = 0.255 vs \u4eba\u7c7b-\u4eba\u7c7b\u4e00\u81f4\u60270.286\uff09\u3002", "conclusion": "TAB\u4f5c\u4e3a\u4e00\u4e2a\u57fa\u4e8e\u4e34\u5e8a\u7684\u3001\u53ef\u6269\u5c55\u7684\u6846\u67b6\u53d1\u5e03\uff0c\u7528\u4e8e\u5206\u6790\u4eba\u5de5\u7cfb\u7edf\u4e2d\u7684\u8bed\u8a00\u7f3a\u9677\u3002"}}
{"id": "2511.20297", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20297", "abs": "https://arxiv.org/abs/2511.20297", "authors": ["Shashank Kirtania", "Param Biyani", "Priyanshu Gupta", "Yasharth Bajpai", "Roshni Iyer", "Sumit Gulwani", "Gustavo Soares"], "title": "Improving Language Agents through BREW", "comment": null, "summary": "Large Language Model (LLM)-based agents are increasingly applied to tasks requiring structured reasoning, tool use, and environmental adaptation, such as data manipulation, multistep planning, and computer-use automation. However, despite their versatility, current training paradigms for model weight optimization methods, like PPO and GRPO, remain relatively impractical with their high computational overhead for rollout convergence. In addition, the resulting agent policies are difficult to interpret, adapt, or incrementally improve. To address this, we investigate creating and refining structured memory of experiential learning of an agent from its environment as an alternative route to agent optimization. We introduce BREW (Bootstrapping expeRientially-learned Environmental knoWledge), a framework for agent optimization for downstream tasks via KB construction and refinement. In our formulation, we introduce an effective method for partitioning agent memory for more efficient retrieval and refinement. BREW uses task graders and behavior rubrics to learn insights while leveraging state-space search for ensuring robustness from the noise and non-specificity in natural language. Empirical results on real world, domain-grounded benchmarks -- OSWorld, $\u03c4^2$Bench, and SpreadsheetBench -- show BREW achieves $10-20\\%$ improvement in task precision, $10-15\\%$ reduction in API/tool calls leading to faster execution time, all while maintaining computational efficiency on par with base models. Unlike prior work where memory is treated as static context, we establish the KB as a modular and controllable substrate for agent optimization -- an explicit lever for shaping behavior in a transparent, interpretable, and extensible manner.", "AI": {"tldr": "BREW\u6846\u67b6\u901a\u8fc7\u6784\u5efa\u548c\u7cbe\u70bc\u7ecf\u9a8c\u77e5\u8bc6\u5e93\u6765\u4f18\u5316LLM\u667a\u80fd\u4f53\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4efb\u52a1\u7cbe\u5ea6\u548c\u51cf\u5c11API\u8c03\u7528\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8ePPO\u548cGRPO\u7684\u667a\u80fd\u4f53\u8bad\u7ec3\u65b9\u6cd5\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u4e14\u4ea7\u751f\u7684\u7b56\u7565\u96be\u4ee5\u89e3\u91ca\u3001\u9002\u5e94\u6216\u589e\u91cf\u6539\u8fdb\u3002", "method": "\u5f15\u5165BREW\u6846\u67b6\uff0c\u901a\u8fc7\u77e5\u8bc6\u5e93\u6784\u5efa\u548c\u7cbe\u70bc\u6765\u4f18\u5316\u667a\u80fd\u4f53\uff0c\u91c7\u7528\u4efb\u52a1\u8bc4\u5206\u548c\u884c\u4e3a\u51c6\u5219\u5b66\u4e60\u6d1e\u5bdf\uff0c\u5229\u7528\u72b6\u6001\u7a7a\u95f4\u641c\u7d22\u786e\u4fdd\u9c81\u68d2\u6027\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBREW\u5b9e\u73b0\u4e8610-20%\u7684\u4efb\u52a1\u7cbe\u5ea6\u63d0\u5347\uff0c10-15%\u7684API\u8c03\u7528\u51cf\u5c11\uff0c\u6267\u884c\u65f6\u95f4\u66f4\u5feb\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u57fa\u7840\u6a21\u578b\u76f8\u5f53\u7684\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u5c06\u77e5\u8bc6\u5e93\u786e\u7acb\u4e3a\u6a21\u5757\u5316\u3001\u53ef\u63a7\u7684\u667a\u80fd\u4f53\u4f18\u5316\u57fa\u5e95\uff0c\u4ee5\u900f\u660e\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u6269\u5c55\u7684\u65b9\u5f0f\u5851\u9020\u884c\u4e3a\u3002"}}
{"id": "2511.20534", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20534", "abs": "https://arxiv.org/abs/2511.20534", "authors": ["Wesley Bian", "Xiaofeng Lin", "Guang Cheng"], "title": "Bridging the Language Gap: Synthetic Voice Diversity via Latent Mixup for Equitable Speech Recognition", "comment": "Accepted at ICML 2025 Workshop on Machine Learning for Audio", "summary": "Modern machine learning models for audio tasks often exhibit superior performance on English and other well-resourced languages, primarily due to the abundance of available training data. This disparity leads to an unfair performance gap for low-resource languages, where data collection is both challenging and costly. In this work, we introduce a novel data augmentation technique for speech corpora designed to mitigate this gap. Through comprehensive experiments, we demonstrate that our method significantly improves the performance of automatic speech recognition systems on low-resource languages. Furthermore, we show that our approach outperforms existing augmentation strategies, offering a practical solution for enhancing speech technology in underrepresented linguistic communities.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bed\u97f3\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u7528\u4e8e\u6539\u5584\u4f4e\u8d44\u6e90\u8bed\u8a00\u5728\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u4e2d\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "motivation": "\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u82f1\u8bed\u7b49\u8d44\u6e90\u4e30\u5bcc\u8bed\u8a00\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u7531\u4e8e\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u5bfc\u81f4\u6027\u80fd\u5dee\u8ddd\u663e\u8457\uff0c\u6570\u636e\u6536\u96c6\u65e2\u56f0\u96be\u53c8\u6602\u8d35\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u65b0\u9896\u7684\u8bed\u97f3\u8bed\u6599\u5e93\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u65e8\u5728\u5f25\u8865\u8fd9\u79cd\u6027\u80fd\u5dee\u8ddd\u3002", "result": "\u901a\u8fc7\u5168\u9762\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u4f18\u4e8e\u73b0\u6709\u7684\u589e\u5f3a\u7b56\u7565\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u589e\u5f3a\u4ee3\u8868\u6027\u4e0d\u8db3\u8bed\u8a00\u793e\u533a\u7684\u8bed\u97f3\u6280\u672f\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20312", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20312", "abs": "https://arxiv.org/abs/2511.20312", "authors": ["Alexander Beiser", "Flavio Martinelli", "Wulfram Gerstner", "Johanni Brea"], "title": "Data Augmentation Techniques to Reverse-Engineer Neural Network Weights from Input-Output Queries", "comment": "Proceedings of the III edition of the Workshop on Unifying Representations in Neural Models (UniReps 2025)", "summary": "Network weights can be reverse-engineered given enough informative samples of a network's input-output function. In a teacher-student setup, this translates into collecting a dataset of the teacher mapping -- querying the teacher -- and fitting a student to imitate such mapping. A sensible choice of queries is the dataset the teacher is trained on. But current methods fail when the teacher parameters are more numerous than the training data, because the student overfits to the queries instead of aligning its parameters to the teacher. In this work, we explore augmentation techniques to best sample the input-output mapping of a teacher network, with the goal of eliciting a rich set of representations from the teacher hidden layers. We discover that standard augmentations such as rotation, flipping, and adding noise, bring little to no improvement to the identification problem. We design new data augmentation techniques tailored to better sample the representational space of the network's hidden layers. With our augmentations we extend the state-of-the-art range of recoverable network sizes. To test their scalability, we show that we can recover networks of up to 100 times more parameters than training data-points.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u7684\u6570\u636e\u589e\u5f3a\u6280\u672f\u6765\u6539\u8fdb\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u9006\u5411\u5de5\u7a0b\uff0c\u901a\u8fc7\u66f4\u597d\u5730\u91c7\u6837\u7f51\u7edc\u9690\u85cf\u5c42\u7684\u8868\u793a\u7a7a\u95f4\uff0c\u53ef\u4ee5\u6062\u590d\u6bd4\u8bad\u7ec3\u6570\u636e\u70b9\u591a100\u500d\u7684\u7f51\u7edc\u53c2\u6570\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u5728\u6559\u5e08\u7f51\u7edc\u53c2\u6570\u591a\u4e8e\u8bad\u7ec3\u6570\u636e\u65f6\u4f1a\u5931\u8d25\uff0c\u56e0\u4e3a\u5b66\u751f\u4f1a\u8fc7\u62df\u5408\u67e5\u8be2\u6570\u636e\u800c\u4e0d\u662f\u5bf9\u9f50\u53c2\u6570\u3002\u9700\u8981\u66f4\u597d\u7684\u91c7\u6837\u6280\u672f\u6765\u83b7\u53d6\u6559\u5e08\u7f51\u7edc\u9690\u85cf\u5c42\u7684\u4e30\u5bcc\u8868\u793a\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e13\u95e8\u7684\u6570\u636e\u589e\u5f3a\u6280\u672f\u6765\u66f4\u597d\u5730\u91c7\u6837\u7f51\u7edc\u9690\u85cf\u5c42\u7684\u8868\u793a\u7a7a\u95f4\uff0c\u800c\u4e0d\u662f\u4f7f\u7528\u6807\u51c6\u7684\u65cb\u8f6c\u3001\u7ffb\u8f6c\u548c\u6dfb\u52a0\u566a\u58f0\u7b49\u589e\u5f3a\u65b9\u6cd5\u3002", "result": "\u65b0\u589e\u5f3a\u6280\u672f\u6269\u5c55\u4e86\u53ef\u6062\u590d\u7f51\u7edc\u5927\u5c0f\u7684\u6700\u5148\u8fdb\u8303\u56f4\uff0c\u80fd\u591f\u6062\u590d\u6bd4\u8bad\u7ec3\u6570\u636e\u70b9\u591a100\u500d\u7684\u7f51\u7edc\u53c2\u6570\u3002", "conclusion": "\u4e13\u95e8\u9488\u5bf9\u7f51\u7edc\u9690\u85cf\u5c42\u8868\u793a\u7a7a\u95f4\u8bbe\u8ba1\u7684\u589e\u5f3a\u6280\u672f\u6bd4\u6807\u51c6\u589e\u5f3a\u65b9\u6cd5\u66f4\u6709\u6548\uff0c\u663e\u8457\u63d0\u5347\u4e86\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u9006\u5411\u5de5\u7a0b\u7684\u80fd\u529b\u3002"}}
{"id": "2511.20547", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20547", "abs": "https://arxiv.org/abs/2511.20547", "authors": ["Farjana Sultana Mim", "Shuchin Aeron", "Eric Miller", "Kristen Wendell"], "title": "From Words to Wisdom: Discourse Annotation and Baseline Models for Student Dialogue Understanding", "comment": null, "summary": "Identifying discourse features in student conversations is quite important for educational researchers to recognize the curricular and pedagogical variables that cause students to engage in constructing knowledge rather than merely completing tasks. The manual analysis of student conversations to identify these discourse features is time-consuming and labor-intensive, which limits the scale and scope of studies. Leveraging natural language processing (NLP) techniques can facilitate the automatic detection of these discourse features, offering educational researchers scalable and data-driven insights. However, existing studies in NLP that focus on discourse in dialogue rarely address educational data. In this work, we address this gap by introducing an annotated educational dialogue dataset of student conversations featuring knowledge construction and task production discourse. We also establish baseline models for automatically predicting these discourse properties for each turn of talk within conversations, using pre-trained large language models GPT-3.5 and Llama-3.1. Experimental results indicate that these state-of-the-art models perform suboptimally on this task, indicating the potential for future research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6559\u80b2\u5bf9\u8bdd\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u81ea\u52a8\u68c0\u6d4b\u5b66\u751f\u5bf9\u8bdd\u4e2d\u7684\u77e5\u8bc6\u5efa\u6784\u548c\u4efb\u52a1\u4ea7\u51fa\u8bdd\u8bed\u7279\u5f81\uff0c\u5e76\u4f7f\u7528GPT-3.5\u548cLlama-3.1\u5efa\u7acb\u4e86\u57fa\u7ebf\u6a21\u578b\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0c\u8868\u660e\u8be5\u4efb\u52a1\u5177\u6709\u7814\u7a76\u6f5c\u529b\u3002", "motivation": "\u624b\u52a8\u5206\u6790\u5b66\u751f\u5bf9\u8bdd\u4e2d\u7684\u8bdd\u8bed\u7279\u5f81\u8017\u65f6\u8d39\u529b\uff0c\u9650\u5236\u4e86\u7814\u7a76\u89c4\u6a21\u3002\u5229\u7528NLP\u6280\u672f\u53ef\u4ee5\u81ea\u52a8\u68c0\u6d4b\u8fd9\u4e9b\u7279\u5f81\uff0c\u4e3a\u6559\u80b2\u7814\u7a76\u8005\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u6570\u636e\u9a71\u52a8\u6d1e\u5bdf\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u6807\u6ce8\u7684\u6559\u80b2\u5bf9\u8bdd\u6570\u636e\u96c6\uff0c\u5305\u542b\u77e5\u8bc6\u5efa\u6784\u548c\u4efb\u52a1\u4ea7\u51fa\u8bdd\u8bed\u7279\u5f81\uff0c\u5e76\u4f7f\u7528\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578bGPT-3.5\u548cLlama-3.1\u5efa\u7acb\u4e86\u81ea\u52a8\u9884\u6d4b\u8bdd\u8bed\u5c5e\u6027\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e9b\u6700\u5148\u8fdb\u7684\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e0a\u8868\u73b0\u6b20\u4f73\u3002", "conclusion": "\u73b0\u6709\u6a21\u578b\u5728\u6559\u80b2\u5bf9\u8bdd\u8bdd\u8bed\u7279\u5f81\u68c0\u6d4b\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u7406\u60f3\uff0c\u8fd9\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u53d1\u5c55\u7a7a\u95f4\u548c\u6f5c\u529b\u3002"}}
{"id": "2511.20321", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20321", "abs": "https://arxiv.org/abs/2511.20321", "authors": ["Patrick Kenny"], "title": "Active Inference in Discrete State Spaces from First Principles", "comment": "56 pages", "summary": "We seek to clarify the concept of active inference by disentangling it from the Free Energy Principle. We show how the optimizations that need to be carried out in order to implement active inference in discrete state spaces can be formulated as constrained divergence minimization problems which can be solved by standard mean field methods that do not appeal to the idea of expected free energy. When it is used to model perception, the perception/action divergence criterion that we propose coincides with variational free energy. When it is used to model action, it differs from an expected free energy functional by an entropy regularizer.", "AI": {"tldr": "\u672c\u6587\u6f84\u6e05\u4e86\u4e3b\u52a8\u63a8\u7406\u4e0e\u81ea\u7531\u80fd\u539f\u7406\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u7ea6\u675f\u6563\u5ea6\u6700\u5c0f\u5316\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u65e0\u9700\u4f9d\u8d56\u671f\u671b\u81ea\u7531\u80fd\u6982\u5ff5\u3002", "motivation": "\u6f84\u6e05\u4e3b\u52a8\u63a8\u7406\u6982\u5ff5\uff0c\u5c06\u5176\u4e0e\u81ea\u7531\u80fd\u539f\u7406\u533a\u5206\u5f00\u6765\uff0c\u63a2\u7d22\u65e0\u9700\u671f\u671b\u81ea\u7531\u80fd\u7684\u5b9e\u73b0\u65b9\u6cd5\u3002", "method": "\u5c06\u4e3b\u52a8\u63a8\u7406\u4f18\u5316\u95ee\u9898\u8868\u8ff0\u4e3a\u7ea6\u675f\u6563\u5ea6\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u4f7f\u7528\u6807\u51c6\u5e73\u5747\u573a\u65b9\u6cd5\u6c42\u89e3\u3002", "result": "\u611f\u77e5\u5efa\u6a21\u65f6\u63d0\u51fa\u7684\u611f\u77e5/\u52a8\u4f5c\u6563\u5ea6\u51c6\u5219\u4e0e\u53d8\u5206\u81ea\u7531\u80fd\u4e00\u81f4\uff1b\u52a8\u4f5c\u5efa\u6a21\u65f6\u4e0e\u671f\u671b\u81ea\u7531\u80fd\u6cdb\u51fd\u76f8\u5dee\u4e00\u4e2a\u71b5\u6b63\u5219\u5316\u9879\u3002", "conclusion": "\u4e3b\u52a8\u63a8\u7406\u53ef\u4ee5\u901a\u8fc7\u7ea6\u675f\u6563\u5ea6\u6700\u5c0f\u5316\u5b9e\u73b0\uff0c\u65e0\u9700\u4f9d\u8d56\u81ea\u7531\u80fd\u539f\u7406\uff0c\u4e3a\u4e3b\u52a8\u63a8\u7406\u63d0\u4f9b\u4e86\u66f4\u6e05\u6670\u7684\u6570\u5b66\u57fa\u7840\u3002"}}
{"id": "2511.20604", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20604", "abs": "https://arxiv.org/abs/2511.20604", "authors": ["Yixin Liu", "Pengfei Liu", "Arman Cohan"], "title": "On Evaluating LLM Alignment by Evaluating LLMs as Judges", "comment": "NeurIPS 2025 Camera Ready", "summary": "Alignment with human preferences is an important evaluation aspect of LLMs, requiring them to be helpful, honest, safe, and to precisely follow human instructions. Evaluating large language models' (LLMs) alignment typically involves directly assessing their open-ended responses, requiring human annotators or strong LLM judges. Conversely, LLMs themselves have also been extensively evaluated as judges for assessing alignment. In this work, we examine the relationship between LLMs' generation and evaluation capabilities in aligning with human preferences. To this end, we first conduct a comprehensive analysis of the generation-evaluation consistency (GE-consistency) among various LLMs, revealing a strong correlation between their generation and evaluation capabilities when evaluated by a strong LLM preference oracle. Utilizing this finding, we propose a benchmarking paradigm that measures LLM alignment with human preferences without directly evaluating their generated outputs, instead assessing LLMs in their role as evaluators. Our evaluation shows that our proposed benchmark, AlignEval, matches or surpasses widely used automatic LLM evaluation benchmarks, such as AlpacaEval and Arena-Hard, in capturing human preferences when ranking LLMs. Our study offers valuable insights into the connection between LLMs' generation and evaluation capabilities, and introduces a benchmark that assesses alignment without directly evaluating model outputs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAlignEval\u57fa\u51c6\uff0c\u901a\u8fc7\u8bc4\u4f30LLMs\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u80fd\u529b\u6765\u95f4\u63a5\u8861\u91cf\u5176\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u907f\u514d\u4e86\u76f4\u63a5\u8bc4\u4f30\u751f\u6210\u8f93\u51fa\u7684\u9700\u6c42\u3002\u7814\u7a76\u53d1\u73b0\u751f\u6210\u4e0e\u8bc4\u4f30\u80fd\u529b\u5b58\u5728\u5f3a\u76f8\u5173\u6027\uff0c\u65b0\u57fa\u51c6\u5728\u6392\u540dLLMs\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u8bc4\u4f30LLMs\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u7684\u65b9\u6cd5\u9700\u8981\u76f4\u63a5\u8bc4\u4f30\u5176\u5f00\u653e\u57df\u751f\u6210\u8f93\u51fa\uff0c\u8fd9\u9700\u8981\u5927\u91cf\u4eba\u5de5\u6807\u6ce8\u6216\u5f3aLLM\u8bc4\u5224\u8005\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22LLMs\u751f\u6210\u80fd\u529b\u4e0e\u8bc4\u4f30\u80fd\u529b\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u9996\u5148\u5206\u6790\u5404\u79cdLLMs\u7684\u751f\u6210-\u8bc4\u4f30\u4e00\u81f4\u6027\uff0c\u53d1\u73b0\u4e24\u8005\u5f3a\u76f8\u5173\u3002\u57fa\u4e8e\u6b64\u63d0\u51faAlignEval\u57fa\u51c6\uff0c\u901a\u8fc7\u8bc4\u4f30LLMs\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u80fd\u529b\u6765\u95f4\u63a5\u8861\u91cf\u5176\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u800c\u4e0d\u76f4\u63a5\u8bc4\u4f30\u751f\u6210\u8f93\u51fa\u3002", "result": "\u5b9e\u9a8c\u663e\u793aAlignEval\u57fa\u51c6\u5728\u6355\u6349\u4eba\u7c7b\u504f\u597d\u6392\u540dLLMs\u65b9\u9762\uff0c\u5339\u914d\u6216\u8d85\u8d8a\u4e86AlpacaEval\u548cArena-Hard\u7b49\u5e7f\u6cdb\u4f7f\u7528\u7684\u81ea\u52a8\u8bc4\u4f30\u57fa\u51c6\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86LLMs\u751f\u6210\u4e0e\u8bc4\u4f30\u80fd\u529b\u4e4b\u95f4\u7684\u7d27\u5bc6\u8054\u7cfb\uff0c\u63d0\u51fa\u7684AlignEval\u57fa\u51c6\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u76f4\u63a5\u8bc4\u4f30\u6a21\u578b\u8f93\u51fa\u5373\u53ef\u8bc4\u4f30\u5bf9\u9f50\u7684\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2511.20333", "categories": ["cs.AI", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2511.20333", "abs": "https://arxiv.org/abs/2511.20333", "authors": ["Roman Kochnev", "Waleed Khalid", "Tolgay Atinc Uzun", "Xi Zhang", "Yashkumar Sanjaybhai Dhameliya", "Furui Qin", "Chandini Vysyaraju", "Raghuvir Duvvuri", "Avi Goyal", "Dmitry Ignatov", "Radu Timofte"], "title": "NNGPT: Rethinking AutoML with Large Language Models", "comment": null, "summary": "Building self-improving AI systems remains a fundamental challenge in the AI domain. We present NNGPT, an open-source framework that turns a large language model (LLM) into a self-improving AutoML engine for neural network development, primarily for computer vision. Unlike previous frameworks, NNGPT extends the dataset of neural networks by generating new models, enabling continuous fine-tuning of LLMs based on closed-loop system of generation, assessment, and self-improvement. It integrates within one unified workflow five synergistic LLM-based pipelines: zero-shot architecture synthesis, hyperparameter optimization (HPO), code-aware accuracy/early-stop prediction, retrieval-augmented synthesis of scope-closed PyTorch blocks (NN-RAG), and reinforcement learning. Built on the LEMUR dataset as an audited corpus with reproducible metrics, NNGPT emits from a single prompt and validates network architecture, preprocessing code, and hyperparameters, executes them end-to-end, and learns from result. The PyTorch adapter makes NNGPT framework-agnostic, enabling strong performance: NN-RAG achieves 73% executability on 1,289 targets, 3-shot prompting boosts accuracy on common datasets, and hash-based deduplication saves hundreds of runs. One-shot prediction matches search-based AutoML, reducing the need for numerous trials. HPO on LEMUR achieves RMSE 0.60, outperforming Optuna (0.64), while the code-aware predictor reaches RMSE 0.14 with Pearson r=0.78. The system has already generated over 5K validated models, proving NNGPT as an autonomous AutoML engine. Upon acceptance, the code, prompts, and checkpoints will be released for public access to enable reproducibility and facilitate community usage.", "AI": {"tldr": "NNGPT\u662f\u4e00\u4e2a\u5f00\u6e90\u6846\u67b6\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f6c\u53d8\u4e3a\u7528\u4e8e\u795e\u7ecf\u7f51\u7edc\u5f00\u53d1\u7684\u81ea\u6539\u8fdbAutoML\u5f15\u64ce\uff0c\u901a\u8fc7\u751f\u6210\u65b0\u6a21\u578b\u3001\u8bc4\u4f30\u548c\u81ea\u6539\u8fdb\u7684\u95ed\u73af\u7cfb\u7edf\uff0c\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u5b9e\u73b0\u6301\u7eed\u4f18\u5316\u3002", "motivation": "\u6784\u5efa\u81ea\u6539\u8fdbAI\u7cfb\u7edf\u662fAI\u9886\u57df\u7684\u6839\u672c\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u81ea\u4e3b\u4f18\u5316\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u548c\u8d85\u53c2\u6570\u7684AutoML\u7cfb\u7edf\u3002", "method": "\u96c6\u6210\u4e94\u4e2a\u534f\u540c\u7684LLM\u7ba1\u9053\uff1a\u96f6\u6837\u672c\u67b6\u6784\u5408\u6210\u3001\u8d85\u53c2\u6570\u4f18\u5316\u3001\u4ee3\u7801\u611f\u77e5\u7cbe\u5ea6\u9884\u6d4b\u3001\u68c0\u7d22\u589e\u5f3a\u7684PyTorch\u5757\u5408\u6210\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u57fa\u4e8eLEMUR\u6570\u636e\u96c6\u6784\u5efa\u95ed\u73af\u751f\u6210-\u8bc4\u4f30-\u81ea\u6539\u8fdb\u7cfb\u7edf\u3002", "result": "\u5728LEMUR\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0RMSE 0.60\uff0c\u4f18\u4e8eOptuna(0.64)\uff1b\u4ee3\u7801\u611f\u77e5\u9884\u6d4b\u5668\u8fbe\u5230RMSE 0.14\u548cPearson r=0.78\uff1b\u5df2\u751f\u6210\u8d85\u8fc75000\u4e2a\u9a8c\u8bc1\u6a21\u578b\uff1bNN-RAG\u57281289\u4e2a\u76ee\u6807\u4e0a\u5b9e\u73b073%\u53ef\u6267\u884c\u6027\u3002", "conclusion": "NNGPT\u8bc1\u660e\u53ef\u4f5c\u4e3a\u81ea\u4e3bAutoML\u5f15\u64ce\uff0c\u663e\u8457\u51cf\u5c11\u8bd5\u9a8c\u6b21\u6570\uff0c\u5355\u6b21\u9884\u6d4b\u5373\u53ef\u5339\u914d\u57fa\u4e8e\u641c\u7d22\u7684AutoML\u6027\u80fd\uff0c\u4ee3\u7801\u548c\u68c0\u67e5\u70b9\u5c06\u516c\u5f00\u53d1\u5e03\u4ee5\u4fc3\u8fdb\u53ef\u590d\u73b0\u6027\u548c\u793e\u533a\u4f7f\u7528\u3002"}}
{"id": "2511.20639", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20639", "abs": "https://arxiv.org/abs/2511.20639", "authors": ["Jiaru Zou", "Xiyuan Yang", "Ruizhong Qiu", "Gaotang Li", "Katherine Tieu", "Pan Lu", "Ke Shen", "Hanghang Tong", "Yejin Choi", "Jingrui He", "James Zou", "Mengdi Wang", "Ling Yang"], "title": "Latent Collaboration in Multi-Agent Systems", "comment": "Project: https://github.com/Gen-Verse/LatentMAS", "summary": "Multi-agent systems (MAS) extend large language models (LLMs) from independent single-model reasoning to coordinative system-level intelligence. While existing LLM agents depend on text-based mediation for reasoning and communication, we take a step forward by enabling models to collaborate directly within the continuous latent space. We introduce LatentMAS, an end-to-end training-free framework that enables pure latent collaboration among LLM agents. In LatentMAS, each agent first performs auto-regressive latent thoughts generation through last-layer hidden embeddings. A shared latent working memory then preserves and transfers each agent's internal representations, ensuring lossless information exchange. We provide theoretical analyses establishing that LatentMAS attains higher expressiveness and lossless information preservation with substantially lower complexity than vanilla text-based MAS. In addition, empirical evaluations across 9 comprehensive benchmarks spanning math and science reasoning, commonsense understanding, and code generation show that LatentMAS consistently outperforms strong single-model and text-based MAS baselines, achieving up to 14.6% higher accuracy, reducing output token usage by 70.8%-83.7%, and providing 4x-4.3x faster end-to-end inference. These results demonstrate that our new latent collaboration framework enhances system-level reasoning quality while offering substantial efficiency gains without any additional training. Code and data are fully open-sourced at https://github.com/Gen-Verse/LatentMAS.", "AI": {"tldr": "LatentMAS\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u4f7fLLM\u667a\u80fd\u4f53\u80fd\u591f\u5728\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fdb\u884c\u534f\u4f5c\uff0c\u76f8\u6bd4\u57fa\u4e8e\u6587\u672c\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5177\u6709\u66f4\u9ad8\u8868\u8fbe\u80fd\u529b\u548c\u65e0\u635f\u4fe1\u606f\u4ea4\u6362\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u8d28\u91cf\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709LLM\u667a\u80fd\u4f53\u4f9d\u8d56\u57fa\u4e8e\u6587\u672c\u7684\u4e2d\u4ecb\u8fdb\u884c\u63a8\u7406\u548c\u901a\u4fe1\uff0c\u9650\u5236\u4e86\u7cfb\u7edf\u7ea7\u667a\u80fd\u7684\u534f\u8c03\u6548\u7387\u3002\u672c\u6587\u65e8\u5728\u8ba9\u6a21\u578b\u76f4\u63a5\u5728\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fdb\u884c\u534f\u4f5c\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u4fe1\u606f\u4ea4\u6362\u3002", "method": "\u63d0\u51faLatentMAS\u6846\u67b6\uff1a\u6bcf\u4e2a\u667a\u80fd\u4f53\u901a\u8fc7\u6700\u540e\u4e00\u5c42\u9690\u85cf\u5d4c\u5165\u8fdb\u884c\u81ea\u56de\u5f52\u6f5c\u5728\u601d\u7ef4\u751f\u6210\uff1b\u5171\u4eab\u6f5c\u5728\u5de5\u4f5c\u5185\u5b58\u4fdd\u5b58\u548c\u4f20\u8f93\u6bcf\u4e2a\u667a\u80fd\u4f53\u7684\u5185\u90e8\u8868\u793a\uff0c\u786e\u4fdd\u65e0\u635f\u4fe1\u606f\u4ea4\u6362\u3002", "result": "\u57289\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLatentMAS\u59cb\u7ec8\u4f18\u4e8e\u5355\u6a21\u578b\u548c\u57fa\u4e8e\u6587\u672c\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u57fa\u7ebf\uff0c\u51c6\u786e\u7387\u63d0\u9ad814.6%\uff0c\u8f93\u51fatoken\u4f7f\u7528\u51cf\u5c1170.8%-83.7%\uff0c\u7aef\u5230\u7aef\u63a8\u7406\u901f\u5ea6\u63d0\u53474-4.3\u500d\u3002", "conclusion": "\u6f5c\u5728\u534f\u4f5c\u6846\u67b6\u5728\u4e0d\u589e\u52a0\u989d\u5916\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u7ea7\u63a8\u7406\u8d28\u91cf\u548c\u6548\u7387\uff0c\u8bc1\u660e\u4e86\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\u534f\u4f5c\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.20422", "categories": ["cs.AI", "cs.CV", "cs.GR", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20422", "abs": "https://arxiv.org/abs/2511.20422", "authors": ["Bo Pang", "Chenxi Xu", "Jierui Ren", "Guoping Wang", "Sheng Li"], "title": "VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning", "comment": null, "summary": "Understanding the physical world requires perceptual models grounded in physical laws rather than mere statistical correlations. However, existing multimodal learning frameworks, focused on vision and language, lack physical consistency and overlook the intrinsic causal relationships among an object's geometry, material, vibration modes, and the sounds it produces. We introduce VibraVerse, a large-scale geometry-acoustics alignment dataset that explicitly bridges the causal chain from 3D geometry -> physical attributes -> modal parameters -> acoustic signals. Each 3D model has explicit physical properties (density, Young's modulus, Poisson's ratio) and volumetric geometry, from which modal eigenfrequencies and eigenvectors are computed for impact sound synthesis under controlled excitations. To establish this coherence, we introduce CLASP, a contrastive learning framework for cross-modal alignment that preserves the causal correspondence between an object's physical structure and its acoustic response. This framework enforces physically consistent alignment across modalities, ensuring that every sample is coherent, traceable to the governing equations, and embedded within a unified representation space spanning shape, image, and sound. Built upon VibraVerse, we define a suite of benchmark tasks for geometry-to-sound prediction, sound-guided shape reconstruction, and cross-modal representation learning. Extensive validations on these tasks demonstrate that models trained on VibraVerse exhibit superior accuracy, interpretability, and generalization across modalities. These results establish VibraVerse as a benchmark for physically consistent and causally interpretable multimodal learning, providing a foundation for sound-guided embodied perception and a deeper understanding of the physical world. The dataset will be open-sourced.", "AI": {"tldr": "VibraVerse\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u51e0\u4f55-\u58f0\u5b66\u5bf9\u9f50\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u7269\u7406\u5b9a\u5f8b\u5c063D\u51e0\u4f55\u3001\u7269\u7406\u5c5e\u6027\u3001\u632f\u52a8\u6a21\u5f0f\u548c\u58f0\u97f3\u4fe1\u53f7\u56e0\u679c\u8fde\u63a5\u8d77\u6765\uff0c\u4e3a\u7269\u7406\u4e00\u81f4\u7684\u591a\u6a21\u6001\u5b66\u4e60\u63d0\u4f9b\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u89c6\u89c9\u548c\u8bed\u8a00\u7684\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6\u7f3a\u4e4f\u7269\u7406\u4e00\u81f4\u6027\uff0c\u5ffd\u89c6\u4e86\u7269\u4f53\u51e0\u4f55\u3001\u6750\u6599\u3001\u632f\u52a8\u6a21\u5f0f\u548c\u4ea7\u751f\u58f0\u97f3\u4e4b\u95f4\u7684\u5185\u5728\u56e0\u679c\u5173\u7cfb\u3002\u9700\u8981\u5efa\u7acb\u57fa\u4e8e\u7269\u7406\u5b9a\u5f8b\u7684\u611f\u77e5\u6a21\u578b\u3002", "method": "\u6784\u5efaVibraVerse\u6570\u636e\u96c6\uff0c\u5305\u542b3D\u6a21\u578b\u7684\u7269\u7406\u5c5e\u6027\uff08\u5bc6\u5ea6\u3001\u6768\u6c0f\u6a21\u91cf\u3001\u6cca\u677e\u6bd4\uff09\u548c\u4f53\u79ef\u51e0\u4f55\uff0c\u8ba1\u7b97\u6a21\u6001\u7279\u5f81\u9891\u7387\u548c\u7279\u5f81\u5411\u91cf\uff0c\u5728\u53d7\u63a7\u6fc0\u52b1\u4e0b\u5408\u6210\u51b2\u51fb\u58f0\u97f3\u3002\u5f00\u53d1CLASP\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u8fdb\u884c\u8de8\u6a21\u6001\u5bf9\u9f50\u3002", "result": "\u5728\u51e0\u4f55\u5230\u58f0\u97f3\u9884\u6d4b\u3001\u58f0\u97f3\u5f15\u5bfc\u5f62\u72b6\u91cd\u5efa\u548c\u8de8\u6a21\u6001\u8868\u793a\u5b66\u4e60\u7b49\u57fa\u51c6\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u9a8c\u8bc1\u8868\u660e\uff0c\u5728VibraVerse\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8de8\u6a21\u6001\u6cdb\u5316\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\u3002", "conclusion": "VibraVerse\u4e3a\u7269\u7406\u4e00\u81f4\u548c\u56e0\u679c\u53ef\u89e3\u91ca\u7684\u591a\u6a21\u6001\u5b66\u4e60\u5efa\u7acb\u4e86\u57fa\u51c6\uff0c\u4e3a\u58f0\u97f3\u5f15\u5bfc\u7684\u5177\u8eab\u611f\u77e5\u548c\u7269\u7406\u4e16\u754c\u6df1\u5ea6\u7406\u89e3\u63d0\u4f9b\u4e86\u57fa\u7840\u3002\u6570\u636e\u96c6\u5c06\u5f00\u6e90\u3002"}}
{"id": "2511.20468", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20468", "abs": "https://arxiv.org/abs/2511.20468", "authors": ["Yuanhao Li", "Mingshan Liu", "Hongbo Wang", "Yiding Zhang", "Yifei Ma", "Wei Tan"], "title": "DRAFT-RL: Multi-Agent Chain-of-Draft Reasoning for Reinforcement Learning-Enhanced LLMs", "comment": null, "summary": "Large Language Models (LLMs) have shown impressive capabilities in multi-step reasoning and problem-solving.Recent works introduce multi-agent reflection frameworks where multiple LLM agents critique and refine each other's outputs using reinforcement learning (RL). However, these approaches often rely on single-shot responses and lack structural diversity in reasoning exploration. In this paper, we propose DRAFT-RL, a novel framework that integrates Chain-of-Draft (CoD) reasoning into multi-agent RL training. Instead of generating single responses, each agent produces multiple drafts per query, which are then evaluated by peer agents and a learned reward model to identify the most promising trajectory. These selected drafts are used to refine future reasoning strategies through actor-critic learning.DRAFT-RL enables explicit multi-path exploration, peer-guided reflection, and reward-aligned selection, resulting in more robust and interpretable LLM agent behavior. We evaluate our method on complex reasoning tasks including code synthesis, symbolic math, and knowledge-intensive QA,demonstrating that DRAFT-RL outperforms existing reflective and RL-based agents by significant margins in both accuracy and convergence speed", "AI": {"tldr": "DRAFT-RL\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u94fe\u5f0f\u8349\u7a3f\u63a8\u7406\uff0c\u8ba9\u6bcf\u4e2a\u667a\u80fd\u4f53\u4e3a\u6bcf\u4e2a\u67e5\u8be2\u751f\u6210\u591a\u4e2a\u8349\u7a3f\uff0c\u901a\u8fc7\u540c\u4f34\u8bc4\u4f30\u548c\u5956\u52b1\u6a21\u578b\u9009\u62e9\u6700\u4f18\u8f68\u8ff9\uff0c\u63d0\u5347\u63a8\u7406\u7684\u591a\u6837\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u591a\u667a\u80fd\u4f53\u53cd\u601d\u6846\u67b6\u4f9d\u8d56\u5355\u6b21\u54cd\u5e94\uff0c\u7f3a\u4e4f\u63a8\u7406\u63a2\u7d22\u7684\u7ed3\u6784\u591a\u6837\u6027\uff0c\u9650\u5236\u4e86LLM\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51faDRAFT-RL\u6846\u67b6\uff0c\u5c06\u94fe\u5f0f\u8349\u7a3f\u63a8\u7406\u6574\u5408\u5230\u591a\u667a\u80fd\u4f53RL\u8bad\u7ec3\u4e2d\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u751f\u6210\u591a\u4e2a\u8349\u7a3f\uff0c\u901a\u8fc7\u540c\u4f34\u8bc4\u4f30\u548c\u5956\u52b1\u6a21\u578b\u9009\u62e9\u6700\u4f18\u8f68\u8ff9\uff0c\u4f7f\u7528actor-critic\u5b66\u4e60\u4f18\u5316\u63a8\u7406\u7b56\u7565\u3002", "result": "\u5728\u4ee3\u7801\u5408\u6210\u3001\u7b26\u53f7\u6570\u5b66\u548c\u77e5\u8bc6\u5bc6\u96c6\u578b\u95ee\u7b54\u7b49\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\uff0cDRAFT-RL\u5728\u51c6\u786e\u6027\u548c\u6536\u655b\u901f\u5ea6\u4e0a\u90fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u53cd\u601d\u548c\u57fa\u4e8eRL\u7684\u667a\u80fd\u4f53\u3002", "conclusion": "DRAFT-RL\u901a\u8fc7\u663e\u5f0f\u591a\u8def\u5f84\u63a2\u7d22\u3001\u540c\u4f34\u5f15\u5bfc\u53cd\u601d\u548c\u5956\u52b1\u5bf9\u9f50\u9009\u62e9\uff0c\u5b9e\u73b0\u4e86\u66f4\u9c81\u68d2\u548c\u53ef\u89e3\u91ca\u7684LLM\u667a\u80fd\u4f53\u884c\u4e3a\uff0c\u4e3a\u590d\u6742\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20471", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20471", "abs": "https://arxiv.org/abs/2511.20471", "authors": ["Yuto Suzuki", "Farnoush Banaei-Kashani"], "title": "Universe of Thoughts: Enabling Creative Reasoning with Large Language Models", "comment": null, "summary": "Reasoning based on Large Language Models (LLMs) has garnered increasing attention due to outstanding performance of these models in mathematical and complex logical tasks. Beginning with the Chain-of-Thought (CoT) prompting technique, numerous reasoning methods have emerged that decompose problems into smaller, sequential steps (or thoughts). However, existing reasoning models focus on conventional problem-solving and do not necessarily generate creative solutions by ``creative reasoning''. In domains where the solution space is expansive and conventional solutions are suboptimal, such as drug discovery or business strategization, creative reasoning to discover innovative solutions is crucial. To address this gap, first we introduce a computational framework for creative reasoning inspired by established cognitive science principles. With this framework, we propose three core creative reasoning paradigms, namely, \\textit{combinational}, \\textit{exploratory}, and \\textit{transformative} reasoning, where each offers specific directions for systematic exploration of the universe of thoughts to generate creative solutions. Next, to materialize this framework using LLMs, we introduce the \\textit{Universe of Thoughts} (or \\textit{UoT}, for short), a novel set of methods to implement the aforementioned three creative processes. Finally, we introduce three novel tasks that necessitate creative problem-solving, along with an evaluation benchmark to assess creativity from three orthogonal perspectives: feasibility as constraint, and utility and novelty as metrics. With a comparative analysis against the state-of-the-art (SOTA) reasoning techniques as well as representative commercial models with reasoning capability, we show that UoT demonstrates superior performance in creative reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u521b\u9020\u6027\u63a8\u7406\u6846\u67b6UoT\uff0c\u5305\u542b\u7ec4\u5408\u3001\u63a2\u7d22\u548c\u8f6c\u6362\u4e09\u79cd\u63a8\u7406\u8303\u5f0f\uff0c\u5728\u9700\u8981\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u7684\u9886\u57df\u4f18\u4e8e\u73b0\u6709\u63a8\u7406\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u5e38\u89c4\u95ee\u9898\u89e3\u51b3\uff0c\u7f3a\u4e4f\u521b\u9020\u6027\u63a8\u7406\u80fd\u529b\u3002\u5728\u836f\u7269\u53d1\u73b0\u3001\u5546\u4e1a\u7b56\u7565\u7b49\u89e3\u51b3\u65b9\u6848\u7a7a\u95f4\u5e7f\u9614\u4e14\u5e38\u89c4\u65b9\u6848\u6b21\u4f18\u7684\u9886\u57df\uff0c\u53d1\u73b0\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f15\u5165\u53d7\u8ba4\u77e5\u79d1\u5b66\u542f\u53d1\u7684\u521b\u9020\u6027\u63a8\u7406\u8ba1\u7b97\u6846\u67b6\uff0c\u63d0\u51fa\u7ec4\u5408\u3001\u63a2\u7d22\u548c\u8f6c\u6362\u4e09\u79cd\u6838\u5fc3\u63a8\u7406\u8303\u5f0f\uff0c\u5e76\u5f00\u53d1UoT\u65b9\u6cd5\u5b9e\u73b0\u8fd9\u4e9b\u521b\u9020\u6027\u8fc7\u7a0b\u3002", "result": "\u5728\u4e09\u4e2a\u9700\u8981\u521b\u9020\u6027\u95ee\u9898\u89e3\u51b3\u7684\u65b0\u4efb\u52a1\u4e0a\uff0cUoT\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u63a8\u7406\u6280\u672f\u548c\u5177\u6709\u63a8\u7406\u80fd\u529b\u7684\u5546\u4e1a\u6a21\u578b\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u521b\u9020\u6027\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "UoT\u6846\u67b6\u901a\u8fc7\u7cfb\u7edf\u63a2\u7d22\u601d\u7ef4\u5b87\u5b99\uff0c\u80fd\u591f\u6709\u6548\u751f\u6210\u521b\u9020\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u9700\u8981\u521b\u65b0\u7684\u9886\u57df\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.20497", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20497", "abs": "https://arxiv.org/abs/2511.20497", "authors": ["Van Tran", "Shinan Liu", "Tian Li", "Nick Feamster"], "title": "Quantifying the Privacy Implications of High-Fidelity Synthetic Network Traffic", "comment": "14 pages, 13 Figures, 6 Tables", "summary": "To address the scarcity and privacy concerns of network traffic data, various generative models have been developed to produce synthetic traffic. However, synthetic traffic is not inherently privacy-preserving, and the extent to which it leaks sensitive information, and how to measure such leakage, remain largely unexplored. This challenge is further compounded by the diversity of model architectures, which shape how traffic is represented and synthesized. We introduce a comprehensive set of privacy metrics for synthetic network traffic, combining standard approaches like membership inference attacks (MIA) and data extraction attacks with network-specific identifiers and attributes. Using these metrics, we systematically evaluate the vulnerability of different representative generative models and examine the factors that influence attack success. Our results reveal substantial variability in privacy risks across models and datasets. MIA success ranges from 0% to 88%, and up to 100% of network identifiers can be recovered from generated traffic, highlighting serious privacy vulnerabilities. We further identify key factors that significantly affect attack outcomes, including training data diversity and how well the generative model fits the training data. These findings provide actionable guidance for designing and deploying generative models that minimize privacy leakage, establishing a foundation for safer synthetic network traffic generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u9488\u5bf9\u5408\u6210\u7f51\u7edc\u6d41\u91cf\u7684\u9690\u79c1\u8bc4\u4f30\u6307\u6807\uff0c\u7ed3\u5408\u6807\u51c6\u653b\u51fb\u65b9\u6cd5\u548c\u7f51\u7edc\u7279\u5b9a\u6807\u8bc6\u7b26\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4e0d\u540c\u751f\u6210\u6a21\u578b\u7684\u9690\u79c1\u98ce\u9669\uff0c\u53d1\u73b0\u9690\u79c1\u6cc4\u9732\u7a0b\u5ea6\u5dee\u5f02\u5f88\u5927\uff0c\u5e76\u8bc6\u522b\u4e86\u5f71\u54cd\u653b\u51fb\u6210\u529f\u7387\u7684\u5173\u952e\u56e0\u7d20\u3002", "motivation": "\u89e3\u51b3\u5408\u6210\u7f51\u7edc\u6d41\u91cf\u6570\u636e\u4e2d\u9690\u79c1\u6cc4\u9732\u95ee\u9898\uff0c\u5f53\u524d\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u9690\u79c1\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4e14\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u7684\u9690\u79c1\u98ce\u9669\u5dee\u5f02\u672a\u77e5\u3002", "method": "\u5f15\u5165\u7efc\u5408\u9690\u79c1\u8bc4\u4f30\u6307\u6807\uff0c\u7ed3\u5408\u6210\u5458\u63a8\u7406\u653b\u51fb\u3001\u6570\u636e\u63d0\u53d6\u653b\u51fb\u548c\u7f51\u7edc\u7279\u5b9a\u6807\u8bc6\u7b26\u5206\u6790\uff0c\u7cfb\u7edf\u8bc4\u4f30\u591a\u79cd\u4ee3\u8868\u6027\u751f\u6210\u6a21\u578b\u7684\u9690\u79c1\u8106\u5f31\u6027\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u95f4\u9690\u79c1\u98ce\u9669\u5dee\u5f02\u663e\u8457\uff1aMIA\u6210\u529f\u73870%-88%\uff0c\u7f51\u7edc\u6807\u8bc6\u7b26\u6062\u590d\u7387\u53ef\u8fbe100%\uff0c\u8bc6\u522b\u51fa\u8bad\u7ec3\u6570\u636e\u591a\u6837\u6027\u548c\u6a21\u578b\u62df\u5408\u5ea6\u662f\u5f71\u54cd\u653b\u51fb\u6210\u529f\u7387\u7684\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "\u4e3a\u8bbe\u8ba1\u548c\u90e8\u7f72\u6700\u5c0f\u5316\u9690\u79c1\u6cc4\u9732\u7684\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u6307\u5bfc\uff0c\u5efa\u7acb\u4e86\u66f4\u5b89\u5168\u7684\u5408\u6210\u7f51\u7edc\u6d41\u91cf\u751f\u6210\u57fa\u7840\u3002"}}
{"id": "2511.20510", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20510", "abs": "https://arxiv.org/abs/2511.20510", "authors": ["Yuto Suzuki", "Paul Awolade", "Daniel V. LaBarbera", "Farnoush Banaei-Kashani"], "title": "FRAGMENTA: End-to-end Fragmentation-based Generative Model with Agentic Tuning for Drug Lead Optimization", "comment": null, "summary": "Molecule generation using generative AI is vital for drug discovery, yet class-specific datasets often contain fewer than 100 training examples. While fragment-based models handle limited data better than atom-based approaches, existing heuristic fragmentation limits diversity and misses key fragments. Additionally, model tuning typically requires slow, indirect collaboration between medicinal chemists and AI engineers. We introduce FRAGMENTA, an end-to-end framework for drug lead optimization comprising: 1) a novel generative model that reframes fragmentation as a \"vocabulary selection\" problem, using dynamic Q-learning to jointly optimize fragmentation and generation; and 2) an agentic AI system that refines objectives via conversational feedback from domain experts. This system removes the AI engineer from the loop and progressively learns domain knowledge to eventually automate tuning. In real-world cancer drug discovery experiments, FRAGMENTA's Human-Agent configuration identified nearly twice as many high-scoring molecules as baselines. Furthermore, the fully autonomous Agent-Agent system outperformed traditional Human-Human tuning, demonstrating the efficacy of agentic tuning in capturing expert intent.", "AI": {"tldr": "FRAGMENTA\u662f\u4e00\u4e2a\u7528\u4e8e\u836f\u7269\u5148\u5bfc\u5316\u5408\u7269\u4f18\u5316\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u5305\u542b\u751f\u6210\u6a21\u578b\u548c\u667a\u80fdAI\u7cfb\u7edf\uff0c\u901a\u8fc7\u52a8\u6001Q\u5b66\u4e60\u4f18\u5316\u5206\u5b50\u788e\u7247\u5316\u548c\u751f\u6210\uff0c\u5e76\u901a\u8fc7\u5bf9\u8bdd\u53cd\u9988\u5b66\u4e60\u4e13\u5bb6\u77e5\u8bc6\uff0c\u5728\u764c\u75c7\u836f\u7269\u53d1\u73b0\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5206\u5b50\u751f\u6210\u5728\u836f\u7269\u53d1\u73b0\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7c7b\u522b\u7279\u5f02\u6027\u6570\u636e\u96c6\u901a\u5e38\u5c11\u4e8e100\u4e2a\u8bad\u7ec3\u6837\u672c\u3002\u73b0\u6709\u542f\u53d1\u5f0f\u788e\u7247\u5316\u65b9\u6cd5\u9650\u5236\u4e86\u591a\u6837\u6027\u5e76\u9057\u6f0f\u5173\u952e\u7247\u6bb5\uff0c\u4e14\u6a21\u578b\u8c03\u4f18\u9700\u8981\u836f\u7269\u5316\u5b66\u5bb6\u548cAI\u5de5\u7a0b\u5e08\u4e4b\u95f4\u7f13\u6162\u7684\u95f4\u63a5\u534f\u4f5c\u3002", "method": "1) \u65b0\u9896\u7684\u751f\u6210\u6a21\u578b\uff0c\u5c06\u788e\u7247\u5316\u91cd\u65b0\u5b9a\u4e49\u4e3a\"\u8bcd\u6c47\u9009\u62e9\"\u95ee\u9898\uff0c\u4f7f\u7528\u52a8\u6001Q\u5b66\u4e60\u8054\u5408\u4f18\u5316\u788e\u7247\u5316\u548c\u751f\u6210\uff1b2) \u667a\u80fdAI\u7cfb\u7edf\uff0c\u901a\u8fc7\u9886\u57df\u4e13\u5bb6\u7684\u5bf9\u8bdd\u53cd\u9988\u7cbe\u70bc\u76ee\u6807\uff0c\u9010\u6b65\u5b66\u4e60\u9886\u57df\u77e5\u8bc6\u4ee5\u6700\u7ec8\u5b9e\u73b0\u81ea\u52a8\u5316\u8c03\u4f18\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u764c\u75c7\u836f\u7269\u53d1\u73b0\u5b9e\u9a8c\u4e2d\uff0cFRAGMENTA\u7684\u4eba\u7c7b-\u667a\u80fd\u4f53\u914d\u7f6e\u8bc6\u522b\u7684\u9ad8\u5206\u5206\u5b50\u6570\u91cf\u51e0\u4e4e\u662f\u57fa\u7ebf\u7684\u4e24\u500d\u3002\u5b8c\u5168\u81ea\u4e3b\u7684\u667a\u80fd\u4f53-\u667a\u80fd\u4f53\u7cfb\u7edf\u4f18\u4e8e\u4f20\u7edf\u7684\u4eba\u7c7b-\u4eba\u7c7b\u8c03\u4f18\u65b9\u6cd5\u3002", "conclusion": "FRAGMENTA\u5c55\u793a\u4e86\u667a\u80fd\u8c03\u4f18\u5728\u6355\u6349\u4e13\u5bb6\u610f\u56fe\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u79fb\u9664AI\u5de5\u7a0b\u5e08\u7684\u53c2\u4e0e\uff0c\u5e76\u9010\u6b65\u5b66\u4e60\u9886\u57df\u77e5\u8bc6\u5b9e\u73b0\u81ea\u52a8\u5316\u8c03\u4f18\u3002"}}
{"id": "2511.20526", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20526", "abs": "https://arxiv.org/abs/2511.20526", "authors": ["Xinran Wang", "Boran Zhu", "Shujuan Zhou", "Ziwen Long", "Dehua Zhou", "Shu Zhang"], "title": "Assessing LLMs' Performance: Insights from the Chinese Pharmacist Exam", "comment": "15 pages, 4 figures", "summary": "Background: As large language models (LLMs) become increasingly integrated into digital health education and assessment workflows, their capabilities in supporting high-stakes, domain-specific certification tasks remain underexplored.In China, the national pharmacist licensure exam serves as a standardized benchmark for evaluating pharmacists' clinical and theoretical competencies. Objective: This study aimed to compare the performance of two LLMs: ChatGPT-4o and DeepSeek-R1 on real questions from the Chinese Pharmacist Licensing Examination (2017-2021), and to discuss the implications of these performance differences for AI-enabled formative evaluation. Methods: A total of 2,306 multiple-choice (text-only) questions were compiled from official exams, training materials, and public databases. Questions containing tables or images were excluded. Each item was input in its original Chinese format, and model responses were evaluated for exact accuracy. Pearson's Chi-squared test was used to compare overall performance, and Fisher's exact test was applied to year-wise multiple-choice accuracy. Results: DeepSeek-R1 outperformed ChatGPT-4o with a significantly higher overall accuracy (90.0% vs. 76.1%, p < 0.001). Unit-level analyses revealed consistent advantages for DeepSeek-R1, particularly in foundational and clinical synthesis modules. While year-by-year multiple-choice performance also favored DeepSeek-R1, this performance gap did not reach statistical significance in any specific unit-year (all p > 0.05). Conclusion: DeepSeek-R1 demonstrated robust alignment with the structural and semantic demands of the pharmacist licensure exam. These findings suggest that domain-specific models warrant further investigation for this context, while also reinforcing the necessity of human oversight in legally and ethically sensitive contexts.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86ChatGPT-4o\u548cDeepSeek-R1\u5728\u4e2d\u56fd\u836f\u5e08\u6267\u4e1a\u8d44\u683c\u8003\u8bd5\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0DeepSeek-R1\u5728\u6574\u4f53\u51c6\u786e\u7387\u4e0a\u663e\u8457\u4f18\u4e8eChatGPT-4o\uff0890.0% vs 76.1%\uff09\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b57\u5065\u5eb7\u6559\u80b2\u548c\u8bc4\u4f30\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u5728\u652f\u6301\u9ad8\u98ce\u9669\u3001\u9886\u57df\u7279\u5b9a\u8ba4\u8bc1\u4efb\u52a1\u65b9\u9762\u7684\u80fd\u529b\u4ecd\u6709\u5f85\u63a2\u7d22\u3002\u4e2d\u56fd\u836f\u5e08\u6267\u4e1a\u8d44\u683c\u8003\u8bd5\u4e3a\u8bc4\u4f30\u836f\u5e08\u4e34\u5e8a\u548c\u7406\u8bba\u80fd\u529b\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u57fa\u51c6\u3002", "method": "\u6536\u96c62017-2021\u5e74\u5b98\u65b9\u8003\u8bd5\u4e2d\u76842,306\u9053\u7eaf\u6587\u672c\u9009\u62e9\u9898\uff0c\u6392\u9664\u542b\u8868\u683c\u6216\u56fe\u50cf\u7684\u9898\u76ee\u3002\u5c06\u9898\u76ee\u4ee5\u539f\u59cb\u4e2d\u6587\u683c\u5f0f\u8f93\u5165\u6a21\u578b\uff0c\u8bc4\u4f30\u6a21\u578b\u54cd\u5e94\u7684\u51c6\u786e\u7387\uff0c\u4f7f\u7528Pearson\u5361\u65b9\u68c0\u9a8c\u6bd4\u8f83\u6574\u4f53\u8868\u73b0\uff0c\u4f7f\u7528Fisher\u7cbe\u786e\u68c0\u9a8c\u5206\u6790\u5e74\u5ea6\u9009\u62e9\u9898\u51c6\u786e\u7387\u3002", "result": "DeepSeek-R1\u5728\u6574\u4f53\u51c6\u786e\u7387\u4e0a\u663e\u8457\u4f18\u4e8eChatGPT-4o\uff0890.0% vs 76.1%\uff0cp < 0.001\uff09\u3002\u5355\u5143\u7ea7\u5206\u6790\u663e\u793aDeepSeek-R1\u5728\u57fa\u7840\u548c\u4e34\u5e8a\u7efc\u5408\u6a21\u5757\u4e2d\u5177\u6709\u6301\u7eed\u4f18\u52bf\u3002\u867d\u7136\u5e74\u5ea6\u9009\u62e9\u9898\u8868\u73b0\u4e5f\u503e\u5411\u4e8eDeepSeek-R1\uff0c\u4f46\u5728\u4efb\u4f55\u7279\u5b9a\u5355\u5143-\u5e74\u4efd\u4e2d\u8fd9\u79cd\u6027\u80fd\u5dee\u8ddd\u672a\u8fbe\u5230\u7edf\u8ba1\u5b66\u663e\u8457\u6027\u3002", "conclusion": "DeepSeek-R1\u5728\u836f\u5e08\u6267\u4e1a\u8d44\u683c\u8003\u8bd5\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u8981\u6c42\u65b9\u9762\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u5bf9\u9f50\u80fd\u529b\u3002\u8fd9\u4e9b\u53d1\u73b0\u8868\u660e\u9886\u57df\u7279\u5b9a\u6a21\u578b\u5728\u6b64\u80cc\u666f\u4e0b\u503c\u5f97\u8fdb\u4e00\u6b65\u7814\u7a76\uff0c\u540c\u65f6\u4e5f\u5f3a\u8c03\u4e86\u5728\u6cd5\u5f8b\u548c\u4f26\u7406\u654f\u611f\u60c5\u5883\u4e2d\u4eba\u7c7b\u76d1\u7763\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2511.20531", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20531", "abs": "https://arxiv.org/abs/2511.20531", "authors": ["Shamima Hossain"], "title": "Beyond Generation: Multi-Hop Reasoning for Factual Accuracy in Vision-Language Models", "comment": "Accepted as poster at NewInML Workshop ICML, 2025", "summary": "Visual Language Models (VLMs) are powerful generative tools but often produce factually inaccurate outputs due to a lack of robust reasoning capabilities. While extensive research has been conducted on integrating external knowledge for reasoning in large language models (LLMs), such efforts remain underexplored in VLMs, where the challenge is compounded by the need to bridge multiple modalities seamlessly. This work introduces a framework for knowledge-guided reasoning in VLMs, leveraging structured knowledge graphs for multi-hop verification using image-captioning task to illustrate our framework. Our approach enables systematic reasoning across multiple steps, including visual entity recognition, knowledge graph traversal, and fact-based caption refinement. We evaluate the framework using hierarchical, triple-based and bullet-point based knowledge representations, analyzing their effectiveness in factual accuracy and logical inference. Empirical results show that our approach improves factual accuracy by approximately 31% on preliminary experiments on a curated dataset of mixtures from Google Landmarks v2, Conceptual captions and Coco captions revealing key insights into reasoning patterns and failure modes. This work demonstrates the potential of integrating external knowledge for advancing reasoning in VLMs, paving the way for more reliable and knowledgable multimodal systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u8df3\u9a8c\u8bc1\u63d0\u5347\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u5728\u6df7\u5408\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u663e\u793a\u4e8b\u5b9e\u51c6\u786e\u7387\u63d0\u9ad8\u7ea631%\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5f3a\u5927\u4f46\u5e38\u4ea7\u751f\u4e8b\u5b9e\u4e0d\u51c6\u786e\u7684\u8f93\u51fa\uff0c\u7f3a\u4e4f\u7a33\u5065\u7684\u63a8\u7406\u80fd\u529b\uff0c\u800c\u73b0\u6709\u7814\u7a76\u5728\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u96c6\u6210\u5916\u90e8\u77e5\u8bc6\u8fdb\u884c\u63a8\u7406\u7684\u5de5\u4f5c\u4ecd\u4e0d\u8db3\u3002", "method": "\u5229\u7528\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u591a\u8df3\u9a8c\u8bc1\uff0c\u901a\u8fc7\u89c6\u89c9\u5b9e\u4f53\u8bc6\u522b\u3001\u77e5\u8bc6\u56fe\u8c31\u904d\u5386\u548c\u57fa\u4e8e\u4e8b\u5b9e\u7684\u6807\u9898\u7cbe\u70bc\u7b49\u6b65\u9aa4\u5b9e\u73b0\u7cfb\u7edf\u5316\u63a8\u7406\u3002", "result": "\u5728Google Landmarks v2\u3001Conceptual captions\u548cCoco captions\u6df7\u5408\u6570\u636e\u96c6\u4e0a\u7684\u521d\u6b65\u5b9e\u9a8c\u663e\u793a\uff0c\u4e8b\u5b9e\u51c6\u786e\u7387\u63d0\u9ad8\u4e86\u7ea631%\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c55\u793a\u4e86\u96c6\u6210\u5916\u90e8\u77e5\u8bc6\u63d0\u5347\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u6f5c\u529b\uff0c\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u3001\u77e5\u8bc6\u4e30\u5bcc\u7684\u591a\u6a21\u6001\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2511.20586", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20586", "abs": "https://arxiv.org/abs/2511.20586", "authors": ["Koffi Ismael Ouattara", "Ioannis Krontiris", "Theo Dimitrakos", "Dennis Eisermann", "Frank Kargl"], "title": "PaTAS: A Parallel System for Trust Propagation in Neural Networks Using Subjective Logic", "comment": null, "summary": "Trustworthiness has become a key requirement for the deployment of artificial intelligence systems in safety-critical applications. Conventional evaluation metrics such as accuracy and precision fail to capture uncertainty or the reliability of model predictions, particularly under adversarial or degraded conditions. This paper introduces the \\emph{Parallel Trust Assessment System (PaTAS)}, a framework for modeling and propagating trust in neural networks using Subjective Logic (SL). PaTAS operates in parallel with standard neural computation through \\emph{Trust Nodes} and \\emph{Trust Functions} that propagate input, parameter, and activation trust across the network. The framework defines a \\emph{Parameter Trust Update} mechanism to refine parameter reliability during training and an \\emph{Inference-Path Trust Assessment (IPTA)} method to compute instance-specific trust at inference. Experiments on real-world and adversarial datasets demonstrate that PaTAS produces interpretable, symmetric, and convergent trust estimates that complement accuracy and expose reliability gaps in poisoned, biased, or uncertain data scenarios. The results show that PaTAS effectively distinguishes between benign and adversarial inputs and identifies cases where model confidence diverges from actual reliability. By enabling transparent and quantifiable trust reasoning within neural architectures, PaTAS provides a principled foundation for evaluating model reliability across the AI lifecycle.", "AI": {"tldr": "\u63d0\u51fa\u4e86PaTAS\u6846\u67b6\uff0c\u4f7f\u7528\u4e3b\u89c2\u903b\u8f91\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u5efa\u6a21\u548c\u4f20\u64ad\u4fe1\u4efb\uff0c\u901a\u8fc7\u5e76\u884c\u4fe1\u4efb\u8282\u70b9\u548c\u51fd\u6570\u8bc4\u4f30\u8f93\u5165\u3001\u53c2\u6570\u548c\u6fc0\u6d3b\u7684\u53ef\u9760\u6027\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u4fe1\u4efb\u4f30\u8ba1\u3002", "motivation": "\u4f20\u7edf\u8bc4\u4f30\u6307\u6807\u5982\u51c6\u786e\u7387\u548c\u7cbe\u786e\u5ea6\u65e0\u6cd5\u6355\u6349\u6a21\u578b\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u6216\u53ef\u9760\u6027\uff0c\u7279\u522b\u662f\u5728\u5bf9\u6297\u6027\u6216\u9000\u5316\u6761\u4ef6\u4e0b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u91cf\u5316\u8bc4\u4f30\u6a21\u578b\u53ef\u4fe1\u5ea6\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u4e3b\u89c2\u903b\u8f91\uff0c\u901a\u8fc7\u5e76\u884c\u8fd0\u884c\u7684\u4fe1\u4efb\u8282\u70b9\u548c\u4fe1\u4efb\u51fd\u6570\u5728\u7f51\u7edc\u4e2d\u4f20\u64ad\u8f93\u5165\u3001\u53c2\u6570\u548c\u6fc0\u6d3b\u7684\u4fe1\u4efb\u5ea6\u3002\u5b9a\u4e49\u4e86\u53c2\u6570\u4fe1\u4efb\u66f4\u65b0\u673a\u5236\u548c\u63a8\u7406\u8def\u5f84\u4fe1\u4efb\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u548c\u5bf9\u6297\u6027\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPaTAS\u4ea7\u751f\u53ef\u89e3\u91ca\u3001\u5bf9\u79f0\u4e14\u6536\u655b\u7684\u4fe1\u4efb\u4f30\u8ba1\uff0c\u80fd\u6709\u6548\u533a\u5206\u826f\u6027\u8f93\u5165\u548c\u5bf9\u6297\u6027\u8f93\u5165\uff0c\u8bc6\u522b\u6a21\u578b\u7f6e\u4fe1\u5ea6\u4e0e\u5b9e\u9645\u53ef\u9760\u6027\u4e0d\u4e00\u81f4\u7684\u60c5\u51b5\u3002", "conclusion": "PaTAS\u4e3a\u5728\u795e\u7ecf\u67b6\u6784\u4e2d\u5b9e\u73b0\u900f\u660e\u548c\u53ef\u91cf\u5316\u7684\u4fe1\u4efb\u63a8\u7406\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u57fa\u7840\uff0c\u80fd\u591f\u5728\u6574\u4e2aAI\u751f\u547d\u5468\u671f\u4e2d\u8bc4\u4f30\u6a21\u578b\u53ef\u9760\u6027\u3002"}}
{"id": "2511.20610", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20610", "abs": "https://arxiv.org/abs/2511.20610", "authors": ["Gaspard Merten", "Mahmoud Sakr", "Gilles Dejaegere"], "title": "Building a Foundation Model for Trajectory from Scratch", "comment": null, "summary": "Foundation models are transformative in artificial intelligence, but building them from scratch, especially for mobility trajectories, is not yet clear or documented. This tutorial bridges this gap by demonstrating the steps and code of a minimal implementation of a trajectory-focused foundation model starting from GPT-2. Through a concise, step-by-step, code-driven process, we demonstrate adapting GPT-2 for spatiotemporal data. We then review and compare representative trajectory foundation models, such as TrajFM and TrajGPT, highlighting their architectural innovations and differences. Additionally, we introduce complementary techniques from related domains, like TimesFM's patching approach. Targeted at researchers and practitioners, this tutorial aims to explain the concepts and terminology of foundation models, at the implementation level. We find it timely and indispensable to create this educational material in order to support the SIGSPATIAL community in building and evaluating mobility foundation models, enhancing both research clarity and peer-review effectiveness in mobility AI.", "AI": {"tldr": "\u672c\u6559\u7a0b\u5c55\u793a\u4e86\u4eceGPT-2\u5f00\u59cb\u6784\u5efa\u8f68\u8ff9\u57fa\u7840\u6a21\u578b\u7684\u6700\u5c0f\u5b9e\u73b0\u6b65\u9aa4\u548c\u4ee3\u7801\uff0c\u6bd4\u8f83\u4e86TrajFM\u548cTrajGPT\u7b49\u4ee3\u8868\u6027\u6a21\u578b\uff0c\u5e76\u4ecb\u7ecd\u4e86\u76f8\u5173\u9886\u57df\u7684\u6280\u672f\u5982TimesFM\u7684\u5206\u5757\u65b9\u6cd5\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u4eba\u5de5\u667a\u80fd\u4e2d\u5177\u6709\u53d8\u9769\u6027\uff0c\u4f46\u6784\u5efa\u4e13\u95e8\u7528\u4e8e\u79fb\u52a8\u8f68\u8ff9\u7684\u57fa\u7840\u6a21\u578b\u5c1a\u672a\u660e\u786e\u8bb0\u5f55\u3002\u672c\u6559\u7a0b\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u652f\u6301SIGSPATIAL\u793e\u533a\u6784\u5efa\u548c\u8bc4\u4f30\u79fb\u52a8\u6027\u57fa\u7840\u6a21\u578b\u3002", "method": "\u901a\u8fc7\u9010\u6b65\u7684\u4ee3\u7801\u9a71\u52a8\u8fc7\u7a0b\uff0c\u6f14\u793a\u5982\u4f55\u5c06GPT-2\u9002\u914d\u5230\u65f6\u7a7a\u6570\u636e\uff0c\u5e76\u6bd4\u8f83\u4ee3\u8868\u6027\u8f68\u8ff9\u57fa\u7840\u6a21\u578b\u7684\u67b6\u6784\u521b\u65b0\u548c\u5dee\u5f02\u3002", "result": "\u63d0\u4f9b\u4e86\u6784\u5efa\u8f68\u8ff9\u57fa\u7840\u6a21\u578b\u7684\u6559\u80b2\u6750\u6599\uff0c\u589e\u5f3a\u4e86\u79fb\u52a8\u6027AI\u7814\u7a76\u7684\u6e05\u6670\u5ea6\u548c\u540c\u884c\u8bc4\u5ba1\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u521b\u5efa\u8fd9\u79cd\u6559\u80b2\u6750\u6599\u5bf9\u4e8e\u652f\u6301\u793e\u533a\u6784\u5efa\u548c\u8bc4\u4f30\u79fb\u52a8\u6027\u57fa\u7840\u6a21\u578b\u662f\u53ca\u65f6\u4e14\u4e0d\u53ef\u6216\u7f3a\u7684\u3002"}}
{"id": "2511.20623", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20623", "abs": "https://arxiv.org/abs/2511.20623", "authors": ["David Szczecina", "Senan Gaffori", "Edmond Li"], "title": "Copyright Detection in Large Language Models: An Ethical Approach to Generative AI Development", "comment": "4 pages, 3 figures", "summary": "The widespread use of Large Language Models (LLMs) raises critical concerns regarding the unauthorized inclusion of copyrighted content in training data. Existing detection frameworks, such as DE-COP, are computationally intensive, and largely inaccessible to independent creators. As legal scrutiny increases, there is a pressing need for a scalable, transparent, and user-friendly solution. This paper introduce an open-source copyright detection platform that enables content creators to verify whether their work was used in LLM training datasets. Our approach enhances existing methodologies by facilitating ease of use, improving similarity detection, optimizing dataset validation, and reducing computational overhead by 10-30% with efficient API calls. With an intuitive user interface and scalable backend, this framework contributes to increasing transparency in AI development and ethical compliance, facilitating the foundation for further research in responsible AI development and copyright enforcement.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5f00\u6e90\u7248\u6743\u68c0\u6d4b\u5e73\u53f0\uff0c\u5e2e\u52a9\u5185\u5bb9\u521b\u4f5c\u8005\u9a8c\u8bc1\u5176\u4f5c\u54c1\u662f\u5426\u88ab\u7528\u4e8eLLM\u8bad\u7ec3\u6570\u636e\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u964d\u4f4e\u4e8610-30%\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "LLM\u5e7f\u6cdb\u4f7f\u7528\u5f15\u53d1\u7248\u6743\u5185\u5bb9\u672a\u7ecf\u6388\u6743\u7eb3\u5165\u8bad\u7ec3\u6570\u636e\u7684\u62c5\u5fe7\uff0c\u73b0\u6709\u68c0\u6d4b\u6846\u67b6\u8ba1\u7b97\u5bc6\u96c6\u4e14\u4e0d\u6613\u8bbf\u95ee\uff0c\u9700\u8981\u53ef\u6269\u5c55\u3001\u900f\u660e\u3001\u7528\u6237\u53cb\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u4f18\u5316API\u8c03\u7528\u63d0\u9ad8\u6548\u7387\uff0c\u6539\u8fdb\u76f8\u4f3c\u6027\u68c0\u6d4b\uff0c\u4f18\u5316\u6570\u636e\u96c6\u9a8c\u8bc1\uff0c\u63d0\u4f9b\u76f4\u89c2\u7528\u6237\u754c\u9762\u548c\u53ef\u6269\u5c55\u540e\u7aef\u3002", "result": "\u5b9e\u73b0\u4e86\u8ba1\u7b97\u5f00\u9500\u964d\u4f4e10-30%\uff0c\u63d0\u9ad8\u4e86\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u7528\u6237\u4f53\u9a8c\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u52a9\u4e8e\u63d0\u9ad8AI\u5f00\u53d1\u7684\u900f\u660e\u5ea6\u548c\u4f26\u7406\u5408\u89c4\u6027\uff0c\u4e3a\u8d1f\u8d23\u4efbAI\u5f00\u53d1\u548c\u7248\u6743\u6267\u6cd5\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.20627", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20627", "abs": "https://arxiv.org/abs/2511.20627", "authors": ["Anastasia Mavridou", "Divya Gopinath", "Corina S. P\u0103s\u0103reanu"], "title": "Fighting AI with AI: Leveraging Foundation Models for Assuring AI-Enabled Safety-Critical Systems", "comment": null, "summary": "The integration of AI components, particularly Deep Neural Networks (DNNs), into safety-critical systems such as aerospace and autonomous vehicles presents fundamental challenges for assurance. The opacity of AI systems, combined with the semantic gap between high-level requirements and low-level network representations, creates barriers to traditional verification approaches. These AI-specific challenges are amplified by longstanding issues in Requirements Engineering, including ambiguity in natural language specifications and scalability bottlenecks in formalization. We propose an approach that leverages AI itself to address these challenges through two complementary components. REACT (Requirements Engineering with AI for Consistency and Testing) employs Large Language Models (LLMs) to bridge the gap between informal natural language requirements and formal specifications, enabling early verification and validation. SemaLens (Semantic Analysis of Visual Perception using large Multi-modal models) utilizes Vision Language Models (VLMs) to reason about, test, and monitor DNN-based perception systems using human-understandable concepts. Together, these components provide a comprehensive pipeline from informal requirements to validated implementations.", "AI": {"tldr": "\u63d0\u51faREACT\u548cSemaLens\u4e24\u4e2a\u4e92\u8865\u7ec4\u4ef6\uff0c\u5229\u7528AI\u6280\u672f\u89e3\u51b3\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2dAI\u7ec4\u4ef6\u96c6\u6210\u7684\u9a8c\u8bc1\u6311\u6218\uff0c\u6784\u5efa\u4ece\u975e\u6b63\u5f0f\u9700\u6c42\u5230\u9a8c\u8bc1\u5b9e\u73b0\u7684\u5b8c\u6574\u6d41\u7a0b\u3002", "motivation": "AI\u7ec4\u4ef6\uff08\u7279\u522b\u662fDNN\uff09\u5728\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u7684\u96c6\u6210\u9762\u4e34\u9a8c\u8bc1\u6311\u6218\uff0c\u5305\u62ecAI\u7cfb\u7edf\u4e0d\u900f\u660e\u6027\u3001\u9ad8\u5c42\u9700\u6c42\u4e0e\u4f4e\u5c42\u7f51\u7edc\u8868\u793a\u4e4b\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\uff0c\u4ee5\u53ca\u9700\u6c42\u5de5\u7a0b\u4e2d\u957f\u671f\u5b58\u5728\u7684\u6a21\u7cca\u6027\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "REACT\u4f7f\u7528LLM\u8fde\u63a5\u975e\u6b63\u5f0f\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u4e0e\u5f62\u5f0f\u5316\u89c4\u8303\uff0c\u5b9e\u73b0\u65e9\u671f\u9a8c\u8bc1\uff1bSemaLens\u5229\u7528VLM\u57fa\u4e8e\u4eba\u7c7b\u53ef\u7406\u89e3\u6982\u5ff5\u5bf9DNN\u611f\u77e5\u7cfb\u7edf\u8fdb\u884c\u63a8\u7406\u3001\u6d4b\u8bd5\u548c\u76d1\u63a7\u3002", "result": "\u6784\u5efa\u4e86\u4ece\u975e\u6b63\u5f0f\u9700\u6c42\u5230\u9a8c\u8bc1\u5b9e\u73b0\u7684\u5b8c\u6574\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u89e3\u51b3\u4e86AI\u7cfb\u7edf\u9a8c\u8bc1\u4e2d\u7684\u8bed\u4e49\u9e3f\u6c9f\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7AI\u6280\u672f\u81ea\u8eab\u6765\u89e3\u51b3AI\u7cfb\u7edf\u9a8c\u8bc1\u6311\u6218\u662f\u53ef\u884c\u7684\uff0cREACT\u548cSemaLens\u63d0\u4f9b\u4e86\u4ece\u9700\u6c42\u5230\u5b9e\u73b0\u7684\u7aef\u5230\u7aef\u9a8c\u8bc1\u89e3\u51b3\u65b9\u6848\u3002"}}
