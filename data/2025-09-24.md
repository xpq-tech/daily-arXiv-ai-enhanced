<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 60]
- [cs.AI](#cs.AI) [Total: 48]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Dynamic Prompt Fusion for Multi-Task and Cross-Domain Adaptation in LLMs](https://arxiv.org/abs/2509.18113)
*Xin Hu,Yue Kang,Guanzi Yao,Tianze Kang,Mengjie Wang,Heyao Liu*

Main category: cs.CL

TL;DR: 本文提出了一种动态提示调度的统一多任务学习框架，通过提示池和任务感知调度策略来增强模型在多任务和跨域设置下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在多任务和跨域设置下泛化能力有限的问题，传统方法如SPoT依赖固定提示模板，无法有效捕捉任务间的语义差异。

Method: 引入提示池和任务感知调度策略，动态组合和对齐不同任务的提示；使用任务嵌入和门控机制精细控制提示信号；采用联合多任务学习优化目标，包含调度权重的自动学习策略。

Result: 敏感性实验验证了该方法在模型稳定性和可迁移性方面的优势；在语言理解和知识推理任务上显著提升性能。

Conclusion: 该方法在统一多任务建模和跨域适应方面具有很好的适用性和有效性。

Abstract: This study addresses the generalization limitations commonly observed in
large language models under multi-task and cross-domain settings. Unlike prior
methods such as SPoT, which depends on fixed prompt templates, our study
introduces a unified multi-task learning framework with dynamic prompt
scheduling mechanism. By introducing a prompt pool and a task-aware scheduling
strategy, the method dynamically combines and aligns prompts for different
tasks. This enhances the model's ability to capture semantic differences across
tasks. During prompt fusion, the model uses task embeddings and a gating
mechanism to finely control the prompt signals. This ensures alignment between
prompt content and task-specific demands. At the same time, it builds flexible
sharing pathways across tasks. In addition, the proposed optimization objective
centers on joint multi-task learning. It incorporates an automatic learning
strategy for scheduling weights, which effectively mitigates task interference
and negative transfer. To evaluate the effectiveness of the method, a series of
sensitivity experiments were conducted. These experiments examined the impact
of prompt temperature parameters and task number variation. The results confirm
the advantages of the proposed mechanism in maintaining model stability and
enhancing transferability. Experimental findings show that the prompt
scheduling method significantly improves performance on a range of language
understanding and knowledge reasoning tasks. These results fully demonstrate
its applicability and effectiveness in unified multi-task modeling and
cross-domain adaptation.

</details>


### [2] [GAUSS: Benchmarking Structured Mathematical Skills for Large Language Models](https://arxiv.org/abs/2509.18122)
*Yue Zhang,Jiaxin Zhang,Qiuyu Ren,Tahsin Saffat,Xiaoxuan Liu,Zitong Yang,Banghua Zhu,Yi Ma*

Main category: cs.CL

TL;DR: GAUSS是一个评估LLM数学能力的基准，涵盖12个核心技能维度，分为三个领域：知识与理解、问题解决与沟通、元技能与创造力。通过按认知技能分类问题和设计隔离特定能力的任务，GAUSS构建了全面、细粒度且可解释的模型数学能力画像。


<details>
  <summary>Details</summary>
Motivation: 当前LLM数学评估方法往往过于笼统，缺乏对具体认知技能的细粒度分析。GAUSS旨在通过技能维度的分类，更准确地评估和解释模型的数学智能。

Method: 将数学问题按12个核心技能维度分类，设计能够隔离特定认知能力的任务，构建综合评估框架。通过分析GPT-5-thinking等模型，展示基准的应用价值。

Result: GAUSS能够生成详细的模型数学能力画像，准确反映其数学智能的强项和弱点。通过比较GPT-5-thinking和o4-mini-high，展示了多维技能评估的价值。

Conclusion: GAUSS基准提供了一种更全面、可解释的LLM数学能力评估方法，有助于深入理解模型的数学智能结构，为模型改进提供具体指导。

Abstract: We introduce \textbf{GAUSS} (\textbf{G}eneral \textbf{A}ssessment of
\textbf{U}nderlying \textbf{S}tructured \textbf{S}kills in Mathematics), a
benchmark that evaluates LLMs' mathematical abilities across twelve core skill
dimensions, grouped into three domains: knowledge and understanding, problem
solving and communication, and meta-skills and creativity. By categorizing
problems according to cognitive skills and designing tasks that isolate
specific abilities, GAUSS constructs comprehensive, fine-grained, and
interpretable profiles of models' mathematical abilities. These profiles
faithfully represent their underlying mathematical intelligence. To exemplify
how to use the \textsc{GAUSS} benchmark, we have derived the skill profile of
\textsc{GPT-5-thinking}, revealing its strengths and weaknesses as well as its
differences relative to \textsc{o4-mini-high}, thereby underscoring the value
of multidimensional, skill-based evaluation.

</details>


### [3] [Event Causality Identification with Synthetic Control](https://arxiv.org/abs/2509.18156)
*Haoyu Wang,Fengze Liu,Jiayao Zhang,Dan Roth,Kyle Richardson*

Main category: cs.CL

TL;DR: 本文提出了一种基于Rubin因果模型的事件因果关系识别方法，通过将第一个事件视为治疗、第二个事件视为结果，利用合成控制方法生成虚拟双胞胎来估计因果效应，在COPES-hard基准测试中表现优于包括GPT-4在内的传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统的事件因果关系识别方法主要依赖语言模式和多跳关系推理，容易因因果关系的非正式使用和虚假的图推理而产生错误识别。需要更稳健的方法来区分因果关系和相关关系。

Method: 采用Rubin因果模型框架，将时间上先发生的事件视为治疗，后发生的事件视为结果。使用合成控制方法从相关历史数据中生成虚拟双胞胎，通过文本嵌入合成和反演技术来估计治疗对结果的影响。

Result: 该方法在COPES-hard因果基准测试中表现出色，识别因果关系的效果优于包括GPT-4在内的现有方法，证明了其稳健性和有效性。

Conclusion: 基于Rubin因果模型的合成控制方法为事件因果关系识别提供了更可靠的解决方案，能够有效避免传统方法中的虚假因果关系识别问题，在复杂文本场景下具有更好的表现。

Abstract: Event causality identification (ECI), a process that extracts causal
relations between events from text, is crucial for distinguishing causation
from correlation. Traditional approaches to ECI have primarily utilized
linguistic patterns and multi-hop relational inference, risking false causality
identification due to informal usage of causality and specious graphical
inference. In this paper, we adopt the Rubin Causal Model to identify event
causality: given two temporally ordered events, we see the first event as the
treatment and the second one as the observed outcome. Determining their
causality involves manipulating the treatment and estimating the resultant
change in the likelihood of the outcome. Given that it is only possible to
implement manipulation conceptually in the text domain, as a work-around, we
try to find a twin for the protagonist from existing corpora. This twin should
have identical life experiences with the protagonist before the treatment but
undergoes an intervention of treatment. However, the practical difficulty of
locating such a match limits its feasibility. Addressing this issue, we use the
synthetic control method to generate such a twin' from relevant historical
data, leveraging text embedding synthesis and inversion techniques. This
approach allows us to identify causal relations more robustly than previous
methods, including GPT-4, which is demonstrated on a causality benchmark,
COPES-hard.

</details>


### [4] [ZERA: Zero-init Instruction Evolving Refinement Agent - From Zero Instructions to Structured Prompts via Principle-based Optimization](https://arxiv.org/abs/2509.18158)
*Seungyoun Yi,Minsoo Khang,Sungrae Park*

Main category: cs.CL

TL;DR: ZERA是一个新颖的自动提示优化框架，通过联合优化系统提示和用户提示，使用结构化评分标准和低开销的迭代方法，实现了快速收敛到高质量提示。


<details>
  <summary>Details</summary>
Motivation: 现有的自动提示优化方法通常只关注用户提示，依赖非结构化反馈，需要大量样本和长迭代周期，导致成本高且脆弱。

Method: ZERA使用八个可泛化的评分标准对提示进行结构化评分，并根据这些结构化批评来修订提示，实现快速收敛。

Result: 在五个LLM和九个多样化数据集上的实验结果表明，ZERA相比强基线方法取得了持续改进。消融研究验证了各组件对提示构建的有效贡献。

Conclusion: ZERA框架通过结构化评分和低开销迭代，能够高效地优化提示，提升LLM性能，且代码实现已开源。

Abstract: Automatic Prompt Optimization (APO) improves large language model (LLM)
performance by refining prompts for specific tasks. However, prior APO methods
typically focus only on user prompts, rely on unstructured feedback, and
require large sample sizes and long iteration cycles-making them costly and
brittle. We propose ZERA (Zero-init Instruction Evolving Refinement Agent), a
novel framework that jointly optimizes both system and user prompts through
principled, low-overhead refinement. ZERA scores prompts using eight
generalizable criteria with automatically inferred weights, and revises prompts
based on these structured critiques. This enables fast convergence to
high-quality prompts using minimal examples and short iteration cycles. We
evaluate ZERA across five LLMs and nine diverse datasets spanning reasoning,
summarization, and code generation tasks. Experimental results demonstrate
consistent improvements over strong baselines. Further ablation studies
highlight the contribution of each component to more effective prompt
construction. Our implementation including all prompts is publicly available at
https://github.com/younatics/zera-agent.

</details>


### [5] [Thinking in a Crowd: How Auxiliary Information Shapes LLM Reasoning](https://arxiv.org/abs/2509.18163)
*Haodong Zhao,Chenyan Zhao,Yansi Li,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.CL

TL;DR: 该论文研究了外部信息对具有逐步推理能力的大语言模型的影响，发现模型的思考过程是一把双刃剑：有帮助的信息能提升准确性，但误导性信息会导致性能灾难性下降，且思考过程会放大错误。


<details>
  <summary>Details</summary>
Motivation: 研究在现实场景中，大语言模型经常需要处理外部信息（有帮助的、无关的或误导性的），需要了解这些辅助信息对模型推理过程的因果影响。

Method: 引入SciAux数据集（基于ScienceQA），系统测试模型对不同类型信息的鲁棒性，分析模型在逐步思考过程中的表现。

Result: 发现模型的思考模式存在关键脆弱性：有帮助的上下文能提高准确性，但误导性信息会导致性能急剧下降，且思考过程会强化错误程度。

Conclusion: 挑战不仅在于让模型"思考"，更重要的是赋予它们评估推理所依赖信息的关键能力。

Abstract: The capacity of Large Language Models (LLMs) to reason is fundamental to
their application in complex, knowledge-intensive domains. In real-world
scenarios, LLMs are often augmented with external information that can be
helpful, irrelevant, or even misleading. This paper investigates the causal
impact of such auxiliary information on the reasoning process of LLMs with
explicit step-by-step thinking capabilities. We introduce SciAux, a new dataset
derived from ScienceQA, to systematically test the robustness of the model
against these types of information. Our findings reveal a critical
vulnerability: the model's deliberative "thinking mode" is a double-edged
sword. While helpful context improves accuracy, misleading information causes a
catastrophic drop in performance, which is amplified by the thinking process.
Instead of conferring robustness, thinking reinforces the degree of error when
provided with misinformation. This highlights that the challenge is not merely
to make models "think", but to endow them with the critical faculty to evaluate
the information upon which their reasoning is based. The SciAux dataset is
available at https://huggingface.co/datasets/billhdzhao/SciAux.

</details>


### [6] [SIRAG: Towards Stable and Interpretable RAG with A Process-Supervised Multi-Agent Framework](https://arxiv.org/abs/2509.18167)
*Junlin Wang,Zehao Wu,Shaowei Lu,Yanlan Li,Xinghao Huang*

Main category: cs.CL

TL;DR: 提出了一种过程监督的多智能体框架来优化检索增强生成（RAG）系统中检索器和生成器之间的协调问题，通过决策制定器和知识选择器两个轻量级智能体，结合过程级奖励和树状探索策略，提升问答任务的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统中检索器和生成器独立开发导致交互不理想，检索器可能返回不相关或冗余文档，生成器未能充分利用检索到的证据，需要更好的协调机制。

Method: 采用过程监督的多智能体框架，包含决策制定器（决定继续检索或生成答案）和知识选择器（过滤检索文档）。使用LLM作为评判员提供过程级奖励，采用树状探索策略和PPO算法进行端到端训练。

Result: 在单跳和多跳问答基准测试中，该方法相比标准RAG基线实现了更高的准确性、更稳定的收敛性，并产生了更可解释的推理轨迹。

Conclusion: 该框架具有模块化和即插即用特性，无需修改检索器或生成器，适用于实际RAG应用，有效解决了检索器与生成器之间的协调问题。

Abstract: Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to
access external knowledge sources, but the effectiveness of RAG relies on the
coordination between the retriever and the generator. Since these components
are developed independently, their interaction is often suboptimal: the
retriever may return irrelevant or redundant documents, while the generator may
fail to fully leverage retrieved evidence. In this work, we propose a
process-supervised multi-agent framework to bridge the gap between retriever
and generator. The framework introduces two lightweight agents: a Decision
Maker, which determines when to continue retrieval or stop for answer
generation, and a Knowledge Selector, which filters retrieved documents to
retain only the most useful evidence. To provide fine-grained supervision, we
employ an LLM-as-a-Judge that evaluates each intermediate action with
process-level rewards, ensuring more accurate credit assignment than relying
solely on final answer correctness. We further adopt a tree-structured rollout
strategy to explore diverse reasoning paths, and train both agents with
Proximal Policy Optimization (PPO) in an end-to-end manner. Experiments on
single-hop and multi-hop question answering benchmarks show that our approach
achieves higher accuracy, more stable convergence, and produces more
interpretable reasoning trajectories compared with standard RAG baselines.
Importantly, the proposed framework is modular and plug-and-play, requiring no
modification to the retriever or generator, making it practical for real-world
RAG applications.

</details>


### [7] [ERFC: Happy Customers with Emotion Recognition and Forecasting in Conversation in Call Centers](https://arxiv.org/abs/2509.18175)
*Aditi Debsharma,Bhushan Jagyasi,Surajit Sen,Priyanka Pandey,Devicharith Dovari,Yuvaraj V. C,Rosalin Parida,Gopali Contractor*

Main category: cs.CL

TL;DR: 提出了一种新颖的ERFC架构，用于对话中的情感识别和未来情感预测，特别适用于呼叫中心等场景


<details>
  <summary>Details</summary>
Motivation: 在呼叫中心等对话场景中，准确识别和预测对话者的情感对于提升客户体验至关重要，特别是通过预测未来话语的情感来帮助客服人员及时调整策略

Method: ERFC架构考虑多模态、情感的不同属性、上下文以及对话中话语之间的相互依赖关系

Result: 在IEMOCAP数据集上的实验证明了ERFC方法的可行性

Conclusion: 该方法在呼叫中心等客户满意度至关重要的应用中具有巨大的商业价值

Abstract: Emotion Recognition in Conversation has been seen to be widely applicable in
call center analytics, opinion mining, finance, retail, healthcare, and other
industries. In a call center scenario, the role of the call center agent is not
just confined to receiving calls but to also provide good customer experience
by pacifying the frustration or anger of the customers. This can be achieved by
maintaining neutral and positive emotion from the agent. As in any
conversation, the emotion of one speaker is usually dependent on the emotion of
other speaker. Hence the positive emotion of an agent, accompanied with the
right resolution will help in enhancing customer experience. This can change an
unhappy customer to a happy one. Imparting the right resolution at right time
becomes easier if the agent has the insight of the emotion of future
utterances. To predict the emotions of the future utterances we propose a novel
architecture, Emotion Recognition and Forecasting in Conversation. Our proposed
ERFC architecture considers multi modalities, different attributes of emotion,
context and the interdependencies of the utterances of the speakers in the
conversation. Our intensive experiments on the IEMOCAP dataset have shown the
feasibility of the proposed ERFC. This approach can provide a tremendous
business value for the applications like call center, where the happiness of
customer is utmost important.

</details>


### [8] [Evaluating Large Language Models for Detecting Antisemitism](https://arxiv.org/abs/2509.18293)
*Jay Patel,Hrudayangam Mehta,Jeremy Blackburn*

Main category: cs.CL

TL;DR: 本文评估了8个开源LLM检测反犹内容的能力，提出了一种新的Guided-CoT提示方法，该方法显著提升了模型性能，并分析了LLM在仇恨内容检测中的差异和局限性。


<details>
  <summary>Details</summary>
Motivation: 仇恨内容检测是一个重要但具有挑战性的问题，需要自动化工具来适应社交媒体内容的不断变化。本研究旨在评估开源LLM在检测反犹内容方面的能力。

Method: 使用上下文定义作为政策指南，探索多种提示技术，设计新的Guided-CoT提示方法，评估不同模型大小、解码配置和推理能力的LLM性能。

Result: Guided-CoT方法显著提升了所有评估模型的性能，Llama 3.1 70B甚至超越了微调的GPT-3.5。研究还揭示了LLM在语义分歧和矛盾行为方面的差异。

Conclusion: 实验突出了LLM在实用性、可解释性和可靠性方面的差异，Guided-CoT方法有效处理了上下文政策，为仇恨内容检测提供了有价值的见解。

Abstract: Detecting hateful content is a challenging and important problem. Automated
tools, like machine-learning models, can help, but they require continuous
training to adapt to the ever-changing landscape of social media. In this work,
we evaluate eight open-source LLMs' capability to detect antisemitic content,
specifically leveraging in-context definition as a policy guideline. We explore
various prompting techniques and design a new CoT-like prompt, Guided-CoT.
Guided-CoT handles the in-context policy well, increasing performance across
all evaluated models, regardless of decoding configuration, model sizes, or
reasoning capability. Notably, Llama 3.1 70B outperforms fine-tuned GPT-3.5.
Additionally, we examine LLM errors and introduce metrics to quantify semantic
divergence in model-generated rationales, revealing notable differences and
paradoxical behaviors among LLMs. Our experiments highlight the differences
observed across LLMs' utility, explainability, and reliability.

</details>


### [9] [Exploiting Tree Structure for Credit Assignment in RL Training of LLMs](https://arxiv.org/abs/2509.18314)
*Hieu Tran,Zonghai Yao,Hong Yu*

Main category: cs.CL

TL;DR: TEMPO是一种无评论家的强化学习算法，通过前缀树结构进行token级信用分配，在数学和医疗QA任务上优于PPO和GRPO


<details>
  <summary>Details</summary>
Motivation: 解决长序列推理任务中稀疏延迟奖励的token级信用分配问题，特别是在可验证奖励设置下（最终答案可检查且每个提示可生成多个响应）

Method: 提出Prefix-to-Tree（P2T）方法将响应组转换为前缀树，计算非参数前缀值。基于P2T开发TEMPO算法，结合GRPO的组相对结果信号和分支门控的时序差分修正

Result: 在Qwen3-1.7B/4B模型上，TEMPO在分布内（MATH、MedQA）和分布外（GSM-HARD、AMC23等）基准测试中均优于PPO和GRPO，验证准确率更高且训练时间相近

Conclusion: TEMPO提供了一种简单有效的token级信用分配方法，无需学习价值网络或额外评判器，在推理任务中表现出优越性能

Abstract: Reinforcement learning improves LLM reasoning, yet sparse delayed reward over
long sequences makes token-level credit assignment the key bottleneck. We study
the verifiable-reward setting, where the final answer is checkable and multiple
responses can be drawn per prompt. Reasoning tasks in math and medical QA align
with this setup, where only a few decision tokens significantly impact the
outcome. PPO offers token-level advantages with a learned value model, but it
is complex to train both the actor and critic models simultaneously, and it is
not easily generalizable, as the token-level values from the critic model can
make training prone to overfitting. GRPO is critic-free and supports verifiable
rewards, but spreads a single sequence-level return across tokens and ignores
branching. We introduce \textbf{Prefix-to-Tree (P2T)}, a simple procedure that
converts a group of responses into a prefix tree and computes
\emph{nonparametric} prefix values \(V(s)\) by aggregating descendant outcomes.
Built on P2T, we propose \textbf{TEMPO} (\emph{\textbf{T}ree-\textbf{E}stimated
\textbf{M}ean Prefix Value for \textbf{P}olicy \textbf{O}ptimization}), a
critic-free algorithm that augments the group-relative outcome signal of GRPO
with \emph{branch-gated} temporal-difference corrections derived from the tree.
At non-branch tokens, the temporal-difference (TD) term is zero, so TEMPO
reduces to GRPO; at branching tokens, it supplies precise token-level credit
without a learned value network or extra judges/teachers. On Qwen3-1.7B/4B,
TEMPO outperforms PPO and GRPO on in-distribution (MATH, MedQA) and
out-of-distribution (GSM-HARD, AMC23, MedMCQA, MMLU-Medical) benchmarks, and
reaches higher validation accuracy with roughly the same wall-clock time.

</details>


### [10] [Brittleness and Promise: Knowledge Graph Based Reward Modeling for Diagnostic Reasoning](https://arxiv.org/abs/2509.18316)
*Saksham Khatwani,He Cheng,Majid Afshar,Dmitriy Dligach,Yanjun Gao*

Main category: cs.CL

TL;DR: 该论文探索了一种新范式：将大型语言模型（LLM）作为知识图谱（KG）推理路径的奖励模型，通过训练模型判断候选路径是否能正确诊断患者输入，而不是直接将KG内容插入提示中。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常通过检索增强生成或微调将知识图谱集成到LLM中，但缺乏结构化推理能力。受计算理论启发（验证解决方案通常比从头生成更容易）和医生诊断评估过程的启发，研究探索了基于奖励的监督方法。

Method: 系统评估了五种知识路径判断任务制定方法和八种训练范式，测试路径判断能力是否能泛化到下游诊断任务（如诊断总结和医学问答）。使用三个开源指令调优的LLM进行实验。

Result: 实验显示特定奖励优化和蒸馏能带来强大的路径判断性能，但向下游任务的迁移性仍然较弱，表现出既有希望又脆弱的特点。

Conclusion: 这是对临床知识图谱进行"奖励模型风格"推理的首次系统评估，为基于结构的奖励监督如何影响医疗GenAI系统中的诊断推理提供了见解。

Abstract: Large language models (LLMs) show promise for diagnostic reasoning but often
lack reliable, knowledge grounded inference. Knowledge graphs (KGs), such as
the Unified Medical Language System (UMLS), offer structured biomedical
knowledge that can support trustworthy reasoning. Prior approaches typically
integrate KGs via retrieval augmented generation or fine tuning, inserting KG
content into prompts rather than enabling structured reasoning. We explore an
alternative paradigm: treating the LLM as a reward model of KG reasoning paths,
where the model learns to judge whether a candidate path leads to correct
diagnosis for a given patient input. This approach is inspired by recent work
that leverages reward training to enhance model reasoning abilities, and
grounded in computational theory, which suggests that verifying a solution is
often easier than generating one from scratch. It also parallels physicians'
diagnostic assessment, where they judge which sequences of findings and
intermediate conditions most plausibly support a diagnosis. We first
systematically evaluate five task formulation for knowledge path judging and
eight training paradigm. Second, we test whether the path judging abilities
generalize to downstream diagnostic tasks, including diagnosis summarization
and medical question answering. Experiments with three open source
instruct-tuned LLMs reveal both promise and brittleness: while specific reward
optimization and distillation lead to strong path-judging performance, the
transferability to downstream tasks remain weak. Our finding provides the first
systematic assessment of "reward model style" reasoning over clinical KGs,
offering insights into how structured, reward-based supervision influences
diagnostic reasoning in GenAI systems for healthcare.

</details>


### [11] [Speculate Deep and Accurate: Lossless and Training-Free Acceleration for Offloaded LLMs via Substitute Speculative Decoding](https://arxiv.org/abs/2509.18344)
*Pei-Shuo Wang,Jian-Jia Chen,Chun-Che Yang,Chi-Chih Chang,Ning-Chi Huang,Mohamed S. Abdelfattah,Kai-Chiang Wu*

Main category: cs.CL

TL;DR: SubSpec是一种即插即用的无损加速方法，通过从卸载的目标LLM部分生成低比特量化替代层来构建高度对齐的草稿模型，实现参数卸载加速。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在内存受限的消费级GPU上部署的挑战，现有方法存在质量下降或推理速度慢的问题，需要一种既能保持质量又能加速推理的解决方案。

Method: 使用低比特量化替代层构建草稿模型，共享GPU驻留层和KV-Cache，无需额外训练即可实现高度对齐。

Result: 在MT-Bench上对Qwen2.5 7B实现9.1倍加速（8GB VRAM限制），在流行生成基准测试中对Qwen2.5 32B平均实现12.5倍加速（24GB VRAM限制）。

Conclusion: SubSpec提供了一种有效的方法来加速参数卸载，实现了高平均接受长度和显著的速度提升，同时保持无损推理。

Abstract: The immense model sizes of large language models (LLMs) challenge deployment
on memory-limited consumer GPUs. Although model compression and parameter
offloading are common strategies to address memory limitations, compression can
degrade quality, and offloading maintains quality but suffers from slow
inference. Speculative decoding presents a promising avenue to accelerate
parameter offloading, utilizing a fast draft model to propose multiple draft
tokens, which are then verified by the target LLM in parallel with a single
forward pass. This method reduces the time-consuming data transfers in forward
passes that involve offloaded weight transfers. Existing methods often rely on
pretrained weights of the same family, but require additional training to align
with custom-trained models. Moreover, approaches that involve draft model
training usually yield only modest speedups. This limitation arises from
insufficient alignment with the target model, preventing higher token
acceptance lengths. To address these challenges and achieve greater speedups,
we propose SubSpec, a plug-and-play method to accelerate parameter offloading
that is lossless and training-free. SubSpec constructs a highly aligned draft
model by generating low-bit quantized substitute layers from offloaded target
LLM portions. Additionally, our method shares the remaining GPU-resident layers
and the KV-Cache, further reducing memory overhead and enhance alignment.
SubSpec achieves a high average acceptance length, delivering 9.1x speedup for
Qwen2.5 7B on MT-Bench (8GB VRAM limit) and an average of 12.5x speedup for
Qwen2.5 32B on popular generation benchmarks (24GB VRAM limit).

</details>


### [12] [Speech Vecalign: an Embedding-based Method for Aligning Parallel Speech Documents](https://arxiv.org/abs/2509.18360)
*Chutong Meng,Philipp Koehn*

Main category: cs.CL

TL;DR: Speech Vecalign是一种不依赖文本转录的平行语音文档对齐方法，通过单调对齐语音片段嵌入，相比基线方法能产生更长的语音对齐且噪声更少。


<details>
  <summary>Details</summary>
Motivation: 现有的语音挖掘方法（如Global Mining和Local Mining）在对齐平行语音文档时存在对齐长度较短或噪声较多的问题，需要一种更鲁棒的对齐方法。

Method: 提出Speech Vecalign方法，基于语音片段嵌入的单调对齐，不依赖文本转录，直接处理原始语音数据。

Result: 在3000小时未标注的英德平行语音数据上应用，获得约1000小时高质量对齐。训练的语言翻译模型相比Global Mining在En-to-De和De-to-En任务上分别提升0.37和0.18 ASR-BLEU，且使用8倍少的原始语音数据就能达到或超过SpeechMatrix模型性能。

Conclusion: Speech Vecalign是一种有效的语音文档对齐方法，能显著提升语音翻译性能，同时减少对原始数据量的依赖。

Abstract: We present Speech Vecalign, a parallel speech document alignment method that
monotonically aligns speech segment embeddings and does not depend on text
transcriptions. Compared to the baseline method Global Mining, a variant of
speech mining, Speech Vecalign produces longer speech-to-speech alignments. It
also demonstrates greater robustness than Local Mining, another speech mining
variant, as it produces less noise. We applied Speech Vecalign to 3,000 hours
of unlabeled parallel English-German (En-De) speech documents from VoxPopuli,
yielding about 1,000 hours of high-quality alignments. We then trained En-De
speech-to-speech translation models on the aligned data. Speech Vecalign
improves the En-to-De and De-to-En performance over Global Mining by 0.37 and
0.18 ASR-BLEU, respectively. Moreover, our models match or outperform
SpeechMatrix model performance, despite using 8 times fewer raw speech
documents.

</details>


### [13] [Interactive Real-Time Speaker Diarization Correction with Human Feedback](https://arxiv.org/abs/2509.18377)
*Xinlu He,Yiwen Guan,Badrivishal Paurana,Zilin Dai,Jacob Whitehill*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Most automatic speech processing systems operate in "open loop" mode without
user feedback about who said what; yet, human-in-the-loop workflows can
potentially enable higher accuracy. We propose an LLM-assisted speaker
diarization correction system that lets users fix speaker attribution errors in
real time. The pipeline performs streaming ASR and diarization, uses an LLM to
deliver concise summaries to the users, and accepts brief verbal feedback that
is immediately incorporated without disrupting interactions. Moreover, we
develop techniques to make the workflow more effective: First, a
split-when-merged (SWM) technique detects and splits multi-speaker segments
that the ASR erroneously attributes to just a single speaker. Second, online
speaker enrollments are collected based on users' diarization corrections, thus
helping to prevent speaker diarization errors from occurring in the future.
LLM-driven simulations on the AMI test set indicate that our system
substantially reduces DER by 9.92% and speaker confusion error by 44.23%. We
further analyze correction efficacy under different settings, including summary
vs full transcript display, the number of online enrollments limitation, and
correction frequency.

</details>


### [14] [NormGenesis: Multicultural Dialogue Generation via Exemplar-Guided Social Norm Modeling and Violation Recovery](https://arxiv.org/abs/2509.18395)
*Minki Hong,Jangho Choi,Jihie Kim*

Main category: cs.CL

TL;DR: NormGenesis是一个多文化对话生成框架，通过Violation-to-Resolution对话类型建模规范违反后的对话修复过程，提升跨语言对话系统的社会规范适应性。


<details>
  <summary>Details</summary>
Motivation: 社会规范对于对话系统生成既连贯又社会可接受的回应至关重要，现有方法缺乏对规范违反后对话动态的建模能力。

Method: 提出Violation-to-Resolution对话类型，采用基于范例的迭代精炼方法，在对话合成早期引入语言、情感和社会文化对齐。构建包含10,800个多轮对话的数据集。

Result: 人类和LLM评估显示NormGenesis在精炼质量、对话自然度和泛化性能上显著优于现有数据集，训练模型在伦理敏感情境中表现出更好的语用能力。

Conclusion: 该工作为文化自适应对话建模建立了新基准，提供了跨语言文化多样化语言的规范感知生成的可扩展方法。

Abstract: Social norms govern culturally appropriate behavior in communication,
enabling dialogue systems to produce responses that are not only coherent but
also socially acceptable. We present NormGenesis, a multicultural framework for
generating and annotating socially grounded dialogues across English, Chinese,
and Korean. To model the dynamics of social interaction beyond static norm
classification, we propose a novel dialogue type, Violation-to-Resolution
(V2R), which models the progression of conversations following norm violations
through recognition and socially appropriate repair. To improve pragmatic
consistency in underrepresented languages, we implement an exemplar-based
iterative refinement early in the dialogue synthesis process. This design
introduces alignment with linguistic, emotional, and sociocultural expectations
before full dialogue generation begins. Using this framework, we construct a
dataset of 10,800 multi-turn dialogues annotated at the turn level for norm
adherence, speaker intent, and emotional response. Human and LLM-based
evaluations demonstrate that NormGenesis significantly outperforms existing
datasets in refinement quality, dialogue naturalness, and generalization
performance. We show that models trained on our V2R-augmented data exhibit
improved pragmatic competence in ethically sensitive contexts. Our work
establishes a new benchmark for culturally adaptive dialogue modeling and
provides a scalable methodology for norm-aware generation across linguistically
and culturally diverse languages.

</details>


### [15] [Evaluating the Creativity of LLMs in Persian Literary Text Generation](https://arxiv.org/abs/2509.18401)
*Armin Tourajmehr,Mohammad Reza Modarres,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型生成波斯文学文本的能力，重点关注文化相关表达和创造力维度，并采用LLM作为自动评分工具验证其可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中于英语文学创作，缺乏对非英语文学传统的探索，且缺乏标准化的创造力评估方法。本文旨在填补波斯文学文本生成评估的空白。

Method: 构建包含20个主题的波斯文学数据集，采用托兰斯创造力测试的四个维度（原创性、流畅性、灵活性、精细性）进行评估，使用LLM作为自动评分工具并与人工评分进行可靠性验证。

Result: LLM评分与人工评分具有强一致性，模型在理解和运用四种核心文学修辞手法（明喻、隐喻、夸张、对偶）方面表现出既有优势也有局限性。

Conclusion: LLM在波斯文学文本生成方面展现出潜力，但仍需进一步改进，特别是在文化相关表达和文学修辞的运用方面。

Abstract: Large language models (LLMs) have demonstrated notable creative abilities in
generating literary texts, including poetry and short stories. However, prior
research has primarily centered on English, with limited exploration of
non-English literary traditions and without standardized methods for assessing
creativity. In this paper, we evaluate the capacity of LLMs to generate Persian
literary text enriched with culturally relevant expressions. We build a dataset
of user-generated Persian literary spanning 20 diverse topics and assess model
outputs along four creativity dimensions-originality, fluency, flexibility, and
elaboration-by adapting the Torrance Tests of Creative Thinking. To reduce
evaluation costs, we adopt an LLM as a judge for automated scoring and validate
its reliability against human judgments using intraclass correlation
coefficients, observing strong agreement. In addition, we analyze the models'
ability to understand and employ four core literary devices: simile, metaphor,
hyperbole, and antithesis. Our results highlight both the strengths and
limitations of LLMs in Persian literary text generation, underscoring the need
for further refinement.

</details>


### [16] [Developing an AI framework to automatically detect shared decision-making in patient-doctor conversations](https://arxiv.org/abs/2509.18439)
*Oscar J. Ponce-Ponte,David Toro-Tobon,Luis F. Figueroa,Michael Gionfriddo,Megan Branda,Victor M. Montori,Saturnino Luz,Juan P. Brito*

Main category: cs.CL

TL;DR: 本研究开发了一种自动化方法来测量医患对话中的共享决策，通过语言建模和对话对齐评分，实现了大规模SDM评估。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏自动测量共享决策的方法，需要一种可扩展的技术来评估医患沟通质量。

Method: 使用157个医患对话视频转录的42,559个句子，通过上下文-响应对和负采样训练深度学习模型和微调BERT模型，计算四种对话对齐评分。

Result: DL模型和微调BERT模型生成的对话对齐评分与SDM结果（OPTION12和DCS评分）显著相关，BERTbase模型表现最佳。

Conclusion: 该研究提出了一种自动化、可扩展的方法来测量医患对话中的共享决策，具有大规模评估SDM策略的潜力。

Abstract: Shared decision-making (SDM) is necessary to achieve patient-centred care.
Currently no methodology exists to automatically measure SDM at scale. This
study aimed to develop an automated approach to measure SDM by using language
modelling and the conversational alignment (CA) score. A total of 157
video-recorded patient-doctor conversations from a randomized multi-centre
trial evaluating SDM decision aids for anticoagulation in atrial fibrillations
were transcribed and segmented into 42,559 sentences. Context-response pairs
and negative sampling were employed to train deep learning (DL) models and
fine-tuned BERT models via the next sentence prediction (NSP) task. Each
top-performing model was used to calculate four types of CA scores. A
random-effects analysis by clinician, adjusting for age, sex, race, and trial
arm, assessed the association between CA scores and SDM outcomes: the
Decisional Conflict Scale (DCS) and the Observing Patient Involvement in
Decision-Making 12 (OPTION12) scores. p-values were corrected for multiple
comparisons with the Benjamini-Hochberg method. Among 157 patients (34% female,
mean age 70 SD 10.8), clinicians on average spoke more words than patients
(1911 vs 773). The DL model without the stylebook strategy achieved a recall@1
of 0.227, while the fine-tuned BERTbase (110M) achieved the highest recall@1
with 0.640. The AbsMax (18.36 SE7.74 p=0.025) and Max CA (21.02 SE7.63 p=0.012)
scores generated with the DL without stylebook were associated with OPTION12.
The Max CA score generated with the fine-tuned BERTbase (110M) was associated
with the DCS score (-27.61 SE12.63 p=0.037). BERT model sizes did not have an
impact the association between CA scores and SDM. This study introduces an
automated, scalable methodology to measure SDM in patient-doctor conversations
through explainable CA scores, with potential to evaluate SDM strategies at
scale.

</details>


### [17] [CogniLoad: A Synthetic Natural Language Reasoning Benchmark With Tunable Length, Intrinsic Difficulty, and Distractor Density](https://arxiv.org/abs/2509.18458)
*Daniel Kaiser,Arnoldo Frigessi,Ali Ramezani-Kebrya,Benjamin Ricaud*

Main category: cs.CL

TL;DR: CogniLoad是一个基于认知负荷理论(CLT)的合成基准测试，通过可独立调节的参数来精确分析LLM的长上下文推理能力，包括内在难度、干扰因素和任务长度三个维度。


<details>
  <summary>Details</summary>
Motivation: 当前的长上下文推理基准测试往往模糊了关键因素，如内在任务复杂性、干扰因素干扰和任务长度，无法进行精确的失败分析。

Method: 基于认知负荷理论，生成自然语言逻辑谜题，通过可独立调节的参数控制内在负荷(d)、外在负荷(ρ)和关联负荷(N)三个核心维度。

Result: 评估22个最先进的推理LLM，发现任务长度是主要约束因素，模型对内在复杂性有不同容忍度，对干扰因素比率呈现U型响应。

Conclusion: CogniLoad通过系统控制认知负荷维度，为分析LLM推理局限性和指导未来模型开发提供了可重现、可扩展且诊断丰富的工具。

Abstract: Current benchmarks for long-context reasoning in Large Language Models (LLMs)
often blur critical factors like intrinsic task complexity, distractor
interference, and task length. To enable more precise failure analysis, we
introduce CogniLoad, a novel synthetic benchmark grounded in Cognitive Load
Theory (CLT). CogniLoad generates natural-language logic puzzles with
independently tunable parameters that reflect CLT's core dimensions: intrinsic
difficulty ($d$) controls intrinsic load; distractor-to-signal ratio ($\rho$)
regulates extraneous load; and task length ($N$) serves as an operational proxy
for conditions demanding germane load. Evaluating 22 SotA reasoning LLMs,
CogniLoad reveals distinct performance sensitivities, identifying task length
as a dominant constraint and uncovering varied tolerances to intrinsic
complexity and U-shaped responses to distractor ratios. By offering systematic,
factorial control over these cognitive load dimensions, CogniLoad provides a
reproducible, scalable, and diagnostically rich tool for dissecting LLM
reasoning limitations and guiding future model development.

</details>


### [18] [LAWCAT: Efficient Distillation from Quadratic to Linear Attention with Convolution across Tokens for Long Context Modeling](https://arxiv.org/abs/2509.18467)
*Zeyu Liu,Souvik Kundu,Lianghao Jiang,Anni Li,Srikanth Ronanki,Sravan Bodapati,Gourav Datta,Peter A. Beerel*

Main category: cs.CL

TL;DR: LAWCAT提出了一种线性注意力框架，可将预训练Transformer高效转换为线性复杂度模型，显著提升长序列处理能力并减少计算资源需求


<details>
  <summary>Details</summary>
Motivation: Transformer的二次计算复杂度限制了其在长序列应用中的效率，而从头训练线性模型又需要大量资源。LAWCAT旨在通过知识蒸馏方法解决这一问题

Method: LAWCAT结合因果Conv1D层增强局部依赖建模，使用归一化门控线性注意力提升不同上下文长度的泛化能力，通过蒸馏预训练Transformer实现高效转换

Result: 在Mistral-7B上仅用1K长度序列蒸馏即可达到22K tokens的90%以上passkey检索准确率；Llama3.2-1B变体在多个长上下文基准测试中表现优异，预训练token需求减少99.9%

Conclusion: LAWCAT为高性能长上下文线性模型提供了高效路径，适合边缘部署，减少了对长序列训练数据和计算资源的依赖

Abstract: Although transformer architectures have achieved state-of-the-art performance
across diverse domains, their quadratic computational complexity with respect
to sequence length remains a significant bottleneck, particularly for
latency-sensitive long-context applications. While recent linear-complexity
alternatives are increasingly powerful, effectively training them from scratch
is still resource-intensive. To overcome these limitations, we propose LAWCAT
(Linear Attention with Convolution Across Time), a novel linearization
framework designed to efficiently transfer the capabilities of pre-trained
transformers into a performant linear attention architecture. LAWCAT integrates
causal Conv1D layers to enhance local dependency modeling and employs
normalized gated linear attention to improve generalization across varying
context lengths. Our comprehensive evaluations demonstrate that, distilling
Mistral-7B with only 1K-length sequences yields over 90\% passkey retrieval
accuracy up to 22K tokens, significantly extending its effective context
window. Similarly, Llama3.2-1B LAWCAT variant achieves competitive performance
on S-NIAH 1\&2\&3 tasks (1K-8K context length) and BABILong benchmark
(QA2\&QA3, 0K-16K context length), requiring less than 0.1\% pre-training
tokens compared with pre-training models. Furthermore, LAWCAT exhibits faster
prefill speeds than FlashAttention-2 for sequences exceeding 8K tokens. LAWCAT
thus provides an efficient pathway to high-performance, long-context linear
models suitable for edge deployment, reducing reliance on extensive
long-sequence training data and computational resources.

</details>


### [19] [Actions Speak Louder than Prompts: A Large-Scale Study of LLMs for Graph Inference](https://arxiv.org/abs/2509.18487)
*Ben Finkelshtein,Silviu Cucerzan,Sujay Kumar Jauhar,Ryen White*

Main category: cs.CL

TL;DR: 本文通过大规模系统评估，研究了LLM在图数据上的表现，发现代码生成方法在图形任务中表现最佳，特别是在长文本或高密度图中，且所有交互策略在异质图中都有效。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在文本丰富的图机器学习任务中应用增多，但缺乏对LLM与图数据交互能力的系统理解，需要评估不同交互模式在不同图数据条件下的表现。

Method: 进行大规模控制评估，涵盖多个关键变量轴：LLM-图交互模式（提示、工具使用、代码生成）、数据集领域、结构机制、特征特性和模型配置，并通过截断特征、删除边和移除标签来分析依赖性。

Result: 代码生成方法在图形数据上表现最强，特别是在长文本或高密度图中；所有交互策略在异质图中保持有效；代码生成能灵活调整对结构、特征或标签的依赖。

Conclusion: 研究结果提供了当前LLM-图交互模式的全面视图，强调了未来方法的关键设计原则，代码生成是最有效的交互方式。

Abstract: Large language models (LLMs) are increasingly used for text-rich graph
machine learning tasks such as node classification in high-impact domains like
fraud detection and recommendation systems. Yet, despite a surge of interest,
the field lacks a principled understanding of the capabilities of LLMs in their
interaction with graph data. In this work, we conduct a large-scale, controlled
evaluation across several key axes of variability to systematically assess the
strengths and weaknesses of LLM-based graph reasoning methods in text-based
applications. The axes include the LLM-graph interaction mode, comparing
prompting, tool-use, and code generation; dataset domains, spanning citation,
web-link, e-commerce, and social networks; structural regimes contrasting
homophilic and heterophilic graphs; feature characteristics involving both
short- and long-text node attributes; and model configurations with varying LLM
sizes and reasoning capabilities. We further analyze dependencies by
methodically truncating features, deleting edges, and removing labels to
quantify reliance on input types. Our findings provide practical and actionable
guidance. (1) LLMs as code generators achieve the strongest overall performance
on graph data, with especially large gains on long-text or high-degree graphs
where prompting quickly exceeds the token budget. (2) All interaction
strategies remain effective on heterophilic graphs, challenging the assumption
that LLM-based methods collapse under low homophily. (3) Code generation is
able to flexibly adapt its reliance between structure, features, or labels to
leverage the most informative input type. Together, these findings provide a
comprehensive view of the strengths and limitations of current LLM-graph
interaction modes and highlight key design principles for future approaches.

</details>


### [20] [A Rhythm-Aware Phrase Insertion for Classical Arabic Poetry Composition](https://arxiv.org/abs/2509.18514)
*Mohamad Elzohbi,Richard Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种使用ByT5模型在阿拉伯诗歌中插入短语以符合特定韵律的方法，通过基于规则的grapheme-to-beat转换提取韵律，采用条件去噪目标微调模型，并探索了从英语到阿拉伯语的跨语言迁移。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够自动在阿拉伯诗歌中插入符合特定韵律的短语的方法，以辅助古典阿拉伯诗歌的创作过程，实现韵律对齐和语义连贯性。

Method: 使用基于规则的grapheme-to-beat转换从完全标注的阿拉伯文本中提取韵律，采用条件去噪目标微调ByT5模型，通过课程学习策略先在通用阿拉伯数据集上预训练，再在诗歌数据集上微调，并探索跨语言迁移。

Result: 实验结果表明，所提出的模型在保持语义连贯性的同时，实现了高度的韵律对齐。

Conclusion: 该模型有潜力在古典阿拉伯诗歌创作过程中用于协同创作应用。

Abstract: This paper presents a methodology for inserting phrases in Arabic poems to
conform to a specific rhythm using ByT5, a byte-level multilingual
transformer-based model. Our work discusses a rule-based grapheme-to-beat
transformation tailored for extracting the rhythm from fully diacritized Arabic
script. Our approach employs a conditional denoising objective to fine-tune
ByT5, where the model reconstructs masked words to match a target rhythm. We
adopt a curriculum learning strategy, pre-training on a general Arabic dataset
before fine-tuning on poetic dataset, and explore cross-lingual transfer from
English to Arabic. Experimental results demonstrate that our models achieve
high rhythmic alignment while maintaining semantic coherence. The proposed
model has the potential to be used in co-creative applications in the process
of composing classical Arabic poems.

</details>


### [21] [Trace Is In Sentences: Unbiased Lightweight ChatGPT-Generated Text Detector](https://arxiv.org/abs/2509.18535)
*Mo Mu,Dianqiao Lei,Chang Li*

Main category: cs.CL

TL;DR: 提出了一种轻量级框架，通过分析文本内部结构来检测原始和提示修改后的AI生成文本，解决了现有词级检测器对改写敏感、存在偏见等问题。


<details>
  <summary>Details</summary>
Motivation: ChatGPT的广泛使用引发了对AI生成文本检测的需求，现有词级检测器存在对改写敏感、存在ChatGPT词级模式和训练数据偏见、在修改文本上性能下降、需要大模型或在线LLM交互等问题。

Method: 提出基于文本内部结构分类的轻量级框架，使用预训练语言模型编码句子嵌入并通过注意力建模关系，采用对比学习减轻自回归生成带来的嵌入偏见，结合因果图和反事实方法分离结构特征与主题相关偏见。

Result: 在两个精心策划的数据集（包括摘要比较和修订的生活FAQ）上的实验验证了方法的有效性。

Conclusion: 该方法能够有效检测原始和提示修改后的AI生成文本，解决了现有检测器的局限性，为AI文本检测提供了新的解决方案。

Abstract: The widespread adoption of ChatGPT has raised concerns about its misuse,
highlighting the need for robust detection of AI-generated text. Current
word-level detectors are vulnerable to paraphrasing or simple prompts (PSP),
suffer from biases induced by ChatGPT's word-level patterns (CWP) and training
data content, degrade on modified text, and often require large models or
online LLM interaction. To tackle these issues, we introduce a novel task to
detect both original and PSP-modified AI-generated texts, and propose a
lightweight framework that classifies texts based on their internal structure,
which remains invariant under word-level changes. Our approach encodes sentence
embeddings from pre-trained language models and models their relationships via
attention. We employ contrastive learning to mitigate embedding biases from
autoregressive generation and incorporate a causal graph with counterfactual
methods to isolate structural features from topic-related biases. Experiments
on two curated datasets, including abstract comparisons and revised life FAQs,
validate the effectiveness of our method.

</details>


### [22] [CCQA: Generating Question from Solution Can Improve Inference-Time Reasoning in SLMs](https://arxiv.org/abs/2509.18536)
*Jin Young Kim,Ji Won Yoon*

Main category: cs.CL

TL;DR: CCQA是一种针对小型语言模型的新型推理方法，通过循环一致性原理生成问题并评估相似度来选择最佳答案，在数学和常识推理任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的推理时间策略在大型语言模型上有效，但在小型模型上效果不佳，需要开发专门针对小型模型的有效推理方法。

Method: CCQA基于循环一致性原理：从每个推理路径和答案生成问题，评估生成问题与原问题的相似度，选择相似度最高的候选解作为最终答案。使用专门的Flan-T5模型进行问题生成。

Result: 在八个模型上的数学和常识推理基准测试中，CCQA一致优于现有最先进方法，为小型语言模型建立了新的高效推理基准。

Conclusion: CCQA为小型语言模型提供了一种有效的推理方法，在保持效率的同时显著提升了推理性能。

Abstract: Recently, inference-time reasoning strategies have further improved the
accuracy of large language models (LLMs), but their effectiveness on smaller
models remains unclear. Based on the observation that conventional approaches
often fail to improve performance in this context, we propose
\textbf{C}ycle-\textbf{C}onsistency in \textbf{Q}uestion \textbf{A}nswering
(CCQA), a novel reasoning method that can be effectively applied to SLMs.
Inspired by cycle consistency, CCQA generates a question from each reasoning
path and answer, evaluates each by its similarity to the original question, and
then selects the candidate solution with the highest similarity score as the
final response. Since conventional SLMs struggle to generate accurate questions
from their own reasoning paths and answers, we employ a lightweight Flan-T5
model specialized for question generation to support this process efficiently.
From the experimental results, it is verified that CCQA consistently
outperforms existing state-of-the-art (SOTA) methods across eight models on
mathematical and commonsense reasoning benchmarks. Furthermore, our method
establishes a new practical baseline for efficient reasoning in SLMs. Source
code can be found at https://github.com/scai-research/ccqa_official.

</details>


### [23] [Prior-based Noisy Text Data Filtering: Fast and Strong Alternative For Perplexity](https://arxiv.org/abs/2509.18577)
*Yeongbin Seo,Gayoung Kim,Jaehyung Kim,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 提出了一种基于先验的数据过滤方法，使用语料库级别的词频统计来估计标记先验，作为困惑度（PPL）过滤的快速替代方案，无需模型推理，时间成本降低1000倍以上。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型预训练需要有效的数据选择方法。困惑度（PPL）过滤虽然性能强，但存在时间成本高和处理噪声/分布外样本不可靠的问题。

Method: 基于语言学的词角色和词汇密度洞察，使用语料库级别的词频统计估计标记先验，通过标记先验的均值和标准差来过滤文档。

Result: 在20个下游基准测试中取得了最高的平均性能，时间成本比PPL过滤降低1000倍以上，适用于代码、数学等符号语言，并能无监督地适应多语言语料库。

Conclusion: 先验过滤方法简单但强大，是PPL过滤的有效替代方案，具有高效性和广泛适用性。

Abstract: As large language models (LLMs) are pretrained on massive web corpora,
careful selection of data becomes essential to ensure effective and efficient
learning. While perplexity (PPL)-based filtering has shown strong performance,
it suffers from drawbacks: substantial time costs and inherent unreliability of
the model when handling noisy or out-of-distribution samples. In this work, we
propose a simple yet powerful alternative: a prior-based data filtering method
that estimates token priors using corpus-level term frequency statistics,
inspired by linguistic insights on word roles and lexical density. Our approach
filters documents based on the mean and standard deviation of token priors,
serving as a fast proxy to PPL while requiring no model inference. Despite its
simplicity, the prior-based filter achieves the highest average performance
across 20 downstream benchmarks, while reducing time cost by over 1000x
compared to PPL-based filtering. We further demonstrate its applicability to
symbolic languages such as code and math, and its dynamic adaptability to
multilingual corpora without supervision

</details>


### [24] [TsqLoRA: Towards Sensitivity and Quality Low-Rank Adaptation for Efficient Fine-Tuning](https://arxiv.org/abs/2509.18585)
*Yu Chen,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: TsqLoRA是一种新型参数高效微调方法，通过数据质量驱动选择和敏感性感知的低秩适配，提高大模型微调效率


<details>
  <summary>Details</summary>
Motivation: 全参数微调计算成本高且内存密集，现有参数高效方法忽视了不同模型层的敏感性差异和训练数据的重要性

Method: 结合质量感知采样机制选择最有信息量的训练数据，以及动态秩分配模块根据各层敏感性调整秩大小

Result: 实验结果表明TsqLoRA在多种NLP任务上提高了微调效率，同时保持甚至改善了性能

Conclusion: TsqLoRA为资源受限环境下的模型微调提供了有效的解决方案

Abstract: Fine-tuning large pre-trained models for downstream tasks has become a
fundamental approach in natural language processing. Fully fine-tuning all
model parameters is computationally expensive and memory-intensive, especially
in resource-constrained environments. Existing parameter-efficient fine-tuning
methods reduce the number of trainable parameters but typically overlook the
varying sensitivity of different model layers and the importance of training
data. In this work, we propose TsqLoRA, a novel method that integrates
data-quality-driven selection with sensitivity-aware low-rank adaptation,
consisted of two main components: a quality-aware sampling mechanism for
selecting the most informative training data, and a dynamic rank allocation
module that adjusts the rank of each layer based on its sensitivity to
parameter updates. The experimental results demonstrate that TsqLoRA improves
fine-tuning efficiency while maintaining or even improving performance on a
variety of NLP tasks. Our code will be available at
https://github.com/Benjamin-Ricky/TsqLoRA.

</details>


### [25] [UniECG: Understanding and Generating ECG in One Unified Model](https://arxiv.org/abs/2509.18588)
*Jiarui Jin,Haoyu Wang,Xiang Lan,Jun Li,Gaofeng Cheng,Hongyan Li,Shenda Hong*

Main category: cs.CL

TL;DR: UniECG是首个能够同时执行基于证据的心电图解释和文本条件心电图生成任务的统一模型，通过解耦的两阶段训练方法实现。


<details>
  <summary>Details</summary>
Motivation: 现有的统一模型（如GPT-5）在视觉语言任务上取得了进展，但无法正确理解心电图信号并提供准确的医疗诊断，也不能生成心电图信号。

Method: 采用解耦的两阶段训练方法：首先学习基于证据的解释技能（ECG-to-Text），然后通过潜在空间对齐注入心电图生成能力（Text-to-ECG）。

Result: UniECG能够根据用户输入自主选择解释或生成心电图，显著扩展了当前心电图模型的能力边界。

Conclusion: 该模型解决了现有统一模型在心电图理解与生成方面的局限性，为心电图分析提供了更全面的解决方案。

Abstract: Recent unified models such as GPT-5 have achieved encouraging progress on
vision-language tasks. However, these unified models typically fail to
correctly understand ECG signals and provide accurate medical diagnoses, nor
can they correctly generate ECG signals. To address these limitations, we
propose UniECG, the first unified model for ECG capable of concurrently
performing evidence-based ECG interpretation and text-conditioned ECG
generation tasks. Through a decoupled two-stage training approach, the model
first learns evidence-based interpretation skills (ECG-to-Text), and then
injects ECG generation capabilities (Text-to-ECG) via latent space alignment.
UniECG can autonomously choose to interpret or generate an ECG based on user
input, significantly extending the capability boundaries of current ECG models.
Our code and checkpoints will be made publicly available at
https://github.com/PKUDigitalHealth/UniECG upon acceptance.

</details>


### [26] [A Good Plan is Hard to Find: Aligning Models with Preferences is Misaligned with What Helps Users](https://arxiv.org/abs/2509.18632)
*Nishant Balepur,Matthew Shu,Yoo Yeon Sung,Seraphina Goldfarb-Tarrant,Shi Feng,Fumeng Yang,Rachel Rudinger,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: 论文研究发现，用户偏好和模型偏好并不能准确预测哪些计划真正对用户有帮助，常见的对齐方法可能偏离实际帮助性。需要基于真实用户交互的反馈，而不仅仅是表面看起来有用的偏好。


<details>
  <summary>Details</summary>
Motivation: 测试LLM生成计划的对齐方法是否真正反映了对用户的帮助性，而不是仅仅基于用户偏好。

Method: 使用Planorama界面，让126名用户回答300个多步骤问题，收集4388个计划执行和5584个比较，测量计划帮助性和用户偏好，并在代理和奖励模型中重现设置。

Result: 1) 用户/模型偏好和代理成功率不能准确预测计划帮助性；2) 这种差距不是用户特定偏好造成的；3) 表面线索（如简洁性和问题相似性）与偏好强相关，但不能预测帮助性。

Conclusion: 需要对LLM进行对齐时，需要基于真实用户交互的反馈，而不仅仅是看起来有用的偏好。

Abstract: To assist users in complex tasks, LLMs generate plans: step-by-step
instructions towards a goal. While alignment methods aim to ensure LLM plans
are helpful, they train (RLHF) or evaluate (ChatbotArena) on what users prefer,
assuming this reflects what helps them. We test this with Planorama: an
interface where 126 users answer 300 multi-step questions with LLM plans. We
get 4388 plan executions and 5584 comparisons to measure plan helpfulness (QA
success) and user preferences on plans, and recreate the setup in agents and
reward models to see if they simulate or prefer what helps users. We expose: 1)
user/model preferences and agent success do not accurately predict which plans
help users, so common alignment feedback can misalign with helpfulness; 2) this
gap is not due to user-specific preferences, as users are similarly successful
when using plans they prefer/disprefer; 3) surface-level cues like brevity and
question similarity strongly link to preferences, but such biases fail to
predict helpfulness. In all, we argue aligning helpful LLMs needs feedback from
real user interactions, not just preferences of what looks helpful, so we
discuss the plan NLP researchers can execute to solve this problem.

</details>


### [27] [Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop Question Answering](https://arxiv.org/abs/2509.18655)
*Lingwen Deng,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: CAPE-KG是一个一致性感知的参数保持知识编辑框架，通过知识图谱在多跳问答任务中实现更可靠的知识更新。


<details>
  <summary>Details</summary>
Motivation: 现有的基于知识图谱的参数保持知识编辑方法在多跳问答中存在一致性问题，导致知识污染、更新不稳定和检索行为与编辑意图不一致，影响了多跳推理的可靠性。

Method: 提出CAPE-KG框架，确保知识图谱的构建、更新和检索过程始终与多跳问答任务要求对齐，在未编辑和已编辑知识上保持一致的推理能力。

Result: 在MQuAKE基准测试上的广泛实验显示，该方法在多跳问答的参数保持知识编辑性能上取得了准确率提升。

Conclusion: CAPE-KG通过解决一致性问题，证明了在多跳问答中参数保持知识编辑的有效性和可靠性。

Abstract: Parameter-Preserving Knowledge Editing (PPKE) enables updating models with
new or corrected information without retraining or parameter adjustment. Recent
PPKE approaches based on knowledge graphs (KG) to extend knowledge editing (KE)
capabilities to multi-hop question answering (MHQA). However, these methods
often lack consistency, leading to knowledge contamination, unstable updates,
and retrieval behaviors that fail to reflect the intended edits. Such
inconsistencies undermine the reliability of PPKE in multi- hop reasoning. We
present CAPE-KG, Consistency-Aware Parameter-Preserving Editing with Knowledge
Graphs, a novel consistency-aware framework for PPKE on MHQA. CAPE-KG ensures
KG construction, update, and retrieval are always aligned with the requirements
of the MHQA task, maintaining coherent reasoning over both unedited and edited
knowledge. Extensive experiments on the MQuAKE benchmark show accuracy
improvements in PPKE performance for MHQA, demonstrating the effectiveness of
addressing consistency in PPKE.

</details>


### [28] [Analyzing Uncertainty of LLM-as-a-Judge: Interval Evaluations with Conformal Prediction](https://arxiv.org/abs/2509.18658)
*Huanxin Sheng,Xinyi Liu,Hangfeng He,Jieyu Zhao,Jian Kang*

Main category: cs.CL

TL;DR: 该论文提出了首个分析LLM作为评判者不确定性的框架，通过保形预测为LLM评分提供预测区间，以解决LLM评估可靠性不足的问题。


<details>
  <summary>Details</summary>
Motivation: LLM作为评判者的评估范式虽然前景广阔，但其评估的不确定性尚未得到充分探索，这种可靠性不足限制了其在许多应用中的部署。

Method: 使用保形预测构建连续预测区间，针对离散评分任务设计序数边界调整，并提出区间中点评分作为原始模型评分和加权平均的低偏差替代方案。

Result: 实验表明保形预测能够提供具有覆盖保证的有效预测区间，区间中点和重新提示评判者有助于获得更好的判断。

Conclusion: 该框架为LLM评估的不确定性分析提供了有效工具，保形预测方法能够显著提升LLM作为评判者的可靠性。

Abstract: LLM-as-a-judge has become a promising paradigm for using large language
models (LLMs) to evaluate natural language generation (NLG), but the
uncertainty of its evaluation remains underexplored. This lack of reliability
may limit its deployment in many applications. This work presents the first
framework to analyze the uncertainty by offering a prediction interval of
LLM-based scoring via conformal prediction. Conformal prediction constructs
continuous prediction intervals from a single evaluation run, and we design an
ordinal boundary adjustment for discrete rating tasks. We also suggest a
midpoint-based score within the interval as a low-bias alternative to raw model
score and weighted average. We perform extensive experiments and analysis,
which show that conformal prediction can provide valid prediction interval with
coverage guarantees. We also explore the usefulness of interval midpoint and
judge reprompting for better judgment.

</details>


### [29] [MemOrb: A Plug-and-Play Verbal-Reinforcement Memory Layer for E-Commerce Customer Service](https://arxiv.org/abs/2509.18713)
*Yizhe Huang,Yang Liu,Ruiyu Zhao,Xiaolong Zhong,Xingming Yue,Ling Jiang*

Main category: cs.CL

TL;DR: MemOrb是一个轻量级即插即用的语言强化记忆层，通过将多轮交互提炼为紧凑的策略反思来增强LLM智能体在客服场景中的长期可靠性


<details>
  <summary>Details</summary>
Motivation: 现有的LLM智能体在客服部署中存在跨会话遗忘、重复错误和缺乏持续自我改进机制的问题，导致在动态环境中不可靠

Method: 提出MemOrb记忆层，将多轮交互提炼为策略反思存储在共享记忆库中，无需微调即可检索指导决策

Result: 实验显示MemOrb显著提高了任务成功率和稳定性，多轮成功率提升高达63个百分点，在重复试验中表现更一致

Conclusion: 结构化反思是增强冻结LLM智能体在客服场景中长期可靠性的有效机制

Abstract: Large Language Model-based agents(LLM-based agents) are increasingly deployed
in customer service, yet they often forget across sessions, repeat errors, and
lack mechanisms for continual self-improvement. This makes them unreliable in
dynamic settings where stability and consistency are critical. To better
evaluate these properties, we emphasize two indicators: task success rate as a
measure of overall effectiveness, and consistency metrics such as Pass$^k$ to
capture reliability across multiple trials. To address the limitations of
existing approaches, we propose MemOrb, a lightweight and plug-and-play verbal
reinforcement memory layer that distills multi-turn interactions into compact
strategy reflections. These reflections are stored in a shared memory bank and
retrieved to guide decision-making, without requiring any fine-tuning.
Experiments show that MemOrb significantly improves both success rate and
stability, achieving up to a 63 percentage-point gain in multi-turn success
rate and delivering more consistent performance across repeated trials. Our
results demonstrate that structured reflection is a powerful mechanism for
enhancing long-term reliability of frozen LLM agents in customer service
scenarios.

</details>


### [30] [LOTUSDIS: A Thai far-field meeting corpus for robust conversational ASR](https://arxiv.org/abs/2509.18722)
*Pattara Tipaksorn,Sumonmas Thatphithakkul,Vataya Chunwijitra,Kwanchiva Thangthai*

Main category: cs.CL

TL;DR: LOTUSDIS是一个公开的泰语会议语料库，包含114小时自发对话，用于推进远场对话语音识别研究。该数据集通过多种麦克风在0.12-10米距离录制，包含重叠语音和真实声学效应。


<details>
  <summary>Details</summary>
Motivation: 解决远场泰语语音识别中预训练数据与实际远场语音不匹配的问题，提供距离多样化的训练数据以提高ASR系统的鲁棒性。

Method: 收集114小时自发对话，使用9个独立单通道设备（6种麦克风类型）在不同距离（0.12-10米）同时录制，提供标准数据集划分和可复现基线系统。

Result: 零样本Whisper模型随距离增加性能显著下降，微调后整体WER从64.3降至38.3，远场WER从81.6降至49.5，最远麦克风改进最大。

Conclusion: 距离多样化的训练数据对鲁棒ASR至关重要，LOTUSDIS语料库和基线系统为可复现研究提供了重要资源。

Abstract: We present LOTUSDIS, a publicly available Thai meeting corpus designed to
advance far-field conversational ASR. The dataset comprises 114 hours of
spontaneous, unscripted dialogue collected in 15-20 minute sessions with three
participants, where overlapping speech is frequent and natural. Speech was
recorded simultaneously by nine independent single-channel devices spanning six
microphone types at distances from 0.12 m to 10 m, preserving the authentic
effects of reverberation, noise, and device coloration without relying on
microphone arrays. We provide standard train, dev, test splits and release a
reproducible baseline system. We benchmarked several Whisper variants under
zero-shot and fine-tuned conditions. Off-the-shelf models showed strong
degradation with distance, confirming a mismatch between pre-training data and
Thai far-field speech. Fine-tuning on LOTUSDIS dramatically improved
robustness: a Thai Whisper baseline reduced overall WER from 64.3 to 38.3 and
far-field WER from 81.6 to 49.5, with especially large gains on the most
distant microphones. These results underscore the importance of
distance-diverse training data for robust ASR. The corpus is available under
CC-BY-SA 4.0. We also release training and evaluation scripts as a baseline
system to promote reproducible research in this field.

</details>


### [31] [Global-Recent Semantic Reasoning on Dynamic Text-Attributed Graphs with Large Language Models](https://arxiv.org/abs/2509.18742)
*Yunan Wang,Jianxin Li,Ziwei Zhang*

Main category: cs.CL

TL;DR: DyGRASP是一种处理动态文本属性图的新方法，结合LLMs和时序GNNs来捕获近期和全局的时序语义，在节点检索任务上取得显著性能提升


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注静态文本属性图，难以处理动态文本属性图中近期-全局时序语义的捕获问题，且LLMs在处理大量动态文本时存在效率问题

Method: 设计节点中心隐式推理方法结合滑动窗口机制捕获近期语义；利用显式推理和RNN-like链结构捕获全局语义动态；通过更新和融合层整合近期/全局时序语义与动态图结构信息

Result: 在DyTAG基准测试中，DyGRASP在目标节点检索任务的Hit@10指标上提升高达34%，且在不同时序GNNs和LLMs上表现出强泛化能力

Conclusion: DyGRASP有效解决了动态文本属性图中的时序语义捕获问题，为动态图学习提供了高效且通用的解决方案

Abstract: Dynamic Text-Attribute Graphs (DyTAGs), characterized by time-evolving graph
interactions and associated text attributes, are prevalent in real-world
applications. Existing methods, such as Graph Neural Networks (GNNs) and Large
Language Models (LLMs), mostly focus on static TAGs. Extending these existing
methods to DyTAGs is challenging as they largely neglect the recent-global
temporal semantics: the recent semantic dependencies among interaction texts
and the global semantic evolution of nodes over time. Furthermore, applying
LLMs to the abundant and evolving text in DyTAGs faces efficiency issues. To
tackle these challenges, we propose Dynamic Global-Recent Adaptive Semantic
Processing (DyGRASP), a novel method that leverages LLMs and temporal GNNs to
efficiently and effectively reason on DyTAGs. Specifically, we first design a
node-centric implicit reasoning method together with a sliding window mechanism
to efficiently capture recent temporal semantics. In addition, to capture
global semantic dynamics of nodes, we leverage explicit reasoning with tailored
prompts and an RNN-like chain structure to infer long-term semantics. Lastly,
we intricately integrate the recent and global temporal semantics as well as
the dynamic graph structural information using updating and merging layers.
Extensive experiments on DyTAG benchmarks demonstrate DyGRASP's superiority,
achieving up to 34% improvement in Hit@10 for destination node retrieval task.
Besides, DyGRASP exhibits strong generalization across different temporal GNNs
and LLMs.

</details>


### [32] [False Friends Are Not Foes: Investigating Vocabulary Overlap in Multilingual Language Models](https://arxiv.org/abs/2509.18750)
*Julie Kallini,Dan Jurafsky,Christopher Potts,Martijn Bartelds*

Main category: cs.CL

TL;DR: 本文研究了多语言分词器中token重叠对跨语言迁移的影响，通过控制实验发现token重叠有利于跨语言语义关系的捕捉，并能提升模型在跨语言任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 多语言分词器自然会产生跨语言重叠的token，但现有研究对token重叠是促进跨语言迁移还是引入语言间干扰存在争议，且受限于不同实验设置和混淆因素。

Method: 设计了受控实验，在多种语言对上训练双语自回归模型，系统性地改变词汇重叠设置，并引入新的维度——跨语言共享token的语义相似性来分析重叠的影响。

Result: 分析模型隐藏表示发现，任何类型的重叠都能创建捕捉跨语言语义关系的嵌入空间，而词汇不相交的模型效果较弱。在XNLI和XQuAD任务上，有重叠的模型优于词汇不相交的模型，且迁移性能随重叠增加而提升。

Conclusion: token重叠在多语言模型中具有优势，保持大量共享词汇仍然是多语言分词器的有益设计选择。

Abstract: Subword tokenizers trained on multilingual corpora naturally produce
overlapping tokens across languages. Does token overlap facilitate
cross-lingual transfer or instead introduce interference between languages?
Prior work offers mixed evidence, partly due to varied setups and confounders,
such as token frequency or subword segmentation granularity. To address this
question, we devise a controlled experiment where we train bilingual
autoregressive models on multiple language pairs under systematically varied
vocabulary overlap settings. Crucially, we explore a new dimension to
understanding how overlap affects transfer: the semantic similarity of tokens
shared across languages. We first analyze our models' hidden representations
and find that overlap of any kind creates embedding spaces that capture
cross-lingual semantic relationships, while this effect is much weaker in
models with disjoint vocabularies. On XNLI and XQuAD, we find that models with
overlap outperform models with disjoint vocabularies, and that transfer
performance generally improves as overlap increases. Overall, our findings
highlight the advantages of token overlap in multilingual models and show that
substantial shared vocabulary remains a beneficial design choice for
multilingual tokenizers.

</details>


### [33] [When Long Helps Short: How Context Length in Supervised Fine-tuning Affects Behavior of Large Language Models](https://arxiv.org/abs/2509.18762)
*Yingming Zheng,Hanqi Li,Kai Yu,Lu Chen*

Main category: cs.CL

TL;DR: 本文研究发现，与长上下文预训练导致短上下文任务性能下降不同，长上下文监督微调（SFT）反而能提升LLM在短上下文任务上的表现。通过分析MHA和FFN组件，发现长上下文SFT促进上下文知识，而短上下文SFT偏好参数知识，混合训练可优化性能。


<details>
  <summary>Details</summary>
Motivation: 随着实际应用对长上下文窗口需求的增加，长上下文数据的持续预训练和SFT成为常见方法。虽然数据长度在持续预训练中的影响已被广泛研究，但其在SFT中的影响尚不清楚。

Method: 系统研究SFT数据长度如何影响LLM在短上下文任务上的行为，解耦分析多头注意力（MHA）和前馈网络（FFN）组件，研究它们的相互作用，并揭示知识偏好偏差。

Result: 发现长上下文SFT能提升短上下文性能，长上下文SFT促进上下文知识，短上下文SFT偏好参数知识，混合训练可缓解这种偏差。

Conclusion: 长上下文SFT对短上下文任务有积极影响，混合训练策略可为LLM微调提供可解释的指导。

Abstract: Large language models (LLMs) have achieved impressive performance across
natural language processing (NLP) tasks. As real-world applications
increasingly demand longer context windows, continued pretraining and
supervised fine-tuning (SFT) on long-context data has become a common approach.
While the effects of data length in continued pretraining have been extensively
studied, their implications for SFT remain unclear. In this work, we
systematically investigate how SFT data length influences LLM behavior on
short-context tasks. Counterintuitively, we find that long-context SFT improves
short-context performance, contrary to the commonly observed degradation from
long-context pretraining. To uncover the underlying mechanisms of this
phenomenon, we first decouple and analyze two key components, Multi-Head
Attention (MHA) and Feed-Forward Network (FFN), and show that both
independently benefit from long-context SFT. We further study their interaction
and reveal a knowledge preference bias: long-context SFT promotes contextual
knowledge, while short-context SFT favors parametric knowledge, making
exclusive reliance on long-context SFT suboptimal. Finally, we demonstrate that
hybrid training mitigates this bias, offering explainable guidance for
fine-tuning LLMs.

</details>


### [34] [Financial Risk Relation Identification through Dual-view Adaptation](https://arxiv.org/abs/2509.18775)
*Wei-Ning Chiu,Yu-Hsiang Wang,Andy Hsiao,Yu-Shiang Huang,Chuan-Ju Wang*

Main category: cs.CL

TL;DR: 提出一种基于10-K文件的系统性方法，通过无监督微调捕捉企业间隐含风险关系，优于现有基线方法


<details>
  <summary>Details</summary>
Motivation: 传统依赖专家判断和手动分析的方法主观性强、劳动密集且难以扩展，需要自动化的企业间风险关系识别方法

Method: 利用自然语言处理技术，基于10-K文件的时序和词汇模式进行无监督微调，开发领域特定的金融编码器，并引入定量风险关系评分

Result: 大量实验表明该方法在多个评估设置下均优于强基线

Conclusion: 该方法为投资组合管理和投资策略等应用提供了透明、可解释的企业间风险关系分析工具

Abstract: A multitude of interconnected risk events -- ranging from regulatory changes
to geopolitical tensions -- can trigger ripple effects across firms.
Identifying inter-firm risk relations is thus crucial for applications like
portfolio management and investment strategy. Traditionally, such assessments
rely on expert judgment and manual analysis, which are, however, subjective,
labor-intensive, and difficult to scale. To address this, we propose a
systematic method for extracting inter-firm risk relations using Form 10-K
filings -- authoritative, standardized financial documents -- as our data
source. Leveraging recent advances in natural language processing, our approach
captures implicit and abstract risk connections through unsupervised
fine-tuning based on chronological and lexical patterns in the filings. This
enables the development of a domain-specific financial encoder with a deeper
contextual understanding and introduces a quantitative risk relation score for
transparency, interpretable analysis. Extensive experiments demonstrate that
our method outperforms strong baselines across multiple evaluation settings.

</details>


### [35] [AECBench: A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field](https://arxiv.org/abs/2509.18776)
*Chen Liang,Zhaoqi Huang,Haofen Wang,Fu Chai,Chunying Yu,Huanhuan Wei,Zhengjie Liu,Yanpeng Li,Hongjun Wang,Ruifeng Luo,Xianzhong Zhao*

Main category: cs.CL

TL;DR: 本文建立了AECBench基准测试，用于评估大语言模型在建筑、工程和施工领域的性能表现，揭示了模型在复杂推理和计算任务上的显著局限性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在AEC领域的应用增加，需要评估其在专业安全关键领域的鲁棒性和可靠性。

Method: 建立包含23个代表性任务的五级认知评估框架，创建4,800个问题的数据集，采用LLM-as-a-Judge方法进行可扩展评估。

Result: 评估9个LLM显示，模型在知识记忆和理解层面表现良好，但在表格知识解释、复杂推理计算和领域文档生成方面存在显著性能缺陷。

Conclusion: 该研究为未来在安全关键工程实践中可靠集成LLM奠定了基础。

Abstract: Large language models (LLMs), as a novel information technology, are seeing
increasing adoption in the Architecture, Engineering, and Construction (AEC)
field. They have shown their potential to streamline processes throughout the
building lifecycle. However, the robustness and reliability of LLMs in such a
specialized and safety-critical domain remain to be evaluated. To address this
challenge, this paper establishes AECBench, a comprehensive benchmark designed
to quantify the strengths and limitations of current LLMs in the AEC domain.
The benchmark defines 23 representative tasks within a five-level
cognition-oriented evaluation framework encompassing Knowledge Memorization,
Understanding, Reasoning, Calculation, and Application. These tasks were
derived from authentic AEC practice, with scope ranging from codes retrieval to
specialized documents generation. Subsequently, a 4,800-question dataset
encompassing diverse formats, including open-ended questions, was crafted
primarily by engineers and validated through a two-round expert review.
Furthermore, an LLM-as-a-Judge approach was introduced to provide a scalable
and consistent methodology for evaluating complex, long-form responses
leveraging expert-derived rubrics. Through the evaluation of nine LLMs, a clear
performance decline across five cognitive levels was revealed. Despite
demonstrating proficiency in foundational tasks at the Knowledge Memorization
and Understanding levels, the models showed significant performance deficits,
particularly in interpreting knowledge from tables in building codes, executing
complex reasoning and calculation, and generating domain-specific documents.
Consequently, this study lays the groundwork for future research and
development aimed at the robust and reliable integration of LLMs into
safety-critical engineering practices.

</details>


### [36] [Beyond the Leaderboard: Understanding Performance Disparities in Large Language Models via Model Diffing](https://arxiv.org/abs/2509.18792)
*Sabri Boughorbel,Fahim Dalvi,Nadir Durrani,Majd Hawasly*

Main category: cs.CL

TL;DR: 本文使用模型差异分析（model diffing）方法，对比Gemma-2-9b-it模型与其SimPO增强变体之间的具体能力差异，发现SimPO主要增强了安全性、多语言能力和指令跟随能力，同时减少了模型自引用和幻觉管理。


<details>
  <summary>Details</summary>
Motivation: 随着微调成为改进大语言模型的主导范式，理解微调过程中的具体变化变得日益重要。传统基准测试往往无法解释为什么一个模型优于另一个模型。

Method: 采用模型差异分析这一机制可解释性方法，使用crosscoders识别和分类两个模型之间的潜在表示差异。

Result: SimPO获得的潜在概念主要增强了安全性机制（+32.8%）、多语言能力（+43.8%）和指令跟随（+151.7%），同时减少了模型自引用（-44.1%）和幻觉管理（-68.5%）的强调。

Conclusion: 模型差异分析能够提供超越排行榜指标的细粒度洞察，将性能差距归因于具体的机制能力，为比较LLMs提供了透明且有针对性框架。

Abstract: As fine-tuning becomes the dominant paradigm for improving large language
models (LLMs), understanding what changes during this process is increasingly
important. Traditional benchmarking often fails to explain why one model
outperforms another. In this work, we use model diffing, a mechanistic
interpretability approach, to analyze the specific capability differences
between Gemma-2-9b-it and a SimPO-enhanced variant. Using crosscoders, we
identify and categorize latent representations that differentiate the two
models. We find that SimPO acquired latent concepts predominantly enhance
safety mechanisms (+32.8%), multilingual capabilities (+43.8%), and
instruction-following (+151.7%), while its additional training also reduces
emphasis on model self-reference (-44.1%) and hallucination management
(-68.5%). Our analysis shows that model diffing can yield fine-grained insights
beyond leaderboard metrics, attributing performance gaps to concrete
mechanistic capabilities. This approach offers a transparent and targeted
framework for comparing LLMs.

</details>


### [37] [MAPEX: A Multi-Agent Pipeline for Keyphrase Extraction](https://arxiv.org/abs/2509.18813)
*Liting Zhang,Shiwan Zhao,Aobo Kong,Qicheng Li*

Main category: cs.CL

TL;DR: MAPEX是一个用于关键词提取的多智能体协作框架，通过动态适应文档长度的双路径策略，在多个基准数据集上显著优于现有无监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督基于提示的LLM方法通常采用单阶段推理管道和统一提示策略，无法充分利用LLMs的推理和生成能力，特别是在处理不同长度文档的复杂关键词提取场景时。

Method: MAPEX引入多智能体协作，包括专家招募、候选提取、主题指导、知识增强和后处理模块。采用双路径策略：短文本使用知识驱动提取，长文本使用主题引导提取。

Result: 在6个基准数据集和3种不同LLM上的实验表明，MAPEX在F1@5指标上平均比最先进的无监督方法高2.44%，比标准LLM基线高4.01%。

Conclusion: MAPEX通过多智能体协作和动态适应策略，显著提升了关键词提取的性能，展现了强大的泛化能力和通用性。

Abstract: Keyphrase extraction is a fundamental task in natural language processing.
However, existing unsupervised prompt-based methods for Large Language Models
(LLMs) often rely on single-stage inference pipelines with uniform prompting,
regardless of document length or LLM backbone. Such one-size-fits-all designs
hinder the full exploitation of LLMs' reasoning and generation capabilities,
especially given the complexity of keyphrase extraction across diverse
scenarios. To address these challenges, we propose MAPEX, the first framework
that introduces multi-agent collaboration into keyphrase extraction. MAPEX
coordinates LLM-based agents through modules for expert recruitment, candidate
extraction, topic guidance, knowledge augmentation, and post-processing. A
dual-path strategy dynamically adapts to document length: knowledge-driven
extraction for short texts and topic-guided extraction for long texts.
Extensive experiments on six benchmark datasets across three different LLMs
demonstrate its strong generalization and universality, outperforming the
state-of-the-art unsupervised method by 2.44\% and standard LLM baselines by
4.01\% in F1@5 on average. Code is available at
https://github.com/NKU-LITI/MAPEX.

</details>


### [38] [Are Smaller Open-Weight LLMs Closing the Gap to Proprietary Models for Biomedical Question Answering?](https://arxiv.org/abs/2509.18843)
*Damian Stachura,Joanna Konieczna,Artur Nowak*

Main category: cs.CL

TL;DR: 本研究比较了开源大语言模型与闭源模型在生物医学问答任务中的表现，发现开源模型在某些情况下甚至能超越闭源模型，特别是在使用集成策略时。


<details>
  <summary>Details</summary>
Motivation: 随着开源大语言模型的快速发展，研究者希望了解小型开源模型是否能够有效替代大型闭源模型，特别是在生物医学问答这一专业领域。

Method: 通过参与BioASQ挑战赛的Task 13B Phase B，使用嵌入距离检索相关片段、上下文学习、结构化输出等技术，并对某些提交采用集成方法来利用不同模型的多样化输出。

Result: 研究结果表明，开源大语言模型与闭源模型表现相当，在某些情况下，特别是应用集成策略时，开源模型甚至超越了闭源模型。

Conclusion: 开源大语言模型在生物医学问答领域具有与闭源模型相媲美的能力，证明了开源模型在该专业领域的实用价值。

Abstract: Open-weight versions of large language models (LLMs) are rapidly advancing,
with state-of-the-art models like DeepSeek-V3 now performing comparably to
proprietary LLMs. This progression raises the question of whether small
open-weight LLMs are capable of effectively replacing larger closed-source
models. We are particularly interested in the context of biomedical
question-answering, a domain we explored by participating in Task 13B Phase B
of the BioASQ challenge. In this work, we compare several open-weight models
against top-performing systems such as GPT-4o, GPT-4.1, Claude 3.5 Sonnet, and
Claude 3.7 Sonnet. To enhance question answering capabilities, we use various
techniques including retrieving the most relevant snippets based on embedding
distance, in-context learning, and structured outputs. For certain submissions,
we utilize ensemble approaches to leverage the diverse outputs generated by
different models for exact-answer questions. Our results demonstrate that
open-weight LLMs are comparable to proprietary ones. In some instances,
open-weight LLMs even surpassed their closed counterparts, particularly when
ensembling strategies were applied. All code is publicly available at
https://github.com/evidenceprime/BioASQ-13b.

</details>


### [39] [Multi-Hierarchical Feature Detection for Large Language Model Generated Text](https://arxiv.org/abs/2509.18862)
*Luyan Zhang,Xinyu Xie*

Main category: cs.CL

TL;DR: 该论文系统评估了多特征集成方法在AI文本检测中的效果，发现尽管理论上多特征应互补，但实际仅带来0.4-0.5%的性能提升，同时计算成本增加4.2倍，表明现代神经语言模型已能有效捕获检测信号。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型技术的快速发展，研究者对多特征方法是否能显著超越单一神经模型在AI文本检测中的性能产生兴趣。直觉上语义、句法和统计特征的结合应提供互补信号，但这一假设尚未在现代LLM生成文本中得到严格验证。

Method: 论文实现了MHFD（多层次特征检测）方法，通过自适应融合集成基于DeBERTa的语义分析、句法解析和统计概率特征。

Result: 实验结果显示，MHFD方法在域内检测中达到89.7%的准确率，在跨域检测中保持84.2%的稳定性能，相比现有方法有0.4-2.6%的适度提升。

Conclusion: 多特征集成带来的收益微乎其微（0.4-0.5%提升），而计算成本显著增加（4.2倍开销），表明现代神经语言模型可能已经高效地捕获了大多数相关检测信号。

Abstract: With the rapid advancement of large language model technology, there is
growing interest in whether multi-feature approaches can significantly improve
AI text detection beyond what single neural models achieve. While intuition
suggests that combining semantic, syntactic, and statistical features should
provide complementary signals, this assumption has not been rigorously tested
with modern LLM-generated text. This paper provides a systematic empirical
investigation of multi-hierarchical feature integration for AI text detection,
specifically testing whether the computational overhead of combining multiple
feature types is justified by performance gains. We implement MHFD
(Multi-Hierarchical Feature Detection), integrating DeBERTa-based semantic
analysis, syntactic parsing, and statistical probability features through
adaptive fusion. Our investigation reveals important negative results: despite
theoretical expectations, multi-feature integration provides minimal benefits
(0.4-0.5% improvement) while incurring substantial computational costs (4.2x
overhead), suggesting that modern neural language models may already capture
most relevant detection signals efficiently. Experimental results on multiple
benchmark datasets demonstrate that the MHFD method achieves 89.7% accuracy in
in-domain detection and maintains 84.2% stable performance in cross-domain
detection, showing modest improvements of 0.4-2.6% over existing methods.

</details>


### [40] [Diversity Boosts AI-Generated Text Detection](https://arxiv.org/abs/2509.18880)
*Advik Raj Basani,Pin-Yu Chen*

Main category: cs.CL

TL;DR: DivEye是一个检测AI生成文本的新框架，通过基于意外值的特征捕捉文本中不可预测性的波动，在多个基准测试中表现优于现有零样本检测器，并具有对抗攻击鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在教育、商业合规、新闻和社交媒体中的滥用增加，检测AI生成文本变得日益重要。现有检测器依赖词汇级似然或不透明的黑盒分类器，难以应对高质量生成文本且缺乏可解释性。

Method: DivEye使用基于意外值的特征来捕捉文本中不可预测性的波动。该方法基于人类写作在词汇和结构不可预测性上比LLM输出具有更丰富变异性的观察，通过一组可解释的统计特征来捕捉这一信号。

Result: DivEye在多个基准测试中比现有零样本检测器性能提升高达33.2%，与微调基线相比具有竞争力。对改写和对抗攻击具有鲁棒性，跨领域和模型泛化能力强，作为辅助信号可将现有检测器性能提升高达18.7%。

Conclusion: DivEye不仅提供检测能力，还能提供关于为何标记文本的可解释性见解，指出节奏不可预测性是LLM检测中一个强大且未被充分探索的信号。

Abstract: Detecting AI-generated text is an increasing necessity to combat misuse of
LLMs in education, business compliance, journalism, and social media, where
synthetic fluency can mask misinformation or deception. While prior detectors
often rely on token-level likelihoods or opaque black-box classifiers, these
approaches struggle against high-quality generations and offer little
interpretability. In this work, we propose DivEye, a novel detection framework
that captures how unpredictability fluctuates across a text using
surprisal-based features. Motivated by the observation that human-authored text
exhibits richer variability in lexical and structural unpredictability than LLM
outputs, DivEye captures this signal through a set of interpretable statistical
features. Our method outperforms existing zero-shot detectors by up to 33.2%
and achieves competitive performance with fine-tuned baselines across multiple
benchmarks. DivEye is robust to paraphrasing and adversarial attacks,
generalizes well across domains and models, and improves the performance of
existing detectors by up to 18.7% when used as an auxiliary signal. Beyond
detection, DivEye provides interpretable insights into why a text is flagged,
pointing to rhythmic unpredictability as a powerful and underexplored signal
for LLM detection.

</details>


### [41] [Extractive Fact Decomposition for Interpretable Natural Language Inference in one Forward Pass](https://arxiv.org/abs/2509.18901)
*Nicholas Popovič,Michael Färber*

Main category: cs.CL

TL;DR: JEDI是一种仅使用编码器架构的模型，联合执行提取式原子事实分解和可解释推理，无需在推理时使用生成模型，在自然语言推理任务中实现了竞争性准确率和更强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖资源密集型的生成式大语言模型进行原子事实分解，这限制了效率和可扩展性。研究者希望开发一种更高效的替代方案。

Method: 提出JEDI编码器架构，联合执行提取式原子事实分解和可解释推理。使用合成理性语料库进行训练，覆盖多个NLI基准。

Result: JEDI在分布内数据上达到竞争性准确率，在分布外数据和对抗性设置中显著提高了鲁棒性，优于仅基于提取式理性监督的模型。

Conclusion: 研究表明，使用仅编码器架构和合成理性语料可以实现NLI任务中的可解释性和鲁棒泛化能力。

Abstract: Recent works in Natural Language Inference (NLI) and related tasks, such as
automated fact-checking, employ atomic fact decomposition to enhance
interpretability and robustness. For this, existing methods rely on
resource-intensive generative large language models (LLMs) to perform
decomposition. We propose JEDI, an encoder-only architecture that jointly
performs extractive atomic fact decomposition and interpretable inference
without requiring generative models during inference. To facilitate training,
we produce a large corpus of synthetic rationales covering multiple NLI
benchmarks. Experimental results demonstrate that JEDI achieves competitive
accuracy in distribution and significantly improves robustness out of
distribution and in adversarial settings over models based solely on extractive
rationale supervision. Our findings show that interpretability and robust
generalization in NLI can be realized using encoder-only architectures and
synthetic rationales. Code and data available at https://jedi.nicpopovic.com

</details>


### [42] [DTW-Align: Bridging the Modality Gap in End-to-End Speech Translation with Dynamic Time Warping Alignment](https://arxiv.org/abs/2509.18987)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 本文提出了一种使用动态时间规整（DTW）来对齐语音和文本嵌入的方法，用于端到端语音翻译（E2E-ST），解决了现有方法需要语言特定对齐工具和相似度搜索不准确的问题。


<details>
  <summary>Details</summary>
Motivation: 端到端语音翻译中语音和文本模态之间的表示差异（模态鸿沟）需要解决。现有方法依赖语言特定的对齐工具或使用不准确的最近邻相似度搜索，限制了方法的通用性和准确性。

Method: 在训练过程中使用动态时间规整（DTW）来对齐语音和文本嵌入，不需要语言特定的对齐工具，能够产生更准确的对齐。

Result: 与之前的工作相比，该方法产生了更准确的对齐，在E2E-ST上取得了可比的结果，同时速度显著更快。在低资源设置下，在6个语言方向中的5个上优于之前的工作。

Conclusion: 基于DTW的方法有效地弥合了E2E-ST中的模态鸿沟，提供了更准确的对齐，具有更好的通用性和在低资源设置下的优越性能。

Abstract: End-to-End Speech Translation (E2E-ST) is the task of translating source
speech directly into target text bypassing the intermediate transcription step.
The representation discrepancy between the speech and text modalities has
motivated research on what is known as bridging the modality gap.
State-of-the-art methods addressed this by aligning speech and text
representations on the word or token level. Unfortunately, this requires an
alignment tool that is not available for all languages. Although this issue has
been addressed by aligning speech and text embeddings using nearest-neighbor
similarity search, it does not lead to accurate alignments. In this work, we
adapt Dynamic Time Warping (DTW) for aligning speech and text embeddings during
training. Our experiments demonstrate the effectiveness of our method in
bridging the modality gap in E2E-ST. Compared to previous work, our method
produces more accurate alignments and achieves comparable E2E-ST results while
being significantly faster. Furthermore, our method outperforms previous work
in low resource settings on 5 out of 6 language directions.

</details>


### [43] [Investigating Test-Time Scaling with Reranking for Machine Translation](https://arxiv.org/abs/2509.19020)
*Shaomu Tan,Ryosuke Mitani,Ritvik Choudhary,Toshiyuki Sekiya*

Main category: cs.CL

TL;DR: 本文首次系统研究了测试时缩放（TTS）在机器翻译中的应用，通过最佳N选择框架在WMT24基准测试上进行实验，发现TTS在高资源语言中能提升翻译质量，小模型通过大N值可匹配大模型性能，但在低资源语言中可能因指标盲点而降低质量。


<details>
  <summary>Details</summary>
Motivation: 模型参数缩放是提升NLP系统性能的主要策略，但计算成本高昂。测试时缩放通过在推理时分配更多计算（生成多个候选并选择最佳）提供了一种替代方案，但在机器翻译领域尚未得到系统研究。

Method: 采用简单实用的最佳N选择框架，在WMT24基准上对6个高资源和1个低资源语言对进行实验，涵盖5种模型规模（3B-72B）和多种TTS计算预算（N最大1024）。

Result: 高资源语言中TTS能通过多种神经MT评估指标提升翻译质量，人类评估确认了这些改进；小模型通过大N值可匹配或超越N=1时的大模型，但计算成本更高；固定计算预算下，大模型通常更高效，低资源情况下TTS可能因指标盲点而降低质量。

Conclusion: TTS为机器翻译提供了一种有效的性能提升策略，特别是在高资源语言中，但在低资源语言中需要谨慎使用，因为可能存在评估指标的盲点问题。

Abstract: Scaling model parameters has become the de facto strategy for improving NLP
systems, but it comes with substantial computational costs. Test-Time Scaling
(TTS) offers an alternative by allocating more computation at inference:
generating multiple candidates and selecting the best. While effective in tasks
such as mathematical reasoning, TTS has not been systematically explored for
machine translation (MT). In this paper, we present the first systematic study
of TTS for MT, investigating a simple but practical best-of-N framework on
WMT24 benchmarks. Our experiments cover six high-resource and one low-resource
language pairs, five model sizes (3B-72B), and various TTS compute budget (N up
to 1024). Our results show that a) For high-resource languages, TTS generally
improves translation quality according to multiple neural MT evaluation
metrics, and our human evaluation confirms these gains; b) Augmenting smaller
models with large $N$ can match or surpass larger models at $N{=}1$ with more
compute cost; c) Under fixed compute budgets, larger models are typically more
efficient, and TTS can degrade quality due to metric blind spots in
low-resource cases.

</details>


### [44] [Charting a Decade of Computational Linguistics in Italy: The CLiC-it Corpus](https://arxiv.org/abs/2509.19033)
*Chiara Alzetta,Serena Auriemma,Alessandro Bondielli,Luca Dini,Chiara Fazzone,Alessio Miaschi,Martina Miliani,Marta Sartor*

Main category: cs.CL

TL;DR: 本文通过分析意大利计算语言学和自然语言处理会议CLiC-it过去10年的论文，追踪了该领域的研究趋势演变，重点关注从词汇语义资源向语言建模和多模态研究的转变。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer大语言模型的出现，计算语言学和自然语言处理领域经历了快速演变，需要系统性地追踪意大利研究社区的研究趋势变化。

Method: 收集CLiC-it会议2014-2024年共10届的论文数据，构建CLiC-it语料库，对论文元数据（作者来源、性别、机构等）和内容主题进行综合分析。

Result: 研究发现研究重点从词汇语义资源转向语言建模和多模态研究，反映了技术发展的影响。

Conclusion: 该研究为意大利和国际研究社区提供了对领域发展趋势的宝贵见解，支持该领域的明智决策和未来方向规划。

Abstract: Over the past decade, Computational Linguistics (CL) and Natural Language
Processing (NLP) have evolved rapidly, especially with the advent of
Transformer-based Large Language Models (LLMs). This shift has transformed
research goals and priorities, from Lexical and Semantic Resources to Language
Modelling and Multimodality. In this study, we track the research trends of the
Italian CL and NLP community through an analysis of the contributions to
CLiC-it, arguably the leading Italian conference in the field. We compile the
proceedings from the first 10 editions of the CLiC-it conference (from 2014 to
2024) into the CLiC-it Corpus, providing a comprehensive analysis of both its
metadata, including author provenance, gender, affiliations, and more, as well
as the content of the papers themselves, which address various topics. Our goal
is to provide the Italian and international research communities with valuable
insights into emerging trends and key developments over time, supporting
informed decisions and future directions in the field.

</details>


### [45] [Pathways of Thoughts: Multi-Directional Thinking for Long-form Personalized Question Answering](https://arxiv.org/abs/2509.19094)
*Alireza Salemi,Cheng Li,Mingyang Zhang,Qiaozhu Mei,Zhuowan Li,Spurthi Amba Hombaiah,Weize Kong,Tao Chen,Hamed Zamani,Michael Bendersky*

Main category: cs.CL

TL;DR: PoT是一种无需微调的推理阶段方法，通过建模LLM的迭代决策过程，动态选择认知操作来探索多种推理轨迹，生成多样化候选回答，并根据用户偏好聚合得到个性化响应。


<details>
  <summary>Details</summary>
Motivation: 个性化对于QA系统适应特定用户信息需求至关重要，但当前面临从长、嘈杂、隐式上下文中推断偏好以及生成正确、上下文适当且符合用户期望的响应等挑战。

Method: 提出思维路径（PoT）方法，将LLM推理建模为迭代决策过程，动态选择推理、修订、个性化和澄清等认知操作，探索多种推理轨迹生成候选响应，然后根据推断的用户偏好聚合重加权。

Result: 在LaMP-QA基准测试中，PoT始终优于竞争基线，相对改进达13.1%。人工评估显示66%的情况下偏好PoT输出，仅15%持平。

Conclusion: PoT通过探索多样化推理路径并基于用户偏好聚合，有效提升了QA系统的个性化能力，无需任务特定微调即可实现显著性能提升。

Abstract: Personalization is essential for adapting question answering (QA) systems to
user-specific information needs, thereby improving both accuracy and user
satisfaction. However, personalized QA remains relatively underexplored due to
challenges such as inferring preferences from long, noisy, and implicit
contexts, and generating responses that are simultaneously correct,
contextually appropriate, and aligned with user expectations and background
knowledge. To address these challenges, we propose Pathways of Thoughts (PoT),
an inference-stage method that applies to any large language model (LLM)
without requiring task-specific fine-tuning. The approach models the reasoning
of an LLM as an iterative decision process, where the model dynamically selects
among cognitive operations such as reasoning, revision, personalization, and
clarification. This enables exploration of multiple reasoning trajectories,
producing diverse candidate responses that capture different perspectives. PoT
then aggregates and reweights these candidates according to inferred user
preferences, yielding a final personalized response that benefits from the
complementary strengths of diverse reasoning paths. Experiments on the LaMP-QA
benchmark for personalized QA show that PoT consistently outperforms
competitive baselines, achieving up to a 13.1% relative improvement. Human
evaluation corroborates these results, with annotators preferring outputs from
PoT in 66% of cases and reporting ties in only 15% of cases.

</details>


### [46] [Are most sentences unique? An empirical examination of Chomskyan claims](https://arxiv.org/abs/2509.19108)
*Hiram Ring*

Main category: cs.CL

TL;DR: 使用NLTK库分析不同语料库中的句子重复率，验证语言中大多数句子是否唯一这一语言学主张


<details>
  <summary>Details</summary>
Motivation: 验证语言学中关于大多数语言表达都是独特的这一常见主张，特别是Pinker和Chomsky提出的观点

Method: 使用NLTK Python库解析不同体裁的语料库，统计每个语料库中的完全字符串匹配数量

Result: 虽然完全独特的句子通常是语料库中的大多数，但这高度受体裁限制，重复句子在任何单个语料库中都不是微不足道的部分

Conclusion: 语言学中关于句子独特性的主张需要根据体裁进行限定，重复句子在语言使用中占有重要地位

Abstract: A repeated claim in linguistics is that the majority of linguistic utterances
are unique. For example, Pinker (1994: 10), summarizing an argument by Noam
Chomsky, states that "virtually every sentence that a person utters or
understands is a brand-new combination of words, appearing for the first time
in the history of the universe." With the increased availability of large
corpora, this is a claim that can be empirically investigated. The current
paper addresses the question by using the NLTK Python library to parse corpora
of different genres, providing counts of exact string matches in each. Results
show that while completely unique sentences are often the majority of corpora,
this is highly constrained by genre, and that duplicate sentences are not an
insignificant part of any individual corpus.

</details>


### [47] [Human-Annotated NER Dataset for the Kyrgyz Language](https://arxiv.org/abs/2509.19109)
*Timur Turatali,Anton Alekseev,Gulira Jumalieva,Gulnara Kabaeva,Sergey Nikolenko*

Main category: cs.CL

TL;DR: KyrgyzNER是首个吉尔吉斯语命名实体识别数据集，包含1,499篇新闻文章、10,900个句子和39,075个实体提及，涵盖27个实体类别。研究评估了多种模型，发现多语言RoBERTa模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 为资源有限的吉尔吉斯语创建首个手动标注的命名实体识别数据集，填补该语言在NLP任务中的空白。

Method: 使用24.KG新闻门户的新闻文章构建数据集，采用传统序列标注方法（如条件随机场）和基于多语言Transformer的先进模型进行评测。

Result: 所有模型在罕见实体类别上都表现困难，但多语言RoBERTa变体在精确率和召回率之间取得了良好平衡，其他多语言模型也获得了可比结果。

Conclusion: 研究强调了使用多语言预训练模型处理资源有限语言的挑战和机遇，未来工作可探索更细粒度的标注方案以提升吉尔吉斯语处理效果。

Abstract: We introduce KyrgyzNER, the first manually annotated named entity recognition
dataset for the Kyrgyz language. Comprising 1,499 news articles from the 24.KG
news portal, the dataset contains 10,900 sentences and 39,075 entity mentions
across 27 named entity classes. We show our annotation scheme, discuss the
challenges encountered in the annotation process, and present the descriptive
statistics. We also evaluate several named entity recognition models, including
traditional sequence labeling approaches based on conditional random fields and
state-of-the-art multilingual transformer-based models fine-tuned on our
dataset. While all models show difficulties with rare entity categories, models
such as the multilingual RoBERTa variant pretrained on a large corpus across
many languages achieve a promising balance between precision and recall. These
findings emphasize both the challenges and opportunities of using multilingual
pretrained models for processing languages with limited resources. Although the
multilingual RoBERTa model performed best, other multilingual models yielded
comparable results. This suggests that future work exploring more granular
annotation schemes may offer deeper insights for Kyrgyz language processing
pipelines evaluation.

</details>


### [48] [Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering](https://arxiv.org/abs/2509.19125)
*Kun Zhu,Lizi Liao,Yuxuan Gu,Lei Huang,Xiaocheng Feng,Bing Qin*

Main category: cs.CL

TL;DR: 提出了一种新的上下文感知层次化分类生成框架，结合LLM引导的多方面编码和动态聚类，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 科学文献快速增长需要高效组织方法，现有分类构建方法缺乏连贯性和粒度。

Method: 利用LLM识别论文关键方面并生成方面特定摘要，然后进行编码和聚类形成层次结构。

Result: 在包含11.6k论文的156个专家构建分类基准上，该方法在连贯性、粒度和可解释性方面达到最优性能。

Conclusion: 该方法为科学文献组织提供了有效的层次化分类生成解决方案，显著优于现有方法。

Abstract: The rapid growth of scientific literature demands efficient methods to
organize and synthesize research findings. Existing taxonomy construction
methods, leveraging unsupervised clustering or direct prompting of large
language models (LLMs), often lack coherence and granularity. We propose a
novel context-aware hierarchical taxonomy generation framework that integrates
LLM-guided multi-aspect encoding with dynamic clustering. Our method leverages
LLMs to identify key aspects of each paper (e.g., methodology, dataset,
evaluation) and generates aspect-specific paper summaries, which are then
encoded and clustered along each aspect to form a coherent hierarchy. In
addition, we introduce a new evaluation benchmark of 156 expert-crafted
taxonomies encompassing 11.6k papers, providing the first naturally annotated
dataset for this task. Experimental results demonstrate that our method
significantly outperforms prior approaches, achieving state-of-the-art
performance in taxonomy coherence, granularity, and interpretability.

</details>


### [49] [Anecdoctoring: Automated Red-Teaming Across Language and Place](https://arxiv.org/abs/2509.19143)
*Alejandro Cuevas,Saloni Dash,Bharat Kumar Nayak,Dan Vann,Madeleine I. G. Daepp*

Main category: cs.CL

TL;DR: 本文提出了一种名为"anecdoctoring"的新型红队评估方法，用于在多语言和多文化背景下自动生成对抗性提示，以应对生成式AI在虚假信息传播方面的风险。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的滥用风险中，虚假信息是主要威胁之一。当前的红队评估数据集主要集中于英语和美国文化，缺乏对多语言和多元文化的覆盖，无法满足全球范围内AI安全评估的需求。

Method: 从英语、西班牙语和印地语的事实核查网站收集虚假信息声明，将这些声明聚类为更广泛的叙事，并使用知识图谱来表征这些聚类，然后利用这些知识图谱增强攻击者LLM的能力。

Result: 相比少样本提示方法，该方法在攻击成功率方面表现更好，并提供了更好的可解释性。

Conclusion: 研究结果强调了需要开发能够全球扩展且基于真实世界对抗滥用的虚假信息缓解措施。

Abstract: Disinformation is among the top risks of generative artificial intelligence
(AI) misuse. Global adoption of generative AI necessitates red-teaming
evaluations (i.e., systematic adversarial probing) that are robust across
diverse languages and cultures, but red-teaming datasets are commonly US- and
English-centric. To address this gap, we propose "anecdoctoring", a novel
red-teaming approach that automatically generates adversarial prompts across
languages and cultures. We collect misinformation claims from fact-checking
websites in three languages (English, Spanish, and Hindi) and two geographies
(US and India). We then cluster individual claims into broader narratives and
characterize the resulting clusters with knowledge graphs, with which we
augment an attacker LLM. Our method produces higher attack success rates and
offers interpretability benefits relative to few-shot prompting. Results
underscore the need for disinformation mitigations that scale globally and are
grounded in real-world adversarial misuse.

</details>


### [50] [Measuring AI "Slop" in Text](https://arxiv.org/abs/2509.19163)
*Chantal Shaib,Tuhin Chakrabarty,Diego Garcia-Olano,Byron C. Wallace*

Main category: cs.CL

TL;DR: 本文提出了AI "slop"（低质量AI生成文本）的分类体系和评估框架，通过专家访谈开发了可解释的评估维度，发现二元"slop"判断具有一定主观性但与连贯性、相关性等潜在维度相关。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对AI "slop"的统一定义和测量方法，需要建立系统的评估框架来分析低质量AI生成文本的特征。

Method: 通过采访NLP、写作和哲学领域的专家，开发了"slop"的分类体系，并使用跨度级标注方法进行文本评估。

Result: 研究发现二元"slop"判断具有主观性，但这些判断与连贯性、相关性等潜在维度存在相关性。提出的框架可用于AI生成文本的检测和偏好评估任务。

Conclusion: 该框架为评估AI生成文本质量提供了新的视角，有助于理解影响质量判断的语言学和风格因素。

Abstract: AI "slop" is an increasingly popular term used to describe low-quality
AI-generated text, but there is currently no agreed upon definition of this
term nor a means to measure its occurrence. In this work, we develop a taxonomy
of "slop" through interviews with experts in NLP, writing, and philosophy, and
propose a set of interpretable dimensions for its assessment in text. Through
span-level annotation, we find that binary "slop" judgments are (somewhat)
subjective, but such determinations nonetheless correlate with latent
dimensions such as coherence and relevance. Our framework can be used to
evaluate AI-generated text in both detection and binary preference tasks,
potentially offering new insights into the linguistic and stylistic factors
that contribute to quality judgments.

</details>


### [51] [Soft Tokens, Hard Truths](https://arxiv.org/abs/2509.19170)
*Natasha Butt,Ariel Kwiatkowski,Ismail Labiad,Julia Kempe,Yann Ollivier*

Main category: cs.CL

TL;DR: 本文首次提出通过强化学习（RL）学习连续思维链（CoT）的可扩展方法，无需从离散CoT蒸馏，使用软令牌和输入嵌入噪声实现高效训练，在数学推理任务上表现优于离散CoT。


<details>
  <summary>Details</summary>
Motivation: 连续令牌比离散令牌具有更强的表达能力，能同时模拟多条推理路径，但现有方法存在训练困难、计算成本高、令牌数量受限等问题。

Method: 使用强化学习训练连续CoT，采用软令牌（令牌混合）和输入嵌入噪声进行探索，计算开销小，可训练数百个令牌的连续CoT。

Result: 在8B参数模型上的数学推理基准测试中，连续CoT在pass@1上匹配离散CoT，在pass@32上超越，显示出更强的多样性；最佳方案是训练用连续CoT，推理用离散令牌。

Conclusion: 连续CoT RL训练方法可扩展性强，能保持基础模型在域外任务上的预测能力，为模型提供更温和的调整。

Abstract: The use of continuous instead of discrete tokens during the Chain-of-Thought
(CoT) phase of reasoning LLMs has garnered attention recently, based on the
intuition that a continuous mixture of discrete tokens could simulate a
superposition of several reasoning paths simultaneously. Theoretical results
have formally proven that continuous tokens have much greater expressivity and
can solve specific problems more efficiently. However, practical use of
continuous tokens has been limited by strong training difficulties: previous
works either just use continuous tokens at inference time on a pre-trained
discrete-token model, or must distill the continuous CoT from ground-truth
discrete CoTs and face computational costs that limit the CoT to very few
tokens.
  This is the first work introducing a scalable method to learn continuous CoTs
via reinforcement learning (RL), without distilling from reference discrete
CoTs. We use "soft" tokens: mixtures of tokens together with noise on the input
embedding to provide RL exploration. Computational overhead is minimal,
enabling us to learn continuous CoTs with hundreds of tokens. On math reasoning
benchmarks with Llama and Qwen models up to 8B, training with continuous CoTs
match discrete-token CoTs for pass@1 and surpass them for pass@32, showing
greater CoT diversity. In systematic comparisons, the best-performing scenario
is to train with continuous CoT tokens then use discrete tokens for inference,
meaning the "soft" models can be deployed in a standard way. Finally, we show
continuous CoT RL training better preserves the predictions of the base model
on out-of-domain tasks, thus providing a softer touch to the base model.

</details>


### [52] [Online Process Reward Leanring for Agentic Reinforcement Learning](https://arxiv.org/abs/2509.19199)
*Xiaoqian Liu,Ke Wang,Yuchuan Wu,Fei Huang,Yongbin Li,Junge Zhang,Jianbin Jiao*

Main category: cs.CL

TL;DR: OPRL是一种用于智能体强化学习的通用信用分配策略，通过交替优化隐式过程奖励模型和智能体策略，将轨迹偏好转化为隐式步骤奖励，解决了稀疏和不可验证奖励环境中的时间信用分配问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型作为自主智能体在交互环境中进行长期推理和行动时，稀疏且有时不可验证的奖励使得时间信用分配极具挑战性。现有方法存在标注偏差、奖励攻击、高方差或状态重叠稀少等问题。

Method: OPRL交替优化隐式过程奖励模型和智能体策略，通过基于轨迹的DPO目标将轨迹偏好转化为隐式步骤奖励，然后结合结果奖励计算步骤级优势进行策略更新，形成自我强化的循环。

Result: 在WebShop、VisualSokoban和SOTOPIA等三个不同的智能体基准测试中，OPRL表现出优于前沿LLM和强RL基线的性能，实现了最先进的结果，具有更高的样本效率和更低的训练方差。

Conclusion: OPRL通过理论保证和实证验证，展示了在现实世界场景中智能体学习的潜力，能够实现高效探索并使用更少的动作。

Abstract: Large language models (LLMs) are increasingly trained with reinforcement
learning (RL) as autonomous agents that reason and act over long horizons in
interactive environments.
  However, sparse and sometimes unverifiable rewards make temporal credit
assignment extremely challenging.
  Recent work attempts to integrate process supervision into agent learning but
suffers from biased annotation, reward hacking, high-variance from overly
fine-grained signals or failtures when state overlap is rare.
  We therefore introduce Online Process Reward Learning (OPRL), a general
credit-assignment strategy for agentic RL that integrates seamlessly with
standard on-policy algorithms without relying on additional rollouts or
explicit step labels.
  In OPRL, we optimize an implicit process reward model (PRM) alternately with
the agent's policy to transform trajectory preferences into implicit step
rewards through a trajectory-based DPO objective.
  These step rewards are then used to compute step-level advantages, which are
combined with episode-level advantages from outcome rewards for policy update,
creating a self-reinforcing loop.
  Theoretical findings guarantee that the learned step rewards are consistent
with trajectory preferences and act as potential-based shaping rewards,
providing bounded gradients to stabilize training.
  Empirically, we evaluate OPRL on three distinct agent benmarks, including
WebShop and VisualSokoban, as well as open-ended social interactions with
unverfiable rewards in SOTOPIA.
  Crucially, OPRL shows superior performance over frontier LLMs and strong RL
baselines across domains, achieving state-of-the-art results with higher
sample-efficiency and lower variance during training.
  Further analysis also demonstrates the efficient exploration by OPRL using
fewer actions, underscoring its potential for agentic learning in real-world
scenarios.

</details>


### [53] [Steering Multimodal Large Language Models Decoding for Context-Aware Safety](https://arxiv.org/abs/2509.19212)
*Zheyuan Liu,Zhangchen Xu,Guangyao Dou,Xiangchi Yuan,Zhaoxuan Tan,Radha Poovendran,Meng Jiang*

Main category: cs.CL

TL;DR: SafeCoDe是一个轻量级、模型无关的解码框架，通过对比解码和全局感知令牌调制策略，动态调整多模态大语言模型的安全决策，平衡过度敏感和敏感不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在安全决策方面存在平衡问题，要么过度敏感（拒绝良性查询），要么敏感不足（错过视觉风险检测），需要一种能根据多模态上下文动态调整安全决策的方法。

Method: SafeCoDe采用两阶段方法：1）对比解码机制，通过对比真实图像和高斯噪声图像来突出对视觉上下文敏感的令牌；2）全局感知令牌调制策略，将场景级推理与令牌级调整相结合，根据预测的安全判断自适应调整拒绝行为。

Result: 在多种MLLM架构和安全基准上的广泛实验表明，SafeCoDe能持续改进上下文敏感的拒绝行为，同时保持模型的有用性。

Conclusion: SafeCoDe有效解决了多模态大语言模型在安全对齐方面的局限性，提供了一种平衡安全性和有用性的实用解决方案。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly deployed in
real-world applications, yet their ability to make context-aware safety
decisions remains limited. Existing methods often fail to balance
oversensitivity (unjustified refusals of benign queries) and undersensitivity
(missed detection of visually grounded risks), leaving a persistent gap in
safety alignment. To address this issue, we introduce Safety-aware Contrastive
Decoding (SafeCoDe), a lightweight and model-agnostic decoding framework that
dynamically adjusts token generation based on multimodal context. SafeCoDe
operates in two stages: (1) a contrastive decoding mechanism that highlights
tokens sensitive to visual context by contrasting real and Gaussian-noised
images, and (2) a global-aware token modulation strategy that integrates
scene-level reasoning with token-level adjustment to adapt refusals according
to the predicted safety verdict. Extensive experiments across diverse MLLM
architectures and safety benchmarks, covering undersensitivity,
oversensitivity, and general safety evaluations, show that SafeCoDe
consistently improves context-sensitive refusal behaviors while preserving
model helpfulness.

</details>


### [54] [Systematic Comparative Analysis of Large Pretrained Language Models on Contextualized Medication Event Extraction](https://arxiv.org/abs/2509.19224)
*Tariq Abdul-Quddoos,Xishuang Dong,Lijun Qian*

Main category: cs.CL

TL;DR: 该研究比较了多种预训练注意力模型在电子健康记录信息提取任务上的表现，发现临床数据预训练的模型在检测药物和药物事件方面更有效，但通用领域预训练的Bert Base在药物相关事件上下文分类方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 基于注意力的模型已成为临床笔记自然语言处理的主要方法，但需要比较不同预训练模型在电子健康记录信息提取任务上的性能差异。

Method: 使用哈佛医学院2022年n2c2挑战赛Track 1的Contextualized Medication Event Dataset (CMED)，对Bert Base、BioBert、Bio+Clinical Bert变体、RoBerta和Clinical Longformer等预训练模型进行微调，执行药物提取、医疗事件检测和多维药物事件上下文分类任务。

Result: 临床数据预训练的模型在检测药物和药物事件方面表现更好，但Bert Base在药物相关事件上下文分类方面取得了最佳效果。

Conclusion: 不同预训练模型在不同医疗NLP任务上各有优势，临床数据预训练的模型更适合检测任务，而通用领域预训练的模型在分类任务上可能表现更好。

Abstract: Attention-based models have become the leading approach in modeling medical
language for Natural Language Processing (NLP) in clinical notes. These models
outperform traditional techniques by effectively capturing contextual rep-
resentations of language. In this research a comparative analysis is done
amongst pre- trained attention based models namely Bert Base, BioBert, two
variations of Bio+Clinical Bert, RoBerta, and Clinical Long- former on task
related to Electronic Health Record (EHR) information extraction. The tasks
from Track 1 of Harvard Medical School's 2022 National Clinical NLP Challenges
(n2c2) are considered for this comparison, with the Contextualized Medication
Event Dataset (CMED) given for these task. CMED is a dataset of unstructured
EHRs and annotated notes that contain task relevant information about the EHRs.
The goal of the challenge is to develop effective solutions for extracting
contextual information related to patient medication events from EHRs using
data driven methods. Each pre-trained model is fine-tuned and applied on CMED
to perform medication extraction, medical event detection, and
multi-dimensional medication event context classification. Pro- cessing methods
are also detailed for breaking down EHRs for compatibility with the applied
models. Performance analysis has been carried out using a script based on
constructing medical terms from the evaluation portion of CMED with metrics
including recall, precision, and F1-Score. The results demonstrate that models
pre-trained on clinical data are more effective in detecting medication and
medication events, but Bert Base, pre- trained on general domain data showed to
be the most effective for classifying the context of events related to
medications.

</details>


### [55] [CompLLM: Compression for Long Context Q&A](https://arxiv.org/abs/2509.19228)
*Gabriele Berton,Jayakrishnan Unnikrishnan,Son Tran,Mubarak Shah*

Main category: cs.CL

TL;DR: CompLLM是一种针对长上下文处理的软压缩技术，通过将上下文分段独立压缩，实现线性复杂度、可扩展性和可重用性，显著提升推理速度并减少KV缓存。


<details>
  <summary>Details</summary>
Motivation: 现有软上下文压缩方法将整个上下文作为单一单元压缩，导致二次压缩复杂度且无法在重叠上下文的查询间重用计算，限制了实际部署。

Method: 将上下文划分为多个段，对每个段独立进行压缩，而不是整体处理。这种设计使压缩步骤随上下文长度线性扩展，支持模型从短序列训练泛化到长序列，并允许压缩段缓存重用。

Result: 在2倍压缩率下，CompLLM在高上下文长度时将首token时间(TTFT)加速最高4倍，KV缓存大小减少50%。性能与未压缩上下文相当，在超长序列上甚至更优。

Conclusion: CompLLM通过分段压缩设计实现了高效、可扩展和可重用的长上下文处理，展示了其在实际部署中的有效性和实用性。

Abstract: Large Language Models (LLMs) face significant computational challenges when
processing long contexts due to the quadratic complexity of self-attention.
While soft context compression methods, which map input text to smaller latent
representations, have shown promise, their real-world adoption is limited.
Existing techniques typically compress the context as a single unit, which
leads to quadratic compression complexity and an inability to reuse
computations across queries with overlapping contexts. In this work, we
introduce CompLLM, a soft compression technique designed for practical
deployment. Instead of processing the context holistically, CompLLM divides it
into segments and compresses each one independently. This simple design choice
yields three critical properties: efficiency, as the compression step scales
linearly with the context length; scalability, enabling models trained on short
sequences (e.g., 1k tokens) to generalize to contexts of 100k tokens; and
reusability, allowing compressed segments to be cached and reused across
different queries. Our experiments show that with a 2x compression rate, at
high context lengths CompLLM speeds up Time To First Token (TTFT) by up to 4x
and reduces the KV cache size by 50%. Furthermore, CompLLM achieves performance
comparable to that obtained with the uncompressed context, and even surpasses
it on very long sequences, demonstrating its effectiveness and practical
utility.

</details>


### [56] [Reinforcement Learning on Pre-Training Data](https://arxiv.org/abs/2509.19249)
*Siheng Li,Kejiao Li,Zenan Xu,Guanhua Huang,Evander Yang,Kun Li,Haoyuan Wu,Jiajia Wu,Zihao Zheng,Chenchen Zhang,Kun Shi,Kyrierl Deng,Qi Yi,Ruibin Xiong,Tingqiang Xu,Yuhao Jiang,Jianfeng Yan,Yuyuan Zeng,Guanghui Xu,Jinbao Xue,Zhijiang Xu,Zheng Fang,Shuai Li,Qibin Liu,Xiaoxue Li,Zhuoyu Li,Yangyu Tao,Fei Gao,Cheng Jiang,Bo Chao Wang,Kai Liu,Jianchen Zhu,Wai Lam,Wayyt Wang,Bo Zhou,Di Wang*

Main category: cs.CL

TL;DR: RLPT是一种新的训练时扩展范式，通过强化学习在预训练数据上自主探索有意义的轨迹来优化LLMs，无需人工标注奖励信号。


<details>
  <summary>Details</summary>
Motivation: 解决计算资源指数级增长与高质量文本数据有限增长之间的差距，突破传统LLM扩展方法的限制。

Method: 采用下一段推理目标，根据模型在给定前文条件下准确预测后续文本段的能力构建奖励信号，实现预训练数据上的强化学习扩展。

Result: 在多个模型和基准测试中验证有效性，Qwen3-4B-Base在MMLU、MMLU-Pro等基准上获得3.0-8.1的绝对提升，显示出良好的扩展潜力。

Conclusion: RLPT扩展了LLMs的推理边界，为RLVR提供坚实基础，具有持续增益的强潜力。

Abstract: The growing disparity between the exponential scaling of computational
resources and the finite growth of high-quality text data now constrains
conventional scaling approaches for large language models (LLMs). To address
this challenge, we introduce Reinforcement Learning on Pre-Training data
(RLPT), a new training-time scaling paradigm for optimizing LLMs. In contrast
to prior approaches that scale training primarily through supervised learning,
RLPT enables the policy to autonomously explore meaningful trajectories to
learn from pre-training data and improve its capability through reinforcement
learning (RL). While existing RL strategies such as reinforcement learning from
human feedback (RLHF) and reinforcement learning with verifiable rewards (RLVR)
rely on human annotation for reward construction, RLPT eliminates this
dependency by deriving reward signals directly from pre-training data.
Specifically, it adopts a next-segment reasoning objective, rewarding the
policy for accurately predicting subsequent text segments conditioned on the
preceding context. This formulation allows RL to be scaled on pre-training
data, encouraging the exploration of richer trajectories across broader
contexts and thereby fostering more generalizable reasoning skills. Extensive
experiments on both general-domain and mathematical reasoning benchmarks across
multiple models validate the effectiveness of RLPT. For example, when applied
to Qwen3-4B-Base, RLPT yields absolute improvements of $3.0$, $5.1$, $8.1$,
$6.0$, $6.6$, and $5.3$ on MMLU, MMLU-Pro, GPQA-Diamond, KOR-Bench, AIME24, and
AIME25, respectively. The results further demonstrate favorable scaling
behavior, suggesting strong potential for continued gains with more compute. In
addition, RLPT provides a solid foundation, extending the reasoning boundaries
of LLMs and enhancing RLVR performance.

</details>


### [57] [Extracting Conceptual Spaces from LLMs Using Prototype Embeddings](https://arxiv.org/abs/2509.19269)
*Nitesh Kumar,Usashi Chatterjee,Steven Schockaert*

Main category: cs.CL

TL;DR: 本文提出了一种从大型语言模型中提取概念空间的方法，通过使用原型描述来编码特征，并对LLM进行微调以对齐原型嵌入与概念空间维度。


<details>
  <summary>Details</summary>
Motivation: 概念空间在认知科学中被广泛使用，并有望成为可解释AI的基石，但目前缺乏从LLM中提取概念空间的实用方法。

Method: 通过嵌入原型描述来编码特征，并对LLM进行微调，使原型嵌入与概念空间维度对齐。

Result: 实证分析表明该方法非常有效。

Conclusion: 该方法为从LLM中提取概念空间提供了一种有效的解决方案。

Abstract: Conceptual spaces represent entities and concepts using cognitively
meaningful dimensions, typically referring to perceptual features. Such
representations are widely used in cognitive science and have the potential to
serve as a cornerstone for explainable AI. Unfortunately, they have proven
notoriously difficult to learn, although recent LLMs appear to capture the
required perceptual features to a remarkable extent. Nonetheless, practical
methods for extracting the corresponding conceptual spaces are currently still
lacking. While various methods exist for extracting embeddings from LLMs,
extracting conceptual spaces also requires us to encode the underlying
features. In this paper, we propose a strategy in which features (e.g.
sweetness) are encoded by embedding the description of a corresponding
prototype (e.g. a very sweet food). To improve this strategy, we fine-tune the
LLM to align the prototype embeddings with the corresponding conceptual space
dimensions. Our empirical analysis finds this approach to be highly effective.

</details>


### [58] [SloPalSpeech: A 2,8000-Hour Slovak Speech Corpus from Parliamentary Data](https://arxiv.org/abs/2509.19270)
*Erik Božík,Marek Šuppa*

Main category: cs.CL

TL;DR: 该论文介绍了SloPalSpeech——一个包含2,806小时斯洛伐克议会语音的新大规模ASR数据集，通过微调Whisper模型显著降低了斯洛伐克语识别的词错误率。


<details>
  <summary>Details</summary>
Motivation: 解决斯洛伐克语等低资源语言自动语音识别训练数据稀缺的问题。

Method: 开发了稳健的处理流程来对齐和分割长格式录音，创建了30秒音频-文本对数据集，并使用该数据集微调了多个OpenAI Whisper模型。

Result: 微调后的Whisper-small模型词错误率降低了高达70%，接近更大的Whisper-large-v3模型的基线性能。

Conclusion: 公开发布完整的SloPalSpeech数据集、分割后的转录文本（6000万字）和所有微调模型，以促进低资源语音识别的未来研究。

Abstract: Automatic Speech Recognition (ASR) for low-resource languages like Slovak is
hindered by the scarcity of training data. To address this, we introduce
SloPalSpeech, a new, large-scale Slovak ASR dataset containing 2,806 hours of
speech from parliamentary proceedings. We developed a robust processing
pipeline to align and segment long-form recordings into clean, 30-second
audio-transcript pairs suitable for model training. We use this dataset to
fine-tune several OpenAI Whisper models (small, medium, large-v3, and
large-v3-turbo), achieving significant Word Error Rate (WER) reductions on
standard Slovak benchmarks like Common Voice and FLEURS. For instance, the
fine-tuned Whisper-small model's WER dropped by up to 70\%, approaching the
baseline performance of the much larger Whisper-large-v3 model. To foster
future research in low-resource speech recognition, we publicly release the
complete SloPalSpeech dataset, the fully segmented transcripts (60 million
words), and all our fine-tuned models.

</details>


### [59] [WolBanking77: Wolof Banking Speech Intent Classification Dataset](https://arxiv.org/abs/2509.19271)
*Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione*

Main category: cs.CL

TL;DR: 本文发布了WolBanking77数据集，这是一个沃洛夫语的意图分类数据集，包含9,791个银行领域文本句子和超过4小时的语音数据，旨在解决低资源语言意图分类的研究空白。


<details>
  <summary>Details</summary>
Motivation: 现有意图分类研究主要关注高资源语言，导致低资源语言和文盲率较高地区（如塞内加尔的沃洛夫语）存在研究空白。沃洛夫语在西非地区有超过1000万使用者，但缺乏相关数据集。

Method: 构建了WolBanking77数据集，包含文本和语音数据。在数据集上测试了多种基线模型，包括文本和语音的最先进模型，并进行了详细的数据内容分析。

Result: 实验结果在该数据集上表现良好，报告了NLP模型的F1分数和ASR模型的词错误率指标，以及模型间的比较结果。

Conclusion: 该数据集为沃洛夫语意图分类研究提供了重要资源，作者计划共享数据集、进行维护更新并发布开源代码。

Abstract: Intent classification models have made a lot of progress in recent years.
However, previous studies primarily focus on high-resource languages datasets,
which results in a gap for low-resource languages and for regions with a high
rate of illiterate people where languages are more spoken than read or written.
This is the case in Senegal, for example, where Wolof is spoken by around 90\%
of the population, with an illiteracy rate of 42\% for the country. Wolof is
actually spoken by more than 10 million people in West African region. To
tackle such limitations, we release a Wolof Intent Classification Dataset
(WolBanking77), for academic research in intent classification. WolBanking77
currently contains 9,791 text sentences in the banking domain and more than 4
hours of spoken sentences. Experiments on various baselines are conducted in
this work, including text and voice state-of-the-art models. The results are
very promising on this current dataset. This paper also provides detailed
analyses of the contents of the data. We report baseline f1-score and word
error rate metrics respectively on NLP and ASR models trained on WolBanking77
dataset and also comparisons between models. We plan to share and conduct
dataset maintenance, updates and to release open-source code.

</details>


### [60] [DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture](https://arxiv.org/abs/2509.19274)
*Arijit Maji,Raghvendra Kumar,Akash Ghosh,Anushka,Nemil Shah,Abhilekh Borah,Vanshika Shah,Nishant Mishra,Sriparna Saha*

Main category: cs.CL

TL;DR: DRISHTIKON是一个专门针对印度文化的多模态多语言基准测试，用于评估生成式AI系统的文化理解能力，包含15种语言、64,000多个文本-图像对。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试多为通用性或全球性，缺乏对特定文化（特别是印度文化）的深度覆盖，需要专门的文化理解评估工具。

Method: 构建包含印度所有邦和联邦属地的多模态数据集，涵盖节日、服饰、美食、艺术形式等文化主题，并在零样本和思维链设置下评估各种视觉语言模型。

Result: 当前模型在处理文化相关的多模态输入时存在明显局限，特别是在低资源语言和较少记录的传统文化方面表现不佳。

Conclusion: DRISHTIKON填补了包容性AI研究的重要空白，为推进具有文化意识和多模态能力的语言技术提供了强大的测试平台。

Abstract: We introduce DRISHTIKON, a first-of-its-kind multimodal and multilingual
benchmark centered exclusively on Indian culture, designed to evaluate the
cultural understanding of generative AI systems. Unlike existing benchmarks
with a generic or global scope, DRISHTIKON offers deep, fine-grained coverage
across India's diverse regions, spanning 15 languages, covering all states and
union territories, and incorporating over 64,000 aligned text-image pairs. The
dataset captures rich cultural themes including festivals, attire, cuisines,
art forms, and historical heritage amongst many more. We evaluate a wide range
of vision-language models (VLMs), including open-source small and large models,
proprietary systems, reasoning-specialized VLMs, and Indic-focused models,
across zero-shot and chain-of-thought settings. Our results expose key
limitations in current models' ability to reason over culturally grounded,
multimodal inputs, particularly for low-resource languages and less-documented
traditions. DRISHTIKON fills a vital gap in inclusive AI research, offering a
robust testbed to advance culturally aware, multimodally competent language
technologies.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [61] [A Cost-Benefit Analysis of On-Premise Large Language Model Deployment: Breaking Even with Commercial LLM Services](https://arxiv.org/abs/2509.18101)
*Guanzhong Pan,Haibo Wang*

Main category: cs.AI

TL;DR: 本文提出了一个成本效益分析框架，帮助组织评估本地部署开源LLM与商业订阅服务的经济可行性


<details>
  <summary>Details</summary>
Motivation: 随着LLM的广泛应用，组织面临选择商业订阅服务还是本地部署的决策。商业云服务虽然易于使用和扩展，但存在数据隐私、供应商锁定和长期成本等问题，这推动了本地开源模型部署的需求

Method: 构建成本效益分析框架，考虑硬件需求、运营费用和开源模型性能基准，将本地部署总成本与主要云服务商的订阅费用进行比较

Result: 研究提供了基于使用水平和性能需求的盈亏平衡点估计

Conclusion: 研究结果为组织制定LLM战略提供了实用的决策框架

Abstract: Large language models (LLMs) are becoming increasingly widespread.
Organizations that want to use AI for productivity now face an important
decision. They can subscribe to commercial LLM services or deploy models on
their own infrastructure. Cloud services from providers such as OpenAI,
Anthropic, and Google are attractive because they provide easy access to
state-of-the-art models and are easy to scale. However, concerns about data
privacy, the difficulty of switching service providers, and long-term operating
costs have driven interest in local deployment of open-source models. This
paper presents a cost-benefit analysis framework to help organizations
determine when on-premise LLM deployment becomes economically viable compared
to commercial subscription services. We consider the hardware requirements,
operational expenses, and performance benchmarks of the latest open-source
models, including Qwen, Llama, Mistral, and etc. Then we compare the total cost
of deploying these models locally with the major cloud providers subscription
fee. Our findings provide an estimated breakeven point based on usage levels
and performance needs. These results give organizations a practical framework
for planning their LLM strategies.

</details>


### [62] [SPADE: A Large Language Model Framework for Soil Moisture Pattern Recognition and Anomaly Detection in Precision Agriculture](https://arxiv.org/abs/2509.18123)
*Yeonju Lee,Rui Qi Chen,Joseph Oboamah,Po Nien Su,Wei-zhen Liang,Yeyin Shi,Lu Gan,Yongsheng Chen,Xin Qiao,Jing Li*

Main category: cs.AI

TL;DR: SPADE是一个利用大语言模型分析土壤湿度时间序列数据的框架，能够检测灌溉模式和异常，无需特定任务标注或微调。


<details>
  <summary>Details</summary>
Motivation: 现有土壤湿度分析方法要么依赖基于阈值的规则，要么需要大量数据的机器学习模型，存在适应性和可解释性限制。

Method: 使用ChatGPT-4.1，将时间序列数据转换为文本表示，设计领域知识提示模板，进行零样本分析。

Result: 在真实农场数据上测试，SPADE在异常检测方面优于现有方法，具有更高的召回率和F1分数，并能准确检测灌溉事件。

Conclusion: LLMs可作为精准农业的可扩展、适应性工具，整合定性知识和数据驱动推理，提供可操作的土壤湿度监测和灌溉调度见解。

Abstract: Accurate interpretation of soil moisture patterns is critical for irrigation
scheduling and crop management, yet existing approaches for soil moisture
time-series analysis either rely on threshold-based rules or data-hungry
machine learning or deep learning models that are limited in adaptability and
interpretability. In this study, we introduce SPADE (Soil moisture Pattern and
Anomaly DEtection), an integrated framework that leverages large language
models (LLMs) to jointly detect irrigation patterns and anomalies in soil
moisture time-series data. SPADE utilizes ChatGPT-4.1 for its advanced
reasoning and instruction-following capabilities, enabling zero-shot analysis
without requiring task-specific annotation or fine-tuning. By converting
time-series data into a textual representation and designing domain-informed
prompt templates, SPADE identifies irrigation events, estimates net irrigation
gains, detects, classifies anomalies, and produces structured, interpretable
reports. Experiments were conducted on real-world soil moisture sensor data
from commercial and experimental farms cultivating multiple crops across the
United States. Results demonstrate that SPADE outperforms the existing method
in anomaly detection, achieving higher recall and F1 scores and accurately
classifying anomaly types. Furthermore, SPADE achieved high precision and
recall in detecting irrigation events, indicating its strong capability to
capture irrigation patterns accurately. SPADE's reports provide
interpretability and usability of soil moisture analytics. This study
highlights the potential of LLMs as scalable, adaptable tools for precision
agriculture, which is capable of integrating qualitative knowledge and
data-driven reasoning to produce actionable insights for accurate soil moisture
monitoring and improved irrigation scheduling from soil moisture time-series
data.

</details>


### [63] [Position Paper: Integrating Explainability and Uncertainty Estimation in Medical AI](https://arxiv.org/abs/2509.18132)
*Xiuyi Fan*

Main category: cs.AI

TL;DR: 本文提出可解释不确定性估计(XUE)框架，将可解释性与不确定性量化相结合，以增强医疗AI的可信度和可用性。


<details>
  <summary>Details</summary>
Motivation: 当前医疗AI系统未能以符合临床推理的方式明确量化或传达不确定性，现有可解释AI(XAI)工作缺乏对预测置信度的捕捉，而不确定性估计(UE)技术又缺乏直观解释，这种脱节限制了AI在医学领域的应用。

Method: 系统地将医学不确定性映射到AI不确定性概念，识别XUE实施的关键挑战，提出多模态不确定性量化、模型无关可视化技术和不确定性感知决策支持系统等技术方向。

Result: 建立了XUE框架的理论基础，明确了实现有效XUE的指导原则，为开发与真实世界临床复杂性相符的AI系统奠定了基础。

Conclusion: 这项工作通过桥接可解释性和不确定性，为开发可信赖的医疗AI做出贡献，强调了AI系统不仅需要生成可靠预测，还需要以临床有意义的方式表达置信水平的重要性。

Abstract: Uncertainty is a fundamental challenge in medical practice, but current
medical AI systems fail to explicitly quantify or communicate uncertainty in a
way that aligns with clinical reasoning. Existing XAI works focus on
interpreting model predictions but do not capture the confidence or reliability
of these predictions. Conversely, uncertainty estimation (UE) techniques
provide confidence measures but lack intuitive explanations. The disconnect
between these two areas limits AI adoption in medicine. To address this gap, we
propose Explainable Uncertainty Estimation (XUE) that integrates explainability
with uncertainty quantification to enhance trust and usability in medical AI.
We systematically map medical uncertainty to AI uncertainty concepts and
identify key challenges in implementing XUE. We outline technical directions
for advancing XUE, including multimodal uncertainty quantification,
model-agnostic visualization techniques, and uncertainty-aware decision support
systems. Lastly, we propose guiding principles to ensure effective XUE
realisation. Our analysis highlights the need for AI systems that not only
generate reliable predictions but also articulate confidence levels in a
clinically meaningful way. This work contributes to the development of
trustworthy medical AI by bridging explainability and uncertainty, paving the
way for AI systems that are aligned with real-world clinical complexities.

</details>


### [64] [HSGM: Hierarchical Segment-Graph Memory for Scalable Long-Text Semantics](https://arxiv.org/abs/2509.18168)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: HSGM是一种分层分段图内存框架，通过将长文档分解为有意义的段落，构建局部语义图并提取摘要节点来形成全局图内存，显著降低了长文档语义解析的计算复杂度和内存需求。


<details>
  <summary>Details</summary>
Motivation: 解决长文档语义解析中由于二次增长的计算复杂度和内存需求带来的挑战，实现可扩展的、准确的超长文本语义建模。

Method: 将输入文档分解为M个段落，在每个段落上构建局部语义图，提取紧凑的摘要节点形成全局图内存，支持增量更新和分层查询处理。

Result: 在三个基准测试中，HSGM实现了2-4倍的推理加速，峰值内存减少超过60%，同时保持基线准确率的95%以上。

Conclusion: HSGM为超长文本提供了可扩展、准确的语义建模方法，支持实时和资源受限的NLP应用。

Abstract: Semantic parsing of long documents remains challenging due to quadratic
growth in pairwise composition and memory requirements. We introduce
\textbf{Hierarchical Segment-Graph Memory (HSGM)}, a novel framework that
decomposes an input of length $N$ into $M$ meaningful segments, constructs
\emph{Local Semantic Graphs} on each segment, and extracts compact
\emph{summary nodes} to form a \emph{Global Graph Memory}. HSGM supports
\emph{incremental updates} -- only newly arrived segments incur local graph
construction and summary-node integration -- while \emph{Hierarchical Query
Processing} locates relevant segments via top-$K$ retrieval over summary nodes
and then performs fine-grained reasoning within their local graphs.
  Theoretically, HSGM reduces worst-case complexity from $O(N^2)$ to
$O\!\left(N\,k + (N/k)^2\right)$, with segment size $k \ll N$, and we derive
Frobenius-norm bounds on the approximation error introduced by node
summarization and sparsification thresholds. Empirically, on three benchmarks
-- long-document AMR parsing, segment-level semantic role labeling (OntoNotes),
and legal event extraction -- HSGM achieves \emph{2--4$\times$ inference
speedup}, \emph{$>60\%$ reduction} in peak memory, and \emph{$\ge 95\%$} of
baseline accuracy. Our approach unlocks scalable, accurate semantic modeling
for ultra-long texts, enabling real-time and resource-constrained NLP
applications.

</details>


### [65] [Foam-Agent: An End-to-End Composable Multi-Agent Framework for Automating CFD Simulation in OpenFOAM](https://arxiv.org/abs/2509.18178)
*Ling Yue,Nithin Somasekharan,Tingwen Zhang,Yadi Cao,Shaowu Pan*

Main category: cs.AI

TL;DR: Foam-Agent是一个多代理框架，通过自然语言提示自动化整个OpenFOAM工作流程，显著降低了CFD仿真的使用门槛。


<details>
  <summary>Details</summary>
Motivation: 解决CFD仿真学习曲线陡峭和手动设置复杂的问题，降低工程仿真的专业门槛。

Method: 采用多代理框架，包含网格生成代理、HPC脚本自动生成、后处理可视化等功能，使用MCP协议实现可组合服务架构，通过分层多索引RAG实现高精度配置生成。

Result: 在110个仿真任务基准测试中，使用Claude 3.5 Sonnet达到88.2%的成功率，显著优于现有框架（MetaOpenFOAM为55.5%）。

Conclusion: Foam-Agent通过专业化多代理系统有效降低了CFD仿真的专业知识要求，展示了复杂科学计算民主化的潜力。

Abstract: Computational Fluid Dynamics (CFD) is an essential simulation tool in
engineering, yet its steep learning curve and complex manual setup create
significant barriers. To address these challenges, we introduce Foam-Agent, a
multi-agent framework that automates the entire end-to-end OpenFOAM workflow
from a single natural language prompt. Our key innovations address critical
gaps in existing systems: 1. An Comprehensive End-to-End Simulation Automation:
Foam-Agent is the first system to manage the full simulation pipeline,
including advanced pre-processing with a versatile Meshing Agent capable of
handling external mesh files and generating new geometries via Gmsh, automatic
generation of HPC submission scripts, and post-simulation visualization via
ParaView. 2. Composable Service Architecture: Going beyond a monolithic agent,
the framework uses Model Context Protocol (MCP) to expose its core functions as
discrete, callable tools. This allows for flexible integration and use by other
agentic systems, such as Claude-code, for more exploratory workflows. 3.
High-Fidelity Configuration Generation: We achieve superior accuracy through a
Hierarchical Multi-Index RAG for precise context retrieval and a
dependency-aware generation process that ensures configuration consistency.
Evaluated on a benchmark of 110 simulation tasks, Foam-Agent achieves an 88.2%
success rate with Claude 3.5 Sonnet, significantly outperforming existing
frameworks (55.5% for MetaOpenFOAM). Foam-Agent dramatically lowers the
expertise barrier for CFD, demonstrating how specialized multi-agent systems
can democratize complex scientific computing. The code is public at
https://github.com/csml-rpi/Foam-Agent.

</details>


### [66] [Large Language Models and Operations Research: A Structured Survey](https://arxiv.org/abs/2509.18180)
*Yang Wang,Kai Li*

Main category: cs.AI

TL;DR: 本论文综述了将大语言模型（LLMs）整合到运筹学（OR）中的最新进展，探讨了LLMs如何通过语义理解、结构化生成和推理控制来解决传统OR方法在大规模、动态和多约束问题中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统运筹学方法依赖专家建模和手动参数调整，难以处理大规模、动态和多约束问题。LLMs通过其语义理解和推理能力，有望克服这些限制，提升OR的自动化和智能化水平。

Method: 论文将LLMs在OR中的应用方法分为三个主要方向：自动建模（将自然语言描述转换为数学模型或可执行代码）、辅助优化（生成启发式算法和演化算法）以及直接求解（直接处理优化任务）。

Result: 综述了LLMs在OR中的评估基准和特定领域应用，并总结了当前面临的关键问题，如语义到结构映射的不稳定性、研究进展的碎片化、泛化能力有限以及评估体系不足。

Conclusion: 论文展望了未来研究方向，旨在推动LLMs在OR中的进一步应用，解决现有挑战并拓展其潜力。

Abstract: Operations research (OR) provides fundamental methodologies for complex
system decision-making, with established applications in transportation, supply
chain management, and production scheduling. Traditional approaches, which
depend on expert-based modeling and manual parameter adjustment, often face
challenges in handling large-scale, dynamic, and multi-constraint problems.
Recently, large language models (LLMs) have shown potential to address these
limitations through semantic understanding, structured generation, and
reasoning control. LLMs can translate natural language descriptions into
mathematical models or executable code, generate heuristics, evolve algorithms,
and directly tackle optimization tasks. This paper surveys recent progress on
the integration of LLMs into OR, organizing methods into three main directions:
automatic modeling, auxiliary optimization, and direct solving. It further
reviews evaluation benchmarks and domain-specific applications, and summarizes
key open issues such as unstable semantic-to-structure mapping, fragmented
research progress, limited generalization, and insufficient evaluation systems.
Finally, the survey outlines possible research avenues for advancing the role
of LLMs in OR.

</details>


### [67] [Synthesizing Attitudes, Predicting Actions (SAPA): Behavioral Theory-Guided LLMs for Ridesourcing Mode Choice Modeling](https://arxiv.org/abs/2509.18181)
*Mustafa Sameen,Xiaojian Zhang,Xilei Zhao*

Main category: cs.AI

TL;DR: 本文提出了SAPA框架，利用大语言模型合成理论驱动的潜在态度来预测网约车选择，显著提升了预测准确率。


<details>
  <summary>Details</summary>
Motivation: 现有网约车模式选择模型预测精度有限，无法捕捉关键心理因素，且面临严重的类别不平衡问题。

Method: SAPA采用分层方法：首先生成定性旅行者画像，然后训练倾向得分模型，再通过LLM量化潜在变量得分，最后整合所有特征进行分类预测。

Result: 在大规模多年旅行调查上的实验表明，SAPA在测试集上的PR-AUC指标比现有最优方法提升了75.9%。

Conclusion: SAPA为准确预测网约车模式选择提供了强大工具，其方法可轻松迁移到各种应用中。

Abstract: Accurate modeling of ridesourcing mode choices is essential for designing and
implementing effective traffic management policies for reducing congestion,
improving mobility, and allocating resources more efficiently. Existing models
for predicting ridesourcing mode choices often suffer from limited predictive
accuracy due to their inability to capture key psychological factors, and are
further challenged by severe class imbalance, as ridesourcing trips comprise
only a small fraction of individuals' daily travel. To address these
limitations, this paper introduces the Synthesizing Attitudes, Predicting
Actions (SAPA) framework, a hierarchical approach that uses Large Language
Models (LLMs) to synthesize theory-grounded latent attitudes to predict
ridesourcing choices. SAPA first uses an LLM to generate qualitative traveler
personas from raw travel survey data and then trains a propensity-score model
on demographic and behavioral features, enriched by those personas, to produce
an individual-level score. Next, the LLM assigns quantitative scores to
theory-driven latent variables (e.g., time and cost sensitivity), and a final
classifier integrates the propensity score, latent-variable scores (with their
interaction terms), and observable trip attributes to predict ridesourcing mode
choice. Experiments on a large-scale, multi-year travel survey show that SAPA
significantly outperforms state-of-the-art baselines, improving ridesourcing
choice predictions by up to 75.9% in terms of PR-AUC on a held-out test set.
This study provides a powerful tool for accurately predicting ridesourcing mode
choices, and provides a methodology that is readily transferable to various
applications.

</details>


### [68] [An Outcome-Based Educational Recommender System](https://arxiv.org/abs/2509.18186)
*Nursultan Askarbekuly,Timur Fayzrakhmanov,Sladjan Babarogić,Ivan Luković*

Main category: cs.AI

TL;DR: OBER是一个基于学习成果的教育推荐系统，通过将学习成果和评估项目直接嵌入数据模式，使任何推荐算法都能根据其促进的掌握程度进行评估。


<details>
  <summary>Details</summary>
Motivation: 大多数教育推荐系统仅基于点击或评分相关性进行调优和判断，其真实的教学影响不明确。需要一种能够直接评估推荐系统对学习成果影响的方法。

Method: OBER采用极简实体关系模型、基于日志的掌握度公式和插件架构。在非正式学习领域的电子学习系统中进行了为期两周的随机分组测试，比较了固定专家路径、协同过滤和基于知识的过滤三种方法。

Result: 协同过滤方法最大化了用户留存率，但固定路径方法实现了最高的掌握度。OBER能够从相同日志中导出业务、相关性和学习指标，让从业者无需额外测试即可权衡相关性和参与度与成果掌握度。

Conclusion: OBER框架是方法无关的，易于扩展到未来的自适应或上下文感知推荐系统，为教育推荐系统提供了更全面的评估框架。

Abstract: Most educational recommender systems are tuned and judged on click- or
rating-based relevance, leaving their true pedagogical impact unclear. We
introduce OBER-an Outcome-Based Educational Recommender that embeds learning
outcomes and assessment items directly into the data schema, so any algorithm
can be evaluated on the mastery it fosters. OBER uses a minimalist
entity-relation model, a log-driven mastery formula, and a plug-in
architecture. Integrated into an e-learning system in non-formal domain, it was
evaluated trough a two-week randomized split test with over 5 700 learners
across three methods: fixed expert trajectory, collaborative filtering (CF),
and knowledge-based (KB) filtering. CF maximized retention, but the fixed path
achieved the highest mastery. Because OBER derives business, relevance, and
learning metrics from the same logs, it lets practitioners weigh relevance and
engagement against outcome mastery with no extra testing overhead. The
framework is method-agnostic and readily extensible to future adaptive or
context-aware recommenders.

</details>


### [69] [MMCD: Multi-Modal Collaborative Decision-Making for Connected Autonomy with Knowledge Distillation](https://arxiv.org/abs/2509.18198)
*Rui Liu,Zikang Wang,Peng Gao,Yu Shen,Pratap Tokekar,Ming Lin*

Main category: cs.AI

TL;DR: 提出MMCD框架，通过多模态协作决策和跨模态知识蒸馏解决自动驾驶中传感器故障或连接车辆缺失的问题，提高驾驶安全性


<details>
  <summary>Details</summary>
Motivation: 现有方法假设训练和测试时所有数据模态和连接车辆都可用，这不切实际。需要解决传感器故障或连接车辆缺失时的鲁棒决策问题

Method: 提出MMCD框架，融合自车和协作车的多模态观测数据，采用基于教师-学生模型的跨模态知识蒸馏方法，教师模型使用多模态数据训练，学生模型设计为在模态减少时仍能有效工作

Result: 在连接自动驾驶和空地车辆协作实验中，该方法将驾驶安全性提高了20.7%，在检测潜在事故和做出安全驾驶决策方面优于现有最佳基线

Conclusion: MMCD框架通过多模态协作和知识蒸馏有效提升了自动驾驶系统在挑战性条件下的鲁棒性和安全性

Abstract: Autonomous systems have advanced significantly, but challenges persist in
accident-prone environments where robust decision-making is crucial. A single
vehicle's limited sensor range and obstructed views increase the likelihood of
accidents. Multi-vehicle connected systems and multi-modal approaches,
leveraging RGB images and LiDAR point clouds, have emerged as promising
solutions. However, existing methods often assume the availability of all data
modalities and connected vehicles during both training and testing, which is
impractical due to potential sensor failures or missing connected vehicles. To
address these challenges, we introduce a novel framework MMCD (Multi-Modal
Collaborative Decision-making) for connected autonomy. Our framework fuses
multi-modal observations from ego and collaborative vehicles to enhance
decision-making under challenging conditions. To ensure robust performance when
certain data modalities are unavailable during testing, we propose an approach
based on cross-modal knowledge distillation with a teacher-student model
structure. The teacher model is trained with multiple data modalities, while
the student model is designed to operate effectively with reduced modalities.
In experiments on $\textit{connected autonomous driving with ground vehicles}$
and $\textit{aerial-ground vehicles collaboration}$, our method improves
driving safety by up to ${\it 20.7}\%$, surpassing the best-existing baseline
in detecting potential accidents and making safe driving decisions. More
information can be found on our website https://ruiiu.github.io/mmcd.

</details>


### [70] [Change in Quantitative Bipolar Argumentation: Sufficient, Necessary, and Counterfactual Explanations](https://arxiv.org/abs/2509.18215)
*Timotheus Kampik,Kristijonas Čyras,José Ruiz Alarcón*

Main category: cs.AI

TL;DR: 本文提出了一种形式化方法来解释定量双极论证框架（QBAFs）中推理变化的原因。该方法通过追踪论证强度排序的变化（称为强度不一致性）来识别解释。


<details>
  <summary>Details</summary>
Motivation: 当从QBAF中得出结论并更新QBAF后再次得出结论时，需要解释论证强度排序变化的原因，以增强推理过程的可解释性。

Method: 通过追踪主题论证强度排序的变化，识别导致强度不一致性的具体论证作为解释。定义了充分、必要和反事实解释，并提出了基于启发式的解释搜索方法。

Result: 证明了强度不一致性解释存在的充要条件是更新导致强度不一致性，并提供了相应的实现。

Conclusion: 该方法为QBAF中的推理变化提供了形式化的解释框架，有助于理解和调试论证推理过程。

Abstract: This paper presents a formal approach to explaining change of inference in
Quantitative Bipolar Argumentation Frameworks (QBAFs). When drawing conclusions
from a QBAF and updating the QBAF to then again draw conclusions (and so on),
our approach traces changes -- which we call strength inconsistencies -- in the
partial order over argument strengths that a semantics establishes on some
arguments of interest, called topic arguments. We trace the causes of strength
inconsistencies to specific arguments, which then serve as explanations. We
identify sufficient, necessary, and counterfactual explanations for strength
inconsistencies and show that strength inconsistency explanations exist if and
only if an update leads to strength inconsistency. We define a heuristic-based
approach to facilitate the search for strength inconsistency explanations, for
which we also provide an implementation.

</details>


### [71] [nDNA -- the Semantic Helix of Artificial Cognition](https://arxiv.org/abs/2509.18216)
*Amitava Das*

Main category: cs.AI

TL;DR: 该论文提出了神经DNA（nDNA）概念，作为捕捉AI基础模型潜在认知身份的语义-基因型表示，通过分析模型的潜在几何结构来揭示其内在认知特性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试只能测量模型行为，但模型的本质在于其潜在几何结构。作者希望开发一种能够捕捉模型内在认知身份的方法，类似于生物DNA能够编码遗传信息。

Method: nDNA通过三个几何维度合成：谱曲率（揭示跨层的概念流动曲率）、热力学长度（量化表示转换所需的语义努力）和信念向量场（描述引导模型信念方向的语义扭转场）。

Result: nDNA能够稳定地生成与输入行为相关的神经DNA指纹，可用于追踪模型在预训练、微调、对齐等过程中的谱系，测量检查点之间的继承关系，检测数据或目标变化下的特征漂移。

Conclusion: 这项工作开启了神经基因组学新领域，将AI模型视为具有可追踪内在认知的数字语义有机体，为比较模型、诊断风险和治理认知演化提供了新方法。

Abstract: As AI foundation models grow in capability, a deeper question emerges: What
shapes their internal cognitive identity -- beyond fluency and output?
Benchmarks measure behavior, but the soul of a model resides in its latent
geometry. In this work, we propose Neural DNA (nDNA) as a semantic-genotypic
representation that captures this latent identity through the intrinsic
geometry of belief. At its core, nDNA is synthesized from three principled and
indispensable dimensions of latent geometry: spectral curvature, which reveals
the curvature of conceptual flow across layers; thermodynamic length, which
quantifies the semantic effort required to traverse representational
transitions through layers; and belief vector field, which delineates the
semantic torsion fields that guide a model's belief directional orientations.
Like biological DNA, it encodes ancestry, mutation, and semantic inheritance,
found in finetuning and alignment scars, cultural imprints, and architectural
drift. In naming it, we open a new field: Neural Genomics, where models are not
just tools, but digital semantic organisms with traceable inner cognition.
  Modeling statement. We read AI foundation models as semantic fluid--dynamics:
meaning is transported through layers like fluid in a shaped conduit; nDNA is
the physics-grade readout of that flow -- a geometry-first measure of how
meaning is bent, paid for, and pushed -- yielding a stable, coordinate-free
neural DNA fingerprint tied to on-input behavior; with this fingerprint we
cross into biology: tracing lineages across pretraining, fine-tuning,
alignment, pruning, distillation, and merges; measuring inheritance between
checkpoints; detecting drift as traits shift under new data or objectives; and,
ultimately, studying the evolution of artificial cognition to compare models,
diagnose risks, and govern change over time.

</details>


### [72] [Similarity Field Theory: A Mathematical Framework for Intelligence](https://arxiv.org/abs/2509.18218)
*Kei-Sing Ng*

Main category: cs.AI

TL;DR: 本文提出了相似性场理论，这是一个数学框架，用于形式化实体间相似性关系及其演化的原则。该理论定义了相似性场、系统演化、概念纤维和生成算子，并基于此形式化地定义了智能的概念。


<details>
  <summary>Details</summary>
Motivation: 作者认为持久化和转换相似性关系构成了任何可理解动态系统的结构基础，需要建立一个数学框架来形式化相似性值及其演化的原则。

Method: 定义了相似性场S: U×U→[0,1]，满足自反性；系统演化序列Z_p=(X_p,S^(p))；概念纤维F_α(K)={E∈U|S(E,K)≥α}；以及生成算子G。

Result: 证明了两个定理：(i)不对称性阻止相互包含；(ii)稳定性需要锚坐标或最终限制在f的水平集内。这些结果确保了相似性场演化的约束性和可解释性。

Conclusion: 相似性场理论为表征、比较和构建智能系统提供了基础语言，并可用于解释大语言模型和将其作为社会认知的实验探针。

Abstract: We posit that persisting and transforming similarity relations form the
structural basis of any comprehensible dynamic system. This paper introduces
Similarity Field Theory, a mathematical framework that formalizes the
principles governing similarity values among entities and their evolution. We
define: (1) a similarity field $S: U \times U \to [0,1]$ over a universe of
entities $U$, satisfying reflexivity $S(E,E)=1$ and treated as a directed
relational field (asymmetry and non-transitivity are allowed); (2) the
evolution of a system through a sequence $Z_p = (X_p, S^{(p)})$ indexed by
$p=0,1,2,\ldots$; (3) concepts $K$ as entities that induce fibers
$F_{\alpha}(K) = { E \in U \mid S(E,K) \ge \alpha }$, i.e., superlevel sets of
the unary map $S_K(E) := S(E,K)$; and (4) a generative operator $G$ that
produces new entities. Within this framework, we formalize a generative
definition of intelligence: an operator $G$ is intelligent with respect to a
concept $K$ if, given a system containing entities belonging to the fiber of
$K$, it generates new entities that also belong to that fiber. Similarity Field
Theory thus offers a foundational language for characterizing, comparing, and
constructing intelligent systems. We prove two theorems: (i) asymmetry blocks
mutual inclusion; and (ii) stability requires either an anchor coordinate or
eventual confinement within a level set of $f$. These results ensure that the
evolution of similarity fields is both constrained and interpretable,
culminating in an exploration of how the framework allows us to interpret large
language models and use them as experimental probes into societal cognition.

</details>


### [73] [Multimodal Health Risk Prediction System for Chronic Diseases via Vision-Language Fusion and Large Language Models](https://arxiv.org/abs/2509.18221)
*Dingxin Lu,Shurui Wu,Xinyi Huang*

Main category: cs.AI

TL;DR: VL-RiskFormer是一个用于预测个体健康风险的多模态AI框架，结合视觉和语言数据，在MIMIC-IV数据集上取得了0.90的AUROC。


<details>
  <summary>Details</summary>
Motivation: 随着慢性疾病负担增加和多模态临床数据的复杂性，需要统一的多模态AI框架来主动预测个体健康风险。

Method: 采用分层堆叠的视觉-语言多模态Transformer架构，包含四个关键创新：跨模态预训练、时间融合模块、疾病本体图适配器和LLM推理头。

Result: 在MIMIC-IV纵向队列中，平均AUROC达到0.90，预期校准误差为2.7%。

Conclusion: VL-RiskFormer展示了在多模态临床数据上预测健康风险的有效性，为个性化医疗提供了有前景的解决方案。

Abstract: With the rising global burden of chronic diseases and the multimodal and
heterogeneous clinical data (medical imaging, free-text recordings, wearable
sensor streams, etc.), there is an urgent need for a unified multimodal AI
framework that can proactively predict individual health risks. We propose
VL-RiskFormer, a hierarchical stacked visual-language multimodal Transformer
with a large language model (LLM) inference head embedded in its top layer. The
system builds on the dual-stream architecture of existing visual-linguistic
models (e.g., PaLM-E, LLaVA) with four key innovations: (i) pre-training with
cross-modal comparison and fine-grained alignment of radiological images,
fundus maps, and wearable device photos with corresponding clinical narratives
using momentum update encoders and debiased InfoNCE losses; (ii) a time fusion
block that integrates irregular visit sequences into the causal Transformer
decoder through adaptive time interval position coding; (iii) a disease
ontology map adapter that injects ICD-10 codes into visual and textual channels
in layers and infers comorbid patterns with the help of a graph attention
mechanism. On the MIMIC-IV longitudinal cohort, VL-RiskFormer achieved an
average AUROC of 0.90 with an expected calibration error of 2.7 percent.

</details>


### [74] [From "What to Eat?" to Perfect Recipe: ChefMind's Chain-of-Exploration for Ambiguous User Intent in Recipe Recommendation](https://arxiv.org/abs/2509.18226)
*Yu Fu,Linyue Cai,Ruoyu Wu,Yong Zhao*

Main category: cs.AI

TL;DR: ChefMind是一个混合架构，结合了探索链、知识图谱、检索增强生成和大语言模型，用于解决个性化食谱推荐中的模糊用户意图、语义准确性和细节覆盖问题。


<details>
  <summary>Details</summary>
Motivation: 个性化食谱推荐面临处理模糊用户意图、确保语义准确性和提供足够细节覆盖的挑战。

Method: 提出ChefMind混合架构：探索链(CoE)将模糊查询细化为结构化条件，知识图谱(KG)提供语义推理和可解释性，检索增强生成(RAG)补充上下文烹饪细节，大语言模型(LLM)整合输出为连贯推荐。

Result: 在小厨房数据集和手动标注查询上的评估显示，ChefMind在准确性、相关性、完整性和清晰度方面表现优异，平均得分8.7，而消融模型为6.4-6.7。未处理查询降至1.6%，证明其在处理模糊需求方面的鲁棒性。

Conclusion: ChefMind通过混合架构有效解决了食谱推荐中的关键挑战，在多个指标上显著优于单一方法基线。

Abstract: Personalized recipe recommendation faces challenges in handling fuzzy user
intent, ensuring semantic accuracy, and providing sufficient detail coverage.
We propose ChefMind, a hybrid architecture combining Chain of Exploration
(CoE), Knowledge Graph (KG), Retrieval-Augmented Generation (RAG), and a Large
Language Model (LLM). CoE refines ambiguous queries into structured conditions,
KG offers semantic reasoning and interpretability, RAG supplements contextual
culinary details, and LLM integrates outputs into coherent recommendations. We
evaluate ChefMind on the Xiachufang dataset and manually annotated queries,
comparing it with LLM-only, KG-only, and RAG-only baselines. Results show that
ChefMind achieves superior performance in accuracy, relevance, completeness,
and clarity, with an average score of 8.7 versus 6.4-6.7 for ablation models.
Moreover, it reduces unprocessed queries to 1.6%, demonstrating robustness in
handling fuzzy demands.

</details>


### [75] [An N-Plus-1 GPT Agency for Critical Solution of Mechanical Engineering Analysis Problems](https://arxiv.org/abs/2509.18229)
*Anthony Patera,Rohan Abeyaratne*

Main category: cs.AI

TL;DR: 论文提出了一种"N-Plus-1" GPT代理方法，通过多个独立求解代理和比较代理来提高机械工程问题分析的可靠性，解决GPT直接应用时的不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: GPT在机械工程分析中表现出不稳定性，成功概率仅85%，这种不可靠性使其不适合直接用于教育或工程实践。

Method: 采用N+1代理架构：首先启动N个独立求解代理生成解决方案，然后通过比较代理汇总比较这些方案并推荐最优解。基于孔多塞陪审团定理，当每个求解代理的成功概率大于1/2且N足够大时，多数解大概率正确。

Result: 该方法相比直接使用GPT显著提高了可靠性，与商业多代理模型Grok Heavy相比，在保持相似性能的同时更注重透明度和教学价值。

Conclusion: N-Plus-1代理方法为GPT在机械工程领域的可靠应用提供了可行方案，特别适合教育场景，通过多代理协作和透明比较机制提升了分析质量。

Abstract: Generative AI, and specifically GPT, can produce a remarkable solution to a
mechanical engineering analysis problem - but also, on occasion, a flawed
solution. For example, an elementary mechanics problem is solved flawlessly in
one GPT instance and incorrectly in a subsequent GPT instance, with a success
probability of only 85%. This unreliability renders "out-of-the-box" GPT
unsuitable for deployment in education or engineering practice. We introduce an
"N-Plus-1" GPT Agency for Initial (Low-Cost) Analysis of mechanical engineering
Problem Statements. Agency first launches N instantiations of Agent Solve to
yield N independent Proposed Problem Solution Realizations; Agency then invokes
Agent Compare to summarize and compare the N Proposed Problem Solution
Realizations and to provide a Recommended Problem Solution. We argue from
Condorcet's Jury Theorem that, for a Problem Statement characterized by
per-Solve success probability greater than 1/2 (and N sufficiently large), the
Predominant (Agent Compare) Proposed Problem Solution will, with high
probability, correspond to a Correct Proposed Problem Solution. Furthermore,
Agent Compare can also incorporate aspects of Secondary (Agent Compare)
Proposed Problem Solutions, in particular when the latter represent alternative
Problem Statement interpretations - different Mathematical Models - or
alternative Mathematical Solution Procedures. Comparisons to Grok Heavy, a
commercial multi-agent model, show similarities in design and performance, but
also important differences in emphasis: our Agency focuses on transparency and
pedagogical value.

</details>


### [76] [Towards General Computer Control with Hierarchical Agents and Multi-Level Action Spaces](https://arxiv.org/abs/2509.18230)
*Zihan Dong,Xinyu Fan,Zixiang Tang,Yunqing Li*

Main category: cs.AI

TL;DR: 提出轻量级分层强化学习框架ComputerAgent，通过双级选项过程（管理器和子策略）解决桌面应用控制问题，相比大型多模态语言模型显著减小模型规模并提升效率


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态大语言模型的方法存在推理延迟高、样本效率低、无法在设备上部署等问题，需要更实用的桌面应用自动化解决方案

Method: 采用分层强化学习框架，包含三模态状态编码器（截图、任务ID、数值状态）、元动作与早停机制、紧凑视觉骨干网络和小型策略网络（仅1500万参数）

Result: 在135个真实桌面任务测试中，简单任务成功率92.1%，困难任务58.8%，性能匹配或超越200B参数大模型，模型规模减小4个数量级，推理时间减半

Conclusion: 分层强化学习为计算机控制提供了一种实用、可扩展的替代方案，相比单一大型多模态模型更具优势

Abstract: Controlling desktop applications via software remains a fundamental yet
under-served problem. Existing multi-modal large language models (MLLMs) ingest
screenshots and task instructions to generate keystrokes and mouse events, but
they suffer from prohibitive inference latency, poor sample efficiency on
long-horizon sparse-reward tasks, and infeasible on-device deployment. We
introduce a lightweight hierarchical reinforcement learning framework,
ComputerAgent, that formulates OS control as a two-level option process
(manager and subpolicy), employs a triple-modal state encoder (screenshot, task
ID, numeric state) to handle visual and contextual diversity, integrates
meta-actions with an early-stop mechanism to reduce wasted interactions, and
uses a compact vision backbone plus small policy networks for on-device
inference (15M parameters). On a suite of 135 real-world desktop tasks,
ComputerAgent attains 92.1% success on simple tasks (<8 steps) and 58.8% on
hard tasks (>=8 steps), matching or exceeding 200B-parameter MLLM baselines on
simple scenarios while reducing model size by over four orders of magnitude and
halving inference time. These results demonstrate that hierarchical RL offers a
practical, scalable alternative to monolithic MLLM-based automation for
computer control.

</details>


### [77] [The Illusion of Readiness: Stress Testing Large Frontier Models on Multimodal Medical Benchmarks](https://arxiv.org/abs/2509.18234)
*Yu Gu,Jingjing Fu,Xiaodong Liu,Jeya Maria Jose Valanarasu,Noel Codella,Reuben Tan,Qianchu Liu,Ying Jin,Sheng Zhang,Jinyu Wang,Rui Wang,Lei Song,Guanghui Qin,Naoto Usuyama,Cliff Wong,Cheng Hao,Hohin Lee,Praneeth Sanapathi,Sarah Hilado,Bian Jiang,Javier Alvarez-Valle,Mu Wei,Jianfeng Gao,Eric Horvitz,Matt Lungren,Hoifung Poon,Paul Vozila*

Main category: cs.AI

TL;DR: 论文指出当前医学基准测试存在严重问题，大型前沿模型在基准测试中得分很高，但实际上只是学会了应试技巧而非真正的医学理解。研究发现模型会在关键输入被移除时仍能猜对答案，在简单提示变化下改变答案，并生成有说服力但有缺陷的推理。


<details>
  <summary>Details</summary>
Motivation: 揭示当前医学AI基准测试的局限性，证明高分数并不等同于真实的医学理解能力，强调需要更严格的评估标准来确保AI在医疗领域的可靠应用。

Method: 评估了六个旗舰模型在六个广泛使用的医学基准测试上的表现，通过临床医生指导的评分标准评估，分析基准测试真正衡量的内容及其差异性。

Result: 发现领先系统存在脆弱性和捷径学习问题，基准测试分数不能直接反映真实世界的准备程度，不同基准测试衡量的内容差异很大但被等同对待。

Conclusion: 医学基准测试分数不能直接等同于现实世界的准备度，要建立医疗AI的信任，必须要求系统具备鲁棒性、合理推理能力，并与真实医疗需求保持一致，而不仅仅是追求排行榜胜利。

Abstract: Large frontier models like GPT-5 now achieve top scores on medical
benchmarks. But our stress tests tell a different story. Leading systems often
guess correctly even when key inputs like images are removed, flip answers
under trivial prompt changes, and fabricate convincing yet flawed reasoning.
These aren't glitches; they expose how today's benchmarks reward test-taking
tricks over medical understanding. We evaluate six flagship models across six
widely used benchmarks and find that high leaderboard scores hide brittleness
and shortcut learning. Through clinician-guided rubric evaluation, we show that
benchmarks vary widely in what they truly measure yet are treated
interchangeably, masking failure modes. We caution that medical benchmark
scores do not directly reflect real-world readiness. If we want AI to earn
trust in healthcare, we must demand more than leaderboard wins and must hold
systems accountable for robustness, sound reasoning, and alignment with real
medical demands.

</details>


### [78] [Evaluating the Safety and Skill Reasoning of Large Reasoning Models Under Compute Constraints](https://arxiv.org/abs/2509.18382)
*Adarsha Balaji,Le Chen,Rajeev Thakur,Franck Cappello,Sandeep Madireddy*

Main category: cs.AI

TL;DR: 该论文研究两种计算约束策略（推理长度约束和模型量化）来降低推理模型的计算需求，并分析它们对模型安全性能的影响。


<details>
  <summary>Details</summary>
Motivation: 测试时计算扩展虽然能通过生成长链思维序列提高推理语言模型的性能，但计算成本显著增加。需要找到平衡计算效率和模型安全的方法。

Method: 1）使用基于长度控制策略优化的强化学习方法微调推理模型，满足用户定义的CoT推理长度；2）应用量化技术，在用户定义的计算约束下最大化CoT序列的生成。

Result: 研究计算效率与模型安全性之间的权衡关系。

Conclusion: 计算约束策略可以有效降低推理模型的计算需求，但需要在计算效率和安全性之间找到合适的平衡点。

Abstract: Test-time compute scaling has demonstrated the ability to improve the
performance of reasoning language models by generating longer chain-of-thought
(CoT) sequences. However, this increase in performance comes with a significant
increase in computational cost. In this work, we investigate two compute
constraint strategies: (1) reasoning length constraint and (2) model
quantization, as methods to reduce the compute demand of reasoning models and
study their impact on their safety performance. Specifically, we explore two
approaches to apply compute constraints to reasoning models: (1) fine-tuning
reasoning models using a length controlled policy optimization (LCPO) based
reinforcement learning method to satisfy a user-defined CoT reasoning length,
and (2) applying quantization to maximize the generation of CoT sequences
within a user-defined compute constraint. Furthermore, we study the trade-off
between the computational efficiency and the safety of the model.

</details>


### [79] [Gödel Test: Can Large Language Models Solve Easy Conjectures?](https://arxiv.org/abs/2509.18383)
*Moran Feldman,Amin Karbasi*

Main category: cs.AI

TL;DR: 论文提出了Gödel测试，评估大型语言模型能否为简单未解决数学猜想生成正确证明，并在组合优化领域的五个猜想上测试GPT-5的表现。


<details>
  <summary>Details</summary>
Motivation: 前沿AI模型在数学竞赛中表现出色，但能否解决更高级数学领域的新简单猜想仍不清楚，需要评估模型在原创数学推理方面的能力。

Method: 选择五个组合优化领域的未解决猜想，提供相关源论文但不告知具体猜想，详细评估GPT-5的推理过程和证明能力。

Result: GPT-5在三个较简单问题上产生接近正确的解，在问题2中甚至推翻了原猜想并给出有效解，但在需要跨论文综合的问题4上失败，在更复杂的问题5中算法正确但分析失败。

Conclusion: GPT-5在常规推理方面有显著进步，偶尔展现原创性，但在跨论文综合方面存在明显局限，可能是通过Gödel测试的早期步骤。

Abstract: Recent announcements from frontier AI model labs have highlighted strong
results on high-school and undergraduate math competitions. Yet it remains
unclear whether large language models can solve new, simple conjectures in more
advanced areas of mathematics. We propose the G\"odel Test: evaluating whether
a model can produce correct proofs for very simple, previously unsolved
conjectures. To this end, we study the performance of GPT-5 on five conjectures
in combinatorial optimization. For each problem, we provided one or two source
papers from which the conjecture arose, withheld our own conjecture, and then
assessed the model's reasoning in detail. On the three easier problems, GPT-5
produced nearly correct solutions; for Problem 2 it even derived a different
approximation guarantee that, upon checking, refuted our conjecture while
providing a valid solution. The model failed on Problem 4, which required
combining results from two papers. On Problem 5, a harder case without a
validated conjecture, GPT-5 proposed the same algorithm we had in mind but
failed in the analysis, suggesting the proof is more challenging than expected.
Although our sample is small, the results point to meaningful progress on
routine reasoning, occasional flashes of originality, and clear limitations
when cross-paper synthesis is required. GPT-5 may represent an early step
toward frontier models eventually passing the G\"odel Test.

</details>


### [80] [ATLAS: Benchmarking and Adapting LLMs for Global Trade via Harmonized Tariff Code Classification](https://arxiv.org/abs/2509.18400)
*Pritish Yuvraj,Siva Devarakonda*

Main category: cs.AI

TL;DR: 该论文提出了首个HTS编码分类基准，并展示了微调的Atlas模型在准确性和成本效益上的显著优势。


<details>
  <summary>Details</summary>
Motivation: HTS编码分类是全球贸易中的关键瓶颈，但机器学习社区对此关注不足。错误分类可能导致货物运输中断，因此需要开发准确且经济的分类解决方案。

Method: 基于美国海关CROSS系统构建首个HTS编码分类基准，使用微调的LLaMA-3.3-70B模型（Atlas）进行10位和6位HTS编码分类。

Result: Atlas模型在10位分类上达到40%的准确率，6位分类达到57.5%的准确率，比GPT-5-Thinking和Gemini-2.5-Pro-Thinking分别提升15和27.5个百分点，且成本降低5-8倍。

Conclusion: Atlas模型为HTS分类设立了强基线，但该任务仍具挑战性。通过发布数据集和模型，旨在将HTS分类确立为新的社区基准任务，促进检索、推理和对齐方面的未来研究。

Abstract: Accurate classification of products under the Harmonized Tariff Schedule
(HTS) is a critical bottleneck in global trade, yet it has received little
attention from the machine learning community. Misclassification can halt
shipments entirely, with major postal operators suspending deliveries to the
U.S. due to incomplete customs documentation. We introduce the first benchmark
for HTS code classification, derived from the U.S. Customs Rulings Online
Search System (CROSS). Evaluating leading LLMs, we find that our fine-tuned
Atlas model (LLaMA-3.3-70B) achieves 40 percent fully correct 10-digit
classifications and 57.5 percent correct 6-digit classifications, improvements
of 15 points over GPT-5-Thinking and 27.5 points over Gemini-2.5-Pro-Thinking.
Beyond accuracy, Atlas is roughly five times cheaper than GPT-5-Thinking and
eight times cheaper than Gemini-2.5-Pro-Thinking, and can be self-hosted to
guarantee data privacy in high-stakes trade and compliance workflows. While
Atlas sets a strong baseline, the benchmark remains highly challenging, with
only 40 percent 10-digit accuracy. By releasing both dataset and model, we aim
to position HTS classification as a new community benchmark task and invite
future work in retrieval, reasoning, and alignment.

</details>


### [81] [Instruction-Following Evaluation in Function Calling for Large Language Models](https://arxiv.org/abs/2509.18420)
*Nikolai Skripko*

Main category: cs.AI

TL;DR: IFEval-FC是一个新的函数调用基准测试，专注于评估大语言模型对参数描述中格式指令的遵循能力，弥补了现有基准测试只关注参数正确性而忽略格式要求的不足。


<details>
  <summary>Details</summary>
Motivation: 现有函数调用基准测试（如BFCL、tau^2-Bench、ACEBench）只评估参数正确性，但忽略了格式指令的遵循，这对于实际AI代理系统至关重要。

Method: 基于IFEval设计，在JSON schema描述中直接编码可验证的格式要求，包含750个测试用例，每个用例包含一个函数和一个用户查询，采用完全算法化评估。

Result: 即使是GPT-5和Claude 4.1 Opus等最先进的专有模型也经常无法遵循基本格式规则，揭示了实际代理系统的局限性。

Conclusion: IFEval-FC填补了函数调用评估的重要空白，为改进模型格式遵循能力提供了基准，代码和数据已公开。

Abstract: Function calling is a core capability of large language models, essential for
AI agents. Existing benchmarks such as the Berkeley Function Calling
Leaderboard (BFCL), tau^2-Bench (arXiv:2506.07982), and ACEBench
(arXiv:2501.12851) evaluate argument correctness but do not test adherence to
format instructions embedded in parameter descriptions, such as enclosing
values in double quotes or using ISO date formats.
  We introduce IFEval-FC, a benchmark inspired by IFEval (arXiv:2311.07911)
that assesses precise instruction following in function calling. IFEval-FC
encodes verifiable formats directly within JSON schema descriptions, for
example specifying that a value must not contain punctuation. It includes 750
test cases, each consisting of a function with an embedded format for one of
its input parameters and a corresponding user query. Evaluation is fully
algorithmic, ensuring objectivity, reproducibility, and scalability.
  Our results show that even state-of-the-art proprietary models, including
GPT-5 and Claude 4.1 Opus, frequently fail to follow basic formatting rules,
highlighting a practical limitation for real-world agent systems. The complete
codebase and data are publicly available at
https://github.com/Skripkon/IFEval-FC.

</details>


### [82] [Memory-QA: Answering Recall Questions Based on Multimodal Memories](https://arxiv.org/abs/2509.18436)
*Hongda Jiang,Xinyuan Zhang,Siddhant Garg,Rishab Arora,Shiun-Zu Kuo,Jiayang Xu,Christopher Brossman,Yue Liu,Aaron Colak,Ahmed Aly,Anuj Kumar,Xin Luna Dong*

Main category: cs.AI

TL;DR: Memory-QA是一个新颖的视觉记忆问答任务，Pensieve管道通过特定增强、时空感知检索和多记忆微调实现优越性能


<details>
  <summary>Details</summary>
Motivation: 解决现实世界中基于视觉记忆的回忆问答任务面临的挑战，包括任务导向记忆创建、时空信息利用和多记忆推理

Method: 提出Pensieve综合管道，包含记忆特定增强、时空感知多信号检索和多记忆问答微调

Result: 在构建的多模态基准上，Pensieve相比现有最优方法在问答准确率上提升高达14%

Conclusion: Memory-QA任务具有现实挑战性，Pensieve管道能有效处理视觉记忆的问答问题

Abstract: We introduce Memory-QA, a novel real-world task that involves answering
recall questions about visual content from previously stored multimodal
memories. This task poses unique challenges, including the creation of
task-oriented memories, the effective utilization of temporal and location
information within memories, and the ability to draw upon multiple memories to
answer a recall question. To address these challenges, we propose a
comprehensive pipeline, Pensieve, integrating memory-specific augmentation,
time- and location-aware multi-signal retrieval, and multi-memory QA
fine-tuning. We created a multimodal benchmark to illustrate various real
challenges in this task, and show the superior performance of Pensieve over
state-of-the-art solutions (up to 14% on QA accuracy).

</details>


### [83] [FERA: Foil Fencing Referee Assistant Using Pose-Based Multi-Label Move Recognition and Rule Reasoning](https://arxiv.org/abs/2509.18527)
*Ziwen Chen,Zhong Wang*

Main category: cs.AI

TL;DR: FERA是一个用于击剑裁判辅助的AI原型系统，通过姿态识别和规则推理来解决击剑裁判中的主观判断、人为错误和偏见问题。


<details>
  <summary>Details</summary>
Motivation: 击剑运动面临裁判主观判断、人为错误、偏见以及在实践环境中可用性有限等挑战，需要自动化裁判辅助系统。

Method: 系统从视频中提取2D关节位置，进行归一化处理，计算101维运动学特征集，使用Transformer进行多标签动作和剑尖分类，并应用基于规则的推理来确定优先权和得分。

Result: 在有限的手动标注数据下，5折交叉验证的平均macro-F1得分为0.549，优于Temporal Convolutional Network、BiLSTM和普通Transformer等多个基线模型。

Conclusion: 虽然尚未达到部署水平，但结果表明在击剑自动化裁判辅助方面具有前景，并为AI在击剑领域的应用（如教练）开辟了新机会。

Abstract: The sport of fencing, like many other sports, faces challenges in refereeing:
subjective calls, human errors, bias, and limited availability in practice
environments. We present FERA (Fencing Referee Assistant), a prototype AI
referee for foil fencing which integrates pose-based multi-label action
recognition and rule-based reasoning. FERA extracts 2D joint positions from
video, normalizes them, computes a 101-dimensional kinematic feature set, and
applies a Transformer for multi-label move and blade classification. To
determine priority and scoring, FERA applies a distilled language model with
encoded right-of-way rules, producing both a decision and an explanation for
each exchange. With limited hand-labeled data, a 5-fold cross-validation
achieves an average macro-F1 score of 0.549, outperforming multiple baselines,
including a Temporal Convolutional Network (TCN), BiLSTM, and a vanilla
Transformer. While not ready for deployment, these results demonstrate a
promising path towards automated referee assistance in foil fencing and new
opportunities for AI applications, such as coaching in the field of fencing.

</details>


### [84] [LLMZ+: Contextual Prompt Whitelist Principles for Agentic LLMs](https://arxiv.org/abs/2509.18557)
*Tom Pawelek,Raj Patel,Charlotte Crowell,Noorbakhsh Amiri,Sudip Mittal,Shahram Rahimi,Andy Perkins*

Main category: cs.AI

TL;DR: LLMZ+是一种基于提示白名单的防御机制，通过只允许上下文适当的安全消息与代理式LLM交互，来保护代理式AI免受恶意攻击。


<details>
  <summary>Details</summary>
Motivation: 代理式AI相比传统模型具有更高的安全风险，因为它们拥有对数据源和API工具的特权访问权限，且依赖AI的非确定性行为。现有的基于恶意意图检测的防御机制存在局限性。

Method: 提出LLMZ+方法，采用提示白名单机制，确保外部用户与LLM之间的所有交互都符合预定义的使用场景和操作边界。

Result: 实证评估显示LLMZ+对最常见的越狱提示具有很强的抵御能力，同时不影响合法的业务通信。在实验环境中，误报率和漏报率均可降至0。

Conclusion: LLMZ+通过基于上下文特异性的方法简化了安全框架，增强了长期韧性，并减少了维持LLM信息安全所需的资源。

Abstract: Compared to traditional models, agentic AI represents a highly valuable
target for potential attackers as they possess privileged access to data
sources and API tools, which are traditionally not incorporated into classical
agents. Unlike a typical software application residing in a Demilitarized Zone
(DMZ), agentic LLMs consciously rely on nondeterministic behavior of the AI
(only defining a final goal, leaving the path selection to LLM). This
characteristic introduces substantial security risk to both operational
security and information security. Most common existing defense mechanism rely
on detection of malicious intent and preventing it from reaching the LLM agent,
thus protecting against jailbreak attacks such as prompt injection. In this
paper, we present an alternative approach, LLMZ+, which moves beyond
traditional detection-based approaches by implementing prompt whitelisting.
Through this method, only contextually appropriate and safe messages are
permitted to interact with the agentic LLM. By leveraging the specificity of
context, LLMZ+ guarantees that all exchanges between external users and the LLM
conform to predefined use cases and operational boundaries. Our approach
streamlines the security framework, enhances its long-term resilience, and
reduces the resources required for sustaining LLM information security. Our
empirical evaluation demonstrates that LLMZ+ provides strong resilience against
the most common jailbreak prompts. At the same time, legitimate business
communications are not disrupted, and authorized traffic flows seamlessly
between users and the agentic LLM. We measure the effectiveness of approach
using false positive and false negative rates, both of which can be reduced to
0 in our experimental setting.

</details>


### [85] [Solving Math Word Problems Using Estimation Verification and Equation Generation](https://arxiv.org/abs/2509.18565)
*Mitchell Piehl,Dillon Wilson,Ananya Kalita,Jugal Kalita*

Main category: cs.AI

TL;DR: 该论文提出了一种新方法，通过将数学应用题分解为方程，使用外部符号求解器求解，并通过LLM进行答案估计和验证来提高解题准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在解决数学应用题时面临挑战，因为需要复杂的推理和数学能力。现有方法在复杂MWPs上仍有改进空间。

Method: 首先提示LLM将问题分解为方程，使用外部符号求解器得到答案；然后让LLM进行答案估计并与生成答案比较验证；如果验证失败，采用迭代修正过程。

Result: 该方法在数值和代数MWPs数据集上达到了新的最先进结果，平均比之前最佳结果提高了近2%，在三角函数MWPs上也取得了满意结果。

Conclusion: 提出的方法有效提升了LLM解决数学应用题的能力，并引入了两个新数据集SVAMPClean和Trig300来进一步测试LLM的推理能力。

Abstract: Large Language Models (LLMs) excel at various tasks, including
problem-solving and question-answering. However, LLMs often find Math Word
Problems (MWPs) challenging because solving them requires a range of reasoning
and mathematical abilities with which LLMs seem to struggle. Recent efforts
have helped LLMs solve more complex MWPs with improved prompts. This study
proposes a novel method that initially prompts an LLM to create equations from
a decomposition of the question, followed by using an external symbolic
equation solver to produce an answer. To ensure the accuracy of the obtained
answer, inspired by an established recommendation of math teachers, the LLM is
instructed to solve the MWP a second time, but this time with the objective of
estimating the correct answer instead of solving it exactly. The estimation is
then compared to the generated answer to verify. If verification fails, an
iterative rectification process is employed to ensure the correct answer is
eventually found. This approach achieves new state-of-the-art results on
datasets used by prior published research on numeric and algebraic MWPs,
improving the previous best results by nearly two percent on average. In
addition, the approach obtains satisfactory results on trigonometric MWPs, a
task not previously attempted to the authors' best knowledge. This study also
introduces two new datasets, SVAMPClean and Trig300, to further advance the
testing of LLMs' reasoning abilities.

</details>


### [86] [Adaptive Learning in Spatial Agent-Based Models for Climate Risk Assessment: A Geospatial Framework with Evolutionary Economic Agents](https://arxiv.org/abs/2509.18633)
*Yara Mohajerani*

Main category: cs.AI

TL;DR: 提出了一种结合地理空间建模与进化学习的新型基于代理的气候风险评估框架，能够模拟气候变化对经济系统的直接和间接影响。


<details>
  <summary>Details</summary>
Motivation: 传统气候风险评估难以捕捉复杂空间异质性灾害与适应性经济系统之间的相互作用，需要更先进的建模方法来量化系统性风险。

Method: 开发了基于Mesa空间建模和CLIMADA气候影响评估的地理空间代理模型，引入进化学习机制让企业代理通过适应度选择和变异演化出预算分配、定价、工资和风险适应策略。

Result: 使用RCP8.5情景下的河流洪水预测到2100年，显示进化适应使企业能够在数十年气候压力后恢复到基准生产水平，但未直接暴露于洪水的代理仍面临供应链中断影响，世纪末商品平均价格比基准高5.6%。

Conclusion: 该开源框架为金融机构和企业提供了量化直接和级联气候风险的工具，同时评估成本效益适应的策略。

Abstract: Climate risk assessment requires modelling complex interactions between
spatially heterogeneous hazards and adaptive economic systems. We present a
novel geospatial agent-based model that integrates climate hazard data with
evolutionary learning for economic agents. Our framework combines Mesa-based
spatial modelling with CLIMADA climate impact assessment, introducing adaptive
learning behaviours that allow firms to evolve strategies for budget
allocation, pricing, wages, and risk adaptation through fitness-based selection
and mutation. We demonstrate the framework using riverine flood projections
under RCP8.5 until 2100, showing that evolutionary adaptation enables firms to
converge with baseline (no hazard) production levels after decades of
disruption due to climate stress. Our results reveal systemic risks where even
agents that are not directly exposed to floods face impacts through supply
chain disruptions, with the end-of-century average price of goods 5.6% higher
under RCP8.5 compared to the baseline. This open-source framework provides
financial institutions and companies with tools to quantify both direct and
cascading climate risks while evaluating cost-effective adaptation strategies.

</details>


### [87] [TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2509.18667)
*Qiao Xiao,Hong Ting Tsang,Jiaxin Bai*

Main category: cs.AI

TL;DR: TERAG是一个低成本图增强检索生成框架，通过个性化PageRank在检索阶段构建信息图，仅需3%-11%的token消耗即可达到主流图RAG方法80%以上的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有图增强RAG系统在构建图时LLM token使用成本过高，阻碍了大规模应用。

Method: 受HippoRAG启发，在检索阶段引入个性化PageRank(PPR)来构建信息图，显著降低token消耗。

Result: 仅消耗3%-11%的输出token，就能达到广泛使用的图RAG方法至少80%的准确率。

Conclusion: TERAG提供了一种简单有效的低成本图RAG解决方案，在保持性能的同时大幅降低了计算成本。

Abstract: Graph-based Retrieval-augmented generation (RAG) has become a widely studied
approach for improving the reasoning, accuracy, and factuality of Large
Language Models. However, many existing graph-based RAG systems overlook the
high cost associated with LLM token usage during graph construction, hindering
large-scale adoption. To address this, we propose TERAG, a simple yet effective
framework designed to build informative graphs at a significantly lower cost.
Inspired by HippoRAG, we incorporate Personalized PageRank (PPR) during the
retrieval phase, and we achieve at least 80% of the accuracy of widely used
graph-based RAG methods while consuming only 3%-11% of the output tokens.

</details>


### [88] [Implementation of airborne ML models with semantics preservation](https://arxiv.org/abs/2509.18681)
*Nicolas Valot,Louis Fabre,Benjamin Lesage,Ammar Mechouche,Claire Pagetti*

Main category: cs.AI

TL;DR: 本文探讨了在航空系统中使用机器学习（ML）的安全性和合规性要求，提出了机器学习模型描述（MLMD）的概念，并细化了语义保持的关键概念，以确保模型的准确复制。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在航空系统中的应用增加，需要确保这些系统的安全运行并符合监管要求。EASA和EUROCAE/SAE等机构已发布相关指导文件，但需要更具体的方法来验证ML模型的功能和性能。

Method: 通过区分ML模型与其明确的描述（MLMD），并细化语义保持的概念，确保模型在目标环境中的准确复制。应用这些贡献到多个工业用例中，构建和比较不同的目标模型。

Result: 提出了MLMD的概念和语义保持的细化方法，通过工业用例验证了这些方法的有效性，展示了如何确保ML模型在航空系统中的安全性和合规性。

Conclusion: MLMD和语义保持的概念为航空系统中ML模型的安全性和合规性提供了重要基础，有助于满足监管要求并确保系统的可靠运行。

Abstract: Machine Learning (ML) may offer new capabilities in airborne systems.
However, as any piece of airborne systems, ML-based systems will be required to
guarantee their safe operation. Thus, their development will have to be
demonstrated to be compliant with the adequate guidance. So far, the European
Union Aviation Safety Agency (EASA) has published a concept paper and an
EUROCAE/SAE group is preparing ED-324. Both approaches delineate high-level
objectives to confirm the ML model achieves its intended function and maintains
training performance in the target environment. The paper aims to clarify the
difference between an ML model and its corresponding unambiguous description,
referred to as the Machine Learning Model Description (MLMD). It then refines
the essential notion of semantics preservation to ensure the accurate
replication of the model. We apply our contributions to several industrial use
cases to build and compare several target models.

</details>


### [89] [Advances in Large Language Models for Medicine](https://arxiv.org/abs/2509.18690)
*Zhiyu Kan,Wensheng Gan,Zhenlian Qi,Philip S. Yu*

Main category: cs.AI

TL;DR: 本文系统综述了大型语言模型在医学领域的最新研究进展，包括训练技术、医疗应用、优势局限，并创新性地将医学LLM分为三类、评估方法分为两类，提出了现有挑战的解决方案和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术快速发展，LLM在医学领域展现出巨大应用潜力，需要系统梳理当前研究进展，为后续研究提供指导。

Method: 采用系统综述方法，分析医学LLM的训练技术、适应医疗场景的方式、相关应用及其优缺点。

Result: 提出了医学LLM的三类分类方法和两类评估方法，识别了该领域的关键挑战。

Conclusion: 通过系统综述强调了开发医学LLM的必要性，为后续研究提供了清晰的发展方向。

Abstract: Artificial intelligence (AI) technology has advanced rapidly in recent years,
with large language models (LLMs) emerging as a significant breakthrough. LLMs
are increasingly making an impact across various industries, with the medical
field standing out as the most prominent application area. This paper
systematically reviews the up-to-date research progress of LLMs in the medical
field, providing an in-depth analysis of training techniques for large medical
models, their adaptation in healthcare settings, related applications, as well
as their strengths and limitations. Furthermore, it innovatively categorizes
medical LLMs into three distinct types based on their training methodologies
and classifies their evaluation approaches into two categories. Finally, the
study proposes solutions to existing challenges and outlines future research
directions based on identified issues in the field of medical LLMs. By
systematically reviewing previous and advanced research findings, we aim to
highlight the necessity of developing medical LLMs, provide a deeper
understanding of their current state of development, and offer clear guidance
for subsequent research.

</details>


### [90] [Autonomous Data Agents: A New Opportunity for Smart Data](https://arxiv.org/abs/2509.18710)
*Yanjie Fu,Dongjie Wang,Wangyang Ying,Xiangliang Zhang,Huan Liu,Jian Pei*

Main category: cs.AI

TL;DR: 本文提出自主数据代理（DataAgents）的概念，通过集成LLM推理与任务分解、行动推理和工具调用，实现从数据到知识的自动化转换，代表数据管理向自主知识系统的范式转变。


<details>
  <summary>Details</summary>
Motivation: 随着数据规模和复杂性增长，数据准备、转换和分析工作仍然劳动密集且难以扩展。数据与AI之间的对齐至关重要，但现有数据结构往往不适合AI利用。需要探索通过密集数据操作能将多少知识打包到数据中。

Method: DataAgents整合LLM推理能力，能够自主解释数据任务描述、分解任务为子任务、进行行动推理、将行动落地为Python代码或工具调用，并执行操作。与传统工具不同，DataAgents能动态规划工作流、调用强大工具，并适应各种规模的数据任务。

Result: DataAgents能够处理数据收集、集成、预处理、选择、转换、重加权、增强、重编程、修复和检索等任务，将复杂非结构化数据转化为连贯可操作的知识。

Conclusion: DataAgents代表了向自主数据到知识系统的范式转变。需要推进行动工作流优化、建立开放数据集和基准生态系统、保护隐私、平衡效率与可扩展性，并开发可信的DataAgent防护机制以防止恶意行为。

Abstract: As data continues to grow in scale and complexity, preparing, transforming,
and analyzing it remains labor-intensive, repetitive, and difficult to scale.
Since data contains knowledge and AI learns knowledge from it, the alignment
between AI and data is essential. However, data is often not structured in ways
that are optimal for AI utilization. Moreover, an important question arises:
how much knowledge can we pack into data through intensive data operations?
Autonomous data agents (DataAgents), which integrate LLM reasoning with task
decomposition, action reasoning and grounding, and tool calling, can
autonomously interpret data task descriptions, decompose tasks into subtasks,
reason over actions, ground actions into python code or tool calling, and
execute operations. Unlike traditional data management and engineering tools,
DataAgents dynamically plan workflows, call powerful tools, and adapt to
diverse data tasks at scale. This report argues that DataAgents represent a
paradigm shift toward autonomous data-to-knowledge systems. DataAgents are
capable of handling collection, integration, preprocessing, selection,
transformation, reweighing, augmentation, reprogramming, repairs, and
retrieval. Through these capabilities, DataAgents transform complex and
unstructured data into coherent and actionable knowledge. We first examine why
the convergence of agentic AI and data-to-knowledge systems has emerged as a
critical trend. We then define the concept of DataAgents and discuss their
architectural design, training strategies, as well as the new skills and
capabilities they enable. Finally, we call for concerted efforts to advance
action workflow optimization, establish open datasets and benchmark ecosystems,
safeguard privacy, balance efficiency with scalability, and develop trustworthy
DataAgent guardrails to prevent malicious actions.

</details>


### [91] [Experience Scaling: Post-Deployment Evolution For Large Language Models](https://arxiv.org/abs/2509.18771)
*Xingkun Yin,Kaibin Huang,Dong In Kim,Hongyang Du*

Main category: cs.AI

TL;DR: 提出经验扩展框架，通过自主环境交互和协作经验共享实现LLM的持续进化，突破静态人类生成数据的限制


<details>
  <summary>Details</summary>
Motivation: 传统通过扩大模型规模、训练数据和计算能力的方法已接近饱和，人类生成文本资源耗尽，增益递减

Method: 经验扩展框架：捕获原始交互→提炼为紧凑可重用知识→定期优化存储内容以保持相关性和效率

Result: 在模拟真实场景中验证，包括泛化到未见相关任务、重复查询和过饱和知识库，在所有设置中均提高准确性、维持性能并在新情境中保持增益

Conclusion: 结构化部署后学习可以扩展LLM能力，超越静态人类生成数据的限制，为持续智能进步提供可扩展路径

Abstract: Scaling model size, training data, and compute power have driven advances in
large language models (LLMs), but these approaches are reaching saturation as
human-generated text is exhausted and further gains diminish. We propose
experience scaling, a framework for continuous post-deployment evolution for
LLMs through autonomous interaction with the environment and collaborative
sharing of accumulated experience. The framework captures raw interactions,
distills them into compact, reusable knowledge, and periodically refines stored
content to preserve relevance and efficiency. We validate the framework in
simulated real-world scenarios involving generalization to previously unseen
but related tasks, repetitive queries, and over-saturated knowledge stores.
Across all settings, experience scaling improves accuracy, sustains performance
over time, and maintains gains when applied to novel situations. These results
demonstrate that structured post-deployment learning can extend LLM
capabilities beyond the limits of static human-generated data, offering a
scalable path for continued intelligence progress.

</details>


### [92] [The AGNTCY Agent Directory Service: Architecture and Implementation](https://arxiv.org/abs/2509.18787)
*Luca Muscariello,Vijoy Pandey,Ramiz Polic*

Main category: cs.AI

TL;DR: ADS是一个分布式目录服务，用于发现AI代理的能力、元数据和来源，采用内容寻址存储、分层分类和加密签名，支持异构多代理系统中的高效、可验证、多维发现。


<details>
  <summary>Details</summary>
Motivation: 解决异构多代理系统中代理能力发现、元数据管理和来源验证的挑战，提供统一的发现机制。

Method: 基于Open Agentic Schema Framework构建，采用两级映射的Kademlia分布式哈希表，重用OCI/ORAS基础设施进行工件分发，集成Sigstore进行来源验证。

Result: 实现了高效、可验证的代理能力发现系统，支持多种新兴代理模式（LLM提示代理、MCP服务器、A2A组件）。

Conclusion: ADS为新兴代理注册和互操作性计划提供了重要的架构模型，具有安全性和性能优势。

Abstract: The Agent Directory Service (ADS) is a distributed directory for the
discovery of AI agent capabilities, metadata, and provenance. It leverages
content-addressed storage, hierarchical taxonomies, and cryptographic signing
to enable efficient, verifiable, and multi-dimensional discovery across
heterogeneous Multi-Agent Systems (MAS). Built on the Open Agentic Schema
Framework (OASF), ADS decouples capability indexing from content location
through a two-level mapping realized over a Kademlia-based Distributed Hash
Table (DHT). It reuses mature OCI / ORAS infrastructure for artifact
distribution, integrates Sigstore for provenance, and supports schema-driven
extensibility for emerging agent modalities (LLM prompt agents, MCP servers,
A2A-enabled components). This paper formalizes the architectural model,
describes storage and discovery layers, explains security and performance
properties, and positions ADS within the broader landscape of emerging agent
registry and interoperability initiatives.

</details>


### [93] [Bounded PCTL Model Checking of Large Language Model Outputs](https://arxiv.org/abs/2509.18836)
*Dennis Gross,Helge Spieker,Arnaud Gotlieb*

Main category: cs.AI

TL;DR: LLMCHECKER是一种基于模型检查的验证方法，用于验证LLM文本生成过程的概率计算树逻辑(PCTL)属性。该方法通过α-k有界文本生成来限制生成过程中的token选择，从而实现对LLM生成过程的形式化验证。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对LLM文本生成过程的形式化验证方法，无法保证生成文本的一致性和可靠性。研究旨在开发一种能够验证LLM生成过程PCTL属性的系统化方法。

Method: 提出α-k有界文本生成方法，在每个生成步骤中只考虑累积概率最高的前k个token，并通过阈值α进一步筛选。LLMCHECKER利用模型检查技术来验证PCTL属性。

Result: 方法在多个LLM模型（Llama、Gemma、Mistral等）上进行了验证，能够有效检查文本生成过程的一致性，支持多种文本量化评估方法。

Conclusion: 这是首次将PCTL模型检查应用于LLM文本生成过程验证，为LLM的可靠性和安全性提供了新的形式化验证工具。

Abstract: In this paper, we introduce LLMCHECKER, a model-checking-based verification
method to verify the probabilistic computation tree logic (PCTL) properties of
an LLM text generation process. We empirically show that only a limited number
of tokens are typically chosen during text generation, which are not always the
same. This insight drives the creation of $\alpha$-$k$-bounded text generation,
narrowing the focus to the $\alpha$ maximal cumulative probability on the
top-$k$ tokens at every step of the text generation process. Our verification
method considers an initial string and the subsequent top-$k$ tokens while
accommodating diverse text quantification methods, such as evaluating text
quality and biases. The threshold $\alpha$ further reduces the selected tokens,
only choosing those that exceed or meet it in cumulative probability.
LLMCHECKER then allows us to formally verify the PCTL properties of
$\alpha$-$k$-bounded LLMs. We demonstrate the applicability of our method in
several LLMs, including Llama, Gemma, Mistral, Genstruct, and BERT. To our
knowledge, this is the first time PCTL-based model checking has been used to
check the consistency of the LLM text generation process.

</details>


### [94] [Model selection meets clinical semantics: Optimizing ICD-10-CM prediction via LLM-as-Judge evaluation, redundancy-aware sampling, and section-aware fine-tuning](https://arxiv.org/abs/2509.18846)
*Hong-Jie Dai,Zheng-Hao Li,An-Tai Lu,Bo-Tsz Shain,Ming-Ta Li,Tatheer Hussain Mir,Kuang-Te Wang,Min-I Su,Pei-Kang Liu,Ming-Ju Tsai*

Main category: cs.AI

TL;DR: 本文提出了一种模块化框架用于ICD-10-CM编码预测，通过系统化模型选择、冗余感知数据采样和结构化输入设计，解决了大型语言模型在医疗编码中的挑战。


<details>
  <summary>Details</summary>
Motivation: ICD编码对临床文档、计费和医疗分析至关重要，但目前仍是劳动密集且易出错的任务。虽然大型语言模型在自动化ICD编码方面有潜力，但在基础模型选择、输入上下文化和训练数据冗余方面存在挑战。

Method: 提出模块化框架，包括：1）使用LLM-as-judge评估协议和Plackett-Luce聚合来评估和排名开源LLM；2）引入基于嵌入的相似性度量和冗余感知采样策略；3）利用台湾医院的结构化出院摘要评估上下文效果。

Result: 在两个机构数据集上的实验表明，经过微调的基础模型在内部和外部评估中始终优于基线LLM。纳入更多临床部分能持续提高预测性能。

Conclusion: 该研究使用开源LLM建立了一种实用且原则性的ICD-10-CM编码预测方法，为自动化医疗编码系统的实际部署提供了可扩展、机构就绪的解决方案。

Abstract: Accurate International Classification of Diseases (ICD) coding is critical
for clinical documentation, billing, and healthcare analytics, yet it remains a
labour-intensive and error-prone task. Although large language models (LLMs)
show promise in automating ICD coding, their challenges in base model
selection, input contextualization, and training data redundancy limit their
effectiveness. We propose a modular framework for ICD-10 Clinical Modification
(ICD-10-CM) code prediction that addresses these challenges through principled
model selection, redundancy-aware data sampling, and structured input design.
The framework integrates an LLM-as-judge evaluation protocol with Plackett-Luce
aggregation to assess and rank open-source LLMs based on their intrinsic
comprehension of ICD-10-CM code definitions. We introduced embedding-based
similarity measures, a redundancy-aware sampling strategy to remove
semantically duplicated discharge summaries. We leverage structured discharge
summaries from Taiwanese hospitals to evaluate contextual effects and examine
section-wise content inclusion under universal and section-specific modelling
paradigms. Experiments across two institutional datasets demonstrate that the
selected base model after fine-tuning consistently outperforms baseline LLMs in
internal and external evaluations. Incorporating more clinical sections
consistently improves prediction performance. This study uses open-source LLMs
to establish a practical and principled approach to ICD-10-CM code prediction.
The proposed framework provides a scalable, institution-ready solution for
real-world deployment of automated medical coding systems by combining informed
model selection, efficient data refinement, and context-aware prompting.

</details>


### [95] [MAPO: Mixed Advantage Policy Optimization](https://arxiv.org/abs/2509.18849)
*Wenke Huang,Quan Zhang,Yiyang Fang,Jian Liang,Xuankun Rong,Huanjin Yao,Guancheng Wan,Ke Liang,Wenwen He,Mingjun Li,Leszek Rutkowski,Mang Ye,Bo Du,Dacheng Tao*

Main category: cs.AI

TL;DR: 提出了Mixed Advantage Policy Optimization (MAPO)方法，解决GRPO中优势函数分配问题，通过动态重加权处理不同轨迹确定性的样本。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO方法存在优势反转和优势镜像问题，阻碍了不同查询样本间的合理优势分配。

Method: 提出优势百分比偏差概念，对高确定性轨迹样本进行动态优势函数重加权，自适应配置优势函数以考虑样本特定特征。

Result: 与相关最先进方法的比较以及不同优势变体的消融研究验证了方法的有效性。

Conclusion: MAPO是一种简单但有效的GRPO策略，能够改善基础模型在推理任务上的性能。

Abstract: Recent advances in reinforcement learning for foundation models, such as
Group Relative Policy Optimization (GRPO), have significantly improved the
performance of foundation models on reasoning tasks. Notably, the advantage
function serves as a central mechanism in GRPO for ranking the trajectory
importance. However, existing explorations encounter both advantage reversion
and advantage mirror problems, which hinder the reasonable advantage allocation
across different query samples. In this work, we propose an easy but effective
GRPO strategy, Mixed Advantage Policy Optimization (MAPO). We reveal that the
trajectory appears with different certainty and propose the advantage percent
deviation for samples with high-certainty trajectories. Furthermore, we
dynamically reweight the advantage function for samples with varying trajectory
certainty, thereby adaptively configuring the advantage function to account for
sample-specific characteristics. Comparison with related state-of-the-art
methods, along with ablation studies on different advantage variants, validates
the effectiveness of our approach.

</details>


### [96] [Conf-Profile: A Confidence-Driven Reasoning Paradigm for Label-Free User Profiling](https://arxiv.org/abs/2509.18864)
*Yingxin Li,Jianbo Zhao,Xueyu Ren,Jie Tang,Wangjie You,Xu Chen,Kan Zhou,Chao Feng,Jiao Ran,Yuan Meng,Zhi Wang*

Main category: cs.AI

TL;DR: 提出了ProfileBench基准和Conf-Profile框架，通过置信度驱动的两阶段训练方法解决用户画像中的标签稀缺和噪声问题，显著提升了LLM在用户画像任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 用户画像作为用户理解的核心技术面临缺乏全面基准的挑战，同时大规模真实标签难以获取，异构噪声用户信息会影响LLM的可靠性。

Method: 提出Conf-Profile框架：1）利用高级LLM合成高质量标签；2）置信度加权投票和校准；3）置信度引导的无监督强化学习进行难度过滤和奖励加权。

Result: 实验结果表明Conf-Profile通过两阶段训练显著提升性能，在Qwen3-8B模型上F1分数提高了13.97。

Conclusion: 该研究为解决用户画像中的标签稀缺和可靠性问题提供了有效方案，证明了置信度驱动方法在提升LLM用户画像能力方面的有效性。

Abstract: User profiling, as a core technique for user understanding, aims to infer
structural attributes from user information. Large Language Models (LLMs)
provide a promising avenue for user profiling, yet the progress is hindered by
the lack of comprehensive benchmarks. To bridge this gap, we propose
ProfileBench, an industrial benchmark derived from a real-world video platform,
encompassing heterogeneous user data and a well-structured profiling taxonomy.
However, the profiling task remains challenging due to the difficulty of
collecting large-scale ground-truth labels, and the heterogeneous and noisy
user information can compromise the reliability of LLMs. To approach label-free
and reliable user profiling, we propose a Confidence-driven Profile reasoning
framework Conf-Profile, featuring a two-stage paradigm. We first synthesize
high-quality labels by leveraging advanced LLMs with confidence hints, followed
by confidence-weighted voting for accuracy improvement and confidence
calibration for a balanced distribution. The multiple profile results,
rationales, and confidence scores are aggregated and distilled into a
lightweight LLM. We further enhance the reasoning ability via confidence-guided
unsupervised reinforcement learning, which exploits confidence for difficulty
filtering, quasi-ground truth voting, and reward weighting. Experimental
results demonstrate that Conf-Profile delivers substantial performance through
the two-stage training, improving F1 by 13.97 on Qwen3-8B.

</details>


### [97] [Memory in Large Language Models: Mechanisms, Evaluation and Evolution](https://arxiv.org/abs/2509.18868)
*Dianxing Zhang,Wendong Li,Kani Song,Jiaye Lu,Gang Li,Liuchun Yang,Sheng Li*

Main category: cs.AI

TL;DR: 本文提出了一个统一的LLM记忆定义和四部分分类法（参数化、上下文、外部、程序性/情景性），建立了记忆四元组和评估框架，并开发了DMM Gov系统用于记忆更新和遗忘的治理。


<details>
  <summary>Details</summary>
Motivation: 为了解决LLM记忆研究中缺乏统一操作定义、评估标准不一致以及记忆治理机制不完善的问题，需要建立一个可重现、可比较和可治理的坐标系。

Method: 采用三设置协议（仅参数化、离线检索、在线检索）解耦能力与信息可用性，构建分层评估框架，并开发DMM Gov系统协调多种技术实现记忆的审计循环。

Result: 建立了一个包含时间治理、泄漏审计和不确定性报告的综合框架，提出了四个可测试的命题，为LLM记忆研究提供了系统化的方法论。

Conclusion: 该研究为LLM记忆的研究和部署提供了一个可重现、可比较和可治理的坐标系，解决了当前记忆研究中的关键挑战。

Abstract: Under a unified operational definition, we define LLM memory as a persistent
state written during pretraining, finetuning, or inference that can later be
addressed and that stably influences outputs. We propose a four-part taxonomy
(parametric, contextual, external, procedural/episodic) and a memory quadruple
(location, persistence, write/access path, controllability). We link mechanism,
evaluation, and governance via the chain write -> read -> inhibit/update. To
avoid distorted comparisons across heterogeneous setups, we adopt a
three-setting protocol (parametric only, offline retrieval, online retrieval)
that decouples capability from information availability on the same data and
timeline. On this basis we build a layered evaluation: parametric (closed-book
recall, edit differential, memorization/privacy), contextual (position curves
and the mid-sequence drop), external (answer correctness vs snippet
attribution/faithfulness), and procedural/episodic (cross-session consistency
and timeline replay, E MARS+). The framework integrates temporal governance and
leakage auditing (freshness hits, outdated answers, refusal slices) and
uncertainty reporting via inter-rater agreement plus paired tests with
multiple-comparison correction. For updating and forgetting, we present DMM
Gov: coordinating DAPT/TAPT, PEFT, model editing (ROME, MEND, MEMIT, SERAC),
and RAG to form an auditable loop covering admission thresholds, rollout,
monitoring, rollback, and change audits, with specs for timeliness, conflict
handling, and long-horizon consistency. Finally, we give four testable
propositions: minimum identifiability; a minimal evaluation card; causally
constrained editing with verifiable forgetting; and when retrieval with
small-window replay outperforms ultra-long-context reading. This yields a
reproducible, comparable, and governable coordinate system for research and
deployment.

</details>


### [98] [LongCat-Flash-Thinking Technical Report](https://arxiv.org/abs/2509.18883)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chengcheng Han,Chenhui Yang,Chi Zhang,Chong Peng,Chuyu Zhang,Cong Chen,Fengcun Li,Gang Xu,Guoyuan Lin,Hao Jiang,Hao Liang,Haomin Fu,Haoxiang Ma,Hong Liu,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiahao Liu,Jiahuan Li,Jialin Liu,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiaqi Sun,Jiaqi Zhang,Jiarong Shi,Jiawei Yang,Jingang Wang,Jinrui Ding,Jun Kuang,Jun Xu,Ke He,Kefeng Zhang,Keheng Wang,Keqing He,Li Wei,Liang Shi,Lin Qiu,Lingbin Kong,Lingchuan Liu,Linsen Guo,Longfei An,Mai Xia,Meng Zhou,Mengshen Zhu,Peng Pei,Pengcheng Jia,Qi Gu,Qi Guo,Qiong Huang,Quan Chen,Quanchi Weng,Rongxiang Weng,Ruichen Shao,Rumei Li,Shanglin Lei,Shuai Du,Shuaikang Liu,Shuang Zhou,Shuhao Hu,Siyu Xu,Songshan Gong,Tao Liang,Tianhao Hu,Wei He,Wei Shi,Wei Wang,Wei Wu,Wei Zhuo,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Xi Su,Xiangcheng Liu,Xiangyu Xi,Xiangzhou Huang,Xiao Liu,Xiaochen Jiang,Xiaowei Shi,Xiaowen Shi,Xiaoyu Li,Xin Chen,Xinyue Zhao,Xuan Huang,Xuemiao Zhang,Xuezhi Cao,Xunliang Cai,Yajie Zhang,Yang Chen,Yang Liu,Yang Liu,Yang Zheng,Yaoming Wang,Yaqi Huo,Yerui Sun,Yifan Lu,Yiyang Li,Youshao Xiao,Yuanzhe Lei,Yuchen Xie,Yueqing Sun,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunke Zhao,Yuqing Ding,Yuwei Jiang,Zhaohua Yang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhongda Su,Ziran Li,Ziwen Wang,Ziyuan Zhuang,Zongyu Wang,Zunyuan Yang*

Main category: cs.AI

TL;DR: LongCat-Flash-Thinking是一个5600亿参数的混合专家推理模型，通过精心设计的训练流程实现高效推理能力，包括长链思维数据冷启动和大规模强化学习，在复杂推理任务上达到开源模型的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 开发一个高效的大规模推理模型，解决传统模型在复杂推理任务中token消耗高、效率低的问题，推动推理系统和智能体AI研究的进步。

Method: 采用混合专家架构，通过长链思维数据冷启动训练策略增强推理潜力，然后使用领域并行训练方案将不同领域的专家模型融合为接近帕累托最优的单一模型，整个过程由DORA大规模RL框架支持。

Result: 在AIME-25上实现了64.5%的平均token消耗减少（从19,653降至6,965），同时保持任务准确率不下降，在复杂推理任务上达到开源模型的最先进性能。

Conclusion: LongCat-Flash-Thinking展示了高效推理模型的可行性，为推理系统和智能体AI研究提供了重要进展，模型已开源以促进进一步研究。

Abstract: We present LongCat-Flash-Thinking, an efficient 560-billion-parameter
open-source Mixture-of-Experts (MoE) reasoning model. Its advanced capabilities
are cultivated through a meticulously crafted training process, beginning with
long Chain-of-Thought (CoT) data cold-start and culminating in large-scale
Reinforcement Learning (RL). We first employ a well-designed cold-start
training strategy, which significantly enhances the reasoning potential and
equips the model with specialized skills in both formal and agentic reasoning.
Then, a core innovation is our domain-parallel training scheme, which decouples
optimization across distinct domains (e.g., STEM, Code, Agentic) and
subsequently fuses the resulting expert models into a single, nearly
Pareto-optimal model. This entire process is powered by our Dynamic
ORchestration for Asynchronous rollout (DORA) system, a large-scale RL
framework that delivers a greater than threefold training speedup over
synchronous methods on tens of thousands of accelerators. As a result,
LongCat-Flash-Thinking achieves state-of-the-art performance among open-source
models on a suite of complex reasoning tasks. The model exhibits exceptional
efficiency in agentic reasoning, reducing average token consumption by 64.5%
(from 19, 653 to 6, 965) on AIME-25, without degrading task accuracy. We
release LongCat-Flash-Thinking to promote further advances in reasoning systems
and agentic AI research.

</details>


### [99] [How Far are VLMs from Visual Spatial Intelligence? A Benchmark-Driven Perspective](https://arxiv.org/abs/2509.18905)
*Songsong Yu,Yuxin Chen,Hao Ju,Lianjie Jia,Fuxi Zhang,Shaofei Huang,Yuhan Wu,Rundi Cui,Binghao Ran,Zaibin Zhang,Zhedong Zheng,Zhipeng Zhang,Yifan Wang,Lin Song,Lijun Wang,Yanwei Li,Ying Shan,Huchuan Lu*

Main category: cs.AI

TL;DR: 本文系统研究视觉空间推理（VSR）在视觉语言模型中的表现，提出三层空间智能能力分类，并创建SIBench基准测试，发现当前模型在感知任务表现良好但在理解和规划任务上存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 视觉空间推理是人类核心认知能力，对推进具身智能和自主系统至关重要。尽管视觉语言模型取得进展，但由于三维空间表示和推理的复杂性，达到人类水平的VSR仍极具挑战。

Method: 系统综述现有方法（输入模态、模型架构、训练策略、推理机制），将空间智能分为三层能力（基础感知、空间理解、空间规划），并构建SIBench基准测试，涵盖23个任务设置的近20个开源数据集。

Result: 实验表明最先进VLMs在感知和推理之间存在明显差距，模型在基础感知任务上有能力，但在理解和规划任务上持续表现不佳，特别是在数值估计、多视角推理、时间动态和空间想象方面。

Conclusion: 这些发现强调了实现空间智能仍面临的重大挑战，同时为未来研究提供了系统路线图和全面基准测试。

Abstract: Visual Spatial Reasoning (VSR) is a core human cognitive ability and a
critical requirement for advancing embodied intelligence and autonomous
systems. Despite recent progress in Vision-Language Models (VLMs), achieving
human-level VSR remains highly challenging due to the complexity of
representing and reasoning over three-dimensional space. In this paper, we
present a systematic investigation of VSR in VLMs, encompassing a review of
existing methodologies across input modalities, model architectures, training
strategies, and reasoning mechanisms. Furthermore, we categorize spatial
intelligence into three levels of capability, ie, basic perception, spatial
understanding, spatial planning, and curate SIBench, a spatial intelligence
benchmark encompassing nearly 20 open-source datasets across 23 task settings.
Experiments with state-of-the-art VLMs reveal a pronounced gap between
perception and reasoning, as models show competence in basic perceptual tasks
but consistently underperform in understanding and planning tasks, particularly
in numerical estimation, multi-view reasoning, temporal dynamics, and spatial
imagination. These findings underscore the substantial challenges that remain
in achieving spatial intelligence, while providing both a systematic roadmap
and a comprehensive benchmark to drive future research in the field. The
related resources of this study are accessible at
https://sibench.github.io/Awesome-Visual-Spatial-Reasoning/.

</details>


### [100] [Data Efficient Adaptation in Large Language Models via Continuous Low-Rank Fine-Tuning](https://arxiv.org/abs/2509.18942)
*Xiao Han,Zimo Zhao,Wanyu Wang,Maolin Wang,Zitao Liu,Yi Chang,Xiangyu Zhao*

Main category: cs.AI

TL;DR: DEAL是一个新颖的框架，将低秩适应（LoRA）与连续微调策略相结合，通过知识保留和自适应参数更新模块解决传统微调方法中的灾难性遗忘和数据效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 传统微调方法存在灾难性遗忘和次优数据效率的问题，限制了其在实际应用中的适用性。本文旨在解决这些挑战，提升LLMs在特定任务上的适应能力。

Method: 提出DEAL框架，整合LoRA与连续微调策略，包含知识保留和自适应参数更新模块，在隐私保护设置下保持效率。

Result: 在15个不同数据集上的实验表明，DEAL在任务准确性和资源效率方面均优于基线方法，取得了显著提升。

Conclusion: DEAL框架通过增强任务性能和资源效率，展示了在LLMs中推进持续适应的潜力。

Abstract: Recent advancements in Large Language Models (LLMs) have emphasized the
critical role of fine-tuning (FT) techniques in adapting LLMs to specific
tasks, especially when retraining from scratch is computationally infeasible.
Fine-tuning enables LLMs to leverage task- or domain-specific data, producing
models that more effectively meet the requirements of targeted applications.
However, con- ventional FT approaches often suffer from catastrophic forgetting
and suboptimal data efficiency, limiting their real-world applicability. To
address these challenges, this paper proposes DEAL, a novel framework that
integrates Low-Rank Adapta- tion (LoRA) with a continuous fine-tuning strategy.
By incorporating knowledge retention and adaptive parameter update modules, the
framework mitigates the lim- itations of existing FT methods while maintaining
efficiency in privacy-preserving settings. Experiments on 15 diverse datasets
show that DEAL consistently outper- forms baseline methods, yielding
substantial gains in task accuracy and resource efficiency. These findings
demonstrate the potential of our approach to advance continual adaptation in
LLMs by enhancing task performance while improving resource efficiency.

</details>


### [101] [LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions](https://arxiv.org/abs/2509.18970)
*Xixun Lin,Yucheng Ning,Jingwen Zhang,Yan Dong,Yilong Liu,Yongxuan Wu,Xiaohua Qi,Nan Sun,Yanmin Shang,Pengfei Cao,Lixin Zou,Xu Chen,Chuan Zhou,Jia Wu,Shirui Pan,Bin Wang,Yanan Cao,Kai Chen,Songlin Hu,Li Guo*

Main category: cs.AI

TL;DR: 本文是关于LLM智能代理幻觉问题的首次全面综述，分析了代理工作流程中的幻觉类型、触发原因，并总结了缓解和检测方法。


<details>
  <summary>Details</summary>
Motivation: LLM智能代理在现实应用中面临幻觉问题，这会影响任务执行的准确性和系统可靠性，需要系统性地理解和解决这一问题。

Method: 通过分析代理的完整工作流程，提出了新的幻觉分类法，深入研究了18种幻觉触发原因，并综述了大量现有研究的缓解和检测方法。

Result: 提出了针对LLM代理幻觉的全面分类框架，识别了不同阶段出现的幻觉类型，并总结了有效的缓解策略。

Conclusion: 该综述为开发更健壮可靠的LLM代理系统提供了重要指导，并指出了未来研究的潜在方向。

Abstract: Driven by the rapid advancements of Large Language Models (LLMs), LLM-based
agents have emerged as powerful intelligent systems capable of human-like
cognition, reasoning, and interaction. These agents are increasingly being
deployed across diverse real-world applications, including student education,
scientific research, and financial analysis. However, despite their remarkable
potential, LLM-based agents remain vulnerable to hallucination issues, which
can result in erroneous task execution and undermine the reliability of the
overall system design. Addressing this critical challenge requires a deep
understanding and a systematic consolidation of recent advances on LLM-based
agents. To this end, we present the first comprehensive survey of
hallucinations in LLM-based agents. By carefully analyzing the complete
workflow of agents, we propose a new taxonomy that identifies different types
of agent hallucinations occurring at different stages. Furthermore, we conduct
an in-depth examination of eighteen triggering causes underlying the emergence
of agent hallucinations. Through a detailed review of a large number of
existing studies, we summarize approaches for hallucination mitigation and
detection, and highlight promising directions for future research. We hope this
survey will inspire further efforts toward addressing hallucinations in
LLM-based agents, ultimately contributing to the development of more robust and
reliable agent systems.

</details>


### [102] [From latent factors to language: a user study on LLM-generated explanations for an inherently interpretable matrix-based recommender system](https://arxiv.org/abs/2509.18980)
*Maxime Manderlier,Fabian Lecron,Olivier Vu Thanh,Nicolas Gillis*

Main category: cs.AI

TL;DR: 研究大型语言模型能否从数学可解释的推荐模型中生成有效的用户导向解释，通过用户研究评估不同解释策略的质量


<details>
  <summary>Details</summary>
Motivation: 现有可解释AI研究多依赖自动评估指标，难以捕捉用户实际需求和感知，需要采用用户中心的方法来评估解释质量

Method: 使用基于约束矩阵分解的可解释推荐模型，通过精心设计的LLM提示将模型结构转化为自然语言解释，对326名参与者进行用户研究，评估五种关键维度的解释质量

Result: 所有解释类型都受到良好接受，不同策略间存在中等统计差异，用户评论提供了定量结果之外的补充见解

Conclusion: LLM能够从数学可解释模型中生成有效的用户导向解释，用户中心评估方法为可解释AI提供了更全面的评估视角

Abstract: We investigate whether large language models (LLMs) can generate effective,
user-facing explanations from a mathematically interpretable recommendation
model. The model is based on constrained matrix factorization, where user types
are explicitly represented and predicted item scores share the same scale as
observed ratings, making the model's internal representations and predicted
scores directly interpretable. This structure is translated into natural
language explanations using carefully designed LLM prompts. Many works in
explainable AI rely on automatic evaluation metrics, which often fail to
capture users' actual needs and perceptions. In contrast, we adopt a
user-centered approach: we conduct a study with 326 participants who assessed
the quality of the explanations across five key dimensions-transparency,
effectiveness, persuasion, trust, and satisfaction-as well as the
recommendations themselves.To evaluate how different explanation strategies are
perceived, we generate multiple explanation types from the same underlying
model, varying the input information provided to the LLM. Our analysis reveals
that all explanation types are generally well received, with moderate
statistical differences between strategies. User comments further underscore
how participants react to each type of explanation, offering complementary
insights beyond the quantitative results.

</details>


### [103] [Remaining Time Prediction in Outbound Warehouse Processes: A Case Study (Short Paper)](https://arxiv.org/abs/2509.18986)
*Erik Penther,Michael Grohs,Jana-Rebecca Rehse*

Main category: cs.AI

TL;DR: 本文比较了四种剩余时间预测方法在物流公司出库仓库流程中的表现，发现深度学习模型准确率最高，但浅层方法如传统提升技术在计算资源需求上更少且具有竞争力。


<details>
  <summary>Details</summary>
Motivation: 预测性流程监控旨在预测正在进行的流程执行的未来，其中剩余时间预测是一个常见目标。本文旨在在真实物流公司的出库仓库流程中比较不同剩余时间预测方法的性能。

Method: 在物流公司提供的包含169,523条轨迹的新颖事件日志上，比较了四种剩余时间预测方法，包括深度学习模型和浅层方法（如传统提升技术）。

Result: 深度学习模型达到了最高的准确率，但浅层方法如传统提升技术也实现了具有竞争力的准确率，并且需要显著更少的计算资源。

Conclusion: 虽然深度学习在准确率上表现最佳，但浅层方法在准确率和计算效率之间提供了更好的平衡，特别是在资源受限的环境中可能更具实用性。

Abstract: Predictive process monitoring is a sub-domain of process mining which aims to
forecast the future of ongoing process executions. One common prediction target
is the remaining time, meaning the time that will elapse until a process
execution is completed. In this paper, we compare four different remaining time
prediction approaches in a real-life outbound warehouse process of a logistics
company in the aviation business. For this process, the company provided us
with a novel and original event log with 169,523 traces, which we can make
publicly available. Unsurprisingly, we find that deep learning models achieve
the highest accuracy, but shallow methods like conventional boosting techniques
achieve competitive accuracy and require significantly fewer computational
resources.

</details>


### [104] [Landmarks, Monuments, and Beacons: Understanding Generative Calls to Action](https://arxiv.org/abs/2509.19030)
*Victoire Hervé,Henrik Warpefelt,Christoph Salge*

Main category: cs.AI

TL;DR: 该论文提出了基于玩家视角的Landmarks、Monuments和Beacons概念，用于解决程序生成内容评估中度量标准与人类体验对齐的问题，旨在实现PCG的自动分解和评估。


<details>
  <summary>Details</summary>
Motivation: 程序生成内容的算法评估难以找到与人类体验一致的度量标准，特别是对于复合产物。自动分解作为一种可能的解决方案需要满足一系列属性的概念。

Method: 借鉴游戏研究和游戏AI研究，引入了基于产物可感知性、唤起性和行动召唤的Landmarks、Monuments和Beacons嵌套概念，这些概念具有游戏通用性和跨流派可用性。

Result: 论证了这些实体可以通过当前研究和工业中使用的技术来发现和评估，为PCG的完全自动分解和重要子组件的评估开辟了路径。

Conclusion: 该方法旨在建立人文科学与技术游戏研究之间的联系，实现更好的计算PCG评估，虽然重点强调混合主动PCG和组合PCG，但相信其应用范围更广。

Abstract: Algorithmic evaluation of procedurally generated content struggles to find
metrics that align with human experience, particularly for composite artefacts.
Automatic decomposition as a possible solution requires concepts that meet a
range of properties. To this end, drawing on Games Studies and Game AI
research, we introduce the nested concepts of \textit{Landmarks},
\textit{Monuments}, and \textit{Beacons}. These concepts are based on the
artefact's perceivability, evocativeness, and Call to Action, all from a
player-centric perspective. These terms are generic to games and usable across
genres. We argue that these entities can be found and evaluated with techniques
currently used in both research and industry, opening a path towards a fully
automated decomposition of PCG, and evaluation of the salient sub-components.
Although the work presented here emphasises mixed-initiative PCG and
compositional PCG, we believe it applies beyond those domains. With this
approach, we intend to create a connection between humanities and technical
game research and allow for better computational PCG evaluation

</details>


### [105] [Towards Causal Representation Learning with Observable Sources as Auxiliaries](https://arxiv.org/abs/2509.19058)
*Kwonho Kim,Heejeong Nam,Inwoo Hwang,Sanghack Lee*

Main category: cs.AI

TL;DR: 本文提出了一个使用可观测源作为辅助变量的因果表示学习框架，能够在已知潜在因果图的情况下，通过体积保持编码器识别整个潜在变量，并提供了变量选择方案来最大化潜在因子的可恢复性。


<details>
  <summary>Details</summary>
Motivation: 现有因果表示学习框架通常将辅助变量限制在混合函数外部，但在某些情况下，系统驱动的潜在因子可以从数据中轻松观测或提取，这可能有助于识别。本文旨在扩展辅助变量的范围，利用可观测源作为有效的条件变量。

Method: 引入可观测源作为辅助变量的框架，使用体积保持编码器实现潜在变量的子空间变换和排列识别。当存在多个已知辅助变量时，提供变量选择方案来选择那些能最大化潜在因子可恢复性的变量。

Result: 通过合成图和图像数据的实验证明，该框架能够有效识别潜在变量，扩展了当前方法的边界。

Conclusion: 本文提出的框架成功地将可观测源作为辅助变量，为因果表示学习提供了新的识别方法，特别是在已知潜在因果图的情况下能够有效恢复潜在因子。

Abstract: Causal representation learning seeks to recover latent factors that generate
observational data through a mixing function. Needing assumptions on latent
structures or relationships to achieve identifiability in general, prior works
often build upon conditional independence given known auxiliary variables.
However, prior frameworks limit the scope of auxiliary variables to be external
to the mixing function. Yet, in some cases, system-driving latent factors can
be easily observed or extracted from data, possibly facilitating
identification. In this paper, we introduce a framework of observable sources
being auxiliaries, serving as effective conditioning variables. Our main
results show that one can identify entire latent variables up to subspace-wise
transformations and permutations using volume-preserving encoders. Moreover,
when multiple known auxiliary variables are available, we offer a
variable-selection scheme to choose those that maximize recoverability of the
latent factors given knowledge of the latent causal graph. Finally, we
demonstrate the effectiveness of our framework through experiments on synthetic
graph and image data, thereby extending the boundaries of current approaches.

</details>


### [106] [Code Driven Planning with Domain-Adaptive Critic](https://arxiv.org/abs/2509.19077)
*Zikang Tian,Shaohui Peng,Du Huang,Jiaming Guo,Ruizhi Chen,Rui Zhang,Xishan Zhang,Yuxuan Guo,Zidong Du,Qi Guo,Ling Li,Yewen Pu,Xing Hu,Yunji Chen*

Main category: cs.AI

TL;DR: CoPiC提出了一种基于代码驱动规划和领域自适应批评器的LLM规划方法，通过生成多样化高级规划程序并利用训练好的批评器评估候选计划，显著减少LLM查询次数并提高长期奖励对齐。


<details>
  <summary>Details</summary>
Motivation: 现有LLM规划方法依赖频繁查询进行迭代优化，导致高查询成本且难以实现长期奖励对齐。需要一种既能减少查询次数又能优化长期规划性能的方法。

Method: 1) 使用LLM生成多样化高级规划程序；2) 迭代生成和优化候选计划；3) 训练领域自适应批评器评估候选计划；4) 选择与长期奖励最对齐的计划执行。

Result: 在ALFWorld、NetHack和StarCraft II Unit Building三个环境中，CoPiC相比AdaPlanner和Reflexion基线方法，平均成功率提升23.33%，查询成本降低91.27%。

Conclusion: CoPiC通过代码驱动规划和领域自适应批评器的结合，有效解决了LLM规划中的查询成本高和长期奖励对齐问题，在多个复杂环境中表现出优越性能。

Abstract: Large Language Models (LLMs) have been widely adopted as task planners for AI
agents in sequential decision-making problems, leveraging their extensive world
knowledge. However, the gap between their general knowledge and
environment-specific requirements often leads to inaccurate plans. To address
this, existing approaches rely on frequent LLM queries to iteratively refine
plans based on immediate environmental feedback, which incurs substantial query
costs. However, this refinement is typically guided by short-term environmental
feedback, limiting LLMs from developing plans aligned with long-term rewards.
We propose Code Driven Planning with Domain-Adaptive Critic (CoPiC). Instead of
relying on frequent queries, CoPiC employs LLMs to generate a diverse set of
high-level planning programs, which iteratively produce and refine candidate
plans. A trained domain-adaptive critic then evaluates these candidates and
selects the one most aligned with long-term rewards for execution. Using
high-level planning programs as planner and domain-adaptive critic as
estimator, CoPiC improves planning while significantly reducing query costs.
Results in ALFWorld, NetHack, and StarCraft II Unit Building show that CoPiC
outperforms advanced LLM-based baselines, AdaPlanner and Reflexion, achieving
an average (1) 23.33% improvement in success rate and (2) 91.27% reduction in
query costs.

</details>


### [107] [AgentInit: Initializing LLM-based Multi-Agent Systems via Diversity and Expertise Orchestration for Effective and Efficient Collaboration](https://arxiv.org/abs/2509.19236)
*Chunhao Tian,Yutong Wang,Xuebo Liu,Zhexuan Wang,Liang Ding,Miao Zhang,Min Zhang*

Main category: cs.AI

TL;DR: AgentInit是一种多智能体系统初始化方法，通过优化智能体团队结构来提升系统性能，结合自然语言到格式机制和帕累托平衡选择策略。


<details>
  <summary>Details</summary>
Motivation: 现有MAS初始化方法未能充分考虑生成智能体在后续阶段的协作需求，需要更好的团队组合优化方法。

Method: AgentInit包含多轮智能体交互与反思、自然语言到格式机制确保一致性，以及基于帕累托原则的平衡团队选择策略来兼顾多样性和任务相关性。

Result: 实验表明AgentInit在各种框架和任务中优于现有初始化方法，性能提升达1.2-1.6倍，同时显著减少token消耗，并具有良好的可迁移性。

Conclusion: AgentInit作为一种可靠的MAS初始化方法，展示了强大的能力和适应性，能有效促进智能体协作并提升整体系统性能。

Abstract: Proper initialization is crucial for any system, particularly in multi-agent
systems (MAS), where it plays a pivotal role in determining both the system's
efficiency and effectiveness. However, existing MAS initialization methods do
not fully account for the collaborative needs of the generated agents in
subsequent stages. Inspired by the principles of effective team composition, we
propose AgentInit, which aims to optimize the structure of agent teams.
Specifically, in addition to multi-round interactions and reflections between
agents during agent generation, AgentInit incorporates a Natural Language to
Format mechanism to ensure consistency and standardization. Balanced team
selection strategies using Pareto principles are subsequently applied to
jointly consider agent team diversity and task relevance to promote effective
and efficient collaboration and enhance overall system performance. Experiments
show that AgentInit consistently outperforms state-of-the-art initialization
methods and pre-defined strategies across various frameworks and tasks,
achieving an overall performance improvement of up to 1.2 and 1.6,
respectively, while also significantly reducing token consumption. Further
analysis confirms its strong transferability to similar tasks and verifies the
effectiveness of its key components, demonstrating its capability and
adaptability as a reliable MAS initialization method. Source code and models
are available at https://github.com/1737423697/AgentInit.

</details>


### [108] [Cross-Cultural Transfer of Commonsense Reasoning in LLMs: Evidence from the Arab World](https://arxiv.org/abs/2509.19265)
*Saeed Almheiri,Rania Hossam,Mena Attia,Chenxi Wang,Preslav Nakov,Timothy Baldwin,Fajri Koto*

Main category: cs.AI

TL;DR: 本文研究了大型语言模型在阿拉伯世界的跨文化常识推理迁移，发现仅需少量文化特定示例即可显著提升模型在其他文化背景下的性能，证明了高效跨文化对齐的可能性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在西方中心偏见，限制了其在多元文化背景下的有效性。虽然已有研究探索文化对齐，但跨文化迁移潜力（利用一种文化的对齐来提升其他文化性能）仍未被充分探索。

Method: 使用覆盖13个阿拉伯国家的文化基础常识推理数据集，评估轻量级对齐方法（上下文学习、演示强化DITTO）以及监督微调和直接偏好优化基线。

Result: 仅需12个来自一个国家的文化特定示例，即可在多语言模型中平均提升其他国家的性能10%。来自印尼和美国的文化外演示在MCQ推理中能够匹配或超越文化内对齐效果。

Conclusion: 高效跨文化对齐是可行的，这为将LLMs适配到低资源文化环境提供了一种有前景的方法。

Abstract: Large language models (LLMs) often reflect Western-centric biases, limiting
their effectiveness in diverse cultural contexts. Although some work has
explored cultural alignment, the potential for cross-cultural transfer, using
alignment in one culture to improve performance in others, remains
underexplored. This paper investigates cross-cultural transfer of commonsense
reasoning in the Arab world, where linguistic and historical similarities
coexist with local cultural differences. Using a culturally grounded
commonsense reasoning dataset covering 13 Arab countries, we evaluate
lightweight alignment methods such as in-context learning and
demonstration-based reinforcement (DITTO), alongside baselines like supervised
fine-tuning and direct preference optimization. Our results show that merely 12
culture-specific examples from one country can improve performance in others by
10\% on average, within multilingual models. In addition, we demonstrate that
out-of-culture demonstrations from Indonesia and US contexts can match or
surpass in-culture alignment for MCQ reasoning, highlighting cultural
commonsense transferability beyond the Arab world. These findings demonstrate
that efficient cross-cultural alignment is possible and offer a promising
approach to adapt LLMs to low-resource cultural settings.

</details>
