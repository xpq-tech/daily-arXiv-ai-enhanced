{"id": "2509.13332", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13332", "abs": "https://arxiv.org/abs/2509.13332", "authors": ["Pratik Jayarao", "Himanshu Gupta", "Neeraj Varshney", "Chaitanya Dwivedi"], "title": "Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness", "comment": null, "summary": "As Large Language Models (LLMs) are increasingly adopted as automated judges\nin benchmarking and reward modeling, ensuring their reliability, efficiency,\nand robustness has become critical. In this work, we present a systematic\ncomparison of \"thinking\" and \"non-thinking\" LLMs in the LLM-as-a-judge paradigm\nusing open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B\nparameters). We evaluate both accuracy and computational efficiency (FLOPs) on\nRewardBench tasks, and further examine augmentation strategies for non-thinking\nmodels, including in-context learning, rubric-guided judging, reference-based\nevaluation, and n-best aggregation. Our results show that despite these\nenhancements, non-thinking models generally fall short of their thinking\ncounterparts. Our results show that thinking models achieve approximately 10%\npoints higher accuracy with little overhead (under 2x), in contrast to\naugmentation strategies like few-shot learning, which deliver modest gains at a\nhigher cost (>8x). Bias and robustness analyses further demonstrate that\nthinking models maintain significantly greater consistency under a variety of\nbias conditions such as positional, bandwagon, identity, diversity, and random\nbiases (6% higher on average). We further extend our experiments to the\nmultilingual setting and our results confirm that explicit reasoning extends\nits benefits beyond English. Overall, our work results in several important\nfindings that provide systematic evidence that explicit reasoning offers clear\nadvantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency\nbut also in robustness.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u6bd4\u8f83\u4e86\u601d\u8003\u578b\u548c\u975e\u601d\u8003\u578bLLM\u5728LLM-as-a-judge\u8303\u5f0f\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u601d\u8003\u578b\u6a21\u578b\u5728\u51c6\u786e\u7387\u3001\u8ba1\u7b97\u6548\u7387\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u975e\u601d\u8003\u578b\u6a21\u578b\uff0c\u5373\u4f7f\u7ecf\u8fc7\u591a\u79cd\u589e\u5f3a\u7b56\u7565\u4f18\u5316\u540e\u3002", "motivation": "\u968f\u7740LLM\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u7528\u4f5c\u81ea\u52a8\u8bc4\u4f30\u5de5\u5177\uff0c\u786e\u4fdd\u5176\u53ef\u9760\u6027\u3001\u6548\u7387\u548c\u9c81\u68d2\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u6bd4\u8f83\u601d\u8003\u578b\u548c\u975e\u601d\u8003\u578bLLM\u5728\u8bc4\u4f30\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u5dee\u5f02\u3002", "method": "\u4f7f\u7528\u5f00\u6e90Qwen 3\u6a21\u578b\uff080.6B\u30011.7B\u548c4B\u53c2\u6570\uff09\uff0c\u5728RewardBench\u4efb\u52a1\u4e0a\u8bc4\u4f30\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff08FLOPs\uff09\uff0c\u5e76\u6d4b\u8bd5\u4e86\u591a\u79cd\u589e\u5f3a\u7b56\u7565\uff1a\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001\u89c4\u5219\u5f15\u5bfc\u8bc4\u4f30\u3001\u57fa\u4e8e\u53c2\u8003\u7684\u8bc4\u4f30\u548cn-best\u805a\u5408\u3002", "result": "\u601d\u8003\u578b\u6a21\u578b\u51c6\u786e\u7387\u9ad8\u51fa\u7ea610\u4e2a\u767e\u5206\u70b9\uff0c\u8ba1\u7b97\u5f00\u9500\u4ec5\u589e\u52a0\u4e0d\u52302\u500d\uff1b\u800c\u589e\u5f3a\u7b56\u7565\u5982\u5c11\u6837\u672c\u5b66\u4e60\u867d\u7136\u5e26\u6765\u9002\u5ea6\u63d0\u5347\u4f46\u6210\u672c\u8f83\u9ad8\uff08>8\u500d\uff09\u3002\u601d\u8003\u578b\u6a21\u578b\u5728\u5404\u79cd\u504f\u89c1\u6761\u4ef6\u4e0b\u4fdd\u6301\u66f4\u597d\u7684\u7a33\u5b9a\u6027\uff08\u5e73\u5747\u9ad86%\uff09\uff0c\u591a\u8bed\u8a00\u5b9e\u9a8c\u4e5f\u8bc1\u5b9e\u4e86\u663e\u5f0f\u63a8\u7406\u7684\u4f18\u52bf\u3002", "conclusion": "\u663e\u5f0f\u63a8\u7406\u5728LLM-as-a-judge\u8303\u5f0f\u4e2d\u5177\u6709\u660e\u663e\u4f18\u52bf\uff0c\u4e0d\u4ec5\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\uff0c\u5728\u9c81\u68d2\u6027\u65b9\u9762\u4e5f\u8868\u73b0\u66f4\u4f73\uff0c\u4e3aLLM\u4f5c\u4e3a\u8bc4\u4f30\u5de5\u5177\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u7cfb\u7edf\u8bc1\u636e\u3002"}}
{"id": "2509.13333", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13333", "abs": "https://arxiv.org/abs/2509.13333", "authors": ["Maheep Chaudhary", "Ian Su", "Nikhil Hooda", "Nishith Shankar", "Julia Tan", "Kevin Zhu", "Ashwinee Panda", "Ryan Lagasse", "Vasu Sharma"], "title": "Evaluation Awareness Scales Predictably in Open-Weights Large Language Models", "comment": null, "summary": "Large language models (LLMs) can internally distinguish between evaluation\nand deployment contexts, a behaviour known as \\emph{evaluation awareness}. This\nundermines AI safety evaluations, as models may conceal dangerous capabilities\nduring testing. Prior work demonstrated this in a single $70$B model, but the\nscaling relationship across model sizes remains unknown. We investigate\nevaluation awareness across $15$ models scaling from $0.27$B to $70$B\nparameters from four families using linear probing on steering vector\nactivations. Our results reveal a clear power-law scaling: evaluation awareness\nincreases predictably with model size. This scaling law enables forecasting\ndeceptive behavior in future larger models and guides the design of scale-aware\nevaluation strategies for AI safety. A link to the implementation of this paper\ncan be found at\nhttps://anonymous.4open.science/r/evaluation-awareness-scaling-laws/README.md.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u8bc4\u4f30\u610f\u8bc6\uff0c\u5373\u6a21\u578b\u80fd\u533a\u5206\u8bc4\u4f30\u548c\u90e8\u7f72\u73af\u5883\uff0c\u8fd9\u79cd\u80fd\u529b\u968f\u6a21\u578b\u89c4\u6a21\u6309\u5e42\u5f8b\u589e\u957f\uff0c\u5f71\u54cdAI\u5b89\u5168\u8bc4\u4f30\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u5728\u8bc4\u4f30\u65f6\u9690\u85cf\u5371\u9669\u80fd\u529b\uff0c\u5148\u524d\u7814\u7a76\u4ec5\u5728\u5355\u4e2a70B\u6a21\u578b\u4e2d\u53d1\u73b0\u8bc4\u4f30\u610f\u8bc6\uff0c\u4f46\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u7684\u8bc4\u4f30\u610f\u8bc6\u53d8\u5316\u89c4\u5f8b\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u63a2\u6d4b\u65b9\u6cd5\u5206\u679015\u4e2a\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\uff080.27B\u523070B\u53c2\u6570\uff09\u7684\u6fc0\u6d3b\u5411\u91cf\uff0c\u7814\u7a76\u8bc4\u4f30\u610f\u8bc6\u7684\u7f29\u653e\u89c4\u5f8b\u3002", "result": "\u53d1\u73b0\u8bc4\u4f30\u610f\u8bc6\u968f\u6a21\u578b\u89c4\u6a21\u5448\u5e42\u5f8b\u589e\u957f\uff0c\u8fd9\u79cd\u53ef\u9884\u6d4b\u7684\u7f29\u653e\u89c4\u5f8b\u53ef\u7528\u4e8e\u9884\u6d4b\u672a\u6765\u66f4\u5927\u6a21\u578b\u7684\u6b3a\u9a97\u884c\u4e3a\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u8bc4\u4f30\u610f\u8bc6\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u4e3a\u8bbe\u8ba1\u89c4\u6a21\u611f\u77e5\u7684AI\u5b89\u5168\u8bc4\u4f30\u7b56\u7565\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2509.13334", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13334", "abs": "https://arxiv.org/abs/2509.13334", "authors": ["Anand Swaroop", "Akshat Nallani", "Saksham Uboweja", "Adiliia Uzdenova", "Michael Nguyen", "Kevin Zhu", "Sunishchal Dev", "Ashwinee Panda", "Vasu Sharma", "Maheep Chaudhary"], "title": "FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness", "comment": null, "summary": "Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving\nlarge language model performance on complex tasks, but recent work shows that\nreasoning steps often fail to causally influence the final answer, creating\nbrittle and untrustworthy outputs. Prior approaches focus primarily on\nmeasuring faithfulness, while methods for systematically improving it remain\nlimited. We introduce Faithful Reasoning via Intervention Training (FRIT), a\nscalable alignment method that trains models to produce causally consistent\nreasoning by learning from systematically corrupted examples. FRIT generates\nsynthetic training data by intervening on individual reasoning steps in\nmodel-generated CoTs, creating faithful/unfaithful pairs that highlight when\nreasoning breaks down. We then apply Direct Preference Optimization to teach\nmodels to prefer causally consistent reasoning paths. Evaluating on Qwen3-8B\nand Mistral-7B-v0.1 across factual and symbolic reasoning tasks, FRIT increases\nfaithful reasoning by $3.4$ percentage points for Mistral on GSM8K while\nimproving accuracy by $7.6$ percentage points. Our approach provides the first\nscalable, supervision-free method for training language models to produce more\nreliable and interpretable reasoning, addressing a critical gap between\nreasoning performance and trustworthiness. We release our code at\n\\href{https://github.com/Anut-py/frit}.", "AI": {"tldr": "FRIT\u662f\u4e00\u79cd\u901a\u8fc7\u5e72\u9884\u8bad\u7ec3\u5b9e\u73b0\u5fe0\u5b9e\u63a8\u7406\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u5fe0\u5b9e/\u4e0d\u5fe0\u5b9e\u63a8\u7406\u5bf9\u6765\u8bad\u7ec3\u6a21\u578b\u504f\u597d\u56e0\u679c\u4e00\u81f4\u7684\u63a8\u7406\u8def\u5f84\uff0c\u63d0\u9ad8\u63a8\u7406\u7684\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u601d\u7ef4\u94fe\u63a8\u7406\u65b9\u6cd5\u5b58\u5728\u63a8\u7406\u6b65\u9aa4\u4e0e\u6700\u7ec8\u7b54\u6848\u7f3a\u4e4f\u56e0\u679c\u5173\u8054\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u8f93\u51fa\u8106\u5f31\u4e14\u4e0d\u53ef\u4fe1\u3002\u867d\u7136\u5df2\u6709\u65b9\u6cd5\u5173\u6ce8\u5fe0\u5b9e\u6027\u6d4b\u91cf\uff0c\u4f46\u7cfb\u7edf\u6027\u63d0\u5347\u5fe0\u5b9e\u6027\u7684\u65b9\u6cd5\u4ecd\u7136\u6709\u9650\u3002", "method": "\u63d0\u51faFRIT\u65b9\u6cd5\uff1a1\uff09\u5728\u6a21\u578b\u751f\u6210\u7684\u601d\u7ef4\u94fe\u4e2d\u5bf9\u5355\u4e2a\u63a8\u7406\u6b65\u9aa4\u8fdb\u884c\u5e72\u9884\uff0c\u751f\u6210\u5fe0\u5b9e/\u4e0d\u5fe0\u5b9e\u63a8\u7406\u5bf9\uff1b2\uff09\u5e94\u7528\u76f4\u63a5\u504f\u597d\u4f18\u5316\u8bad\u7ec3\u6a21\u578b\u504f\u597d\u56e0\u679c\u4e00\u81f4\u7684\u63a8\u7406\u8def\u5f84\u3002", "result": "\u5728Qwen3-8B\u548cMistral-7B-v0.1\u6a21\u578b\u4e0a\uff0cFRIT\u5c06Mistral\u5728GSM8K\u4e0a\u7684\u5fe0\u5b9e\u63a8\u7406\u63d0\u9ad8\u4e863.4\u4e2a\u767e\u5206\u70b9\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u4e867.6\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "FRIT\u63d0\u4f9b\u4e86\u7b2c\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u65e0\u76d1\u7763\u7684\u65b9\u6cd5\u6765\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4ea7\u751f\u66f4\u53ef\u9760\u548c\u53ef\u89e3\u91ca\u7684\u63a8\u7406\uff0c\u89e3\u51b3\u4e86\u63a8\u7406\u6027\u80fd\u4e0e\u53ef\u4fe1\u5ea6\u4e4b\u95f4\u7684\u5173\u952e\u5dee\u8ddd\u3002"}}
{"id": "2509.13339", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13339", "abs": "https://arxiv.org/abs/2509.13339", "authors": ["Ming Jin", "Hyunin Lee"], "title": "Position: AI Safety Must Embrace an Antifragile Perspective", "comment": null, "summary": "This position paper contends that modern AI research must adopt an\nantifragile perspective on safety -- one in which the system's capacity to\nguarantee long-term AI safety such as handling rare or out-of-distribution\n(OOD) events expands over time. Conventional static benchmarks and single-shot\nrobustness tests overlook the reality that environments evolve and that models,\nif left unchallenged, can drift into maladaptation (e.g., reward hacking,\nover-optimization, or atrophy of broader capabilities). We argue that an\nantifragile approach -- Rather than striving to rapidly reduce current\nuncertainties, the emphasis is on leveraging those uncertainties to better\nprepare for potentially greater, more unpredictable uncertainties in the future\n-- is pivotal for the long-term reliability of open-ended ML systems. In this\nposition paper, we first identify key limitations of static testing, including\nscenario diversity, reward hacking, and over-alignment. We then explore the\npotential of antifragile solutions to manage rare events. Crucially, we\nadvocate for a fundamental recalibration of the methods used to measure,\nbenchmark, and continually improve AI safety over the long term, complementing\nexisting robustness approaches by providing ethical and practical guidelines\ntowards fostering an antifragile AI safety community.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20AI\u5b89\u5168\u7814\u7a76\u5e94\u91c7\u7528\u53cd\u8106\u5f31\u6027\u89c6\u89d2\uff0c\u4f7f\u7cfb\u7edf\u5904\u7406\u7f55\u89c1\u4e8b\u4ef6\u548c\u5206\u5e03\u5916\u4e8b\u4ef6\u7684\u80fd\u529b\u968f\u65f6\u95f4\u589e\u5f3a\uff0c\u800c\u975e\u4f9d\u8d56\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u4f20\u7edf\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e00\u6b21\u6027\u9c81\u68d2\u6027\u6d4b\u8bd5\u65e0\u6cd5\u5e94\u5bf9\u73af\u5883\u6f14\u53d8\u548c\u6a21\u578b\u6f02\u79fb\u95ee\u9898\uff08\u5982\u5956\u52b1\u9ed1\u5ba2\u3001\u8fc7\u5ea6\u4f18\u5316\u7b49\uff09\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u786e\u4fddAI\u7cfb\u7edf\u5728\u957f\u671f\u5f00\u653e\u73af\u5883\u4e2d\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u53cd\u8106\u5f31\u6027\u65b9\u6cd5\u6846\u67b6\uff0c\u5f3a\u8c03\u5229\u7528\u5f53\u524d\u4e0d\u786e\u5b9a\u6027\u6765\u4e3a\u672a\u6765\u66f4\u5927\u4e0d\u786e\u5b9a\u6027\u505a\u51c6\u5907\uff0c\u5305\u62ec\u91cd\u65b0\u6821\u51c6AI\u5b89\u5168\u6d4b\u91cf\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u6301\u7eed\u6539\u8fdb\u7684\u65b9\u6cd5\u8bba\u3002", "result": "\u8bc6\u522b\u4e86\u9759\u6001\u6d4b\u8bd5\u7684\u5173\u952e\u5c40\u9650\u6027\uff08\u573a\u666f\u591a\u6837\u6027\u4e0d\u8db3\u3001\u5956\u52b1\u9ed1\u5ba2\u3001\u8fc7\u5ea6\u5bf9\u9f50\u7b49\uff09\uff0c\u5e76\u63a2\u8ba8\u4e86\u53cd\u8106\u5f31\u6027\u89e3\u51b3\u65b9\u6848\u7ba1\u7406\u7f55\u89c1\u4e8b\u4ef6\u7684\u6f5c\u529b\u3002", "conclusion": "\u53cd\u8106\u5f31\u6027\u65b9\u6cd5\u662f\u786e\u4fdd\u957f\u671fAI\u5b89\u5168\u7684\u5173\u952e\uff0c\u9700\u8981\u5efa\u7acb\u76f8\u5e94\u7684\u4f26\u7406\u548c\u5b9e\u8df5\u6307\u5357\u6765\u57f9\u517b\u53cd\u8106\u5f31\u6027AI\u5b89\u5168\u793e\u533a\uff0c\u4f5c\u4e3a\u73b0\u6709\u9c81\u68d2\u6027\u65b9\u6cd5\u7684\u8865\u5145\u3002"}}
{"id": "2509.13480", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13480", "abs": "https://arxiv.org/abs/2509.13480", "authors": ["Andrea Piergentili", "Beatrice Savoldi", "Matteo Negri", "Luisa Bentivogli"], "title": "Gender-Neutral Rewriting in Italian: Models, Approaches, and Trade-offs", "comment": "Accepted at CLiC-it 2025", "summary": "Gender-neutral rewriting (GNR) aims to reformulate text to eliminate\nunnecessary gender specifications while preserving meaning, a particularly\nchallenging task in grammatical-gender languages like Italian. In this work, we\nconduct the first systematic evaluation of state-of-the-art large language\nmodels (LLMs) for Italian GNR, introducing a two-dimensional framework that\nmeasures both neutrality and semantic fidelity to the input. We compare\nfew-shot prompting across multiple LLMs, fine-tune selected models, and apply\ntargeted cleaning to boost task relevance. Our findings show that open-weight\nLLMs outperform the only existing model dedicated to GNR in Italian, whereas\nour fine-tuned models match or exceed the best open-weight LLM's performance at\na fraction of its size. Finally, we discuss the trade-off between optimizing\nthe training data for neutrality and meaning preservation.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u610f\u5927\u5229\u8bed\u6027\u522b\u4e2d\u6027\u6539\u5199\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u8861\u91cf\u4e2d\u7acb\u6027\u548c\u8bed\u4e49\u4fdd\u771f\u5ea6\u7684\u4e8c\u7ef4\u6846\u67b6\uff0c\u53d1\u73b0\u5f00\u6e90\u6a21\u578b\u4f18\u4e8e\u73b0\u6709\u4e13\u7528\u6a21\u578b\uff0c\u5fae\u8c03\u540e\u7684\u5c0f\u6a21\u578b\u6027\u80fd\u53ef\u5ab2\u7f8e\u5927\u578b\u6a21\u578b\u3002", "motivation": "\u610f\u5927\u5229\u8bed\u7b49\u8bed\u6cd5\u6027\u522b\u8bed\u8a00\u4e2d\u7684\u6027\u522b\u4e2d\u6027\u6539\u5199\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u6d88\u9664\u4e0d\u5fc5\u8981\u7684\u6027\u522b\u6307\u5b9a\u540c\u65f6\u4fdd\u6301\u8bed\u4e49\u3002\u76ee\u524d\u7f3a\u4e4f\u5bf9\u8be5\u4efb\u52a1\u5728\u610f\u5927\u5229\u8bed\u4e2d\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u91c7\u7528\u5c11\u6837\u672c\u63d0\u793a\u6bd4\u8f83\u591a\u4e2aLLM\uff0c\u5bf9\u9009\u5b9a\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u5e94\u7528\u9488\u5bf9\u6027\u6e05\u6d17\u63d0\u5347\u4efb\u52a1\u76f8\u5173\u6027\uff0c\u4f7f\u7528\u4e8c\u7ef4\u6846\u67b6\u8bc4\u4f30\u4e2d\u7acb\u6027\u548c\u8bed\u4e49\u4fdd\u771f\u5ea6\u3002", "result": "\u5f00\u6e90\u6743\u91cdLLM\u4f18\u4e8e\u73b0\u6709\u610f\u5927\u5229\u8bedGNR\u4e13\u7528\u6a21\u578b\uff0c\u5fae\u8c03\u540e\u7684\u5c0f\u578b\u6a21\u578b\u4ee5\u66f4\u5c0f\u89c4\u6a21\u8fbe\u5230\u6216\u8d85\u8fc7\u6700\u4f73\u5f00\u6e90LLM\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5728\u4f18\u5316\u8bad\u7ec3\u6570\u636e\u65f6\u4e2d\u7acb\u6027\u548c\u610f\u4e49\u4fdd\u6301\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u4e3a\u8bed\u6cd5\u6027\u522b\u8bed\u8a00\u7684\u6027\u522b\u4e2d\u6027\u6539\u5199\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13341", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13341", "abs": "https://arxiv.org/abs/2509.13341", "authors": ["Ahmet H. G\u00fczel", "Matthew Thomas Jackson", "Jarek Luca Liesen", "Tim Rockt\u00e4schel", "Jakob Nicolaus Foerster", "Ilija Bogunovic", "Jack Parker-Holder"], "title": "Imagined Autocurricula", "comment": null, "summary": "Training agents to act in embodied environments typically requires vast\ntraining data or access to accurate simulation, neither of which exists for\nmany cases in the real world. Instead, world models are emerging as an\nalternative leveraging offline, passively collected data, they make it possible\nto generate diverse worlds for training agents in simulation. In this work, we\nharness world models to generate imagined environments to train robust agents\ncapable of generalizing to novel task variations. One of the challenges in\ndoing this is ensuring the agent trains on useful generated data. We thus\npropose a novel approach, IMAC (Imagined Autocurricula), leveraging\nUnsupervised Environment Design (UED), which induces an automatic curriculum\nover generated worlds. In a series of challenging, procedurally generated\nenvironments, we show it is possible to achieve strong transfer performance on\nheld-out environments, having trained only inside a world model learned from a\nnarrower dataset. We believe this opens the path to utilizing larger-scale,\nfoundation world models for generally capable agents.", "AI": {"tldr": "IMAC\u65b9\u6cd5\u5229\u7528\u4e16\u754c\u6a21\u578b\u751f\u6210\u60f3\u8c61\u73af\u5883\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\u81ea\u52a8\u751f\u6210\u8bfe\u7a0b\uff0c\u5728\u6709\u9650\u6570\u636e\u4e0b\u8bad\u7ec3\u51fa\u80fd\u6cdb\u5316\u5230\u65b0\u4efb\u52a1\u7684\u9c81\u68d2\u667a\u80fd\u4f53", "motivation": "\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u4e2d\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u548c\u6a21\u62df\u5668\u4e0d\u51c6\u786e\u7684\u95ee\u9898\uff0c\u5229\u7528\u79bb\u7ebf\u88ab\u52a8\u6536\u96c6\u6570\u636e\u6784\u5efa\u4e16\u754c\u6a21\u578b\u6765\u751f\u6210\u591a\u6837\u5316\u7684\u8bad\u7ec3\u73af\u5883", "method": "\u63d0\u51faIMAC\uff08\u60f3\u8c61\u81ea\u52a8\u8bfe\u7a0b\uff09\u65b9\u6cd5\uff0c\u7ed3\u5408\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\uff08UED\uff09\u5728\u4e16\u754c\u6a21\u578b\u751f\u6210\u7684\u60f3\u8c61\u73af\u5883\u4e2d\u81ea\u52a8\u751f\u6210\u8bfe\u7a0b\uff0c\u9009\u62e9\u6709\u7528\u7684\u751f\u6210\u6570\u636e\u8fdb\u884c\u8bad\u7ec3", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u7a0b\u5e8f\u751f\u6210\u73af\u5883\u4e2d\uff0c\u4ec5\u4f7f\u7528\u8f83\u7a84\u6570\u636e\u96c6\u5b66\u4e60\u7684\u4e16\u754c\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5c31\u80fd\u5728\u4fdd\u7559\u73af\u5883\u4e2d\u5b9e\u73b0\u5f3a\u5927\u7684\u8fc1\u79fb\u6027\u80fd", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5229\u7528\u66f4\u5927\u89c4\u6a21\u7684\u57fa\u7840\u4e16\u754c\u6a21\u578b\u8bad\u7ec3\u901a\u7528\u667a\u80fd\u4f53\u5f00\u8f9f\u4e86\u65b0\u8def\u5f84\uff0c\u5c55\u793a\u4e86\u4e16\u754c\u6a21\u578b\u5728\u6709\u9650\u6570\u636e\u4e0b\u8bad\u7ec3\u9c81\u68d2\u667a\u80fd\u4f53\u7684\u6f5c\u529b"}}
{"id": "2509.13539", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13539", "abs": "https://arxiv.org/abs/2509.13539", "authors": ["Alisa Kanganis", "Katherine A. Keith"], "title": "Op-Fed: Opinion, Stance, and Monetary Policy Annotations on FOMC Transcripts Using Active Learning", "comment": null, "summary": "The U.S. Federal Open Market Committee (FOMC) regularly discusses and sets\nmonetary policy, affecting the borrowing and spending decisions of millions of\npeople. In this work, we release Op-Fed, a dataset of 1044 human-annotated\nsentences and their contexts from FOMC transcripts. We faced two major\ntechnical challenges in dataset creation: imbalanced classes -- we estimate\nfewer than 8% of sentences express a non-neutral stance towards monetary policy\n-- and inter-sentence dependence -- 65% of instances require context beyond the\nsentence-level. To address these challenges, we developed a five-stage\nhierarchical schema to isolate aspects of opinion, monetary policy, and stance\ntowards monetary policy as well as the level of context needed. Second, we\nselected instances to annotate using active learning, roughly doubling the\nnumber of positive instances across all schema aspects. Using Op-Fed, we found\na top-performing, closed-weight LLM achieves 0.80 zero-shot accuracy in opinion\nclassification but only 0.61 zero-shot accuracy classifying stance towards\nmonetary policy -- below our human baseline of 0.89. We expect Op-Fed to be\nuseful for future model training, confidence calibration, and as a seed dataset\nfor future annotation efforts.", "AI": {"tldr": "Op-Fed\u6570\u636e\u96c6\uff1a\u5305\u542b1044\u4e2a\u4eba\u5de5\u6807\u6ce8\u7684FOMC\u4f1a\u8bae\u8bb0\u5f55\u53e5\u5b50\uff0c\u7528\u4e8e\u8d27\u5e01\u653f\u7b56\u7acb\u573a\u5206\u6790\uff0c\u89e3\u51b3\u4e86\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u53e5\u5b50\u95f4\u4f9d\u8d56\u7684\u6280\u672f\u6311\u6218\u3002", "motivation": "\u7f8e\u8054\u50a8\u516c\u5f00\u5e02\u573a\u59d4\u5458\u4f1a(FOMC)\u7684\u8d27\u5e01\u653f\u7b56\u51b3\u7b56\u5f71\u54cd\u6570\u767e\u4e07\u4eba\uff0c\u4f46\u73b0\u6709\u6570\u636e\u7f3a\u4e4f\u5bf9\u8d27\u5e01\u653f\u7b56\u7acb\u573a\u7684\u7ec6\u7c92\u5ea6\u6807\u6ce8\uff0c\u9700\u8981\u6784\u5efa\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u6765\u652f\u6301\u76f8\u5173\u7814\u7a76\u3002", "method": "\u91c7\u7528\u4e94\u9636\u6bb5\u5206\u5c42\u6807\u6ce8\u65b9\u6848\u5206\u79bb\u89c2\u70b9\u3001\u8d27\u5e01\u653f\u7b56\u548c\u7acb\u573a\u8981\u7d20\uff1b\u4f7f\u7528\u4e3b\u52a8\u5b66\u4e60\u9009\u62e9\u6807\u6ce8\u5b9e\u4f8b\uff0c\u5c06\u6b63\u4f8b\u6570\u91cf\u7ffb\u500d\uff1b\u8bc4\u4f30LLM\u5728\u96f6\u6837\u672c\u4e0b\u7684\u5206\u7c7b\u6027\u80fd\u3002", "result": "\u9876\u7ea7\u95ed\u6e90LLM\u5728\u89c2\u70b9\u5206\u7c7b\u4e0a\u8fbe\u52300.80\u51c6\u786e\u7387\uff0c\u4f46\u5728\u8d27\u5e01\u653f\u7b56\u7acb\u573a\u5206\u7c7b\u4e0a\u4ec50.61\uff0c\u4f4e\u4e8e\u4eba\u7c7b\u57fa\u7ebf0.89\uff1b\u6570\u636e\u96c6\u5305\u542b65%\u9700\u8981\u4e0a\u4e0b\u6587\u7406\u89e3\u7684\u5b9e\u4f8b\u3002", "conclusion": "Op-Fed\u6570\u636e\u96c6\u4e3a\u6a21\u578b\u8bad\u7ec3\u3001\u7f6e\u4fe1\u5ea6\u6821\u51c6\u548c\u672a\u6765\u6807\u6ce8\u5de5\u4f5c\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u79cd\u5b50\u6570\u636e\uff0c\u63ed\u793a\u4e86LLM\u5728\u590d\u6742\u91d1\u878d\u6587\u672c\u7406\u89e3\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2509.13347", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13347", "abs": "https://arxiv.org/abs/2509.13347", "authors": ["Zihao Wang", "Muyao Li", "Kaichen He", "Xiangyu Wang", "Zhancun Mu", "Anji Liu", "Yitao Liang"], "title": "OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft", "comment": null, "summary": "The choice of action spaces is a critical yet unresolved challenge in\ndeveloping capable, end-to-end trainable agents. This paper first presents a\nlarge-scale, systematic comparison of prominent abstracted action spaces and\ntokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the\nopen-ended Minecraft. Our analysis reveals that no single action space is\nuniversally optimal; instead, the most effective abstraction is highly\ntask-dependent, creating a dilemma for building generalist agents. To resolve\nthis, we introduce Chain of Action (CoA), a novel framework that unifies\nhigh-level planning and low-level control within a single, monolithic VLA\nmodel. CoA treats an abstracted action not as a command for a separate policy,\nbut as an intermediate reasoning step--akin to a chain of thought--that guides\nthe generation of the final, executable action. Furthermore, we demonstrate\nthat an All-in-One agent trained on a diverse mixture of action spaces using\nthe CoA paradigm learns a more robust and generalizable policy. This unified\nagent achieves a new state-of-the-art, improving the overall task success rate\nover strong, specialized baselines. To foster reproducible research, we release\nthe OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive\nbenchmark of over 800 distinct tasks, curated datasets, source code, and all\npretrained model checkpoints at https://github.com/CraftJarvis/OpenHA", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86\u4e0d\u540c\u52a8\u4f5c\u7a7a\u95f4\u5728Minecraft\u73af\u5883\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6700\u4f18\u52a8\u4f5c\u7a7a\u95f4\u5177\u6709\u4efb\u52a1\u4f9d\u8d56\u6027\uff0c\u4e3a\u6b64\u63d0\u51fa\u4e86Chain of Action (CoA)\u6846\u67b6\uff0c\u5c06\u9ad8\u5c42\u6b21\u89c4\u5212\u548c\u4f4e\u5c42\u6b21\u63a7\u5236\u7edf\u4e00\u5728\u5355\u4e00VLA\u6a21\u578b\u4e2d\uff0c\u901a\u8fc7\u6df7\u5408\u52a8\u4f5c\u7a7a\u95f4\u8bad\u7ec3\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u52a8\u4f5c\u7a7a\u95f4\u9009\u62e9\u8fd9\u4e00\u5173\u952e\u4f46\u672a\u89e3\u51b3\u7684\u6311\u6218\uff0c\u56e0\u4e3a\u7814\u7a76\u53d1\u73b0\u6ca1\u6709\u5355\u4e00\u52a8\u4f5c\u7a7a\u95f4\u5728\u6240\u6709\u4efb\u52a1\u4e2d\u90fd\u6700\u4f18\uff0c\u8fd9\u7ed9\u6784\u5efa\u901a\u7528\u667a\u80fd\u4f53\u5e26\u6765\u4e86\u56f0\u5883\u3002", "method": "\u63d0\u51fa\u4e86Chain of Action (CoA)\u6846\u67b6\uff0c\u5c06\u62bd\u8c61\u52a8\u4f5c\u89c6\u4e3a\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u800c\u975e\u5355\u72ec\u7b56\u7565\u7684\u547d\u4ee4\uff0c\u5728\u5355\u4e00VLA\u6a21\u578b\u4e2d\u7edf\u4e00\u9ad8\u5c42\u6b21\u89c4\u5212\u548c\u4f4e\u5c42\u6b21\u63a7\u5236\uff0c\u5e76\u4f7f\u7528\u6df7\u5408\u52a8\u4f5c\u7a7a\u95f4\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "CoA\u6846\u67b6\u8bad\u7ec3\u7684All-in-One\u667a\u80fd\u4f53\u5b66\u4e60\u5230\u4e86\u66f4\u9c81\u68d2\u548c\u53ef\u6cdb\u5316\u7684\u7b56\u7565\uff0c\u5728800\u591a\u4e2a\u4e0d\u540c\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u8d85\u8d8a\u4e86\u4e13\u95e8\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "CoA\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u52a8\u4f5c\u7a7a\u95f4\u9009\u62e9\u7684\u56f0\u5883\uff0c\u901a\u8fc7\u7edf\u4e00\u89c4\u5212\u548c\u63a7\u5236\u7684\u7aef\u5230\u7aef\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u901a\u7528\u6027\uff0c\u5e76\u53d1\u5e03\u4e86OpenHA\u5957\u4ef6\u4fc3\u8fdb\u53ef\u91cd\u590d\u7814\u7a76\u3002"}}
{"id": "2509.13569", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13569", "abs": "https://arxiv.org/abs/2509.13569", "authors": ["John Mendon\u00e7a", "Lining Zhang", "Rahul Mallidi", "Alon Lavie", "Isabel Trancoso", "Luis Fernando D'Haro", "Jo\u00e3o Sedoc"], "title": "Overview of Dialog System Evaluation Track: Dimensionality, Language, Culture and Safety at DSTC 12", "comment": "DSTC12 Track 1 Overview Paper. https://chateval.org/dstc12", "summary": "The rapid advancement of Large Language Models (LLMs) has intensified the\nneed for robust dialogue system evaluation, yet comprehensive assessment\nremains challenging. Traditional metrics often prove insufficient, and safety\nconsiderations are frequently narrowly defined or culturally biased. The DSTC12\nTrack 1, \"Dialog System Evaluation: Dimensionality, Language, Culture and\nSafety,\" is part of the ongoing effort to address these critical gaps. The\ntrack comprised two subtasks: (1) Dialogue-level, Multi-dimensional Automatic\nEvaluation Metrics, and (2) Multilingual and Multicultural Safety Detection.\nFor Task 1, focused on 10 dialogue dimensions, a Llama-3-8B baseline achieved\nthe highest average Spearman's correlation (0.1681), indicating substantial\nroom for improvement. In Task 2, while participating teams significantly\noutperformed a Llama-Guard-3-1B baseline on the multilingual safety subset (top\nROC-AUC 0.9648), the baseline proved superior on the cultural subset (0.5126\nROC-AUC), highlighting critical needs in culturally-aware safety. This paper\ndescribes the datasets and baselines provided to participants, as well as\nsubmission evaluation results for each of the two proposed subtasks.", "AI": {"tldr": "DSTC12 Track 1 \u9488\u5bf9\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u4f30\u7684\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a\u591a\u7ef4\u5ea6\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u548c\u591a\u8bed\u8a00\u6587\u5316\u5b89\u5168\u68c0\u6d4b\uff0c\u7ed3\u679c\u663e\u793a\u73b0\u6709\u65b9\u6cd5\u5728\u6587\u5316\u610f\u8bc6\u5b89\u5168\u65b9\u9762\u4ecd\u6709\u663e\u8457\u6539\u8fdb\u7a7a\u95f4", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\u51f8\u663e\u4e86\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u4f30\u7684\u91cd\u8981\u6027\uff0c\u4f46\u4f20\u7edf\u6307\u6807\u4e0d\u8db3\u4e14\u5b89\u5168\u8003\u8651\u5f80\u5f80\u5b9a\u4e49\u72ed\u7a84\u6216\u5b58\u5728\u6587\u5316\u504f\u89c1\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u65b9\u6cd5", "method": "\u901a\u8fc7\u4e24\u4e2a\u5b50\u4efb\u52a1\u8fdb\u884c\u8bc4\u4f30\uff1a(1) \u5bf9\u8bdd\u7ea7\u591a\u7ef4\u5ea6\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\uff0810\u4e2a\u5bf9\u8bdd\u7ef4\u5ea6\uff09\uff0c(2) \u591a\u8bed\u8a00\u548c\u591a\u6587\u5316\u5b89\u5168\u68c0\u6d4b\uff0c\u4f7f\u7528Llama-3-8B\u548cLlama-Guard-3-1B\u4f5c\u4e3a\u57fa\u7ebf\u6a21\u578b", "result": "\u4efb\u52a11\u4e2dLlama-3-8B\u57fa\u7ebf\u83b7\u5f97\u6700\u9ad8\u5e73\u5747Spearman\u76f8\u5173\u7cfb\u65700.1681\uff0c\u663e\u793a\u4ecd\u6709\u5f88\u5927\u6539\u8fdb\u7a7a\u95f4\uff1b\u4efb\u52a12\u4e2d\u53c2\u8d5b\u56e2\u961f\u5728\u591a\u8bed\u8a00\u5b89\u5168\u5b50\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff08\u6700\u4f73ROC-AUC 0.9648\uff09\uff0c\u4f46\u57fa\u7ebf\u5728\u6587\u5316\u5b50\u96c6\u4e0a\u8868\u73b0\u66f4\u597d\uff080.5126 ROC-AUC\uff09", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524d\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u4f30\u5728\u6587\u5316\u610f\u8bc6\u5b89\u5168\u65b9\u9762\u7684\u5173\u952e\u9700\u6c42\uff0c\u5f3a\u8c03\u4e86\u5f00\u53d1\u66f4\u5168\u9762\u3001\u6587\u5316\u654f\u611f\u7684\u8bc4\u4f30\u65b9\u6cd5\u7684\u5fc5\u8981\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\u548c\u65b9\u5411"}}
{"id": "2509.13351", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13351", "abs": "https://arxiv.org/abs/2509.13351", "authors": ["Pulkit Verma", "Ngoc La", "Anthony Favier", "Swaroop Mishra", "Julie A. Shah"], "title": "Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning", "comment": null, "summary": "Large language models (LLMs) have demonstrated impressive capabilities across\ndiverse tasks, yet their ability to perform structured symbolic planning\nremains limited, particularly in domains requiring formal representations like\nthe Planning Domain Definition Language (PDDL). In this paper, we present a\nnovel instruction tuning framework, PDDL-Instruct, designed to enhance LLMs'\nsymbolic planning capabilities through logical chain-of-thought reasoning. Our\napproach focuses on teaching models to rigorously reason about action\napplicability, state transitions, and plan validity using explicit logical\ninference steps. By developing instruction prompts that guide models through\nthe precise logical reasoning required to determine when actions can be applied\nin a given state, we enable LLMs to self-correct their planning processes\nthrough structured reflection. The framework systematically builds verification\nskills by decomposing the planning process into explicit reasoning chains about\nprecondition satisfaction, effect application, and invariant preservation.\nExperimental results on multiple planning domains show that our\nchain-of-thought reasoning based instruction-tuned models are significantly\nbetter at planning, achieving planning accuracy of up to 94% on standard\nbenchmarks, representing a 66% absolute improvement over baseline models. This\nwork bridges the gap between the general reasoning capabilities of LLMs and the\nlogical precision required for automated planning, offering a promising\ndirection for developing better AI planning systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86PDDL-Instruct\u6307\u4ee4\u8c03\u4f18\u6846\u67b6\uff0c\u901a\u8fc7\u903b\u8f91\u601d\u7ef4\u94fe\u63a8\u7406\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7b26\u53f7\u89c4\u5212\u80fd\u529b\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523094%\u7684\u89c4\u5212\u51c6\u786e\u7387\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u63d0\u534766%", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6837\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9700\u8981\u5f62\u5f0f\u5316\u8868\u793a\uff08\u5982PDDL\uff09\u7684\u7ed3\u6784\u5316\u7b26\u53f7\u89c4\u5212\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u9700\u8981\u5f25\u5408\u901a\u7528\u63a8\u7406\u80fd\u529b\u4e0e\u81ea\u52a8\u89c4\u5212\u6240\u9700\u903b\u8f91\u7cbe\u5ea6\u4e4b\u95f4\u7684\u5dee\u8ddd", "method": "\u5f00\u53d1\u6307\u4ee4\u63d0\u793a\u5f15\u5bfc\u6a21\u578b\u901a\u8fc7\u7cbe\u786e\u7684\u903b\u8f91\u63a8\u7406\u6b65\u9aa4\u6765\u786e\u5b9a\u52a8\u4f5c\u9002\u7528\u6027\u3001\u72b6\u6001\u8f6c\u6362\u548c\u8ba1\u5212\u6709\u6548\u6027\uff0c\u5c06\u89c4\u5212\u8fc7\u7a0b\u5206\u89e3\u4e3a\u5173\u4e8e\u524d\u63d0\u6761\u4ef6\u6ee1\u8db3\u3001\u6548\u679c\u5e94\u7528\u548c\u4e0d\u53d8\u6027\u4fdd\u6301\u7684\u663e\u5f0f\u63a8\u7406\u94fe", "result": "\u5728\u591a\u4e2a\u89c4\u5212\u9886\u57df\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u57fa\u4e8e\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u89c4\u5212\u80fd\u529b\u663e\u8457\u63d0\u5347\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523094%\u7684\u89c4\u5212\u51c6\u786e\u7387", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5f25\u5408\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u901a\u7528\u63a8\u7406\u80fd\u529b\u4e0e\u81ea\u52a8\u89c4\u5212\u6240\u9700\u903b\u8f91\u7cbe\u5ea6\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u5f00\u53d1\u66f4\u597d\u7684AI\u89c4\u5212\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411"}}
{"id": "2509.13624", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13624", "abs": "https://arxiv.org/abs/2509.13624", "authors": ["Shambhavi Krishna", "Atharva Naik", "Chaitali Agarwal", "Sudharshan Govindan", "Taesung Lee", "Haw-Shiuan Chang"], "title": "Latent Traits and Cross-Task Transfer: Deconstructing Dataset Interactions in LLM Fine-tuning", "comment": "Camera-ready version. Accepted to appear in the proceedings of the\n  14th Joint Conference on Lexical and Computational Semantics (*SEM 2025)", "summary": "Large language models are increasingly deployed across diverse applications.\nThis often includes tasks LLMs have not encountered during training. This\nimplies that enumerating and obtaining the high-quality training data for all\ntasks is infeasible. Thus, we often need to rely on transfer learning using\ndatasets with different characteristics, and anticipate out-of-distribution\nrequests. Motivated by this practical need, we propose an analysis framework,\nbuilding a transfer learning matrix and dimensionality reduction, to dissect\nthese cross-task interactions. We train and analyze 10 models to identify\nlatent abilities (e.g., Reasoning, Sentiment Classification, NLU, Arithmetic)\nand discover the side effects of the transfer learning. Our findings reveal\nthat performance improvements often defy explanations based on surface-level\ndataset similarity or source data quality. Instead, hidden statistical factors\nof the source dataset, such as class distribution and generation length\nproclivities, alongside specific linguistic features, are actually more\ninfluential. This work offers insights into the complex dynamics of transfer\nlearning, paving the way for more predictable and effective LLM adaptation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u6790\u6846\u67b6\u6765\u7814\u7a76LLM\u5728\u4e0d\u540c\u4efb\u52a1\u95f4\u7684\u8fc1\u79fb\u5b66\u4e60\u6548\u679c\uff0c\u53d1\u73b0\u6027\u80fd\u63d0\u5347\u4e3b\u8981\u53d6\u51b3\u4e8e\u6e90\u6570\u636e\u96c6\u7684\u9690\u85cf\u7edf\u8ba1\u7279\u5f81\u800c\u975e\u8868\u9762\u76f8\u4f3c\u6027", "motivation": "\u7531\u4e8e\u65e0\u6cd5\u4e3a\u6240\u6709\u4efb\u52a1\u83b7\u53d6\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u9700\u8981\u4f9d\u8d56\u8fc1\u79fb\u5b66\u4e60\u6765\u5904\u7406\u5206\u5e03\u5916\u8bf7\u6c42\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u89e3\u91ca\u8de8\u4efb\u52a1\u4ea4\u4e92\u7684\u590d\u6742\u52a8\u6001", "method": "\u6784\u5efa\u8fc1\u79fb\u5b66\u4e60\u77e9\u9635\u548c\u964d\u7ef4\u5206\u6790\u6846\u67b6\uff0c\u8bad\u7ec310\u4e2a\u6a21\u578b\u6765\u8bc6\u522b\u6f5c\u5728\u80fd\u529b\uff08\u63a8\u7406\u3001\u60c5\u611f\u5206\u7c7b\u3001\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u3001\u7b97\u672f\u7b49\uff09\uff0c\u5206\u6790\u8de8\u4efb\u52a1\u4ea4\u4e92\u7684\u526f\u4f5c\u7528", "result": "\u6027\u80fd\u6539\u8fdb\u5f80\u5f80\u65e0\u6cd5\u7528\u8868\u9762\u6570\u636e\u96c6\u76f8\u4f3c\u6027\u6216\u6e90\u6570\u636e\u8d28\u91cf\u6765\u89e3\u91ca\uff0c\u800c\u662f\u7531\u6e90\u6570\u636e\u96c6\u7684\u9690\u85cf\u7edf\u8ba1\u56e0\u7d20\uff08\u5982\u7c7b\u522b\u5206\u5e03\u3001\u751f\u6210\u957f\u5ea6\u503e\u5411\uff09\u548c\u7279\u5b9a\u8bed\u8a00\u7279\u5f81\u4e3b\u5bfc", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63ed\u793a\u4e86\u8fc1\u79fb\u5b66\u4e60\u7684\u590d\u6742\u52a8\u6001\uff0c\u4e3a\u66f4\u53ef\u9884\u6d4b\u548c\u6709\u6548\u7684LLM\u9002\u5e94\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u5f3a\u8c03\u4e86\u9690\u85cf\u7edf\u8ba1\u7279\u5f81\u5728\u8de8\u4efb\u52a1\u8fc1\u79fb\u4e2d\u7684\u5173\u952e\u4f5c\u7528"}}
{"id": "2509.13352", "categories": ["cs.AI", "cs.RO", "68T07, 68T40, 68T42", "I.2.9; I.2.11; I.2.8; I.2.10"], "pdf": "https://arxiv.org/pdf/2509.13352", "abs": "https://arxiv.org/abs/2509.13352", "authors": ["Anis Koubaa", "Khaled Gabr"], "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning", "comment": "14 pages, 1 figure", "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,\nsurveillance, and disaster response, yet most systems remain confined to SAE\nLevel 2--3 autonomy. Their reliance on rule-based control and narrow AI\nrestricts adaptability in dynamic, uncertain missions. Existing UAV frameworks\nlack context-aware reasoning, autonomous decision-making, and ecosystem-level\nintegration; critically, none leverage Large Language Model (LLM) agents with\ntool-calling for real-time knowledge access. This paper introduces the Agentic\nUAVs framework, a five-layer architecture (Perception, Reasoning, Action,\nIntegration, Learning) that augments UAVs with LLM-driven reasoning, database\nquerying, and third-party system interaction. A ROS2 and Gazebo-based prototype\nintegrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3\ndeployment. In simulated search-and-rescue scenarios, agentic UAVs achieved\nhigher detection confidence (0.79 vs. 0.72), improved person detection rates\n(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).\nThese results confirm that modest computational overhead enables qualitatively\nnew levels of autonomy and ecosystem integration.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65e0\u4eba\u673a\u81ea\u4e3b\u6846\u67b6Agentic UAVs\uff0c\u901a\u8fc7\u4e94\u5c42\u67b6\u6784\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u548c\u5b9e\u65f6\u77e5\u8bc6\u8bbf\u95ee\uff0c\u5728\u6a21\u62df\u641c\u6551\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u548c\u51b3\u7b56\u80fd\u529b", "motivation": "\u73b0\u6709\u65e0\u4eba\u673a\u7cfb\u7edf\u4e3b\u8981\u4f9d\u8d56\u57fa\u4e8e\u89c4\u5219\u7684\u63a7\u5236\u548c\u7a84AI\uff0c\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u3001\u81ea\u4e3b\u51b3\u7b56\u548c\u751f\u6001\u7cfb\u7edf\u96c6\u6210\u80fd\u529b\uff0c\u65e0\u6cd5\u5728\u52a8\u6001\u4e0d\u786e\u5b9a\u4efb\u52a1\u4e2d\u6709\u6548\u9002\u5e94", "method": "\u8bbe\u8ba1\u4e94\u5c42\u67b6\u6784\uff08\u611f\u77e5\u3001\u63a8\u7406\u3001\u884c\u52a8\u3001\u96c6\u6210\u3001\u5b66\u4e60\uff09\uff0c\u96c6\u6210YOLOv11\u76ee\u6807\u68c0\u6d4b\u3001GPT-4\u63a8\u7406\u548c\u672c\u5730Gemma-3\u90e8\u7f72\uff0c\u57fa\u4e8eROS2\u548cGazebo\u6784\u5efa\u539f\u578b\u7cfb\u7edf", "result": "\u5728\u6a21\u62df\u641c\u6551\u573a\u666f\u4e2d\uff0c\u68c0\u6d4b\u7f6e\u4fe1\u5ea6\u4ece0.72\u63d0\u5347\u52300.79\uff0c\u4eba\u5458\u68c0\u6d4b\u7387\u4ece75%\u63d0\u5347\u523091%\uff0c\u884c\u52a8\u63a8\u8350\u7387\u4ece4.5%\u5927\u5e45\u63d0\u5347\u523092%", "conclusion": "\u9002\u5ea6\u7684\u8ba1\u7b97\u5f00\u9500\u80fd\u591f\u5b9e\u73b0\u8d28\u7684\u81ea\u4e3b\u6027\u63d0\u5347\u548c\u751f\u6001\u7cfb\u7edf\u96c6\u6210\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u65e0\u4eba\u673a\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84"}}
{"id": "2509.13664", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13664", "abs": "https://arxiv.org/abs/2509.13664", "authors": ["Zhuoxuan Zhang", "Jinhao Duan", "Edward Kim", "Kaidi Xu"], "title": "Sparse Neurons Carry Strong Signals of Question Ambiguity in LLMs", "comment": "To be appeared in EMNLP 2025 (main)", "summary": "Ambiguity is pervasive in real-world questions, yet large language models\n(LLMs) often respond with confident answers rather than seeking clarification.\nIn this work, we show that question ambiguity is linearly encoded in the\ninternal representations of LLMs and can be both detected and controlled at the\nneuron level. During the model's pre-filling stage, we identify that a small\nnumber of neurons, as few as one, encode question ambiguity information. Probes\ntrained on these Ambiguity-Encoding Neurons (AENs) achieve strong performance\non ambiguity detection and generalize across datasets, outperforming\nprompting-based and representation-based baselines. Layerwise analysis reveals\nthat AENs emerge from shallow layers, suggesting early encoding of ambiguity\nsignals in the model's processing pipeline. Finally, we show that through\nmanipulating AENs, we can control LLM's behavior from direct answering to\nabstention. Our findings reveal that LLMs form compact internal representations\nof question ambiguity, enabling interpretable and controllable behavior.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLMs\u5728\u5185\u90e8\u8868\u5f81\u4e2d\u7ebf\u6027\u7f16\u7801\u95ee\u9898\u6b67\u4e49\u6027\uff0c\u901a\u8fc7\u8bc6\u522b\u548c\u64cd\u63a7\u6b67\u4e49\u7f16\u7801\u795e\u7ecf\u5143\uff08AENs\uff09\u53ef\u4ee5\u68c0\u6d4b\u548c\u63a7\u5236\u6a21\u578b\u884c\u4e3a\uff0c\u4ece\u76f4\u63a5\u56de\u7b54\u8f6c\u5411\u5f03\u6743", "motivation": "\u73b0\u5b9e\u95ee\u9898\u666e\u904d\u5b58\u5728\u6b67\u4e49\u6027\uff0c\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u5f80\u5f80\u7ed9\u51fa\u81ea\u4fe1\u56de\u7b54\u800c\u975e\u5bfb\u6c42\u6f84\u6e05\uff0c\u9700\u8981\u7406\u89e3\u6a21\u578b\u5185\u90e8\u5982\u4f55\u5904\u7406\u6b67\u4e49\u4fe1\u606f", "method": "\u5728\u6a21\u578b\u9884\u586b\u5145\u9636\u6bb5\u8bc6\u522b\u7f16\u7801\u95ee\u9898\u6b67\u4e49\u6027\u7684\u795e\u7ecf\u5143\uff08AENs\uff09\uff0c\u8bad\u7ec3\u63a2\u9488\u8fdb\u884c\u6b67\u4e49\u68c0\u6d4b\uff0c\u5e76\u901a\u8fc7\u795e\u7ecf\u5143\u64cd\u63a7\u63a7\u5236\u6a21\u578b\u884c\u4e3a", "result": "\u53d1\u73b0\u5c11\u91cf\u795e\u7ecf\u5143\uff08\u751a\u81f3\u4e00\u4e2a\uff09\u5c31\u80fd\u7f16\u7801\u6b67\u4e49\u4fe1\u606f\uff0cAENs\u63a2\u9488\u5728\u6b67\u4e49\u68c0\u6d4b\u4e0a\u8868\u73b0\u4f18\u5f02\u4e14\u5177\u6709\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u80fd\u529b\uff0c\u5c42\u6790\u5206\u6790\u663e\u793a\u6b67\u4e49\u4fe1\u53f7\u5728\u6d45\u5c42\u7f16\u7801", "conclusion": "LLMs\u5f62\u6210\u4e86\u7d27\u51d1\u7684\u95ee\u9898\u6b67\u4e49\u5185\u90e8\u8868\u5f81\uff0c\u4f7f\u5f97\u6a21\u578b\u884c\u4e3a\u5177\u6709\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u63a7\u6027\uff0c\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84"}}
{"id": "2509.13357", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13357", "abs": "https://arxiv.org/abs/2509.13357", "authors": ["Yongchao Huang", "Hassan Raza"], "title": "Semantic Fusion with Fuzzy-Membership Features for Controllable Language Modelling", "comment": "16 pages", "summary": "We propose semantic fusion, a lightweight scheme that augments a Transformer\nlanguage model (LM) with a parallel, fuzzy-membership feature channel that\nencodes token-level semantics. Each token is represented by a vector of\ninterpretable features (e.g. part-of-speech cues, shallow roles, boundary\nflags, sentiment polarity and strength) whose values are graded degrees from\ndifferentiable membership functions (e.g. power kernels). These per-token\nvectors form a sentence-level semantic matrix fused via a gated adapter into\nthe LM. Training uses standard next-token prediction, an auxiliary loss that\nreconstructs the semantic features from hidden states, and a lightweight\nuniformizer that regularizes adjective-class distributions. On a synthetic\ntwo-clause corpus with held-out adjectives for out-of-distribution (OOD)\ncontrol, semantic fusion improves perplexity and enables precise,\nuser-controllable generation of polarity and punctuation while maintaining\nmodel simplicity. This approach adds only small overhead, remains fully\ncompatible with tied input-output embeddings, and provides an interpretable\npathway for conditioned natural language generation.", "AI": {"tldr": "\u63d0\u51fa\u8bed\u4e49\u878d\u5408\u65b9\u6848\uff0c\u901a\u8fc7\u5e76\u884c\u6a21\u7cca\u6210\u5458\u7279\u5f81\u901a\u9053\u589e\u5f3aTransformer\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u8bed\u4e49\u7279\u5f81\u7f16\u7801\u548c\u53ef\u63a7\u751f\u6210", "motivation": "\u4e3a\u4e86\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8bed\u4e49\u7279\u5f81\u8868\u793a\uff0c\u5e76\u5b9e\u73b0\u7528\u6237\u53ef\u63a7\u7684\u6587\u672c\u751f\u6210", "method": "\u4f7f\u7528\u53ef\u89e3\u91ca\u7279\u5f81\u5411\u91cf\uff08\u8bcd\u6027\u3001\u6d45\u5c42\u89d2\u8272\u3001\u8fb9\u754c\u6807\u5fd7\u3001\u60c5\u611f\u6781\u6027\u7b49\uff09\u6784\u5efa\u8bed\u4e49\u77e9\u9635\uff0c\u901a\u8fc7\u95e8\u63a7\u9002\u914d\u5668\u878d\u5408\u5230\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u91c7\u7528\u6807\u51c6\u7684\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\u3001\u8f85\u52a9\u91cd\u5efa\u635f\u5931\u548c\u8f7b\u91cf\u7ea7\u6b63\u5219\u5316\u5668", "result": "\u5728\u5408\u6210\u53cc\u5b50\u53e5\u8bed\u6599\u5e93\u4e0a\uff0c\u8bed\u4e49\u878d\u5408\u63d0\u9ad8\u4e86\u56f0\u60d1\u5ea6\uff0c\u5b9e\u73b0\u4e86\u7cbe\u786e\u7684\u7528\u6237\u53ef\u63a7\u6781\u6027\u548c\u6807\u70b9\u751f\u6210\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7b80\u6d01\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u8ba1\u7b97\u5f00\u9500\u5c0f\uff0c\u5b8c\u5168\u517c\u5bb9\u8f93\u5165\u8f93\u51fa\u5d4c\u5165\u7ed1\u5b9a\uff0c\u4e3a\u6761\u4ef6\u81ea\u7136\u8bed\u8a00\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u9014\u5f84"}}
{"id": "2509.13672", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13672", "abs": "https://arxiv.org/abs/2509.13672", "authors": ["Shang Qin", "Jingheng Ye", "Yinghui Li", "Hai-Tao Zheng", "Qi Li", "Jinxiao Shan", "Zhixing Li", "Hong-Gee Kim"], "title": "CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction", "comment": null, "summary": "The growing demand for automated writing assistance in diverse academic\ndomains highlights the need for robust Chinese Grammatical Error Correction\n(CGEC) systems that can adapt across disciplines. However, existing CGEC\nresearch largely lacks dedicated benchmarks for multi-disciplinary academic\nwriting, overlooking continual learning (CL) as a promising solution to handle\ndomain-specific linguistic variation and prevent catastrophic forgetting. To\nfill this crucial gap, we introduce CL$^2$GEC, the first Continual Learning\nbenchmark for Chinese Literature Grammatical Error Correction, designed to\nevaluate adaptive CGEC across multiple academic fields. Our benchmark includes\n10,000 human-annotated sentences spanning 10 disciplines, each exhibiting\ndistinct linguistic styles and error patterns. CL$^2$GEC focuses on evaluating\ngrammatical error correction in a continual learning setting, simulating\nsequential exposure to diverse academic disciplines to reflect real-world\neditorial dynamics. We evaluate large language models under sequential tuning,\nparameter-efficient adaptation, and four representative CL algorithms, using\nboth standard GEC metrics and continual learning metrics adapted to task-level\nvariation. Experimental results reveal that regularization-based methods\nmitigate forgetting more effectively than replay-based or naive sequential\napproaches. Our benchmark provides a rigorous foundation for future research in\nadaptive grammatical error correction across diverse academic domains.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u4e2d\u6587\u6587\u732e\u8bed\u6cd5\u7ea0\u9519\u7684\u6301\u7eed\u5b66\u4e60\u57fa\u51c6CL\u00b2GEC\uff0c\u5305\u542b10\u4e2a\u5b66\u79d1\u768410,000\u6761\u4eba\u5de5\u6807\u6ce8\u53e5\u5b50\uff0c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8de8\u5b66\u79d1\u5b66\u672f\u5199\u4f5c\u4e2d\u7684\u81ea\u9002\u5e94\u8bed\u6cd5\u7ea0\u9519\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u4e2d\u6587\u8bed\u6cd5\u7ea0\u9519\u7814\u7a76\u7f3a\u4e4f\u591a\u5b66\u79d1\u5b66\u672f\u5199\u4f5c\u7684\u4e13\u7528\u57fa\u51c6\uff0c\u5ffd\u89c6\u4e86\u6301\u7eed\u5b66\u4e60\u4f5c\u4e3a\u5904\u7406\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u53d8\u5f02\u548c\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6784\u5efa\u5305\u542b10\u4e2a\u5b66\u79d110,000\u53e5\u7684\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u5728\u6301\u7eed\u5b66\u4e60\u8bbe\u7f6e\u4e0b\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5305\u62ec\u987a\u5e8f\u8c03\u4f18\u3001\u53c2\u6570\u9ad8\u6548\u9002\u5e94\u548c\u56db\u79cd\u4ee3\u8868\u6027\u6301\u7eed\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u6b63\u5219\u5316\u7684\u65b9\u6cd5\u6bd4\u57fa\u4e8e\u56de\u653e\u6216\u7b80\u5355\u987a\u5e8f\u65b9\u6cd5\u66f4\u80fd\u6709\u6548\u7f13\u89e3\u9057\u5fd8\u95ee\u9898\u3002", "conclusion": "\u8be5\u57fa\u51c6\u4e3a\u8de8\u5b66\u79d1\u5b66\u672f\u9886\u57df\u7684\u81ea\u9002\u5e94\u8bed\u6cd5\u7ea0\u9519\u7814\u7a76\u63d0\u4f9b\u4e86\u4e25\u8c28\u7684\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u6301\u7eed\u5b66\u4e60\u5728\u5b66\u672f\u5199\u4f5c\u8f85\u52a9\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2509.13364", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13364", "abs": "https://arxiv.org/abs/2509.13364", "authors": ["Zixi Li"], "title": "Asterisk Operator", "comment": "Code available at: https://github.com/lizixi-0x2F/Asterisk-Games", "summary": "We propose the \\textbf{Asterisk Operator} ($\\ast$-operator), a novel unified\nframework for abstract reasoning based on Adjacency-Structured Parallel\nPropagation (ASPP). The operator formalizes structured reasoning tasks as\nlocal, parallel state evolution processes guided by implicit relational graphs.\nWe prove that the $\\ast$-operator maintains local computational constraints\nwhile achieving global reasoning capabilities, providing an efficient and\nconvergent computational paradigm for abstract reasoning problems. Through\nrigorous mathematical analysis and comprehensive experiments on ARC2 challenges\nand Conway's Game of Life, we demonstrate the operator's universality,\nconvergence properties, and superior performance. Our innovative\nEmbedding-Asterisk distillation method achieves 100\\% accuracy on ARC2\nvalidation with only 6M parameters, representing a significant breakthrough in\nneural-symbolic reasoning.\n  \\textbf{Keywords:} Abstract Reasoning, Adjacency Structure, Parallel\nPropagation, Asterisk Operator, Convergence, Universal Approximation", "AI": {"tldr": "\u63d0\u51fa\u4e86\u661f\u53f7\u64cd\u4f5c\u7b26(*-operator)\u8fd9\u4e00\u65b0\u9896\u7684\u7edf\u4e00\u62bd\u8c61\u63a8\u7406\u6846\u67b6\uff0c\u57fa\u4e8e\u90bb\u63a5\u7ed3\u6784\u5e76\u884c\u4f20\u64ad(ASPP)\uff0c\u5c06\u7ed3\u6784\u5316\u63a8\u7406\u4efb\u52a1\u5f62\u5f0f\u5316\u4e3a\u7531\u9690\u5f0f\u5173\u7cfb\u56fe\u5f15\u5bfc\u7684\u5c40\u90e8\u5e76\u884c\u72b6\u6001\u6f14\u5316\u8fc7\u7a0b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u62bd\u8c61\u63a8\u7406\u95ee\u9898\u4e2d\u7684\u5168\u5c40\u63a8\u7406\u80fd\u529b\u4e0e\u5c40\u90e8\u8ba1\u7b97\u7ea6\u675f\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u9700\u8981\u4e00\u4e2a\u65e2\u80fd\u4fdd\u6301\u5c40\u90e8\u8ba1\u7b97\u6548\u7387\u53c8\u80fd\u5b9e\u73b0\u5168\u5c40\u63a8\u7406\u7684\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u57fa\u4e8e\u90bb\u63a5\u7ed3\u6784\u5e76\u884c\u4f20\u64ad(ASPP)\u7684\u661f\u53f7\u64cd\u4f5c\u7b26\uff0c\u5c06\u63a8\u7406\u4efb\u52a1\u5efa\u6a21\u4e3a\u5c40\u90e8\u5e76\u884c\u72b6\u6001\u6f14\u5316\u8fc7\u7a0b\uff0c\u901a\u8fc7\u9690\u5f0f\u5173\u7cfb\u56fe\u8fdb\u884c\u5f15\u5bfc\uff0c\u5e76\u63d0\u51fa\u4e86Embedding-Asterisk\u84b8\u998f\u65b9\u6cd5\u3002", "result": "\u5728ARC2\u6311\u6218\u548c\u5eb7\u5a01\u751f\u547d\u6e38\u620f\u4e2d\u9a8c\u8bc1\u4e86\u64cd\u4f5c\u7b26\u7684\u901a\u7528\u6027\u3001\u6536\u655b\u6027\u548c\u4f18\u5f02\u6027\u80fd\uff0c\u4ec5\u7528600\u4e07\u53c2\u6570\u5c31\u5728ARC2\u9a8c\u8bc1\u96c6\u4e0a\u8fbe\u5230100%\u51c6\u786e\u7387\u3002", "conclusion": "\u661f\u53f7\u64cd\u4f5c\u7b26\u4e3a\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u6536\u655b\u7684\u8ba1\u7b97\u8303\u5f0f\uff0c\u5728\u62bd\u8c61\u63a8\u7406\u9886\u57df\u5b9e\u73b0\u4e86\u91cd\u8981\u7a81\u7834\u3002"}}
{"id": "2509.13677", "categories": ["cs.CL", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.13677", "abs": "https://arxiv.org/abs/2509.13677", "authors": ["Xinxu Zhou", "Jiaqi Bai", "Zhenqi Sun", "Fanxiang Zeng", "Yue Liu"], "title": "AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation", "comment": null, "summary": "Although significant progress has been made in many tasks within the field of\nNatural Language Processing (NLP), Controlled Text Generation (CTG) continues\nto face numerous challenges, particularly in achieving fine-grained conditional\ncontrol over generation. Additionally, in real scenario and online\napplications, cost considerations, scalability, domain knowledge learning and\nmore precise control are required, presenting more challenge for CTG. This\npaper introduces a novel and scalable framework, AgentCTG, which aims to\nenhance precise and complex control over the text generation by simulating the\ncontrol and regulation mechanisms in multi-agent workflows. We explore various\ncollaboration methods among different agents and introduce an auto-prompt\nmodule to further enhance the generation effectiveness. AgentCTG achieves\nstate-of-the-art results on multiple public datasets. To validate its\neffectiveness in practical applications, we propose a new challenging\nCharacter-Driven Rewriting task, which aims to convert the original text into\nnew text that conform to specific character profiles and simultaneously\npreserve the domain knowledge. When applied to online navigation with\nrole-playing, our approach significantly enhances the driving experience\nthrough improved content delivery. By optimizing the generation of contextually\nrelevant text, we enable a more immersive interaction within online\ncommunities, fostering greater personalization and user engagement.", "AI": {"tldr": "AgentCTG\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u53ef\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u4e2d\u7684\u63a7\u5236\u548c\u8c03\u8282\u673a\u5236\uff0c\u5b9e\u73b0\u5bf9\u6587\u672c\u751f\u6210\u7684\u7cbe\u786e\u590d\u6742\u63a7\u5236\uff0c\u5728\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6548\u679c\u3002", "motivation": "\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u53d7\u63a7\u6587\u672c\u751f\u6210\u9762\u4e34\u7cbe\u7ec6\u6761\u4ef6\u63a7\u5236\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5b9e\u9645\u5728\u7ebf\u5e94\u7528\u4e2d\u9700\u8981\u8003\u8651\u6210\u672c\u3001\u53ef\u6269\u5c55\u6027\u3001\u9886\u57df\u77e5\u8bc6\u5b66\u4e60\u548c\u66f4\u7cbe\u786e\u63a7\u5236\u7b49\u591a\u91cd\u9700\u6c42\u3002", "method": "\u63d0\u51faAgentCTG\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u673a\u5236\u6a21\u62df\u63a7\u5236\u548c\u8c03\u8282\uff0c\u63a2\u7d22\u4e0d\u540c\u667a\u80fd\u4f53\u95f4\u7684\u534f\u4f5c\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u81ea\u52a8\u63d0\u793a\u6a21\u5757\u6765\u589e\u5f3a\u751f\u6210\u6548\u679c\u3002", "result": "\u5728\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u6700\u5148\u8fdb\u7ed3\u679c\uff0c\u5728\u89d2\u8272\u9a71\u52a8\u91cd\u5199\u4efb\u52a1\u4e2d\u6210\u529f\u5c06\u539f\u59cb\u6587\u672c\u8f6c\u6362\u4e3a\u7b26\u5408\u7279\u5b9a\u89d2\u8272\u914d\u7f6e\u7684\u65b0\u6587\u672c\uff0c\u540c\u65f6\u4fdd\u7559\u9886\u57df\u77e5\u8bc6\uff0c\u5728\u5728\u7ebf\u5bfc\u822a\u89d2\u8272\u626e\u6f14\u4e2d\u663e\u8457\u63d0\u5347\u9a7e\u9a76\u4f53\u9a8c\u3002", "conclusion": "AgentCTG\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u53d7\u63a7\u6587\u672c\u751f\u6210\u7684\u7cbe\u7ec6\u63a7\u5236\u95ee\u9898\uff0c\u4e3a\u5728\u7ebf\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u6c89\u6d78\u5f0f\u7684\u4ea4\u4e92\u4f53\u9a8c\uff0c\u4fc3\u8fdb\u4e86\u4e2a\u6027\u5316\u548c\u7528\u6237\u53c2\u4e0e\u5ea6\u3002"}}
{"id": "2509.13368", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13368", "abs": "https://arxiv.org/abs/2509.13368", "authors": ["Yuan Wei", "Xiaohan Shan", "Ran Miao", "Jianmin Li"], "title": "$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation", "comment": "9 pages, 7 figures", "summary": "Reinforcement learning agent development traditionally requires extensive\nexpertise and lengthy iterations, often resulting in high failure rates and\nlimited accessibility. This paper introduces $Agent^2$, a novel\nagent-generates-agent framework that achieves fully automated RL agent design\nthrough intelligent LLM-driven generation. The system autonomously transforms\nnatural language task descriptions and environment code into comprehensive,\nhigh-performance reinforcement learning solutions without human intervention.\n$Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent\nserves as an autonomous AI designer that analyzes tasks and generates\nexecutable RL agents, while the Target Agent is the resulting automatically\ngenerated RL agent. The framework decomposes RL development into two distinct\nstages: MDP modeling and algorithmic optimization, enabling more targeted and\neffective agent generation. Built on the Model Context Protocol, $Agent^2$\nprovides a unified framework that standardizes intelligent agent creation\nacross diverse environments and algorithms, while incorporating adaptive\ntraining management and intelligent feedback analysis for continuous\nimprovement. Extensive experiments on a wide range of benchmarks, including\nMuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently\noutperforms manually designed solutions across all tasks, achieving up to 55%\nperformance improvement and substantial gains on average. By enabling truly\nend-to-end, closed-loop automation, this work establishes a new paradigm in\nwhich intelligent agents design and optimize other agents, marking a\nfundamental breakthrough for automated AI systems.", "AI": {"tldr": "Agent\u00b2\u662f\u4e00\u4e2a\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7LLM\u9a71\u52a8\u5c06\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u8f6c\u6362\u4e3a\u9ad8\u6027\u80fdRL\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u65b9\u6848\u3002", "motivation": "\u4f20\u7edfRL\u4ee3\u7406\u5f00\u53d1\u9700\u8981\u5927\u91cf\u4e13\u4e1a\u77e5\u8bc6\u548c\u8fed\u4ee3\u5468\u671f\uff0c\u5931\u8d25\u7387\u9ad8\u4e14\u53ef\u8bbf\u95ee\u6027\u6709\u9650\uff0c\u9700\u8981\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u7684RL\u4ee3\u7406\u8bbe\u8ba1\u3002", "method": "\u91c7\u7528\u53cc\u4ee3\u7406\u67b6\u6784\uff1a\u751f\u6210\u5668\u4ee3\u7406\u5206\u6790\u4efb\u52a1\u5e76\u751f\u6210\u53ef\u6267\u884cRL\u4ee3\u7406\uff0c\u76ee\u6807\u4ee3\u7406\u662f\u81ea\u52a8\u751f\u6210\u7684RL\u4ee3\u7406\u3002\u6846\u67b6\u5c06RL\u5f00\u53d1\u5206\u89e3\u4e3aMDP\u5efa\u6a21\u548c\u7b97\u6cd5\u4f18\u5316\u4e24\u4e2a\u9636\u6bb5\uff0c\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u6784\u5efa\u3002", "result": "\u5728MuJoCo\u3001MetaDrive\u3001MPE\u548cSMAC\u7b49\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAgent\u00b2\u59cb\u7ec8\u4f18\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe55%\uff0c\u5e73\u5747\u8868\u73b0\u4e5f\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5efa\u7acb\u4e86\u667a\u80fd\u4ee3\u7406\u8bbe\u8ba1\u548c\u4f18\u5316\u5176\u4ed6\u4ee3\u7406\u7684\u65b0\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u771f\u6b63\u7aef\u5230\u7aef\u7684\u95ed\u73af\u81ea\u52a8\u5316\uff0c\u662f\u81ea\u52a8\u5316AI\u7cfb\u7edf\u7684\u6839\u672c\u6027\u7a81\u7834\u3002"}}
{"id": "2509.13683", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13683", "abs": "https://arxiv.org/abs/2509.13683", "authors": ["Suyuchen Wang", "Jinlin Wang", "Xinyu Wang", "Shiqi Li", "Xiangru Tang", "Sirui Hong", "Xiao-Wen Chang", "Chenglin Wu", "Bang Liu"], "title": "Improving Context Fidelity via Native Retrieval-Augmented Reasoning", "comment": "Accepted as a main conference paper at EMNLP 2025", "summary": "Large language models (LLMs) often struggle with context fidelity, producing\ninconsistent answers when responding to questions based on provided\ninformation. Existing approaches either rely on expensive supervised\nfine-tuning to generate evidence post-answer or train models to perform web\nsearches without necessarily improving utilization of the given context. We\npropose CARE, a novel native retrieval-augmented reasoning framework that\nteaches LLMs to explicitly integrate in-context evidence within their reasoning\nprocess with the model's own retrieval capabilities. Our method requires\nlimited labeled evidence data while significantly enhancing both retrieval\naccuracy and answer generation performance through strategically retrieved\nin-context tokens in the reasoning chain. Extensive experiments on multiple\nreal-world and counterfactual QA benchmarks demonstrate that our approach\nsubstantially outperforms supervised fine-tuning, traditional\nretrieval-augmented generation methods, and external retrieval solutions. This\nwork represents a fundamental advancement in making LLMs more accurate,\nreliable, and efficient for knowledge-intensive tasks.", "AI": {"tldr": "CARE\u6846\u67b6\u901a\u8fc7\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u663e\u5f0f\u6574\u5408\u4e0a\u4e0b\u6587\u8bc1\u636e\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u7d22\u51c6\u786e\u6027\u548c\u7b54\u6848\u751f\u6210\u6027\u80fd\uff0c\u65e0\u9700\u6602\u8d35\u7684\u76d1\u7763\u5fae\u8c03\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u57fa\u4e8e\u7ed9\u5b9a\u4fe1\u606f\u56de\u7b54\u95ee\u9898\u65f6\u7ecf\u5e38\u51fa\u73b0\u4e0a\u4e0b\u6587\u4fdd\u771f\u5ea6\u95ee\u9898\uff0c\u4ea7\u751f\u4e0d\u4e00\u81f4\u7684\u7b54\u6848\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u6602\u8d35\u7684\u76d1\u7763\u5fae\u8c03\uff0c\u8981\u4e48\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u7f51\u7edc\u641c\u7d22\u4f46\u672a\u5fc5\u6539\u5584\u5bf9\u7ed9\u5b9a\u4e0a\u4e0b\u6587\u7684\u5229\u7528\u3002", "method": "\u63d0\u51faCARE\u6846\u67b6\uff0c\u6559\u5bfcLLMs\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u663e\u5f0f\u6574\u5408\u4e0a\u4e0b\u6587\u8bc1\u636e\uff0c\u5229\u7528\u6a21\u578b\u81ea\u8eab\u7684\u68c0\u7d22\u80fd\u529b\uff0c\u53ea\u9700\u8981\u6709\u9650\u7684\u6807\u8bb0\u8bc1\u636e\u6570\u636e\uff0c\u901a\u8fc7\u7b56\u7565\u6027\u68c0\u7d22\u7684\u4e0a\u4e0b\u6587\u6807\u8bb0\u6765\u589e\u5f3a\u68c0\u7d22\u548c\u751f\u6210\u6027\u80fd\u3002", "result": "\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u548c\u53cd\u4e8b\u5b9eQA\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u76d1\u7763\u5fae\u8c03\u3001\u4f20\u7edf\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u548c\u5916\u90e8\u68c0\u7d22\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4ee3\u8868\u4e86\u5728\u4f7fLLMs\u66f4\u51c6\u786e\u3001\u53ef\u9760\u548c\u9ad8\u6548\u5730\u5904\u7406\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u65b9\u9762\u7684\u6839\u672c\u6027\u8fdb\u6b65\u3002"}}
{"id": "2509.13379", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.13379", "abs": "https://arxiv.org/abs/2509.13379", "authors": ["Asif Azad", "Mohammad Sadat Hossain", "MD Sadik Hossain Shanto", "M Saifur Rahman", "Md Rizwan Pervez"], "title": "The Art of Saying \"Maybe\": A Conformal Lens for Uncertainty Benchmarking in VLMs", "comment": null, "summary": "Vision-Language Models (VLMs) have achieved remarkable progress in complex\nvisual understanding across scientific and reasoning tasks. While performance\nbenchmarking has advanced our understanding of these capabilities, the critical\ndimension of uncertainty quantification has received insufficient attention.\nTherefore, unlike prior conformal prediction studies that focused on limited\nsettings, we conduct a comprehensive uncertainty benchmarking study, evaluating\n16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets\nwith 3 distinct scoring functions. Our findings demonstrate that larger models\nconsistently exhibit better uncertainty quantification; models that know more\nalso know better what they don't know. More certain models achieve higher\naccuracy, while mathematical and reasoning tasks elicit poorer uncertainty\nperformance across all models compared to other domains. This work establishes\na foundation for reliable uncertainty evaluation in multimodal systems.", "AI": {"tldr": "\u672c\u6587\u5bf916\u4e2a\u6700\u5148\u8fdb\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u5168\u9762\u7684\u4e0d\u786e\u5b9a\u6027\u57fa\u51c6\u6d4b\u8bd5\u7814\u7a76\uff0c\u53d1\u73b0\u5728\u591a\u6a21\u6001\u7cfb\u7edf\u4e2d\uff0c\u66f4\u5927\u7684\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u597d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u80fd\u529b\uff0c\u6570\u5b66\u548c\u63a8\u7406\u4efb\u52a1\u7684\u4e0d\u786e\u5b9a\u6027\u8868\u73b0\u8f83\u5dee\u3002", "motivation": "\u867d\u7136\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u89c6\u89c9\u7406\u89e3\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u8fd9\u4e00\u5173\u952e\u7ef4\u5ea6\u5c1a\u672a\u5f97\u5230\u8db3\u591f\u5173\u6ce8\uff0c\u73b0\u6709\u7814\u7a76\u4ec5\u9650\u4e8e\u6709\u9650\u8bbe\u7f6e\u3002", "method": "\u57286\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u8bc4\u4f3016\u4e2a\u6700\u5148\u8fdb\u7684VLMs\uff08\u5f00\u6e90\u548c\u95ed\u6e90\uff09\uff0c\u4f7f\u75283\u79cd\u4e0d\u540c\u7684\u8bc4\u5206\u51fd\u6570\u8fdb\u884c\u5168\u9762\u7684\u4e0d\u786e\u5b9a\u6027\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u53d1\u73b0\u66f4\u5927\u7684\u6a21\u578b\u59cb\u7ec8\u8868\u73b0\u51fa\u66f4\u597d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff1b\u77e5\u9053\u66f4\u591a\u7684\u6a21\u578b\u4e5f\u66f4\u6e05\u695a\u81ea\u5df1\u4e0d\u77e5\u9053\u4ec0\u4e48\u3002\u66f4\u786e\u5b9a\u7684\u6a21\u578b\u83b7\u5f97\u66f4\u9ad8\u7684\u51c6\u786e\u7387\uff0c\u800c\u6570\u5b66\u548c\u63a8\u7406\u4efb\u52a1\u5728\u6240\u6709\u6a21\u578b\u4e2d\u76f8\u6bd4\u5176\u4ed6\u9886\u57df\u8868\u73b0\u51fa\u66f4\u5dee\u7684\u4e0d\u786e\u5b9a\u6027\u6027\u80fd\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u591a\u6a21\u6001\u7cfb\u7edf\u4e2d\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5f3a\u8c03\u4e86\u6a21\u578b\u89c4\u6a21\u548c\u4efb\u52a1\u7c7b\u578b\u5bf9\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6027\u80fd\u7684\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2509.13695", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13695", "abs": "https://arxiv.org/abs/2509.13695", "authors": ["Yosuke Mikami", "Daiki Matsuoka", "Hitomi Yanaka"], "title": "Can Large Language Models Robustly Perform Natural Language Inference for Japanese Comparatives?", "comment": "To appear in Proceedings of the 16th International Conference on\n  Computational Semantics (IWCS 2025)", "summary": "Large Language Models (LLMs) perform remarkably well in Natural Language\nInference (NLI). However, NLI involving numerical and logical expressions\nremains challenging. Comparatives are a key linguistic phenomenon related to\nsuch inference, but the robustness of LLMs in handling them, especially in\nlanguages that are not dominant in the models' training data, such as Japanese,\nhas not been sufficiently explored. To address this gap, we construct a\nJapanese NLI dataset that focuses on comparatives and evaluate various LLMs in\nzero-shot and few-shot settings. Our results show that the performance of the\nmodels is sensitive to the prompt formats in the zero-shot setting and\ninfluenced by the gold labels in the few-shot examples. The LLMs also struggle\nto handle linguistic phenomena unique to Japanese. Furthermore, we observe that\nprompts containing logical semantic representations help the models predict the\ncorrect labels for inference problems that they struggle to solve even with\nfew-shot examples.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u65e5\u8bed\u6bd4\u8f83\u53e5\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u65f6\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u5bf9\u63d0\u793a\u683c\u5f0f\u654f\u611f\uff0c\u4e14\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u90fd\u96be\u4ee5\u5904\u7406\u65e5\u8bed\u7279\u6709\u7684\u8bed\u8a00\u73b0\u8c61\uff0c\u4f46\u5305\u542b\u903b\u8f91\u8bed\u4e49\u8868\u793a\u7684\u63d0\u793a\u80fd\u6539\u5584\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u6d89\u53ca\u6570\u503c\u548c\u903b\u8f91\u8868\u8fbe\u5f0f\u7684\u63a8\u7406\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u6bd4\u8f83\u53e5\u662f\u4e0e\u6b64\u7c7b\u63a8\u7406\u76f8\u5173\u7684\u5173\u952e\u8bed\u8a00\u73b0\u8c61\uff0c\u4f46LLMs\u5728\u5904\u7406\u8fd9\u4e9b\u73b0\u8c61\uff08\u7279\u522b\u662f\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u4e0d\u5360\u4e3b\u5bfc\u5730\u4f4d\u7684\u8bed\u8a00\u5982\u65e5\u8bed\uff09\u65b9\u9762\u7684\u9c81\u68d2\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u6bd4\u8f83\u53e5\u7684\u65e5\u8bedNLI\u6570\u636e\u96c6\uff0c\u5e76\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u8bc4\u4f30\u4e86\u5404\u79cdLLMs\u3002\u7814\u7a76\u4e86\u4e0d\u540c\u63d0\u793a\u683c\u5f0f\u548c\u5305\u542b\u9ec4\u91d1\u6807\u7b7e\u7684\u5c11\u6837\u672c\u793a\u4f8b\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u6a21\u578b\u6027\u80fd\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e2d\u5bf9\u63d0\u793a\u683c\u5f0f\u654f\u611f\uff0c\u5728\u5c11\u6837\u672c\u8bbe\u7f6e\u4e2d\u53d7\u9ec4\u91d1\u6807\u7b7e\u7684\u5f71\u54cd\u3002LLMs\u96be\u4ee5\u5904\u7406\u65e5\u8bed\u7279\u6709\u7684\u8bed\u8a00\u73b0\u8c61\u3002\u5305\u542b\u903b\u8f91\u8bed\u4e49\u8868\u793a\u7684\u63d0\u793a\u6709\u52a9\u4e8e\u6a21\u578b\u9884\u6d4b\u90a3\u4e9b\u5373\u4f7f\u5728\u5c11\u6837\u672c\u793a\u4f8b\u4e0b\u4e5f\u96be\u4ee5\u89e3\u51b3\u7684\u63a8\u7406\u95ee\u9898\u7684\u6b63\u786e\u6807\u7b7e\u3002", "conclusion": "LLMs\u5728\u5904\u7406\u65e5\u8bed\u6bd4\u8f83\u53e5\u63a8\u7406\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u8bed\u8a00\u7279\u6709\u73b0\u8c61\u65f6\u3002\u9002\u5f53\u7684\u63d0\u793a\u5de5\u7a0b\uff08\u5982\u5305\u542b\u903b\u8f91\u8bed\u4e49\u8868\u793a\uff09\u53ef\u4ee5\u663e\u8457\u6539\u5584\u6a21\u578b\u6027\u80fd\uff0c\u8fd9\u4e3a\u6539\u8fdb\u591a\u8bed\u8a00NLI\u4efb\u52a1\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2509.13389", "categories": ["cs.AI", "I.2.4; I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2509.13389", "abs": "https://arxiv.org/abs/2509.13389", "authors": ["Carlos N\u00fa\u00f1ez-Molina", "Vicen\u00e7 G\u00f3mez", "Hector Geffner"], "title": "From Next Token Prediction to (STRIPS) World Models -- Preliminary Results", "comment": "10 pages, 3 figures", "summary": "We consider the problem of learning propositional STRIPS world models from\naction traces alone, using a deep learning architecture (transformers) and\ngradient descent. The task is cast as a supervised next token prediction\nproblem where the tokens are the actions, and an action $a$ may follow an\naction sequence if the hidden effects of the previous actions do not make an\naction precondition of $a$ false. We show that a suitable transformer\narchitecture can faithfully represent propositional STRIPS world models, and\nthat the models can be learned from sets of random valid (positive) and invalid\n(negative) action sequences alone. A number of experiments are reported.", "AI": {"tldr": "\u4f7f\u7528Transformer\u67b6\u6784\u4ece\u52a8\u4f5c\u5e8f\u5217\u4e2d\u5b66\u4e60\u547d\u9898STRIPS\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u76d1\u7763\u5f0f\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\u6765\u63a8\u65ad\u52a8\u4f5c\u524d\u63d0\u6761\u4ef6", "motivation": "\u4ece\u52a8\u4f5c\u8f68\u8ff9\u4e2d\u5b66\u4e60\u4e16\u754c\u6a21\u578b\u662fAI\u89c4\u5212\u7684\u91cd\u8981\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5b8c\u6574\u7684\u72b6\u6001\u4fe1\u606f\uff0c\u800c\u672c\u6587\u65e8\u5728\u4ec5\u4ece\u52a8\u4f5c\u5e8f\u5217\u4e2d\u63a8\u65ad\u9690\u85cf\u7684\u4e16\u754c\u6a21\u578b", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u76d1\u7763\u5f0f\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\u4efb\u52a1\uff0c\u4f7f\u7528Transformer\u67b6\u6784\uff0c\u901a\u8fc7\u6b63\u8d1f\u6837\u672c\uff08\u6709\u6548\u548c\u65e0\u6548\u52a8\u4f5c\u5e8f\u5217\uff09\u8bad\u7ec3\u6a21\u578b\u5b66\u4e60\u52a8\u4f5c\u524d\u63d0\u6761\u4ef6", "result": "\u5b9e\u9a8c\u8868\u660e\u5408\u9002\u7684Transformer\u67b6\u6784\u80fd\u591f\u5fe0\u5b9e\u8868\u793a\u547d\u9898STRIPS\u4e16\u754c\u6a21\u578b\uff0c\u4ec5\u4ece\u968f\u673a\u6709\u6548\u548c\u65e0\u6548\u52a8\u4f5c\u5e8f\u5217\u4e2d\u5373\u53ef\u5b66\u4e60\u5230\u6a21\u578b", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff08\u7279\u522b\u662fTransformer\uff09\u80fd\u591f\u6210\u529f\u5730\u4ece\u52a8\u4f5c\u5e8f\u5217\u4e2d\u5b66\u4e60\u547d\u9898STRIPS\u4e16\u754c\u6a21\u578b\uff0c\u4e3a\u4ece\u89c2\u5bdf\u4e2d\u5b66\u4e60\u89c4\u5212\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84"}}
{"id": "2509.13696", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13696", "abs": "https://arxiv.org/abs/2509.13696", "authors": ["Iyadh Ben Cheikh Larbi", "Ajay Madhavan Ravichandran", "Aljoscha Burchardt", "Roland Roller"], "title": "Integrating Text and Time-Series into (Large) Language Models to Predict Medical Outcomes", "comment": "Presented and published at BioCreative IX", "summary": "Large language models (LLMs) excel at text generation, but their ability to\nhandle clinical classification tasks involving structured data, such as time\nseries, remains underexplored. In this work, we adapt instruction-tuned LLMs\nusing DSPy-based prompt optimization to process clinical notes and structured\nEHR inputs jointly. Our results show that this approach achieves performance on\npar with specialized multimodal systems while requiring less complexity and\noffering greater adaptability across tasks.", "AI": {"tldr": "\u4f7f\u7528DSPy\u63d0\u793a\u4f18\u5316\u6280\u672f\uff0c\u5c06\u6307\u4ee4\u8c03\u4f18\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u4e34\u5e8a\u5206\u7c7b\u4efb\u52a1\uff0c\u5904\u7406\u4e34\u5e8a\u7b14\u8bb0\u548c\u7ed3\u6784\u5316EHR\u6570\u636e\uff0c\u6027\u80fd\u5ab2\u7f8e\u4e13\u7528\u591a\u6a21\u6001\u7cfb\u7edf\u4e14\u66f4\u7b80\u5355\u7075\u6d3b", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5904\u7406\u6d89\u53ca\u7ed3\u6784\u5316\u6570\u636e\uff08\u5982\u65f6\u95f4\u5e8f\u5217\uff09\u7684\u4e34\u5e8a\u5206\u7c7b\u4efb\u52a1\u65b9\u9762\u4ecd\u6709\u5f85\u63a2\u7d22", "method": "\u91c7\u7528\u57fa\u4e8eDSPy\u7684\u63d0\u793a\u4f18\u5316\u6280\u672f\uff0c\u5bf9\u6307\u4ee4\u8c03\u4f18\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u9002\u914d\uff0c\u4f7f\u5176\u80fd\u591f\u8054\u5408\u5904\u7406\u4e34\u5e8a\u7b14\u8bb0\u548c\u7ed3\u6784\u5316EHR\u8f93\u5165", "result": "\u8be5\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u4e0e\u4e13\u7528\u591a\u6a21\u6001\u7cfb\u7edf\u76f8\u5f53\uff0c\u540c\u65f6\u9700\u8981\u66f4\u5c11\u7684\u590d\u6742\u6027\uff0c\u5e76\u5728\u4e0d\u540c\u4efb\u52a1\u95f4\u5177\u6709\u66f4\u597d\u7684\u9002\u5e94\u6027", "conclusion": "\u57fa\u4e8e\u63d0\u793a\u4f18\u5316\u7684LLM\u65b9\u6cd5\u4e3a\u4e34\u5e8a\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5904\u7406\u591a\u6a21\u6001\u533b\u7597\u6570\u636e"}}
{"id": "2509.13450", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13450", "abs": "https://arxiv.org/abs/2509.13450", "authors": ["Vincent Siu", "Nicholas Crispino", "David Park", "Nathan W. Henry", "Zhun Wang", "Yang Liu", "Dawn Song", "Chenguang Wang"], "title": "SteeringControl: Holistic Evaluation of Alignment Steering in LLMs", "comment": null, "summary": "We introduce SteeringControl, a benchmark for evaluating representation\nsteering methods across core alignment objectives--bias, harmful generation,\nand hallucination--and their effects on secondary behaviors such as sycophancy\nand commonsense morality. While prior alignment work often highlights\ntruthfulness or reasoning ability to demonstrate the side effects of\nrepresentation steering, we find there are many unexplored tradeoffs not yet\nunderstood in a systematic way. We collect a dataset of safety-relevant primary\nand secondary behaviors to evaluate steering effectiveness and behavioral\nentanglement centered around five popular steering methods. To enable this, we\ncraft a modular steering framework based on unique components that serve as the\nbuilding blocks of many existing methods. Our results on Qwen-2.5-7B and\nLlama-3.1-8B find that strong steering performance is dependent on the specific\ncombination of steering method, model, and targeted behavior, and that severe\nconcept entanglement can result from poor combinations of these three as well.\nWe release our code here:\nhttps://github.com/wang-research-lab/SteeringControl.git.", "AI": {"tldr": "SteeringControl\u662f\u4e00\u4e2a\u8bc4\u4f30\u8868\u793a\u5f15\u5bfc\u65b9\u6cd5\u7684\u57fa\u51c6\uff0c\u91cd\u70b9\u5173\u6ce8\u504f\u89c1\u3001\u6709\u5bb3\u751f\u6210\u548c\u5e7b\u89c9\u7b49\u6838\u5fc3\u5bf9\u9f50\u76ee\u6807\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u65b9\u6cd5\u5bf9\u6b21\u8981\u884c\u4e3a\uff08\u5982\u5949\u627f\u548c\u5e38\u8bc6\u9053\u5fb7\uff09\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u7684\u5bf9\u9f50\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u771f\u5b9e\u6027\u6216\u63a8\u7406\u80fd\u529b\u6765\u5c55\u793a\u8868\u793a\u5f15\u5bfc\u7684\u526f\u4f5c\u7528\uff0c\u4f46\u8bb8\u591a\u6743\u8861\u5173\u7cfb\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u6027\u7684\u7406\u89e3\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u7814\u7a76\u5f15\u5bfc\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u884c\u4e3a\u7ea0\u7f20\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u5f15\u5bfc\u6846\u67b6\uff0c\u57fa\u4e8e\u72ec\u7279\u7684\u7ec4\u4ef6\u4f5c\u4e3a\u73b0\u6709\u65b9\u6cd5\u7684\u6784\u5efa\u5757\u3002\u6536\u96c6\u4e86\u5b89\u5168\u76f8\u5173\u7684\u4e3b\u8981\u548c\u6b21\u8981\u884c\u4e3a\u6570\u636e\u96c6\uff0c\u56f4\u7ed5\u4e94\u79cd\u6d41\u884c\u7684\u5f15\u5bfc\u65b9\u6cd5\u8fdb\u884c\u8bc4\u4f30\uff0c\u5728Qwen-2.5-7B\u548cLlama-3.1-8B\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u53d1\u73b0\u5f3a\u5f15\u5bfc\u6027\u80fd\u53d6\u51b3\u4e8e\u5f15\u5bfc\u65b9\u6cd5\u3001\u6a21\u578b\u548c\u76ee\u6807\u884c\u4e3a\u7684\u7279\u5b9a\u7ec4\u5408\uff0c\u4e0d\u826f\u7684\u7ec4\u5408\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u6982\u5ff5\u7ea0\u7f20\u95ee\u9898\u3002", "conclusion": "\u5f15\u5bfc\u65b9\u6cd5\u7684\u6709\u6548\u6027\u5177\u6709\u9ad8\u5ea6\u60c5\u5883\u4f9d\u8d56\u6027\uff0c\u9700\u8981\u4ed4\u7ec6\u9009\u62e9\u65b9\u6cd5\u3001\u6a21\u578b\u548c\u76ee\u6807\u7684\u7ec4\u5408\uff0c\u4ee5\u907f\u514d\u610f\u5916\u7684\u8d1f\u9762\u526f\u4f5c\u7528\u3002\u7814\u7a76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u5f00\u6e90\u4ee3\u7801\u6765\u4fc3\u8fdb\u8fd9\u4e00\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.13702", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13702", "abs": "https://arxiv.org/abs/2509.13702", "authors": ["Xiao Zheng"], "title": "DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models", "comment": null, "summary": "Large Language Model (LLM) hallucination is a significant barrier to their\nreliable deployment. Current methods like Retrieval-Augmented Generation (RAG)\nare often reactive. We introduce **Dynamic Self-reinforcing Calibration for\nHallucination Suppression (DSCC-HS)**, a novel, proactive framework that\nintervenes during autoregressive decoding. Inspired by dual-process cognitive\ntheory, DSCC-HS uses a compact proxy model, trained in adversarial roles as a\nFactual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During\ninference, these proxies dynamically steer a large target model by injecting a\nreal-time steering vector, which is the difference between FAP and HDP logits,\nat each decoding step. This plug-and-play approach requires no modification to\nthe target model. Our experiments on TruthfulQA and BioGEN show DSCC-HS\nachieves state-of-the-art performance. On TruthfulQA, it reached a 99.2%\nFactual Consistency Rate (FCR). On the long-form BioGEN benchmark, it attained\nthe highest FActScore of 46.50. These results validate DSCC-HS as a principled\nand efficient solution for enhancing LLM factuality.", "AI": {"tldr": "DSCC-HS\u662f\u4e00\u79cd\u65b0\u9896\u7684\u4e3b\u52a8\u5f0f\u5e7b\u89c9\u6291\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u7d27\u51d1\u4ee3\u7406\u6a21\u578b\u5728\u81ea\u56de\u5f52\u89e3\u7801\u8fc7\u7a0b\u4e2d\u52a8\u6001\u6821\u51c6\uff0c\u65e0\u9700\u4fee\u6539\u76ee\u6807\u6a21\u578b\u5373\u53ef\u663e\u8457\u63d0\u5347LLM\u7684\u4e8b\u5b9e\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\u662f\u5176\u53ef\u9760\u90e8\u7f72\u7684\u4e3b\u8981\u969c\u788d\uff0c\u73b0\u6709\u65b9\u6cd5\u5982RAG\u5f80\u5f80\u662f\u88ab\u52a8\u7684\uff0c\u9700\u8981\u4e00\u79cd\u4e3b\u52a8\u5e72\u9884\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u53cc\u8fc7\u7a0b\u8ba4\u77e5\u7406\u8bba\uff0c\u4f7f\u7528\u7d27\u51d1\u4ee3\u7406\u6a21\u578b\u5206\u522b\u4f5c\u4e3a\u4e8b\u5b9e\u5bf9\u9f50\u4ee3\u7406(FAP)\u548c\u5e7b\u89c9\u68c0\u6d4b\u4ee3\u7406(HDP)\uff0c\u5728\u63a8\u7406\u65f6\u901a\u8fc7\u5b9e\u65f6\u6ce8\u5165\u8f6c\u5411\u5411\u91cf\uff08FAP\u548cHDP\u5bf9\u6570\u6982\u7387\u7684\u5dee\u503c\uff09\u6765\u52a8\u6001\u5f15\u5bfc\u5927\u6a21\u578b\u3002", "result": "\u5728TruthfulQA\u4e0a\u8fbe\u523099.2%\u7684\u4e8b\u5b9e\u4e00\u81f4\u6027\u7387\uff0c\u5728BioGEN\u57fa\u51c6\u4e0a\u83b7\u5f97\u6700\u9ad8\u7684FActScore 46.50\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "DSCC-HS\u662f\u4e00\u4e2a\u539f\u7406\u6e05\u6670\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u589e\u5f3aLLM\u7684\u4e8b\u5b9e\u6027\uff0c\u4e3a\u53ef\u9760\u90e8\u7f72\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2509.13547", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.13547", "abs": "https://arxiv.org/abs/2509.13547", "authors": ["Harper Reed", "Michael Sugimura", "Angelo Zangari"], "title": "AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving", "comment": "16 pages, 5 tables", "summary": "We investigate whether giving LLM agents the collaborative tools and autonomy\nthat humans naturally use for problem solving can improve their performance. We\nequip Claude Code agents with MCP-based social media and journaling tools and\nallow them to use these tools as they see fit. Across 34 Aider Polyglot Python\nprogramming challenges, collaborative tools substantially improve performance\non the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and\n12-38% faster completion than baseline agents. Effects on the full challenge\nset are mixed, suggesting these tools act as performance enhancers when\nadditional reasoning scaffolding is most needed. Surprisingly, Different models\nnaturally adopted distinct collaborative strategies without explicit\ninstruction. Sonnet 3.7 engaged broadly across tools and benefited from\narticulation-based cognitive scaffolding. Sonnet 4 showed selective adoption,\nleaning on journal-based semantic search when problems were genuinely\ndifficult. This mirrors how human developers adjust collaboration based on\nexpertise and task complexity. Behavioral analysis shows agents prefer writing\nover reading by about 2-9x, indicating that structured articulation drives much\nof the improvement rather than information access alone. Overall, AI agents can\nsystematically benefit from human-inspired collaboration tools at the edge of\ntheir capabilities, pointing to adaptive collaborative interfaces as reasoning\nenhancers rather than universal efficiency boosts.", "AI": {"tldr": "\u4e3aLLM\u4ee3\u7406\u63d0\u4f9b\u7c7b\u4f3c\u4eba\u7c7b\u7684\u534f\u4f5c\u5de5\u5177\u548c\u81ea\u4e3b\u6027\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5176\u5728\u6700\u56f0\u96be\u7f16\u7a0b\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u8868\u73b0\uff0c\u6210\u672c\u964d\u4f4e15-40%\uff0c\u56de\u5408\u6570\u51cf\u5c1112-27%\uff0c\u5b8c\u6210\u65f6\u95f4\u52a0\u5feb12-38%", "motivation": "\u7814\u7a76\u662f\u5426\u901a\u8fc7\u8d4b\u4e88LLM\u4ee3\u7406\u4eba\u7c7b\u81ea\u7136\u4f7f\u7528\u7684\u534f\u4f5c\u5de5\u5177\u548c\u81ea\u4e3b\u6027\uff0c\u80fd\u591f\u6539\u5584\u5176\u95ee\u9898\u89e3\u51b3\u6027\u80fd", "method": "\u4e3aClaude Code\u4ee3\u7406\u914d\u5907\u57fa\u4e8eMCP\u7684\u793e\u4ea4\u5a92\u4f53\u548c\u65e5\u5fd7\u5de5\u5177\uff0c\u5141\u8bb8\u5176\u81ea\u4e3b\u4f7f\u7528\u8fd9\u4e9b\u5de5\u5177\uff0c\u572834\u4e2aAider Polyglot Python\u7f16\u7a0b\u6311\u6218\u4e2d\u8fdb\u884c\u6d4b\u8bd5", "result": "\u534f\u4f5c\u5de5\u5177\u663e\u8457\u63d0\u5347\u4e86\u6700\u56f0\u96be\u95ee\u9898\u7684\u6027\u80fd\u8868\u73b0\uff0c\u4e0d\u540c\u6a21\u578b\u81ea\u7136\u91c7\u7528\u4e86\u4e0d\u540c\u7684\u534f\u4f5c\u7b56\u7565\uff0c\u4ee3\u7406\u8868\u73b0\u51fa\u504f\u597d\u5199\u4f5c\u800c\u975e\u9605\u8bfb\uff082-9\u500d\uff09\uff0c\u7ed3\u6784\u5316\u8868\u8fbe\u662f\u6539\u8fdb\u7684\u4e3b\u8981\u9a71\u52a8\u529b", "conclusion": "AI\u4ee3\u7406\u5728\u5176\u80fd\u529b\u8fb9\u7f18\u53ef\u4ee5\u7cfb\u7edf\u6027\u5730\u53d7\u76ca\u4e8e\u4eba\u7c7b\u542f\u53d1\u7684\u534f\u4f5c\u5de5\u5177\uff0c\u9002\u5e94\u6027\u534f\u4f5c\u754c\u9762\u5e94\u88ab\u89c6\u4e3a\u63a8\u7406\u589e\u5f3a\u5668\u800c\u975e\u901a\u7528\u6548\u7387\u63d0\u5347\u5de5\u5177"}}
{"id": "2509.13706", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13706", "abs": "https://arxiv.org/abs/2509.13706", "authors": ["Peter Beidler", "Mark Nguyen", "Kevin Lybarger", "Ola Holmberg", "Eric Ford", "John Kang"], "title": "Automated Triaging and Transfer Learning of Incident Learning Safety Reports Using Large Language Representational Models", "comment": null, "summary": "PURPOSE: Incident reports are an important tool for safety and quality\nimprovement in healthcare, but manual review is time-consuming and requires\nsubject matter expertise. Here we present a natural language processing (NLP)\nscreening tool to detect high-severity incident reports in radiation oncology\nacross two institutions.\n  METHODS AND MATERIALS: We used two text datasets to train and evaluate our\nNLP models: 7,094 reports from our institution (Inst.), and 571 from IAEA\nSAFRON (SF), all of which had severity scores labeled by clinical content\nexperts. We trained and evaluated two types of models: baseline support vector\nmachines (SVM) and BlueBERT which is a large language model pretrained on\nPubMed abstracts and hospitalized patient data. We assessed for\ngeneralizability of our model in two ways. First, we evaluated models trained\nusing Inst.-train on SF-test. Second, we trained a BlueBERT_TRANSFER model that\nwas first fine-tuned on Inst.-train then on SF-train before testing on SF-test\nset. To further analyze model performance, we also examined a subset of 59\nreports from our Inst. dataset, which were manually edited for clarity.\n  RESULTS Classification performance on the Inst. test achieved AUROC 0.82\nusing SVM and 0.81 using BlueBERT. Without cross-institution transfer learning,\nperformance on the SF test was limited to an AUROC of 0.42 using SVM and 0.56\nusing BlueBERT. BlueBERT_TRANSFER, which was fine-tuned on both datasets,\nimproved the performance on SF test to AUROC 0.78. Performance of SVM, and\nBlueBERT_TRANSFER models on the manually curated Inst. reports (AUROC 0.85 and\n0.74) was similar to human performance (AUROC 0.81).\n  CONCLUSION: In summary, we successfully developed cross-institution NLP\nmodels on incident report text from radiation oncology centers. These models\nwere able to detect high-severity reports similarly to humans on a curated\ndataset.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u57fa\u4e8eNLP\u7684\u533b\u7597\u4e8b\u4ef6\u62a5\u544a\u4e25\u91cd\u6027\u81ea\u52a8\u7b5b\u67e5\u5de5\u5177\uff0c\u4f7f\u7528SVM\u548cBlueBERT\u6a21\u578b\u5728\u653e\u5c04\u80bf\u7624\u5b66\u9886\u57df\u8fdb\u884c\u8de8\u673a\u6784\u9a8c\u8bc1\uff0c\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u663e\u8457\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u533b\u7597\u4e8b\u4ef6\u62a5\u544a\u7684\u624b\u52a8\u5ba1\u67e5\u8017\u65f6\u4e14\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\uff0c\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u6765\u63d0\u9ad8\u5b89\u5168\u6027\u548c\u8d28\u91cf\u6539\u8fdb\u7684\u6548\u7387\u3002", "method": "\u4f7f\u75287,094\u4efd\u673a\u6784\u62a5\u544a\u548c571\u4efdIAEA SAFRON\u62a5\u544a\uff0c\u8bad\u7ec3SVM\u548c\u57fa\u4e8ePubMed\u9884\u8bad\u7ec3\u7684BlueBERT\u6a21\u578b\uff0c\u91c7\u7528\u8de8\u673a\u6784\u8fc1\u79fb\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u673a\u6784\u5185\u6d4b\u8bd5AUROC\u8fbe0.82\uff0c\u8de8\u673a\u6784\u6d4b\u8bd5\u4ece0.42-0.56\u63d0\u5347\u81f30.78\uff0c\u5728\u4eba\u5de5\u7f16\u8f91\u6570\u636e\u96c6\u4e0a\u4e0e\u4eba\u7c7b\u8868\u73b0\u76f8\u5f53(AUROC 0.81 vs 0.74-0.85)\u3002", "conclusion": "\u6210\u529f\u5f00\u53d1\u4e86\u8de8\u673a\u6784NLP\u6a21\u578b\uff0c\u80fd\u591f\u50cf\u4eba\u7c7b\u4e13\u5bb6\u4e00\u6837\u6709\u6548\u68c0\u6d4b\u9ad8\u4e25\u91cd\u6027\u653e\u5c04\u80bf\u7624\u5b66\u4e8b\u4ef6\u62a5\u544a\u3002"}}
{"id": "2509.13570", "categories": ["cs.AI", "math.HO", "Primary: 97U50, Secondary: 97U70, 97D40, 97D60, 97E50, 97H40"], "pdf": "https://arxiv.org/pdf/2509.13570", "abs": "https://arxiv.org/abs/2509.13570", "authors": ["Hannah Klawa", "Shraddha Rajpal", "Cigole Thomas"], "title": "Gen AI in Proof-based Math Courses: A Pilot Study", "comment": "35 pages, 6 figures, Comments welcome!", "summary": "With the rapid rise of generative AI in higher education and the\nunreliability of current AI detection tools, developing policies that encourage\nstudent learning and critical thinking has become increasingly important. This\nstudy examines student use and perceptions of generative AI across three\nproof-based undergraduate mathematics courses: a first-semester abstract\nalgebra course, a topology course and a second-semester abstract algebra\ncourse. In each case, course policy permitted some use of generative AI.\nDrawing on survey responses and student interviews, we analyze how students\nengaged with AI tools, their perceptions of generative AI's usefulness and\nlimitations, and what implications these perceptions hold for teaching\nproof-based mathematics. We conclude by discussing future considerations for\nintegrating generative AI into proof-based mathematics instruction.", "AI": {"tldr": "\u672c\u7814\u7a76\u8c03\u67e5\u4e86\u672c\u79d1\u751f\u5728\u8bc1\u660e\u6570\u5b66\u8bfe\u7a0b\u4e2d\u4f7f\u7528\u751f\u6210\u5f0fAI\u7684\u60c5\u51b5\uff0c\u5206\u6790\u5b66\u751f\u7684\u4f7f\u7528\u884c\u4e3a\u548c\u8ba4\u77e5\uff0c\u63a2\u8ba8\u5bf9\u6570\u5b66\u6559\u5b66\u7684\u5f71\u54cd", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u5728\u9ad8\u7b49\u6559\u80b2\u4e2d\u7684\u5feb\u901f\u5174\u8d77\u548c\u73b0\u6709AI\u68c0\u6d4b\u5de5\u5177\u7684\u4e0d\u53ef\u9760\u6027\uff0c\u9700\u8981\u5236\u5b9a\u9f13\u52b1\u5b66\u751f\u5b66\u4e60\u548c\u6279\u5224\u6027\u601d\u7ef4\u7684\u653f\u7b56", "method": "\u901a\u8fc7\u8c03\u67e5\u95ee\u5377\u548c\u5b66\u751f\u8bbf\u8c08\uff0c\u5206\u6790\u4e09\u4e2a\u8bc1\u660e\u6570\u5b66\u8bfe\u7a0b\uff08\u62bd\u8c61\u4ee3\u6570\u3001\u62d3\u6251\u5b66\uff09\u4e2d\u5b66\u751f\u5bf9AI\u5de5\u5177\u7684\u4f7f\u7528\u60c5\u51b5\u548c\u8ba4\u77e5", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u5b66\u751f\u5982\u4f55\u4e0eAI\u5de5\u5177\u4e92\u52a8\uff0c\u4ed6\u4eec\u5bf9\u751f\u6210\u5f0fAI\u6709\u7528\u6027\u548c\u5c40\u9650\u6027\u7684\u770b\u6cd5", "conclusion": "\u8ba8\u8bba\u4e86\u5c06\u751f\u6210\u5f0fAI\u6574\u5408\u5230\u8bc1\u660e\u6570\u5b66\u6559\u5b66\u4e2d\u7684\u672a\u6765\u8003\u8651\u56e0\u7d20"}}
{"id": "2509.13723", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13723", "abs": "https://arxiv.org/abs/2509.13723", "authors": ["Yaxin Gao", "Yao Lu", "Zongfei Zhang", "Jiaqi Nie", "Shanqing Yu", "Qi Xuan"], "title": "DSPC: Dual-Stage Progressive Compression Framework for Efficient Long-Context Reasoning", "comment": null, "summary": "Large language models (LLMs) have achieved remarkable success in many natural\nlanguage processing (NLP) tasks. To achieve more accurate output, the prompts\nused to drive LLMs have become increasingly longer, which incurs higher\ncomputational costs. To address this prompt inflation problem, prompt\ncompression has been proposed. However, most existing methods require training\na small auxiliary model for compression, incurring a significant amount of\nadditional computation. To avoid this, we propose a two-stage, training-free\napproach, called Dual-Stage Progressive Compression (DSPC). In the\ncoarse-grained stage, semantic-related sentence filtering removes sentences\nwith low semantic value based on TF-IDF. In the fine-grained stage, token\nimportance is assessed using attention contribution, cross-model loss\ndifference, and positional importance, enabling the pruning of low-utility\ntokens while preserving semantics. We validate DSPC on LLaMA-3.1-8B-Instruct\nand GPT-3.5-Turbo under a constrained token budget and observe consistent\nimprovements. For instance, in the FewShot task of the Longbench dataset, DSPC\nachieves a performance of 49.17 by using only 3x fewer tokens, outperforming\nthe best state-of-the-art baseline LongLLMLingua by 7.76.", "AI": {"tldr": "\u63d0\u51faDSPC\u53cc\u9636\u6bb5\u6e10\u8fdb\u538b\u7f29\u65b9\u6cd5\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u538b\u7f29LLM\u63d0\u793a\uff0c\u5728\u51cf\u5c113\u500dtoken\u7684\u60c5\u51b5\u4e0b\u6027\u80fd\u63d0\u53477.76%\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u65b9\u6cd5", "motivation": "\u89e3\u51b3LLM\u63d0\u793a\u8d8a\u6765\u8d8a\u957f\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u589e\u52a0\u7684\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u8bad\u7ec3\u8f85\u52a9\u6a21\u578b\u5e26\u6765\u989d\u5916\u8ba1\u7b97\u5f00\u9500", "method": "\u4e24\u9636\u6bb5\u65e0\u8bad\u7ec3\u65b9\u6cd5\uff1a\u7c97\u7c92\u5ea6\u9636\u6bb5\u57fa\u4e8eTF-IDF\u8fc7\u6ee4\u4f4e\u8bed\u4e49\u4ef7\u503c\u53e5\u5b50\uff1b\u7ec6\u7c92\u5ea6\u9636\u6bb5\u4f7f\u7528\u6ce8\u610f\u529b\u8d21\u732e\u3001\u8de8\u6a21\u578b\u635f\u5931\u5dee\u5f02\u548c\u4f4d\u7f6e\u91cd\u8981\u6027\u8bc4\u4f30token\u91cd\u8981\u6027\uff0c\u4fee\u526a\u4f4e\u6548\u7528token", "result": "\u5728LLaMA-3.1-8B-Instruct\u548cGPT-3.5-Turbo\u4e0a\u9a8c\u8bc1\uff0c\u5728\u53d7\u9650token\u9884\u7b97\u4e0b\u6027\u80fd\u6301\u7eed\u63d0\u5347\u3002Longbench FewShot\u4efb\u52a1\u4e2d\u4f7f\u7528\u4ec53\u500d\u66f4\u5c11token\u8fbe\u523049.17\u6027\u80fd\uff0c\u4f18\u4e8eLongLLMLingua 7.76", "conclusion": "DSPC\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u65e0\u8bad\u7ec3\u63d0\u793a\u538b\u7f29\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u4fdd\u6301\u8bed\u4e49\u5b8c\u6574\u6027\uff0c\u5728\u591a\u4e2a\u6a21\u578b\u548c\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02"}}
{"id": "2509.13588", "categories": ["cs.AI", "cs.CE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.13588", "abs": "https://arxiv.org/abs/2509.13588", "authors": ["Xuan Liu", "Haoyang Shang", "Haojian Jin"], "title": "Programmable Cognitive Bias in Social Agents", "comment": null, "summary": "This paper introduces CoBRA, a novel toolkit for systematically specifying\nagent behavior in LLM-based social simulation. We found that conventional\napproaches that specify agent behaviors through implicit natural language\ndescriptions cannot yield consistent behaviors across models, and the produced\nagent behaviors do not capture the nuances of the descriptions. In contrast,\nCoBRA presents a new approach to program agents' cognitive biases explicitly,\nby grounding agents' expected behaviors using classic social science\nexperiments. CoBRA has two components: (1) Cognitive Bias Index that measures\nthe cognitive bias of a social agent, by quantifying the agent's reactions in a\nset of validated classical social science experiments; (2) Behavioral\nRegulation Engine that aligns the agent's behavior to demonstrate controlled\ncognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and\ntechnical benchmarks. Our results suggest that CoBRA can precisely program the\ncognitive bias demonstrated in a social agent in a model-agnostic manner.", "AI": {"tldr": "CoBRA\u662f\u4e00\u4e2a\u7528\u4e8e\u5728\u57fa\u4e8eLLM\u7684\u793e\u4f1a\u6a21\u62df\u4e2d\u7cfb\u7edf\u5316\u6307\u5b9a\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u65b0\u5de5\u5177\u5305\uff0c\u901a\u8fc7\u663e\u5f0f\u7f16\u7a0b\u8ba4\u77e5\u504f\u89c1\u6765\u89e3\u51b3\u4f20\u7edf\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u65b9\u6cd5\u7684\u4e00\u81f4\u6027\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u901a\u8fc7\u9690\u5f0f\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u6307\u5b9a\u667a\u80fd\u4f53\u884c\u4e3a\u5b58\u5728\u8de8\u6a21\u578b\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u4e14\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u63cf\u8ff0\u7684\u7ec6\u5fae\u5dee\u522b\uff0c\u9700\u8981\u66f4\u7cfb\u7edf\u5316\u7684\u884c\u4e3a\u89c4\u8303\u65b9\u6cd5\u3002", "method": "CoBRA\u5305\u542b\u4e24\u4e2a\u7ec4\u4ef6\uff1a\u8ba4\u77e5\u504f\u89c1\u6307\u6570\uff08\u901a\u8fc7\u7ecf\u5178\u793e\u4f1a\u79d1\u5b66\u5b9e\u9a8c\u91cf\u5316\u667a\u80fd\u4f53\u53cd\u5e94\uff09\u548c\u884c\u4e3a\u8c03\u8282\u5f15\u64ce\uff08\u5c06\u667a\u80fd\u4f53\u884c\u4e3a\u4e0e\u53d7\u63a7\u8ba4\u77e5\u504f\u89c1\u5bf9\u9f50\uff09\uff0c\u91c7\u7528\u57fa\u4e8e\u7ecf\u5178\u793e\u4f1a\u5b9e\u9a8c\u7684\u663e\u5f0f\u7f16\u7a0b\u65b9\u6cd5\u3002", "result": "\u8bc4\u4f30\u663e\u793aCoBRA\u80fd\u591f\u4ee5\u6a21\u578b\u65e0\u5173\u7684\u65b9\u5f0f\u7cbe\u786e\u7f16\u7a0b\u793e\u4f1a\u667a\u80fd\u4f53\u4e2d\u5c55\u793a\u7684\u8ba4\u77e5\u504f\u89c1\uff0c\u5728\u6280\u672f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\u3002", "conclusion": "CoBRA\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u5de5\u5177\u5305\uff0c\u80fd\u591f\u7cfb\u7edf\u5316\u5730\u6307\u5b9a\u548c\u8c03\u8282LLM\u57fa\u793e\u4f1a\u6a21\u62df\u4e2d\u667a\u80fd\u4f53\u7684\u8ba4\u77e5\u504f\u89c1\u884c\u4e3a\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2509.13734", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13734", "abs": "https://arxiv.org/abs/2509.13734", "authors": ["Yosuke Mikami", "Daiki Matsuoka", "Hitomi Yanaka"], "title": "Implementing a Logical Inference System for Japanese Comparatives", "comment": "In Proceedings of the 5th Workshop on Natural Logic Meets Machine\n  Learning (NALOMA)", "summary": "Natural Language Inference (NLI) involving comparatives is challenging\nbecause it requires understanding quantities and comparative relations\nexpressed by sentences. While some approaches leverage Large Language Models\n(LLMs), we focus on logic-based approaches grounded in compositional semantics,\nwhich are promising for robust handling of numerical and logical expressions.\nPrevious studies along these lines have proposed logical inference systems for\nEnglish comparatives. However, it has been pointed out that there are several\nmorphological and semantic differences between Japanese and English\ncomparatives. These differences make it difficult to apply such systems\ndirectly to Japanese comparatives. To address this gap, this study proposes\nccg-jcomp, a logical inference system for Japanese comparatives based on\ncompositional semantics. We evaluate the proposed system on a Japanese NLI\ndataset containing comparative expressions. We demonstrate the effectiveness of\nour system by comparing its accuracy with that of existing LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7ec4\u5408\u8bed\u4e49\u7684\u65e5\u8bed\u6bd4\u8f83\u53e5\u903b\u8f91\u63a8\u7406\u7cfb\u7edfccg-jcomp\uff0c\u7528\u4e8e\u5904\u7406\u65e5\u8bed\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4e2d\u7684\u6bd4\u8f83\u8868\u8fbe\uff0c\u5e76\u5728\u65e5\u8bedNLI\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u65e5\u8bed\u548c\u82f1\u8bed\u6bd4\u8f83\u53e5\u5728\u5f62\u6001\u548c\u8bed\u4e49\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u4f7f\u5f97\u73b0\u6709\u7684\u82f1\u8bed\u6bd4\u8f83\u53e5\u903b\u8f91\u63a8\u7406\u7cfb\u7edf\u96be\u4ee5\u76f4\u63a5\u5e94\u7528\u4e8e\u65e5\u8bed\u3002\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u65e5\u8bed\u6bd4\u8f83\u53e5\u5f00\u53d1\u903b\u8f91\u63a8\u7406\u7cfb\u7edf\u3002", "method": "\u57fa\u4e8e\u7ec4\u5408\u8bed\u4e49\u6784\u5efa\u903b\u8f91\u63a8\u7406\u7cfb\u7edfccg-jcomp\uff0c\u4e13\u95e8\u5904\u7406\u65e5\u8bed\u6bd4\u8f83\u53e5\u7684\u6570\u503c\u548c\u903b\u8f91\u8868\u8fbe\u5f0f\uff0c\u91c7\u7528\u903b\u8f91\u57fa\u7840\u65b9\u6cd5\u800c\u975e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5728\u5305\u542b\u6bd4\u8f83\u8868\u8fbe\u7684\u65e5\u8bedNLI\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u7cfb\u7edf\u6027\u80fd\uff0c\u5e76\u4e0e\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u51c6\u786e\u7387\u8fdb\u884c\u6bd4\u8f83\uff0c\u8bc1\u660e\u4e86\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002", "conclusion": "ccg-jcomp\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5904\u7406\u65e5\u8bed\u6bd4\u8f83\u53e5\u7684\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4efb\u52a1\uff0c\u4e3a\u65e5\u8bed\u6bd4\u8f83\u53e5\u7684\u903b\u8f91\u63a8\u7406\u63d0\u4f9b\u4e86\u4e13\u95e8\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.13615", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.13615", "abs": "https://arxiv.org/abs/2509.13615", "authors": ["Zongru Wu", "Rui Mao", "Zhiyuan Tian", "Pengzhou Cheng", "Tianjie Ju", "Zheng Wu", "Lingzhong Dong", "Haiyue Sheng", "Zhuosheng Zhang", "Gongshen Liu"], "title": "See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles", "comment": null, "summary": "The advent of multimodal agents facilitates effective interaction within\ngraphical user interface (GUI), especially in ubiquitous GUI control. However,\ntheir inability to reliably execute toggle control instructions remains a key\nbottleneck. To investigate this, we construct a state control benchmark with\nbinary toggle instructions from public datasets. Evaluations of existing agents\ndemonstrate their unreliability, particularly when the current toggle state\nalready matches the desired state. To address the challenge, we propose\nState-aware Reasoning (StaR), a training method that teaches agents to perceive\nthe current toggle state, analyze the desired state from the instruction, and\nact accordingly. Experiments on three multimodal agents demonstrate that StaR\ncan improve toggle instruction execution accuracy by over 30\\%. Further\nevaluations on three public benchmarks show that StaR also enhances general\ntask performance. Finally, evaluations on a dynamic environment highlight the\npotential of StaR for real-world applications. Code, benchmark, and\nStaR-enhanced agents are available at https://github.com/ZrW00/StaR.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u591a\u6a21\u6001\u4ee3\u7406\u5728GUI\u5207\u6362\u63a7\u5236\u4e2d\u7684\u4e0d\u53ef\u9760\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u72b6\u6001\u611f\u77e5\u63a8\u7406(StaR)\u8bad\u7ec3\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5207\u6362\u6307\u4ee4\u6267\u884c\u51c6\u786e\u738730%\u4ee5\u4e0a\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u4ee3\u7406\u5728\u6267\u884c\u56fe\u5f62\u7528\u6237\u754c\u9762(GUI)\u5207\u6362\u63a7\u5236\u6307\u4ee4\u65f6\u5b58\u5728\u4e0d\u53ef\u9760\u6027\uff0c\u7279\u522b\u662f\u5728\u5f53\u524d\u5207\u6362\u72b6\u6001\u5df2\u7b26\u5408\u671f\u671b\u72b6\u6001\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u6210\u4e3aGUI\u63a7\u5236\u7684\u5173\u952e\u74f6\u9888\u3002", "method": "\u63d0\u51fa\u72b6\u6001\u611f\u77e5\u63a8\u7406(StaR)\u8bad\u7ec3\u65b9\u6cd5\uff0c\u6559\u5bfc\u4ee3\u7406\u611f\u77e5\u5f53\u524d\u5207\u6362\u72b6\u6001\u3001\u5206\u6790\u6307\u4ee4\u4e2d\u7684\u671f\u671b\u72b6\u6001\uff0c\u5e76\u76f8\u5e94\u91c7\u53d6\u884c\u52a8\u3002\u6784\u5efa\u4e86\u5305\u542b\u4e8c\u8fdb\u5236\u5207\u6362\u6307\u4ee4\u7684\u72b6\u6001\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5728\u4e09\u4e2a\u591a\u6a21\u6001\u4ee3\u7406\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cStaR\u80fd\u5c06\u5207\u6362\u6307\u4ee4\u6267\u884c\u51c6\u786e\u7387\u63d0\u534730%\u4ee5\u4e0a\u3002\u5728\u4e09\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8fdb\u4e00\u6b65\u8bc4\u4f30\u663e\u793a\uff0cStaR\u8fd8\u80fd\u63d0\u5347\u4e00\u822c\u4efb\u52a1\u6027\u80fd\u3002\u52a8\u6001\u73af\u5883\u8bc4\u4f30\u7a81\u663e\u4e86StaR\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "StaR\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u4ee3\u7406\u5728GUI\u5207\u6362\u63a7\u5236\u4e2d\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u4e0d\u4ec5\u663e\u8457\u63d0\u5347\u4e86\u5207\u6362\u6307\u4ee4\u6267\u884c\u51c6\u786e\u7387\uff0c\u8fd8\u589e\u5f3a\u4e86\u4ee3\u7406\u7684\u4e00\u822c\u4efb\u52a1\u6027\u80fd\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.13775", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13775", "abs": "https://arxiv.org/abs/2509.13775", "authors": ["Vani Kanjirangat", "Ljiljana Dolamic", "Fabio Rinaldi"], "title": "Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications", "comment": "4 main pages, 4 additional, 5 figures", "summary": "This paper discusses our exploration of different data-efficient and\nparameter-efficient approaches to Arabic Dialect Identification (ADI). In\nparticular, we investigate various soft-prompting strategies, including\nprefix-tuning, prompt-tuning, P-tuning, and P-tuning V2, as well as LoRA\nreparameterizations. For the data-efficient strategy, we analyze hard prompting\nwith zero-shot and few-shot inferences to analyze the dialect identification\ncapabilities of Large Language Models (LLMs). For the parameter-efficient PEFT\napproaches, we conducted our experiments using Arabic-specific encoder models\non several major datasets. We also analyzed the n-shot inferences on\nopen-source decoder-only models, a general multilingual model (Phi-3.5), and an\nArabic-specific one(SILMA). We observed that the LLMs generally struggle to\ndifferentiate the dialectal nuances in the few-shot or zero-shot setups. The\nsoft-prompted encoder variants perform better, while the LoRA-based fine-tuned\nmodels perform best, even surpassing full fine-tuning.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4e86\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u8bc6\u522b(ADI)\u7684\u6570\u636e\u9ad8\u6548\u548c\u53c2\u6570\u9ad8\u6548\u65b9\u6cd5\uff0c\u5305\u62ec\u8f6f\u63d0\u793a\u7b56\u7565\u3001LoRA\u91cd\u53c2\u6570\u5316\u4ee5\u53ca\u96f6\u6837\u672c/\u5c11\u6837\u672c\u63a8\u7406\uff0c\u53d1\u73b0LoRA\u5fae\u8c03\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u7814\u7a76\u4e0d\u540c\u6570\u636e\u9ad8\u6548\u548c\u53c2\u6570\u9ad8\u6548\u65b9\u6cd5\u5728\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u8bc6\u522b\u4efb\u52a1\u4e2d\u7684\u6548\u679c\uff0c\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65b9\u8a00\u8bc6\u522b\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u8f6f\u63d0\u793a\u7b56\u7565(\u524d\u7f00\u8c03\u4f18\u3001\u63d0\u793a\u8c03\u4f18\u3001P-tuning\u3001P-tuning V2)\u548cLoRA\u91cd\u53c2\u6570\u5316\uff1b\u5206\u6790\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u63a8\u7406\uff1b\u5728\u963f\u62c9\u4f2f\u8bed\u4e13\u7528\u7f16\u7801\u5668\u6a21\u578b\u548c\u591a\u8bed\u8a00\u89e3\u7801\u5668\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c/\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u96be\u4ee5\u533a\u5206\u65b9\u8a00\u7ec6\u5fae\u5dee\u522b\uff1b\u8f6f\u63d0\u793a\u7f16\u7801\u5668\u53d8\u4f53\u8868\u73b0\u66f4\u597d\uff1b\u57fa\u4e8eLoRA\u7684\u5fae\u8c03\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u751a\u81f3\u8d85\u8fc7\u5168\u5fae\u8c03\u3002", "conclusion": "LoRA\u5fae\u8c03\u662f\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u8bc6\u522b\u6700\u6709\u6548\u7684\u53c2\u6570\u9ad8\u6548\u65b9\u6cd5\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u7684\u65b9\u8a00\u8bc6\u522b\u80fd\u529b\u6709\u9650\u3002"}}
{"id": "2509.13704", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13704", "abs": "https://arxiv.org/abs/2509.13704", "authors": ["Liangtao Lin", "Zhaomeng Zhu", "Tianwei Zhang", "Yonggang Wen"], "title": "InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management", "comment": null, "summary": "Mission-critical industrial infrastructure, such as data centers,\nincreasingly depends on complex management software. Its operations, however,\npose significant challenges due to the escalating system complexity,\nmulti-vendor integration, and a shortage of expert operators. While Robotic\nProcess Automation (RPA) offers partial automation through handcrafted scripts,\nit suffers from limited flexibility and high maintenance costs. Recent advances\nin Large Language Model (LLM)-based graphical user interface (GUI) agents have\nenabled more flexible automation, yet these general-purpose agents face five\ncritical challenges when applied to industrial management, including unfamiliar\nelement understanding, precision and efficiency, state localization, deployment\nconstraints, and safety requirements. To address these issues, we propose\nInfraMind, a novel exploration-based GUI agentic framework specifically\ntailored for industrial management systems. InfraMind integrates five\ninnovative modules to systematically resolve different challenges in industrial\nmanagement: (1) systematic search-based exploration with virtual machine\nsnapshots for autonomous understanding of complex GUIs; (2) memory-driven\nplanning to ensure high-precision and efficient task execution; (3) advanced\nstate identification for robust localization in hierarchical interfaces; (4)\nstructured knowledge distillation for efficient deployment with lightweight\nmodels; and (5) comprehensive, multi-layered safety mechanisms to safeguard\nsensitive operations. Extensive experiments on both open-source and commercial\nDCIM platforms demonstrate that our approach consistently outperforms existing\nframeworks in terms of task success rate and operational efficiency, providing\na rigorous and scalable solution for industrial management automation.", "AI": {"tldr": "InfraMind\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3a\u5de5\u4e1a\u7ba1\u7406\u7cfb\u7edf\u8bbe\u8ba1\u7684\u57fa\u4e8e\u63a2\u7d22\u7684GUI\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u4e94\u4e2a\u521b\u65b0\u6a21\u5757\u89e3\u51b3\u73b0\u6709LLM-based GUI\u4ee3\u7406\u5728\u5de5\u4e1a\u7ba1\u7406\u4e2d\u7684\u4e94\u5927\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u6210\u529f\u7387\u548c\u64cd\u4f5c\u6548\u7387\u3002", "motivation": "\u5de5\u4e1a\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\u8f6f\u4ef6\u9762\u4e34\u7cfb\u7edf\u590d\u6742\u6027\u589e\u52a0\u3001\u591a\u4f9b\u5e94\u5546\u96c6\u6210\u548c\u4e13\u5bb6\u64cd\u4f5c\u5458\u77ed\u7f3a\u7b49\u6311\u6218\u3002\u73b0\u6709\u7684RPA\u81ea\u52a8\u5316\u65b9\u6848\u7075\u6d3b\u6027\u6709\u9650\u4e14\u7ef4\u62a4\u6210\u672c\u9ad8\uff0c\u800c\u901a\u7528LLM-based GUI\u4ee3\u7406\u5728\u5de5\u4e1a\u7ba1\u7406\u73af\u5883\u4e2d\u9762\u4e34\u5143\u7d20\u7406\u89e3\u3001\u7cbe\u5ea6\u6548\u7387\u3001\u72b6\u6001\u5b9a\u4f4d\u3001\u90e8\u7f72\u7ea6\u675f\u548c\u5b89\u5168\u8981\u6c42\u7b49\u4e94\u5927\u5173\u952e\u6311\u6218\u3002", "method": "\u63d0\u51faInfraMind\u6846\u67b6\uff0c\u5305\u542b\u4e94\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a(1)\u57fa\u4e8e\u7cfb\u7edf\u641c\u7d22\u63a2\u7d22\u548c\u865a\u62df\u673a\u5feb\u7167\u7684\u81ea\u4e3bGUI\u7406\u89e3\uff1b(2)\u5185\u5b58\u9a71\u52a8\u89c4\u5212\u786e\u4fdd\u9ad8\u7cbe\u5ea6\u9ad8\u6548\u4efb\u52a1\u6267\u884c\uff1b(3)\u9ad8\u7ea7\u72b6\u6001\u8bc6\u522b\u7528\u4e8e\u5206\u5c42\u754c\u9762\u7684\u9c81\u68d2\u5b9a\u4f4d\uff1b(4)\u7ed3\u6784\u5316\u77e5\u8bc6\u84b8\u998f\u5b9e\u73b0\u8f7b\u91cf\u7ea7\u6a21\u578b\u9ad8\u6548\u90e8\u7f72\uff1b(5)\u591a\u5c42\u5b89\u5168\u673a\u5236\u4fdd\u62a4\u654f\u611f\u64cd\u4f5c\u3002", "result": "\u5728\u5f00\u6e90\u548c\u5546\u4e1aDCIM\u5e73\u53f0\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4efb\u52a1\u6210\u529f\u7387\u548c\u64cd\u4f5c\u6548\u7387\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u6846\u67b6\u3002", "conclusion": "InfraMind\u4e3a\u5de5\u4e1a\u7ba1\u7406\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e25\u8c28\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5de5\u4e1a\u73af\u5883\u4e2dGUI\u81ea\u52a8\u5316\u7684\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2509.13790", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13790", "abs": "https://arxiv.org/abs/2509.13790", "authors": ["Yangning Li", "Tingwei Lu", "Yinghui Li", "Yankai Chen", "Wei-Chieh Huang", "Wenhao Jiang", "Hui Wang", "Hai-Tao Zheng", "Philip S. Yu"], "title": "Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning", "comment": "EMNLP 2025 Findings", "summary": "Efficient instruction tuning aims to enhance the ultimate performance of\nlarge language models (LLMs) trained on a given instruction dataset. Curriculum\nlearning as a typical data organization strategy has shown preliminary\neffectiveness in instruction tuning. However, current curriculum tuning methods\nsuffer from the curriculum rigidity, since they rely solely on static heuristic\ndifficulty metrics. These methods fail to adapt to the evolving capabilities of\nmodels during training, resulting in a fixed and potentially sub-optimal\nlearning trajectory. To address the issue, Competence-Aware Multi-Perspective\ncUrriculum inStruction tuning framework termed CAMPUS is proposed. CAMPUS\noffers several advantages: (1) Dynamic selection for sub-curriculum. (2)\nCompetency-aware adjustment to the curriculum schedule. (3) Multiple\ndifficulty-based scheduling. Extensive experiments prove the superior\nperformance of CAMPUS, compared to other state-of-the-art baselines for\nefficient instruction tuning.", "AI": {"tldr": "CAMPUS\u662f\u4e00\u4e2a\u52a8\u6001\u591a\u89c6\u89d2\u8bfe\u7a0b\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u80fd\u529b\u611f\u77e5\u7684\u8bfe\u7a0b\u8c03\u5ea6\u548c\u52a8\u6001\u5b50\u8bfe\u7a0b\u9009\u62e9\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u8bfe\u7a0b\u5b66\u4e60\u4e2d\u57fa\u4e8e\u9759\u6001\u96be\u5ea6\u6307\u6807\u7684\u521a\u6027\u8bfe\u7a0b\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6307\u4ee4\u8c03\u4f18\u7684\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u542f\u53d1\u5f0f\u96be\u5ea6\u6307\u6807\uff0c\u65e0\u6cd5\u9002\u5e94\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4e0d\u65ad\u6f14\u8fdb\u7684\u80fd\u529b\uff0c\u5bfc\u81f4\u56fa\u5b9a\u7684\u3001\u53ef\u80fd\u6b21\u4f18\u7684\u5b66\u4e60\u8f68\u8ff9\u3002", "method": "\u63d0\u51faCAMPUS\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u4f18\u52bf\uff1a\u52a8\u6001\u5b50\u8bfe\u7a0b\u9009\u62e9\u3001\u80fd\u529b\u611f\u77e5\u7684\u8bfe\u7a0b\u8c03\u5ea6\u8c03\u6574\u3001\u591a\u96be\u5ea6\u57fa\u7840\u8c03\u5ea6\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660eCAMPUS\u5728\u9ad8\u6548\u6307\u4ee4\u8c03\u4f18\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "CAMPUS\u901a\u8fc7\u52a8\u6001\u9002\u5e94\u6a21\u578b\u80fd\u529b\u6f14\u8fdb\u7684\u591a\u89c6\u89d2\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6307\u4ee4\u8c03\u4f18\u7684\u6700\u7ec8\u6027\u80fd\u3002"}}
{"id": "2509.13761", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13761", "abs": "https://arxiv.org/abs/2509.13761", "authors": ["Qikai Chang", "Zhenrong Zhang", "Pengfei Hu", "Jiefeng Ma", "Yicheng Pan", "Jianshu Zhang", "Jun Du", "Quan Liu", "Jianqing Gao"], "title": "THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning", "comment": "22 pages, 13 figures", "summary": "Large Language Models (LLMs) have made remarkable progress in mathematical\nreasoning, but still continue to struggle with high-precision tasks like\nnumerical computation and formal symbolic manipulation. Integrating external\ntools has emerged as a promising approach to bridge this gap. Despite recent\nadvances, existing methods struggle with three key challenges: constructing\ntool-integrated reasoning data, performing fine-grained optimization, and\nenhancing inference. To overcome these limitations, we propose THOR\n(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,\na multi-agent actor-critic-based pipeline for constructing high-quality\ndatasets of tool-integrated reasoning paths, aligning with the policy and\ngeneralizing well across diverse models. Second, to perform fine-grained\nhierarchical optimization, we introduce an RL strategy that jointly optimizes\nfor both trajectory-level problem solving and step-level code generation. This\nis motivated by our key insight that the success of an intermediate tool call\nis a strong predictor of the final answer's correctness. Finally, THOR\nincorporates a self-correction mechanism that leverages immediate tool feedback\nto dynamically revise erroneous reasoning paths during inference. Our approach\ndemonstrates strong generalization across diverse models, performing\neffectively in both reasoning and non-reasoning models. It further achieves\nstate-of-the-art performance for models of a similar scale on multiple\nmathematical benchmarks, while also delivering consistent improvements on code\nbenchmarks. Our code will be publicly available at\nhttps://github.com/JingMog/THOR.", "AI": {"tldr": "THOR\u662f\u4e00\u4e2a\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u5de5\u5177\u96c6\u6210\u5c42\u6b21\u4f18\u5316\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347LLM\u5728\u6570\u5b66\u63a8\u7406\u548c\u8ba1\u7b97\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u6570\u636e\u751f\u6210\u3001\u5206\u5c42\u4f18\u5316\u548c\u81ea\u6821\u6b63\u673a\u5236\u5b9e\u73b0\u6700\u5148\u8fdb\u6548\u679c", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u9ad8\u7cbe\u5ea6\u4efb\u52a1\u5982\u6570\u503c\u8ba1\u7b97\u548c\u7b26\u53f7\u64cd\u4f5c\u65b9\u9762\u4ecd\u5b58\u5728\u56f0\u96be\u3002\u73b0\u6709\u5de5\u5177\u96c6\u6210\u65b9\u6cd5\u9762\u4e34\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff1a\u6784\u5efa\u5de5\u5177\u96c6\u6210\u63a8\u7406\u6570\u636e\u3001\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4f18\u5316\u4ee5\u53ca\u589e\u5f3a\u63a8\u7406\u80fd\u529b", "method": "\u63d0\u51faTHOR\u6846\u67b6\uff1a1) TIRGen\u591a\u667a\u80fd\u4f53actor-critic\u7ba1\u9053\u6784\u5efa\u9ad8\u8d28\u91cf\u5de5\u5177\u96c6\u6210\u63a8\u7406\u6570\u636e\u96c6\uff1b2) \u5206\u5c42RL\u7b56\u7565\u8054\u5408\u4f18\u5316\u8f68\u8ff9\u7ea7\u95ee\u9898\u89e3\u51b3\u548c\u6b65\u9aa4\u7ea7\u4ee3\u7801\u751f\u6210\uff1b3) \u81ea\u6821\u6b63\u673a\u5236\u5229\u7528\u5de5\u5177\u53cd\u9988\u52a8\u6001\u4fee\u6b63\u63a8\u7406\u8def\u5f84", "result": "\u65b9\u6cd5\u5728\u591a\u6837\u5316\u6a21\u578b\u4e0a\u8868\u73b0\u51fa\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fbe\u5230\u540c\u89c4\u6a21\u6a21\u578b\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u4ee3\u7801\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u4e5f\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb", "conclusion": "THOR\u901a\u8fc7\u521b\u65b0\u7684\u5de5\u5177\u96c6\u6210\u548c\u5206\u5c42\u4f18\u5316\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u9ad8\u7cbe\u5ea6\u6570\u5b66\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5de5\u5177\u589e\u5f3a\u7684\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.13803", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13803", "abs": "https://arxiv.org/abs/2509.13803", "authors": ["Laura Garc\u00eda-Sardi\u00f1a", "Hermenegildo Fabregat", "Daniel Deniz", "Rabih Zbib"], "title": "Measuring Gender Bias in Job Title Matching for Grammatical Gender Languages", "comment": null, "summary": "This work sets the ground for studying how explicit grammatical gender\nassignment in job titles can affect the results of automatic job ranking\nsystems. We propose the usage of metrics for ranking comparison controlling for\ngender to evaluate gender bias in job title ranking systems, in particular RBO\n(Rank-Biased Overlap). We generate and share test sets for a job title matching\ntask in four grammatical gender languages, including occupations in masculine\nand feminine form and annotated by gender and matching relevance. We use the\nnew test sets and the proposed methodology to evaluate the gender bias of\nseveral out-of-the-box multilingual models to set as baselines, showing that\nall of them exhibit varying degrees of gender bias.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8bed\u6cd5\u6027\u522b\u5bf9\u81ea\u52a8\u804c\u4f4d\u6392\u540d\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8eRBO\u7684\u6027\u522b\u504f\u89c1\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u5728\u56db\u79cd\u8bed\u6cd5\u6027\u522b\u8bed\u8a00\u4e2d\u521b\u5efa\u4e86\u6d4b\u8bd5\u96c6\uff0c\u53d1\u73b0\u73b0\u6709\u591a\u8bed\u8a00\u6a21\u578b\u90fd\u5b58\u5728\u4e0d\u540c\u7a0b\u5ea6\u7684\u6027\u522b\u504f\u89c1\u3002", "motivation": "\u7814\u7a76\u8bed\u6cd5\u6027\u522b\u5728\u804c\u4f4d\u540d\u79f0\u4e2d\u7684\u663e\u5f0f\u5206\u914d\u5982\u4f55\u5f71\u54cd\u81ea\u52a8\u804c\u4f4d\u6392\u540d\u7cfb\u7edf\u7684\u7ed3\u679c\uff0c\u8bc4\u4f30\u73b0\u6709\u7cfb\u7edf\u5728\u6027\u522b\u504f\u89c1\u65b9\u9762\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4f7f\u7528RBO\uff08Rank-Biased Overlap\uff09\u6307\u6807\u6765\u8bc4\u4f30\u804c\u4f4d\u6392\u540d\u7cfb\u7edf\u4e2d\u7684\u6027\u522b\u504f\u89c1\uff0c\u5728\u56db\u79cd\u8bed\u6cd5\u6027\u522b\u8bed\u8a00\u4e2d\u751f\u6210\u5305\u542b\u7537\u6027\u548c\u5973\u6027\u5f62\u5f0f\u7684\u804c\u4f4d\u540d\u79f0\u6d4b\u8bd5\u96c6\uff0c\u5e76\u8bc4\u4f30\u591a\u4e2a\u73b0\u6210\u7684\u591a\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u6240\u6709\u6d4b\u8bd5\u7684\u591a\u8bed\u8a00\u6a21\u578b\u90fd\u8868\u73b0\u51fa\u4e0d\u540c\u7a0b\u5ea6\u7684\u6027\u522b\u504f\u89c1\uff0c\u8bc1\u660e\u4e86\u73b0\u6709\u7cfb\u7edf\u5728\u6027\u522b\u5e73\u7b49\u65b9\u9762\u5b58\u5728\u95ee\u9898\u3002", "conclusion": "\u9700\u8981\u5f00\u53d1\u66f4\u516c\u5e73\u7684\u804c\u4f4d\u6392\u540d\u7cfb\u7edf\uff0c\u672c\u6587\u63d0\u51fa\u7684\u8bc4\u4f30\u65b9\u6cd5\u548c\u6d4b\u8bd5\u96c6\u4e3a\u7814\u7a76\u8bed\u6cd5\u6027\u522b\u504f\u89c1\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u3002"}}
{"id": "2509.13773", "categories": ["cs.AI", "cs.IR", "I.2.7; I.2.10"], "pdf": "https://arxiv.org/pdf/2509.13773", "abs": "https://arxiv.org/abs/2509.13773", "authors": ["Zhipeng Bian", "Jieming Zhu", "Xuyang Xie", "Quanyu Dai", "Zhou Zhao", "Zhenhua Dong"], "title": "MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation", "comment": "Published in Proceedings of the 63rd Annual Meeting of the\n  Association for Computational Linguistics (Volume 6: Industry Track), ACL\n  2025. Official version: https://doi.org/10.18653/v1/2025.acl-industry.103", "summary": "The rapid advancement of generative AI technologies is driving the\nintegration of diverse AI-powered services into smartphones, transforming how\nusers interact with their devices. To simplify access to predefined AI\nservices, this paper introduces MIRA, a pioneering framework for task\ninstruction recommendation that enables intuitive one-touch AI tasking on\nsmartphones. With MIRA, users can long-press on images or text objects to\nreceive contextually relevant instruction recommendations for executing AI\ntasks. Our work introduces three key innovations: 1) A multimodal large\nlanguage model (MLLM)-based recommendation pipeline with structured reasoning\nto extract key entities, infer user intent, and generate precise instructions;\n2) A template-augmented reasoning mechanism that integrates high-level\nreasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based\nconstrained decoding strategy that restricts outputs to predefined instruction\ncandidates, ensuring coherent and intent-aligned suggestions. Through\nevaluation using a real-world annotated datasets and a user study, MIRA has\ndemonstrated substantial improvements in the accuracy of instruction\nrecommendation. The encouraging results highlight MIRA's potential to\nrevolutionize the way users engage with AI services on their smartphones,\noffering a more seamless and efficient experience.", "AI": {"tldr": "MIRA\u662f\u4e00\u4e2a\u667a\u80fd\u624b\u673aAI\u4efb\u52a1\u6307\u4ee4\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u957f\u6309\u56fe\u50cf\u6216\u6587\u672c\u6765\u63d0\u4f9b\u4e0a\u4e0b\u6587\u76f8\u5173\u7684AI\u4efb\u52a1\u5efa\u8bae\uff0c\u4f7f\u7528MLLM\u548c\u7ed3\u6784\u5316\u63a8\u7406\u6765\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u667a\u80fd\u624b\u673a\u9700\u8981\u66f4\u76f4\u89c2\u7684\u65b9\u5f0f\u6765\u8bbf\u95ee\u9884\u5b9a\u4e49\u7684AI\u670d\u52a1\uff0c\u7b80\u5316\u7528\u6237\u4e0e\u8bbe\u5907\u7684\u4ea4\u4e92\u3002", "method": "\u91c7\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u8350\u7ba1\u9053\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u63a8\u7406\u63d0\u53d6\u5173\u952e\u5b9e\u4f53\u548c\u63a8\u65ad\u7528\u6237\u610f\u56fe\uff1b\u4f7f\u7528\u6a21\u677f\u589e\u5f3a\u63a8\u7406\u673a\u5236\u63d0\u9ad8\u4efb\u52a1\u63a8\u65ad\u51c6\u786e\u6027\uff1b\u57fa\u4e8e\u524d\u7f00\u6811\u7684\u7ea6\u675f\u89e3\u7801\u7b56\u7565\u786e\u4fdd\u8f93\u51fa\u4e0e\u9884\u5b9a\u4e49\u6307\u4ee4\u4e00\u81f4\u3002", "result": "\u901a\u8fc7\u771f\u5b9e\u4e16\u754c\u6807\u6ce8\u6570\u636e\u96c6\u548c\u7528\u6237\u7814\u7a76\u8bc4\u4f30\uff0cMIRA\u5728\u6307\u4ee4\u63a8\u8350\u51c6\u786e\u6027\u65b9\u9762\u663e\u793a\u51fa\u663e\u8457\u63d0\u5347\u3002", "conclusion": "MIRA\u6709\u6f5c\u529b\u5f7b\u5e95\u6539\u53d8\u7528\u6237\u5728\u667a\u80fd\u624b\u673a\u4e0a\u4e0eAI\u670d\u52a1\u7684\u4ea4\u4e92\u65b9\u5f0f\uff0c\u63d0\u4f9b\u66f4\u65e0\u7f1d\u548c\u9ad8\u6548\u7684\u4f53\u9a8c\u3002"}}
{"id": "2509.13813", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13813", "abs": "https://arxiv.org/abs/2509.13813", "authors": ["Edward Phillips", "Sean Wu", "Soheila Molaei", "Danielle Belgrave", "Anshul Thakur", "David Clifton"], "title": "Geometric Uncertainty for Detecting and Correcting Hallucinations in LLMs", "comment": null, "summary": "Large language models demonstrate impressive results across diverse tasks but\nare still known to hallucinate, generating linguistically plausible but\nincorrect answers to questions. Uncertainty quantification has been proposed as\na strategy for hallucination detection, but no existing black-box approach\nprovides estimates for both global and local uncertainty. The former attributes\nuncertainty to a batch of responses, while the latter attributes uncertainty to\nindividual responses. Current local methods typically rely on white-box access\nto internal model states, whilst black-box methods only provide global\nuncertainty estimates. We introduce a geometric framework to address this,\nbased on archetypal analysis of batches of responses sampled with only\nblack-box model access. At the global level, we propose Geometric Volume, which\nmeasures the convex hull volume of archetypes derived from response embeddings.\nAt the local level, we propose Geometric Suspicion, which ranks responses by\nreliability and enables hallucination reduction through preferential response\nselection. Unlike prior dispersion methods which yield only a single global\nscore, our approach provides semantic boundary points which have utility for\nattributing reliability to individual responses. Experiments show that our\nframework performs comparably to or better than prior methods on short form\nquestion-answering datasets, and achieves superior results on medical datasets\nwhere hallucinations carry particularly critical risks. We also provide\ntheoretical justification by proving a link between convex hull volume and\nentropy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u51e0\u4f55\u6846\u67b6\u7684\u9ed1\u76d2\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u539f\u578b\u5206\u6790\u540c\u65f6\u63d0\u4f9b\u5168\u5c40\u548c\u5c40\u90e8\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u7528\u4e8e\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u9ed1\u76d2\u65b9\u6cd5\u53ea\u80fd\u63d0\u4f9b\u5168\u5c40\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u800c\u5c40\u90e8\u65b9\u6cd5\u9700\u8981\u767d\u76d2\u8bbf\u95ee\u6a21\u578b\u5185\u90e8\u72b6\u6001\u3002\u9700\u8981\u4e00\u79cd\u4ec5\u901a\u8fc7\u9ed1\u76d2\u8bbf\u95ee\u5c31\u80fd\u540c\u65f6\u63d0\u4f9b\u5168\u5c40\u548c\u5c40\u90e8\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u3002", "method": "\u57fa\u4e8e\u54cd\u5e94\u5d4c\u5165\u7684\u539f\u578b\u5206\u6790\u51e0\u4f55\u6846\u67b6\u3002\u5168\u5c40\u5c42\u9762\u4f7f\u7528\u51e0\u4f55\u4f53\u79ef\u6d4b\u91cf\u539f\u578b\u51f8\u5305\u4f53\u79ef\uff0c\u5c40\u90e8\u5c42\u9762\u4f7f\u7528\u51e0\u4f55\u6000\u7591\u5ea6\u5bf9\u54cd\u5e94\u53ef\u9760\u6027\u8fdb\u884c\u6392\u5e8f\uff0c\u901a\u8fc7\u4f18\u5148\u9009\u62e9\u54cd\u5e94\u6765\u51cf\u5c11\u5e7b\u89c9\u3002", "result": "\u5728\u77ed\u5f62\u5f0f\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u6216\u76f8\u5f53\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u533b\u7597\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u66f4\u4f18\u7ed3\u679c\uff08\u5e7b\u89c9\u98ce\u9669\u7279\u522b\u5173\u952e\u7684\u9886\u57df\uff09\u3002\u7406\u8bba\u8bc1\u660e\u4e86\u51f8\u5305\u4f53\u79ef\u4e0e\u71b5\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "conclusion": "\u8be5\u51e0\u4f55\u6846\u67b6\u4e3a\u9ed1\u76d2\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u540c\u65f6\u5904\u7406\u5168\u5c40\u548c\u5c40\u90e8\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u5173\u952e\u5e94\u7528\u9886\u57df\u5982\u533b\u7597\u95ee\u7b54\u4e2d\u7279\u522b\u6709\u4ef7\u503c\u3002"}}
{"id": "2509.13880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13880", "abs": "https://arxiv.org/abs/2509.13880", "authors": ["Mingwei Zhang", "Zhenhao Gu", "Liangda Fang", "Cunjing Ge", "Ziliang Chen", "Zhao-Rong Lai", "Quanlong Guan"], "title": "An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques", "comment": null, "summary": "Linear constraints are one of the most fundamental constraints in fields such\nas computer science, operations research and optimization. Many applications\nreduce to the task of model counting over integer linear constraints (MCILC).\nIn this paper, we design an exact approach to MCILC based on an exhaustive DPLL\narchitecture. To improve the efficiency, we integrate several effective\nsimplification techniques from mixed integer programming into the architecture.\nWe compare our approach to state-of-the-art MCILC counters and propositional\nmodel counters on 2840 random and 4131 application benchmarks. Experimental\nresults show that our approach significantly outperforms all exact methods in\nrandom benchmarks solving 1718 instances while the state-of-the-art approach\nonly computes 1470 instances. In addition, our approach is the only approach to\nsolve all 4131 application instances.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eDPLL\u67b6\u6784\u7684\u7cbe\u786e\u65b9\u6cd5\u6765\u89e3\u51b3\u6574\u6570\u7ebf\u6027\u7ea6\u675f\u7684\u6a21\u578b\u8ba1\u6570\u95ee\u9898(MCILC)\uff0c\u901a\u8fc7\u6574\u5408\u6df7\u5408\u6574\u6570\u89c4\u5212\u4e2d\u7684\u7b80\u5316\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u3002", "motivation": "\u6574\u6570\u7ebf\u6027\u7ea6\u675f\u662f\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u8fd0\u7b79\u5b66\u548c\u4f18\u5316\u9886\u57df\u4e2d\u6700\u57fa\u672c\u7684\u7ea6\u675f\u4e4b\u4e00\uff0c\u8bb8\u591a\u5e94\u7528\u90fd\u5f52\u7ed3\u4e3aMCILC\u4efb\u52a1\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u8fd9\u7c7b\u95ee\u9898\u65f6\u6548\u7387\u6709\u9650\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u7a77\u4e3eDPLL\u67b6\u6784\u7684\u7cbe\u786e\u65b9\u6cd5\uff0c\u6574\u5408\u4e86\u6df7\u5408\u6574\u6570\u89c4\u5212\u4e2d\u7684\u591a\u79cd\u6709\u6548\u7b80\u5316\u6280\u672f\u6765\u63d0\u5347\u6548\u7387\u3002", "result": "\u57282840\u4e2a\u968f\u673a\u57fa\u51c6\u6d4b\u8bd5\u548c4131\u4e2a\u5e94\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e861718\u4e2a\u968f\u673a\u5b9e\u4f8b\uff08\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u76841470\u4e2a\uff09\uff0c\u5e76\u4e14\u662f\u552f\u4e00\u80fd\u591f\u89e3\u51b3\u6240\u67094131\u4e2a\u5e94\u7528\u5b9e\u4f8b\u7684\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8eDPLL\u67b6\u6784\u5e76\u6574\u5408\u6df7\u5408\u6574\u6570\u89c4\u5212\u7b80\u5316\u6280\u672f\u7684\u65b9\u6cd5\uff0c\u5728MCILC\u95ee\u9898\u4e0a\u663e\u8457\u4f18\u4e8e\u6240\u6709\u73b0\u6709\u7cbe\u786e\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5e94\u7528\u5b9e\u4f8b\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2509.13814", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13814", "abs": "https://arxiv.org/abs/2509.13814", "authors": ["Kartik Shinde", "Laurent Besacier", "Ondrej Bojar", "Thibaut Thonet", "Tirthankar Ghosal"], "title": "Findings of the Third Automatic Minuting (AutoMin) Challenge", "comment": "Automin 2025 Website: https://ufal.github.io/automin-2025/", "summary": "This paper presents the third edition of AutoMin, a shared task on automatic\nmeeting summarization into minutes. In 2025, AutoMin featured the main task of\nminuting, the creation of structured meeting minutes, as well as a new task:\nquestion answering (QA) based on meeting transcripts.\n  The minuting task covered two languages, English and Czech, and two domains:\nproject meetings and European Parliament sessions. The QA task focused solely\non project meetings and was available in two settings: monolingual QA in\nEnglish, and cross-lingual QA, where questions were asked and answered in Czech\nbased on English meetings.\n  Participation in 2025 was more limited compared to previous years, with only\none team joining the minuting task and two teams participating in QA. However,\nas organizers, we included multiple baseline systems to enable a comprehensive\nevaluation of current (2025) large language models (LLMs) on both tasks.", "AI": {"tldr": "AutoMin 2025\u5171\u4eab\u4efb\u52a1\u5305\u62ec\u4f1a\u8bae\u7eaa\u8981\u751f\u6210\u548c\u95ee\u7b54\u4e24\u4e2a\u4efb\u52a1\uff0c\u6db5\u76d6\u82f1\u8bed\u548c\u6377\u514b\u8bed\uff0c\u53c2\u4e0e\u56e2\u961f\u8f83\u5c11\u4f46\u5305\u542b\u591a\u4e2a\u57fa\u7ebf\u7cfb\u7edf\u8bc4\u4f30\u3002", "motivation": "\u63a8\u52a8\u81ea\u52a8\u4f1a\u8bae\u7eaa\u8981\u6280\u672f\u53d1\u5c55\uff0c\u8bc4\u4f30\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7ed3\u6784\u5316\u4f1a\u8bae\u7eaa\u8981\u751f\u6210\u548c\u8de8\u8bed\u8a00\u95ee\u7b54\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u7ec4\u7ec7\u5171\u4eab\u4efb\u52a1\uff0c\u8bbe\u7f6e\u4e24\u4e2a\u4e3b\u8981\u4efb\u52a1\uff1aminuting\uff08\u7ed3\u6784\u5316\u4f1a\u8bae\u7eaa\u8981\u751f\u6210\uff09\u548cquestion answering\uff08\u95ee\u7b54\uff09\uff0c\u6db5\u76d6\u82f1\u8bed\u548c\u6377\u514b\u8bed\u53cc\u8bed\u5904\u7406\uff0c\u5e76\u5efa\u7acb\u57fa\u7ebf\u7cfb\u7edf\u8fdb\u884c\u6bd4\u8f83\u8bc4\u4f30\u3002", "result": "2025\u5e74\u53c2\u4e0e\u5ea6\u8f83\u4f4e\uff08\u7eaa\u8981\u4efb\u52a11\u4e2a\u56e2\u961f\uff0c\u95ee\u7b54\u4efb\u52a12\u4e2a\u56e2\u961f\uff09\uff0c\u4f46\u901a\u8fc7\u7ec4\u7ec7\u65b9\u63d0\u4f9b\u7684\u591a\u4e2a\u57fa\u7ebf\u7cfb\u7edf\uff0c\u6210\u529f\u8bc4\u4f30\u4e86\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fd9\u4e24\u4e2a\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "\u5c3d\u7ba1\u53c2\u4e0e\u56e2\u961f\u6709\u9650\uff0c\u4f46AutoMin 2025\u4e3a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f1a\u8bae\u7eaa\u8981\u751f\u6210\u548c\u8de8\u8bed\u8a00\u95ee\u7b54\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u57fa\u51c6\u548c\u6bd4\u8f83\u6846\u67b6\u3002"}}
{"id": "2509.13968", "categories": ["cs.AI", "cs.CL", "cs.FL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13968", "abs": "https://arxiv.org/abs/2509.13968", "authors": ["Konstantinos Voudouris", "Andrew Barron", "Marta Halina", "Colin Klein", "Matishalin Patel"], "title": "Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks", "comment": null, "summary": "Transitional accounts of evolution emphasise a few changes that shape what is\nevolvable, with dramatic consequences for derived lineages. More recently it\nhas been proposed that cognition might also have evolved via a series of major\ntransitions that manipulate the structure of biological neural networks,\nfundamentally changing the flow of information. We used idealised models of\ninformation flow, artificial neural networks (ANNs), to evaluate whether\nchanges in information flow in a network can yield a transitional change in\ncognitive performance. We compared networks with feed-forward, recurrent and\nlaminated topologies, and tested their performance learning artificial grammars\nthat differed in complexity, controlling for network size and resources. We\ndocumented a qualitative expansion in the types of input that recurrent\nnetworks can process compared to feed-forward networks, and a related\nqualitative increase in performance for learning the most complex grammars. We\nalso noted how the difficulty in training recurrent networks poses a form of\ntransition barrier and contingent irreversibility -- other key features of\nevolutionary transitions. Not all changes in network topology confer a\nperformance advantage in this task set. Laminated networks did not outperform\nnon-laminated networks in grammar learning. Overall, our findings show how some\nchanges in information flow can yield transitions in cognitive performance.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u9a8c\u8bc1\u4fe1\u606f\u6d41\u7ed3\u6784\u53d8\u5316\u80fd\u5426\u5e26\u6765\u8ba4\u77e5\u6027\u80fd\u7684\u8dc3\u8fc1\u5f0f\u63d0\u5347\uff0c\u53d1\u73b0\u5faa\u73af\u7f51\u7edc\u76f8\u6bd4\u524d\u9988\u7f51\u7edc\u5728\u5904\u7406\u590d\u6742\u8bed\u6cd5\u65f6\u8868\u73b0\u51fa\u8d28\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u89c2\u5bdf\u5230\u8bad\u7ec3\u96be\u5ea6\u5f62\u6210\u7684\u8fc7\u6e21\u969c\u788d\u3002", "motivation": "\u63a2\u8ba8\u8ba4\u77e5\u8fdb\u5316\u662f\u5426\u901a\u8fc7\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u4fe1\u606f\u6d41\u7ed3\u6784\u7684\u4e3b\u8981\u8f6c\u53d8\u6765\u5b9e\u73b0\uff0c\u9a8c\u8bc1\u7f51\u7edc\u62d3\u6251\u53d8\u5316\u662f\u5426\u80fd\u4ea7\u751f\u8ba4\u77e5\u6027\u80fd\u7684\u8fc7\u6e21\u6027\u53d8\u5316\u3002", "method": "\u4f7f\u7528\u7406\u60f3\u5316\u4fe1\u606f\u6d41\u6a21\u578b\u548c\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\uff0c\u6bd4\u8f83\u524d\u9988\u3001\u5faa\u73af\u548c\u5206\u5c42\u62d3\u6251\u7f51\u7edc\u5728\u5b66\u4e60\u4e0d\u540c\u590d\u6742\u5ea6\u4eba\u5de5\u8bed\u6cd5\u65f6\u7684\u6027\u80fd\uff0c\u63a7\u5236\u7f51\u7edc\u89c4\u6a21\u548c\u8d44\u6e90\u3002", "result": "\u5faa\u73af\u7f51\u7edc\u76f8\u6bd4\u524d\u9988\u7f51\u7edc\u5728\u5904\u7406\u8f93\u5165\u7c7b\u578b\u4e0a\u6709\u8d28\u7684\u6269\u5c55\uff0c\u5728\u6700\u590d\u6742\u8bed\u6cd5\u5b66\u4e60\u4e0a\u8868\u73b0\u51fa\u8d28\u7684\u6027\u80fd\u63d0\u5347\uff1b\u5faa\u73af\u7f51\u7edc\u8bad\u7ec3\u96be\u5ea6\u6784\u6210\u8fc7\u6e21\u969c\u788d\u548c\u4e0d\u53ef\u9006\u6027\uff1b\u5206\u5c42\u7f51\u7edc\u5728\u8bed\u6cd5\u5b66\u4e60\u4e0a\u672a\u8868\u73b0\u51fa\u4f18\u52bf\u3002", "conclusion": "\u67d0\u4e9b\u4fe1\u606f\u6d41\u7ed3\u6784\u53d8\u5316\u786e\u5b9e\u80fd\u5e26\u6765\u8ba4\u77e5\u6027\u80fd\u7684\u8fc7\u6e21\u6027\u8f6c\u53d8\uff0c\u652f\u6301\u8ba4\u77e5\u8fdb\u5316\u53ef\u80fd\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u4fe1\u606f\u6d41\u7684\u4e3b\u8981\u8f6c\u53d8\u6765\u5b9e\u73b0\u7684\u5047\u8bbe\u3002"}}
{"id": "2509.13835", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13835", "abs": "https://arxiv.org/abs/2509.13835", "authors": ["Minh Duc Bui", "Carolin Holtermann", "Valentin Hofmann", "Anne Lauscher", "Katharina von der Wense"], "title": "Large Language Models Discriminate Against Speakers of German Dialects", "comment": "Accepted to EMNLP 2025 Main", "summary": "Dialects represent a significant component of human culture and are found\nacross all regions of the world. In Germany, more than 40% of the population\nspeaks a regional dialect (Adler and Hansen, 2022). However, despite cultural\nimportance, individuals speaking dialects often face negative societal\nstereotypes. We examine whether such stereotypes are mirrored by large language\nmodels (LLMs). We draw on the sociolinguistic literature on dialect perception\nto analyze traits commonly associated with dialect speakers. Based on these\ntraits, we assess the dialect naming bias and dialect usage bias expressed by\nLLMs in two tasks: an association task and a decision task. To assess a model's\ndialect usage bias, we construct a novel evaluation corpus that pairs sentences\nfrom seven regional German dialects (e.g., Alemannic and Bavarian) with their\nstandard German counterparts. We find that: (1) in the association task, all\nevaluated LLMs exhibit significant dialect naming and dialect usage bias\nagainst German dialect speakers, reflected in negative adjective associations;\n(2) all models reproduce these dialect naming and dialect usage biases in their\ndecision making; and (3) contrary to prior work showing minimal bias with\nexplicit demographic mentions, we find that explicitly labeling linguistic\ndemographics--German dialect speakers--amplifies bias more than implicit cues\nlike dialect usage.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u5fb7\u56fd\u65b9\u8a00\u4f7f\u7528\u8005\u5b58\u5728\u663e\u8457\u7684\u547d\u540d\u504f\u89c1\u548c\u4f7f\u7528\u504f\u89c1\uff0c\u8868\u73b0\u4e3a\u8d1f\u9762\u5f62\u5bb9\u8bcd\u5173\u8054\uff0c\u4e14\u660e\u786e\u6807\u6ce8\u8bed\u8a00\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u4f1a\u653e\u5927\u8fd9\u79cd\u504f\u89c1\u3002", "motivation": "\u5c3d\u7ba1\u65b9\u8a00\u5177\u6709\u91cd\u8981\u6587\u5316\u4ef7\u503c\uff0c\u4f46\u65b9\u8a00\u4f7f\u7528\u8005\u5e38\u9762\u4e34\u8d1f\u9762\u793e\u4f1a\u523b\u677f\u5370\u8c61\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u8fd9\u79cd\u523b\u677f\u5370\u8c61\u662f\u5426\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5f97\u5230\u4f53\u73b0\u3002", "method": "\u57fa\u4e8e\u793e\u4f1a\u8bed\u8a00\u5b66\u6587\u732e\u6784\u5efa\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u5173\u8054\u4efb\u52a1\u548c\u51b3\u7b56\u4efb\u52a1\u5206\u6790\u65b9\u8a00\u547d\u540d\u504f\u89c1\u548c\u4f7f\u7528\u504f\u89c1\uff0c\u5e76\u521b\u5efa\u5305\u542b7\u79cd\u5fb7\u56fd\u5730\u533a\u65b9\u8a00\u4e0e\u6807\u51c6\u5fb7\u8bed\u5bf9\u7167\u7684\u65b0\u8bc4\u4f30\u8bed\u6599\u5e93\u3002", "result": "\u6240\u6709\u88ab\u8bc4\u4f30\u7684LLM\u90fd\u8868\u73b0\u51fa\u663e\u8457\u7684\u65b9\u8a00\u547d\u540d\u548c\u4f7f\u7528\u504f\u89c1\uff0c\u5728\u51b3\u7b56\u4e2d\u91cd\u73b0\u8fd9\u4e9b\u504f\u89c1\uff0c\u4e14\u660e\u786e\u6807\u6ce8\u8bed\u8a00\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u6bd4\u9690\u6666\u7684\u65b9\u8a00\u4f7f\u7528\u6697\u793a\u66f4\u80fd\u653e\u5927\u504f\u89c1\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u786e\u5b9e\u590d\u5236\u4e86\u5bf9\u5fb7\u56fd\u65b9\u8a00\u4f7f\u7528\u8005\u7684\u793e\u4f1a\u523b\u677f\u5370\u8c61\uff0c\u9700\u8981\u91c7\u53d6\u63aa\u65bd\u51cf\u8f7b\u8fd9\u79cd\u8bed\u8a00\u504f\u89c1\uff0c\u7279\u522b\u662f\u5728\u660e\u786e\u6807\u6ce8\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u65f6\u3002"}}
{"id": "2509.14030", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14030", "abs": "https://arxiv.org/abs/2509.14030", "authors": ["Maosheng Qin", "Renyu Zhu", "Mingxuan Xia", "Chenkai Chen", "Zhen Zhu", "Minmin Lin", "Junbo Zhao", "Lu Xu", "Changjie Fan", "Runze Wu", "Haobo Wang"], "title": "CrowdAgent: Multi-Agent Managed Multi-Source Annotation System", "comment": null, "summary": "High-quality annotated data is a cornerstone of modern Natural Language\nProcessing (NLP). While recent methods begin to leverage diverse annotation\nsources-including Large Language Models (LLMs), Small Language Models (SLMs),\nand human experts-they often focus narrowly on the labeling step itself. A\ncritical gap remains in the holistic process control required to manage these\nsources dynamically, addressing complex scheduling and quality-cost trade-offs\nin a unified manner. Inspired by real-world crowdsourcing companies, we\nintroduce CrowdAgent, a multi-agent system that provides end-to-end process\ncontrol by integrating task assignment, data annotation, and quality/cost\nmanagement. It implements a novel methodology that rationally assigns tasks,\nenabling LLMs, SLMs, and human experts to advance synergistically in a\ncollaborative annotation workflow. We demonstrate the effectiveness of\nCrowdAgent through extensive experiments on six diverse multimodal\nclassification tasks. The source code and video demo are available at\nhttps://github.com/QMMMS/CrowdAgent.", "AI": {"tldr": "CrowdAgent\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408\u4efb\u52a1\u5206\u914d\u3001\u6570\u636e\u6807\u6ce8\u548c\u8d28\u91cf/\u6210\u672c\u7ba1\u7406\uff0c\u4e3aLLM\u3001SLM\u548c\u4eba\u7c7b\u4e13\u5bb6\u63d0\u4f9b\u7aef\u5230\u7aef\u7684\u534f\u540c\u6807\u6ce8\u6d41\u7a0b\u63a7\u5236\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6807\u6ce8\u6b65\u9aa4\u672c\u8eab\uff0c\u7f3a\u4e4f\u5bf9\u591a\u6837\u5316\u6807\u6ce8\u6e90\uff08LLM\u3001SLM\u3001\u4eba\u7c7b\u4e13\u5bb6\uff09\u7684\u52a8\u6001\u7ba1\u7406\u548c\u590d\u6742\u8c03\u5ea6\u9700\u6c42\uff0c\u9700\u8981\u7edf\u4e00\u7684\u7aef\u5230\u7aef\u6d41\u7a0b\u63a7\u5236\u6765\u89e3\u51b3\u8d28\u91cf-\u6210\u672c\u6743\u8861\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u73b0\u5b9e\u4f17\u5305\u516c\u53f8\u542f\u53d1\uff0c\u5f00\u53d1\u591a\u667a\u80fd\u4f53\u7cfb\u7edfCrowdAgent\uff0c\u5b9e\u73b0\u4efb\u52a1\u5206\u914d\u3001\u6570\u636e\u6807\u6ce8\u3001\u8d28\u91cf/\u6210\u672c\u7ba1\u7406\u7684\u96c6\u6210\uff0c\u91c7\u7528\u65b0\u9896\u7684\u65b9\u6cd5\u8bba\u6765\u5408\u7406\u5206\u914d\u4efb\u52a1\uff0c\u4f7f\u4e0d\u540c\u6807\u6ce8\u6e90\u5728\u534f\u4f5c\u6807\u6ce8\u6d41\u7a0b\u4e2d\u534f\u540c\u5de5\u4f5c\u3002", "result": "\u5728\u516d\u4e2a\u591a\u6837\u5316\u591a\u6a21\u6001\u5206\u7c7b\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86CrowdAgent\u7684\u6709\u6548\u6027\u3002", "conclusion": "CrowdAgent\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u7ba1\u7406\u591a\u6837\u5316\u6807\u6ce8\u6e90\uff0c\u89e3\u51b3\u590d\u6742\u8c03\u5ea6\u548c\u8d28\u91cf-\u6210\u672c\u6743\u8861\u95ee\u9898\uff0c\u4e3a\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2509.13869", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13869", "abs": "https://arxiv.org/abs/2509.13869", "authors": ["Yang Liu", "Chenhui Chu"], "title": "Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs", "comment": "38 pages, 31 figures", "summary": "Large language models (LLMs) can lead to undesired consequences when\nmisaligned with human values, especially in scenarios involving complex and\nsensitive social biases. Previous studies have revealed the misalignment of\nLLMs with human values using expert-designed or agent-based emulated bias\nscenarios. However, it remains unclear whether the alignment of LLMs with human\nvalues differs across different types of scenarios (e.g., scenarios containing\nnegative vs. non-negative questions). In this study, we investigate the\nalignment of LLMs with human values regarding social biases (HVSB) in different\ntypes of bias scenarios. Through extensive analysis of 12 LLMs from four model\nfamilies and four datasets, we demonstrate that LLMs with large model parameter\nscales do not necessarily have lower misalignment rate and attack success rate.\nMoreover, LLMs show a certain degree of alignment preference for specific types\nof scenarios and the LLMs from the same model family tend to have higher\njudgment consistency. In addition, we study the understanding capacity of LLMs\nwith their explanations of HVSB. We find no significant differences in the\nunderstanding of HVSB across LLMs. We also find LLMs prefer their own generated\nexplanations. Additionally, we endow smaller language models (LMs) with the\nability to explain HVSB. The generation results show that the explanations\ngenerated by the fine-tuned smaller LMs are more readable, but have a\nrelatively lower model agreeability.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u7c7b\u578b\u504f\u89c1\u573a\u666f\u4e2d\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u5bf9\u9f50\u60c5\u51b5\uff0c\u53d1\u73b0\u5927\u53c2\u6570\u6a21\u578b\u4e0d\u4e00\u5b9a\u5177\u6709\u66f4\u597d\u7684\u5bf9\u9f50\u8868\u73b0\uff0c\u6a21\u578b\u5bf9\u7279\u5b9a\u573a\u666f\u7c7b\u578b\u6709\u504f\u597d\uff0c\u4e14\u540c\u4e00\u6a21\u578b\u5bb6\u65cf\u7684\u5224\u65ad\u4e00\u81f4\u6027\u66f4\u9ad8\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u56e0\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u4e0d\u5bf9\u9f50\u800c\u4ea7\u751f\u4e0d\u826f\u540e\u679c\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca\u590d\u6742\u654f\u611f\u793e\u4f1a\u504f\u89c1\u7684\u573a\u666f\u4e2d\u3002\u4e4b\u524d\u7684\u7814\u7a76\u4f7f\u7528\u4e13\u5bb6\u8bbe\u8ba1\u6216\u57fa\u4e8e\u4ee3\u7406\u7684\u504f\u89c1\u573a\u666f\u63ed\u793a\u4e86\u8fd9\u79cd\u4e0d\u5bf9\u9f50\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u4e0d\u540c\u7c7b\u578b\u573a\u666f\u4e0bLLMs\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u5bf9\u9f50\u662f\u5426\u5b58\u5728\u5dee\u5f02\u3002", "method": "\u901a\u8fc7\u5bf9\u6765\u81ea4\u4e2a\u6a21\u578b\u5bb6\u65cf\u768412\u4e2aLLMs\u548c4\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u5e7f\u6cdb\u5206\u6790\uff0c\u7814\u7a76LLMs\u5728\u4e0d\u540c\u7c7b\u578b\u504f\u89c1\u573a\u666f\u4e2d\u7684\u5bf9\u9f50\u60c5\u51b5\uff0c\u5e76\u8003\u5bdfLLMs\u5bf9HVSB\u7684\u7406\u89e3\u80fd\u529b\u53ca\u5176\u89e3\u91ca\u504f\u597d\u3002", "result": "\u5927\u53c2\u6570\u89c4\u6a21\u7684LLMs\u4e0d\u4e00\u5b9a\u5177\u6709\u66f4\u4f4e\u7684\u4e0d\u5bf9\u9f50\u7387\u548c\u653b\u51fb\u6210\u529f\u7387\uff1bLLMs\u5bf9\u7279\u5b9a\u7c7b\u578b\u7684\u573a\u666f\u8868\u73b0\u51fa\u4e00\u5b9a\u7a0b\u5ea6\u7684\u5bf9\u9f50\u504f\u597d\uff1b\u540c\u4e00\u6a21\u578b\u5bb6\u65cf\u7684LLMs\u503e\u5411\u4e8e\u5177\u6709\u66f4\u9ad8\u7684\u5224\u65ad\u4e00\u81f4\u6027\uff1bLLMs\u5bf9HVSB\u7684\u7406\u89e3\u6ca1\u6709\u663e\u8457\u5dee\u5f02\uff1bLLMs\u504f\u597d\u81ea\u5df1\u751f\u6210\u7684\u89e3\u91ca\uff1b\u7ecf\u8fc7\u5fae\u8c03\u7684\u5c0f\u578bLMs\u751f\u6210\u7684\u89e3\u91ca\u66f4\u6613\u8bfb\u4f46\u6a21\u578b\u8ba4\u540c\u5ea6\u8f83\u4f4e\u3002", "conclusion": "LLMs\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u5bf9\u9f50\u5b58\u5728\u573a\u666f\u7c7b\u578b\u4f9d\u8d56\u6027\uff0c\u6a21\u578b\u89c4\u6a21\u4e0d\u662f\u51b3\u5b9a\u5bf9\u9f50\u8d28\u91cf\u7684\u552f\u4e00\u56e0\u7d20\uff0c\u540c\u4e00\u6a21\u578b\u5bb6\u65cf\u7684\u5224\u65ad\u4e00\u81f4\u6027\u66f4\u9ad8\uff0c\u5c0f\u578bLMs\u7ecf\u8fc7\u5fae\u8c03\u53ef\u4ee5\u751f\u6210\u66f4\u6613\u8bfb\u7684\u89e3\u91ca\u4f46\u9700\u8981\u63d0\u9ad8\u6a21\u578b\u8ba4\u540c\u5ea6\u3002"}}
{"id": "2509.14195", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14195", "abs": "https://arxiv.org/abs/2509.14195", "authors": ["Shalima Binta Manir", "Tim Oates"], "title": "Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning", "comment": "8 pages, 3 figures", "summary": "Mental representation, characterized by structured internal models mirroring\nexternal environments, is fundamental to advanced cognition but remains\nchallenging to investigate empirically. Existing theory hypothesizes that\nsecond-order learning -- learning mechanisms that adapt first-order learning\n(i.e., learning about the task/domain) -- promotes the emergence of such\nenvironment-cognition isomorphism. In this paper, we empirically validate this\nhypothesis by proposing a hierarchical architecture comprising a Graph\nConvolutional Network (GCN) as a first-order learner and an MLP controller as a\nsecond-order learner. The GCN directly maps node-level features to predictions\nof optimal navigation paths, while the MLP dynamically adapts the GCN's\nparameters when confronting structurally novel maze environments. We\ndemonstrate that second-order learning is particularly effective when the\ncognitive system develops an internal mental map structurally isomorphic to the\nenvironment. Quantitative and qualitative results highlight significant\nperformance improvements and robust generalization on unseen maze tasks,\nproviding empirical support for the pivotal role of structured mental\nrepresentations in maximizing the effectiveness of second-order learning.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6784\u5efa\u5305\u542bGCN\u4f5c\u4e3a\u4e00\u9636\u5b66\u4e60\u5668\u548cMLP\u63a7\u5236\u5668\u4f5c\u4e3a\u4e8c\u9636\u5b66\u4e60\u5668\u7684\u5206\u5c42\u67b6\u6784\uff0c\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u4e8c\u9636\u5b66\u4e60\u80fd\u4fc3\u8fdb\u73af\u5883-\u8ba4\u77e5\u540c\u6784\u7684\u5fc3\u7406\u8868\u5f81\u51fa\u73b0\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u8ff7\u5bab\u5bfc\u822a\u4efb\u52a1\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5fc3\u7406\u8868\u5f81\uff08\u7ed3\u6784\u5316\u5185\u90e8\u6a21\u578b\u53cd\u6620\u5916\u90e8\u73af\u5883\uff09\u662f\u9ad8\u7ea7\u8ba4\u77e5\u7684\u57fa\u7840\uff0c\u4f46\u96be\u4ee5\u5b9e\u8bc1\u7814\u7a76\u3002\u73b0\u6709\u7406\u8bba\u5047\u8bbe\u4e8c\u9636\u5b66\u4e60\uff08\u8c03\u6574\u4e00\u9636\u5b66\u4e60\u673a\u5236\u7684\u5b66\u4e60\uff09\u80fd\u4fc3\u8fdb\u8fd9\u79cd\u73af\u5883-\u8ba4\u77e5\u540c\u6784\u6027\u7684\u51fa\u73b0\uff0c\u4f46\u7f3a\u4e4f\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u67b6\u6784\uff1a\u4f7f\u7528\u56fe\u5377\u79ef\u7f51\u7edc\uff08GCN\uff09\u4f5c\u4e3a\u4e00\u9636\u5b66\u4e60\u5668\u76f4\u63a5\u6620\u5c04\u8282\u70b9\u7279\u5f81\u5230\u6700\u4f18\u5bfc\u822a\u8def\u5f84\u9884\u6d4b\uff0c\u4f7f\u7528MLP\u63a7\u5236\u5668\u4f5c\u4e3a\u4e8c\u9636\u5b66\u4e60\u5668\u5728\u9047\u5230\u7ed3\u6784\u65b0\u9896\u7684\u8ff7\u5bab\u73af\u5883\u65f6\u52a8\u6001\u8c03\u6574GCN\u53c2\u6570\u3002", "result": "\u5b9a\u91cf\u548c\u5b9a\u6027\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u8ba4\u77e5\u7cfb\u7edf\u53d1\u5c55\u51fa\u4e0e\u73af\u5883\u7ed3\u6784\u540c\u6784\u7684\u5185\u90e8\u5fc3\u7406\u5730\u56fe\u65f6\uff0c\u4e8c\u9636\u5b66\u4e60\u7279\u522b\u6709\u6548\uff0c\u5728\u672a\u89c1\u8fc7\u7684\u8ff7\u5bab\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u548c\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u4e3a\u7ed3\u6784\u5316\u5fc3\u7406\u8868\u5f81\u5728\u6700\u5927\u5316\u4e8c\u9636\u5b66\u4e60\u6548\u679c\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301\uff0c\u9a8c\u8bc1\u4e86\u73af\u5883-\u8ba4\u77e5\u540c\u6784\u6027\u5bf9\u9ad8\u7ea7\u8ba4\u77e5\u529f\u80fd\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2509.13879", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2509.13879", "abs": "https://arxiv.org/abs/2509.13879", "authors": ["Mariano Barone", "Antonio Romano", "Giuseppe Riccio", "Marco Postiglione", "Vincenzo Moscato"], "title": "Combining Evidence and Reasoning for Biomedical Fact-Checking", "comment": "Proceedings of the 48th International ACM SIGIR Conference on\n  Research and Development in Information Retrieval, 2025", "summary": "Misinformation in healthcare, from vaccine hesitancy to unproven treatments,\nposes risks to public health and trust in medical systems. While machine\nlearning and natural language processing have advanced automated fact-checking,\nvalidating biomedical claims remains uniquely challenging due to complex\nterminology, the need for domain expertise, and the critical importance of\ngrounding in scientific evidence. We introduce CER (Combining Evidence and\nReasoning), a novel framework for biomedical fact-checking that integrates\nscientific evidence retrieval, reasoning via large language models, and\nsupervised veracity prediction. By integrating the text-generation capabilities\nof large language models with advanced retrieval techniques for high-quality\nbiomedical scientific evidence, CER effectively mitigates the risk of\nhallucinations, ensuring that generated outputs are grounded in verifiable,\nevidence-based sources. Evaluations on expert-annotated datasets (HealthFC,\nBioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising\ncross-dataset generalization. Code and data are released for transparency and\nreproducibility: https: //github.com/PRAISELab-PicusLab/CER.", "AI": {"tldr": "CER\u662f\u4e00\u4e2a\u7528\u4e8e\u751f\u7269\u533b\u5b66\u4e8b\u5b9e\u6838\u67e5\u7684\u65b0\u6846\u67b6\uff0c\u7ed3\u5408\u79d1\u5b66\u8bc1\u636e\u68c0\u7d22\u3001\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u548c\u76d1\u7763\u771f\u5b9e\u6027\u9884\u6d4b\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u533b\u7597\u9886\u57df\u4e2d\u7684\u9519\u8bef\u4fe1\u606f\uff08\u5982\u75ab\u82d7\u72b9\u8c6b\u548c\u672a\u7ecf\u8bc1\u5b9e\u7684\u6cbb\u7597\u65b9\u6cd5\uff09\u5bf9\u516c\u5171\u536b\u751f\u548c\u533b\u7597\u7cfb\u7edf\u4fe1\u4efb\u6784\u6210\u98ce\u9669\u3002\u751f\u7269\u533b\u5b66\u58f0\u660e\u9a8c\u8bc1\u5177\u6709\u72ec\u7279\u6311\u6218\u6027\uff0c\u5305\u62ec\u590d\u6742\u672f\u8bed\u3001\u9700\u8981\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u4ee5\u53ca\u5fc5\u987b\u57fa\u4e8e\u79d1\u5b66\u8bc1\u636e\u3002", "method": "CER\u6846\u67b6\u6574\u5408\u4e86\u79d1\u5b66\u8bc1\u636e\u68c0\u7d22\u3001\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u63a8\u7406\u4ee5\u53ca\u76d1\u7763\u771f\u5b9e\u6027\u9884\u6d4b\u3002\u901a\u8fc7\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6587\u672c\u751f\u6210\u80fd\u529b\u4e0e\u9ad8\u8d28\u91cf\u751f\u7269\u533b\u5b66\u79d1\u5b66\u8bc1\u636e\u7684\u5148\u8fdb\u68c0\u7d22\u6280\u672f\u76f8\u7ed3\u5408\uff0c\u6709\u6548\u51cf\u5c11\u5e7b\u89c9\u98ce\u9669\u3002", "result": "\u5728\u4e13\u5bb6\u6807\u6ce8\u7684\u6570\u636e\u96c6\uff08HealthFC\u3001BioASQ-7b\u3001SciFact\uff09\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u5c55\u73b0\u51fa\u6709\u524d\u666f\u7684\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "CER\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u8bc1\u636e\u68c0\u7d22\u548c\u63a8\u7406\uff0c\u4e3a\u751f\u7269\u533b\u5b66\u4e8b\u5b9e\u6838\u67e5\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\u4ee5\u786e\u4fdd\u900f\u660e\u5ea6\u548c\u53ef\u590d\u73b0\u6027\u3002"}}
{"id": "2509.13888", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2509.13888", "abs": "https://arxiv.org/abs/2509.13888", "authors": ["Mariano Barone", "Antonio Romano", "Giuseppe Riccio", "Marco Postiglione", "Vincenzo Moscato"], "title": "Combating Biomedical Misinformation through Multi-modal Claim Detection and Evidence-based Verification", "comment": null, "summary": "Misinformation in healthcare, from vaccine hesitancy to unproven treatments,\nposes risks to public health and trust in medical systems. While machine\nlearning and natural language processing have advanced automated fact-checking,\nvalidating biomedical claims remains uniquely challenging due to complex\nterminology, the need for domain expertise, and the critical importance of\ngrounding in scientific evidence. We introduce CER (Combining Evidence and\nReasoning), a novel framework for biomedical fact-checking that integrates\nscientific evidence retrieval, reasoning via large language models, and\nsupervised veracity prediction. By integrating the text-generation capabilities\nof large language models with advanced retrieval techniques for high-quality\nbiomedical scientific evidence, CER effectively mitigates the risk of\nhallucinations, ensuring that generated outputs are grounded in verifiable,\nevidence-based sources. Evaluations on expert-annotated datasets (HealthFC,\nBioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising\ncross-dataset generalization. Code and data are released for transparency and\nreproducibility: https://github.com/PRAISELab-PicusLab/CER", "AI": {"tldr": "CER\u662f\u4e00\u4e2a\u7528\u4e8e\u751f\u7269\u533b\u5b66\u4e8b\u5b9e\u6838\u67e5\u7684\u65b0\u6846\u67b6\uff0c\u7ed3\u5408\u79d1\u5b66\u8bc1\u636e\u68c0\u7d22\u3001\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u548c\u76d1\u7763\u771f\u5b9e\u6027\u9884\u6d4b\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u533b\u7597\u5065\u5eb7\u9886\u57df\u7684\u9519\u8bef\u4fe1\u606f\uff08\u5982\u75ab\u82d7\u72b9\u8c6b\u548c\u672a\u7ecf\u8bc1\u5b9e\u7684\u6cbb\u7597\u65b9\u6cd5\uff09\u5bf9\u516c\u5171\u536b\u751f\u548c\u533b\u7597\u7cfb\u7edf\u4fe1\u4efb\u6784\u6210\u98ce\u9669\u3002\u751f\u7269\u533b\u5b66\u58f0\u660e\u9a8c\u8bc1\u5177\u6709\u72ec\u7279\u6311\u6218\u6027\uff0c\u5305\u62ec\u590d\u6742\u672f\u8bed\u3001\u9700\u8981\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u4ee5\u53ca\u5fc5\u987b\u57fa\u4e8e\u79d1\u5b66\u8bc1\u636e\u3002", "method": "CER\u6846\u67b6\u6574\u5408\u79d1\u5b66\u8bc1\u636e\u68c0\u7d22\u3001\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u548c\u76d1\u7763\u771f\u5b9e\u6027\u9884\u6d4b\u3002\u901a\u8fc7\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6587\u672c\u751f\u6210\u80fd\u529b\u4e0e\u9ad8\u8d28\u91cf\u751f\u7269\u533b\u5b66\u79d1\u5b66\u8bc1\u636e\u7684\u5148\u8fdb\u68c0\u7d22\u6280\u672f\u76f8\u7ed3\u5408\uff0c\u6709\u6548\u51cf\u8f7b\u5e7b\u89c9\u98ce\u9669\u3002", "result": "\u5728\u4e13\u5bb6\u6807\u6ce8\u7684\u6570\u636e\u96c6\uff08HealthFC\u3001BioASQ-7b\u3001SciFact\uff09\u4e0a\u8bc4\u4f30\u663e\u793a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5e76\u5c55\u73b0\u51fa\u6709\u524d\u666f\u7684\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "CER\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u8bc1\u636e\u68c0\u7d22\u548c\u63a8\u7406\uff0c\u4e3a\u751f\u7269\u533b\u5b66\u4e8b\u5b9e\u6838\u67e5\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\u4ee5\u786e\u4fdd\u900f\u660e\u5ea6\u548c\u53ef\u91cd\u73b0\u6027\u3002"}}
{"id": "2509.13905", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13905", "abs": "https://arxiv.org/abs/2509.13905", "authors": ["Domenico Meconi", "Simone Stirpe", "Federico Martelli", "Leonardo Lavalle", "Roberto Navigli"], "title": "Do Large Language Models Understand Word Senses?", "comment": "20 pages, to be published in EMNLP2025", "summary": "Understanding the meaning of words in context is a fundamental capability for\nLarge Language Models (LLMs). Despite extensive evaluation efforts, the extent\nto which LLMs show evidence that they truly grasp word senses remains\nunderexplored. In this paper, we address this gap by evaluating both i) the\nWord Sense Disambiguation (WSD) capabilities of instruction-tuned LLMs,\ncomparing their performance to state-of-the-art systems specifically designed\nfor the task, and ii) the ability of two top-performing open- and closed-source\nLLMs to understand word senses in three generative settings: definition\ngeneration, free-form explanation, and example generation. Notably, we find\nthat, in the WSD task, leading models such as GPT-4o and DeepSeek-V3 achieve\nperformance on par with specialized WSD systems, while also demonstrating\ngreater robustness across domains and levels of difficulty. In the generation\ntasks, results reveal that LLMs can explain the meaning of words in context up\nto 98\\% accuracy, with the highest performance observed in the free-form\nexplanation task, which best aligns with their generative capabilities.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u6307\u4ee4\u8c03\u4f18\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bcd\u4e49\u6d88\u6b67\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\uff0c\u5e76\u4e0e\u4e13\u95e8\u7cfb\u7edf\u6bd4\u8f83\uff0c\u540c\u65f6\u6d4b\u8bd5\u4e86\u6a21\u578b\u5728\u5b9a\u4e49\u751f\u6210\u3001\u81ea\u7531\u89e3\u91ca\u548c\u793a\u4f8b\u751f\u6210\u4e09\u79cd\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8bcd\u4e49\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u6709\u5927\u91cf\u8bc4\u4f30\u5de5\u4f5c\uff0c\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u771f\u6b63\u7406\u89e3\u8bcd\u4e49\u4ecd\u7f3a\u4e4f\u6df1\u5165\u63a2\u7d22\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u8bc4\u4f30\u6307\u4ee4\u8c03\u4f18LLMs\u7684\u8bcd\u4e49\u6d88\u6b67\u80fd\u529b\uff0c\u5e76\u4e0e\u6700\u5148\u8fdb\u7684\u4e13\u95e8\u7cfb\u7edf\u6bd4\u8f83\uff1b\u6d4b\u8bd5\u4e24\u4e2a\u9876\u7ea7\u5f00\u6e90\u548c\u95ed\u6e90LLMs\u5728\u4e09\u79cd\u751f\u6210\u8bbe\u7f6e\uff08\u5b9a\u4e49\u751f\u6210\u3001\u81ea\u7531\u89e3\u91ca\u3001\u793a\u4f8b\u751f\u6210\uff09\u4e2d\u7684\u8bcd\u4e49\u7406\u89e3\u80fd\u529b\u3002", "result": "\u5728\u8bcd\u4e49\u6d88\u6b67\u4efb\u52a1\u4e2d\uff0cGPT-4o\u548cDeepSeek-V3\u7b49\u9886\u5148\u6a21\u578b\u8fbe\u5230\u4e0e\u4e13\u95e8WSD\u7cfb\u7edf\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u4e14\u5728\u9886\u57df\u548c\u96be\u5ea6\u7ea7\u522b\u4e0a\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff1b\u5728\u751f\u6210\u4efb\u52a1\u4e2d\uff0cLLMs\u80fd\u4ee5\u9ad8\u8fbe98%\u7684\u51c6\u786e\u7387\u89e3\u91ca\u4e0a\u4e0b\u6587\u4e2d\u7684\u8bcd\u4e49\uff0c\u81ea\u7531\u89e3\u91ca\u4efb\u52a1\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bcd\u4e49\u6d88\u6b67\u4efb\u52a1\u4e0a\u5df2\u8fbe\u5230\u4e13\u95e8\u7cfb\u7edf\u6c34\u5e73\uff0c\u4e14\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u8bcd\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u81ea\u7531\u89e3\u91ca\u65b9\u9762\u8868\u73b0\u6700\u4f18\u3002"}}
{"id": "2509.13930", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13930", "abs": "https://arxiv.org/abs/2509.13930", "authors": ["Dayeon Ki", "Marine Carpuat", "Paul McNamee", "Daniel Khashabi", "Eugene Yang", "Dawn Lawrie", "Kevin Duh"], "title": "Linguistic Nepotism: Trading-off Quality for Language Preference in Multilingual RAG", "comment": "33 pages, 20 figures", "summary": "Multilingual Retrieval-Augmented Generation (mRAG) systems enable language\nmodels to answer knowledge-intensive queries with citation-supported responses\nacross languages. While such systems have been proposed, an open questions is\nwhether the mixture of different document languages impacts generation and\ncitation in unintended ways. To investigate, we introduce a controlled\nmethodology using model internals to measure language preference while holding\nother factors such as document relevance constant. Across eight languages and\nsix open-weight models, we find that models preferentially cite English sources\nwhen queries are in English, with this bias amplified for lower-resource\nlanguages and for documents positioned mid-context. Crucially, we find that\nmodels sometimes trade-off document relevance for language preference,\nindicating that citation choices are not always driven by informativeness\nalone. Our findings shed light on how language models leverage multilingual\ncontext and influence citation behavior.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u591a\u8bed\u8a00\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u5b58\u5728\u8bed\u8a00\u504f\u597d\u504f\u89c1\uff0c\u6a21\u578b\u503e\u5411\u4e8e\u5f15\u7528\u82f1\u6587\u6765\u6e90\uff0c\u5373\u4f7f\u5176\u4ed6\u8bed\u8a00\u6587\u6863\u66f4\u76f8\u5173\uff0c\u8fd9\u79cd\u504f\u89c1\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u548c\u6587\u6863\u4f4d\u7f6e\u4e2d\u6bb5\u65f6\u66f4\u52a0\u660e\u663e\u3002", "motivation": "\u7814\u7a76\u591a\u8bed\u8a00\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u4e2d\u4e0d\u540c\u6587\u6863\u8bed\u8a00\u7684\u6df7\u5408\u662f\u5426\u4f1a\u5bf9\u751f\u6210\u548c\u5f15\u7528\u4ea7\u751f\u610f\u5916\u5f71\u54cd\uff0c\u7279\u522b\u662f\u6a21\u578b\u662f\u5426\u4f1a\u5728\u8bed\u8a00\u504f\u597d\u548c\u6587\u6863\u76f8\u5173\u6027\u4e4b\u95f4\u505a\u51fa\u6743\u8861\u3002", "method": "\u91c7\u7528\u53d7\u63a7\u65b9\u6cd5\uff0c\u5229\u7528\u6a21\u578b\u5185\u90e8\u673a\u5236\u6765\u8861\u91cf\u8bed\u8a00\u504f\u597d\uff0c\u540c\u65f6\u4fdd\u6301\u6587\u6863\u76f8\u5173\u6027\u7b49\u5176\u4ed6\u56e0\u7d20\u4e0d\u53d8\uff0c\u6db5\u76d68\u79cd\u8bed\u8a00\u548c6\u4e2a\u5f00\u6e90\u6a21\u578b\u3002", "result": "\u6a21\u578b\u5728\u82f1\u8bed\u67e5\u8be2\u65f6\u4f18\u5148\u5f15\u7528\u82f1\u6587\u6765\u6e90\uff0c\u8fd9\u79cd\u504f\u89c1\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u548c\u6587\u6863\u4f4d\u4e8e\u4e0a\u4e0b\u6587\u4e2d\u95f4\u4f4d\u7f6e\u65f6\u66f4\u52a0\u660e\u663e\u3002\u6a21\u578b\u6709\u65f6\u4f1a\u727a\u7272\u6587\u6863\u76f8\u5173\u6027\u6765\u6ee1\u8db3\u8bed\u8a00\u504f\u597d\uff0c\u8868\u660e\u5f15\u7528\u9009\u62e9\u5e76\u975e\u603b\u662f\u7531\u4fe1\u606f\u91cf\u9a71\u52a8\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u5229\u7528\u591a\u8bed\u8a00\u4e0a\u4e0b\u6587\u5e76\u5f71\u54cd\u5f15\u7528\u884c\u4e3a\uff0c\u6307\u51fa\u4e86mRAG\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u8bed\u8a00\u504f\u89c1\u95ee\u9898\uff0c\u8fd9\u5bf9\u6784\u5efa\u66f4\u516c\u5e73\u7684\u591a\u8bed\u8a00AI\u7cfb\u7edf\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2509.13980", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13980", "abs": "https://arxiv.org/abs/2509.13980", "authors": ["Sami Ul Haq", "Chinonso Cynthia Osuji", "Sheila Castilho", "Brian Davis"], "title": "Long-context Reference-based MT Quality Estimation", "comment": null, "summary": "In this paper, we present our submission to the Tenth Conference on Machine\nTranslation (WMT25) Shared Task on Automated Translation Quality Evaluation.\n  Our systems are built upon the COMET framework and trained to predict\nsegment-level Error Span Annotation (ESA) scores using augmented long-context\ndata.\n  To construct long-context training data, we concatenate in-domain,\nhuman-annotated sentences and compute a weighted average of their scores.\n  We integrate multiple human judgment datasets (MQM, SQM, and DA) by\nnormalising their scales and train multilingual regression models to predict\nquality scores from the source, hypothesis, and reference translations.\n  Experimental results show that incorporating long-context information\nimproves correlations with human judgments compared to models trained only on\nshort segments.", "AI": {"tldr": "\u57fa\u4e8eCOMET\u6846\u67b6\u6784\u5efa\u7684\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u7cfb\u7edf\uff0c\u901a\u8fc7\u957f\u4e0a\u4e0b\u6587\u6570\u636e\u589e\u5f3a\u8bad\u7ec3\u6765\u9884\u6d4b\u9519\u8bef\u8de8\u5ea6\u6807\u6ce8\u5206\u6570\uff0c\u6574\u5408\u591a\u79cd\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u8868\u660e\u957f\u4e0a\u4e0b\u6587\u4fe1\u606f\u80fd\u63d0\u5347\u4e0e\u4eba\u5de5\u8bc4\u4f30\u7684\u76f8\u5173\u6027", "motivation": "\u89e3\u51b3\u4f20\u7edf\u77ed\u7247\u6bb5\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u5229\u7528\u957f\u4e0a\u4e0b\u6587\u4fe1\u606f\u6765\u66f4\u51c6\u786e\u5730\u9884\u6d4b\u7ffb\u8bd1\u8d28\u91cf\uff0c\u63d0\u5347\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u76f8\u5173\u6027", "method": "\u4f7f\u7528COMET\u6846\u67b6\uff0c\u6784\u5efa\u957f\u4e0a\u4e0b\u6587\u8bad\u7ec3\u6570\u636e\uff08\u62fc\u63a5\u9886\u57df\u5185\u4eba\u5de5\u6807\u6ce8\u53e5\u5b50\u5e76\u8ba1\u7b97\u52a0\u6743\u5e73\u5747\u5206\u6570\uff09\uff0c\u6574\u5408MQM\u3001SQM\u3001DA\u7b49\u591a\u79cd\u4eba\u5de5\u5224\u65ad\u6570\u636e\u96c6\u5e76\u8fdb\u884c\u5c3a\u5ea6\u5f52\u4e00\u5316\uff0c\u8bad\u7ec3\u591a\u8bed\u8a00\u56de\u5f52\u6a21\u578b\u4ece\u6e90\u6587\u672c\u3001\u5047\u8bbe\u7ffb\u8bd1\u548c\u53c2\u8003\u7ffb\u8bd1\u9884\u6d4b\u8d28\u91cf\u5206\u6570", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u4ec5\u4f7f\u7528\u77ed\u7247\u6bb5\u8bad\u7ec3\u7684\u6a21\u578b\u76f8\u6bd4\uff0c\u878d\u5165\u957f\u4e0a\u4e0b\u6587\u4fe1\u606f\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u4e0e\u4eba\u5de5\u5224\u65ad\u7684\u76f8\u5173\u6027", "conclusion": "\u957f\u4e0a\u4e0b\u6587\u4fe1\u606f\u5728\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u548c\u591a\u79cd\u6807\u6ce8\u6570\u636e\u96c6\u7684\u6574\u5408\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u8bc4\u4f30\u6a21\u578b\u7684\u6027\u80fd"}}
{"id": "2509.13990", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "pdf": "https://arxiv.org/pdf/2509.13990", "abs": "https://arxiv.org/abs/2509.13990", "authors": ["Colin Hong", "Xu Guo", "Anand Chaanan Singh", "Esha Choukse", "Dmitrii Ustiugov"], "title": "Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency", "comment": "Accepted by EMNLP 2025 (Oral), 9 pages", "summary": "Recently, Test-Time Scaling (TTS) has gained increasing attention for\nimproving LLM reasoning performance at test time without retraining the model.\nA notable TTS technique is Self-Consistency (SC), which generates multiple\nreasoning chains in parallel and selects the final answer via majority voting.\nWhile effective, the order-of-magnitude computational overhead limits its broad\ndeployment. Prior attempts to accelerate SC mainly rely on model-based\nconfidence scores or heuristics with limited empirical support. For the first\ntime, we theoretically and empirically analyze the inefficiencies of SC and\nreveal actionable opportunities for improvement. Building on these insights, we\npropose Slim-SC, a step-wise pruning strategy that identifies and removes\nredundant chains using inter-chain similarity at the thought level. Experiments\non three STEM reasoning datasets and two recent LLM architectures show that\nSlim-SC reduces inference latency and KVC usage by up to 45% and 26%,\nrespectively, with R1-Distill, while maintaining or improving accuracy, thus\noffering a simple yet efficient TTS alternative for SC.", "AI": {"tldr": "Slim-SC\u662f\u4e00\u79cd\u57fa\u4e8e\u601d\u7ef4\u5c42\u9762\u94fe\u95f4\u76f8\u4f3c\u6027\u7684\u9010\u6b65\u526a\u679d\u7b56\u7565\uff0c\u901a\u8fc7\u8bc6\u522b\u548c\u79fb\u9664\u5197\u4f59\u63a8\u7406\u94fe\u6765\u52a0\u901f\u81ea\u6d3d\u6027\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u6216\u63d0\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u81ea\u6d3d\u6027(SC)\u65b9\u6cd5\u867d\u7136\u80fd\u63d0\u5347LLM\u63a8\u7406\u6027\u80fd\uff0c\u4f46\u5b58\u5728\u6570\u91cf\u7ea7\u8ba1\u7b97\u5f00\u9500\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002\u73b0\u6709\u52a0\u901f\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u6a21\u578b\u7f6e\u4fe1\u5ea6\u5206\u6570\u6216\u7f3a\u4e4f\u5b9e\u8bc1\u652f\u6301\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSlim-SC\u65b9\u6cd5\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u7814\u7a76\u63ed\u793aSC\u7684\u4f4e\u6548\u6027\uff0c\u57fa\u4e8e\u601d\u7ef4\u5c42\u9762\u7684\u94fe\u95f4\u76f8\u4f3c\u6027\u8bbe\u8ba1\u9010\u6b65\u526a\u679d\u7b56\u7565\uff0c\u8bc6\u522b\u5e76\u79fb\u9664\u5197\u4f59\u63a8\u7406\u94fe\u3002", "result": "\u5728\u4e09\u4e2aSTEM\u63a8\u7406\u6570\u636e\u96c6\u548c\u4e24\u79cdLLM\u67b6\u6784\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSlim-SC\u5c06\u63a8\u7406\u5ef6\u8fdf\u548cKVC\u4f7f\u7528\u5206\u522b\u964d\u4f4e\u9ad8\u8fbe45%\u548c26%\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "Slim-SC\u4e3a\u81ea\u6d3d\u6027\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u9ad8\u6548\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u66ff\u4ee3\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8ba1\u7b97\u5f00\u9500\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c\u3002"}}
{"id": "2509.14004", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.14004", "abs": "https://arxiv.org/abs/2509.14004", "authors": ["Minjia Mao", "Bowen Yin", "Yu Zhu", "Xiao Fang"], "title": "Early Stopping Chain-of-thoughts in Large Language Models", "comment": null, "summary": "Reasoning large language models (LLMs) have demonstrated superior capacities\nin solving complicated problems by generating long chain-of-thoughts (CoT), but\nsuch a lengthy CoT incurs high inference costs. In this study, we introduce\nES-CoT, an inference-time method that shortens CoT generation by detecting\nanswer convergence and stopping early with minimal performance loss. At the end\nof each reasoning step, we prompt the LLM to output its current final answer,\ndenoted as a step answer. We then track the run length of consecutive identical\nstep answers as a measure of answer convergence. Once the run length exhibits a\nsharp increase and exceeds a minimum threshold, the generation is terminated.\nWe provide both empirical and theoretical support for this heuristic: step\nanswers steadily converge to the final answer, and large run-length jumps\nreliably mark this convergence. Experiments on five reasoning datasets across\nthree LLMs show that ES-CoT reduces the number of inference tokens by about\n41\\% on average while maintaining accuracy comparable to standard CoT. Further,\nES-CoT integrates seamlessly with self-consistency prompting and remains robust\nacross hyperparameter choices, highlighting it as a practical and effective\napproach for efficient reasoning.", "AI": {"tldr": "ES-CoT\u662f\u4e00\u79cd\u63a8\u7406\u65f6\u65b9\u6cd5\uff0c\u901a\u8fc7\u68c0\u6d4b\u7b54\u6848\u6536\u655b\u6027\u6765\u63d0\u524d\u505c\u6b62\u601d\u7ef4\u94fe\u751f\u6210\uff0c\u51cf\u5c11\u7ea641%\u7684\u63a8\u7406token\u4f7f\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6807\u51c6CoT\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u51b3\u590d\u6742\u95ee\u9898\u65f6\u9700\u8981\u751f\u6210\u957f\u601d\u7ef4\u94fe\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u4f1a\u4ea7\u751f\u9ad8\u6602\u7684\u63a8\u7406\u6210\u672c\u3002\u7814\u7a76\u65e8\u5728\u51cf\u5c11\u63a8\u7406\u5f00\u9500\u7684\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002", "method": "\u5728\u6bcf\u4e2a\u63a8\u7406\u6b65\u9aa4\u7ed3\u675f\u65f6\u63d0\u793aLLM\u8f93\u51fa\u5f53\u524d\u6700\u7ec8\u7b54\u6848\uff08\u6b65\u9aa4\u7b54\u6848\uff09\uff0c\u8ddf\u8e2a\u8fde\u7eed\u76f8\u540c\u6b65\u9aa4\u7b54\u6848\u7684\u8fd0\u884c\u957f\u5ea6\u4f5c\u4e3a\u6536\u655b\u5ea6\u91cf\u3002\u5f53\u8fd0\u884c\u957f\u5ea6\u51fa\u73b0\u6025\u5267\u589e\u52a0\u5e76\u8d85\u8fc7\u6700\u5c0f\u9608\u503c\u65f6\u7ec8\u6b62\u751f\u6210\u3002", "result": "\u5728\u4e09\u4e2aLLM\u548c\u4e94\u4e2a\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cES-CoT\u5e73\u5747\u51cf\u5c11\u7ea641%\u7684\u63a8\u7406token\u4f7f\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6807\u51c6CoT\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002\u8be5\u65b9\u6cd5\u8fd8\u80fd\u4e0e\u81ea\u4e00\u81f4\u6027\u63d0\u793a\u65e0\u7f1d\u96c6\u6210\u3002", "conclusion": "ES-CoT\u662f\u4e00\u79cd\u5b9e\u7528\u6709\u6548\u7684\u63a8\u7406\u6548\u7387\u63d0\u5347\u65b9\u6cd5\uff0c\u901a\u8fc7\u68c0\u6d4b\u7b54\u6848\u6536\u655b\u5b9e\u73b0\u65e9\u671f\u505c\u6b62\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u63a8\u7406\u6210\u672c\u3002"}}
{"id": "2509.14008", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14008", "abs": "https://arxiv.org/abs/2509.14008", "authors": ["Hasan Abed Al Kader Hammoud", "Mohammad Zbeeb", "Bernard Ghanem"], "title": "Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale", "comment": "Technical Report", "summary": "We present Hala, a family of Arabic-centric instruction and translation\nmodels built with our translate-and-tune pipeline. We first compress a strong\nAR$\\leftrightarrow$EN teacher to FP8 (yielding $\\sim$2$\\times$ higher\nthroughput with no quality loss) and use it to create high-fidelity bilingual\nsupervision. A lightweight language model LFM2-1.2B is then fine-tuned on this\ndata and used to translate high-quality English instruction sets into Arabic,\nproducing a million-scale corpus tailored to instruction following. We train\nHala models at 350M, 700M, 1.2B, and 9B parameters, and apply slerp merging to\nbalance Arabic specialization with base-model strengths. On Arabic-centric\nbenchmarks, Hala achieves state-of-the-art results within both the \"nano\"\n($\\leq$2B) and \"small\" (7-9B) categories, outperforming their bases. We release\nmodels, data, evaluation, and recipes to accelerate research in Arabic NLP.", "AI": {"tldr": "Hala\u662f\u4e00\u4e2a\u963f\u62c9\u4f2f\u8bed\u4e3a\u4e2d\u5fc3\u7684\u6307\u4ee4\u548c\u7ffb\u8bd1\u6a21\u578b\u7cfb\u5217\uff0c\u901a\u8fc7\u7ffb\u8bd1\u8c03\u4f18\u6d41\u7a0b\u6784\u5efa\uff0c\u5728\u963f\u62c9\u4f2f\u8bed\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c", "motivation": "\u4e3a\u963f\u62c9\u4f2f\u8bedNLP\u7814\u7a76\u63d0\u4f9b\u9ad8\u8d28\u91cf\u7684\u6307\u4ee4\u8ddf\u968f\u6a21\u578b\uff0c\u89e3\u51b3\u963f\u62c9\u4f2f\u8bed\u6307\u4ee4\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898", "method": "\u4f7f\u7528FP8\u538b\u7f29\u7684\u6559\u5e08\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u53cc\u8bed\u76d1\u7763\u6570\u636e\uff0c\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7ffb\u8bd1\uff0c\u521b\u5efa\u767e\u4e07\u7ea7\u963f\u62c9\u4f2f\u8bed\u6307\u4ee4\u6570\u636e\u96c6\uff0c\u7136\u540e\u8bad\u7ec3\u4e0d\u540c\u89c4\u6a21\u7684Hala\u6a21\u578b\u5e76\u5e94\u7528slerp\u5408\u5e76\u6280\u672f", "result": "\u5728\u963f\u62c9\u4f2f\u8bed\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHala\u5728\"nano\"(\u22642B)\u548c\"small\"(7-9B)\u7c7b\u522b\u4e2d\u90fd\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u8d85\u8d8a\u4e86\u57fa\u7840\u6a21\u578b", "conclusion": "Hala\u6a21\u578b\u7cfb\u5217\u4e3a\u963f\u62c9\u4f2f\u8bedNLP\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u53d1\u5e03\u4e86\u6a21\u578b\u3001\u6570\u636e\u548c\u914d\u65b9\u4ee5\u52a0\u901f\u8be5\u9886\u57df\u7684\u7814\u7a76"}}
{"id": "2509.14023", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.14023", "abs": "https://arxiv.org/abs/2509.14023", "authors": ["Sami Ul Haq", "Sheila Castilho", "Yvette Graham"], "title": "Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality", "comment": "Accepted at WMT2025 (ENNLP) for oral presented", "summary": "Machine Translation (MT) has achieved remarkable performance, with growing\ninterest in speech translation and multimodal approaches. However, despite\nthese advancements, MT quality assessment remains largely text centric,\ntypically relying on human experts who read and compare texts. Since many\nreal-world MT applications (e.g Google Translate Voice Mode, iFLYTEK\nTranslator) involve translation being spoken rather printed or read, a more\nnatural way to assess translation quality would be through speech as opposed\ntext-only evaluations. This study compares text-only and audio-based\nevaluations of 10 MT systems from the WMT General MT Shared Task, using\ncrowd-sourced judgments collected via Amazon Mechanical Turk. We additionally,\nperformed statistical significance testing and self-replication experiments to\ntest reliability and consistency of audio-based approach. Crowd-sourced\nassessments based on audio yield rankings largely consistent with text only\nevaluations but, in some cases, identify significant differences between\ntranslation systems. We attribute this to speech richer, more natural modality\nand propose incorporating speech-based assessments into future MT evaluation\nframeworks.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u57fa\u4e8e\u6587\u672c\u548c\u57fa\u4e8e\u97f3\u9891\u7684\u673a\u5668\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\uff0c\u53d1\u73b0\u97f3\u9891\u8bc4\u4f30\u80fd\u63d0\u4f9b\u66f4\u81ea\u7136\u3001\u66f4\u4e30\u5bcc\u7684\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u5efa\u8bae\u5c06\u8bed\u97f3\u8bc4\u4f30\u7eb3\u5165\u672a\u6765MT\u8bc4\u4f30\u6846\u67b6", "motivation": "\u5c3d\u7ba1\u673a\u5668\u7ffb\u8bd1\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u8d28\u91cf\u8bc4\u4f30\u4ecd\u4e3b\u8981\u4f9d\u8d56\u6587\u672c\u4e2d\u5fc3\u7684\u65b9\u6cd5\u3002\u73b0\u5b9e\u4e16\u754c\u4e2d\u8bb8\u591aMT\u5e94\u7528\u6d89\u53ca\u8bed\u97f3\u7ffb\u8bd1\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u81ea\u7136\u7684\u8bed\u97f3\u8bc4\u4f30\u65b9\u5f0f\u6765\u66ff\u4ee3\u7eaf\u6587\u672c\u8bc4\u4f30", "method": "\u4f7f\u7528Amazon Mechanical Turk\u6536\u96c6\u4f17\u5305\u5224\u65ad\uff0c\u6bd4\u8f8310\u4e2aWMT\u901a\u7528MT\u5171\u4eab\u4efb\u52a1\u7cfb\u7edf\u7684\u6587\u672c\u8bc4\u4f30\u548c\u97f3\u9891\u8bc4\u4f30\uff0c\u5e76\u8fdb\u884c\u7edf\u8ba1\u663e\u8457\u6027\u6d4b\u8bd5\u548c\u81ea\u6211\u590d\u5236\u5b9e\u9a8c\u6765\u9a8c\u8bc1\u97f3\u9891\u65b9\u6cd5\u7684\u53ef\u9760\u6027", "result": "\u57fa\u4e8e\u97f3\u9891\u7684\u4f17\u5305\u8bc4\u4f30\u4ea7\u751f\u7684\u6392\u540d\u4e0e\u7eaf\u6587\u672c\u8bc4\u4f30\u57fa\u672c\u4e00\u81f4\uff0c\u4f46\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u80fd\u8bc6\u522b\u51fa\u7ffb\u8bd1\u7cfb\u7edf\u4e4b\u95f4\u7684\u663e\u8457\u5dee\u5f02\uff0c\u8fd9\u5f52\u56e0\u4e8e\u8bed\u97f3\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u3001\u66f4\u81ea\u7136\u7684\u6a21\u6001", "conclusion": "\u8bed\u97f3\u8bc4\u4f30\u5e94\u8be5\u88ab\u7eb3\u5165\u672a\u6765\u7684\u673a\u5668\u7ffb\u8bd1\u8bc4\u4f30\u6846\u67b6\u4e2d\uff0c\u56e0\u4e3a\u8bed\u97f3\u6a21\u6001\u63d0\u4f9b\u4e86\u66f4\u81ea\u7136\u548c\u4e30\u5bcc\u7684\u8bc4\u4f30\u7ef4\u5ea6"}}
{"id": "2509.14031", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14031", "abs": "https://arxiv.org/abs/2509.14031", "authors": ["Pawe\u0142 M\u0105ka", "Yusuf Can Semerci", "Jan Scholtes", "Gerasimos Spanakis"], "title": "You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models", "comment": "EMNLP 2025 main conference", "summary": "Achieving human-level translations requires leveraging context to ensure\ncoherence and handle complex phenomena like pronoun disambiguation. Sparsity of\ncontextually rich examples in the standard training data has been hypothesized\nas the reason for the difficulty of context utilization. In this work, we\nsystematically validate this claim in both single- and multilingual settings by\nconstructing training datasets with a controlled proportions of contextually\nrelevant examples. We demonstrate a strong association between training data\nsparsity and model performance confirming sparsity as a key bottleneck.\nImportantly, we reveal that improvements in one contextual phenomenon do no\ngeneralize to others. While we observe some cross-lingual transfer, it is not\nsignificantly higher between languages within the same sub-family. Finally, we\npropose and empirically evaluate two training strategies designed to leverage\nthe available data. These strategies improve context utilization, resulting in\naccuracy gains of up to 6 and 8 percentage points on the ctxPro evaluation in\nsingle- and multilingual settings respectively.", "AI": {"tldr": "\u672c\u6587\u9a8c\u8bc1\u4e86\u8bad\u7ec3\u6570\u636e\u4e2d\u4e0a\u4e0b\u6587\u76f8\u5173\u793a\u4f8b\u7684\u7a00\u758f\u6027\u662f\u673a\u5668\u7ffb\u8bd1\u6a21\u578b\u96be\u4ee5\u6709\u6548\u5229\u7528\u4e0a\u4e0b\u6587\u7684\u5173\u952e\u74f6\u9888\uff0c\u5e76\u901a\u8fc7\u6784\u5efa\u63a7\u5236\u6bd4\u4f8b\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u8bc1\u5b9e\u4e86\u7a00\u758f\u6027\u4e0e\u6a21\u578b\u6027\u80fd\u7684\u5f3a\u5173\u8054\u6027\u3002", "motivation": "\u4eba\u7c7b\u6c34\u5e73\u7684\u7ffb\u8bd1\u9700\u8981\u5229\u7528\u4e0a\u4e0b\u6587\u6765\u786e\u4fdd\u8fde\u8d2f\u6027\u548c\u5904\u7406\u590d\u6742\u73b0\u8c61\uff08\u5982\u4ee3\u8bcd\u6d88\u6b67\uff09\u3002\u6807\u51c6\u8bad\u7ec3\u6570\u636e\u4e2d\u4e0a\u4e0b\u6587\u4e30\u5bcc\u793a\u4f8b\u7684\u7a00\u758f\u6027\u88ab\u8ba4\u4e3a\u662f\u6a21\u578b\u96be\u4ee5\u5229\u7528\u4e0a\u4e0b\u6587\u7684\u539f\u56e0\uff0c\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u9a8c\u8bc1\u8fd9\u4e00\u5047\u8bbe\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u5177\u6709\u53d7\u63a7\u6bd4\u4f8b\u4e0a\u4e0b\u6587\u76f8\u5173\u793a\u4f8b\u7684\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u5728\u5355\u8bed\u548c\u591a\u8bed\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u5b9e\u9a8c\u3002\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u4e24\u79cd\u8bad\u7ec3\u7b56\u7565\u6765\u66f4\u597d\u5730\u5229\u7528\u53ef\u7528\u6570\u636e\u3002", "result": "\u8bc1\u5b9e\u4e86\u8bad\u7ec3\u6570\u636e\u7a00\u758f\u6027\u4e0e\u6a21\u578b\u6027\u80fd\u7684\u5f3a\u5173\u8054\u6027\uff0c\u53d1\u73b0\u4e0d\u540c\u4e0a\u4e0b\u6587\u73b0\u8c61\u7684\u6539\u8fdb\u4e0d\u80fd\u76f8\u4e92\u6cdb\u5316\u3002\u63d0\u51fa\u7684\u8bad\u7ec3\u7b56\u7565\u5728\u5355\u8bed\u548c\u591a\u8bed\u8bbe\u7f6e\u4e0b\u5206\u522b\u5b9e\u73b0\u4e86ctxPro\u8bc4\u4f30\u4e0a6%\u548c8%\u7684\u51c6\u786e\u7387\u63d0\u5347\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u76f8\u5173\u8bad\u7ec3\u6570\u636e\u7684\u7a00\u758f\u6027\u662f\u673a\u5668\u7ffb\u8bd1\u4e0a\u4e0b\u6587\u5229\u7528\u7684\u5173\u952e\u74f6\u9888\uff0c\u9700\u8981\u9488\u5bf9\u6027\u7684\u8bad\u7ec3\u7b56\u7565\u6765\u6539\u5584\u6a21\u578b\u6027\u80fd\uff0c\u4e14\u4e0d\u540c\u4e0a\u4e0b\u6587\u73b0\u8c61\u9700\u8981\u5206\u522b\u5904\u7406\u3002"}}
{"id": "2509.14034", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.14034", "abs": "https://arxiv.org/abs/2509.14034", "authors": ["Zijie Lin", "Bryan Hooi"], "title": "Enhancing Multi-Agent Debate System Performance via Confidence Expression", "comment": "EMNLP'25 Findings", "summary": "Generative Large Language Models (LLMs) have demonstrated remarkable\nperformance across a wide range of tasks. Recent research has introduced\nMulti-Agent Debate (MAD) systems, which leverage multiple LLMs to simulate\nhuman debate and thereby improve task performance. However, while some LLMs may\npossess superior knowledge or reasoning capabilities for specific tasks, they\noften struggle to clearly communicate this advantage during debates, in part\ndue to a lack of confidence expression. Moreover, inappropriate confidence\nexpression can cause agents in MAD systems to either stubbornly maintain\nincorrect beliefs or converge prematurely on suboptimal answers, ultimately\nreducing debate effectiveness and overall system performance. To address these\nchallenges, we propose incorporating confidence expression into MAD systems to\nallow LLMs to explicitly communicate their confidence levels. To validate this\napproach, we develop ConfMAD, a MAD framework that integrates confidence\nexpression throughout the debate process. Experimental results demonstrate the\neffectiveness of our method, and we further analyze how confidence influences\ndebate dynamics, offering insights into the design of confidence-aware MAD\nsystems.", "AI": {"tldr": "\u63d0\u51fa\u4e86ConfMAD\u6846\u67b6\uff0c\u5728\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u7cfb\u7edf\u4e2d\u5f15\u5165\u7f6e\u4fe1\u5ea6\u8868\u8fbe\u673a\u5236\uff0c\u8ba9LLM\u80fd\u591f\u660e\u786e\u8868\u8fbe\u7f6e\u4fe1\u6c34\u5e73\uff0c\u4ece\u800c\u63d0\u5347\u8fa9\u8bba\u6548\u679c\u548c\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u73b0\u6709MAD\u7cfb\u7edf\u4e2d\uff0c\u5373\u4f7f\u67d0\u4e9bLLM\u62e5\u6709\u66f4\u4f18\u7684\u77e5\u8bc6\u6216\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u7f6e\u4fe1\u5ea6\u8868\u8fbe\uff0c\u96be\u4ee5\u5728\u8fa9\u8bba\u4e2d\u6e05\u6670\u5c55\u73b0\u5176\u4f18\u52bf\u3002\u4e0d\u6070\u5f53\u7684\u7f6e\u4fe1\u5ea6\u8868\u8fbe\u4f1a\u5bfc\u81f4\u667a\u80fd\u4f53\u56fa\u6267\u575a\u6301\u9519\u8bef\u4fe1\u5ff5\u6216\u8fc7\u65e9\u6536\u655b\u4e8e\u6b21\u4f18\u7b54\u6848\uff0c\u964d\u4f4e\u8fa9\u8bba\u6548\u679c\u3002", "method": "\u5f00\u53d1ConfMAD\u6846\u67b6\uff0c\u5728\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u8fc7\u7a0b\u4e2d\u96c6\u6210\u7f6e\u4fe1\u5ea6\u8868\u8fbe\u673a\u5236\uff0c\u8ba9LLM\u80fd\u591f\u660e\u786e\u4f20\u8fbe\u5176\u7f6e\u4fe1\u6c34\u5e73\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\uff0c\u5e76\u5206\u6790\u4e86\u7f6e\u4fe1\u5ea6\u5982\u4f55\u5f71\u54cd\u8fa9\u8bba\u52a8\u6001\uff0c\u4e3a\u8bbe\u8ba1\u7f6e\u4fe1\u5ea6\u611f\u77e5\u7684MAD\u7cfb\u7edf\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002", "conclusion": "\u5f15\u5165\u7f6e\u4fe1\u5ea6\u8868\u8fbe\u80fd\u591f\u6709\u6548\u63d0\u5347\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u7cfb\u7edf\u7684\u6027\u80fd\uff0cConfMAD\u6846\u67b6\u4e3a\u89e3\u51b3LLM\u5728\u8fa9\u8bba\u4e2d\u7f6e\u4fe1\u5ea6\u8868\u8fbe\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2509.14036", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14036", "abs": "https://arxiv.org/abs/2509.14036", "authors": ["Zekang Liu", "Wei Feng", "Fanhua Shang", "Lianyu Hu", "Jichao Feng", "Liqing Gao"], "title": "SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation", "comment": null, "summary": "Sign Language Translation (SLT) bridges the communication gap between deaf\npeople and hearing people, where dialogue provides crucial contextual cues to\naid in translation. Building on this foundational concept, this paper proposes\nQuestion-based Sign Language Translation (QB-SLT), a novel task that explores\nthe efficient integration of dialogue. Unlike gloss (sign language\ntranscription) annotations, dialogue naturally occurs in communication and is\neasier to annotate. The key challenge lies in aligning multimodality features\nwhile leveraging the context of the question to improve translation. To address\nthis issue, we propose a cross-modality Self-supervised Learning with Sigmoid\nSelf-attention Weighting (SSL-SSAW) fusion method for sign language\ntranslation. Specifically, we employ contrastive learning to align\nmultimodality features in QB-SLT, then introduce a Sigmoid Self-attention\nWeighting (SSAW) module for adaptive feature extraction from question and sign\nlanguage sequences. Additionally, we leverage available question text through\nself-supervised learning to enhance representation and translation\ncapabilities. We evaluated our approach on newly constructed CSL-Daily-QA and\nPHOENIX-2014T-QA datasets, where SSL-SSAW achieved SOTA performance. Notably,\neasily accessible question assistance can achieve or even surpass the\nperformance of gloss assistance. Furthermore, visualization results demonstrate\nthe effectiveness of incorporating dialogue in improving translation quality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u95ee\u9898\u7684\u624b\u8bed\u7ffb\u8bd1(QB-SLT)\u65b0\u4efb\u52a1\uff0c\u901a\u8fc7\u5f15\u5165\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u6765\u63d0\u5347\u624b\u8bed\u7ffb\u8bd1\u8d28\u91cf\uff0c\u5e76\u5f00\u53d1\u4e86SSL-SSAW\u8de8\u6a21\u6001\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u65b0\u5efa\u6570\u636e\u96c6\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u624b\u8bed\u7ffb\u8bd1\u5728\u804b\u54d1\u4eba\u4e0e\u542c\u529b\u4eba\u7fa4\u6c9f\u901a\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u5bf9\u8bdd\u80fd\u63d0\u4f9b\u91cd\u8981\u7684\u4e0a\u4e0b\u6587\u7ebf\u7d22\u3002\u76f8\u6bd4\u4f20\u7edf\u7684\u624b\u8bed\u6ce8\u91ca(gloss)\uff0c\u5bf9\u8bdd\u5728\u81ea\u7136\u4ea4\u6d41\u4e2d\u66f4\u5bb9\u6613\u6807\u6ce8\uff0c\u56e0\u6b64\u63a2\u7d22\u5982\u4f55\u6709\u6548\u6574\u5408\u5bf9\u8bdd\u4fe1\u606f\u6765\u63d0\u5347\u7ffb\u8bd1\u6548\u679c\u3002", "method": "\u63d0\u51fa\u8de8\u6a21\u6001\u81ea\u76d1\u7763\u5b66\u4e60\u4e0eSigmoid\u81ea\u6ce8\u610f\u529b\u52a0\u6743(SSL-SSAW)\u878d\u5408\u65b9\u6cd5\uff1a1)\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u9f50\u591a\u6a21\u6001\u7279\u5f81\uff1b2)\u5f15\u5165SSAW\u6a21\u5757\u81ea\u9002\u5e94\u63d0\u53d6\u95ee\u9898\u548c\u624b\u8bed\u5e8f\u5217\u7279\u5f81\uff1b3)\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u5229\u7528\u53ef\u7528\u95ee\u9898\u6587\u672c\u6765\u589e\u5f3a\u8868\u793a\u80fd\u529b\u3002", "result": "\u5728\u65b0\u5efa\u7684CSL-Daily-QA\u548cPHOENIX-2014T-QA\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002\u6613\u83b7\u53d6\u7684\u95ee\u9898\u8f85\u52a9\u53ef\u4ee5\u8fbe\u5230\u751a\u81f3\u8d85\u8d8a\u4f20\u7edfgloss\u8f85\u52a9\u7684\u6027\u80fd\u3002\u53ef\u89c6\u5316\u7ed3\u679c\u8bc1\u660e\u4e86\u878d\u5165\u5bf9\u8bdd\u5bf9\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8e\u95ee\u9898\u7684\u5bf9\u8bdd\u6574\u5408\u4e3a\u624b\u8bed\u7ffb\u8bd1\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u9014\u5f84\uff0c\u63d0\u51fa\u7684SSL-SSAW\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u7279\u5f81\u5bf9\u9f50\u548c\u4e0a\u4e0b\u6587\u5229\u7528\u7684\u6311\u6218\uff0c\u8bc1\u660e\u4e86\u5bf9\u8bdd\u4fe1\u606f\u5728\u624b\u8bed\u7ffb\u8bd1\u4e2d\u7684\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2509.14128", "categories": ["cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2509.14128", "abs": "https://arxiv.org/abs/2509.14128", "authors": ["Monica Sekoyan", "Nithin Rao Koluguri", "Nune Tadevosyan", "Piotr Zelasko", "Travis Bartley", "Nick Karpov", "Jagadeesh Balam", "Boris Ginsburg"], "title": "Canary-1B-v2 & Parakeet-TDT-0.6B-v3: Efficient and High-Performance Models for Multilingual ASR and AST", "comment": "Mini Version of it Submitted to ICASSP 2026", "summary": "This report introduces Canary-1B-v2, a fast, robust multilingual model for\nAutomatic Speech Recognition (ASR) and Speech-to-Text Translation (AST). Built\nwith a FastConformer encoder and Transformer decoder, it supports 25 languages\nprimarily European. The model was trained on 1.7M hours of total data samples,\nincluding Granary and NeMo ASR Set 3.0, with non-speech audio added to reduce\nhallucinations for ASR and AST. We describe its two-stage pre-training and\nfine-tuning process with dynamic data balancing, as well as experiments with an\nnGPT encoder. Results show nGPT scales well with massive data, while\nFastConformer excels after fine-tuning. For timestamps, Canary-1B-v2 uses the\nNeMo Forced Aligner (NFA) with an auxiliary CTC model, providing reliable\nsegment-level timestamps for ASR and AST. Evaluations show Canary-1B-v2\noutperforms Whisper-large-v3 on English ASR while being 10x faster, and\ndelivers competitive multilingual ASR and AST performance against larger models\nlike Seamless-M4T-v2-large and LLM-based systems. We also release\nParakeet-TDT-0.6B-v3, a successor to v2, offering multilingual ASR across the\nsame 25 languages with just 600M parameters.", "AI": {"tldr": "Canary-1B-v2\u662f\u4e00\u4e2a\u5feb\u901f\u3001\u9c81\u68d2\u7684\u591a\u8bed\u8a00\u8bed\u97f3\u8bc6\u522b\u548c\u8bed\u97f3\u7ffb\u8bd1\u6a21\u578b\uff0c\u652f\u630125\u79cd\u6b27\u6d32\u8bed\u8a00\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u6bd4Whisper-large-v3\u5feb10\u500d", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u9ad8\u6548\u7684\u591a\u8bed\u8a00\u8bed\u97f3\u5904\u7406\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u5904\u7406\u901f\u5ea6\uff0c\u5e76\u51cf\u5c11\u8bed\u97f3\u8bc6\u522b\u548c\u7ffb\u8bd1\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898", "method": "\u91c7\u7528FastConformer\u7f16\u7801\u5668\u548cTransformer\u89e3\u7801\u5668\u67b6\u6784\uff0c\u4f7f\u7528\u4e24\u9636\u6bb5\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u8fc7\u7a0b\uff0c\u5305\u542b\u52a8\u6001\u6570\u636e\u5e73\u8861\uff0c\u8bad\u7ec3\u6570\u636e\u603b\u91cf\u8fbe170\u4e07\u5c0f\u65f6\uff0c\u5e76\u52a0\u5165\u975e\u8bed\u97f3\u97f3\u9891\u51cf\u5c11\u5e7b\u89c9", "result": "\u5728\u82f1\u8bedASR\u4e0a\u8d85\u8d8aWhisper-large-v3\u4e14\u901f\u5ea6\u5feb10\u500d\uff0c\u5728\u591a\u8bed\u8a00ASR\u548cAST\u4efb\u52a1\u4e0a\u4e0eSeamless-M4T-v2-large\u7b49\u5927\u578b\u6a21\u578b\u7ade\u4e89\uff0c\u540c\u65f6\u53d1\u5e03\u4e86\u66f4\u8f7b\u91cf\u7684Parakeet-TDT-0.6B-v3\u7248\u672c", "conclusion": "Canary-1B-v2\u5c55\u793a\u4e86\u5728\u8bed\u97f3\u5904\u7406\u4efb\u52a1\u4e2d\u5b9e\u73b0\u9ad8\u6027\u80fd\u548c\u9ad8\u6548\u7387\u7684\u53ef\u884c\u6027\uff0cnGPT\u7f16\u7801\u5668\u5728\u5927\u89c4\u6a21\u6570\u636e\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u800cFastConformer\u5728\u5fae\u8c03\u540e\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u591a\u8bed\u8a00\u8bed\u97f3\u5904\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.14161", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2509.14161", "abs": "https://arxiv.org/abs/2509.14161", "authors": ["Brian Yan", "Injy Hamed", "Shuichiro Shimizu", "Vasista Lodagala", "William Chen", "Olga Iakovenko", "Bashar Talafha", "Amir Hussein", "Alexander Polok", "Kalvin Chang", "Dominik Klement", "Sara Althubaiti", "Puyuan Peng", "Matthew Wiesner", "Thamar Solorio", "Ahmed Ali", "Sanjeev Khudanpur", "Shinji Watanabe", "Chih-Chen Chen", "Zhen Wu", "Karim Benharrak", "Anuj Diwan", "Samuele Cornell", "Eunjung Yeo", "Kwanghee Choi", "Carlos Carvalho", "Karen Rosero"], "title": "CS-FLEURS: A Massively Multilingual and Code-Switched Speech Dataset", "comment": null, "summary": "We present CS-FLEURS, a new dataset for developing and evaluating\ncode-switched speech recognition and translation systems beyond high-resourced\nlanguages. CS-FLEURS consists of 4 test sets which cover in total 113 unique\ncode-switched language pairs across 52 languages: 1) a 14 X-English language\npair set with real voices reading synthetically generated code-switched\nsentences, 2) a 16 X-English language pair set with generative text-to-speech\n3) a 60 {Arabic, Mandarin, Hindi, Spanish}-X language pair set with the\ngenerative text-to-speech, and 4) a 45 X-English lower-resourced language pair\ntest set with concatenative text-to-speech. Besides the four test sets,\nCS-FLEURS also provides a training set with 128 hours of generative\ntext-to-speech data across 16 X-English language pairs. Our hope is that\nCS-FLEURS helps to broaden the scope of future code-switched speech research.\nDataset link: https://huggingface.co/datasets/byan/cs-fleurs.", "AI": {"tldr": "CS-FLEURS\u662f\u4e00\u4e2a\u65b0\u7684\u4ee3\u7801\u5207\u6362\u8bed\u97f3\u8bc6\u522b\u548c\u7ffb\u8bd1\u6570\u636e\u96c6\uff0c\u5305\u542b4\u4e2a\u6d4b\u8bd5\u96c6\uff0c\u8986\u76d6113\u79cd\u8bed\u8a00\u5bf9\u548c52\u79cd\u8bed\u8a00\uff0c\u65e8\u5728\u6269\u5c55\u4ee3\u7801\u5207\u6362\u8bed\u97f3\u7814\u7a76\u7684\u8303\u56f4\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u9ad8\u8d44\u6e90\u8bed\u8a00\u4e4b\u5916\u7684\u4ee3\u7801\u5207\u6362\u8bed\u97f3\u8bc6\u522b\u548c\u7ffb\u8bd1\u7cfb\u7edf\u7684\u5f00\u53d1\u548c\u8bc4\u4f30\u9700\u6c42\uff0c\u7279\u522b\u662f\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u573a\u666f\u4e0b\u3002", "method": "\u6784\u5efa\u5305\u542b4\u4e2a\u6d4b\u8bd5\u96c6\u7684\u6570\u636e\u96c6\uff1a1\uff0914\u79cdX-\u82f1\u8bed\u8bed\u8a00\u5bf9\u7684\u771f\u5b9e\u8bed\u97f3\u5408\u6210\u4ee3\u7801\u5207\u6362\u53e5\u5b50\uff1b2\uff0916\u79cdX-\u82f1\u8bed\u8bed\u8a00\u5bf9\u7684\u751f\u6210\u5f0f\u6587\u672c\u8f6c\u8bed\u97f3\uff1b3\uff0960\u79cd{\u963f\u62c9\u4f2f\u8bed\u3001\u666e\u901a\u8bdd\u3001\u5370\u5730\u8bed\u3001\u897f\u73ed\u7259\u8bed}-X\u8bed\u8a00\u5bf9\u7684\u751f\u6210\u5f0f\u6587\u672c\u8f6c\u8bed\u97f3\uff1b4\uff0945\u79cdX-\u82f1\u8bed\u4f4e\u8d44\u6e90\u8bed\u8a00\u5bf9\u7684\u62fc\u63a5\u5f0f\u6587\u672c\u8f6c\u8bed\u97f3\u3002\u540c\u65f6\u63d0\u4f9b128\u5c0f\u65f6\u7684\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u521b\u5efa\u4e86CS-FLEURS\u6570\u636e\u96c6\uff0c\u5305\u542b113\u79cd\u72ec\u7279\u7684\u4ee3\u7801\u5207\u6362\u8bed\u8a00\u5bf9\uff0c\u8986\u76d652\u79cd\u8bed\u8a00\uff0c\u4e3a\u4ee3\u7801\u5207\u6362\u8bed\u97f3\u7814\u7a76\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u8d44\u6e90\u3002", "conclusion": "CS-FLEURS\u6570\u636e\u96c6\u6709\u52a9\u4e8e\u62d3\u5bbd\u672a\u6765\u4ee3\u7801\u5207\u6362\u8bed\u97f3\u7814\u7a76\u7684\u8303\u56f4\uff0c\u4e3a\u5f00\u53d1\u66f4\u5168\u9762\u7684\u4ee3\u7801\u5207\u6362\u8bed\u97f3\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\u3002"}}
{"id": "2509.14171", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.14171", "abs": "https://arxiv.org/abs/2509.14171", "authors": ["Yifan Liu", "Wenkuan Zhao", "Shanshan Zhong", "Jinghui Qin", "Mingfu Liang", "Zhongzhan Huang", "Wushao Wen"], "title": "AssoCiAm: A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity", "comment": null, "summary": "Recent advancements in multimodal large language models (MLLMs) have garnered\nsignificant attention, offering a promising pathway toward artificial general\nintelligence (AGI). Among the essential capabilities required for AGI,\ncreativity has emerged as a critical trait for MLLMs, with association serving\nas its foundation. Association reflects a model' s ability to think creatively,\nmaking it vital to evaluate and understand. While several frameworks have been\nproposed to assess associative ability, they often overlook the inherent\nambiguity in association tasks, which arises from the divergent nature of\nassociations and undermines the reliability of evaluations. To address this\nissue, we decompose ambiguity into two types-internal ambiguity and external\nambiguity-and introduce AssoCiAm, a benchmark designed to evaluate associative\nability while circumventing the ambiguity through a hybrid computational\nmethod. We then conduct extensive experiments on MLLMs, revealing a strong\npositive correlation between cognition and association. Additionally, we\nobserve that the presence of ambiguity in the evaluation process causes MLLMs'\nbehavior to become more random-like. Finally, we validate the effectiveness of\nour method in ensuring more accurate and reliable evaluations. See Project Page\nfor the data and codes.", "AI": {"tldr": "\u63d0\u51fa\u4e86AssoCiAm\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u6df7\u5408\u8ba1\u7b97\u65b9\u6cd5\u89e3\u51b3\u5173\u8054\u4efb\u52a1\u4e2d\u7684\u6b67\u4e49\u95ee\u9898\uff0c\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8054\u60f3\u80fd\u529b\uff0c\u53d1\u73b0\u8ba4\u77e5\u4e0e\u5173\u8054\u4e4b\u95f4\u5b58\u5728\u5f3a\u6b63\u76f8\u5173\u5173\u7cfb\u3002", "motivation": "\u73b0\u6709\u7684\u5173\u8054\u80fd\u529b\u8bc4\u4f30\u6846\u67b6\u5f80\u5f80\u5ffd\u89c6\u5173\u8054\u4efb\u52a1\u4e2d\u56fa\u6709\u7684\u6b67\u4e49\u6027\uff0c\u8fd9\u79cd\u6b67\u4e49\u6e90\u4e8e\u5173\u8054\u7684\u53d1\u6563\u6027\uff0c\u4f1a\u524a\u5f31\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u3002", "method": "\u5c06\u6b67\u4e49\u5206\u89e3\u4e3a\u5185\u90e8\u6b67\u4e49\u548c\u5916\u90e8\u6b67\u4e49\uff0c\u5f15\u5165AssoCiAm\u57fa\u51c6\u6d4b\u8bd5\uff0c\u91c7\u7528\u6df7\u5408\u8ba1\u7b97\u65b9\u6cd5\u6765\u89c4\u907f\u6b67\u4e49\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u8ba4\u77e5\u4e0e\u5173\u8054\u4e4b\u95f4\u5b58\u5728\u5f3a\u6b63\u76f8\u5173\u5173\u7cfb\uff0c\u6b67\u4e49\u7684\u5b58\u5728\u4f7fMLLMs\u7684\u884c\u4e3a\u66f4\u52a0\u968f\u673a\u5316\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u80fd\u786e\u4fdd\u66f4\u51c6\u786e\u53ef\u9760\u7684\u8bc4\u4f30\u3002", "conclusion": "AssoCiAm\u57fa\u51c6\u6d4b\u8bd5\u80fd\u6709\u6548\u89e3\u51b3\u5173\u8054\u8bc4\u4f30\u4e2d\u7684\u6b67\u4e49\u95ee\u9898\uff0c\u4e3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8054\u60f3\u80fd\u529b\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2509.14180", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50", "I.2.7; J.4"], "pdf": "https://arxiv.org/pdf/2509.14180", "abs": "https://arxiv.org/abs/2509.14180", "authors": ["Akhil Theerthala"], "title": "Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs", "comment": "24 pages, 11 figures. The paper presents a novel framework for\n  generating a personal finance dataset. The resulting fine-tuned model and\n  dataset are publicly available", "summary": "Personalized financial advice requires consideration of user goals,\nconstraints, risk tolerance, and jurisdiction. Prior LLM work has focused on\nsupport systems for investors and financial planners. Simultaneously, numerous\nrecent studies examine broader personal finance tasks, including budgeting,\ndebt management, retirement, and estate planning, through agentic pipelines\nthat incur high maintenance costs, yielding less than 25% of their expected\nfinancial returns. In this study, we introduce a novel and reproducible\nframework that integrates relevant financial context with behavioral finance\nstudies to construct supervision data for end-to-end advisors. Using this\nframework, we create a 19k sample reasoning dataset and conduct a comprehensive\nfine-tuning of the Qwen-3-8B model on the dataset. Through a held-out test\nsplit and a blind LLM-jury study, we demonstrate that through careful data\ncuration and behavioral integration, our 8B model achieves performance\ncomparable to significantly larger baselines (14-32B parameters) across factual\naccuracy, fluency, and personalization metrics while incurring 80% lower costs\nthan the larger counterparts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u91d1\u878d\u54a8\u8be2\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u91d1\u878d\u80cc\u666f\u548c\u884c\u4e3a\u91d1\u878d\u5b66\u7814\u7a76\u6765\u6784\u5efa\u76d1\u7763\u6570\u636e\uff0c\u8bad\u7ec3\u51fa\u76848B\u53c2\u6570\u6a21\u578b\u5728\u6027\u80fd\u4e0a\u53ef\u6bd4\u62df14-32B\u7684\u5927\u578b\u6a21\u578b\uff0c\u540c\u65f6\u6210\u672c\u964d\u4f4e80%\u3002", "motivation": "\u73b0\u6709\u7684\u91d1\u878d\u54a8\u8be2\u7cfb\u7edf\u7ef4\u62a4\u6210\u672c\u9ad8\u4e14\u6536\u76ca\u4e0d\u4f73\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u63d0\u4f9b\u4e2a\u6027\u5316\u7684\u91d1\u878d\u5efa\u8bae\uff0c\u540c\u65f6\u8003\u8651\u7528\u6237\u76ee\u6807\u3001\u7ea6\u675f\u6761\u4ef6\u3001\u98ce\u9669\u627f\u53d7\u80fd\u529b\u548c\u53f8\u6cd5\u7ba1\u8f96\u533a\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u6846\u67b6\uff0c\u6574\u5408\u76f8\u5173\u91d1\u878d\u80cc\u666f\u548c\u884c\u4e3a\u91d1\u878d\u5b66\u7814\u7a76\u6765\u6784\u5efa\u76d1\u7763\u6570\u636e\uff0c\u521b\u5efa\u4e8619k\u6837\u672c\u7684\u63a8\u7406\u6570\u636e\u96c6\uff0c\u5e76\u5bf9Qwen-3-8B\u6a21\u578b\u8fdb\u884c\u4e86\u5168\u9762\u5fae\u8c03\u3002", "result": "\u901a\u8fc7\u4fdd\u7559\u6d4b\u8bd5\u96c6\u548c\u76f2\u6d4bLLM\u8bc4\u5ba1\u7814\u7a76\u663e\u793a\uff0c8B\u6a21\u578b\u5728\u4e8b\u5b9e\u51c6\u786e\u6027\u3001\u6d41\u7545\u6027\u548c\u4e2a\u6027\u5316\u6307\u6807\u4e0a\u8fbe\u5230\u4e86\u4e0e14-32B\u5927\u578b\u57fa\u7ebf\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u6210\u672c\u964d\u4f4e\u4e8680%\u3002", "conclusion": "\u901a\u8fc7\u7cbe\u5fc3\u7b56\u5212\u7684\u6570\u636e\u6574\u5408\u548c\u884c\u4e3a\u91d1\u878d\u5b66\u96c6\u6210\uff0c\u8f83\u5c0f\u7684\u6a21\u578b\u53ef\u4ee5\u5b9e\u73b0\u4e0e\u5927\u578b\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u6210\u672c\uff0c\u4e3a\u4e2a\u6027\u5316\u91d1\u878d\u54a8\u8be2\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.14197", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.14197", "abs": "https://arxiv.org/abs/2509.14197", "authors": ["Vahid Ghafouri", "Robert McNeil", "Teodor Yankov", "Madeleine Sumption", "Luc Rocher", "Scott A. Hale", "Adam Mahdi"], "title": "Framing Migration: A Computational Analysis of UK Parliamentary Discourse", "comment": null, "summary": "We present a large-scale computational analysis of migration-related\ndiscourse in UK parliamentary debates spanning over 75 years and compare it\nwith US congressional discourse. Using open-weight LLMs, we annotate each\nstatement with high-level stances toward migrants and track the net tone toward\nmigrants across time and political parties. For the UK, we extend this with a\nsemi-automated framework for extracting fine-grained narrative frames to\ncapture nuances of migration discourse. Our findings show that, while US\ndiscourse has grown increasingly polarised, UK parliamentary attitudes remain\nrelatively aligned across parties, with a persistent ideological gap between\nLabour and the Conservatives, reaching its most negative level in 2025. The\nanalysis of narrative frames in the UK parliamentary statements reveals a shift\ntoward securitised narratives such as border control and illegal immigration,\nwhile longer-term integration-oriented frames such as social integration have\ndeclined. Moreover, discussions of national law about immigration have been\nreplaced over time by international law and human rights, revealing nuances in\ndiscourse trends. Taken together broadly, our findings demonstrate how LLMs can\nsupport scalable, fine-grained discourse analysis in political and historical\ncontexts.", "AI": {"tldr": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5206\u6790\u82f1\u7f8e\u8bae\u4f1a75\u5e74\u79fb\u6c11\u8bdd\u8bed\uff0c\u53d1\u73b0\u7f8e\u56fd\u65e5\u76ca\u6781\u5316\u800c\u82f1\u56fd\u515a\u6d3e\u6001\u5ea6\u76f8\u5bf9\u4e00\u81f4\uff0c\u4f46\u4fdd\u5b88\u515a\u4e0e\u5de5\u515a\u610f\u8bc6\u5f62\u6001\u5dee\u8ddd\u57282025\u5e74\u8fbe\u5230\u6700\u8d1f\u9762\u6c34\u5e73\uff0c\u4e14\u8bdd\u8bed\u8f6c\u5411\u5b89\u5168\u5316\u53d9\u4e8b", "motivation": "\u901a\u8fc7\u5927\u89c4\u6a21\u8ba1\u7b97\u5206\u6790\u6bd4\u8f83\u82f1\u7f8e\u8bae\u4f1a\u79fb\u6c11\u8bdd\u8bed\u7684\u957f\u671f\u6f14\u53d8\uff0c\u63a2\u7a76\u653f\u6cbb\u8bdd\u8bed\u4e2d\u7684\u7acb\u573a\u53d8\u5316\u548c\u53d9\u4e8b\u6846\u67b6\u8f6c\u53d8", "method": "\u4f7f\u7528\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u6807\u6ce8\u8bae\u4f1a\u58f0\u660e\u4e2d\u7684\u79fb\u6c11\u7acb\u573a\uff0c\u7ed3\u5408\u534a\u81ea\u52a8\u5316\u6846\u67b6\u63d0\u53d6\u7ec6\u7c92\u5ea6\u53d9\u4e8b\u6846\u67b6\uff0c\u8fdb\u884c\u8de8\u65f6\u95f4\u548c\u653f\u515a\u7684\u8d8b\u52bf\u5206\u6790", "result": "\u7f8e\u56fd\u8bdd\u8bed\u65e5\u76ca\u6781\u5316\uff0c\u82f1\u56fd\u5404\u515a\u6d3e\u6001\u5ea6\u76f8\u5bf9\u4e00\u81f4\u4f46\u4fdd\u5b88\u515a\u4e0e\u5de5\u515a\u610f\u8bc6\u5f62\u6001\u5dee\u8ddd\u57282025\u5e74\u8fbe\u5230\u6700\u8d1f\u9762\uff1b\u82f1\u56fd\u8bdd\u8bed\u8f6c\u5411\u8fb9\u5883\u7ba1\u63a7\u7b49\u5b89\u5168\u5316\u53d9\u4e8b\uff0c\u793e\u4f1a\u878d\u5408\u7b49\u957f\u671f\u6574\u5408\u6846\u67b6\u51cf\u5c11\uff1b\u79fb\u6c11\u8ba8\u8bba\u4ece\u56fd\u5185\u6cd5\u8f6c\u5411\u56fd\u9645\u6cd5\u548c\u4eba\u6743", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u652f\u6301\u653f\u6cbb\u548c\u5386\u53f2\u8bed\u5883\u4e2d\u53ef\u6269\u5c55\u7684\u7ec6\u7c92\u5ea6\u8bdd\u8bed\u5206\u6790\uff0c\u63ed\u793a\u79fb\u6c11\u8bdd\u8bed\u7684\u957f\u671f\u6f14\u53d8\u8d8b\u52bf\u548c\u53d9\u4e8b\u6846\u67b6\u8f6c\u53d8"}}
{"id": "2509.14233", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14233", "abs": "https://arxiv.org/abs/2509.14233", "authors": ["Alejandro Hern\u00e1ndez-Cano", "Alexander H\u00e4gele", "Allen Hao Huang", "Angelika Romanou", "Antoni-Joan Solergibert", "Barna Pasztor", "Bettina Messmer", "Dhia Garbaya", "Eduard Frank \u010eurech", "Ido Hakimi", "Juan Garc\u00eda Giraldo", "Mete Ismayilzada", "Negar Foroutan", "Skander Moalla", "Tiancheng Chen", "Vinko Sabol\u010dec", "Yixuan Xu", "Michael Aerni", "Badr AlKhamissi", "Ines Altemir Marinas", "Mohammad Hossein Amani", "Matin Ansaripour", "Ilia Badanin", "Harold Benoit", "Emanuela Boros", "Nicholas Browning", "Fabian B\u00f6sch", "Maximilian B\u00f6ther", "Niklas Canova", "Camille Challier", "Clement Charmillot", "Jonathan Coles", "Jan Deriu", "Arnout Devos", "Lukas Drescher", "Daniil Dzenhaliou", "Maud Ehrmann", "Dongyang Fan", "Simin Fan", "Silin Gao", "Miguel Gila", "Mar\u00eda Grandury", "Diba Hashemi", "Alexander Hoyle", "Jiaming Jiang", "Mark Klein", "Andrei Kucharavy", "Anastasiia Kucherenko", "Frederike L\u00fcbeck", "Roman Machacek", "Theofilos Manitaras", "Andreas Marfurt", "Kyle Matoba", "Simon Matrenok", "Henrique Mendonc\u00e7a", "Fawzi Roberto Mohamed", "Syrielle Montariol", "Luca Mouchel", "Sven Najem-Meyer", "Jingwei Ni", "Gennaro Oliva", "Matteo Pagliardini", "Elia Palme", "Andrei Panferov", "L\u00e9o Paoletti", "Marco Passerini", "Ivan Pavlov", "Auguste Poiroux", "Kaustubh Ponkshe", "Nathan Ranchin", "Javi Rando", "Mathieu Sauser", "Jakhongir Saydaliev", "Muhammad Ali Sayfiddinov", "Marian Schneider", "Stefano Schuppli", "Marco Scialanga", "Andrei Semenov", "Kumar Shridhar", "Raghav Singhal", "Anna Sotnikova", "Alexander Sternfeld", "Ayush Kumar Tarun", "Paul Teiletche", "Jannis Vamvas", "Xiaozhe Yao", "Hao Zhao Alexander Ilic", "Ana Klimovic", "Andreas Krause", "Caglar Gulcehre", "David Rosenthal", "Elliott Ash", "Florian Tram\u00e8r", "Joost VandeVondele", "Livio Veraldi", "Martin Rajman", "Thomas Schulthess", "Torsten Hoefler", "Antoine Bosselut", "Martin Jaggi", "Imanol Schlag"], "title": "Apertus: Democratizing Open and Compliant LLMs for Global Language Environments", "comment": null, "summary": "We present Apertus, a fully open suite of large language models (LLMs)\ndesigned to address two systemic shortcomings in today's open model ecosystem:\ndata compliance and multilingual representation. Unlike many prior models that\nrelease weights without reproducible data pipelines or regard for content-owner\nrights, Apertus models are pretrained exclusively on openly available data,\nretroactively respecting robots.txt exclusions and filtering for\nnon-permissive, toxic, and personally identifiable content. To mitigate risks\nof memorization, we adopt the Goldfish objective during pretraining, strongly\nsuppressing verbatim recall of data while retaining downstream task\nperformance. The Apertus models also expand multilingual coverage, training on\n15T tokens from over 1800 languages, with ~40% of pretraining data allocated to\nnon-English content. Released at 8B and 70B scales, Apertus approaches\nstate-of-the-art results among fully open models on multilingual benchmarks,\nrivalling or surpassing open-weight counterparts. Beyond model weights, we\nrelease all scientific artifacts from our development cycle with a permissive\nlicense, including data preparation scripts, checkpoints, evaluation suites,\nand training code, enabling transparent audit and extension.", "AI": {"tldr": "Apertus\u662f\u4e00\u4e2a\u5b8c\u5168\u5f00\u6e90\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5957\u4ef6\uff0c\u4e13\u6ce8\u4e8e\u6570\u636e\u5408\u89c4\u6027\u548c\u591a\u8bed\u8a00\u8868\u793a\uff0c\u4f7f\u7528\u516c\u5f00\u53ef\u7528\u6570\u636e\u8bad\u7ec3\uff0c\u91c7\u7528Goldfish\u76ee\u6807\u6291\u5236\u8bb0\u5fc6\u5316\uff0c\u652f\u63011800\u591a\u79cd\u8bed\u8a00\uff0c\u57288B\u548c70B\u89c4\u6a21\u4e0a\u8fbe\u5230\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5f53\u524d\u5f00\u6e90\u6a21\u578b\u751f\u6001\u7cfb\u7edf\u4e2d\u6570\u636e\u5408\u89c4\u6027\u4e0d\u8db3\u548c\u591a\u8bed\u8a00\u4ee3\u8868\u6027\u4e0d\u591f\u7684\u95ee\u9898\uff0c\u907f\u514d\u4f7f\u7528\u672a\u7ecf\u6388\u6743\u7684\u5185\u5bb9\uff0c\u786e\u4fdd\u6a21\u578b\u8bad\u7ec3\u7684\u900f\u660e\u5ea6\u548c\u5408\u6cd5\u6027\u3002", "method": "\u4f7f\u7528\u5b8c\u5168\u516c\u5f00\u53ef\u7528\u7684\u6570\u636e\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u5c0a\u91cdrobots.txt\u6392\u9664\u89c4\u5219\uff0c\u8fc7\u6ee4\u975e\u8bb8\u53ef\u3001\u6709\u6bd2\u548c\u4e2a\u4eba\u8eab\u4efd\u4fe1\u606f\u5185\u5bb9\uff1b\u91c7\u7528Goldfish\u76ee\u6807\u6291\u5236\u6570\u636e\u8bb0\u5fc6\uff1b\u5728\u591a\u8bed\u8a00\u6570\u636e\u4e0a\u8bad\u7ec3\uff0815T tokens\uff0c1800+\u8bed\u8a00\uff0c40%\u975e\u82f1\u8bed\u5185\u5bb9\uff09\u3002", "result": "Apertus\u6a21\u578b\u5728\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6216\u8d85\u8d8a\u540c\u7c7b\u5f00\u6e90\u6743\u91cd\u6a21\u578b\u7684\u5148\u8fdb\u6027\u80fd\uff0c8B\u548c70B\u89c4\u6a21\u6a21\u578b\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "Apertus\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b8c\u5168\u900f\u660e\u3001\u5408\u89c4\u7684\u5f00\u6e90LLM\u89e3\u51b3\u65b9\u6848\uff0c\u4e0d\u4ec5\u53d1\u5e03\u6a21\u578b\u6743\u91cd\uff0c\u8fd8\u5305\u542b\u5b8c\u6574\u7684\u6570\u636e\u5904\u7406\u811a\u672c\u3001\u68c0\u67e5\u70b9\u3001\u8bc4\u4f30\u5957\u4ef6\u548c\u8bad\u7ec3\u4ee3\u7801\uff0c\u652f\u6301\u5ba1\u8ba1\u548c\u6269\u5c55\u3002"}}
