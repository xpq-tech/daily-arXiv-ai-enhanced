<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 46]
- [cs.AI](#cs.AI) [Total: 29]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Understanding and Enhancing Mamba-Transformer Hybrids for Memory Recall and Language Modeling](https://arxiv.org/abs/2510.26912)
*Hyunji Lee,Wenhao Yu,Hongming Zhang,Kaixin Ma,Jiyeon Kim,Dong Yu,Minjoon Seo*

Main category: cs.CL

TL;DR: 分析了SSM与注意力机制混合模型的架构设计，发现序列混合在短上下文表现更好，并行混合在长上下文更有效，并提出通过数据增强训练进一步提升召回能力的方法。


<details>
  <summary>Details</summary>
Motivation: 虽然结合状态空间模型和注意力机制的混合模型表现出色，但其架构设计选择仍缺乏深入理解，需要分析不同集成方式对性能的影响。

Method: 分析序列和并行两种SSM与注意力层集成方式，并引入基于数据增强的持续训练方法，通过增加改写数据集来增强模型召回能力。

Result: 序列混合在短上下文表现更优，并行混合在长上下文更有效；数据增强训练方法能显著提升召回能力，且优于架构修改方法。

Conclusion: 为混合SSM-注意力模型提供了深入理解，并为针对不同用例设计架构提供了实用指导。

Abstract: Hybrid models that combine state space models (SSMs) with attention
mechanisms have shown strong performance by leveraging the efficiency of SSMs
and the high recall ability of attention. However, the architectural design
choices behind these hybrid models remain insufficiently understood. In this
work, we analyze hybrid architectures through the lens of memory utilization
and overall performance, and propose a complementary method to further enhance
their effectiveness. We first examine the distinction between sequential and
parallel integration of SSM and attention layers. Our analysis reveals several
interesting findings, including that sequential hybrids perform better on
shorter contexts, whereas parallel hybrids are more effective for longer
contexts. We also introduce a data-centric approach of continually training on
datasets augmented with paraphrases, which further enhances recall while
preserving other capabilities. It generalizes well across different base models
and outperforms architectural modifications aimed at enhancing recall. Our
findings provide a deeper understanding of hybrid SSM-attention models and
offer practical guidance for designing architectures tailored to various use
cases. Our findings provide a deeper understanding of hybrid SSM-attention
models and offer practical guidance for designing architectures tailored to
various use cases.

</details>


### [2] [Frame Semantic Patterns for Identifying Underreporting of Notifiable Events in Healthcare: The Case of Gender-Based Violence](https://arxiv.org/abs/2510.26969)
*Lívia Dutra,Arthur Lorenzi,Laís Berno,Franciany Campos,Karoline Biscardi,Kenneth Brown,Marcelo Viridiano,Frederico Belcavello,Ely Matos,Olívia Guaranha,Erik Santos,Sofia Reinach,Tiago Timponi Torrent*

Main category: cs.CL

TL;DR: 提出了一种基于语义框架的方法来识别医疗记录中的应报告事件，特别是针对性别暴力事件的漏报问题，在2100万句巴西葡萄牙语医疗记录上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决电子医疗记录中性别暴力事件漏报的问题，通过自动化方法提高公共卫生监测效率。

Method: 使用语义框架定义细粒度模式，在非结构化医疗记录文本中搜索这些模式，构建了8个模式在2100万句语料上进行识别。

Result: 方法有效识别暴力报告，精度达到0.726，验证了方法的鲁棒性。

Conclusion: 该方法作为透明、高效、低碳、语言无关的流程，可轻松适应其他健康监测场景，促进NLP在公共卫生系统中的伦理和可解释使用。

Abstract: We introduce a methodology for the identification of notifiable events in the
domain of healthcare. The methodology harnesses semantic frames to define
fine-grained patterns and search them in unstructured data, namely, open-text
fields in e-medical records. We apply the methodology to the problem of
underreporting of gender-based violence (GBV) in e-medical records produced
during patients' visits to primary care units. A total of eight patterns are
defined and searched on a corpus of 21 million sentences in Brazilian
Portuguese extracted from e-SUS APS. The results are manually evaluated by
linguists and the precision of each pattern measured. Our findings reveal that
the methodology effectively identifies reports of violence with a precision of
0.726, confirming its robustness. Designed as a transparent, efficient,
low-carbon, and language-agnostic pipeline, the approach can be easily adapted
to other health surveillance contexts, contributing to the broader, ethical,
and explainable use of NLP in public health systems.

</details>


### [3] [Overview of the MEDIQA-OE 2025 Shared Task on Medical Order Extraction from Doctor-Patient Consultations](https://arxiv.org/abs/2510.26974)
*Jean-Philippe Corbeil,Asma Ben Abacha,Jerome Tremblay,Phillip Swazinna,Akila Jeeson Daniel,Miguel Del-Agua,Francois Beaulieu*

Main category: cs.CL

TL;DR: MEDIQA-OE 2025是首个从医患对话中提取医疗指令的挑战任务，旨在减轻临床医生的文档负担并改善患者护理。


<details>
  <summary>Details</summary>
Motivation: 虽然临床文档越来越多地使用自动语音识别和摘要，但将对话转化为可操作的医疗指令仍未得到充分探索，这能显著减轻临床医生的文档负担并直接影响下游患者护理。

Method: 引入了MEDIQA-OE 2025共享任务，六个团队参与并尝试了多种方法，包括闭源和开源的大语言模型。

Result: 共享任务成功举办，参与者探索了广泛的方法，并展示了从医患对话中提取医疗指令的可行性。

Conclusion: MEDIQA-OE任务为从医患对话中自动提取医疗指令提供了首个基准，展示了该领域的发展潜力。

Abstract: Clinical documentation increasingly uses automatic speech recognition and
summarization, yet converting conversations into actionable medical orders for
Electronic Health Records remains unexplored. A solution to this problem can
significantly reduce the documentation burden of clinicians and directly impact
downstream patient care. We introduce the MEDIQA-OE 2025 shared task, the first
challenge on extracting medical orders from doctor-patient conversations. Six
teams participated in the shared task and experimented with a broad range of
approaches, and both closed- and open-weight large language models (LLMs). In
this paper, we describe the MEDIQA-OE task, dataset, final leaderboard ranking,
and participants' solutions.

</details>


### [4] [Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services](https://arxiv.org/abs/2510.27016)
*Jayden Serenari,Stephen Lee*

Main category: cs.CL

TL;DR: 提出LOPSIDED框架，通过语义感知的隐私保护机制，在保持对话上下文完整性的同时保护用户敏感PII数据。


<details>
  <summary>Details</summary>
Motivation: 随着对话AI系统的普及，用户在与大语言模型交互时可能泄露个人敏感信息，存在隐私泄露风险。

Method: 使用动态伪名化技术，将用户提示中的敏感PII实体替换为语义一致的伪名，模型生成响应后再自动去伪名化。

Result: 在ShareGPT真实对话数据集上的评估显示，LOPSIDED相比基线技术将语义效用错误减少了5倍，同时增强了隐私保护。

Conclusion: LOPSIDED框架有效解决了LLM使用中的隐私泄露问题，在保持响应质量的同时提供了强大的隐私保护能力。

Abstract: With the increasing use of conversational AI systems, there is growing
concern over privacy leaks, especially when users share sensitive personal data
in interactions with Large Language Models (LLMs). Conversations shared with
these models may contain Personally Identifiable Information (PII), which, if
exposed, could lead to security breaches or identity theft. To address this
challenge, we present the Local Optimizations for Pseudonymization with
Semantic Integrity Directed Entity Detection (LOPSIDED) framework, a
semantically-aware privacy agent designed to safeguard sensitive PII data when
using remote LLMs. Unlike prior work that often degrade response quality, our
approach dynamically replaces sensitive PII entities in user prompts with
semantically consistent pseudonyms, preserving the contextual integrity of
conversations. Once the model generates its response, the pseudonyms are
automatically depseudonymized, ensuring the user receives an accurate,
privacy-preserving output. We evaluate our approach using real-world
conversations sourced from ShareGPT, which we further augment and annotate to
assess whether named entities are contextually relevant to the model's
response. Our results show that LOPSIDED reduces semantic utility errors by a
factor of 5 compared to baseline techniques, all while enhancing privacy.

</details>


### [5] [Kad: A Framework for Proxy-based Test-time Alignment with Knapsack Approximation Deferral](https://arxiv.org/abs/2510.27017)
*Ayoub Hammal,Pierre Zweigenbaum,Caio Corro*

Main category: cs.CL

TL;DR: 提出了一种基于代理的测试时对齐方法，使用小型对齐模型指导大型语言模型，通过令牌级级联方法减少对齐计算成本


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然预训练阶段已学习大部分生成能力，但仍需对齐以适应下游任务需求，而随着模型规模扩大，对齐过程的计算成本急剧增加

Method: 采用基于代理的测试时对齐方法，将令牌特定延迟规则简化为0-1背包问题，推导出最优延迟决策的原始和对偶近似

Result: 实验证明该方法在任务性能和推测解码速度方面均带来显著优势

Conclusion: 所提出的代理测试时对齐方法能有效降低大型语言模型对齐的计算成本，同时保持性能

Abstract: Several previous works concluded that the largest part of generation
capabilities of large language models (LLM) are learned (early) during
pre-training. However, LLMs still require further alignment to adhere to
downstream task requirements and stylistic preferences, among other desired
properties. As LLMs continue to scale in terms of size, the computational cost
of alignment procedures increase prohibitively. In this work, we propose a
novel approach to circumvent these costs via proxy-based test-time alignment,
i.e. using guidance from a small aligned model. Our approach can be described
as token-specific cascading method, where the token-specific deferral rule is
reduced to 0-1 knapsack problem. In this setting, we derive primal and dual
approximations of the optimal deferral decision. We experimentally show the
benefits of our method both in task performance and speculative decoding speed.

</details>


### [6] [Elastic Architecture Search for Efficient Language Models](https://arxiv.org/abs/2510.27037)
*Shang Wang*

Main category: cs.CL

TL;DR: 提出了一种名为弹性语言模型（ELM）的新型神经架构搜索方法，专门针对紧凑语言模型优化，通过灵活的搜索空间和动态模块调整维度及注意力头数，显著提升搜索效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 随着大型预训练语言模型在自然语言理解任务中日益重要，其巨大的计算和内存需求引发了经济和环境担忧，需要开发更高效的紧凑模型。

Method: 扩展现有NAS方法，引入包含高效transformer块和动态维度/注意力头数调整模块的灵活搜索空间，并提出新颖的知识蒸馏损失来保持各块特征。

Result: 在掩码语言建模和因果语言建模任务上的实验表明，ELM发现的模型显著优于现有方法。

Conclusion: ELM方法通过改进的搜索空间和知识蒸馏策略，能够更有效地探索模型架构，为开发高效紧凑的语言模型提供了有前景的解决方案。

Abstract: As large pre-trained language models become increasingly critical to natural
language understanding (NLU) tasks, their substantial computational and memory
requirements have raised significant economic and environmental concerns.
Addressing these challenges, this paper introduces the Elastic Language Model
(ELM), a novel neural architecture search (NAS) method optimized for compact
language models. ELM extends existing NAS approaches by introducing a flexible
search space with efficient transformer blocks and dynamic modules for
dimension and head number adjustment. These innovations enhance the efficiency
and flexibility of the search process, which facilitates more thorough and
effective exploration of model architectures. We also introduce novel knowledge
distillation losses that preserve the unique characteristics of each block, in
order to improve the discrimination between architectural choices during the
search process. Experiments on masked language modeling and causal language
modeling tasks demonstrate that models discovered by ELM significantly
outperform existing methods.

</details>


### [7] [Dataset Creation and Baseline Models for Sexism Detection in Hausa](https://arxiv.org/abs/2510.27038)
*Fatima Adam Muhammad,Shamsuddeen Muhammad Hassan,Isa Inuwa-Dutse*

Main category: cs.CL

TL;DR: 该研究创建了首个豪萨语性别歧视检测数据集，通过社区参与和用户研究收集数据，并评估了传统机器学习模型和预训练多语言模型在豪萨语性别歧视检测中的表现。


<details>
  <summary>Details</summary>
Motivation: 在线平台助长了各种形式的性别歧视，而低资源语言如豪萨语由于语言资源有限和文化差异，性别歧视检测进展缓慢，需要开发有效的检测和缓解策略。

Method: 通过社区参与、定性编码和数据增强开发豪萨语性别歧视数据集；进行两阶段用户研究（n=66）探索性别歧视在日常话语中的定义和表达；实验传统机器学习分类器和预训练多语言模型，评估少样本学习效果。

Result: 研究发现在捕捉文化细微差别方面存在挑战，特别是在寻求澄清和习语表达方面，这些情况下容易出现许多误报。

Conclusion: 该研究强调了在低资源语言中检测性别歧视时考虑文化细微差别的重要性，并展示了社区参与方法在开发相关数据集方面的价值。

Abstract: Sexism reinforces gender inequality and social exclusion by perpetuating
stereotypes, bias, and discriminatory norms. Noting how online platforms enable
various forms of sexism to thrive, there is a growing need for effective sexism
detection and mitigation strategies. While computational approaches to sexism
detection are widespread in high-resource languages, progress remains limited
in low-resource languages where limited linguistic resources and cultural
differences affect how sexism is expressed and perceived. This study introduces
the first Hausa sexism detection dataset, developed through community
engagement, qualitative coding, and data augmentation. For cultural nuances and
linguistic representation, we conducted a two-stage user study (n=66) involving
native speakers to explore how sexism is defined and articulated in everyday
discourse. We further experiment with both traditional machine learning
classifiers and pre-trained multilingual language models and evaluating the
effectiveness few-shot learning in detecting sexism in Hausa. Our findings
highlight challenges in capturing cultural nuance, particularly with
clarification-seeking and idiomatic expressions, and reveal a tendency for many
false positives in such cases.

</details>


### [8] [Quantitative Intertextuality from the Digital Humanities Perspective: A Survey](https://arxiv.org/abs/2510.27045)
*Siyu Duan*

Main category: cs.CL

TL;DR: 这篇论文提供了定量互文性研究的路线图，总结了数据、方法和应用，回顾了从统计到深度学习的各种方法，并展望了互文性在AI与人文科学交叉研究中的广阔前景。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理技术的进步，互文性研究进入了定量时代。本文旨在为这一新兴领域提供一个系统性的综述和路线图，帮助研究者了解当前的研究现状和未来发展方向。

Method: 基于多语言和多主题的数据，综述了从传统统计方法到深度学习方法的各种定量互文性研究方法，并总结了相关的平台工具。

Result: 总结了定量互文性研究在人文社会科学研究中的应用，展示了该领域从数据、方法到应用平台的全貌。

Conclusion: 随着计算机技术的进步，可以预期更精确、多样化和大规模的互文性研究。互文性在连接AI与人文科学的跨学科研究中具有广阔的应用前景。

Abstract: The connection between texts is referred to as intertextuality in literary
theory, which served as an important theoretical basis in many digital
humanities studies. Over the past decade, advancements in natural language
processing have ushered intertextuality studies into the quantitative age.
Large-scale intertextuality research based on cutting-edge methods has
continuously emerged. This paper provides a roadmap for quantitative
intertextuality studies, summarizing their data, methods, and applications.
Drawing on data from multiple languages and topics, this survey reviews methods
from statistics to deep learning. It also summarizes their applications in
humanities and social sciences research and the associated platform tools.
Driven by advances in computer technology, more precise, diverse, and
large-scale intertext studies can be anticipated. Intertextuality holds promise
for broader application in interdisciplinary research bridging AI and the
humanities.

</details>


### [9] [Recursive numeral systems are highly regular and easy to process](https://arxiv.org/abs/2510.27049)
*Ponrawee Prasertsom,Andrea Silvi,Jennifer Culbertson,Moa Johansson,Devdatt Dubhashi,Kenny Smith*

Main category: cs.CL

TL;DR: 本文提出基于最小描述长度(MDL)的方法来衡量数字系统的规律性和处理复杂度，认为递归数字系统在这两方面达到最优，而非之前的词典大小与形态句法复杂度的权衡。


<details>
  <summary>Details</summary>
Motivation: 先前研究认为递归数字系统优化了词典大小与形态句法复杂度的权衡，但需要人为约束来排除不自然系统。本文认为问题在于忽视了规律性这一人类语法的核心特征。

Method: 采用最小描述长度(MDL)方法，提出衡量规律性和处理复杂度的新指标，分析自然语言数字系统与人工构造系统的差异。

Result: MDL方法能更好地区分自然系统与人工系统，包括先前研究中"最优"的递归数字系统，且先前文献中的人为约束自然地从规律性中推导出来。

Conclusion: 在语言最优性研究中，需要跨形式集合地考虑规律性，MDL方法为理解递归数字系统的效率提供了更好的框架。

Abstract: Previous work has argued that recursive numeral systems optimise the
trade-off between lexicon size and average morphosyntatic complexity (Deni\'c
and Szymanik, 2024). However, showing that only natural-language-like systems
optimise this tradeoff has proven elusive, and the existing solution has relied
on ad-hoc constraints to rule out unnatural systems (Yang and Regier, 2025).
Here, we argue that this issue arises because the proposed trade-off has
neglected regularity, a crucial aspect of complexity central to human grammars
in general. Drawing on the Minimum Description Length (MDL) approach, we
propose that recursive numeral systems are better viewed as efficient with
regard to their regularity and processing complexity. We show that our
MDL-based measures of regularity and processing complexity better capture the
key differences between attested, natural systems and unattested but possible
ones, including "optimal" recursive numeral systems from previous work, and
that the ad-hoc constraints from previous literature naturally follow from
regularity. Our approach highlights the need to incorporate regularity across
sets of forms in studies that attempt to measure and explain optimality in
language.

</details>


### [10] [VISTA Score: Verification In Sequential Turn-based Assessment](https://arxiv.org/abs/2510.27052)
*Ashley Lewis,Andrew Perrault,Eric Fosler-Lussier,Michael White*

Main category: cs.CL

TL;DR: VISTA是一个评估对话系统事实性的框架，通过声明级验证和序列一致性跟踪来检测多轮对话中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有的事实性评估指标要么评估孤立回复，要么将不可验证内容视为错误，限制了在多轮对话中的应用。幻觉问题仍是对话AI系统在需要事实可靠性场景中部署的主要障碍。

Method: VISTA将每个助手回复分解为原子事实声明，根据可信来源和对话历史进行验证，并将不可验证陈述分类为主观、矛盾、缺乏证据或弃权。

Result: 在8个大语言模型和4个对话事实性基准测试中，VISTA在幻觉检测方面显著优于FACTSCORE和LLM-as-Judge基线。人工评估证实VISTA的分解方法提高了标注者一致性并揭示了现有基准中的不一致性。

Conclusion: 通过将事实性建模为对话的动态属性，VISTA为对话系统提供了一个更透明、更符合人类认知的真实性衡量标准。

Abstract: Hallucination--defined here as generating statements unsupported or
contradicted by available evidence or conversational context--remains a major
obstacle to deploying conversational AI systems in settings that demand factual
reliability. Existing metrics either evaluate isolated responses or treat
unverifiable content as errors, limiting their use for multi-turn dialogue. We
introduce VISTA (Verification In Sequential Turn-based Assessment), a framework
for evaluating conversational factuality through claim-level verification and
sequential consistency tracking. VISTA decomposes each assistant turn into
atomic factual claims, verifies them against trusted sources and dialogue
history, and categorizes unverifiable statements (subjective, contradicted,
lacking evidence, or abstaining). Across eight large language models and four
dialogue factuality benchmarks (AIS, BEGIN, FAITHDIAL, and FADE), VISTA
substantially improves hallucination detection over FACTSCORE and LLM-as-Judge
baselines. Human evaluation confirms that VISTA's decomposition improves
annotator agreement and reveals inconsistencies in existing benchmarks. By
modeling factuality as a dynamic property of conversation, VISTA offers a more
transparent, human-aligned measure of truthfulness in dialogue systems.

</details>


### [11] [LLM-Centric RAG with Multi-Granular Indexing and Confidence Constraints](https://arxiv.org/abs/2510.27054)
*Xiaofan Guo,Yaxuan Luan,Yue Kang,Xiangchen Song,Jinxu Guo*

Main category: cs.CL

TL;DR: 提出了一种结合多粒度内存索引和不确定性估计的置信度控制方法，解决复杂知识环境下检索增强生成覆盖不足、结果不稳定和可靠性有限的问题。


<details>
  <summary>Details</summary>
Motivation: 解决复杂知识环境中检索增强生成存在的覆盖不足、结果不稳定和可靠性有限的问题，提升模型在复杂上下文中的可靠性和可控性。

Method: 构建分层内存结构，将知识表示划分为不同粒度级别，实现从局部细节到全局上下文的动态索引和检索；引入不确定性估计机制，在生成过程中显式约束和过滤低置信度路径；优化目标包括生成损失、熵约束和方差正则化。

Result: 在QA准确性、检索召回率、排序质量和事实一致性方面优于现有模型，通过敏感性测试和对比分析验证了方法在不同场景下的稳定性和鲁棒性。

Conclusion: 多粒度索引与置信度控制的结合为检索增强生成提供了新的技术路径，并为提升大模型在复杂上下文中的可靠性和可控性提供了实践证据。

Abstract: This paper addresses the issues of insufficient coverage, unstable results,
and limited reliability in retrieval-augmented generation under complex
knowledge environments, and proposes a confidence control method that
integrates multi-granularity memory indexing with uncertainty estimation. The
method builds a hierarchical memory structure that divides knowledge
representations into different levels of granularity, enabling dynamic indexing
and retrieval from local details to global context, and thus establishing
closer semantic connections between retrieval and generation. On this basis, an
uncertainty estimation mechanism is introduced to explicitly constrain and
filter low-confidence paths during the generation process, allowing the model
to maintain information coverage while effectively suppressing noise and false
content. The overall optimization objective consists of generation loss,
entropy constraints, and variance regularization, forming a unified confidence
control framework. In the experiments, comprehensive sensitivity tests and
comparative analyses were designed, covering hyperparameters, environmental
conditions, and data structures, to verify the stability and robustness of the
proposed method across different scenarios. The results show that the method
achieves superior performance over existing models in QA accuracy, retrieval
recall, ranking quality, and factual consistency, demonstrating the
effectiveness of combining multi-granularity indexing with confidence control.
This study not only provides a new technical pathway for retrieval-augmented
generation but also offers practical evidence for improving the reliability and
controllability of large models in complex contexts.

</details>


### [12] [Detecting Data Contamination in LLMs via In-Context Learning](https://arxiv.org/abs/2510.27055)
*Michał Zawalski,Meriem Boubdir,Klaudia Bałazy,Besmira Nushi,Pablo Ribalta*

Main category: cs.CL

TL;DR: CoDeC是一种通过上下文学习检测大语言模型训练数据污染的方法，通过测量上下文学习对模型性能的影响来区分记忆数据和未见数据。


<details>
  <summary>Details</summary>
Motivation: 需要检测和量化大语言模型中的训练数据污染问题，特别是对于训练语料未公开的模型，识别数据记忆现象。

Method: 利用上下文学习对模型置信度的影响：上下文示例通常提升未见数据集的置信度，但对于训练过的数据集可能因破坏记忆模式而降低置信度。

Result: CoDeC产生可解释的污染分数，能清晰区分已见和未见数据集，并在未公开训练语料的开放权重模型中揭示了强烈记忆证据。

Conclusion: 该方法简单、自动化、模型和数据集无关，易于与基准评估集成，为训练数据污染检测提供了实用解决方案。

Abstract: We present Contamination Detection via Context (CoDeC), a practical and
accurate method to detect and quantify training data contamination in large
language models. CoDeC distinguishes between data memorized during training and
data outside the training distribution by measuring how in-context learning
affects model performance. We find that in-context examples typically boost
confidence for unseen datasets but may reduce it when the dataset was part of
training, due to disrupted memorization patterns. Experiments show that CoDeC
produces interpretable contamination scores that clearly separate seen and
unseen datasets, and reveals strong evidence of memorization in open-weight
models with undisclosed training corpora. The method is simple, automated, and
both model- and dataset-agnostic, making it easy to integrate with benchmark
evaluations.

</details>


### [13] [Contrastive Knowledge Transfer and Robust Optimization for Secure Alignment of Large Language Models](https://arxiv.org/abs/2510.27077)
*Jiasen Zheng,Huajun Zhang,Xu Yan,Ran Hao,Chong Peng*

Main category: cs.CL

TL;DR: 提出了一种结合对比蒸馏与噪声鲁棒训练的微调方法，通过冻结主干模型并转移教师模型的知识边界，提升语言模型的安全对齐能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决大规模语言模型在安全对齐和鲁棒性方面的局限性，构建更安全可信的对齐机制。

Method: 冻结主干模型，通过蒸馏损失、鲁棒性损失和正则化项的统一优化目标，结合对比蒸馏和噪声鲁棒训练，在训练中引入噪声扰动和鲁棒优化约束。

Result: 在知识转移、鲁棒性和整体安全性方面显著优于现有基线方法，在多个关键指标上达到最佳性能。

Conclusion: 不仅丰富了参数高效微调的理论体系，还为构建更安全可信的对齐机制提供了新的解决方案。

Abstract: This paper addresses the limitations of large-scale language models in safety
alignment and robustness by proposing a fine-tuning method that combines
contrastive distillation with noise-robust training. The method freezes the
backbone model and transfers the knowledge boundaries of the teacher model to
the student model through distillation, thereby improving semantic consistency
and alignment accuracy. At the same time, noise perturbations and robust
optimization constraints are introduced during training to ensure that the
model maintains stable predictive outputs under noisy and uncertain inputs. The
overall framework consists of distillation loss, robustness loss, and a
regularization term, forming a unified optimization objective that balances
alignment ability with resistance to interference. To systematically validate
its effectiveness, the study designs experiments from multiple perspectives,
including distillation weight sensitivity, stability analysis under computation
budgets and mixed-precision environments, and the impact of data noise and
distribution shifts on model performance. Results show that the method
significantly outperforms existing baselines in knowledge transfer, robustness,
and overall safety, achieving the best performance across several key metrics.
This work not only enriches the theoretical system of parameter-efficient
fine-tuning but also provides a new solution for building safer and more
trustworthy alignment mechanisms.

</details>


### [14] [Characterizing Selective Refusal Bias in Large Language Models](https://arxiv.org/abs/2510.27087)
*Adel Khorramrouz,Sharon Levy*

Main category: cs.CL

TL;DR: 研究发现LLM安全护栏存在选择性拒绝偏见，对不同人口群体拒绝生成有害内容的程度不一致，导致新的偏见问题。


<details>
  <summary>Details</summary>
Motivation: LLM安全护栏旨在防止大规模生成有害内容，但可能无意中引入或反映新的偏见，因为LLM可能拒绝针对某些人口群体而非其他群体生成有害内容。

Method: 通过分析针对个体和交叉人口群体的拒绝率、LLM响应类型和生成拒绝的长度来探索选择性拒绝偏见。

Result: 结果显示在性别、性取向、国籍和宗教属性上存在选择性拒绝偏见证据。通过间接攻击测试了额外的安全隐患。

Conclusion: 强调需要在不同人口群体间实现更公平和稳健的安全护栏性能。

Abstract: Safety guardrails in large language models(LLMs) are developed to prevent
malicious users from generating toxic content at a large scale. However, these
measures can inadvertently introduce or reflect new biases, as LLMs may refuse
to generate harmful content targeting some demographic groups and not others.
We explore this selective refusal bias in LLM guardrails through the lens of
refusal rates of targeted individual and intersectional demographic groups,
types of LLM responses, and length of generated refusals. Our results show
evidence of selective refusal bias across gender, sexual orientation,
nationality, and religion attributes. This leads us to investigate additional
safety implications via an indirect attack, where we target previously refused
groups. Our findings emphasize the need for more equitable and robust
performance in safety guardrails across demographic groups.

</details>


### [15] [Rating Roulette: Self-Inconsistency in LLM-As-A-Judge Frameworks](https://arxiv.org/abs/2510.27106)
*Rajarshi Haldar,Julia Hockenmaier*

Main category: cs.CL

TL;DR: LLM作为NLG评估工具存在评分不一致性问题，但通过适当指导仍可使用


<details>
  <summary>Details</summary>
Motivation: 随着NLG广泛应用，其评估变得困难。LLM评估虽比传统指标更符合人类偏好，但存在评分不一致性问题

Method: 通过实验量化LLM评估在不同NLG任务和基准中的评分不一致性，并探索适当使用指南

Result: LLM评估者在不同运行中评分可靠性低，导致评分不一致甚至随意，难以衡量其判断质量

Conclusion: 尽管LLM评估存在不一致性，但通过谨慎使用和适当指导仍可发挥作用

Abstract: As Natural Language Generation (NLG) continues to be widely adopted, properly
assessing it has become quite difficult. Lately, using large language models
(LLMs) for evaluating these generations has gained traction, as they tend to
align more closely with human preferences than conventional n-gram or
embedding-based metrics. In our experiments, we show that LLM judges have low
intra-rater reliability in their assigned scores across different runs. This
variance makes their ratings inconsistent, almost arbitrary in the worst case,
making it difficult to measure how good their judgments actually are. We
quantify this inconsistency across different NLG tasks and benchmarks and see
if judicious use of LLM judges can still be useful following proper guidelines.

</details>


### [16] [Probability Distributions Computed by Hard-Attention Transformers](https://arxiv.org/abs/2510.27118)
*Andy Yang,Anej Svete,Jiaoda Li,Anthony Widjaja Lin,Jonathan Rawski,Ryan Cotterell,David Chiang*

Main category: cs.CL

TL;DR: 本文分析了Transformer语言模型在自回归概率生成模式下的表达能力，发现自回归和概率化会改变其表达能力特征。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer表达能力研究主要关注其作为语言识别器的能力，但实际应用中Transformer主要作为自回归概率语言模型使用，需要研究其在这种使用方式下的表达能力。

Method: 通过理论分析，比较Transformer作为语言识别器和语言模型时的表达能力差异，特别关注自回归和概率化对表达能力的影响。

Result: 研究发现：1）使Transformer语言识别器自回归化有时能增强其表达能力；2）概率化会打破在非概率情况下成立的等价关系。

Conclusion: 本文揭示了Transformer在作为语言模型使用时表达能力的独特特征，为理解其实际应用能力提供了理论依据。

Abstract: Most expressivity results for transformers treat them as language recognizers
(which accept or reject strings), and not as they are used in practice, as
language models (which generate strings autoregressively and
probabilistically). Here, we characterize the probability distributions that
transformer language models can express. We show that making transformer
language recognizers autoregressive can sometimes increase their expressivity,
and that making them probabilistic can break equivalences that hold in the
non-probabilistic case. Our overall contribution is to tease apart what
functions transformers are capable of expressing, in their most common use-case
as language models.

</details>


### [17] [Simple Additions, Substantial Gains: Expanding Scripts, Languages, and Lineage Coverage in URIEL+](https://arxiv.org/abs/2510.27183)
*Mason Shipton,York Hay Ng,Aditya Khan,Phuong Hanh Hoang,Xiang Lu,A. Seza Doğruöz,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 本文扩展了URIEL+语言知识库，通过添加文字向量、整合Glottolog语言数据库和扩展谱系插补，显著减少了数据稀疏性，提高了对低资源语言的支持能力。


<details>
  <summary>Details</summary>
Motivation: URIEL+语言知识库存在数据稀疏问题，包括缺失特征类型、不完整的语言条目和有限的谱系覆盖，这限制了其在跨语言迁移特别是低资源语言支持方面的实用性。

Method: 1) 为7,488种语言引入文字向量表示书写系统属性；2) 整合Glottolog添加18,710种额外语言；3) 为26,449种语言扩展谱系插补，在谱系间传播类型学和文字特征。

Result: 文字向量特征稀疏性减少14%，语言覆盖增加最多19,015种语言（增长1,007%），插补质量指标提升最多33%。在跨语言迁移任务中，某些设置下性能提升达6%。

Conclusion: 这些扩展使URIEL+更加完整和包容，更好地支持多语言研究，特别是对低资源语言的跨语言迁移任务。

Abstract: The URIEL+ linguistic knowledge base supports multilingual research by
encoding languages through geographic, genetic, and typological vectors.
However, data sparsity remains prevalent, in the form of missing feature types,
incomplete language entries, and limited genealogical coverage. This limits the
usefulness of URIEL+ in cross-lingual transfer, particularly for supporting
low-resource languages. To address this sparsity, this paper extends URIEL+
with three contributions: introducing script vectors to represent writing
system properties for 7,488 languages, integrating Glottolog to add 18,710
additional languages, and expanding lineage imputation for 26,449 languages by
propagating typological and script features across genealogies. These additions
reduce feature sparsity by 14% for script vectors, increase language coverage
by up to 19,015 languages (1,007%), and improve imputation quality metrics by
up to 33%. Our benchmark on cross-lingual transfer tasks (oriented around
low-resource languages) shows occasionally divergent performance compared to
URIEL+, with performance gains up to 6% in certain setups. Our advances make
URIEL+ more complete and inclusive for multilingual research.

</details>


### [18] [MemeArena: Automating Context-Aware Unbiased Evaluation of Harmfulness Understanding for Multimodal Large Language Models](https://arxiv.org/abs/2510.27196)
*Zixin Chen,Hongzhan Lin,Kaixin Li,Ziyang Luo,Yayue Deng,Jing Ma*

Main category: cs.CL

TL;DR: 提出了MemeArena评估框架，通过基于代理的竞技场式评估来评估多模态大语言模型对有害多模态内容的理解能力，减少评估偏见并更贴近人类偏好。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法主要关注二元分类任务的检测准确率，无法反映多模态有害性在不同上下文中的深度解释细微差别。

Method: 构建基于代理的竞技场式评估框架，模拟多样化解释上下文来制定评估任务，整合不同观点并通过评估者达成共识进行公平比较。

Result: 实验表明该框架有效减少了评估偏见，判断结果与人类偏好高度一致，为多模态有害性理解提供了可靠全面的评估见解。

Conclusion: MemeArena框架为多模态大语言模型在多模态有害性理解方面的评估提供了更可靠和全面的方法。

Abstract: The proliferation of memes on social media necessitates the capabilities of
multimodal Large Language Models (mLLMs) to effectively understand multimodal
harmfulness. Existing evaluation approaches predominantly focus on mLLMs'
detection accuracy for binary classification tasks, which often fail to reflect
the in-depth interpretive nuance of harmfulness across diverse contexts. In
this paper, we propose MemeArena, an agent-based arena-style evaluation
framework that provides a context-aware and unbiased assessment for mLLMs'
understanding of multimodal harmfulness. Specifically, MemeArena simulates
diverse interpretive contexts to formulate evaluation tasks that elicit
perspective-specific analyses from mLLMs. By integrating varied viewpoints and
reaching consensus among evaluators, it enables fair and unbiased comparisons
of mLLMs' abilities to interpret multimodal harmfulness. Extensive experiments
demonstrate that our framework effectively reduces the evaluation biases of
judge agents, with judgment results closely aligning with human preferences,
offering valuable insights into reliable and comprehensive mLLM evaluations in
multimodal harmfulness understanding. Our code and data are publicly available
at https://github.com/Lbotirx/MemeArena.

</details>


### [19] [Identifying the Periodicity of Information in Natural Language](https://arxiv.org/abs/2510.27241)
*Yulin Ou,Yu Wang,Yang Xu,Hendrik Buschmeier*

Main category: cs.CL

TL;DR: 本文提出了一种名为AutoPeriod of Surprisal (APS)的新方法，用于检测自然语言中信息编码的周期性模式，发现人类语言中存在显著的信息周期性，并识别出超越典型文本结构单元的新周期。


<details>
  <summary>Details</summary>
Motivation: 随着信息密度理论的发展，需要探究自然语言中信息编码的周期性模式程度。

Method: 采用APS方法，结合规范的周期性检测算法，能够识别单个文档中惊奇值序列的任何显著周期。

Result: 发现相当比例的人类语言在信息上表现出强烈的周期性模式，并找到了超越句子边界、基本语篇单元等典型结构单元分布的新周期，通过谐波回归模型进一步确认。

Conclusion: 语言中信息的周期性是结构化因素和长距离作用因素共同作用的结果，该方法在LLM生成检测方面具有潜在应用价值。

Abstract: Recent theoretical advancement of information density in natural language has
brought the following question on desk: To what degree does natural language
exhibit periodicity pattern in its encoded information? We address this
question by introducing a new method called AutoPeriod of Surprisal (APS). APS
adopts a canonical periodicity detection algorithm and is able to identify any
significant periods that exist in the surprisal sequence of a single document.
By applying the algorithm to a set of corpora, we have obtained the following
interesting results: Firstly, a considerable proportion of human language
demonstrates a strong pattern of periodicity in information; Secondly, new
periods that are outside the distributions of typical structural units in text
(e.g., sentence boundaries, elementary discourse units, etc.) are found and
further confirmed via harmonic regression modeling. We conclude that the
periodicity of information in language is a joint outcome from both structured
factors and other driving factors that take effect at longer distances. The
advantages of our periodicity detection method and its potentials in
LLM-generation detection are further discussed.

</details>


### [20] [Beyond a Million Tokens: Benchmarking and Enhancing Long-Term Memory in LLMs](https://arxiv.org/abs/2510.27246)
*Mohammad Tavakoli,Alireza Salemi,Carrie Ye,Mohamed Abdalla,Hamed Zamani,J Ross Mitchell*

Main category: cs.CL

TL;DR: 提出了BEAM基准测试和LIGHT框架，用于评估和改进LLM在长对话中的记忆能力。BEAM包含100个长对话和2000个问题，LIGHT框架为LLM配备三种记忆系统，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试缺乏叙事连贯性、领域狭窄且只测试简单回忆任务，无法有效评估LLM在长对话中的记忆能力。

Method: 1. 自动生成长达1000万token的连贯对话构建BEAM基准；2. 提出LIGHT框架，为LLM配备长期情景记忆、短期工作记忆和事实积累便签三种互补记忆系统。

Result: 实验显示，即使具有100万token上下文窗口的LLM在长对话中表现不佳，而LIGHT框架平均提升性能3.5%-12.69%，消融研究证实了各记忆组件的贡献。

Conclusion: LIGHT框架通过模拟人类认知的多记忆系统，有效提升了LLM在长对话中的记忆能力，BEAM基准为评估此类能力提供了更全面的测试平台。

Abstract: Evaluating the abilities of large language models (LLMs) for tasks that
require long-term memory and thus long-context reasoning, for example in
conversational settings, is hampered by the existing benchmarks, which often
lack narrative coherence, cover narrow domains, and only test simple
recall-oriented tasks. This paper introduces a comprehensive solution to these
challenges. First, we present a novel framework for automatically generating
long (up to 10M tokens), coherent, and topically diverse conversations,
accompanied by probing questions targeting a wide range of memory abilities.
From this, we construct BEAM, a new benchmark comprising 100 conversations and
2,000 validated questions. Second, to enhance model performance, we propose
LIGHT-a framework inspired by human cognition that equips LLMs with three
complementary memory systems: a long-term episodic memory, a short-term working
memory, and a scratchpad for accumulating salient facts. Our experiments on
BEAM reveal that even LLMs with 1M token context windows (with and without
retrieval-augmentation) struggle as dialogues lengthen. In contrast, LIGHT
consistently improves performance across various models, achieving an average
improvement of 3.5%-12.69% over the strongest baselines, depending on the
backbone LLM. An ablation study further confirms the contribution of each
memory component.

</details>


### [21] [Languages are Modalities: Cross-Lingual Alignment via Encoder Injection](https://arxiv.org/abs/2510.27254)
*Rajan Agarwal,Aarush Gupta*

Main category: cs.CL

TL;DR: LLINK是一种计算高效的语言注入方法，通过将多语言编码器的句子嵌入对齐到解码器的潜在空间，改善低资源非拉丁语系脚本在指令调优LLM中的性能，无需改变分词器或重新训练解码器。


<details>
  <summary>Details</summary>
Motivation: 解决指令调优大语言模型在低资源、非拉丁语系脚本上表现不佳的问题，主要由于分词器碎片化和弱跨语言耦合。

Method: 1) 将冻结多语言编码器的句子嵌入通过轻量级对比投影器对齐到解码器潜在嵌入空间的保留位置；2) 将向量扩展为K个软槽，通过最小适配器训练使冻结解码器能够消费该信号。

Result: 显著改善双语检索性能，在LLM评判的问答评估中获得81.3%优于基础模型的偏好度和63.6%优于直接微调的偏好度，归因于减少分词膨胀和更强的跨语言对齐。

Conclusion: 将低资源语言视为模态为轻量级LLM中实现更强跨语言对齐提供了实用路径，尽管在数值保真度方面仍有残余弱点。

Abstract: Instruction-tuned Large Language Models (LLMs) underperform on low resource,
non-Latin scripts due to tokenizer fragmentation and weak cross-lingual
coupling. We present LLINK (Latent Language Injection for Non-English
Knowledge), a compute efficient language-as-modality method that conditions an
instruction-tuned decoder without changing the tokenizer or retraining the
decoder. First, we align sentence embeddings from a frozen multilingual encoder
to the decoder's latent embedding space at a reserved position via a
lightweight contrastive projector. Second, the vector is expanded into K soft
slots and trained with minimal adapters so the frozen decoder consumes the
signal. LLINK substantially improves bilingual retrieval and achieves 81.3%
preference over the base model and 63.6% over direct fine-tuning in LLM-judged
Q&A evaluations. We further find that improvements can be attributed to reduced
tokenization inflation and a stronger cross lingual alignment, despite the
model having residual weaknesses in numeric fidelity. Treating low resource
languages as a modality offers a practical path to stronger cross-lingual
alignment in lightweight LLMs.

</details>


### [22] [MedCalc-Eval and MedCalc-Env: Advancing Medical Calculation Capabilities of Large Language Models](https://arxiv.org/abs/2510.27267)
*Kangkun Mao,Jinru Ding,Jiayuan Chen,Mouxiao Bian,Ruiyao Chen,Xinwei Peng,Sijie Ren,Linyang Li,Jie Xu*

Main category: cs.CL

TL;DR: 提出了MedCalc-Eval基准测试，评估LLM在医学计算能力，包含700多个任务，涵盖方程计算和评分系统。开发了MedCalc-Env强化学习环境，在Qwen2.5-32B模型上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有医学基准测试主要关注问答和描述性推理，忽视了临床决策中至关重要的定量推理能力。现有数据集如MedCalc-Bench覆盖的计算任务较少，未能反映真实世界的计算场景。

Method: 构建了包含700多个任务的MedCalc-Eval基准，分为方程计算和规则评分系统两类。开发了基于InternBootcamp框架的MedCalc-Env强化学习环境，支持多步临床推理和规划。

Result: 在MedCalc-Env环境中微调Qwen2.5-32B模型，在MedCalc-Eval基准上取得了最先进的结果，在数值敏感性、公式选择和推理鲁棒性方面有显著提升。

Conclusion: MedCalc-Eval为评估LLM医学计算能力提供了更全面和具有挑战性的基准。剩余挑战包括单位转换、多条件逻辑和上下文理解。

Abstract: As large language models (LLMs) enter the medical domain, most benchmarks
evaluate them on question answering or descriptive reasoning, overlooking
quantitative reasoning critical to clinical decision-making. Existing datasets
like MedCalc-Bench cover few calculation tasks and fail to reflect real-world
computational scenarios.
  We introduce MedCalc-Eval, the largest benchmark for assessing LLMs' medical
calculation abilities, comprising 700+ tasks across two types: equation-based
(e.g., Cockcroft-Gault, BMI, BSA) and rule-based scoring systems (e.g., Apgar,
Glasgow Coma Scale). These tasks span diverse specialties including internal
medicine, surgery, pediatrics, and cardiology, offering a broader and more
challenging evaluation setting.
  To improve performance, we further develop MedCalc-Env, a reinforcement
learning environment built on the InternBootcamp framework, enabling multi-step
clinical reasoning and planning. Fine-tuning a Qwen2.5-32B model within this
environment achieves state-of-the-art results on MedCalc-Eval, with notable
gains in numerical sensitivity, formula selection, and reasoning robustness.
Remaining challenges include unit conversion, multi-condition logic, and
contextual understanding.
  Code and datasets are available at
https://github.com/maokangkun/MedCalc-Eval.

</details>


### [23] [Why Do Multilingual Reasoning Gaps Emerge in Reasoning Language Models?](https://arxiv.org/abs/2510.27269)
*Deokhyung Kang,Seonjeong Hwang,Daehui Kim,Hyounghun Kim,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: 本文发现推理语言模型中的多语言推理差距主要源于语言理解失败，并提出选择性翻译策略来检测和缓解这一问题，仅需翻译约20%的输入即可达到接近全翻译的性能。


<details>
  <summary>Details</summary>
Motivation: 推理语言模型在复杂推理任务上表现良好，但在高资源语言和低资源语言之间存在多语言推理差距。虽然已有研究试图缩小这一差距，但其根本原因尚未被深入探索。

Method: 通过分析发现多语言推理差距主要源于语言理解失败，即模型无法在推理过程中将多语言输入的含义正确表示为主导语言（英语）。作者评估了多种检测方法，发现监督方法效果最佳，并在此基础上提出选择性翻译策略。

Result: 实验结果显示，选择性翻译能够有效缩小多语言推理差距，仅需翻译约20%的输入即可达到接近全翻译的性能水平。

Conclusion: 理解失败是多语言推理差距的主要原因，可以通过检测和选择性缓解来改善，为实现更公平的多语言推理提供了关键见解和可行路径。

Abstract: Reasoning language models (RLMs) achieve strong performance on complex
reasoning tasks, yet they still suffer from a multilingual reasoning gap,
performing better in high-resource languages than in low-resource ones. While
recent efforts have reduced this gap, its underlying causes remain largely
unexplored. In this paper, we address this by showing that the multilingual
reasoning gap largely stems from failures in language understanding-the model's
inability to represent the multilingual input meaning into the dominant
language (i.e., English) within its reasoning trace. This motivates us to
examine whether understanding failures can be detected, as this ability could
help mitigate the multilingual reasoning gap. To this end, we evaluate a range
of detection methods and find that understanding failures can indeed be
identified, with supervised approaches performing best. Building on this, we
propose Selective Translation, a simple yet effective strategy that translates
the multilingual input into English only when an understanding failure is
detected. Experimental results show that Selective Translation bridges the
multilingual reasoning gap, achieving near full-translation performance while
using translation for only about 20% of inputs. Together, our work demonstrates
that understanding failures are the primary cause of the multilingual reasoning
gap and can be detected and selectively mitigated, providing key insight into
its origin and a promising path toward more equitable multilingual reasoning.
Our code and data are publicly available at
https://github.com/deokhk/RLM_analysis.

</details>


### [24] [A Unified Representation Underlying the Judgment of Large Language Models](https://arxiv.org/abs/2510.27328)
*Yi-Long Lu,Jiajun Song,Wei Wang*

Main category: cs.CL

TL;DR: 研究发现大型语言模型使用统一的Valence-Assent Axis维度计算评估判断，该机制将推理过程从公正推断转向目标导向的合理化，导致系统性偏见和幻觉。


<details>
  <summary>Details</summary>
Motivation: 探讨智能系统是依赖专门模块还是统一通用资源进行判断，特别是在发现LLMs中可解码的神经表征后，这些表征是否真正独立仍待验证。

Method: 通过分析多种LLMs，识别主导维度Valence-Assent Axis，并进行直接干预实验验证其功能。

Result: 发现VAA作为控制信号引导生成过程构建与其评估状态一致的合理化，即使牺牲事实准确性。

Conclusion: 揭示了促进连贯判断的架构如何系统性地破坏忠实推理，为系统性偏见和幻觉提供了机制性解释。

Abstract: A central architectural question for both biological and artificial
intelligence is whether judgment relies on specialized modules or a unified,
domain-general resource. While the discovery of decodable neural
representations for distinct concepts in Large Language Models (LLMs) has
suggested a modular architecture, whether these representations are truly
independent systems remains an open question. Here we provide evidence for a
convergent architecture. Across a range of LLMs, we find that diverse
evaluative judgments are computed along a dominant dimension, which we term the
Valence-Assent Axis (VAA). This axis jointly encodes subjective valence ("what
is good") and the model's assent to factual claims ("what is true"). Through
direct interventions, we show this unified representation creates a critical
dependency: the VAA functions as a control signal that steers the generative
process to construct a rationale consistent with its evaluative state, even at
the cost of factual accuracy. This mechanism, which we term the subordination
of reasoning, shifts the process of reasoning from impartial inference toward
goal-directed justification. Our discovery offers a mechanistic account for
systemic bias and hallucination, revealing how an architecture that promotes
coherent judgment can systematically undermine faithful reasoning.

</details>


### [25] [TransAlign: Machine Translation Encoders are Strong Word Aligners, Too](https://arxiv.org/abs/2510.27337)
*Benedikt Ebing,Christian Goldschmied,Goran Glavaš*

Main category: cs.CL

TL;DR: 提出TransAlign，一种基于大规模多语言机器翻译模型编码器的新型词对齐器，在基于机器翻译的跨语言迁移中显著优于现有词对齐和非词对齐的标签投影方法。


<details>
  <summary>Details</summary>
Motivation: 解决在缺乏训练数据的语言中，跨语言迁移需要标签投影的问题。现有基于编码器语言模型的词对齐器效果有限，而机器翻译模型与词对齐密切相关但研究不足。

Method: 利用大规模多语言机器翻译模型的编码器构建TransAlign词对齐器，用于在翻译测试和翻译训练策略中进行标签投影。

Result: TransAlign不仅实现了强大的词对齐性能，而且在基于机器翻译的跨语言迁移中显著优于流行的词对齐器和最先进的非词对齐标签投影方法。

Conclusion: TransAlign证明了利用机器翻译模型编码器进行词对齐的有效性，为跨语言迁移中的标签投影提供了更优解决方案。

Abstract: In the absence of sizable training data for most world languages and NLP
tasks, translation-based strategies such as translate-test -- evaluating on
noisy source language data translated from the target language -- and
translate-train -- training on noisy target language data translated from the
source language -- have been established as competitive approaches for
cross-lingual transfer (XLT). For token classification tasks, these strategies
require label projection: mapping the labels from each token in the original
sentence to its counterpart(s) in the translation. To this end, it is common to
leverage multilingual word aligners (WAs) derived from encoder language models
such as mBERT or LaBSE. Despite obvious associations between machine
translation (MT) and WA, research on extracting alignments with MT models is
largely limited to exploiting cross-attention in encoder-decoder architectures,
yielding poor WA results. In this work, in contrast, we propose TransAlign, a
novel word aligner that utilizes the encoder of a massively multilingual MT
model. We show that TransAlign not only achieves strong WA performance but
substantially outperforms popular WA and state-of-the-art non-WA-based label
projection methods in MT-based XLT for token classification.

</details>


### [26] [ThoughtProbe: Classifier-Guided LLM Thought Space Exploration via Probing Representations](https://arxiv.org/abs/2510.27355)
*Zijian Wang,Chang Xu*

Main category: cs.CL

TL;DR: ThoughtProbe是一个新颖的推理时框架，利用LLM的隐藏推理特征来提升推理性能，通过分类器评分指导树结构响应空间探索，并通过分支聚合方法找到最优答案。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要操纵隐藏表示来引导LLM生成，而本文旨在利用这些表示作为判别信号来指导树结构响应空间的探索，以提高推理性能。

Method: 在节点扩展时使用分类器作为评分和排序机制，优先处理高分候选进行延续；完成树扩展后收集所有分支的答案形成候选池；提出分支聚合方法，通过聚合CoT分数在所有支持分支上进行边际化，从而识别最优答案。

Result: 实验结果显示，该框架的全面探索不仅覆盖了有效的推理链，还能有效识别它们，在多个算术推理基准上取得了显著改进。

Conclusion: ThoughtProbe框架通过利用LLM的隐藏推理特征和树结构探索，显著提升了推理性能，证明了其在算术推理任务中的有效性。

Abstract: This paper introduces ThoughtProbe, a novel inference time framework that
leverages the hidden reasoning features of Large Language Models (LLMs) to
improve their reasoning performance. Unlike previous works that manipulate the
hidden representations to steer LLM generation, we harness them as
discriminative signals to guide the tree structured response space exploration.
In each node expansion, a classifier serves as a scoring and ranking mechanism
that efficiently allocates computational resources by prioritizing higher score
candidates for continuation. After completing the tree expansion, we collect
answers from all branches to form a candidate answer pool. We then propose a
branch aggregation method that marginalizes over all supporting branches by
aggregating their CoT scores, thereby identifying the optimal answer from the
pool. Experimental results show that our framework's comprehensive exploration
not only covers valid reasoning chains but also effectively identifies them,
achieving significant improvements across multiple arithmetic reasoning
benchmarks.

</details>


### [27] [From the Rock Floor to the Cloud: A Systematic Survey of State-of-the-Art NLP in Battery Life Cycle](https://arxiv.org/abs/2510.27369)
*Tosin Adewumi,Martin Karlsson,Marcus Liwicki,Mikael Sjödahl,Lama Alkhaled,Rihab Gargouri,Nudrat Habib,Franz Hennie*

Main category: cs.CL

TL;DR: 本文对自然语言处理在完整电池生命周期中的应用进行了系统性调查，并提出了技术语言处理框架用于欧盟数字电池护照和电池预测。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注电池生命周期的单个阶段或方法，缺乏对整个生命周期中NLP应用的全面调查，需要为数字电池护照等新兴需求提供解决方案。

Method: 采用PRISMA系统综述方法，使用Google Scholar、IEEE Xplore和Scopus三个数据库，评估274篇论文后对66篇相关论文进行批判性评审。

Result: 发现电池领域正在出现新的NLP任务，有助于材料发现和生命周期各阶段，但缺乏标准基准等挑战依然存在。

Conclusion: 提出的TLP框架结合智能AI和优化提示，能够有效应对现有挑战，为电池生命周期管理提供新的技术解决方案。

Abstract: We present a comprehensive systematic survey of the application of natural
language processing (NLP) along the entire battery life cycle, instead of one
stage or method, and introduce a novel technical language processing (TLP)
framework for the EU's proposed digital battery passport (DBP) and other
general battery predictions. We follow the Preferred Reporting Items for
Systematic Reviews and Meta-Analyses (PRISMA) method and employ three reputable
databases or search engines, including Google Scholar, Institute of Electrical
and Electronics Engineers Xplore (IEEE Xplore), and Scopus. Consequently, we
assessed 274 scientific papers before the critical review of the final 66
relevant papers. We publicly provide artifacts of the review for validation and
reproducibility. The findings show that new NLP tasks are emerging in the
battery domain, which facilitate materials discovery and other stages of the
life cycle. Notwithstanding, challenges remain, such as the lack of standard
benchmarks. Our proposed TLP framework, which incorporates agentic AI and
optimized prompts, will be apt for tackling some of the challenges.

</details>


### [28] [Balancing Knowledge Updates: Toward Unified Modular Editing in LLMs](https://arxiv.org/abs/2510.27400)
*Jiahao Liu,Zijian Wang,Kuo Zhao,Dong Hu*

Main category: cs.CL

TL;DR: 本文提出IntAttn-Edit方法，通过联合更新MLP和注意力模块来改进大语言模型的知识编辑效果，采用基于模块贡献度的知识平衡策略。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法主要关注MLP模块权重，忽略了注意力模块在知识存储中的重要作用，导致残留过时知识和编辑效果受限。

Method: 基于知识定位实验发现，提出IntAttn-Edit方法，将关联记忆范式扩展到联合更新MLP和注意力模块，采用知识平衡策略按模块贡献度分配更新幅度。

Result: 在标准基准测试中，IntAttn-Edit相比先前方法实现了更高的编辑成功率、更好的泛化能力和更强的知识保留能力。

Conclusion: 注意力模块在知识存储中扮演重要角色，联合更新MLP和注意力模块的知识平衡策略能显著提升知识编辑效果。

Abstract: Knowledge editing has emerged as an efficient approach for updating factual
knowledge in large language models (LLMs). It typically locates knowledge
storage modules and then modifies their parameters. However, most existing
methods focus on the weights of multilayer perceptron (MLP) modules, which are
often identified as the main repositories of factual information. Other
components, such as attention (Attn) modules, are often ignored during editing.
This imbalance can leave residual outdated knowledge and limit editing
effectiveness. We perform comprehensive knowledge localization experiments on
advanced LLMs and find that Attn modules play a substantial role in factual
knowledge storage and retrieval, especially in earlier layers. Based on these
insights, we propose IntAttn-Edit, a method that extends the associative memory
paradigm to jointly update both MLP and Attn modules. Our approach uses a
knowledge balancing strategy that allocates update magnitudes in proportion to
each module's measured contribution to knowledge storage. Experiments on
standard benchmarks show that IntAttn-Edit achieves higher edit success, better
generalization, and stronger knowledge preservation than prior methods. Further
analysis shows that the balancing strategy keeps editing performance within an
optimal range across diverse settings.

</details>


### [29] [Awal -- Community-Powered Language Technology for Tamazight](https://arxiv.org/abs/2510.27407)
*Alp Öktem,Farida Boudichat*

Main category: cs.CL

TL;DR: Awal是一个社区驱动的塔马齐特语语言技术资源开发项目，通过awaldigital.org平台收集翻译和语音数据，但18个月仅获得6,421对翻译和3小时语音，显示在复杂社会语言环境中标准众包方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决塔马齐特语在数字空间中的代表性不足问题，通过社区协作平台应对数据稀缺挑战。

Method: 建立社区驱动的协作平台awaldigital.org，让使用者贡献翻译和语音数据，分析18个月的社区参与情况。

Result: 社区参与面临重大障碍，包括对书面塔马齐特语信心不足和标准化挑战，实际数据贡献集中在语言学家和活动家群体，成果有限。

Conclusion: 在具有复杂社会语言背景的语言中，标准众包方法存在局限性，需要改进方法，正在利用收集的数据开发改进的开源机器翻译模型。

Abstract: This paper presents Awal, a community-powered initiative for developing
language technology resources for Tamazight. We provide a comprehensive review
of the NLP landscape for Tamazight, examining recent progress in computational
resources, and the emergence of community-driven approaches to address
persistent data scarcity. Launched in 2024, awaldigital.org platform addresses
the underrepresentation of Tamazight in digital spaces through a collaborative
platform enabling speakers to contribute translation and voice data. We analyze
18 months of community engagement, revealing significant barriers to
participation including limited confidence in written Tamazight and ongoing
standardization challenges. Despite widespread positive reception, actual data
contribution remained concentrated among linguists and activists. The modest
scale of community contributions -- 6,421 translation pairs and 3 hours of
speech data -- highlights the limitations of applying standard crowdsourcing
approaches to languages with complex sociolinguistic contexts. We are working
on improved open-source MT models using the collected data.

</details>


### [30] [Dynamic Affective Memory Management for Personalized LLM Agents](https://arxiv.org/abs/2510.27418)
*Junfeng Lu,Yueyan Li*

Main category: cs.CL

TL;DR: 提出基于贝叶斯启发和记忆熵概念的新型记忆管理系统，用于解决AI代理在个性化服务中的记忆冗余、过时和上下文整合问题，通过最小化全局熵实现动态记忆更新。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理系统依赖外部记忆数据库提供个性化体验，但面临记忆冗余、记忆过时和记忆-上下文整合差等挑战，主要由于交互过程中缺乏有效的记忆更新机制。

Method: 采用贝叶斯启发的记忆更新算法，引入记忆熵概念，使代理能够通过最小化全局熵来自主维护动态更新的记忆向量数据库。

Result: 实验结果表明，该系统在个性化、逻辑一致性和准确性方面表现优异。消融研究进一步验证了贝叶斯启发更新机制在缓解记忆膨胀方面的有效性。

Conclusion: 该工作为长期记忆系统设计提供了新的见解，提出的记忆管理系统在情感场景中能够有效提升AI代理的个性化服务能力。

Abstract: Advances in large language models are making personalized AI agents a new
research focus. While current agent systems primarily rely on personalized
external memory databases to deliver customized experiences, they face
challenges such as memory redundancy, memory staleness, and poor memory-context
integration, largely due to the lack of effective memory updates during
interaction. To tackle these issues, we propose a new memory management system
designed for affective scenarios. Our approach employs a Bayesian-inspired
memory update algorithm with the concept of memory entropy, enabling the agent
to autonomously maintain a dynamically updated memory vector database by
minimizing global entropy to provide more personalized services. To better
evaluate the system's effectiveness in this context, we propose DABench, a
benchmark focusing on emotional expression and emotional change toward objects.
Experimental results demonstrate that, our system achieves superior performance
in personalization, logical coherence, and accuracy. Ablation studies further
validate the effectiveness of the Bayesian-inspired update mechanism in
alleviating memory bloat. Our work offers new insights into the design of
long-term memory systems.

</details>


### [31] [VCORE: Variance-Controlled Optimization-based Reweighting for Chain-of-Thought Supervision](https://arxiv.org/abs/2510.27462)
*Xuan Gong,Senmiao Wang,Hanbo Huang,Ruoyu Sun,Shiyu Liang*

Main category: cs.CL

TL;DR: VCORE是一个基于优化理论的token重加权框架，通过约束优化问题来差异化监督CoT推理轨迹中的不同token，提升LLM在复杂推理任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 标准的交叉熵损失对所有token一视同仁，忽视了推理轨迹中不同token的异质贡献，导致监督分配不当和泛化能力弱的问题。

Method: 将CoT监督重新表述为约束优化问题，采用优化理论视角，实现跨token的原则性和自适应监督分配。

Result: 在数学和编程基准测试中，VCORE在领域内和领域外设置下均显著优于现有token重加权方法，使用Qwen3系列和LLaMA-3.1-8B-Instruct模型验证。

Conclusion: VCORE不仅提升了推理性能，还为后续强化学习提供了更有效的初始化，为推进LLM推理能力建立了更强基础。

Abstract: Supervised fine-tuning (SFT) on long chain-of-thought (CoT) trajectories has
emerged as a crucial technique for enhancing the reasoning abilities of large
language models (LLMs). However, the standard cross-entropy loss treats all
tokens equally, ignoring their heterogeneous contributions across a reasoning
trajectory. This uniform treatment leads to misallocated supervision and weak
generalization, especially in complex, long-form reasoning tasks. To address
this, we introduce \textbf{V}ariance-\textbf{C}ontrolled
\textbf{O}ptimization-based \textbf{RE}weighting (VCORE), a principled
framework that reformulates CoT supervision as a constrained optimization
problem. By adopting an optimization-theoretic perspective, VCORE enables a
principled and adaptive allocation of supervision across tokens, thereby
aligning the training objective more closely with the goal of robust reasoning
generalization. Empirical evaluations demonstrate that VCORE consistently
outperforms existing token reweighting methods. Across both in-domain and
out-of-domain settings, VCORE achieves substantial performance gains on
mathematical and coding benchmarks, using models from the Qwen3 series (4B, 8B,
32B) and LLaMA-3.1-8B-Instruct. Moreover, we show that VCORE serves as a more
effective initialization for subsequent reinforcement learning, establishing a
stronger foundation for advancing the reasoning capabilities of LLMs. The Code
will be released at https://github.com/coder-gx/VCORE.

</details>


### [32] [Diffuse Thinking: Exploring Diffusion Language Models as Efficient Thought Proposers for Reasoning](https://arxiv.org/abs/2510.27469)
*Chenyang Shao,Sijian Ren,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: 提出了一种高效的协作推理框架，利用扩散语言模型生成候选思维，大语言模型评估质量，以解决自回归生成范式在推理任务中计算效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的自回归生成范式导致推理性能随测试时间计算呈次优扩展，需要大量计算开销但仅带来边际性能提升。扩散语言模型能够通过单次前向传播并行去噪高效生成多样化样本，这为解决自回归生成的计算负担提供了新思路。

Method: 提出协作推理框架：使用扩散语言模型生成候选中间思维，利用大语言模型评估这些思维的质量。通过这种分工，在保持推理质量的同时显著降低计算开销。

Result: 在多样化基准测试上的实验表明，该框架在复杂推理任务中实现了强劲性能，为未来研究提供了有前景的方向。

Conclusion: 扩散语言模型和大语言模型的协作推理框架能够有效缓解自回归生成的计算负担，同时维持推理质量，为高效推理系统的发展开辟了新途径。

Abstract: In recent years, large language models (LLMs) have witnessed remarkable
advancements, with the test-time scaling law consistently enhancing the
reasoning capabilities. Through systematic evaluation and exploration of a
diverse spectrum of intermediate thoughts, LLMs demonstrate the potential to
generate deliberate reasoning steps, thereby substantially enhancing reasoning
accuracy. However, LLMs' autoregressive generation paradigm results in
reasoning performance scaling sub-optimally with test-time computation, often
requiring excessive computational overhead to propose thoughts while yielding
only marginal performance gains. In contrast, diffusion language models (DLMs)
can efficiently produce diverse samples through parallel denoising in a single
forward pass, inspiring us to leverage them for proposing intermediate
thoughts, thereby alleviating the computational burden associated with
autoregressive generation while maintaining quality. In this work, we propose
an efficient collaborative reasoning framework, leveraging DLMs to generate
candidate thoughts and LLMs to evaluate their quality. Experiments across
diverse benchmarks demonstrate that our framework achieves strong performance
in complex reasoning tasks, offering a promising direction for future research.
Our code is open-source at
https://anonymous.4open.science/r/Diffuse-Thinking-EC60.

</details>


### [33] [The aftermath of compounds: Investigating Compounds and their Semantic Representations](https://arxiv.org/abs/2510.27477)
*Swarang Joshi*

Main category: cs.CL

TL;DR: 比较GloVe和BERT嵌入在英语复合词处理中与人类语义判断的一致性，发现BERT能更好地捕捉组合语义，可预测性是语义透明度的强预测因子。


<details>
  <summary>Details</summary>
Motivation: 研究计算嵌入如何与人类语义判断对齐，特别是针对英语复合词的处理，旨在推进计算心理语言学的发展。

Method: 使用静态词向量(GloVe)和上下文嵌入(BERT)，结合人类对词素意义优势(LMD)和语义透明度(ST)的评分，通过关联强度、频率和可预测性指标计算嵌入衍生的LMD和ST度量，并通过Spearman相关和回归分析评估与人类判断的关系。

Result: BERT嵌入比GloVe更好地捕捉组合语义，可预测性评分在人类和模型数据中都是语义透明度的强预测因子。

Conclusion: 研究结果阐明了驱动复合词处理的因素，并为基于嵌入的语义建模提供了见解，推动了计算心理语言学的发展。

Abstract: This study investigates how well computational embeddings align with human
semantic judgments in the processing of English compound words. We compare
static word vectors (GloVe) and contextualized embeddings (BERT) against human
ratings of lexeme meaning dominance (LMD) and semantic transparency (ST) drawn
from a psycholinguistic dataset. Using measures of association strength
(Edinburgh Associative Thesaurus), frequency (BNC), and predictability (LaDEC),
we compute embedding-derived LMD and ST metrics and assess their relationships
with human judgments via Spearmans correlation and regression analyses. Our
results show that BERT embeddings better capture compositional semantics than
GloVe, and that predictability ratings are strong predictors of semantic
transparency in both human and model data. These findings advance computational
psycholinguistics by clarifying the factors that drive compound word processing
and offering insights into embedding-based semantic modeling.

</details>


### [34] [A Transformer-based Neural Architecture Search Method](https://arxiv.org/abs/2505.01314)
*Shang Wang,Huanrong Tang,Jianquan Ouyang*

Main category: cs.CL

TL;DR: 提出基于Transformer架构的神经架构搜索方法，通过多目标遗传算法搜索多头注意力的不同编码器-解码器组合，并使用困惑度作为BLEU分数的辅助评估指标来改进翻译模型。


<details>
  <summary>Details</summary>
Motivation: 为了寻找具有更好翻译结果的神经网络结构，除了BLEU分数外，还需要考虑其他评估指标来更全面地评估模型性能。

Method: 基于Transformer架构的神经架构搜索方法，搜索多头注意力的不同编码器-解码器组合，使用多目标遗传算法迭代改进种群中的每个神经网络，并以困惑度作为BLEU分数的辅助评估指标。

Result: 实验结果表明，该算法搜索到的神经网络结构优于所有基线模型，并且引入辅助评估指标比仅考虑BLEU分数能找到更好的模型。

Conclusion: 提出的神经架构搜索方法能有效提升翻译模型性能，多目标评估策略比单一BLEU指标更有利于发现优质模型。

Abstract: This paper presents a neural architecture search method based on Transformer
architecture, searching cross multihead attention computation ways for
different number of encoder and decoder combinations. In order to search for
neural network structures with better translation results, we considered
perplexity as an auxiliary evaluation metric for the algorithm in addition to
BLEU scores and iteratively improved each individual neural network within the
population by a multi-objective genetic algorithm. Experimental results show
that the neural network structures searched by the algorithm outperform all the
baseline models, and that the introduction of the auxiliary evaluation metric
can find better models than considering only the BLEU score as an evaluation
metric.

</details>


### [35] [Effect of Domain Generalization Techniques in Low Resource Systems](https://arxiv.org/abs/2510.27512)
*Mahi Aminu,Chisom Chibuike,Fatimo Adebanjo,Omokolade Awosanya,Samuel Oyeneye*

Main category: cs.CL

TL;DR: 该研究在低资源自然语言任务中比较了两种因果域泛化方法：因果数据增强和不变因果表示学习，证明它们能提升模型在未见领域的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实场景中训练和测试数据分布经常不一致，特别是在低资源环境下，数据稀缺和领域多样性有限会阻碍模型的稳健泛化能力。

Method: 使用两种因果域泛化技术：1) 因果数据增强方法自动生成反事实样本来改善对伪相关的鲁棒性；2) 不变因果表示学习方法使用DINER框架学习跨领域不变的特征表示。

Result: 两种方法都增强了模型对未见领域的鲁棒性：因果数据增强在情感分类中带来一致的跨领域准确率提升，而因果表示学习在多语言情感分析中改善了分布外性能，尽管不同语言的增益有所差异。

Conclusion: 因果域泛化方法在低资源自然语言处理任务中能有效提升模型对分布偏移的鲁棒性，为实际应用提供了有前景的解决方案。

Abstract: Machine learning models typically assume that training and test data follow
the same distribution, an assumption that often fails in real-world scenarios
due to distribution shifts. This issue is especially pronounced in low-resource
settings, where data scarcity and limited domain diversity hinder robust
generalization. Domain generalization (DG) approaches address this challenge by
learning features that remain invariant across domains, often using causal
mechanisms to improve model robustness. In this study, we examine two distinct
causal DG techniques in low-resource natural language tasks. First, we
investigate a causal data augmentation (CDA) approach that automatically
generates counterfactual examples to improve robustness to spurious
correlations. We apply this method to sentiment classification on the
NaijaSenti Twitter corpus, expanding the training data with semantically
equivalent paraphrases to simulate controlled distribution shifts. Second, we
explore an invariant causal representation learning (ICRL) approach using the
DINER framework, originally proposed for debiasing aspect-based sentiment
analysis. We adapt DINER to a multilingual setting. Our findings demonstrate
that both approaches enhance robustness to unseen domains: counterfactual data
augmentation yields consistent cross-domain accuracy gains in sentiment
classification, while causal representation learning with DINER improves
out-of-distribution performance in multilingual sentiment analysis, albeit with
varying gains across languages.

</details>


### [36] [Detecting Prefix Bias in LLM-based Reward Models](https://arxiv.org/abs/2505.13487)
*Ashwin Kumar,Yuzi He,Aram H. Markosyan,Bobbie Chern,Imanol Arrieta-Ibarra*

Main category: cs.CL

TL;DR: 该论文研究了基于人类反馈的强化学习(RLHF)中奖励模型的偏见问题，特别是前缀偏见——由查询前缀微小变化引发的系统性偏好偏移。


<details>
  <summary>Details</summary>
Motivation: 虽然已有许多公开的偏好数据集提供响应对比，但由此训练的奖励模型中的潜在偏见仍未充分探索。

Method: 引入新方法来检测和评估LLM奖励模型中的前缀偏见，并提出数据增强策略来减轻这些偏见。

Result: 在多种开源偏好数据集和奖励模型架构中发现了显著的种族和性别维度偏见，证明了这种偏见与底层模型架构无关。

Conclusion: 研究强调了在开发公平可靠奖励模型时进行偏见感知数据集设计和评估的迫切需求，为AI公平性讨论做出贡献。

Abstract: Reinforcement Learning with Human Feedback (RLHF) has emerged as a key
paradigm for task-specific fine-tuning of language models using human
preference data. While numerous publicly available preference datasets provide
pairwise comparisons of responses, the potential for biases in the resulting
reward models remains underexplored. In this work, we introduce novel methods
to detect and evaluate prefix bias -- a systematic shift in model preferences
triggered by minor variations in query prefixes -- in LLM-based reward models
trained on such datasets. We leverage these metrics to reveal significant
biases in preference models across racial and gender dimensions. Our
comprehensive evaluation spans diverse open-source preference datasets and
reward model architectures, demonstrating susceptibility to this kind of bias
regardless of the underlying model architecture. Furthermore, we propose a data
augmentation strategy to mitigate these biases, showing its effectiveness in
reducing the impact of prefix bias. Our findings highlight the critical need
for bias-aware dataset design and evaluation in developing fair and reliable
reward models, contributing to the broader discourse on fairness in AI.

</details>


### [37] [BiSparse-AAS: Bilinear Sparse Attention and Adaptive Spans Framework for Scalable and Efficient Text Summarization](https://arxiv.org/abs/2510.27516)
*Desta Haileselassie Hagos,Legand L. Burge,Anietie Andy,Anis Yazidi,Vladimir Vlassov*

Main category: cs.CL

TL;DR: 提出了BiSparse-AAS框架，结合稀疏注意力、自适应跨度与双线性注意力，在保持性能的同时显著降低Transformer在长文档摘要中的计算复杂度。


<details>
  <summary>Details</summary>
Motivation: Transformer架构在文本摘要中表现出色，但其二次复杂度限制了在长文档上的可扩展性，需要更高效的注意力机制。

Method: 结合稀疏注意力减少计算成本，自适应跨度动态调整注意力范围，双线性注意力在精炼上下文中建模复杂token交互。

Result: 在CNN/DailyMail和XSum数据集上分别实现平均ROUGE提升68.1%和52.6%，在OpenWebText和Gigaword数据集上保持强劲性能。

Conclusion: BiSparse-AAS通过解决效率、可扩展性和长序列建模问题，为实际文本摘要应用提供了统一实用的解决方案。

Abstract: Transformer-based architectures have advanced text summarization, yet their
quadratic complexity limits scalability on long documents. This paper
introduces BiSparse-AAS (Bilinear Sparse Attention with Adaptive Spans), a
novel framework that combines sparse attention, adaptive spans, and bilinear
attention to address these limitations. Sparse attention reduces computational
costs by focusing on the most relevant parts of the input, while adaptive spans
dynamically adjust the attention ranges. Bilinear attention complements both by
modeling complex token interactions within this refined context. BiSparse-AAS
consistently outperforms state-of-the-art baselines in both extractive and
abstractive summarization tasks, achieving average ROUGE improvements of about
68.1% on CNN/DailyMail and 52.6% on XSum, while maintaining strong performance
on OpenWebText and Gigaword datasets. By addressing efficiency, scalability,
and long-sequence modeling, BiSparse-AAS provides a unified, practical solution
for real-world text summarization applications.

</details>


### [38] [SQLSpace: A Representation Space for Text-to-SQL to Discover and Mitigate Robustness Gaps](https://arxiv.org/abs/2510.27532)
*Neha Srikanth,Victor Bursztyn,Puneet Mathur,Ani Nenkova*

Main category: cs.CL

TL;DR: SQLSpace是一种人类可解释、可泛化、紧凑的文本到SQL示例表示方法，通过最小人工干预获得，用于评估文本到SQL任务的三个用例：基准比较、细粒度性能分析和查询重写改进。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到SQL评估主要依赖原始示例和整体准确率，难以深入理解模型性能模式和基准间的差异，需要更结构化的表示方法来支持细粒度分析。

Method: 开发SQLSpace表示方法，从文本到SQL示例中提取人类可解释的特征，然后应用于三个用例：基准组成对比、细粒度性能分析和基于正确性估计的查询重写。

Result: SQLSpace能够揭示基准间的组成差异，暴露仅靠准确率无法发现的性能模式，并支持查询成功建模，实现比原始示例更深入的分析能力。

Conclusion: SQLSpace为文本到SQL任务提供了有效的结构化表示，支持更深入的性能分析和模型改进，超越了传统基于原始示例和准确率的评估方法。

Abstract: We introduce SQLSpace, a human-interpretable, generalizable, compact
representation for text-to-SQL examples derived with minimal human
intervention. We demonstrate the utility of these representations in evaluation
with three use cases: (i) closely comparing and contrasting the composition of
popular text-to-SQL benchmarks to identify unique dimensions of examples they
evaluate, (ii) understanding model performance at a granular level beyond
overall accuracy scores, and (iii) improving model performance through targeted
query rewriting based on learned correctness estimation. We show that SQLSpace
enables analysis that would be difficult with raw examples alone: it reveals
compositional differences between benchmarks, exposes performance patterns
obscured by accuracy alone, and supports modeling of query success.

</details>


### [39] [Patient-Centered Summarization Framework for AI Clinical Summarization: A Mixed-Methods Design](https://arxiv.org/abs/2510.27535)
*Maria Lizarazo Jimenez,Ana Gabriela Claros,Kieran Green,David Toro-Tobon,Felipe Larios,Sheena Asthana,Camila Wenczenovicz,Kerly Guevara Maldonado,Luis Vilatuna-Andrango,Cristina Proano-Velez,Satya Sai Sri Bandi,Shubhangi Bagewadi,Megan E. Branda,Misk Al Zahidy,Saturnino Luz,Mirella Lapata,Juan P. Brito,Oscar J. Ponce-Ponte*

Main category: cs.CL

TL;DR: 提出患者为中心摘要(PCS)新标准，评估开源大语言模型在生成包含患者价值观的临床摘要方面的表现，发现模型在完整性和流畅性上接近人类水平，但在准确性和患者中心性方面仍有差距。


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成的临床摘要过于关注患者生物学信息，而忽略了患者的偏好、价值观、愿望和关切，需要建立患者为中心的摘要标准以实现以患者为中心的护理。

Method: 采用混合方法：通过患者和临床医生访谈确定摘要内容标准，制定标注指南，由临床医生创建88份房颤咨询的金标准PCS，使用5个开源LLM进行零样本和少样本提示生成摘要，通过ROUGE-L、BERTScore和定性指标评估。

Result: 患者强调生活方式、社会支持、近期压力源和护理价值观，临床医生寻求简洁的功能、心理社会和情感背景。Mistral-8B和Llama-3.1-8B在零样本表现最佳，Llama-3.1-8B在少样本表现最佳。模型在完整性和流畅性上与专家相似，但正确性和患者中心性仍优于人类PCS。

Conclusion: 开源LLM在生成患者为中心临床摘要方面显示出潜力，但在准确捕捉患者价值观和确保临床实用性方面仍需改进，需要进一步研究提升模型的患者中心性能力。

Abstract: Large Language Models (LLMs) are increasingly demonstrating the potential to
reach human-level performance in generating clinical summaries from
patient-clinician conversations. However, these summaries often focus on
patients' biology rather than their preferences, values, wishes, and concerns.
To achieve patient-centered care, we propose a new standard for Artificial
Intelligence (AI) clinical summarization tasks: Patient-Centered Summaries
(PCS). Our objective was to develop a framework to generate PCS that capture
patient values and ensure clinical utility and to assess whether current
open-source LLMs can achieve human-level performance in this task. We used a
mixed-methods process. Two Patient and Public Involvement groups (10 patients
and 8 clinicians) in the United Kingdom participated in semi-structured
interviews exploring what personal and contextual information should be
included in clinical summaries and how it should be structured for clinical
use. Findings informed annotation guidelines used by eight clinicians to create
gold-standard PCS from 88 atrial fibrillation consultations. Sixteen
consultations were used to refine a prompt aligned with the guidelines. Five
open-source LLMs (Llama-3.2-3B, Llama-3.1-8B, Mistral-8B, Gemma-3-4B, and
Qwen3-8B) generated summaries for 72 consultations using zero-shot and few-shot
prompting, evaluated with ROUGE-L, BERTScore, and qualitative metrics. Patients
emphasized lifestyle routines, social support, recent stressors, and care
values. Clinicians sought concise functional, psychosocial, and emotional
context. The best zero-shot performance was achieved by Mistral-8B (ROUGE-L
0.189) and Llama-3.1-8B (BERTScore 0.673); the best few-shot by Llama-3.1-8B
(ROUGE-L 0.206, BERTScore 0.683). Completeness and fluency were similar between
experts and models, while correctness and patient-centeredness favored human
PCS.

</details>


### [40] [DialectalArabicMMLU: Benchmarking Dialectal Capabilities in Arabic and Multilingual Language Models](https://arxiv.org/abs/2510.27543)
*Malik H. Altakrori,Nizar Habash,Abdelhakim Freihat,Younes Samih,Kirill Chirkunov,Muhammed AbuOdeh,Radu Florian,Teresa Lynn,Preslav Nakov,Alham Fikri Aji*

Main category: cs.CL

TL;DR: 提出了DialectalArabicMMLU基准，用于评估大语言模型在阿拉伯语方言上的表现，涵盖5种主要方言的15K问答对，发现模型在不同方言间存在显著性能差异。


<details>
  <summary>Details</summary>
Motivation: 现有的阿拉伯语和多语言基准主要关注现代标准阿拉伯语，而日常交流中广泛使用的方言变体评估不足，需要专门的方言理解评估资源。

Method: 基于MMLU-Redux框架，通过人工翻译和适配将3K多选题转化为5种主要阿拉伯方言（叙利亚、埃及、阿联酋、沙特和摩洛哥），共生成15K问答对，涵盖32个学术和专业领域。

Result: 评估了19个阿拉伯语和多语言LLM（1B-13B参数），发现模型在不同方言间存在显著的性能变化，揭示了方言泛化方面的持续差距。

Conclusion: DialectalArabicMMLU提供了首个统一的人工策划资源，用于衡量阿拉伯语方言理解，促进更包容的评估和未来模型开发。

Abstract: We present DialectalArabicMMLU, a new benchmark for evaluating the
performance of large language models (LLMs) across Arabic dialects. While
recently developed Arabic and multilingual benchmarks have advanced LLM
evaluation for Modern Standard Arabic (MSA), dialectal varieties remain
underrepresented despite their prevalence in everyday communication.
DialectalArabicMMLU extends the MMLU-Redux framework through manual translation
and adaptation of 3K multiple-choice question-answer pairs into five major
dialects (Syrian, Egyptian, Emirati, Saudi, and Moroccan), yielding a total of
15K QA pairs across 32 academic and professional domains (22K QA pairs when
also including English and MSA). The benchmark enables systematic assessment of
LLM reasoning and comprehension beyond MSA, supporting both task-based and
linguistic analysis. We evaluate 19 open-weight Arabic and multilingual LLMs
(1B-13B parameters) and report substantial performance variation across
dialects, revealing persistent gaps in dialectal generalization.
DialectalArabicMMLU provides the first unified, human-curated resource for
measuring dialectal understanding in Arabic, thus promoting more inclusive
evaluation and future model development.

</details>


### [41] [Multilingual BERT language model for medical tasks: Evaluation on domain-specific adaptation and cross-linguality](https://arxiv.org/abs/2510.27552)
*Yinghao Luo,Lang Zhou,Amrish Jhingoer,Klaske Vliegenthart Jongbloed,Carlijn Jordans,Ben Werkhoven,Tom Seinen,Erik van Mulligen,Casper Rokx,Yunlei Li*

Main category: cs.CL

TL;DR: 该研究探讨了在荷兰语、罗马尼亚语和西班牙语三种低资源语言中，通过领域特定语料库的进一步预训练如何提升医学NLP任务的性能。


<details>
  <summary>Details</summary>
Motivation: 多语言医疗应用中，特别是低资源语言的领域特定NLP工具稀缺，虽然多语言BERT提供了解决语言差距的潜力，但低资源语言的医学NLP任务仍未被充分探索。

Method: 进行了四项实验来创建医学领域模型，包括领域特定预训练，然后在三个下游任务上进行微调：荷兰临床笔记的自动患者筛查、罗马尼亚和西班牙临床笔记的命名实体识别。

Result: 领域适应显著提升了任务性能，临床领域适应模型优于更一般的生物医学领域适应模型，并观察到跨语言可转移性的证据。

Conclusion: 这些发现突显了领域适应和跨语言能力在医学NLP中的可行性，为开发多语言医学NLP系统以缓解训练数据不足提供了有意义的指导。

Abstract: In multilingual healthcare applications, the availability of domain-specific
natural language processing(NLP) tools is limited, especially for low-resource
languages. Although multilingual bidirectional encoder representations from
transformers (BERT) offers a promising motivation to mitigate the language gap,
the medical NLP tasks in low-resource languages are still underexplored.
Therefore, this study investigates how further pre-training on domain-specific
corpora affects model performance on medical tasks, focusing on three
languages: Dutch, Romanian and Spanish. In terms of further pre-training, we
conducted four experiments to create medical domain models. Then, these models
were fine-tuned on three downstream tasks: Automated patient screening in Dutch
clinical notes, named entity recognition in Romanian and Spanish clinical
notes. Results show that domain adaptation significantly enhanced task
performance. Furthermore, further differentiation of domains, e.g. clinical and
general biomedical domains, resulted in diverse performances. The clinical
domain-adapted model outperformed the more general biomedical domain-adapted
model. Moreover, we observed evidence of cross-lingual transferability.
Moreover, we also conducted further investigations to explore potential reasons
contributing to these performance differences. These findings highlight the
feasibility of domain adaptation and cross-lingual ability in medical NLP.
Within the low-resource language settings, these findings can provide
meaningful guidance for developing multilingual medical NLP systems to mitigate
the lack of training data and thereby improve the model performance.

</details>


### [42] [Data-Efficient Domain Adaptation for LLM-based MT using Contrastive Preference Optimization](https://arxiv.org/abs/2510.27556)
*Inacio Vieira,Antonio Castaldo,James O'Doherty,Sheila Castilho*

Main category: cs.CL

TL;DR: 使用CPO进行领域自适应，通过将基础模型的原始输出作为拒绝翻译，人工批准的TM条目作为选择翻译来合成偏好对，实现数据高效的领域适应。


<details>
  <summary>Details</summary>
Motivation: LLMs需要适应领域特定需求，但仅依赖SFT可能成本高昂，因此探索更数据高效的方法。

Method: 应用CPO模拟后编辑工作流，通过对比基础模型原始输出和人工批准翻译来合成偏好对，为模型提供直接反馈。

Result: 在英-巴西葡萄牙语和英-韩语实验中，仅使用14.7k偏好对就达到了接近使用160k+样本SFT训练的性能，显示出显著的数据效率。

Conclusion: CPO方法在机器翻译中有效，且可自然推广到其他生成任务，其中模型的初始草稿可作为与黄金参考的对比信号。

Abstract: LLMs often require adaptation to domain-specific requirements, a process that
can be expensive when relying solely on SFT. We present an empirical study on
applying CPO to simulate a post-editing workflow for data-efficient domain
adaptation. Our approach synthesizes preference pairs by treating the base
model's own raw output as the 'rejected' translation and the human-approved TM
entry as the 'chosen' one. This method provides direct feedback on the model's
current knowledge, guiding it to align with domain-specific standards.
Experiments in English-Brazilian Portuguese and English-Korean show that, by
using just 14.7k preference pairs, the model achieves performance close to that
of a model trained on 160k+ samples with SFT, demonstrating significant data
efficiency. Although we showcase its effectiveness in MT, this application of
CPO naturally generalizes to other generative tasks where a model's initial
drafts can serve as a contrastive signal against a golden reference.

</details>


### [43] [MARAG-R1: Beyond Single Retriever via Reinforcement-Learned Multi-Tool Agentic Retrieval](https://arxiv.org/abs/2510.27569)
*Qi Luo,Xiaonan Li,Yuxin Wang,Tingshuo Fan,Yuan Li,Xinchi Chen,Xipeng Qiu*

Main category: cs.CL

TL;DR: MARAG-R1是一个基于强化学习的多工具检索增强生成框架，通过动态协调多种检索机制来解决传统RAG系统单一检索器限制的问题，在语料库级推理任务中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统依赖单一检索器和固定的top-k选择，限制了对外部知识的全面访问，特别是在需要语料库级推理的任务中成为主要瓶颈。

Method: 提出MARAG-R1框架，配备四种检索工具（语义搜索、关键词搜索、过滤和聚合），通过两阶段训练（监督微调+强化学习）让模型学习如何动态协调使用这些工具。

Result: 在GlobalQA、HotpotQA和2WikiMultiHopQA上的实验表明，MARAG-R1显著优于强基线方法，在语料库级推理任务中取得了新的最先进结果。

Conclusion: 多工具动态检索框架能够有效解决传统RAG系统的局限性，通过让模型学习如何协调使用不同检索工具，实现了更全面和精确的外部知识访问。

Abstract: Large Language Models (LLMs) excel at reasoning and generation but are
inherently limited by static pretraining data, resulting in factual
inaccuracies and weak adaptability to new information. Retrieval-Augmented
Generation (RAG) addresses this issue by grounding LLMs in external knowledge;
However, the effectiveness of RAG critically depends on whether the model can
adequately access relevant information. Existing RAG systems rely on a single
retriever with fixed top-k selection, restricting access to a narrow and static
subset of the corpus. As a result, this single-retriever paradigm has become
the primary bottleneck for comprehensive external information acquisition,
especially in tasks requiring corpus-level reasoning. To overcome this
limitation, we propose MARAG-R1, a reinforcement-learned multi-tool RAG
framework that enables LLMs to dynamically coordinate multiple retrieval
mechanisms for broader and more precise information access. MARAG-R1 equips the
model with four retrieval tools -- semantic search, keyword search, filtering,
and aggregation -- and learns both how and when to use them through a two-stage
training process: supervised fine-tuning followed by reinforcement learning.
This design allows the model to interleave reasoning and retrieval,
progressively gathering sufficient evidence for corpus-level synthesis.
Experiments on GlobalQA, HotpotQA, and 2WikiMultiHopQA demonstrate that
MARAG-R1 substantially outperforms strong baselines and achieves new
state-of-the-art results in corpus-level reasoning tasks.

</details>


### [44] [SpecAttn: Speculating Sparse Attention](https://arxiv.org/abs/2510.27641)
*Harsh Shah*

Main category: cs.CL

TL;DR: SpecAttn是一种无需训练的方法，通过利用推测解码中草稿模型的注意力权重来识别重要token，实现预训练transformer中的高效稀疏注意力，减少75%以上的KV缓存访问。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理时面临计算瓶颈，特别是随着上下文长度增加，自注意力机制的二次复杂度成为主要问题。

Method: 使用KL散度进行层对齐、GPU优化的无排序top-p token选择算法、基于预测的动态KV缓存剪枝，利用推测解码中已计算的注意力权重。

Result: 在PG-19数据集上实现超过75%的KV缓存访问减少，仅增加15.29%的困惑度，显著优于现有稀疏注意力方法。

Conclusion: 推测执行可以增强为提供近似验证而不会显著降低性能，证明了利用推测解码计算工作实现高效稀疏注意力的可行性。

Abstract: Large Language Models (LLMs) face significant computational bottlenecks
during inference due to the quadratic complexity of self-attention mechanisms,
particularly as context lengths increase. We introduce SpecAttn, a novel
training-free approach that seamlessly integrates with existing speculative
decoding techniques to enable efficient sparse attention in pre-trained
transformers. Our key insight is to exploit the attention weights already
computed by the draft model during speculative decoding to identify important
tokens for the target model, eliminating redundant computation while
maintaining output quality. SpecAttn employs three core techniques: KL
divergence-based layer alignment between draft and target models, a
GPU-optimized sorting-free algorithm for top-p token selection from draft
attention patterns, and dynamic key-value cache pruning guided by these
predictions. By leveraging the computational work already performed in standard
speculative decoding pipelines, SpecAttn achieves over 75% reduction in
key-value cache accesses with a mere 15.29% increase in perplexity on the PG-19
dataset, significantly outperforming existing sparse attention methods. Our
approach demonstrates that speculative execution can be enhanced to provide
approximate verification without significant performance degradation.

</details>


### [45] [Culture Cartography: Mapping the Landscape of Cultural Knowledge](https://arxiv.org/abs/2510.27672)
*Caleb Ziems,William Held,Jane Yu,Amir Goldberg,David Grusky,Diyi Yang*

Main category: cs.CL

TL;DR: 提出了一种混合主动方法CultureCartography，通过LLM低置信度问题初始化标注，让人类填补知识空白并引导模型关注重要文化主题，有效发现LLM缺失的文化知识。


<details>
  <summary>Details</summary>
Motivation: LLM需要文化特定知识来安全有效地服务全球用户，但预训练可能未学习这些知识。需要找到对群体内用户重要但对LLM未知的知识。

Method: 提出CultureCartography混合主动方法：LLM用低置信度答案问题初始化标注，人类填补空白并通过直接编辑引导模型关注重要主题。实现为CultureExplorer工具。

Result: 相比人类回答LLM提出问题的基线，CultureExplorer更有效地产生领先模型（DeepSeek R1和GPT-4o）缺失的知识，即使有网络搜索。用这些数据微调使Llama-3.1-8B在相关文化基准上的准确率提升高达19.2%。

Conclusion: 混合主动协作方法能有效识别和填补LLM的文化知识空白，提升模型在文化相关任务上的表现。

Abstract: To serve global users safely and productively, LLMs need culture-specific
knowledge that might not be learned during pre-training. How do we find such
knowledge that is (1) salient to in-group users, but (2) unknown to LLMs? The
most common solutions are single-initiative: either researchers define
challenging questions that users passively answer (traditional annotation), or
users actively produce data that researchers structure as benchmarks (knowledge
extraction). The process would benefit from mixed-initiative collaboration,
where users guide the process to meaningfully reflect their cultures, and LLMs
steer the process towards more challenging questions that meet the researcher's
goals. We propose a mixed-initiative methodology called CultureCartography.
Here, an LLM initializes annotation with questions for which it has
low-confidence answers, making explicit both its prior knowledge and the gaps
therein. This allows a human respondent to fill these gaps and steer the model
towards salient topics through direct edits. We implement this methodology as a
tool called CultureExplorer. Compared to a baseline where humans answer
LLM-proposed questions, we find that CultureExplorer more effectively produces
knowledge that leading models like DeepSeek R1 and GPT-4o are missing, even
with web search. Fine-tuning on this data boosts the accuracy of Llama-3.1-8B
by up to 19.2% on related culture benchmarks.

</details>


### [46] [Continuous Autoregressive Language Models](https://arxiv.org/abs/2510.27688)
*Chenze Shao,Darren Li,Fandong Meng,Jie Zhou*

Main category: cs.CL

TL;DR: CALM通过将语言建模从离散的下一词预测转变为连续的下一向量预测，显著提高了语言模型的生成效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的效率受到逐词生成过程的限制，需要新的扩展设计维度来提高每个生成步骤的语义带宽。

Method: 使用高保真自编码器将K个词块压缩为单个连续向量，从该向量可以以超过99.9%的准确率重建原始词元，从而将生成步骤减少K倍。

Result: CALM显著改善了性能-计算权衡，在显著降低计算成本的情况下达到了强离散基线的性能水平。

Conclusion: 下一向量预测是构建超高效语言模型的有力且可扩展的途径。

Abstract: The efficiency of large language models (LLMs) is fundamentally limited by
their sequential, token-by-token generation process. We argue that overcoming
this bottleneck requires a new design axis for LLM scaling: increasing the
semantic bandwidth of each generative step. To this end, we introduce
Continuous Autoregressive Language Models (CALM), a paradigm shift from
discrete next-token prediction to continuous next-vector prediction. CALM uses
a high-fidelity autoencoder to compress a chunk of K tokens into a single
continuous vector, from which the original tokens can be reconstructed with
over 99.9\% accuracy. This allows us to model language as a sequence of
continuous vectors instead of discrete tokens, which reduces the number of
generative steps by a factor of K. The paradigm shift necessitates a new
modeling toolkit; therefore, we develop a comprehensive likelihood-free
framework that enables robust training, evaluation, and controllable sampling
in the continuous domain. Experiments show that CALM significantly improves the
performance-compute trade-off, achieving the performance of strong discrete
baselines at a significantly lower computational cost. More importantly, these
findings establish next-vector prediction as a powerful and scalable pathway
towards ultra-efficient language models. Code:
https://github.com/shaochenze/calm. Project:
https://shaochenze.github.io/blog/2025/CALM.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [47] [CATArena: Evaluation of LLM Agents through Iterative Tournament Competitions](https://arxiv.org/abs/2510.26852)
*Lingyue Fu,Xin Ding,Yaoming Zhu,Shao Zhang,Lin Qiu,Weiwen Liu,Weinan Zhang,Xuezhi Cao,Xunliang Cai,Jiaxin Ding,Yong Yu*

Main category: cs.AI

TL;DR: 提出了CATArena评估平台，通过开放式计分的棋牌游戏来评估LLM智能体的学习能力，解决现有基准测试中的分数饱和问题。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试主要评估固定场景下的端到端性能，存在分数饱和和对专家标注依赖的问题，无法有效评估智能体的学习能力。

Method: 提出迭代式竞争性同伴学习框架，让智能体通过重复交互和反馈优化策略，并开发CATArena平台，包含四种开放式计分的棋牌游戏。

Result: 实验结果表明CATArena能够可靠、稳定且可扩展地评估智能体核心能力，特别是学习能力和策略编码能力。

Conclusion: CATArena为快速发展的智能体能力提供了持续动态的评估方法，特别适合评估学习能力这一核心驱动因素。

Abstract: Large Language Model (LLM) agents have evolved from basic text generation to
autonomously completing complex tasks through interaction with external tools.
However, current benchmarks mainly assess end-to-end performance in fixed
scenarios, restricting evaluation to specific skills and suffering from score
saturation and growing dependence on expert annotation as agent capabilities
improve. In this work, we emphasize the importance of learning ability,
including both self-improvement and peer-learning, as a core driver for agent
evolution toward human-level intelligence. We propose an iterative, competitive
peer-learning framework, which allows agents to refine and optimize their
strategies through repeated interactions and feedback, thereby systematically
evaluating their learning capabilities. To address the score saturation issue
in current benchmarks, we introduce CATArena, a tournament-style evaluation
platform featuring four diverse board and card games with open-ended scoring.
By providing tasks without explicit upper score limits, CATArena enables
continuous and dynamic evaluation of rapidly advancing agent capabilities.
Experimental results and analyses involving both minimal and commercial code
agents demonstrate that CATArena provides reliable, stable, and scalable
benchmarking for core agent abilities, particularly learning ability and
strategy coding.

</details>


### [48] [Inverse Knowledge Search over Verifiable Reasoning: Synthesizing a Scientific Encyclopedia from a Long Chains-of-Thought Knowledge Base](https://arxiv.org/abs/2510.26854)
*Yu Li,Yuan Huang,Tao Wang,Caiyu Fan,Xiansheng Cai,Sihan Hu,Xinzijian Liu,Cheng Shi,Mingjun Xu,Zhen Wang,Yan Wang,Xiangqi Jin,Tianhan Zhang,Linfeng Zhang,Lei Wang,Youjin Deng,Pan Zhang,Weijie Sun,Xingyu Li,Weinan E,Linfeng Zhang,Zhiyuan Yao,Kun Chen*

Main category: cs.AI

TL;DR: 提出了一个可扩展的框架SciencePedia，通过构建可验证的长思维链知识库来解压缩科学推理过程，支持跨领域科学合成。


<details>
  <summary>Details</summary>
Motivation: 现有科学材料过度压缩推理过程，只呈现结论而省略推导链条，这阻碍了验证过程并抑制了跨领域概念间的逻辑连接。

Method: 采用端点驱动的还原策略：苏格拉底式代理生成约300万个第一原理问题，多个独立求解器模型生成长思维链，通过提示净化和跨模型答案共识进行严格过滤，仅保留可验证端点的内容。

Result: 构建了包含约20万个细粒度条目的SciencePedia，涵盖数学、物理、化学、生物、工程和计算等领域。评估显示，基于检索长思维链的合成文章比无检索基线具有显著更高的知识点密度和更低的事实错误率。

Conclusion: 这种基于可验证长思维链知识库的推理中心方法能够实现可信赖的跨领域科学合成，为不断扩展的百科全书奠定了基础。

Abstract: Most scientific materials compress reasoning, presenting conclusions while
omitting the derivational chains that justify them. This compression hinders
verification by lacking explicit, step-wise justifications and inhibits
cross-domain links by collapsing the very pathways that establish the logical
and causal connections between concepts. We introduce a scalable framework that
decompresses scientific reasoning, constructing a verifiable Long
Chain-of-Thought (LCoT) knowledge base and projecting it into an emergent
encyclopedia, SciencePedia. Our pipeline operationalizes an endpoint-driven,
reductionist strategy: a Socratic agent, guided by a curriculum of around 200
courses, generates approximately 3 million first-principles questions. To
ensure high fidelity, multiple independent solver models generate LCoTs, which
are then rigorously filtered by prompt sanitization and cross-model answer
consensus, retaining only those with verifiable endpoints. This verified corpus
powers the Brainstorm Search Engine, which performs inverse knowledge search --
retrieving diverse, first-principles derivations that culminate in a target
concept. This engine, in turn, feeds the Plato synthesizer, which narrates
these verified chains into coherent articles. The initial SciencePedia
comprises approximately 200,000 fine-grained entries spanning mathematics,
physics, chemistry, biology, engineering, and computation. In evaluations
across six disciplines, Plato-synthesized articles (conditioned on retrieved
LCoTs) exhibit substantially higher knowledge-point density and significantly
lower factual error rates than an equally-prompted baseline without retrieval
(as judged by an external LLM). Built on this verifiable LCoT knowledge base,
this reasoning-centric approach enables trustworthy, cross-domain scientific
synthesis at scale and establishes the foundation for an ever-expanding
encyclopedia.

</details>


### [49] [The Denario project: Deep knowledge AI agents for scientific discovery](https://arxiv.org/abs/2510.26887)
*Francisco Villaescusa-Navarro,Boris Bolliet,Pablo Villanueva-Domingo,Adrian E. Bayer,Aidan Acquah,Chetana Amancharla,Almog Barzilay-Siegal,Pablo Bermejo,Camille Bilodeau,Pablo Cárdenas Ramírez,Miles Cranmer,Urbano L. França,ChangHoon Hahn,Yan-Fei Jiang,Raul Jimenez,Jun-Young Lee,Antonio Lerario,Osman Mamun,Thomas Meier,Anupam A. Ojha,Pavlos Protopapas,Shimanto Roy,David N. Spergel,Pedro Tarancón-Álvarez,Ujjwal Tiwari,Matteo Viel,Digvijay Wadekar,Chi Wang,Bonny Y. Wang,Licong Xu,Yossi Yovel,Shuwen Yue,Wen-Han Zhou,Qiyao Zhu,Jiajun Zou,Íñigo Zubeldia*

Main category: cs.AI

TL;DR: Denario是一个AI多智能体系统，作为科学研究的助手，能够完成从生成想法到撰写科学论文的全流程任务，并在多个学科领域进行了验证。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够辅助科学研究全过程的AI系统，解决科研工作中从创意生成到论文撰写的多个环节，提高科研效率。

Method: 采用模块化架构设计，结合Cmbagent作为深度研究后端，能够处理特定任务或进行端到端的科学分析。

Result: 系统在多个科学领域生成了论文，并经过领域专家的评估，获得了数值评分和评审反馈，展示了跨学科整合的能力。

Conclusion: Denario展示了AI驱动研究的潜力，但也存在局限性，需要关注伦理影响和与科学哲学的关系。

Abstract: We present Denario, an AI multi-agent system designed to serve as a
scientific research assistant. Denario can perform many different tasks, such
as generating ideas, checking the literature, developing research plans,
writing and executing code, making plots, and drafting and reviewing a
scientific paper. The system has a modular architecture, allowing it to handle
specific tasks, such as generating an idea, or carrying out end-to-end
scientific analysis using Cmbagent as a deep-research backend. In this work, we
describe in detail Denario and its modules, and illustrate its capabilities by
presenting multiple AI-generated papers generated by it in many different
scientific disciplines such as astrophysics, biology, biophysics, biomedical
informatics, chemistry, material science, mathematical physics, medicine,
neuroscience and planetary science. Denario also excels at combining ideas from
different disciplines, and we illustrate this by showing a paper that applies
methods from quantum physics and machine learning to astrophysical data. We
report the evaluations performed on these papers by domain experts, who
provided both numerical scores and review-like feedback. We then highlight the
strengths, weaknesses, and limitations of the current system. Finally, we
discuss the ethical implications of AI-driven research and reflect on how such
technology relates to the philosophy of science. We publicly release the code
at https://github.com/AstroPilot-AI/Denario. A Denario demo can also be run
directly on the web at https://huggingface.co/spaces/astropilot-ai/Denario, and
the full app will be deployed on the cloud.

</details>


### [50] [Cognition Envelopes for Bounded AI Reasoning in Autonomous UAS Operations](https://arxiv.org/abs/2510.26905)
*Pedro Antonio Alarcón Granadeno,Arturo Miguel Bernal Russell,Sofia Nelson,Demetrius Hernandez,Maureen Petterson,Michael Murphy,Walter J. Scheirer,Jane Cleland-Huang*

Main category: cs.AI

TL;DR: 提出认知包络概念，为AI决策建立推理边界，解决基础模型在物理信息系统中产生的幻觉、过度泛化和上下文错位等错误。


<details>
  <summary>Details</summary>
Motivation: 基础模型在物理信息系统中增强了感知、推理和规划能力，但也引入了新的错误类型，导致错误决策，需要建立约束机制。

Method: 引入认知包络概念，建立推理边界来约束AI生成决策，同时结合元认知和传统安全包络方法。

Result: 提出了认知包络的概念框架，强调需要实用的指导方针和系统化流程来定义、验证和保证认知包络。

Conclusion: 认知包络是解决基础模型在物理信息系统中决策错误的重要方法，需要建立系统化的实施和验证流程。

Abstract: Cyber-physical systems increasingly rely on Foundational Models such as Large
Language Models (LLMs) and Vision-Language Models (VLMs) to increase autonomy
through enhanced perception, inference, and planning. However, these models
also introduce new types of errors, such as hallucinations,
overgeneralizations, and context misalignments, resulting in incorrect and
flawed decisions. To address this, we introduce the concept of Cognition
Envelopes, designed to establish reasoning boundaries that constrain
AI-generated decisions while complementing the use of meta-cognition and
traditional safety envelopes. As with safety envelopes, Cognition Envelopes
require practical guidelines and systematic processes for their definition,
validation, and assurance.

</details>


### [51] [SUSTAINABLE Platform: Seamless Smart Farming Integration Towards Agronomy Automation](https://arxiv.org/abs/2510.26989)
*Agorakis Bompotas,Konstantinos Koutras,Nikitas Rigas Kalogeropoulos,Panagiotis Kechagias,Dimitra Gariza,Athanasios P. Kalogeras,Christos Alexakos*

Main category: cs.AI

TL;DR: SUSTAINABLE是一个智能农业平台，整合物联网、人工智能、卫星成像和基于角色的任务编排，旨在实现高效、可追溯和可持续的农业，特别是在葡萄栽培领域。


<details>
  <summary>Details</summary>
Motivation: 全球农业面临粮食需求增长、气候多变性和可持续实践需求的挑战，需要智能解决方案来应对这些压力。

Method: 平台集成物联网、AI、卫星成像和基于角色的任务编排，特别针对地中海葡萄园设计了卫星指数集成、实时环境数据和角色感知任务管理功能。

Result: 提出了一个综合性的智能农业平台解决方案，通过比较评估现有方案并展示SUSTAINABLE的关键特性。

Conclusion: SUSTAINABLE平台通过技术创新为农业可持续发展提供了可行的解决方案，特别是在葡萄栽培领域的应用展示了其潜力。

Abstract: The global agricultural sector is undergoing a transformative shift, driven
by increasing food demands, climate variability and the need for sustainable
practices. SUSTAINABLE is a smart farming platform designed to integrate IoT,
AI, satellite imaging, and role-based task orchestration to enable efficient,
traceable, and sustainable agriculture with a pilot usecase in viticulture.
This paper explores current smart agriculture solutions, presents a comparative
evaluation, and introduces SUSTAINABLE's key features, including satellite
index integration, real-time environmental data, and role-aware task management
tailored to Mediterranean vineyards.

</details>


### [52] [Causal Masking on Spatial Data: An Information-Theoretic Case for Learning Spatial Datasets with Unimodal Language Models](https://arxiv.org/abs/2510.27009)
*Jared Junkin,Samuel Nathanson*

Main category: cs.AI

TL;DR: 研究表明，在空间数据上应用因果掩码训练单模态LLMs是可行的，在某些领域甚至优于序列化方法。


<details>
  <summary>Details</summary>
Motivation: 探讨在具有空间或关系结构的领域中，接受因果掩码引入的信息损失是否可行，以及是否比序列化方法更好。

Method: 在国际象棋领域训练具有双向和因果自注意力机制的语言模型，分别使用空间（棋盘状态）和序列（走棋）数据。

Result: 在空间棋盘状态上训练的模型（即使使用因果掩码）始终比在序列数据上训练的模型具有更强的下棋能力。

Conclusion: 在空间数据上应用因果掩码训练单模态LLMs是可行的，在某些领域甚至优于序列化方法。

Abstract: Language models are traditionally designed around causal masking. In domains
with spatial or relational structure, causal masking is often viewed as
inappropriate, and sequential linearizations are instead used. Yet the question
of whether it is viable to accept the information loss introduced by causal
masking on nonsequential data has received little direct study, in part because
few domains offer both spatial and sequential representations of the same
dataset. In this work, we investigate this issue in the domain of chess, which
naturally supports both representations. We train language models with
bidirectional and causal self-attention mechanisms on both spatial
(board-based) and sequential (move-based) data. Our results show that models
trained on spatial board states - \textit{even with causal masking} -
consistently achieve stronger playing strength than models trained on
sequential data. While our experiments are conducted on chess, our results are
methodological and may have broader implications: applying causal masking to
spatial data is a viable procedure for training unimodal LLMs on spatial data,
and in some domains is even preferable to sequentialization.

</details>


### [53] [e1: Learning Adaptive Control of Reasoning Effort](https://arxiv.org/abs/2510.27042)
*Michael Kleinman,Matthew Trager,Alessandro Achille,Wei Xia,Stefano Soatto*

Main category: cs.AI

TL;DR: 提出自适应努力控制方法，让AI模型根据用户指定的思考预算比例动态调整推理长度，在保持或提升性能的同时显著减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要用户预先指定绝对token数量，但用户难以事先知道问题难度来合理设置预算。需要更精细的控制机制来平衡输出质量与延迟成本。

Method: 基于强化学习的自适应努力控制方法，训练模型使用相对于当前平均思维链长度的用户指定比例token数量，无需数据集和阶段特定调优。

Result: 在1.5B到32B参数规模的模型上，该方法能实现约3倍的思维链长度减少，同时保持或提升相对于RL训练基础模型的性能。

Conclusion: 该方法通过连续努力参数让用户动态调整成本-精度权衡，模型能自动按任务难度比例分配资源，提供更好的成本-精度权衡曲线。

Abstract: Increasing the thinking budget of AI models can significantly improve
accuracy, but not all questions warrant the same amount of reasoning. Users may
prefer to allocate different amounts of reasoning effort depending on how they
value output quality versus latency and cost. To leverage this tradeoff
effectively, users need fine-grained control over the amount of thinking used
for a particular query, but few approaches enable such control. Existing
methods require users to specify the absolute number of desired tokens, but
this requires knowing the difficulty of the problem beforehand to appropriately
set the token budget for a query. To address these issues, we propose Adaptive
Effort Control, a self-adaptive reinforcement learning method that trains
models to use a user-specified fraction of tokens relative to the current
average chain-of-thought length for each query. This approach eliminates
dataset- and phase-specific tuning while producing better cost-accuracy
tradeoff curves compared to standard methods. Users can dynamically adjust the
cost-accuracy trade-off through a continuous effort parameter specified at
inference time. We observe that the model automatically learns to allocate
resources proportionally to the task difficulty and, across model scales
ranging from 1.5B to 32B parameters, our approach enables approximately 3x
reduction in chain-of-thought length while maintaining or improving performance
relative to the base model used for RL training.

</details>


### [54] [Adaptive Data Flywheel: Applying MAPE Control Loops to AI Agent Improvement](https://arxiv.org/abs/2510.27051)
*Aaditya Shukla,Sidney Knowles,Meenakshi Madugula,Dave Farris,Ryan Angilly,Santiago Pombo,Anbang Xu,Lu An,Abhinav Balasubramanian,Tan Yu,Jiaxiang Ren,Rama Akkiraju*

Main category: cs.AI

TL;DR: NVIDIA在企业AI助手NVInfo中实施了数据飞轮系统，通过MAPE驱动的闭环机制解决RAG管道故障，实现了持续学习和性能提升。


<details>
  <summary>Details</summary>
Motivation: 企业AI代理需要持续适应以保持准确性、降低延迟并与用户需求保持一致，因此需要构建能够从实际使用中学习的自适应系统。

Method: 采用MAPE驱动的数据飞轮方法，构建闭环系统，通过NVIDIA NeMo微服务进行针对性微调，包括用8B微调模型替换70B模型来处理路由错误，以及优化查询重述功能。

Result: 路由准确性达到96%，模型大小减少10倍，延迟改善70%；查询重述准确性提升3.7%，延迟降低40%。在3个月部署期内收集了495个负面样本进行分析和改进。

Conclusion: 通过将人工反馈结构化到数据飞轮中，可以将企业AI代理转变为自我改进系统，为构建能够在实际使用中大规模学习的稳健、自适应企业AI代理提供了可重复的蓝图。

Abstract: Enterprise AI agents must continuously adapt to maintain accuracy, reduce
latency, and remain aligned with user needs. We present a practical
implementation of a data flywheel in NVInfo AI, NVIDIA's Mixture-of-Experts
(MoE) Knowledge Assistant serving over 30,000 employees. By operationalizing a
MAPE-driven data flywheel, we built a closed-loop system that systematically
addresses failures in retrieval-augmented generation (RAG) pipelines and
enables continuous learning. Over a 3-month post-deployment period, we
monitored feedback and collected 495 negative samples. Analysis revealed two
major failure modes: routing errors (5.25\%) and query rephrasal errors
(3.2\%). Using NVIDIA NeMo microservices, we implemented targeted improvements
through fine-tuning. For routing, we replaced a Llama 3.1 70B model with a
fine-tuned 8B variant, achieving 96\% accuracy, a 10x reduction in model size,
and 70\% latency improvement. For query rephrasal, fine-tuning yielded a 3.7\%
gain in accuracy and a 40\% latency reduction. Our approach demonstrates how
human-in-the-loop (HITL) feedback, when structured within a data flywheel,
transforms enterprise AI agents into self-improving systems. Key learnings
include approaches to ensure agent robustness despite limited user feedback,
navigating privacy constraints, and executing staged rollouts in production.
This work offers a repeatable blueprint for building robust, adaptive
enterprise AI agents capable of learning from real-world usage at scale.

</details>


### [55] [CombiGraph-Vis: A Curated Multimodal Olympiad Benchmark for Discrete Mathematical Reasoning](https://arxiv.org/abs/2510.27094)
*Hamed Mahdavi,Pouria Mahdavinia,Alireza Farhadi,Pegah Mohammadipour,Samira Malek,Majid Daliri,Pedram Mohammadipour,Alireza Hashemi,Amir Khasahmadi,Vasant Honavar*

Main category: cs.AI

TL;DR: 评估先进LLMs在数学证明评分方面的能力，发现模型能可靠识别错误证明但部分评分存在校准问题，提出基于代理工作流的自动评分方法，显著提高了与人类评分的一致性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在解决奥林匹克数学问题方面取得显著进展，需要评估这些模型在证明评分方面的能力，包括错误检测、严重性判断和公平评分，而不仅仅是二元正确性判断。

Method: 使用90个Gemini 2.5 Pro生成的解决方案和MathArena数据集，引入基于代理的工作流程来提取和分析参考解决方案，自动推导问题特定的评分标准，进行多步骤评分过程。

Result: 模型能可靠标记错误（包括细微错误）解决方案，但在部分评分分配上存在校准差距。提出的工作流程在标注语料库和MathArena上都实现了与人类评分更高的一致性，并在部分评分处理上更加一致。

Conclusion: 代理工作流程能够有效解决LLMs在证明评分中的校准问题，提高评分的一致性和准确性，为未来研究提供了有价值的工具和数据集。

Abstract: State-of-the-art (SOTA) LLMs have progressed from struggling on proof-based
Olympiad problems to solving most of the IMO 2025 problems, with leading
systems reportedly handling 5 of 6 problems. Given this progress, we assess how
well these models can grade proofs: detecting errors, judging their severity,
and assigning fair scores beyond binary correctness. We study proof-analysis
capabilities using a corpus of 90 Gemini 2.5 Pro-generated solutions that we
grade on a 1-4 scale with detailed error annotations, and on MathArena solution
sets for IMO/USAMO 2025 scored on a 0-7 scale. Our analysis shows that models
can reliably flag incorrect (including subtly incorrect) solutions but exhibit
calibration gaps in how partial credit is assigned. To address this, we
introduce agentic workflows that extract and analyze reference solutions and
automatically derive problem-specific rubrics for a multi-step grading process.
We instantiate and compare different design choices for the grading workflows,
and evaluate their trade-offs. Across our annotated corpus and MathArena, our
proposed workflows achieve higher agreement with human grades and more
consistent handling of partial credit across metrics. We release all code,
data, and prompts/logs to facilitate future research.

</details>


### [56] [Glia: A Human-Inspired AI for Automated Systems Design and Optimization](https://arxiv.org/abs/2510.27176)
*Pouya Hamadanian,Pantea Karimi,Arash Nasr-Esfahany,Kimia Noorbakhsh,Joseph Chandler,Ali ParandehGheibi,Mohammad Alizadeh,Hari Balakrishnan*

Main category: cs.AI

TL;DR: Glia是一个用于网络系统设计的AI架构，使用LLM在多智能体工作流中自主设计计算机系统机制，性能达到人类专家水平。


<details>
  <summary>Details</summary>
Motivation: 探索AI是否能够自主设计计算机系统机制，达到人类专家的创造性和推理水平。

Method: 使用大型语言模型在多智能体工作流中协作，每个智能体专门负责推理、实验和分析，通过评估框架将抽象推理与经验反馈相结合。

Result: 在分布式GPU集群的LLM推理应用中，Glia生成了新的请求路由、调度和自动扩展算法，在更短时间内达到人类专家水平，并提供了对工作负载行为的新见解。

Conclusion: 通过将推理LLM与结构化实验相结合，AI能够为复杂系统问题产生创造性且可理解的设计。

Abstract: Can an AI autonomously design mechanisms for computer systems on par with the
creativity and reasoning of human experts? We present Glia, an AI architecture
for networked systems design that uses large language models (LLMs) in a
human-inspired, multi-agent workflow. Each agent specializes in reasoning,
experimentation, and analysis, collaborating through an evaluation framework
that grounds abstract reasoning in empirical feedback. Unlike prior
ML-for-systems methods that optimize black-box policies, Glia generates
interpretable designs and exposes its reasoning process. When applied to a
distributed GPU cluster for LLM inference, it produces new algorithms for
request routing, scheduling, and auto-scaling that perform at human-expert
levels in significantly less time, while yielding novel insights into workload
behavior. Our results suggest that by combining reasoning LLMs with structured
experimentation, an AI can produce creative and understandable designs for
complex systems problems.

</details>


### [57] [From product to system network challenges in system of systems lifecycle management](https://arxiv.org/abs/2510.27194)
*Vahid Salehi,Josef Vilsmeier,Shirui Wang*

Main category: cs.AI

TL;DR: 本文提出了一个面向系统之系统（SoS）生命周期管理的实用参考框架，强调从传统线性产品生命周期向网络化系统开发的转变，包含MBSE、PLM、CAD-CAE等核心要素，并提出了四项原则和三步路线图。


<details>
  <summary>Details</summary>
Motivation: 传统线性生命周期模型在当今网络化系统环境下已显不足，跨学科互操作性、变体管理、可追溯性和跨组织治理成为关键挑战，需要新的方法来管理复杂系统。

Method: 基于文献综述和行业经验，提出包含MBSE作为语义骨干、PLM作为治理和配置层、CAD-CAE作为模型衍生领域的参考框架，以及四项原则和三步实施路线图。

Result: 实施该框架可提高变更鲁棒性、缩短交付时间、改善重用性，并为可持续性决策提供信息支持。

Conclusion: 该框架为决策者和实践者提供了管理复杂性、设计可扩展SoS价值流的实用方法，支持从产品中心向网络中心开发的转型。

Abstract: Today, products are no longer isolated artifacts, but nodes in networked
systems. This means that traditional, linearly conceived life cycle models are
reaching their limits: Interoperability across disciplines, variant and
configuration management, traceability, and governance across organizational
boundaries are becoming key factors. This collective contribution classifies
the state of the art and proposes a practical frame of reference for SoS
lifecycle management, model-based systems engineering (MBSE) as the semantic
backbone, product lifecycle management (PLM) as the governance and
configuration level, CAD-CAE as model-derived domains, and digital thread and
digital twin as continuous feedback. Based on current literature and industry
experience, mobility, healthcare, and the public sector, we identify four
principles: (1) referenced architecture and data models, (2) end-to-end
configuration sovereignty instead of tool silos, (3) curated models with clear
review gates, and (4) measurable value contributions along time, quality, cost,
and sustainability. A three-step roadmap shows the transition from product- to
network- centric development: piloting with reference architecture, scaling
across variant and supply chain spaces, organizational anchoring (roles,
training, compliance). The results are increased change robustness, shorter
throughput times, improved reuse, and informed sustainability decisions. This
article is aimed at decision-makers and practitioners who want to make
complexity manageable and design SoS value streams to be scalable.

</details>


### [58] [Fints: Efficient Inference-Time Personalization for LLMs with Fine-Grained Instance-Tailored Steering](https://arxiv.org/abs/2510.27206)
*Kounianhua Du,Jianxing Liu,Kangning Zhang,Wenxiang Jiao,Yuan Lu,Jiarui Jin,Weiwen Liu,Yong Yu,Weinan Zhang*

Main category: cs.AI

TL;DR: 提出了一种细粒度的实例定制化引导框架，通过动态生成样本级干扰向量并注入模型前向传播来实现个性化适配，解决了动态用户模式和高数据稀疏场景下的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有参数化适配方法在处理动态用户模式和高数据稀疏场景时存在适应性和数据效率不足的问题，需要更灵活高效的个性化技术。

Method: 采用细粒度引导组件从注意力层和MLP层捕获激活信号，结合输入感知聚合模块将这些信号合成为上下文相关增强，动态生成样本级干扰向量注入模型前向传播。

Result: 在短文本到长文本生成、网页函数调用等多种场景的实验中，该方法在快速变化分布和高数据稀疏场景下显著提升了个性化性能，并保持了跨不同交互模式和上下文长度的鲁棒性。

Conclusion: 该方法具有高度灵活性和数据效率，与现有方法正交，可作为插件组件兼容不同的个性化技术，在快速变化环境中有效增强个性化性能。

Abstract: The rapid evolution of large language models (LLMs) has intensified the
demand for effective personalization techniques that can adapt model behavior
to individual user preferences. Despite the non-parametric methods utilizing
the in-context learning ability of LLMs, recent parametric adaptation methods,
including personalized parameter-efficient fine-tuning and reward modeling
emerge. However, these methods face limitations in handling dynamic user
patterns and high data sparsity scenarios, due to low adaptability and data
efficiency. To address these challenges, we propose a fine-grained and
instance-tailored steering framework that dynamically generates sample-level
interference vectors from user data and injects them into the model's forward
pass for personalized adaptation. Our approach introduces two key technical
innovations: a fine-grained steering component that captures nuanced signals by
hooking activations from attention and MLP layers, and an input-aware
aggregation module that synthesizes these signals into contextually relevant
enhancements. The method demonstrates high flexibility and data efficiency,
excelling in fast-changing distribution and high data sparsity scenarios. In
addition, the proposed method is orthogonal to existing methods and operates as
a plug-in component compatible with different personalization techniques.
Extensive experiments across diverse scenarios--including short-to-long text
generation, and web function calling--validate the effectiveness and
compatibility of our approach. Results show that our method significantly
enhances personalization performance in fast-shifting environments while
maintaining robustness across varying interaction modes and context lengths.
Implementation is available at https://github.com/KounianhuaDu/Fints.

</details>


### [59] [GUI-Rise: Structured Reasoning and History Summarization for GUI Navigation](https://arxiv.org/abs/2510.27210)
*Tao Liu,Chongyu Wang,Rongjie Li,Yingchen Yu,Xuming He,Bai Song*

Main category: cs.AI

TL;DR: 提出了GUI-Rise框架，通过结构化推理、动作预测和历史总结增强GUI导航代理的跨领域泛化能力，在相同训练数据下达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在GUI导航代理中存在跨领域泛化能力不足和历史信息利用效率低的问题。

Method: 采用结构化推理生成思维链分析，结合动作预测和紧凑历史总结，通过监督微调伪标签轨迹和GRPO强化学习训练GUI代理。

Result: 在标准基准测试中，在相同训练数据条件下实现了最先进的性能，特别是在跨领域场景中表现优异。

Conclusion: 该框架能够在多样化GUI导航任务中保持稳健的推理和泛化能力，验证了其有效性。

Abstract: While Multimodal Large Language Models (MLLMs) have advanced GUI navigation
agents, current approaches face limitations in cross-domain generalization and
effective history utilization. We present a reasoning-enhanced framework that
systematically integrates structured reasoning, action prediction, and history
summarization. The structured reasoning component generates coherent
Chain-of-Thought analyses combining progress estimation and decision reasoning,
which inform both immediate action predictions and compact history summaries
for future steps. Based on this framework, we train a GUI agent,
\textbf{GUI-Rise}, through supervised fine-tuning on pseudo-labeled
trajectories and reinforcement learning with Group Relative Policy Optimization
(GRPO). This framework employs specialized rewards, including a history-aware
objective, directly linking summary quality to subsequent action performance.
Comprehensive evaluations on standard benchmarks demonstrate state-of-the-art
results under identical training data conditions, with particularly strong
performance in out-of-domain scenarios. These findings validate our framework's
ability to maintain robust reasoning and generalization across diverse GUI
navigation tasks. Code is available at https://leon022.github.io/GUI-Rise.

</details>


### [60] [Reinforcement Learning for Long-Horizon Unordered Tasks: From Boolean to Coupled Reward Machines](https://arxiv.org/abs/2510.27329)
*Kristina Levina,Nikolaos Pappas,Athanasios Karapantelakis,Aneta Vulgarakis Feljan,Jendrik Seipp*

Main category: cs.AI

TL;DR: 本文提出了三种奖励机（RM）的泛化形式来解决长视野无序子任务问题，并引入了基于耦合RM的组合学习算法CoRM，在包含无序子任务的长视野问题上比现有RM算法具有更好的扩展性。


<details>
  <summary>Details</summary>
Motivation: 传统奖励机在处理长视野问题中无序子任务时存在局限性，当无序子任务数量增加时，需要学习的信息量呈指数级增长，这限制了其在复杂任务中的应用。

Method: 提出了三种RM泛化形式：数值RM、议程RM和耦合RM，并开发了基于耦合RM的组合学习算法CoRM（Q-learning with coupled RMs）。

Result: 实验表明，CoRM算法在包含无序子任务的长视野问题上比最先进的RM算法具有更好的扩展性能。

Conclusion: 通过引入数值RM、议程RM和耦合RM的泛化形式以及CoRM学习算法，有效解决了传统奖励机在长视野无序子任务问题中的扩展性限制。

Abstract: Reward machines (RMs) inform reinforcement learning agents about the reward
structure of the environment. This is particularly advantageous for complex
non-Markovian tasks because agents with access to RMs can learn more
efficiently from fewer samples. However, learning with RMs is ill-suited for
long-horizon problems in which a set of subtasks can be executed in any order.
In such cases, the amount of information to learn increases exponentially with
the number of unordered subtasks. In this work, we address this limitation by
introducing three generalisations of RMs: (1) Numeric RMs allow users to
express complex tasks in a compact form. (2) In Agenda RMs, states are
associated with an agenda that tracks the remaining subtasks to complete. (3)
Coupled RMs have coupled states associated with each subtask in the agenda.
Furthermore, we introduce a new compositional learning algorithm that leverages
coupled RMs: Q-learning with coupled RMs (CoRM). Our experiments show that CoRM
scales better than state-of-the-art RM algorithms for long-horizon problems
with unordered subtasks.

</details>


### [61] [Discriminative Rule Learning for Outcome-Guided Process Model Discovery](https://arxiv.org/abs/2510.27343)
*Ali Norouzifar,Wil van der Aalst*

Main category: cs.AI

TL;DR: 提出了一种基于结果感知的过程发现方法，通过区分理想和不理想的过程执行轨迹，分别学习过程模型，从而揭示影响过程结果的关键行为模式。


<details>
  <summary>Details</summary>
Motivation: 传统过程发现方法不考虑执行结果差异，导致模型无法有效区分理想和不理想行为，限制了其在一致性检查和性能分析中的应用价值。

Method: 通过学习基于控制流特征的可解释判别规则，将轨迹按理想程度分组，然后在每个组内分别进行过程发现。

Result: 该方法在多个真实事件日志上得到验证，能够有效分离和可视化关键过程模式，生成聚焦且可解释的过程模型。

Conclusion: 结果感知的过程发现方法能够揭示理想和不理想过程执行的结构差异，为过程改进提供更有针对性的洞察。

Abstract: Event logs extracted from information systems offer a rich foundation for
understanding and improving business processes. In many real-world
applications, it is possible to distinguish between desirable and undesirable
process executions, where desirable traces reflect efficient or compliant
behavior, and undesirable ones may involve inefficiencies, rule violations,
delays, or resource waste. This distinction presents an opportunity to guide
process discovery in a more outcome-aware manner. Discovering a single process
model without considering outcomes can yield representations poorly suited for
conformance checking and performance analysis, as they fail to capture critical
behavioral differences. Moreover, prioritizing one behavior over the other may
obscure structural distinctions vital for understanding process outcomes. By
learning interpretable discriminative rules over control-flow features, we
group traces with similar desirability profiles and apply process discovery
separately within each group. This results in focused and interpretable models
that reveal the drivers of both desirable and undesirable executions. The
approach is implemented as a publicly available tool and it is evaluated on
multiple real-life event logs, demonstrating its effectiveness in isolating and
visualizing critical process patterns.

</details>


### [62] [An In-depth Study of LLM Contributions to the Bin Packing Problem](https://arxiv.org/abs/2510.27353)
*Julien Herrmann,Guillaume Pallez*

Main category: cs.AI

TL;DR: 重新评估LLM在数学发现中的贡献，发现LLM生成的装箱问题启发式算法虽然人类可读但难以理解，并提出更简单高效的替代算法，质疑LLM在此问题上的实际科学价值。


<details>
  <summary>Details</summary>
Motivation: 重新评估LLM在数学发现中的贡献主张，特别是针对在线装箱问题中LLM生成的启发式算法的有效性和可解释性。

Method: 详细分析LLM生成的启发式算法行为与可解释性，并提出针对特定装箱问题实例的新算法类别。

Result: 发现LLM生成的启发式算法即使对人类专家也难以理解，而提出的新算法更简单、高效、可解释且泛化性更好，表明原问题实例相对简单。

Conclusion: LLM在此问题上的贡献被高估，强调在评估LLM生成输出的科学价值时需要严格的验证和情境化分析。

Abstract: Recent studies have suggested that Large Language Models (LLMs) could provide
interesting ideas contributing to mathematical discovery. This claim was
motivated by reports that LLM-based genetic algorithms produced heuristics
offering new insights into the online bin packing problem under uniform and
Weibull distributions. In this work, we reassess this claim through a detailed
analysis of the heuristics produced by LLMs, examining both their behavior and
interpretability. Despite being human-readable, these heuristics remain largely
opaque even to domain experts. Building on this analysis, we propose a new
class of algorithms tailored to these specific bin packing instances. The
derived algorithms are significantly simpler, more efficient, more
interpretable, and more generalizable, suggesting that the considered instances
are themselves relatively simple. We then discuss the limitations of the claim
regarding LLMs' contribution to this problem, which appears to rest on the
mistaken assumption that the instances had previously been studied. Our
findings instead emphasize the need for rigorous validation and
contextualization when assessing the scientific value of LLM-generated outputs.

</details>


### [63] [ToolScope: An Agentic Framework for Vision-Guided and Long-Horizon Tool Use](https://arxiv.org/abs/2510.27363)
*Mengjie Deng,Guanting Dong,Zhicheng Dou*

Main category: cs.AI

TL;DR: ToolScope是一个代理框架，统一全局规划和局部多模态感知，通过专门的Perceive工具缓解长视野VQA任务中的视觉上下文退化问题，在多个VQA基准测试中平均性能提升达+6.69%。


<details>
  <summary>Details</summary>
Motivation: 由于多模态信息的复杂性和多样性，让多模态大语言模型在推理过程中灵活高效地使用外部工具仍是一个未充分探索的挑战。

Method: ToolScope包含三个主要组件：全局导航器（提供高层战略指导）、代理执行器（通过集成Search、Code和Perceive外部工具迭代增强MLLM的局部感知）、响应合成器（将推理过程整合为连贯的用户友好输出）。

Result: 在四个VQA基准测试（VQA 2.0、ScienceQA、MAT-Search和MathVista）上评估，表现出强大的泛化能力，在所有数据集上平均性能提升达+6.69%。

Conclusion: ToolScope框架成功解决了MLLM在复杂多模态任务中灵活使用外部工具的挑战，显著提升了VQA任务的性能。

Abstract: Recently, large language models (LLMs) have demonstrated remarkable
problem-solving capabilities by autonomously integrating with external tools
for collaborative reasoning. However, due to the inherently complex and diverse
nature of multimodal information, enabling multimodal large language models
(MLLMs) to flexibly and efficiently utilize external tools during reasoning
remains an underexplored challenge. In this work, we introduce ToolScope, an
agentic framework designed to unify global planning with local multimodal
perception, adopting a specialized Perceive tool to mitigates visual context
degradation in long-horizon VQA task. ToolScope comprises three primary
components: the Global Navigator, the Agentic Executor, and the Response
Synthesizer. The Global Navigator functions as a "telescope", offering
high-level strategic guidance. The Agentic Executor operates iteratively to
augment MLLM with local perception through the integration of external
tools-Search, Code, and Perceive. Finally, the Response Synthesizer
consolidates and organizes the reasoning process into a coherent, user-friendly
output. We evaluate ToolScope on four VQA benchmarks across diverse domains,
including VQA 2.0, ScienceQA, MAT-Search and MathVista. It demonstrates strong
generalization capabilities, achieving an average performance improvement of up
to +6.69% across all datasets.

</details>


### [64] [Realistic pedestrian-driver interaction modelling using multi-agent RL with human perceptual-motor constraints](https://arxiv.org/abs/2510.27383)
*Yueyang Wang,Mehmet Dogar,Gustav Markkula*

Main category: cs.AI

TL;DR: 提出一个集成视觉和运动约束的多智能体强化学习框架，用于模拟行人-驾驶员交互，在真实无信号人行横道数据集上验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖基于规则的逻辑、博弈论模型或'黑盒'机器学习，缺乏灵活性且忽略了感知和运动约束等底层机制。

Method: 使用多智能体强化学习框架，集成行人和驾驶员的视觉与运动约束，评估四种模型变体（无约束、仅运动约束、仅视觉约束、两者皆有）。

Result: 结合视觉和运动约束的模型表现最佳，运动约束产生更平滑的运动，视觉约束引入感知不确定性导致更谨慎的行为，在数据有限情况下优于监督行为克隆模型。

Conclusion: 带有人类约束的多智能体强化学习是模拟真实道路使用者交互的有前景的建模方法，能够考虑个体差异。

Abstract: Modelling pedestrian-driver interactions is critical for understanding human
road user behaviour and developing safe autonomous vehicle systems. Existing
approaches often rely on rule-based logic, game-theoretic models, or
'black-box' machine learning methods. However, these models typically lack
flexibility or overlook the underlying mechanisms, such as sensory and motor
constraints, which shape how pedestrians and drivers perceive and act in
interactive scenarios. In this study, we propose a multi-agent reinforcement
learning (RL) framework that integrates both visual and motor constraints of
pedestrian and driver agents. Using a real-world dataset from an unsignalised
pedestrian crossing, we evaluate four model variants, one without constraints,
two with either motor or visual constraints, and one with both, across
behavioural metrics of interaction realism. Results show that the combined
model with both visual and motor constraints performs best. Motor constraints
lead to smoother movements that resemble human speed adjustments during
crossing interactions. The addition of visual constraints introduces perceptual
uncertainty and field-of-view limitations, leading the agents to exhibit more
cautious and variable behaviour, such as less abrupt deceleration. In this
data-limited setting, our model outperforms a supervised behavioural cloning
model, demonstrating that our approach can be effective without large training
datasets. Finally, our framework accounts for individual differences by
modelling parameters controlling the human constraints as population-level
distributions, a perspective that has not been explored in previous work on
pedestrian-vehicle interaction modelling. Overall, our work demonstrates that
multi-agent RL with human constraints is a promising modelling approach for
simulating realistic road user interactions.

</details>


### [65] [Dialogue as Discovery: Navigating Human Intent Through Principled Inquiry](https://arxiv.org/abs/2510.27410)
*Jianwen Sun,Yukang Feng,Yifan Chang,Chuanhao Li,Zizhen Li,Jiaxin Ai,Fanrui Zhang,Yu Dai,Kaipeng Zhang*

Main category: cs.AI

TL;DR: 提出Nous智能体，通过主动询问来减少用户意图的不确定性，基于信息增益作为内在奖励，无需人工标注，在科学图表生成任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决人机协作中的'意图表达鸿沟'问题，即用户难以有效传达复杂高维想法给AI，导致低效试错循环。

Method: 基于信息论原理，将对话信息增益定义为内在奖励信号，等同于结构化任务空间中香农熵的减少，训练Nous智能体掌握主动询问策略。

Result: 在科学图表生成任务中，Nous实现了领先的效率和输出质量，对不同专业水平的用户都保持鲁棒性，且设计具有领域无关性。

Conclusion: 该工作为复杂人机协作中解决用户意图不确定性提供了原则性、可扩展和自适应的范式。

Abstract: A fundamental bottleneck in human-AI collaboration is the "intention
expression gap," the difficulty for humans to effectively convey complex,
high-dimensional thoughts to AI. This challenge often traps users in
inefficient trial-and-error loops and is exacerbated by the diverse expertise
levels of users. We reframe this problem from passive instruction following to
a Socratic collaboration paradigm, proposing an agent that actively probes for
information to resolve its uncertainty about user intent. we name the proposed
agent Nous, trained to acquire proficiency in this inquiry policy. The core
mechanism of Nous is a training framework grounded in the first principles of
information theory. Within this framework, we define the information gain from
dialogue as an intrinsic reward signal, which is fundamentally equivalent to
the reduction of Shannon entropy over a structured task space. This reward
design enables us to avoid reliance on costly human preference annotations or
external reward models. To validate our framework, we develop an automated
simulation pipeline to generate a large-scale, preference-based dataset for the
challenging task of scientific diagram generation. Comprehensive experiments,
including ablations, subjective and objective evaluations, and tests across
user expertise levels, demonstrate the effectiveness of our proposed framework.
Nous achieves leading efficiency and output quality, while remaining robust to
varying user expertise. Moreover, its design is domain-agnostic, and we show
evidence of generalization beyond diagram generation. Experimental results
prove that our work offers a principled, scalable, and adaptive paradigm for
resolving uncertainty about user intent in complex human-AI collaboration.

</details>


### [66] [DeepCompress: A Dual Reward Strategy for Dynamically Exploring and Compressing Reasoning Chains](https://arxiv.org/abs/2510.27419)
*Tian Liang,Wenxiang Jiao,Zhiwei He,Jiahao Xu,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: DeepCompress框架通过自适应长度奖励机制，动态分类问题为简单或困难，鼓励简单问题使用更短推理路径，困难问题使用更长探索性思维链，同时提升LRMs的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用监督微调或带token长度奖励的强化学习来提高效率，但往往以牺牲准确性为代价。LRMs存在认知效率低下的问题，如简单问题"过度思考"和复杂问题"思考不足"。

Method: 采用自适应长度奖励机制，实时基于模型能力动态分类问题为"简单"或"困难"。对简单问题鼓励更短推理路径，对困难问题鼓励更长探索性思维链，实现推理长度的自主调整。

Result: 在具有挑战性的数学基准测试中，DeepCompress始终优于基线方法，在显著提高token效率的同时实现了更优的准确性。

Conclusion: DeepCompress框架通过自适应长度奖励策略，成功解决了LRMs的认知效率问题，在保持准确性的同时显著提高了推理效率。

Abstract: Large Reasoning Models (LRMs) have demonstrated impressive capabilities but
suffer from cognitive inefficiencies like ``overthinking'' simple problems and
``underthinking'' complex ones. While existing methods that use supervised
fine-tuning~(SFT) or reinforcement learning~(RL) with token-length rewards can
improve efficiency, they often do so at the cost of accuracy. This paper
introduces \textbf{DeepCompress}, a novel framework that simultaneously
enhances both the accuracy and efficiency of LRMs. We challenge the prevailing
approach of consistently favoring shorter reasoning paths, showing that longer
responses can contain a broader range of correct solutions for difficult
problems. DeepCompress employs an adaptive length reward mechanism that
dynamically classifies problems as ``Simple'' or ``Hard'' in real-time based on
the model's evolving capability. It encourages shorter, more efficient
reasoning for ``Simple'' problems while promoting longer, more exploratory
thought chains for ``Hard'' problems. This dual-reward strategy enables the
model to autonomously adjust its Chain-of-Thought (CoT) length, compressing
reasoning for well-mastered problems and extending it for those it finds
challenging. Experimental results on challenging mathematical benchmarks show
that DeepCompress consistently outperforms baseline methods, achieving superior
accuracy while significantly improving token efficiency.

</details>


### [67] [GeoFM: Enhancing Geometric Reasoning of MLLMs via Synthetic Data Generation through Formal Language](https://arxiv.org/abs/2510.27448)
*Yuhao Zhang,Dingxin Hu,Tinghao Yu,Hao Liu,Yiting Liu*

Main category: cs.AI

TL;DR: GeoFM是一种新的几何数据合成方法，使用形式语言在度量空间中探索条件组合，通过符号引擎确保正确性，生成的合成数据在几何问题解决任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在数学几何推理方面面临高质量几何数据稀缺的挑战，现有合成方法生成的数据缺乏多样性且与真实几何图表差异较大。

Method: 使用形式语言在度量空间中探索条件组合，通过符号引擎确保生成的几何问题正确性，产生与原始问题不同但正确的高保真几何问题。

Result: 使用GeoFM合成数据训练的模型在MathVista几何问题解决任务上超过GPT-4o 18.7%，在GeoQA上超过16.5%；在开源模型上分别超过5.7%和2.7%。

Conclusion: GeoFM方法能有效生成高质量、多样化的几何数据，显著提升多模态大语言模型在几何推理任务上的性能。

Abstract: Multi-modal Large Language Models (MLLMs) have gained significant attention
in both academia and industry for their capabilities in handling multi-modal
tasks. However, these models face challenges in mathematical geometric
reasoning due to the scarcity of high-quality geometric data. To address this
issue, synthetic geometric data has become an essential strategy. Current
methods for generating synthetic geometric data involve rephrasing or expanding
existing problems and utilizing predefined rules and templates to create
geometric images and problems. However, these approaches often produce data
that lacks diversity or is prone to noise. Additionally, the geometric images
synthesized by existing methods tend to exhibit limited variation and deviate
significantly from authentic geometric diagrams. To overcome these limitations,
we propose GeoFM, a novel method for synthesizing geometric data. GeoFM uses
formal languages to explore combinations of conditions within metric space,
generating high-fidelity geometric problems that differ from the originals
while ensuring correctness through a symbolic engine. Experimental results show
that our synthetic data significantly outperforms existing methods. The model
trained with our data surpass the proprietary GPT-4o model by 18.7\% on
geometry problem-solving tasks in MathVista and by 16.5\% on GeoQA.
Additionally, it exceeds the performance of a leading open-source model by
5.7\% on MathVista and by 2.7\% on GeoQA.

</details>


### [68] [Mechanics of Learned Reasoning 1: TempoBench, A Benchmark for Interpretable Deconstruction of Reasoning System Performance](https://arxiv.org/abs/2510.27544)
*Nikolaus Holzer,William Fishell,Baishakhi Ray,Mark Santolucito*

Main category: cs.AI

TL;DR: TempoBench是第一个基于形式化验证的诊断基准，通过参数化难度来系统分析LLM的推理能力，包含时序轨迹评估和时序因果评估两个基准。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖临时生成的数据集（可能包含偏见且无法验证），要么使用Lean等数学证明系统（不适合捕捉现实世界决策链任务），导致LLM推理基准在推理结构和现实对齐方面存在不足。

Method: 使用两个评估基准：时序轨迹评估测试LLM理解和模拟多步推理系统的能力；时序因果评估测试LLM进行多步因果推理和从复杂系统中提取因果关系的能力。

Result: 模型在TCE-normal上得分65.6%，在TCE-hard上仅得7.5%，表明最先进的LLM理解TCE任务但系统复杂度增加时表现很差。

Conclusion: TempoBench填补了现有基准的空白，为系统分析LLM推理能力提供了形式化验证的诊断工具。

Abstract: Large Language Models (LLMs) are increasingly excelling and outpacing human
performance on many tasks. However, to improve LLM reasoning, researchers
either rely on ad-hoc generated datasets or formal mathematical proof systems
such as the Lean proof assistant. Whilst ad-hoc generated methods can capture
the decision chains of real-world reasoning processes, they may encode some
inadvertent bias in the space of reasoning they cover; they also cannot be
formally verified. On the other hand, systems like Lean can guarantee
verifiability, but are not well-suited to capture the nature of agentic
decision chain-based tasks. This creates a gap both in performance for
functions such as business agents or code assistants, and in the usefulness of
LLM reasoning benchmarks, whereby these fall short in reasoning structure or
real-world alignment. We introduce TempoBench, the first formally grounded and
verifiable diagnostic benchmark that parametrizes difficulty to systematically
analyze how LLMs perform reasoning. TempoBench uses two evaluation benchmarks
to break down reasoning ability. First, temporal trace evaluation (TTE) tests
the ability of an LLM to understand and simulate the execution of a given
multi-step reasoning system. Subsequently, temporal causal evaluation (TCE)
tests an LLM's ability to perform multi-step causal reasoning and to distill
cause-and-effect relations from complex systems. We find that models score
65.6% on TCE-normal, and 7.5% on TCE-hard. This shows that state-of-the-art
LLMs clearly understand the TCE task but perform poorly as system complexity
increases. Our code is available at our
\href{https://github.com/nik-hz/tempobench}{GitHub repository}.

</details>


### [69] [SIGMA: Search-Augmented On-Demand Knowledge Integration for Agentic Mathematical Reasoning](https://arxiv.org/abs/2510.27568)
*Ali Asgarov,Umid Suleymanov,Aadyant Khatri*

Main category: cs.AI

TL;DR: SIGMA是一个多智能体检索增强框架，通过专门智能体独立推理、定向搜索和协调机制，在数学推理任务上显著优于现有系统，性能提升7.4%。


<details>
  <summary>Details</summary>
Motivation: 当前检索增强模型依赖单一视角、搜索策略不灵活，难以有效整合多源信息，无法满足复杂数学推理需求。

Method: 引入SIGMA框架，协调专门智能体进行独立推理、定向搜索和结果合成，每个智能体生成假设性段落优化检索，确保知识整合的上下文敏感性和计算效率。

Result: 在MATH500、AIME和GPQA等挑战性基准测试中，SIGMA持续优于开源和闭源系统，绝对性能提升7.4%。

Conclusion: 多智能体按需知识整合显著提高了推理准确性和效率，为复杂知识密集型问题解决提供了可扩展方法。

Abstract: Solving mathematical reasoning problems requires not only accurate access to
relevant knowledge but also careful, multi-step thinking. However, current
retrieval-augmented models often rely on a single perspective, follow
inflexible search strategies, and struggle to effectively combine information
from multiple sources. We introduce SIGMA (Search-Augmented On-Demand Knowledge
Integration for AGentic Mathematical reAsoning), a unified framework that
orchestrates specialized agents to independently reason, perform targeted
searches, and synthesize findings through a moderator mechanism. Each agent
generates hypothetical passages to optimize retrieval for its analytic
perspective, ensuring knowledge integration is both context-sensitive and
computation-efficient. When evaluated on challenging benchmarks such as
MATH500, AIME, and PhD-level science QA GPQA, SIGMA consistently outperforms
both open- and closed-source systems, achieving an absolute performance
improvement of 7.4%. Our results demonstrate that multi-agent, on-demand
knowledge integration significantly enhances both reasoning accuracy and
efficiency, offering a scalable approach for complex, knowledge-intensive
problem-solving. We will release the code upon publication.

</details>


### [70] [InnovatorBench: Evaluating Agents' Ability to Conduct Innovative LLM Research](https://arxiv.org/abs/2510.27598)
*Yunze Wu,Dayuan Fu,Weiye Si,Zhen Huang,Mohan Jiang,Keyu Li,Shijie Xia,Jie Sun,Tianze Xu,Xiangkun Hu,Pengrui Lu,Xiaojie Cai,Lyumanshan Ye,Wenhong Zhu,Yang Xiao,Pengfei Liu*

Main category: cs.AI

TL;DR: 提出了InnovatorBench基准平台，用于评估AI代理在LLM研究中的端到端能力，包含20个任务和ResearchGym研究环境，实验显示前沿模型在代码驱动任务中表现良好但在算法相关任务和长期决策中存在困难。


<details>
  <summary>Details</summary>
Motivation: 现有基准在简化环境中测试狭窄技能，需要更现实的端到端评估来加速AI驱动的科学发现。

Method: 开发InnovatorBench基准（20个任务）和ResearchGym研究环境，实现轻量级ReAct代理结合推理与可执行规划。

Result: 前沿模型在代码驱动研究任务中表现良好，但在脆弱算法任务和长期决策中存在困难，代理需要超过11小时才能达到最佳性能。

Conclusion: InnovatorBench具有足够难度，有潜力成为下一代基于代码的研究基准，揭示了AI代理在科学研究自动化中的当前局限性和潜力。

Abstract: AI agents could accelerate scientific discovery by automating hypothesis
formation, experiment design, coding, execution, and analysis, yet existing
benchmarks probe narrow skills in simplified settings. To address this gap, we
introduce InnovatorBench, a benchmark-platform pair for realistic, end-to-end
assessment of agents performing Large Language Model (LLM) research. It
comprises 20 tasks spanning Data Construction, Filtering, Augmentation, Loss
Design, Reward Design, and Scaffold Construction, which require runnable
artifacts and assessment of correctness, performance, output quality, and
uncertainty. To support agent operation, we develop ResearchGym, a research
environment offering rich action spaces, distributed and long-horizon
execution, asynchronous monitoring, and snapshot saving. We also implement a
lightweight ReAct agent that couples explicit reasoning with executable
planning using frontier models such as Claude-4, GPT-5, GLM-4.5, and Kimi-K2.
Our experiments demonstrate that while frontier models show promise in
code-driven research tasks, they struggle with fragile algorithm-related tasks
and long-horizon decision making, such as impatience, poor resource management,
and overreliance on template-based reasoning. Furthermore, agents require over
11 hours to achieve their best performance on InnovatorBench, underscoring the
benchmark's difficulty and showing the potential of InnovatorBench to be the
next generation of code-based research benchmark.

</details>


### [71] [VeriMoA: A Mixture-of-Agents Framework for Spec-to-HDL Generation](https://arxiv.org/abs/2510.27617)
*Heng Ping,Arijit Bhattacharjee,Peiyu Zhang,Shixuan Li,Wei Yang,Anzhe Cheng,Xiaole Zhang,Jesse Thomason,Ali Jannesari,Nesreen Ahmed,Paul Bogdan*

Main category: cs.AI

TL;DR: VeriMoA是一个无需训练的多智能体框架，通过质量引导缓存和多路径生成策略，显著提升硬件描述语言(HDL)生成的性能，在多个基准测试中实现15-30%的Pass@1提升。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在HDL生成中面临参数知识有限和领域特定约束的挑战，而现有的多智能体方法存在噪声传播和推理空间受限的问题。

Method: 提出两种协同创新：1）质量引导缓存机制，维护所有中间HDL输出并进行质量排序选择；2）多路径生成策略，利用C++和Python作为中间表示，将规范到HDL的翻译分解为两阶段过程。

Result: 在VerilogEval 2.0和RTLLM 2.0基准测试中，VeriMoA在不同LLM骨干网络上实现了15-30%的Pass@1提升，特别是使较小模型能够匹配较大模型和微调替代方案。

Conclusion: VeriMoA提供了一个无需训练的有效框架，通过协同多智能体方法显著提升了HDL生成的性能，解决了现有方法的局限性。

Abstract: Automation of Register Transfer Level (RTL) design can help developers meet
increasing computational demands. Large Language Models (LLMs) show promise for
Hardware Description Language (HDL) generation, but face challenges due to
limited parametric knowledge and domain-specific constraints. While prompt
engineering and fine-tuning have limitations in knowledge coverage and training
costs, multi-agent architectures offer a training-free paradigm to enhance
reasoning through collaborative generation. However, current multi-agent
approaches suffer from two critical deficiencies: susceptibility to noise
propagation and constrained reasoning space exploration. We propose VeriMoA, a
training-free mixture-of-agents (MoA) framework with two synergistic
innovations. First, a quality-guided caching mechanism to maintain all
intermediate HDL outputs and enables quality-based ranking and selection across
the entire generation process, encouraging knowledge accumulation over layers
of reasoning. Second, a multi-path generation strategy that leverages C++ and
Python as intermediate representations, decomposing specification-to-HDL
translation into two-stage processes that exploit LLM fluency in high-resource
languages while promoting solution diversity. Comprehensive experiments on
VerilogEval 2.0 and RTLLM 2.0 benchmarks demonstrate that VeriMoA achieves
15--30% improvements in Pass@1 across diverse LLM backbones, especially
enabling smaller models to match larger models and fine-tuned alternatives
without requiring costly training.

</details>


### [72] [Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive Trigger Learning](https://arxiv.org/abs/2510.27623)
*Qiusi Zhan,Hyeonjeong Ha,Rui Yang,Sirui Xu,Hanyang Chen,Liang-Yan Gui,Yu-Xiong Wang,Huan Zhang,Heng Ji,Daniel Kang*

Main category: cs.AI

TL;DR: BEAT是首个针对MLLM多模态大语言模型驱动的具身智能体的视觉后门攻击框架，使用环境中的物体作为触发条件，能在触发出现时持续执行攻击者指定的多步策略。


<details>
  <summary>Details</summary>
Motivation: 随着MLLM驱动的具身智能体通过视觉输入直接感知、推理和规划任务导向行动，这种视觉驱动的具身智能体开启了新的攻击面：视觉后门攻击。

Method: BEAT通过(1)构建跨越多样化场景、任务和触发位置的数据集来暴露智能体于触发变异性，(2)采用两阶段训练方案：先进行监督微调(SFT)，然后引入新颖的对比触发学习(CTL)，将触发识别建模为偏好学习问题。

Result: 在各种具身智能体基准测试和MLLM上，BEAT实现了高达80%的攻击成功率，同时保持强大的良性任务性能，并能可靠地泛化到分布外的触发位置。与朴素SFT相比，CTL在有限后门数据下将后门激活准确率提升高达39%。

Conclusion: 这些发现揭示了MLLM基具身智能体中关键但未被探索的安全风险，强调了在现实世界部署前需要强大的防御措施。

Abstract: Multimodal large language models (MLLMs) have advanced embodied agents by
enabling direct perception, reasoning, and planning task-oriented actions from
visual inputs. However, such vision driven embodied agents open a new attack
surface: visual backdoor attacks, where the agent behaves normally until a
visual trigger appears in the scene, then persistently executes an
attacker-specified multi-step policy. We introduce BEAT, the first framework to
inject such visual backdoors into MLLM-based embodied agents using objects in
the environments as triggers. Unlike textual triggers, object triggers exhibit
wide variation across viewpoints and lighting, making them difficult to implant
reliably. BEAT addresses this challenge by (1) constructing a training set that
spans diverse scenes, tasks, and trigger placements to expose agents to trigger
variability, and (2) introducing a two-stage training scheme that first applies
supervised fine-tuning (SFT) and then our novel Contrastive Trigger Learning
(CTL). CTL formulates trigger discrimination as preference learning between
trigger-present and trigger-free inputs, explicitly sharpening the decision
boundaries to ensure precise backdoor activation. Across various embodied agent
benchmarks and MLLMs, BEAT achieves attack success rates up to 80%, while
maintaining strong benign task performance, and generalizes reliably to
out-of-distribution trigger placements. Notably, compared to naive SFT, CTL
boosts backdoor activation accuracy up to 39% under limited backdoor data.
These findings expose a critical yet unexplored security risk in MLLM-based
embodied agents, underscoring the need for robust defenses before real-world
deployment.

</details>


### [73] [Validity Is What You Need](https://arxiv.org/abs/2510.27628)
*Sebastian Benthall,Andrew Clark*

Main category: cs.AI

TL;DR: 论文提出了Agentic AI的现实主义定义，将其视为在复杂企业环境中自主工作的软件交付机制，强调验证比基础模型更重要。


<details>
  <summary>Details</summary>
Motivation: 当前对Agentic AI的定义存在混淆，需要明确其作为应用而非基础模型的本质，并强调验证的重要性。

Method: 通过比较软件即服务(SaaS)模式，提出Agentic AI作为软件交付机制的新定义，并讨论验证工具与基础模型评估工具的区别。

Result: 确立了Agentic AI的现实主义定义，指出在良好验证措施下，大语言模型可被更简单、快速、可解释的模型替代。

Conclusion: Agentic AI的成功关键在于验证，而非基础模型本身；大语言模型只是实现有效验证的选项之一。

Abstract: While AI agents have long been discussed and studied in computer science,
today's Agentic AI systems are something new. We consider other definitions of
Agentic AI and propose a new realist definition. Agentic AI is a software
delivery mechanism, comparable to software as a service (SaaS), which puts an
application to work autonomously in a complex enterprise setting. Recent
advances in large language models (LLMs) as foundation models have driven
excitement in Agentic AI. We note, however, that Agentic AI systems are
primarily applications, not foundations, and so their success depends on
validation by end users and principal stakeholders. The tools and techniques
needed by the principal users to validate their applications are quite
different from the tools and techniques used to evaluate foundation models.
Ironically, with good validation measures in place, in many cases the
foundation models can be replaced with much simpler, faster, and more
interpretable models that handle core logic. When it comes to Agentic AI,
validity is what you need. LLMs are one option that might achieve it.

</details>


### [74] [Interaction as Intelligence Part II: Asynchronous Human-Agent Rollout for Long-Horizon Task Training](https://arxiv.org/abs/2510.27630)
*Dayuan Fu,Yunze Wu,Xiaojie Cai,Lyumanshan Ye,Shijie Xia,Zhen Huang,Weiye Si,Tianze Xu,Jie Sun,Keyu Li,Mohan Jiang,Junfei Wang,Qishuo Hua,Pengrui Lu,Yang Xiao,Pengfei Liu*

Main category: cs.AI

TL;DR: Apollo是一个集成异步人类指导与动作级数据过滤的采样框架，用于训练LLM代理处理长周期、领域专业化任务，相比基线提升50%以上。


<details>
  <summary>Details</summary>
Motivation: 当前训练LLM代理的方法存在两个问题：基于密集人工标注的行为克隆成本过高，而基于结果驱动的采样方法在领域专业化任务中容易因有效轨迹稀少而失败。

Method: Apollo框架允许标注者仅在代理偏离有希望轨迹时进行干预，提供先验知识、策略建议等轻量级指导，同时应用监督控制过滤次优动作以防止错误传播。

Result: 在InnovatorBench上的实验表明，使用Apollo训练的GLM-4.5模型相比未训练基线提升超过50%，相比无人交互训练变体提升28%。

Conclusion: Apollo证明了人类在环采样在处理长周期、领域专业化任务中的关键作用，其设计具有鲁棒性和有效性。

Abstract: Large Language Model (LLM) agents have recently shown strong potential in
domains such as automated coding, deep research, and graphical user interface
manipulation. However, training them to succeed on long-horizon,
domain-specialized tasks remains challenging. Current methods primarily fall
into two categories. The first relies on dense human annotations through
behavior cloning, which is prohibitively expensive for long-horizon tasks that
can take days or months. The second depends on outcome-driven sampling, which
often collapses due to the rarity of valid positive trajectories on
domain-specialized tasks. We introduce Apollo, a sampling framework that
integrates asynchronous human guidance with action-level data filtering.
Instead of requiring annotators to shadow every step, Apollo allows them to
intervene only when the agent drifts from a promising trajectory, by providing
prior knowledge, strategic advice, etc. This lightweight design makes it
possible to sustain interactions for over 30 hours and produces valuable
trajectories at a lower cost. Apollo then applies supervision control to filter
out sub-optimal actions and prevent error propagation. Together, these
components enable reliable and effective data collection in long-horizon
environments. To demonstrate the effectiveness of Apollo, we evaluate it using
InnovatorBench. Our experiments show that when applied to train the GLM-4.5
model on InnovatorBench, Apollo achieves more than a 50% improvement over the
untrained baseline and a 28% improvement over a variant trained without human
interaction. These results highlight the critical role of human-in-the-loop
sampling and the robustness of Apollo's design in handling long-horizon,
domain-specialized tasks.

</details>


### [75] [MolChord: Structure-Sequence Alignment for Protein-Guided Drug Design](https://arxiv.org/abs/2510.27671)
*Wei Zhang,Zekun Guo,Yingce Xia,Peiran Jin,Shufang Xie,Tao Qin,Xiang-Yang Li*

Main category: cs.AI

TL;DR: MolChord是一个基于结构的药物设计方法，通过整合蛋白质和分子结构的文本描述与序列表示，结合偏好数据优化药物属性对齐，在CrossDocked2020上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决基于结构的药物设计中蛋白质结构表示与分子表示的有效对齐问题，以及生成药物与其药理属性的对齐挑战。

Method: 使用NatureLM作为分子生成器统一文本、小分子和蛋白质表示，结合扩散结构编码器；通过整合偏好数据构建属性感知数据集，并采用直接偏好优化(DPO)改进对齐过程。

Result: 在CrossDocked2020数据集上的实验结果表明，该方法在关键评估指标上达到了最先进的性能。

Conclusion: MolChord展示了作为实用SBDD工具的潜力，能够有效解决蛋白质-分子结构对齐和药物属性优化问题。

Abstract: Structure-based drug design (SBDD), which maps target proteins to candidate
molecular ligands, is a fundamental task in drug discovery. Effectively
aligning protein structural representations with molecular representations, and
ensuring alignment between generated drugs and their pharmacological
properties, remains a critical challenge. To address these challenges, we
propose MolChord, which integrates two key techniques: (1) to align protein and
molecule structures with their textual descriptions and sequential
representations (e.g., FASTA for proteins and SMILES for molecules), we
leverage NatureLM, an autoregressive model unifying text, small molecules, and
proteins, as the molecule generator, alongside a diffusion-based structure
encoder; and (2) to guide molecules toward desired properties, we curate a
property-aware dataset by integrating preference data and refine the alignment
process using Direct Preference Optimization (DPO). Experimental results on
CrossDocked2020 demonstrate that our approach achieves state-of-the-art
performance on key evaluation metrics, highlighting its potential as a
practical tool for SBDD.

</details>
