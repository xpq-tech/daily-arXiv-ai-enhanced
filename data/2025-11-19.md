<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 47]
- [cs.AI](#cs.AI) [Total: 31]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Signature vs. Substance: Evaluating the Balance of Adversarial Resistance and Linguistic Quality in Watermarking Large Language Models](https://arxiv.org/abs/2511.13722)
*William Guo,Adaku Uchendu,Ana Smith*

Main category: cs.CL

TL;DR: 评估水印技术在对抗攻击下的鲁棒性，分析其对文本质量和写作风格的保留能力，发现现有水印技术能保持语义但会改变写作风格，且易受对抗攻击影响。


<details>
  <summary>Details</summary>
Motivation: 减轻大语言模型生成文本的潜在危害，通过水印技术嵌入可检测信号，但现有技术存在影响文本质量和易受攻击的问题，阻碍了广泛应用。

Method: 评估多种水印技术对对抗攻击的鲁棒性，比较改述和回译攻击，使用语言指标分析水印文本在质量和写作风格上的保留能力。

Result: 水印技术能保持语义，但会偏离原始文本的写作风格，且容易受到对抗攻击，特别是回译攻击。

Conclusion: 当前水印技术在语义保留方面表现良好，但在写作风格保持和对抗攻击鲁棒性方面存在不足，需要改进以促进更广泛采用。

Abstract: To mitigate the potential harms of Large Language Models (LLMs)generated text, researchers have proposed watermarking, a process of embedding detectable signals within text. With watermarking, we can always accurately detect LLM-generated texts. However, recent findings suggest that these techniques often negatively affect the quality of the generated texts, and adversarial attacks can strip the watermarking signals, causing the texts to possibly evade detection. These findings have created resistance in the wide adoption of watermarking by LLM creators. Finally, to encourage adoption, we evaluate the robustness of several watermarking techniques to adversarial attacks by comparing paraphrasing and back translation (i.e., English $\to$ another language $\to$ English) attacks; and their ability to preserve quality and writing style of the unwatermarked texts by using linguistic metrics to capture quality and writing style of texts. Our results suggest that these watermarking techniques preserve semantics, deviate from the writing style of the unwatermarked texts, and are susceptible to adversarial attacks, especially for the back translation attack.

</details>


### [2] [Refine Thought: A Test-Time Inference Method for Embedding Model Reasoning](https://arxiv.org/abs/2511.13726)
*Guangzhi Wang,Kai Li,Yinghao Jiao,Zhi Liu*

Main category: cs.CL

TL;DR: RT（Refine Thought）是一种通过多次前向传递来增强文本嵌入模型语义推理能力的方法，在语义推理任务上表现显著提升，同时保持通用语义理解任务的性能。


<details>
  <summary>Details</summary>
Motivation: 增强文本嵌入模型的语义推理能力，激活预训练期间学到的语义推理潜力。

Method: 通过多次前向传递运行文本嵌入模型，获得最终的语义表示。

Result: 在BRIGHT和PJBenchmark1语义推理任务上取得显著改进，在C-MTEB等通用语义理解任务上保持稳定性能。

Conclusion: RT作为测试时推理方法，能有效激活仅解码器文本嵌入模型在预训练期间学到的语义推理能力。

Abstract: We propose RT (Refine Thought), a method that can enhance the semantic rea-soning ability of text embedding models. The method obtains the final semanticrepresentation by running multiple forward passes of the text embedding model.Experiments show that RT achieves significant improvements on semantic reason-ing tasks in BRIGHT and the person job matching benchmark PJBenchmark1, while maintaining consistent performance on general-purpose semantic under-standing tasks such as C-MTEB. Our results indicate that RT is effective becauseit further activates the semantic reasoning ability learned during pretraining bydecoder-only text embedding models(e.g., Qwen3-Embedding-8B). RT canbe seen as a test-time inference method.

</details>


### [3] [Can QE-informed (Re)Translation lead to Error Correction?](https://arxiv.org/abs/2511.13884)
*Govardhan Padmanabhan*

Main category: cs.CL

TL;DR: 论文提出了两种无需训练的方法用于WMT 2025质量评估指导的机器翻译错误修正任务：基于质量评估的重翻译方法和基于质量评估解释的错误替换方法，前者在排行榜上获得优胜。


<details>
  <summary>Details</summary>
Motivation: 虽然联合训练质量评估系统和自动后编辑系统能提升性能，但自动后编辑系统存在过度修正问题，导致性能下降。研究者希望探索无需训练的简单方法来避免这个问题。

Method: 方法一：质量评估指导的重翻译，从不同大语言模型生成的多个候选中选择质量最高的翻译。方法二：基于质量评估解释的错误替换，使用条件启发式方法最小化编辑次数以最大化增益编辑比。

Result: 两种方法分别获得了0.0201和-0.0108的Delta COMET分数，第一种方法在子任务排行榜上获得优胜位置。

Conclusion: 质量评估指导的重翻译方法在无需训练的情况下表现优于基于质量评估解释的错误替换方法，证明了从多个候选中选择最佳翻译的有效性。

Abstract: The paper presents two approaches submitted to the WMT 2025 Automated Translation Quality Evaluation Systems Task 3 - Quality Estimation (QE)-informed Segment-level Error Correction. While jointly training QE systems with Automatic Post-Editing (APE) has shown improved performance for both tasks, APE systems are still known to overcorrect the output of Machine Translation (MT), leading to a degradation in performance. We investigate a simple training-free approach - QE-informed Retranslation, and compare it with another within the same training-free paradigm. Our winning approach selects the highest-quality translation from multiple candidates generated by different LLMs. The second approach, more akin to APE, instructs an LLM to replace error substrings as specified in the provided QE explanation(s). A conditional heuristic was employed to minimise the number of edits, with the aim of maximising the Gain-to-Edit ratio. The two proposed approaches achieved a Delta COMET score of 0.0201 and -0.0108, respectively, leading the first approach to achieve the winning position on the subtask leaderboard.

</details>


### [4] [What Works for 'Lost-in-the-Middle' in LLMs? A Study on GM-Extract and Mitigations](https://arxiv.org/abs/2511.13900)
*Mihir Gupte,Eshan Dixit,Muhammad Tayyab,Arun Adiththan*

Main category: cs.CL

TL;DR: 提出了GM-Extract基准数据集来评估LLM在长文档中检索控制变量的能力，发现数据表示方式显著影响检索性能，并测试了缓解方法的效果。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在长范围上下文中的"迷失在中间"现象，特别是在基于检索的LLM应用中。

Method: 使用GM-Extract基准数据集，通过文档指标和变量提取指标两个维度评估7-8B参数模型在多文档任务中的表现，并测试黑盒和白盒缓解方法。

Result: 数据表示方式显著改变检索性能，虽然未始终观察到明显的U形曲线，但发现了清晰的性能模式。缓解方法的效果具有高度细微差别，有些情况下甚至会产生负面影响。

Conclusion: 在真实应用场景中，长上下文检索性能受多种因素影响，缓解策略需要根据具体情境谨慎应用。

Abstract: The diminishing ability of large language models (LLMs) to effectively utilize long-range context-the "lost-in-the-middle" phenomenon-poses a significant challenge in retrieval-based LLM applications. To study the impact of this phenomenon in a real-world application setting, we introduce GM-Extract, a novel benchmark dataset meticulously designed to evaluate LLM performance on retrieval of control variables. To accurately diagnose failure modes, we propose a simple yet elegant evaluation system using two distinct metrics: one for spatial retrieval capability (Document Metric) and the other for semantic retrieval capability (Variable Extraction Metric). We conduct a systematic evaluation of 7-8B parameter models on two multi-document tasks (key-value extraction and question-answering), demonstrating a significant change in retrieval performance simply by altering how the data is represented in the context window. While a distinct U-shaped curve was not consistently observed, our analysis reveals a clear pattern of performance across models, which we further correlate with perplexity scores. Furthermore, we perform a literature survey of mitigation methods, which we categorize into two distinct approaches: black-box and white-box methods. We then apply these techniques to our benchmark, finding that their efficacy is highly nuanced. Our evaluation highlights scenarios where these strategies successfully improve performance, as well as surprising cases where they lead to a negative impact, providing a comprehensive understanding of their utility in a practical context.

</details>


### [5] [Hint-Augmented Re-ranking: Efficient Product Search using LLM-Based Query Decomposition](https://arxiv.org/abs/2511.13994)
*Yilun Zhu,Nikhita Vedula,Shervin Malmasi*

Main category: cs.CL

TL;DR: LLM框架解析电商搜索中的最高级查询意图，通过提取结构化提示来改进搜索性能，同时解决延迟问题


<details>
  <summary>Details</summary>
Motivation: 最高级搜索查询（如'最好'、'最受欢迎'）需要跨多个维度比较候选商品，这需要语言理解和领域知识

Method: 将查询分解为属性-值提示，与检索过程并行生成，并将最高级解释迁移到轻量级模型中

Result: 搜索性能提升10.9点MAP，排名提升5.9点MRR，同时解决了直接LLM重排的延迟问题

Conclusion: 该方法为最高级语义在检索系统中的表示和迁移提供了见解，在解决实际部署约束的同时推进了语言解释能力

Abstract: Search queries with superlatives (e.g., best, most popular) require comparing candidates across multiple dimensions, demanding linguistic understanding and domain knowledge. We show that LLMs can uncover latent intent behind these expressions in e-commerce queries through a framework that extracts structured interpretations or hints. Our approach decomposes queries into attribute-value hints generated concurrently with retrieval, enabling efficient integration into the ranking pipeline. Our method improves search performanc eby 10.9 points in MAP and ranking by 5.9 points in MRR over baselines. Since direct LLM-based reranking faces prohibitive latency, we develop an efficient approach transferring superlative interpretations to lightweight models. Our findings provide insights into how superlative semantics can be represented and transferred between models, advancing linguistic interpretation in retrieval systems while addressing practical deployment constraints.

</details>


### [6] [Knowledge-Grounded Agentic Large Language Models for Multi-Hazard Understanding from Reconnaissance Reports](https://arxiv.org/abs/2511.14010)
*Chenchen Kuai,Zihao Li,Braden Rosen,Stephanie Paan,Navid Jafari,Jean-Louis Briaud,Yunlong Zhang,Youssef M. A. Hashash,Yang Zhou*

Main category: cs.CL

TL;DR: 提出了MoRA-RAG框架，通过混合检索和代理分块技术，将灾后勘察报告转化为结构化知识，用于多灾害推理，显著提高准确率并减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 灾后勘察报告包含理解多灾害相互作用的关键证据，但其非结构化叙述使得系统知识转移困难。LLMs在缺乏领域基础时会产生不可靠或幻觉输出。

Method: MoRA-RAG框架整合混合检索机制，动态路由跨灾害特定数据库的查询，使用代理分块保持检索中的上下文连贯性，并包含验证循环评估证据充分性。

Result: 在HazardRecQA数据集上达到94.5%准确率，比零样本LLMs提高30%，比最先进RAG系统提高10%，同时在不同LLM架构中减少幻觉。

Conclusion: MoRA-RAG为将灾后文档转化为可操作、可信赖的灾害韧性情报建立了新范式，使开源LLMs达到与专有模型相当的性能。

Abstract: Post-disaster reconnaissance reports contain critical evidence for understanding multi-hazard interactions, yet their unstructured narratives make systematic knowledge transfer difficult. Large language models (LLMs) offer new potential for analyzing these reports, but often generate unreliable or hallucinated outputs when domain grounding is absent. This study introduces the Mixture-of-Retrieval Agentic RAG (MoRA-RAG), a knowledge-grounded LLM framework that transforms reconnaissance reports into a structured foundation for multi-hazard reasoning. The framework integrates a Mixture-of-Retrieval mechanism that dynamically routes queries across hazard-specific databases while using agentic chunking to preserve contextual coherence during retrieval. It also includes a verification loop that assesses evidence sufficiency, refines queries, and initiates targeted searches when information remains incomplete. We construct HazardRecQA by deriving question-answer pairs from GEER reconnaissance reports, which document 90 global events across seven major hazard types. MoRA-RAG achieves up to 94.5 percent accuracy, outperforming zero-shot LLMs by 30 percent and state-of-the-art RAG systems by 10 percent, while reducing hallucinations across diverse LLM architectures. MoRA-RAG also enables open-weight LLMs to achieve performance comparable to proprietary models. It establishes a new paradigm for transforming post-disaster documentation into actionable, trustworthy intelligence for hazard resilience.

</details>


### [7] [HiEAG: Evidence-Augmented Generation for Out-of-Context Misinformation Detection](https://arxiv.org/abs/2511.14027)
*Junjie Wu,Yumeng Fu,Nan Yu,Guohong Fu*

Main category: cs.CL

TL;DR: HiEAG是一个新颖的分层证据增强生成框架，通过利用多模态大语言模型的知识来改进外部一致性检查，在跨模态虚假信息检测中超越了现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有的跨模态虚假信息检测方法主要关注内部一致性，而忽略了图像-文本对与外部证据之间的外部一致性的重要性。

Method: 提出HiEAG框架，将外部一致性检查分解为检索、重排序和重写的综合引擎流程，使用自动证据选择提示和自动证据生成提示来改进任务适应性。

Result: 在不同基准数据集上的实验结果表明，HiEAG在所有样本的准确率上超越了之前的最先进方法。

Conclusion: HiEAG通过分层证据增强生成框架有效提升了跨模态虚假信息检测的性能，证明了外部一致性检查的重要性。

Abstract: Recent advancements in multimodal out-of-context (OOC) misinformation detection have made remarkable progress in checking the consistencies between different modalities for supporting or refuting image-text pairs. However, existing OOC misinformation detection methods tend to emphasize the role of internal consistency, ignoring the significant of external consistency between image-text pairs and external evidence. In this paper, we propose HiEAG, a novel Hierarchical Evidence-Augmented Generation framework to refine external consistency checking through leveraging the extensive knowledge of multimodal large language models (MLLMs). Our approach decomposes external consistency checking into a comprehensive engine pipeline, which integrates reranking and rewriting, apart from retrieval. Evidence reranking module utilizes Automatic Evidence Selection Prompting (AESP) that acquires the relevant evidence item from the products of evidence retrieval. Subsequently, evidence rewriting module leverages Automatic Evidence Generation Prompting (AEGP) to improve task adaptation on MLLM-based OOC misinformation detectors. Furthermore, our approach enables explanation for judgment, and achieves impressive performance with instruction tuning. Experimental results on different benchmark datasets demonstrate that our proposed HiEAG surpasses previous state-of-the-art (SOTA) methods in the accuracy over all samples.

</details>


### [8] [Based on Data Balancing and Model Improvement for Multi-Label Sentiment Classification Performance Enhancement](https://arxiv.org/abs/2511.14073)
*Zijin Su,Huanzhu Lv,Yuren Niu,Yiming Liu*

Main category: cs.CL

TL;DR: 构建了一个平衡的多标签情感数据集，并开发了增强的多标签分类模型，在情感分类性能上相比不平衡数据训练的模型有显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决现有多标签情感分类数据集（如GoEmotions）中严重的类别不平衡问题，该问题阻碍了模型性能，特别是对于代表性不足的情绪类别。

Method: 1）通过整合原始GoEmotions数据、使用RoBERTa-base-GoEmotions模型标记的Sentiment140样本和GPT-4 mini生成的手动标注文本，构建平衡的多标签情感数据集；2）开发包含FastText嵌入、卷积层、双向LSTM、注意力机制和Sigmoid输出层的多标签分类模型；3）采用混合精度训练提高计算效率。

Result: 实验结果显示，在准确率、精确率、召回率、F1分数和AUC方面相比在不平衡数据上训练的模型有显著改进。

Conclusion: 该方法有效解决了多标签情感分类中的类别不平衡问题，显著提升了模型性能。

Abstract: Multi-label sentiment classification plays a vital role in natural language processing by detecting multiple emotions within a single text. However, existing datasets like GoEmotions often suffer from severe class imbalance, which hampers model performance, especially for underrepresented emotions. To address this, we constructed a balanced multi-label sentiment dataset by integrating the original GoEmotions data, emotion-labeled samples from Sentiment140 using a RoBERTa-base-GoEmotions model, and manually annotated texts generated by GPT-4 mini. Our data balancing strategy ensured an even distribution across 28 emotion categories. Based on this dataset, we developed an enhanced multi-label classification model that combines pre-trained FastText embeddings, convolutional layers for local feature extraction, bidirectional LSTM for contextual learning, and an attention mechanism to highlight sentiment-relevant words. A sigmoid-activated output layer enables multi-label prediction, and mixed precision training improves computational efficiency. Experimental results demonstrate significant improvements in accuracy, precision, recall, F1-score, and AUC compared to models trained on imbalanced data, highlighting the effectiveness of our approach.

</details>


### [9] [Stealth Fine-Tuning: Efficiently Breaking Alignment in RVLMs Using Self-Generated CoT](https://arxiv.org/abs/2511.14106)
*Le Yu,Zhengyue Zhao,Yawen Zheng,Yunhao Liu*

Main category: cs.CL

TL;DR: 提出了一种名为Stealth Fine-Tuning的新型攻击方法，通过分段干扰和自生成输出作为监督微调数据，能够以低成本高效地绕过RVLMs的安全对齐防御。


<details>
  <summary>Details</summary>
Motivation: 虽然RVLMs依赖安全对齐来防止有害行为，但其暴露的思维链轨迹引入了新的攻击面。研究发现RVLMs的安全对齐很容易被突破。

Method: 使用分段干扰引发有害推理轨迹，将自生成输出作为监督微调数据，采用基于轮次的加权损失设计，实现轻量级、分布一致的微调方法。

Result: 仅用499个样本和单张A100显卡3小时（QLoRA），攻击成功率比IDEATOR提高38.52%，同时保持通用推理能力，模型保留原始表示分布。

Conclusion: Stealth Fine-Tuning是一种低成本、高效的方法，能够有效绕过对齐防御，在AdvBench和多个通用基准测试中表现出色。

Abstract: Reasoning-augmented Vision-Language Models (RVLMs) rely on safety alignment to prevent harmful behavior, yet their exposed chain-of-thought (CoT) traces introduce new attack surfaces. In this work, we find that the safety alignment of RVLMs can be easily break through a novel attack method termed \textbf{Stealth Fine-Tuning}. Our method elicits harmful reasoning traces through \textbf{segment-level interference} and reuses the self-generated outputs as supervised fine-tuning data. Through a \textbf{turn-based weighted} loss design, yielding a lightweight, distribution-consistent finetuning method. In our experiment, with only 499 samples and under 3 hours on a single A100 (QLoRA), Stealth Fine-Tuning outperforms IDEATOR by 38.52\% ASR while preserving general reasoning ability, as the tuned model retains the original representation distribution. Experiments on AdvBench and several general benchmarks demonstrate that Stealth Fine-Tuning is a low-cost and highly effective way to bypass alignment defenses. \textcolor{red}{\textbf{Disclaimer: This paper contains content that may be disturbing or offensive.}}

</details>


### [10] [Synthetic Clinical Notes for Rare ICD Codes: A Data-Centric Framework for Long-Tail Medical Coding](https://arxiv.org/abs/2511.14112)
*Truong Vo,Weiyi Wu,Kaize Ding*

Main category: cs.CL

TL;DR: 提出基于数据中心的框架，通过生成高质量合成出院摘要来缓解ICD编码的长尾分布问题，在保持强微观F1的同时适度提升宏观F1性能。


<details>
  <summary>Details</summary>
Motivation: 自动ICD编码任务受到诊断代码极端长尾分布的阻碍，数千个罕见和零样本ICD代码在数据集中严重不足，导致宏观F1分数低下。

Method: 构建基于罕见代码的现实多标签代码集，利用真实世界共现模式、ICD描述、同义词、分类法和相似临床笔记生成结构化提示，生成90,000个合成笔记覆盖7,902个ICD代码。

Result: 在两个最先进的基于transformer的模型上微调，实验表明该方法在保持强微观F1的同时适度提升宏观F1，优于先前SOTA。

Conclusion: 精心设计的合成数据可以增强长尾ICD代码预测的公平性，尽管相对于计算成本而言增益可能显得有限。

Abstract: Automatic ICD coding from clinical text is a critical task in medical NLP but remains hindered by the extreme long-tail distribution of diagnostic codes. Thousands of rare and zero-shot ICD codes are severely underrepresented in datasets like MIMIC-III, leading to low macro-F1 scores. In this work, we propose a data-centric framework that generates high-quality synthetic discharge summaries to mitigate this imbalance. Our method constructs realistic multi-label code sets anchored on rare codes by leveraging real-world co-occurrence patterns, ICD descriptions, synonyms, taxonomy, and similar clinical notes. Using these structured prompts, we generate 90,000 synthetic notes covering 7,902 ICD codes, significantly expanding the training distribution. We fine-tune two state-of-the-art transformer-based models, PLM-ICD and GKI-ICD, on both the original and extended datasets. Experiments show that our approach modestly improves macro-F1 while maintaining strong micro-F1, outperforming prior SOTA. While the gain may seem marginal relative to the computational cost, our results demonstrate that carefully crafted synthetic data can enhance equity in long-tail ICD code prediction.

</details>


### [11] [From Graphs to Hypergraphs: Enhancing Aspect-Based Sentiment Analysis via Multi-Level Relational Modeling](https://arxiv.org/abs/2511.14142)
*Omkar Mahesh Kashyap,Padegal Amit,Madhav Kashyap,Ashwini M Joshi,Shylaja SS*

Main category: cs.CL

TL;DR: HyperABSA是一个动态超图框架，通过样本特定的层次聚类来构建方面-观点结构，解决了传统图方法在多关系视图中的冗余、参数开销和错误传播问题，在短文本、低资源场景下表现更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 传统基于图的方法只能建模成对依赖关系，需要为不同关系视图构建多个图，这引入了冗余、参数开销和融合过程中的错误传播，限制了在短文本、低资源设置下的鲁棒性。

Method: 提出了HyperABSA动态超图框架，通过样本特定的层次聚类诱导方面-观点结构。引入了一种新颖的加速-回退截止策略用于层次聚类，自适应地确定粒度级别。

Result: 在三个基准数据集（Lap14、Rest14、MAMS）上的实验显示，与强大的图基线相比取得了持续改进，特别是与RoBERTa骨干网络配对时获得了显著增益。

Conclusion: 动态超图构建是ABSA任务的高效、强大替代方案，并有潜力扩展到其他短文本NLP任务。

Abstract: Aspect-Based Sentiment Analysis (ABSA) predicts sentiment polarity for specific aspect terms, a task made difficult by conflicting sentiments across aspects and the sparse context of short texts. Prior graph-based approaches model only pairwise dependencies, forcing them to construct multiple graphs for different relational views. These introduce redundancy, parameter overhead, and error propagation during fusion, limiting robustness in short-text, low-resource settings. We present HyperABSA, a dynamic hypergraph framework that induces aspect-opinion structures through sample-specific hierarchical clustering. To construct these hyperedges, we introduce a novel acceleration-fallback cutoff for hierarchical clustering, which adaptively determines the level of granularity. Experiments on three benchmarks (Lap14, Rest14, MAMS) show consistent improvements over strong graph baselines, with substantial gains when paired with RoBERTa backbones. These results position dynamic hypergraph construction as an efficient, powerful alternative for ABSA, with potential extensions to other short-text NLP tasks.

</details>


### [12] [Applying Relation Extraction and Graph Matching to Answering Multiple Choice Questions](https://arxiv.org/abs/2511.14144)
*Naoki Shimoda,Akihiro Yamamoto*

Main category: cs.CL

TL;DR: 提出了一种结合Transformer关系抽取和知识图谱匹配的方法，用于回答填空题形式的多选题，并保持输出过程的可追溯性。


<details>
  <summary>Details</summary>
Motivation: 传统知识图谱构建成本高且被视为静态数据库，而基于Transformer的关系抽取方法能够动态生成知识图谱，为表示输入句子的含义提供了可能性。

Method: 通过关系抽取方法将问题句子转换为关系图，然后在封闭世界假设下与事实正确的知识图谱进行验证，以衡量每个问题句子的真实性。

Result: 实验结果表明，该方法能够正确回答约70%的问题，同时提供程序的可追溯性。问题类别对准确性有显著影响。

Conclusion: 该方法成功实现了基于动态生成知识图谱的多选题回答，并保持了推理过程的透明度。

Abstract: In this research, we combine Transformer-based relation extraction with matching of knowledge graphs (KGs) and apply them to answering multiple-choice questions (MCQs) while maintaining the traceability of the output process. KGs are structured representations of factual knowledge consisting of entities and relations. Due to the high construction cost, they had been regarded as static databases with validated links. However, the recent development of Transformer-based relation extraction (RE) methods has enabled us to generate KGs dynamically by giving them natural language texts, and thereby opened the possibility for representing the meaning of the input sentences with the created KGs. Using this effect, we propose a method that answers MCQs in the "fill-in-the-blank" format, taking care of the point that RE methods generate KGs that represent false information if provided with factually incorrect texts. We measure the truthfulness of each question sentence by (i) converting the sentence into a relational graph using an RE method and (ii) verifying it against factually correct KGs under the closed-world assumption. The experimental results demonstrate that our method correctly answers up to around 70% of the questions, while providing traceability of the procedure. We also highlight that the question category has a vast influence on the accuracy.

</details>


### [13] [Selective Weak-to-Strong Generalization](https://arxiv.org/abs/2511.14166)
*Hao Lang,Fei Huang,Yongbin Li*

Main category: cs.CL

TL;DR: 提出了选择性弱到强泛化框架，通过训练二元分类器识别强模型能回答的问题，避免不必要的弱监督，并使用图平滑方法精炼弱标签，在三个基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决超人类模型对齐中高质量数据缺乏的问题，现有弱到强泛化方法使用不变的弱监督存在鲁棒性问题，部分弱标签对模型有害。

Method: 训练二元分类器P(IK)识别强模型能回答的问题，使用自生成标签进行对齐，通过图平滑方法精炼弱标签。

Result: 在三个基准测试中持续优于竞争基线，P(IK)能够跨任务和难度泛化。

Conclusion: 选择性弱到强泛化有助于实现超对齐。

Abstract: Future superhuman models will surpass the ability of humans and humans will only be able to \textit{weakly} supervise superhuman models. To alleviate the issue of lacking high-quality data for model alignment, some works on weak-to-strong generalization (W2SG) finetune a strong pretrained model with a weak supervisor so that it can generalize beyond weak supervision. However, the invariable use of weak supervision in existing methods exposes issues in robustness, with a proportion of weak labels proving harmful to models. In this paper, we propose a selective W2SG framework to avoid using weak supervision when unnecessary. We train a binary classifier P(IK) to identify questions that a strong model can answer and use its self-generated labels for alignment. We further refine weak labels with a graph smoothing method. Extensive experiments on three benchmarks show that our method consistently outperforms competitive baselines. Further analyses show that P(IK) can generalize across tasks and difficulties, which indicates selective W2SG can help superalignment.

</details>


### [14] [SymLoc: Symbolic Localization of Hallucination across HaluEval and TruthfulQA](https://arxiv.org/abs/2511.14172)
*Naveen Lamba,Sanju Tiwari,Manas Gaur*

Main category: cs.CL

TL;DR: 提出了首个基于符号语言学知识的幻觉定位框架，通过分析模型如何处理符号触发器来追踪幻觉在各层的发展。研究发现符号语义处理在早期层（2-4）就出现关键不稳定性，特别是否定触发灾难性方差水平。


<details>
  <summary>Details</summary>
Motivation: LLMs在遇到符号触发器（如修饰语、否定、数字、例外和命名实体）时仍存在幻觉问题，但缺乏对这些符号幻觉起源的清晰理解，需要系统性地处理这些触发器并在模型内部定位幻觉的出现。

Method: 提出符号定位框架，利用符号语言学和语义知识，分析五个模型在HaluEval和TruthfulQA数据集上如何处理符号触发器，通过注意力方差分析追踪幻觉在各层的发展。

Result: 符号语言元素的注意力方差在早期层（2-4）爆炸性增长到关键不稳定性，否定触发灾难性方差水平。尽管模型规模增大，幻觉率仍保持高位（78.3%-83.7%），深层中符号语义触发器的注意力急剧下降。

Conclusion: 幻觉本质上是符号语言处理失败，而非一般生成问题，符号语义知识为理解和定位LLMs中幻觉机制提供了关键。

Abstract: LLMs still struggle with hallucination, especially when confronted with symbolic triggers like modifiers, negation, numbers, exceptions, and named entities. Yet, we lack a clear understanding of where these symbolic hallucinations originate, making it crucial to systematically handle such triggers and localize the emergence of hallucination inside the model. While prior work explored localization using statistical techniques like LSC and activation variance analysis, these methods treat all tokens equally and overlook the role symbolic linguistic knowledge plays in triggering hallucinations. So far, no approach has investigated how symbolic elements specifically drive hallucination failures across model layers, nor has symbolic linguistic knowledge been used as the foundation for a localization framework. We propose the first symbolic localization framework that leverages symbolic linguistic and semantic knowledge to meaningfully trace the development of hallucinations across all model layers. By focusing on how models process symbolic triggers, we analyze five models using HaluEval and TruthfulQA. Our symbolic knowledge approach reveals that attention variance for these linguistic elements explodes to critical instability in early layers (2-4), with negation triggering catastrophic variance levels, demonstrating that symbolic semantic processing breaks down from the very beginning. Through the lens of symbolic linguistic knowledge, despite larger model sizes, hallucination rates remain consistently high (78.3%-83.7% across Gemma variants), with steep attention drops for symbolic semantic triggers throughout deeper layers. Our findings demonstrate that hallucination is fundamentally a symbolic linguistic processing failure, not a general generation problem, revealing that symbolic semantic knowledge provides the key to understanding and localizing hallucination mechanisms in LLMs.

</details>


### [15] [Harnessing Deep LLM Participation for Robust Entity Linking](https://arxiv.org/abs/2511.14181)
*Jiajun Hou,Chenyu Zhang,Rui Meng*

Main category: cs.CL

TL;DR: DeepEL是一个将大语言模型深度集成到实体链接各个阶段的框架，通过自验证机制利用全局上下文信息纠正预测，在10个基准数据集上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常只在实体链接的孤立阶段使用LLMs，未能充分利用其能力。同时，孤立地消歧实体无法达到最优性能。

Method: 提出DeepEL框架，将LLMs集成到实体链接的每个阶段，并引入自验证机制利用全局上下文信息让LLMs纠正自身预测。

Result: 在10个基准数据集上，DeepEL显著优于现有最先进方法，整体F1分数平均提升2.6%，在领域外数据集上提升4%。

Conclusion: 深度集成LLMs能有效推进实体链接技术发展，自验证机制通过利用全局上下文显著提升了性能。

Abstract: Entity Linking (EL), the task of mapping textual entity mentions to their corresponding entries in knowledge bases, constitutes a fundamental component of natural language understanding. Recent advancements in Large Language Models (LLMs) have demonstrated remarkable potential for enhancing EL performance. Prior research has leveraged LLMs to improve entity disambiguation and input representation, yielding significant gains in accuracy and robustness. However, these approaches typically apply LLMs to isolated stages of the EL task, failing to fully integrate their capabilities throughout the entire process.
  In this work, we introduce DeepEL, a comprehensive framework that incorporates LLMs into every stage of the entity linking task. Furthermore, we identify that disambiguating entities in isolation is insufficient for optimal performance. To address this limitation, we propose a novel self-validation mechanism that utilizes global contextual information, enabling LLMs to rectify their own predictions and better recognize cohesive relationships among entities within the same sentence.
  Extensive empirical evaluation across ten benchmark datasets demonstrates that DeepEL substantially outperforms existing state-of-the-art methods, achieving an average improvement of 2.6\% in overall F1 score and a remarkable 4% gain on out-of-domain datasets. These results underscore the efficacy of deep LLM integration in advancing the state-of-the-art in entity linking.

</details>


### [16] [ArbESC+: Arabic Enhanced Edit Selection System Combination for Grammatical Error Correction Resolving conflict and improving system combination in Arabic GEC](https://arxiv.org/abs/2511.14230)
*Ahlam Alrehili,Areej Alhothali*

Main category: cs.CL

TL;DR: 提出首个阿拉伯语语法错误校正的多系统方法ArbESC+，通过组合多个模型生成修正建议，使用分类器选择最佳修正，在QALB数据集上取得优于单一模型的性能。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语具有复杂的形态和句法结构，现有方法多使用单一模型，未充分利用多系统组合的潜在优势。

Method: 使用AraT5、ByT5、mT5、AraBART等多个模型生成修正建议，将其表示为数值特征，通过分类器选择最佳修正，并采用支持技术过滤重叠修正和评估决策可靠性。

Result: 在QALB-14测试数据上F0.5达到82.63%，QALB-15 L1数据上84.64%，QALB-15 L2数据上65.55%，优于单一模型。

Conclusion: 这是首个集成语言错误校正的阿拉伯语尝试，为开发先进的阿拉伯语文本处理工具提供了实用步骤。

Abstract: Grammatical Error Correction (GEC) is an important aspect of natural language processing. Arabic has a complicated morphological and syntactic structure, posing a greater challenge than other languages. Even though modern neural models have improved greatly in recent years, the majority of previous attempts used individual models without taking into account the potential benefits of combining different systems. In this paper, we present one of the first multi-system approaches for correcting grammatical errors in Arabic, the Arab Enhanced Edit Selection System Complication (ArbESC+). Several models are used to collect correction proposals, which are represented as numerical features in the framework. A classifier determines and implements the appropriate corrections based on these features. In order to improve output quality, the framework uses support techniques to filter overlapping corrections and estimate decision reliability. A combination of AraT5, ByT5, mT5, AraBART, AraBART+Morph+GEC, and Text editing systems gave better results than a single model alone, with F0.5 at 82.63% on QALB-14 test data, 84.64% on QALB-15 L1 data, and 65.55% on QALB-15 L2 data. As one of the most significant contributions of this work, it's the first Arab attempt to integrate linguistic error correction. Improving existing models provides a practical step towards developing advanced tools that will benefit users and researchers of Arabic text processing.

</details>


### [17] [MuCPT: Music-related Natural Language Model Continued Pretraining](https://arxiv.org/abs/2511.14245)
*Kai Tian,Yirong Mao,Wendong Bi,Hanjie Wang,Que Wenhui*

Main category: cs.CL

TL;DR: 构建了大规模音乐相关语料库（40B tokens），提出基于参考模型的token级软评分质量控制和统一损失比标准，用于数据选择和动态降权优化，减少噪声梯度并增强任务对齐信号，实现更有效的音乐领域持续预训练和对齐。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在通用任务上表现良好，但在音乐等专业领域受到限制，特别是在音乐娱乐领域，语料规模、纯净度以及数据与训练目标的匹配至关重要。

Method: 构建大规模音乐相关自然语言语料库，实施领域优先的数据管道：轻量级分类器过滤和加权领域内文本，多阶段清理、去重和隐私保护掩码；集成多源音乐文本与元数据；引入基于参考模型的token级软评分进行质量控制，使用统一损失比标准进行数据选择和动态降权优化。

Result: 开发了MusicSimpleQA基准测试，采用短单答案提示和自动一致性评分；通过数据组成轴进行系统比较，提供了可扩展的数据训练框架和可重用的评估工具。

Conclusion: 这项工作在语料库和训练目标两方面都取得了进展，为音乐领域构建领域大语言模型提供了可扩展的数据训练框架和可重用的评估工具。

Abstract: Large language models perform strongly on general tasks but remain constrained in specialized settings such as music, particularly in the music-entertainment domain, where corpus scale, purity, and the match between data and training objectives are critical. We address this by constructing a large, music-related natural language corpus (40B tokens) that combines open source and in-house data, and by implementing a domain-first data pipeline: a lightweight classifier filters and weights in-domain text, followed by multi-stage cleaning, de-duplication, and privacy-preserving masking. We further integrate multi-source music text with associated metadata to form a broader, better-structured foundation of domain knowledge. On the training side, we introduce reference-model (RM)-based token-level soft scoring for quality control: a unified loss-ratio criterion is used both for data selection and for dynamic down-weighting during optimization, reducing noise gradients and amplifying task-aligned signals, thereby enabling more effective music-domain continued pretraining and alignment. To assess factuality, we design the MusicSimpleQA benchmark, which adopts short, single-answer prompts with automated agreement scoring. Beyond the benchmark design, we conduct systematic comparisons along the axes of data composition. Overall, this work advances both the right corpus and the right objective, offering a scalable data-training framework and a reusable evaluation tool for building domain LLMs in the music field.

</details>


### [18] [Towards Authentic Movie Dubbing with Retrieve-Augmented Director-Actor Interaction Learning](https://arxiv.org/abs/2511.14249)
*Rui Liu,Yuan Zhao,Zhenqi Jia*

Main category: cs.CL

TL;DR: 提出Authentic-Dubber模型，通过检索增强的导演-演员交互学习方案，模拟真实电影配音工作流程，显著提升情感表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有电影配音方法简化了工作流程，忽略了导演与演员之间的关键互动，而真实工作流程中导演会指导演员内化情感上下文线索。

Method: 构建多模态参考素材库，使用情感相似性检索增强策略，开发渐进式图基语音生成方法，整合检索到的多模态情感知识。

Result: 在V2C Animation基准数据集上的主观和客观评估验证了有效性，在情感表达方面实现了全面改进。

Conclusion: Authentic-Dubber能够忠实复制真实配音工作流程，显著提升情感表现力，为自动电影配音提供了更真实的解决方案。

Abstract: The automatic movie dubbing model generates vivid speech from given scripts, replicating a speaker's timbre from a brief timbre prompt while ensuring lip-sync with the silent video. Existing approaches simulate a simplified workflow where actors dub directly without preparation, overlooking the critical director-actor interaction. In contrast, authentic workflows involve a dynamic collaboration: directors actively engage with actors, guiding them to internalize the context cues, specifically emotion, before performance. To address this issue, we propose a new Retrieve-Augmented Director-Actor Interaction Learning scheme to achieve authentic movie dubbing, termed Authentic-Dubber, which contains three novel mechanisms: (1) We construct a multimodal Reference Footage library to simulate the learning footage provided by directors. Note that we integrate Large Language Models (LLMs) to achieve deep comprehension of emotional representations across multimodal signals. (2) To emulate how actors efficiently and comprehensively internalize director-provided footage during dubbing, we propose an Emotion-Similarity-based Retrieval-Augmentation strategy. This strategy retrieves the most relevant multimodal information that aligns with the target silent video. (3) We develop a Progressive Graph-based speech generation approach that incrementally incorporates the retrieved multimodal emotional knowledge, thereby simulating the actor's final dubbing process. The above mechanisms enable the Authentic-Dubber to faithfully replicate the authentic dubbing workflow, achieving comprehensive improvements in emotional expressiveness. Both subjective and objective evaluations on the V2C Animation benchmark dataset validate the effectiveness. The code and demos are available at https://github.com/AI-S2-Lab/Authentic-Dubber.

</details>


### [19] [AfriSpeech-MultiBench: A Verticalized Multidomain Multicountry Benchmark Suite for African Accented English ASR](https://arxiv.org/abs/2511.14255)
*Gabrial Zencha Ashungafac,Mardhiyah Sanni,Busayo Awobade,Alex Gichamba,Tobi Olatunji*

Main category: cs.CL

TL;DR: AfriSpeech-MultiBench是首个针对非洲英语口音的领域特定评估套件，涵盖10+国家、100多种口音和7个应用领域，评估了多种语音识别系统在非洲语境下的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管语音AI技术快速发展，但目前缺乏针对非洲语言多样性的公开应用特定模型评估，需要为非洲社区开发包容性语音应用提供基准。

Method: 构建包含100多种非洲英语口音的评估套件，涵盖7个应用领域，使用自发和非自发语音对话，对开源、闭源、单模态ASR和多模态LLM语音识别系统进行基准测试。

Result: 开源ASR在自发语音中表现良好但在嘈杂非母语对话中退化；多模态LLM对口音更鲁棒但处理领域特定命名实体困难；专有模型在清晰语音中准确率高但随国家和领域变化显著；非洲英语微调模型在延迟方面有优势；大多数SOTA模型仍存在幻觉问题。

Conclusion: 通过发布这一全面基准，使从业者和研究人员能够选择适合非洲用例的语音技术，促进对服务不足社区的包容性语音应用发展。

Abstract: Recent advances in speech-enabled AI, including Google's NotebookLM and OpenAI's speech-to-speech API, are driving widespread interest in voice interfaces globally. Despite this momentum, there exists no publicly available application-specific model evaluation that caters to Africa's linguistic diversity. We present AfriSpeech-MultiBench, the first domain-specific evaluation suite for over 100 African English accents across 10+ countries and seven application domains: Finance, Legal, Medical, General dialogue, Call Center, Named Entities and Hallucination Robustness. We benchmark a diverse range of open, closed, unimodal ASR and multimodal LLM-based speech recognition systems using both spontaneous and non-spontaneous speech conversation drawn from various open African accented English speech datasets. Our empirical analysis reveals systematic variation: open-source ASR models excels in spontaneous speech contexts but degrades on noisy, non-native dialogue; multimodal LLMs are more accent-robust yet struggle with domain-specific named entities; proprietary models deliver high accuracy on clean speech but vary significantly by country and domain. Models fine-tuned on African English achieve competitive accuracy with lower latency, a practical advantage for deployment, hallucinations still remain a big problem for most SOTA models. By releasing this comprehensive benchmark, we empower practitioners and researchers to select voice technologies suited to African use-cases, fostering inclusive voice applications for underserved communities.

</details>


### [20] [Entropy-Guided Reasoning Compression](https://arxiv.org/abs/2511.14258)
*Hourun Zhu,Yang Gao,Wenlong Fei,Jiawei Li,Huashan Sun*

Main category: cs.CL

TL;DR: 提出一种熵引导训练框架来解决推理模型压缩中的熵冲突问题，将推理长度压缩到原始的20%同时保持或提升准确率


<details>
  <summary>Details</summary>
Motivation: 大型推理模型的思维链输出过长导致计算成本高和部署困难，现有压缩方法忽视了训练过程中的熵冲突现象

Method: 采用熵引导训练框架，在熵下降时鼓励简洁思维步骤，在熵上升时增强紧凑推理模式下的探索能力

Result: 在六个数学基准测试中，将推理长度压缩到原始的20%，同时保持或超过基线准确率

Conclusion: 熵引导训练能有效解决推理压缩中的熵冲突问题，实现高效紧凑的推理

Abstract: Large reasoning models have demonstrated remarkable performance on complex reasoning tasks, yet the excessive length of their chain-of-thought outputs remains a major practical bottleneck due to high computation cost and poor deployability. Existing compression methods have achieved partial success but overlook a crucial phenomenon in the training process -- the entropy conflict. During compression training, entropy decreases, leading to shorter reasoning but limited exploration, while accuracy-oriented objectives increase entropy, lengthening reasoning chains. This can cause the model to get stuck in a local dilemma. Our analysis further reveals the origin of the entropy conflict: many high-entropy tokens are logical connectors that receive larger gradients and are encouraged under the performance objective, while the compression objective simultaneously penalizes these potentially redundant connectors. This opposing pressure creates a direct source of entropy conflict. To address these issues, we adopt an entropy-guided training framework. As entropy descends, the model is guided toward efficient reasoning by encouraging concise thought steps; as entropy rises, exploration is reinforced under the compact reasoning mode to improve robustness. Experiments on six mathematical benchmarks show that our method compresses reasoning length to 20% of the original while maintaining or even surpassing baseline accuracy. Code and models will be released publicly.

</details>


### [21] [Don't Miss the Forest for the Trees: In-Depth Confidence Estimation for LLMs via Reasoning over the Answer Space](https://arxiv.org/abs/2511.14275)
*Ante Wang,Weizhi Ma,Yang Liu*

Main category: cs.CL

TL;DR: 该论文提出通过预测语言化概率分布来增强LLM的置信度估计，这种方法能鼓励深度推理，考虑所有候选答案而非单一猜测，在各种模型和任务中都显示出优势。


<details>
  <summary>Details</summary>
Motivation: 了解模型响应的可靠性在应用中至关重要。虽然已有研究关注生成语言化置信度，并结合思维链推理提供逻辑透明的估计，但推理策略如何影响置信度估计仍需深入探索。

Method: 提出预测语言化概率分布的方法，要求LLM考虑答案空间中的所有候选答案而非单一猜测，并仔细分配置信度分数以满足分布要求。

Result: 该方法在不同模型和各种任务中都显示出优势，无论答案空间是否已知。即使在强化学习后仍保持优势，分析显示其推理模式符合人类期望。

Conclusion: 预测语言化概率分布能有效鼓励深度推理进行置信度估计，提供更可靠和透明的置信度评估。

Abstract: Knowing the reliability of a model's response is essential in application. With the strong generation capabilities of LLMs, research has focused on generating verbalized confidence. This is further enhanced by combining chain-of-thought reasoning, which provides logical and transparent estimation. However, how reasoning strategies affect the estimated confidence is still under-explored. In this work, we demonstrate that predicting a verbalized probability distribution can effectively encourage in-depth reasoning for confidence estimation. Intuitively, it requires an LLM to consider all candidates within the answer space instead of basing on a single guess, and to carefully assign confidence scores to meet the requirements of a distribution. This method shows an advantage across different models and various tasks, regardless of whether the answer space is known. Its advantage is maintained even after reinforcement learning, and further analysis shows its reasoning patterns are aligned with human expectations.

</details>


### [22] [AraLingBench A Human-Annotated Benchmark for Evaluating Arabic Linguistic Capabilities of Large Language Models](https://arxiv.org/abs/2511.14295)
*Mohammad Zbib,Hasan Abed Al Kader Hammoud,Sina Mukalled,Nadine Rizk,Fatima Karnib,Issam Lakkis,Ammar Mohanna,Bernard Ghanem*

Main category: cs.CL

TL;DR: AraLingBench是一个全面人工标注的基准测试，用于评估大型语言模型的阿拉伯语语言能力，涵盖语法、形态学、拼写、阅读理解和句法五个核心类别。


<details>
  <summary>Details</summary>
Motivation: 当前阿拉伯语和双语LLMs在表面水平表现出色，但在深层语法和句法推理方面存在困难，需要专门的基准测试来评估真正的语言掌握程度。

Method: 通过150个专家设计的多项选择题，直接评估结构语言理解能力，对35个阿拉伯语和双语LLMs进行全面评估。

Result: 评估显示当前模型在表面水平表现出色，但在深层语法和句法推理方面存在困难，许多模型通过记忆或模式识别而非真正理解来获得高分。

Conclusion: AraLingBench通过分离和测量基本语言技能，为开发阿拉伯语LLMs提供了诊断框架，揭示了基于知识的基准测试高分与真正语言掌握之间的持续差距。

Abstract: We present AraLingBench: a fully human annotated benchmark for evaluating the Arabic linguistic competence of large language models (LLMs). The benchmark spans five core categories: grammar, morphology, spelling, reading comprehension, and syntax, through 150 expert-designed multiple choice questions that directly assess structural language understanding. Evaluating 35 Arabic and bilingual LLMs reveals that current models demonstrate strong surface level proficiency but struggle with deeper grammatical and syntactic reasoning. AraLingBench highlights a persistent gap between high scores on knowledge-based benchmarks and true linguistic mastery, showing that many models succeed through memorization or pattern recognition rather than authentic comprehension. By isolating and measuring fundamental linguistic skills, AraLingBench provides a diagnostic framework for developing Arabic LLMs. The full evaluation code is publicly available on GitHub.

</details>


### [23] [ConInstruct: Evaluating Large Language Models on Conflict Detection and Resolution in Instructions](https://arxiv.org/abs/2511.14342)
*Xingwei He,Qianru Zhang,Pengfei Chen,Guanhua Chen,Linlin Yu,Yuan Yuan,Siu-Ming Yiu*

Main category: cs.CL

TL;DR: ConInstruct基准测试评估LLMs在检测和解决用户指令中冲突约束的能力，发现专有模型表现较好但很少明确通知用户冲突。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLMs遵循用户指令的能力，但忽略了指令包含冲突约束的常见场景，这种行为研究不足。

Method: 引入ConInstruct基准数据集，评估LLMs的冲突检测性能并分析其冲突解决行为。

Result: 专有LLMs冲突检测能力强，DeepSeek-R1和Claude-4.5-Sonnet表现最佳；但LLMs很少明确通知用户冲突或请求澄清。

Conclusion: 当前LLMs在冲突处理方面存在关键缺陷，这是设计指令遵循LLMs时需要改进的重要领域。

Abstract: Instruction-following is a critical capability of Large Language Models (LLMs). While existing works primarily focus on assessing how well LLMs adhere to user instructions, they often overlook scenarios where instructions contain conflicting constraints-a common occurrence in complex prompts. The behavior of LLMs under such conditions remains under-explored. To bridge this gap, we introduce ConInstruct, a benchmark specifically designed to assess LLMs' ability to detect and resolve conflicts within user instructions. Using this dataset, we evaluate LLMs' conflict detection performance and analyze their conflict resolution behavior. Our experiments reveal two key findings: (1) Most proprietary LLMs exhibit strong conflict detection capabilities, whereas among open-source models, only DeepSeek-R1 demonstrates similarly strong performance. DeepSeek-R1 and Claude-4.5-Sonnet achieve the highest average F1-scores at 91.5% and 87.3%, respectively, ranking first and second overall. (2) Despite their strong conflict detection abilities, LLMs rarely explicitly notify users about the conflicts or request clarification when faced with conflicting constraints. These results underscore a critical shortcoming in current LLMs and highlight an important area for future improvement when designing instruction-following LLMs.

</details>


### [24] [The Tokenization Bottleneck: How Vocabulary Extension Improves Chemistry Representation Learning in Pretrained Language Models](https://arxiv.org/abs/2511.14365)
*Prathamesh Kalamkar,Ned Letcher,Meissane Chami,Sahger Lad,Shayan Mohanty,Prasanna Pendse*

Main category: cs.CL

TL;DR: 解决LLMs在化学领域应用中的tokenization瓶颈问题，通过词汇扩展和领域预训练统一自然语言和分子结构表示


<details>
  <summary>Details</summary>
Motivation: 通用领域文本的tokenizer会将化学表示如SMILES分割成无意义的子token，阻碍LLMs在化学领域的应用

Method: 目标词汇扩展（在预训练LLM词汇表中添加化学相关token）+化学领域文本的持续预训练

Result: 在多个下游化学任务上表现出优越性能

Conclusion: 该方法有效解决了化学领域的tokenization瓶颈，提升了LLMs在化学任务上的表现

Abstract: The application of large language models (LLMs) to chemistry is frequently hampered by a "tokenization bottleneck", where tokenizers tuned on general-domain text tend to fragment chemical representations such as SMILES into semantically uninformative sub-tokens. This paper introduces a principled methodology to resolve this bottleneck by unifying the representation of natural language and molecular structures within a single model. Our approach involves targeted vocabulary extension-augmenting a pretrained LLM's vocabulary with chemically salient tokens, followed by continued pretraining on chemistry-domain text to integrate this new knowledge. We provide an empirical demonstration of the effectiveness of this strategy, showing that our methodology leads to superior performance on a range of downstream chemical tasks.

</details>


### [25] [ATLAS: A High-Difficulty, Multidisciplinary Benchmark for Frontier Scientific Reasoning](https://arxiv.org/abs/2511.14366)
*Hongwei Liu,Junnan Liu,Shudong Liu,Haodong Duan,Yuqiang Li,Mao Su,Xiaohong Liu,Guangtao Zhai,Xinyu Fang,Qianhong Ma,Taolin Zhang,Zihan Ma,Yufeng Zhao,Peiheng Zhou,Linchen Xiao,Wenlong Zhang,Shijie Zhou,Xingjian Ma,Siqi Sun,Jiaye Ge,Meng Li,Yuhong Liu,Jianxin Dong,Jiaying Li,Hui Wu,Hanwen Liang,Jintai Lin,Yanting Wang,Jie Dong,Tong Zhu,Tianfan Fu,Conghui He,Qi Zhang,Songyang Zhang,Lei Bai,Kai Chen*

Main category: cs.CL

TL;DR: ATLAS是一个面向AGI的大规模、高难度跨学科科学评估套件，包含约800个原创问题，旨在解决现有基准测试在区分前沿模型能力方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在性能饱和、学科范围狭窄、答案格式简化、数据污染等问题，无法有效评估模型在真实科学探究中的能力。

Method: 由领域专家开发，涵盖七大科学领域，采用原创问题设计、跨学科整合、高保真答案格式和多阶段质量控制的评估方法。

Result: 初步结果显示ATLAS能有效区分领先模型的先进科学推理能力。

Conclusion: ATLAS将发展成长期开放的社区驱动平台，为AGI进展提供可靠评估标准。

Abstract: The rapid advancement of Large Language Models (LLMs) has led to performance saturation on many established benchmarks, questioning their ability to distinguish frontier models. Concurrently, existing high-difficulty benchmarks often suffer from narrow disciplinary focus, oversimplified answer formats, and vulnerability to data contamination, creating a fidelity gap with real-world scientific inquiry. To address these challenges, we introduce ATLAS (AGI-Oriented Testbed for Logical Application in Science), a large-scale, high-difficulty, and cross-disciplinary evaluation suite composed of approximately 800 original problems. Developed by domain experts (PhD-level and above), ATLAS spans seven core scientific fields: mathematics, physics, chemistry, biology, computer science, earth science, and materials science. Its key features include: (1) High Originality and Contamination Resistance, with all questions newly created or substantially adapted to prevent test data leakage; (2) Cross-Disciplinary Focus, designed to assess models' ability to integrate knowledge and reason across scientific domains; (3) High-Fidelity Answers, prioritizing complex, open-ended answers involving multi-step reasoning and LaTeX-formatted expressions over simple multiple-choice questions; and (4) Rigorous Quality Control, employing a multi-stage process of expert peer review and adversarial testing to ensure question difficulty, scientific value, and correctness. We also propose a robust evaluation paradigm using a panel of LLM judges for automated, nuanced assessment of complex answers. Preliminary results on leading models demonstrate ATLAS's effectiveness in differentiating their advanced scientific reasoning capabilities. We plan to develop ATLAS into a long-term, open, community-driven platform to provide a reliable "ruler" for progress toward Artificial General Intelligence.

</details>


### [26] [Mitigating Label Length Bias in Large Language Models](https://arxiv.org/abs/2511.14385)
*Mario Sanz-Guerrero,Katharina von der Wense*

Main category: cs.CL

TL;DR: 提出标准化上下文校准(NCC)方法，解决大语言模型中多token类别标签的长度偏差问题，在多个数据集和模型上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在预测候选选项时存在标签偏差，现有校准方法忽视了多token类别标签带来的偏差，特别是标签长度不一致导致的预测不一致问题。

Method: 提出标准化上下文校准(NCC)，在全标签级别进行标准化和校准预测，扩展偏差缓解到更广泛的任务如多项选择题回答。

Result: NCC在多个数据集和模型上实现统计显著改进，F1分数提升高达10%，结合上下文学习时对少样本示例选择更不敏感，需要更少示例达到竞争性能，产生更可靠置信度估计。

Conclusion: 缓解全标签偏差对于提升基于LLM方法的性能和鲁棒性至关重要，特别是在现实应用中类别标签自然包含多个token的场景。

Abstract: Large language models (LLMs) are powerful zero- and few-shot learners. However, when predicting over a set of candidate options, LLMs suffer from label biases, and existing calibration methods overlook biases arising from multi-token class labels. We tackle an issue we call label length bias, where labels of different lengths are treated inconsistently, even after standard length normalization. To mitigate it, we propose normalized contextual calibration (NCC), an effective method that normalizes and calibrates predictions at the full-label level. NCC achieves statistically significant improvements over prior approaches across multiple datasets and models, with gains of up to 10% F1. Moreover, NCC extends bias mitigation to broader tasks such as multiple-choice question answering. Our analysis shows that, when combined with in-context learning, NCC is less sensitive to few-shot example selection, requires fewer examples for competitive performance, and produces more reliable confidence estimates. These findings highlight the importance of mitigating full-label biases to improve the performance and robustness of LLM-based methods, particularly in real-world applications where class labels naturally consist of multiple tokens.

</details>


### [27] [Unified Defense for Large Language Models against Jailbreak and Fine-Tuning Attacks in Education](https://arxiv.org/abs/2511.14423)
*Xin Yi,Yue Li,Dongsheng Shi,Linlin Wang,Xiaoling Wang,Liang He*

Main category: cs.CL

TL;DR: 提出了EduHarm基准和TSSF框架，用于评估和防御教育场景中LLM的安全风险，包括越狱攻击和微调攻击。


<details>
  <summary>Details</summary>
Motivation: LLM在教育应用中面临越狱和微调攻击的安全威胁，现有研究主要关注通用安全评估，缺乏针对教育场景独特安全需求的研究。

Method: 构建EduHarm基准包含五个教育场景的安全-不安全指令对；提出三阶段防护框架：安全感知注意力重对齐、分层安全判断、防御驱动双路由。

Result: 在八种越狱攻击策略下有效增强安全性且不过度拒绝良性查询；在三个微调攻击数据集上保持对有害查询的鲁棒防御，同时保留良性微调的效用增益。

Conclusion: TSSF框架能够同时缓解越狱和微调攻击，为教育LLM提供有效的安全防护，在保持模型效用的同时增强安全性。

Abstract: Large Language Models (LLMs) are increasingly integrated into educational applications. However, they remain vulnerable to jailbreak and fine-tuning attacks, which can compromise safety alignment and lead to harmful outputs. Existing studies mainly focus on general safety evaluations, with limited attention to the unique safety requirements of educational scenarios. To address this gap, we construct EduHarm, a benchmark containing safe-unsafe instruction pairs across five representative educational scenarios, enabling systematic safety evaluation of educational LLMs. Furthermore, we propose a three-stage shield framework (TSSF) for educational LLMs that simultaneously mitigates both jailbreak and fine-tuning attacks. First, safety-aware attention realignment redirects attention toward critical unsafe tokens, thereby restoring the harmfulness feature that discriminates between unsafe and safe inputs. Second, layer-wise safety judgment identifies harmfulness features by aggregating safety cues across multiple layers to detect unsafe instructions. Finally, defense-driven dual routing separates safe and unsafe queries, ensuring normal processing for benign inputs and guarded responses for harmful ones. Extensive experiments across eight jailbreak attack strategies demonstrate that TSSF effectively strengthens safety while preventing over-refusal of benign queries. Evaluations on three fine-tuning attack datasets further show that it consistently achieves robust defense against harmful queries while maintaining preserving utility gains from benign fine-tuning.

</details>


### [28] [MedBench v4: A Robust and Scalable Benchmark for Evaluating Chinese Medical Language Models, Multimodal Models, and Intelligent Agents](https://arxiv.org/abs/2511.14439)
*Jinru Ding,Lu Lu,Chao Ding,Mouxiao Bian,Jiayuan Chen,Renjie Lu,Wenrao Pang,Xiaoqin Wu,Zhiqiang Liu,Luyi Jiang,Bing Han,Yunqiu Wang,Jie Xu*

Main category: cs.CL

TL;DR: MedBench v4是一个全国性的医疗AI评估框架，包含70多万个专家策划的任务，涵盖24个主要专科和91个次要专科，专门评估LLM、多模态模型和智能体。


<details>
  <summary>Details</summary>
Motivation: 需要反映真实临床工作流程和安全约束的评估框架来评估医疗大语言模型、多模态模型和智能体的表现。

Method: 建立云基准测试基础设施，任务经过多阶段细化和多轮临床医生评审，开放式回答通过LLM作为评委进行评分并与人类评分校准。

Result: 基础LLM平均得分54.1/100（最佳Claude Sonnet 4.5为62.5/100），但安全和伦理得分较低（18.4/100）。多模态模型表现更差（平均47.5/100），智能体表现显著提升（平均79.8/100）。

Conclusion: MedBench v4揭示了多模态推理和安全性的持续差距，但治理感知的智能体编排可以显著提升临床准备度，为医院、开发者和政策制定者提供实用参考。

Abstract: Recent advances in medical large language models (LLMs), multimodal models, and agents demand evaluation frameworks that reflect real clinical workflows and safety constraints. We present MedBench v4, a nationwide, cloud-based benchmarking infrastructure comprising over 700,000 expert-curated tasks spanning 24 primary and 91 secondary specialties, with dedicated tracks for LLMs, multimodal models, and agents. Items undergo multi-stage refinement and multi-round review by clinicians from more than 500 institutions, and open-ended responses are scored by an LLM-as-a-judge calibrated to human ratings. We evaluate 15 frontier models. Base LLMs reach a mean overall score of 54.1/100 (best: Claude Sonnet 4.5, 62.5/100), but safety and ethics remain low (18.4/100). Multimodal models perform worse overall (mean 47.5/100; best: GPT-5, 54.9/100), with solid perception yet weaker cross-modal reasoning. Agents built on the same backbones substantially improve end-to-end performance (mean 79.8/100), with Claude Sonnet 4.5-based agents achieving up to 85.3/100 overall and 88.9/100 on safety tasks. MedBench v4 thus reveals persisting gaps in multimodal reasoning and safety for base models, while showing that governance-aware agentic orchestration can markedly enhance benchmarked clinical readiness without sacrificing capability. By aligning tasks with Chinese clinical guidelines and regulatory priorities, the platform offers a practical reference for hospitals, developers, and policymakers auditing medical AI.

</details>


### [29] [Tell Me: An LLM-powered Mental Well-being Assistant with RAG, Synthetic Dialogue Generation, and Agentic Planning](https://arxiv.org/abs/2511.14445)
*Trishala Jayesh Ahalpara*

Main category: cs.CL

TL;DR: Tell Me是一个基于大语言模型的心理健康系统，包含RAG助手、合成对话生成器和AI健康团队三个组件，旨在提供个性化心理健康支持，但不替代专业治疗。


<details>
  <summary>Details</summary>
Motivation: 解决心理健康资源获取障碍，利用AI技术提供可访问的心理支持，同时解决治疗对话数据稀缺问题。

Method: 系统集成三个核心组件：RAG助手提供个性化对话，合成对话生成器基于用户档案生成治疗对话，AI健康团队使用CrewAI生成周度自我护理计划和冥想音频。

Result: 系统在精心设计的健康场景中通过自动LLM评估和用户研究进行了评估，展示了降低支持门槛、补充现有护理的潜力。

Conclusion: 这项工作强调了NLP研究者与心理健康专业人士跨学科合作的机会，推动人机交互在健康领域的负责任创新。

Abstract: We present Tell Me, a mental well-being system that leverages advances in large language models to provide accessible, context-aware support for users and researchers. The system integrates three components: (i) a retrieval-augmented generation (RAG) assistant for personalized, knowledge-grounded dialogue; (ii) a synthetic client-therapist dialogue generator conditioned on client profiles to facilitate research on therapeutic language and data augmentation; and (iii) a Well-being AI crew, implemented with CrewAI, that produces weekly self-care plans and guided meditation audio. The system is designed as a reflective space for emotional processing rather than a substitute for professional therapy. It illustrates how conversational assistants can lower barriers to support, complement existing care, and broaden access to mental health resources. To address the shortage of confidential therapeutic data, we introduce synthetic client-therapist dialogue generation conditioned on client profiles. Finally, the planner demonstrates an innovative agentic workflow for dynamically adaptive, personalized self-care, bridging the limitations of static well-being tools. We describe the architecture, demonstrate its functionalities, and report evaluation of the RAG assistant in curated well-being scenarios using both automatic LLM-based judgments and a human-user study. This work highlights opportunities for interdisciplinary collaboration between NLP researchers and mental health professionals to advance responsible innovation in human-AI interaction for well-being.

</details>


### [30] [Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning](https://arxiv.org/abs/2511.14460)
*Mingyue Cheng,Jie Ouyang,Shuo Yu,Ruiran Yan,Yucong Luo,Zirui Liu,Daoyu Wang,Qi Liu,Enhong Chen*

Main category: cs.CL

TL;DR: 本文系统化地将强化学习应用于LLM智能体，提出了扩展的MDP框架和Agent-R1训练框架，并在多跳问答任务上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 当前RL在LLM智能体训练中的应用仍处于早期阶段，缺乏专门针对LLM智能体的RL方法探索和灵活可扩展的训练框架。

Method: 1. 系统化扩展MDP框架来定义LLM智能体的关键组件；2. 提出Agent-R1模块化训练框架，支持跨任务场景和环境适配。

Result: 在多跳问答基准任务上的实验初步验证了所提方法和框架的有效性。

Conclusion: 该研究为RL在LLM智能体训练中的应用提供了系统化方法和实用框架，推动了这一新兴领域的发展。

Abstract: Large Language Models (LLMs) are increasingly being explored for building Agents capable of active environmental interaction (e.g., via tool use) to solve complex problems. Reinforcement Learning (RL) is considered a key technology with significant potential for training such Agents; however, the effective application of RL to LLM Agents is still in its nascent stages and faces considerable challenges. Currently, this emerging field lacks in-depth exploration into RL approaches specifically tailored for the LLM Agent context, alongside a scarcity of flexible and easily extensible training frameworks designed for this purpose. To help advance this area, this paper first revisits and clarifies Reinforcement Learning methodologies for LLM Agents by systematically extending the Markov Decision Process (MDP) framework to comprehensively define the key components of an LLM Agent. Secondly, we introduce Agent-R1, a modular, flexible, and user-friendly training framework for RL-based LLM Agents, designed for straightforward adaptation across diverse task scenarios and interactive environments. We conducted experiments on Multihop QA benchmark tasks, providing initial validation for the effectiveness of our proposed methods and framework.

</details>


### [31] [LiveRAG: A diverse Q&A dataset with varying difficulty level for RAG evaluation](https://arxiv.org/abs/2511.14531)
*David Carmel,Simone Filice,Guy Horowitz,Yoelle Maarek,Alex Shtoff,Oren Somekh,Ran Tavory*

Main category: cs.CL

TL;DR: LiveRAG基准是一个包含895个合成问答对的公开数据集，用于系统评估基于RAG的问答系统，源自SIGIR'2025 LiveRAG挑战赛，包含真实答案、支持声明和难度评分。


<details>
  <summary>Details</summary>
Motivation: 随着RAG在生成式AI解决方案中日益重要，需要系统评估其有效性。

Method: 创建包含895个合成问答对的公开数据集，基于SIGIR'2025 LiveRAG挑战赛，添加真实答案、支持声明，并应用项目反应理论模型计算难度和区分度分数。

Result: 分析显示基准问题具有多样性、广泛的难度范围，并能有效区分系统能力。

Conclusion: LiveRAG基准将有助于推进RAG研究、进行系统评估和开发更稳健的问答系统。

Abstract: With Retrieval Augmented Generation (RAG) becoming more and more prominent in generative AI solutions, there is an emerging need for systematically evaluating their effectiveness. We introduce the LiveRAG benchmark, a publicly available dataset of 895 synthetic questions and answers designed to support systematic evaluation of RAG-based Q&A systems. This synthetic benchmark is derived from the one used during the SIGIR'2025 LiveRAG Challenge, where competitors were evaluated under strict time constraints. It is augmented with information that was not made available to competitors during the Challenge, such as the ground-truth answers, together with their associated supporting claims which were used for evaluating competitors' answers. In addition, each question is associated with estimated difficulty and discriminability scores, derived from applying an Item Response Theory model to competitors' responses. Our analysis highlights the benchmark's questions diversity, the wide range of their difficulty levels, and their usefulness in differentiating between system capabilities. The LiveRAG benchmark will hopefully help the community advance RAG research, conduct systematic evaluation, and develop more robust Q&A systems.

</details>


### [32] [Examining the Metrics for Document-Level Claim Extraction in Czech and Slovak](https://arxiv.org/abs/2511.14566)
*Lucia Makaiová,Martin Fajčík,Antonín Jarolím*

Main category: cs.CL

TL;DR: 本文探讨了文档级主张提取的评估方法，通过对齐算法计算两组主张的相似度，为事实核查提供可靠的评估框架。


<details>
  <summary>Details</summary>
Motivation: 文档级主张提取在事实核查领域仍具挑战性，现有的评估方法关注有限，需要建立可靠的评估框架来比较模型提取和人工标注的主张集。

Method: 研究对齐两组主张的技术，通过对齐分数计算相似度，并在捷克和斯洛伐克新闻评论数据集上进行实验。

Result: 结果揭示了当前评估方法在文档级主张提取中的局限性，特别是在处理非正式语言、强本地语境和语言细微差别时的不足。

Conclusion: 需要开发更先进的评估方法，能够正确捕捉语义相似度并评估关键主张属性，如原子性、可核查性和去语境化。

Abstract: Document-level claim extraction remains an open challenge in the field of fact-checking, and subsequently, methods for evaluating extracted claims have received limited attention. In this work, we explore approaches to aligning two sets of claims pertaining to the same source document and computing their similarity through an alignment score. We investigate techniques to identify the best possible alignment and evaluation method between claim sets, with the aim of providing a reliable evaluation framework. Our approach enables comparison between model-extracted and human-annotated claim sets, serving as a metric for assessing the extraction performance of models and also as a possible measure of inter-annotator agreement. We conduct experiments on newly collected dataset-claims extracted from comments under Czech and Slovak news articles-domains that pose additional challenges due to the informal language, strong local context, and subtleties of these closely related languages. The results draw attention to the limitations of current evaluation approaches when applied to document-level claim extraction and highlight the need for more advanced methods-ones able to correctly capture semantic similarity and evaluate essential claim properties such as atomicity, checkworthiness, and decontextualization.

</details>


### [33] [Leveraging Digitized Newspapers to Collect Summarization Data in Low-Resource Languages](https://arxiv.org/abs/2511.14598)
*Noam Dahan,Omer Kidron,Gabriel Stanovsky*

Main category: cs.CL

TL;DR: 利用报纸头版摘要自动构建多文档摘要数据集，特别关注资源稀缺语言，以希伯来语为例创建了首个专用多文档摘要数据集。


<details>
  <summary>Details</summary>
Motivation: 在资源稀缺语言中高质量摘要数据匮乏，而数字化历史报纸提供了丰富的自然标注数据源。

Method: 通过报纸头版摘要自动收集自然生成的摘要，开发了适应不同语言资源水平的自动化流程。

Result: 在七种不同语言中验证了该方法的普遍适用性，并成功构建了希伯来语首个多文档摘要数据集HEBTEASESUM。

Conclusion: 报纸头版摘要为资源稀缺语言提供了可行的多文档摘要数据收集方法，具有推广价值。

Abstract: High quality summarization data remains scarce in under-represented languages. However, historical newspapers, made available through recent digitization efforts, offer an abundant source of untapped, naturally annotated data. In this work, we present a novel method for collecting naturally occurring summaries via Front-Page Teasers, where editors summarize full length articles. We show that this phenomenon is common across seven diverse languages and supports multi-document summarization. To scale data collection, we develop an automatic process, suited to varying linguistic resource levels. Finally, we apply this process to a Hebrew newspaper title, producing HEBTEASESUM, the first dedicated multi-document summarization dataset in Hebrew.

</details>


### [34] [A Method for Characterizing Disease Progression from Acute Kidney Injury to Chronic Kidney Disease](https://arxiv.org/abs/2511.14603)
*Yilu Fang,Jordan G. Nestor,Casey N. Ta,Jerard Z. Kneifati-Hayek,Chunhua Weng*

Main category: cs.CL

TL;DR: 使用电子健康记录数据动态追踪AKI患者的临床演变，通过聚类分析识别15种不同的AKI后临床状态，发现17%的AKI患者发展为CKD，并识别了不同状态下CKD风险因素的差异。


<details>
  <summary>Details</summary>
Motivation: 急性肾损伤患者发展为慢性肾病的风险很高，但识别高风险患者仍然具有挑战性，需要开发数据驱动的方法来支持早期检测和干预。

Method: 使用电子健康记录数据，通过聚类分析识别AKI后临床状态，采用多状态模型估计状态间转移概率和CKD进展风险，通过生存分析识别不同亚群中的CKD风险因素。

Result: 在20,699名入院时患有AKI的患者中，3,491名发展为CKD；识别出15种不同的AKI后临床状态，每种状态具有不同的CKD发展概率；75%的患者在研究期间保持单一状态或仅进行一次状态转移。

Conclusion: 该研究展示了识别高风险AKI患者的数据驱动方法，支持开发用于早期CKD检测和干预的决策支持工具，发现了已确定和新颖的CKD风险因素在不同临床状态中的影响差异。

Abstract: Patients with acute kidney injury (AKI) are at high risk of developing chronic kidney disease (CKD), but identifying those at greatest risk remains challenging. We used electronic health record (EHR) data to dynamically track AKI patients' clinical evolution and characterize AKI-to-CKD progression. Post-AKI clinical states were identified by clustering patient vectors derived from longitudinal medical codes and creatinine measurements. Transition probabilities between states and progression to CKD were estimated using multi-state modeling. After identifying common post-AKI trajectories, CKD risk factors in AKI subpopulations were identified through survival analysis. Of 20,699 patients with AKI at admission, 3,491 (17%) developed CKD. We identified fifteen distinct post-AKI states, each with different probabilities of CKD development. Most patients (75%, n=15,607) remained in a single state or made only one transition during the study period. Both established (e.g., AKI severity, diabetes, hypertension, heart failure, liver disease) and novel CKD risk factors, with their impact varying across these clinical states. This study demonstrates a data-driven approach for identifying high-risk AKI patients, supporting the development of decision-support tools for early CKD detection and intervention.

</details>


### [35] [Bridging Human and Model Perspectives: A Comparative Analysis of Political Bias Detection in News Media Using Large Language Models](https://arxiv.org/abs/2511.14606)
*Shreya Adrita Banik,Niaz Nafi Rahman,Tahsina Moiukh,Farig Sadeque*

Main category: cs.CL

TL;DR: 本研究比较了人类标注与多种大语言模型在政治偏见检测方面的表现，发现RoBERTa与人类标注最一致，GPT在零样本设置下表现最佳，揭示了人类与LLMs在政治偏见感知上的系统性差异。


<details>
  <summary>Details</summary>
Motivation: 虽然NLP技术已能自动进行偏见分类，但大语言模型与人类判断在政治偏见检测方面的对齐程度仍未被充分探索和理解。

Method: 构建手动标注的新闻文章数据集，评估标注一致性、偏见极性和模型间一致性，量化人类与模型在偏见感知上的差异。

Result: 传统基于Transformer的模型中，RoBERTa与人类标注对齐度最高；生成模型如GPT在零样本设置下与人类标注总体一致性最强；微调后的RoBERTa模型在所有基线中获得了最高准确率和最强的人类标注对齐度。

Conclusion: 人类与LLMs在政治偏见感知上存在系统性差异，需要结合人类可解释性和模型可扩展性的混合评估框架来进行自动化媒体偏见检测。

Abstract: Detecting political bias in news media is a complex task that requires interpreting subtle linguistic and contextual cues. Although recent advances in Natural Language Processing (NLP) have enabled automatic bias classification, the extent to which large language models (LLMs) align with human judgment still remains relatively underexplored and not yet well understood. This study aims to present a comparative framework for evaluating the detection of political bias across human annotations and multiple LLMs, including GPT, BERT, RoBERTa, and FLAN. We construct a manually annotated dataset of news articles and assess annotation consistency, bias polarity, and inter-model agreement to quantify divergence between human and model perceptions of bias. Experimental results show that among traditional transformer-based models, RoBERTa achieves the highest alignment with human labels, whereas generative models such as GPT demonstrate the strongest overall agreement with human annotations in a zero-shot setting. Among all transformer-based baselines, our fine-tuned RoBERTa model acquired the highest accuracy and the strongest alignment with human-annotated labels. Our findings highlight systematic differences in how humans and LLMs perceive political slant, underscoring the need for hybrid evaluation frameworks that combine human interpretability with model scalability in automated media bias detection.

</details>


### [36] [Enhancing Agentic Autonomous Scientific Discovery with Vision-Language Model Capabilities](https://arxiv.org/abs/2511.14631)
*Kahaan Gandhi,Boris Bolliet,Inigo Zubeldia*

Main category: cs.CL

TL;DR: 使用视觉语言模型指导多智能体系统进行自主科学发现，通过将图表作为可验证检查点，让VLM作为评判者根据动态生成的领域特定标准评估图表，使智能体能够纠正自身错误并实时引导探索性数据分析。


<details>
  <summary>Details</summary>
Motivation: 提高端到端自主科学发现的效率和准确性，通过多智能体系统结合视觉语言模型来解决传统方法在数据驱动发现中的局限性。

Method: 采用VLM作为评判者，将图表作为可验证检查点，根据动态生成的领域特定标准评估图表，使智能体能够自我纠正错误并实时调整数据分析方向。

Result: 在宇宙学和天体化学的案例研究中，系统能够从错误推理路径中恢复并适应新数据集而无需人工干预。在10个数据驱动发现任务的基准测试中，VLM增强系统达到0.7-0.8的pass@1分数，显著优于仅代码（0.2-0.3）和代码加文本（0.4-0.5）的基线方法。

Conclusion: VLM增强的多智能体系统显著提升了自主科学发现的性能，同时提供了可审计的推理轨迹以提高可解释性，为数据驱动发现提供了有效的解决方案。

Abstract: We show that multi-agent systems guided by vision-language models (VLMs) improve end-to-end autonomous scientific discovery. By treating plots as verifiable checkpoints, a VLM-as-a-judge evaluates figures against dynamically generated domain-specific rubrics, enabling agents to correct their own errors and steer exploratory data analysis in real-time. Case studies in cosmology and astrochemistry demonstrate recovery from faulty reasoning paths and adaptation to new datasets without human intervention. On a 10-task benchmark for data-driven discovery, VLM-augmented systems achieve pass at 1 scores of 0.7-0.8, compared to 0.2-0.3 for code-only and 0.4-0.5 for code-and-text baselines, while also providing auditable reasoning traces that improve interpretability. Code available here: https://github.com/CMBAgents/cmbagent

</details>


### [37] [A Specialized Large Language Model for Clinical Reasoning and Diagnosis in Rare Diseases](https://arxiv.org/abs/2511.14638)
*Tao Yang,Dandan Huang,Yunting Lin,Pengfei Wu,Zhikun Wu,Gangyuan Ma,Yulan Lu,Xinran Dong,Dingpeng Li,Junshuang Ge,Zhiyan Zhang,Xuanzhao Huang,Wenyan Nong,Yao Zhou,Hui Tang,Hongxi Yang,Shijie Zhang,Juan Li,Xiaojun Cao,Lin Yang,Xia Gao,Kaishou Xu,Xiaoqiong Gu,Wen Zhang,Huimin Xia,Li Liu,Wenhao Zhou,Mulin Jun Li*

Main category: cs.CL

TL;DR: 开发了RareSeek R1系统，通过领域专业临床语料库和临床验证推理集，结合指令调优、思维链学习和图基检索，在罕见病诊断中达到最先进准确率，性能与经验丰富的医生相当。


<details>
  <summary>Details</summary>
Motivation: 罕见病影响全球数亿人，但诊断往往需要多年时间。传统流程将噪声证据提取与下游推理诊断分离，通用/医学大语言模型面临真实世界电子健康记录稀缺、领域知识陈旧和幻觉问题。

Method: 构建大型领域专业临床语料库和临床验证推理集，通过分阶段指令调优、思维链学习和图基检索开发RareSeek R1系统。

Result: 在多中心电子健康记录叙述和公共基准测试中，RareSeek R1达到最先进准确率，在噪声或重叠表型下具有稳健泛化能力和稳定性。增强检索在叙述与优先变异配对时效果最佳。人类研究表明性能与经验丰富的医生相当。

Conclusion: 这项工作推进了以叙述为先、知识整合的推理范式，缩短诊断历程，实现可审计、临床可转化的决策支持。透明推理突显了支撑许多正确诊断的决定性非表型证据（中位数23.1%）。

Abstract: Rare diseases affect hundreds of millions worldwide, yet diagnosis often spans years. Convectional pipelines decouple noisy evidence extraction from downstream inferential diagnosis, and general/medical large language models (LLMs) face scarce real world electronic health records (EHRs), stale domain knowledge, and hallucinations. We assemble a large, domain specialized clinical corpus and a clinician validated reasoning set, and develop RareSeek R1 via staged instruction tuning, chain of thought learning, and graph grounded retrieval. Across multicenter EHR narratives and public benchmarks, RareSeek R1 attains state of the art accuracy, robust generalization, and stability under noisy or overlapping phenotypes. Augmented retrieval yields the largest gains when narratives pair with prioritized variants by resolving ambiguity and aligning candidates to mechanisms. Human studies show performance on par with experienced physicians and consistent gains in assistive use. Notably, transparent reasoning highlights decisive non phenotypic evidence (median 23.1%, such as imaging, interventions, functional tests) underpinning many correct diagnoses. This work advances a narrative first, knowledge integrated reasoning paradigm that shortens the diagnostic odyssey and enables auditable, clinically translatable decision support.

</details>


### [38] [Graded strength of comparative illusions is explained by Bayesian inference](https://arxiv.org/abs/2511.14642)
*Yuhan Zhang,Erxiao Wang,Cory Shain*

Main category: cs.CL

TL;DR: 该研究通过定量模型验证了语言处理中的比较幻觉现象可以用贝叶斯推理和噪声信道理论来解释，模型成功预测了幻觉强度的细微差异和代词与名词短语的影响。


<details>
  <summary>Details</summary>
Motivation: 研究比较幻觉现象，验证语言处理中的噪声信道理论，解释为什么人们会系统性地错误感知某些不合逻辑的句子。

Method: 结合统计语言模型和人类行为数据，构建定量模型计算合理解释的后验概率，直接预测幻觉强度。

Result: 模型成功解释了比较幻觉强度的细微差异，以及代词与全名词短语than从句主语对幻觉强度的影响，支持噪声信道理论。

Conclusion: 噪声信道推理可以作为语言处理现象的统一计算级理论，该研究为噪声信道理论提供了新的实证支持。

Abstract: Like visual processing, language processing is susceptible to illusions in which people systematically misperceive stimuli. In one such case--the comparative illusion (CI), e.g., More students have been to Russia than I have--comprehenders tend to judge the sentence as acceptable despite its underlying nonsensical comparison. Prior research has argued that this phenomenon can be explained as Bayesian inference over a noisy channel: the posterior probability of an interpretation of a sentence is proportional to both the prior probability of that interpretation and the likelihood of corruption into the observed (CI) sentence. Initial behavioral work has supported this claim by evaluating a narrow set of alternative interpretations of CI sentences and showing that comprehenders favor interpretations that are more likely to have been corrupted into the illusory sentence. In this study, we replicate and go substantially beyond this earlier work by directly predicting the strength of illusion with a quantitative model of the posterior probability of plausible interpretations, which we derive through a novel synthesis of statistical language models with human behavioral data. Our model explains not only the fine gradations in the strength of CI effects, but also a previously unexplained effect caused by pronominal vs. full noun phrase than-clause subjects. These findings support a noisy-channel theory of sentence comprehension by demonstrating that the theory makes novel predictions about the comparative illusion that bear out empirically. This outcome joins related evidence of noisy channel processing in both illusory and non-illusory contexts to support noisy channel inference as a unified computational-level theory of diverse language processing phenomena.

</details>


### [39] [Bias in, Bias out: Annotation Bias in Multilingual Large Language Models](https://arxiv.org/abs/2511.14662)
*Xia Cui,Ziyi Huang,Naeemeh Adel*

Main category: cs.CL

TL;DR: 提出了一个理解NLP数据集中标注偏见的综合框架，包括指令偏见、标注者偏见和语境文化偏见，并介绍了检测方法和缓解策略。


<details>
  <summary>Details</summary>
Motivation: NLP数据集中的标注偏见是开发多语言大语言模型的主要挑战，特别是在文化多样环境中，这种偏见会扭曲模型输出并加剧社会危害。

Method: 提出了标注偏见的分类法，包括指令偏见、标注者偏见和语境文化偏见；综述了检测方法（标注者间一致性、模型分歧、元数据分析等）；提出了主动和被动的缓解策略。

Result: 开发了一个综合框架来理解、检测和缓解标注偏见，包括偏见分类法、检测指标综合、针对多语言环境的集成缓解方法，以及标注过程的伦理分析。

Conclusion: 这些见解旨在为LLMs提供更公平和文化基础的标注流程，促进多语言大语言模型的公平发展。

Abstract: Annotation bias in NLP datasets remains a major challenge for developing multilingual Large Language Models (LLMs), particularly in culturally diverse settings. Bias from task framing, annotator subjectivity, and cultural mismatches can distort model outputs and exacerbate social harms. We propose a comprehensive framework for understanding annotation bias, distinguishing among instruction bias, annotator bias, and contextual and cultural bias. We review detection methods (including inter-annotator agreement, model disagreement, and metadata analysis) and highlight emerging techniques such as multilingual model divergence and cultural inference. We further outline proactive and reactive mitigation strategies, including diverse annotator recruitment, iterative guideline refinement, and post-hoc model adjustments. Our contributions include: (1) a typology of annotation bias; (2) a synthesis of detection metrics; (3) an ensemble-based bias mitigation approach adapted for multilingual settings, and (4) an ethical analysis of annotation processes. Together, these insights aim to inform more equitable and culturally grounded annotation pipelines for LLMs.

</details>


### [40] [Streamlining Industrial Contract Management with Retrieval-Augmented LLMs](https://arxiv.org/abs/2511.14671)
*Kristi Topollai,Tolga Dimlioglu,Anna Choromanska,Simon Odie,Reginald Hui*

Main category: cs.CL

TL;DR: 提出了一个基于检索增强生成的模块化框架，用于自动化合同管理工作流程，通过合成数据生成、语义条款检索、可接受性分类和基于奖励的对齐来识别问题修订并生成改进方案。


<details>
  <summary>Details</summary>
Motivation: 合同管理涉及审查和谈判条款，但自动化这一工作流程具有挑战性，因为标记数据稀缺且存在大量非结构化遗留合同。

Method: 采用检索增强生成（RAG）管道，整合合成数据生成、语义条款检索、可接受性分类和基于奖励的对齐。

Result: 与行业合作伙伴共同开发和评估的系统在识别和优化问题修订方面达到超过80%的准确率。

Conclusion: 该系统在现实世界低资源条件下表现出色，为加速合同修订工作流程提供了实用手段。

Abstract: Contract management involves reviewing and negotiating provisions, individual clauses that define rights, obligations, and terms of agreement. During this process, revisions to provisions are proposed and iteratively refined, some of which may be problematic or unacceptable. Automating this workflow is challenging due to the scarcity of labeled data and the abundance of unstructured legacy contracts. In this paper, we present a modular framework designed to streamline contract management through a retrieval-augmented generation (RAG) pipeline. Our system integrates synthetic data generation, semantic clause retrieval, acceptability classification, and reward-based alignment to flag problematic revisions and generate improved alternatives. Developed and evaluated in collaboration with an industry partner, our system achieves over 80% accuracy in both identifying and optimizing problematic revisions, demonstrating strong performance under real-world, low-resource conditions and offering a practical means of accelerating contract revision workflows.

</details>


### [41] [Quadratic Term Correction on Heaps' Law](https://arxiv.org/abs/2511.14683)
*Oscar Fontanelli,Wentian Li*

Main category: cs.CL

TL;DR: 本文发现Heaps定律在双对数坐标下仍呈轻微凹形，通过20部英文作品验证了二次函数能完美拟合类型-标记关系，线性系数略大于1，二次系数约-0.02，并用随机抽球模型解释了这种曲率。


<details>
  <summary>Details</summary>
Motivation: 传统Heaps定律假设类型-标记关系在双对数坐标下呈直线，但实际观测显示仍存在轻微凹形，这挑战了幂律关系的有效性。

Method: 使用20部英文作品（部分为翻译作品）的类型-标记数据，在双对数坐标下进行线性回归和二次回归分析，并采用随机抽球模型进行理论解释。

Result: 二次函数完美拟合数据，线性系数略大于1，二次系数约-0.02；曲率与负的"伪方差"相同，但大标记数量时存在数值不稳定性。

Conclusion: Heaps定律在双对数坐标下的轻微凹形可通过二次函数精确描述，随机抽球模型为这种曲率提供了理论解释，但大样本时需注意数值稳定性问题。

Abstract: Heaps' or Herdan's law characterizes the word-type vs. word-token relation by a power-law function, which is concave in linear-linear scale but a straight line in log-log scale. However, it has been observed that even in log-log scale, the type-token curve is still slightly concave, invalidating the power-law relation. At the next-order approximation, we have shown, by twenty English novels or writings (some are translated from another language to English), that quadratic functions in log-log scale fit the type-token data perfectly. Regression analyses of log(type)-log(token) data with both a linear and quadratic term consistently lead to a linear coefficient of slightly larger than 1, and a quadratic coefficient around -0.02. Using the ``random drawing colored ball from the bag with replacement" model, we have shown that the curvature of the log-log scale is identical to a ``pseudo-variance" which is negative. Although a pseudo-variance calculation may encounter numeric instability when the number of tokens is large, due to the large values of pseudo-weights, this formalism provides a rough estimation of the curvature when the number of tokens is small.

</details>


### [42] [SMRC: Aligning Large Language Models with Student Reasoning for Mathematical Error Correction](https://arxiv.org/abs/2511.14684)
*Biaojie Zeng,Min Zhang,Juan Zhou,Fengrui Liu,Ruiyang Huang,Xin Lin*

Main category: cs.CL

TL;DR: SMRC是一种新颖的数学推理纠错方法，通过蒙特卡洛树搜索探索最优纠错路径，利用LLM引导的广度优先搜索生成奖励信号，并在高中数学基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注模型内部自校正，无法满足教育场景中"教师式"纠错的需求，即系统性地指导和修正学生解题过程。

Method: 将学生推理建模为多步序列决策问题，引入蒙特卡洛树搜索探索最优纠错路径；利用LLM引导的广度优先搜索和最终答案评估生成奖励信号，通过反向传播机制将奖励分配到中间推理步骤。

Result: 在两个公共数据集（ProcessBench和MR-GSM8K）和自建的MSEB基准测试中，SMRC在效果和整体性能上显著优于现有方法。

Conclusion: SMRC方法在教育适用性方面表现出色，通过精细的过程监督实现了有效的学生数学推理纠错。

Abstract: Large language models (LLMs) often make reasoning errors when solving mathematical problems, and how to automatically detect and correct these errors has become an important research direction. However, existing approaches \textit{mainly focus on self-correction within the model}, which falls short of the ``teacher-style`` correction required in educational settings, \textit{i.e.}, systematically guiding and revising a student's problem-solving process. To address this gap, we propose \texttt{SMRC} (\textit{\underline{S}tudent \underline{M}athematical \underline{R}easoning \underline{C}orrection}), a novel method that aligns LLMs with student reasoning. Specifically, \texttt{SMRC} formulates student reasoning as a multi-step sequential decision problem and introduces Monte Carlo Tree Search (MCTS) to explore optimal correction paths. To reduce the cost of the annotating process-level rewards, we leverage breadth-first search (BFS) guided by LLMs and final-answer evaluation to generate reward signals, which are then distributed across intermediate reasoning steps via a back-propagation mechanism, enabling fine-grained process supervision. Additionally, we construct a benchmark for high school mathematics, MSEB (Multi-Solution Error Benchmark), consisting of 158 instances that include problem statements, student solutions, and correct reasoning steps. We further propose a dual evaluation protocol centered on \textbf{solution accuracy} and \textbf{correct-step retention}, offering a comprehensive measure of educational applicability. Experiments demonstrate that \texttt{SMRC} significantly outperforms existing methods on two public datasets (ProcessBench and MR-GSM8K) and our MSEB in terms of effectiveness and overall performance. The code and data are available at https://github.com/Mind-Lab-ECNU/SMRC.

</details>


### [43] [Encoding and Understanding Astrophysical Information in Large Language Model-Generated Summaries](https://arxiv.org/abs/2511.14685)
*Kiera McCormick,Rafael Martínez-Galarza*

Main category: cs.CL

TL;DR: 研究探讨大语言模型能否编码天体物理学测量中的物理统计信息，分析提示工程和语言特征对物理信息编码的影响


<details>
  <summary>Details</summary>
Motivation: 利用LLM编码通常只能通过科学测量获得且松散存在于文本描述中的物理信息，以天体物理学为测试平台

Method: 使用稀疏自编码器从文本中提取可解释特征，研究提示工程的作用和语言特征的重要性

Result: 未在摘要中明确说明具体结果

Conclusion: 研究LLM嵌入如何编码物理统计信息，重点关注提示工程和语言特征的作用

Abstract: Large Language Models have demonstrated the ability to generalize well at many levels across domains, modalities, and even shown in-context learning capabilities. This enables research questions regarding how they can be used to encode physical information that is usually only available from scientific measurements, and loosely encoded in textual descriptions. Using astrophysics as a test bed, we investigate if LLM embeddings can codify physical summary statistics that are obtained from scientific measurements through two main questions: 1) Does prompting play a role on how those quantities are codified by the LLM? and 2) What aspects of language are most important in encoding the physics represented by the measurement? We investigate this using sparse autoencoders that extract interpretable features from the text.

</details>


### [44] [Ground Truth Generation for Multilingual Historical NLP using LLMs](https://arxiv.org/abs/2511.14688)
*Clovis Gladstone,Zhao Fang,Spencer Dean Stewart*

Main category: cs.CL

TL;DR: 使用大语言模型为历史法语和中文文本生成标注数据，通过微调spaCy模型显著提升了词性标注、词形还原和命名实体识别在特定历史时期的性能


<details>
  <summary>Details</summary>
Motivation: 解决历史文本和低资源NLP面临的标注数据稀缺以及与现代网络语料领域不匹配的挑战

Method: 利用LLM生成历史语料的标注数据，然后用这些数据微调spaCy模型

Result: 在特定历史时期的测试中，词性标注、词形还原和命名实体识别任务都取得了显著提升

Conclusion: 领域特定模型的重要性得到验证，即使相对有限的合成数据也能改善计算人文学研究中低资源语料的NLP工具

Abstract: Historical and low-resource NLP remains challenging due to limited annotated data and domain mismatches with modern, web-sourced corpora. This paper outlines our work in using large language models (LLMs) to create ground-truth annotations for historical French (16th-20th centuries) and Chinese (1900-1950) texts. By leveraging LLM-generated ground truth on a subset of our corpus, we were able to fine-tune spaCy to achieve significant gains on period-specific tests for part-of-speech (POS) annotations, lemmatization, and named entity recognition (NER). Our results underscore the importance of domain-specific models and demonstrate that even relatively limited amounts of synthetic data can improve NLP tools for under-resourced corpora in computational humanities research.

</details>


### [45] [Talk, Snap, Complain: Validation-Aware Multimodal Expert Framework for Fine-Grained Customer Grievances](https://arxiv.org/abs/2511.14693)
*Rishu Kumar Singh,Navneet Shreya,Sarmistha Das,Apoorva Singh,Sriparna Saha*

Main category: cs.CL

TL;DR: VALOR是一个用于多模态投诉分析的验证感知学习框架，通过多专家推理和语义对齐实现细粒度投诉分类，在复杂场景中优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有投诉分析方法主要依赖单模态短文本，而实际客服对话中用户常同时提供文本投诉和视觉证据，需要更细粒度的多模态分析方法。

Method: 提出VALOR框架，采用多专家推理设置，使用大规模生成模型和思维链提示进行决策，通过语义对齐分数和元融合策略确保模态间一致性。

Result: 在标注有多模态投诉数据集上评估，VALOR始终优于基线模型，特别是在信息分布在文本和图像中的复杂投诉场景中表现更佳。

Conclusion: 该研究强调了多模态交互和专家验证在实际投诉理解系统中的价值，支持联合国可持续发展目标中的产业创新和负责任消费目标。

Abstract: Existing approaches to complaint analysis largely rely on unimodal, short-form content such as tweets or product reviews. This work advances the field by leveraging multimodal, multi-turn customer support dialogues, where users often share both textual complaints and visual evidence (e.g., screenshots, product photos) to enable fine-grained classification of complaint aspects and severity. We introduce VALOR, a Validation-Aware Learner with Expert Routing, tailored for this multimodal setting. It employs a multi-expert reasoning setup using large-scale generative models with Chain-of-Thought (CoT) prompting for nuanced decision-making. To ensure coherence between modalities, a semantic alignment score is computed and integrated into the final classification through a meta-fusion strategy. In alignment with the United Nations Sustainable Development Goals (UN SDGs), the proposed framework supports SDG 9 (Industry, Innovation and Infrastructure) by advancing AI-driven tools for robust, scalable, and context-aware service infrastructure. Further, by enabling structured analysis of complaint narratives and visual context, it contributes to SDG 12 (Responsible Consumption and Production) by promoting more responsive product design and improved accountability in consumer services. We evaluate VALOR on a curated multimodal complaint dataset annotated with fine-grained aspect and severity labels, showing that it consistently outperforms baseline models, especially in complex complaint scenarios where information is distributed across text and images. This study underscores the value of multimodal interaction and expert validation in practical complaint understanding systems. Resources related to data and codes are available here: https://github.com/sarmistha-D/VALOR

</details>


### [46] [Subword Tokenization Strategies for Kurdish Word Embeddings](https://arxiv.org/abs/2511.14696)
*Ali Salehi,Cassandra L. Jacobs*

Main category: cs.CL

TL;DR: 比较库尔德语词嵌入的不同分词策略，发现基于语素的分词在综合评估中表现最优，而BPE方法因评估覆盖率不足导致性能虚高。


<details>
  <summary>Details</summary>
Motivation: 研究库尔德语词嵌入的分词策略，比较词级、语素级和BPE方法在形态相似性保持任务中的表现，特别关注低资源语言处理中的评估偏差问题。

Method: 开发基于BiLSTM-CRF的形态分析器，使用最小手动标注进行引导训练，在Word2Vec嵌入上通过相似性保持、聚类质量和语义组织等综合指标评估不同分词方法。

Result: BPE方法仅在28.6%的测试用例中评估，而语素模型覆盖68.7%，造成BPE性能虚高。综合评估显示语素分词在嵌入空间组织、语义邻域结构和形态复杂度覆盖方面表现更优。

Conclusion: 在低资源语言处理中，基于语素的分词策略优于BPE，研究强调了覆盖率感知评估的重要性，为低资源语言处理提供了不同的分词方法选择。

Abstract: We investigate tokenization strategies for Kurdish word embeddings by comparing word-level, morpheme-based, and BPE approaches on morphological similarity preservation tasks. We develop a BiLSTM-CRF morphological segmenter using bootstrapped training from minimal manual annotation and evaluate Word2Vec embeddings across comprehensive metrics including similarity preservation, clustering quality, and semantic organization. Our analysis reveals critical evaluation biases in tokenization comparison. While BPE initially appears superior in morphological similarity, it evaluates only 28.6\% of test cases compared to 68.7\% for morpheme model, creating artificial performance inflation. When assessed comprehensively, morpheme-based tokenization demonstrates superior embedding space organization, better semantic neighborhood structure, and more balanced coverage across morphological complexity levels. These findings highlight the importance of coverage-aware evaluation in low-resource language processing and offers different tokenization methods for low-resourced language processing.

</details>


### [47] [Strategic Innovation Management in the Age of Large Language Models Market Intelligence, Adaptive R&D, and Ethical Governance](https://arxiv.org/abs/2511.14709)
*Raha Aghaei,Ali A. Kiaei,Mahnaz Boush,Mahan Rofoosheh,Mohammad Zavvar*

Main category: cs.CL

TL;DR: LLMs通过自动化知识发现、促进假设生成、整合跨学科见解和推动创新生态系统合作，显著提升研发过程的效率和效果。


<details>
  <summary>Details</summary>
Motivation: 分析大型语言模型在转变研发过程中的多重功能，探索如何通过自动化知识发现和促进合作来加速创新周期。

Method: 通过广泛分析科学文献、专利数据库和实验数据，利用LLMs实现更灵活和智能化的研发工作流程。

Result: LLMs显著提高了研发过程的效率和效果，使创新周期加速，突破性想法的上市时间缩短。

Conclusion: 大型语言模型通过多种功能转变研发过程，为加速创新和降低时间成本提供了有效工具。

Abstract: This study analyzes the multiple functions of Large Language Models (LLMs) in transforming research and development (R&D) processes. By automating knowledge discovery, boosting hypothesis creation, integrating transdisciplinary insights, and enabling cooperation within innovation ecosystems, LLMs dramatically improve the efficiency and effectiveness of research processes. Through extensive analysis of scientific literature, patent databases, and experimental data, these models enable more flexible and informed R&D workflows, ultimately accelerating innovation cycles and lowering time-to-market for breakthrough ideas.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [48] [Imagine in Space: Exploring the Frontier of Spatial Intelligence and Reasoning Efficiency in Vision Language Models](https://arxiv.org/abs/2511.13782)
*Xiaoxing Lian,Aidong Yang,Jun Zhu,Peng Wang,Yue Zhang*

Main category: cs.AI

TL;DR: SpatiaLite是一个合成基准测试，揭示了先进视觉语言模型在空间推理方面的局限性，主要依赖语言表征而非视觉想象，并提出IDF框架来改进


<details>
  <summary>Details</summary>
Motivation: 当前先进的视觉语言模型在逻辑推理、问题解决等方面表现出色，但在空间推理（如心理旋转、导航、空间关系理解）方面仍存在显著挑战，需要系统评估其推理机制

Method: 引入SpatiaLite合成基准测试，联合测量空间推理准确性和效率；提出基于想象的IDF数据合成和训练框架

Result: 发现三个关键发现：1）先进VLM主要依赖语言表征，在视觉中心任务上表现不佳；2）空间推理效率低下，token使用随复杂度快速增加；3）IDF框架能隐式构建内部世界模型

Conclusion: 该工作界定了先进VLM的空间推理限制和模式，识别了关键缺陷，并为未来发展提供了指导

Abstract: Large language models (LLMs) and vision language models (VLMs), such as DeepSeek R1,OpenAI o3, and Gemini 2.5 Pro, have demonstrated remarkable reasoning capabilities across logical inference, problem solving, and decision making. However, spatial reasoning:a fundamental component of human cognition that includes mental rotation, navigation, and spatial relationship comprehension remains a significant challenge for current advanced VLMs. We hypothesize that imagination, the internal simulation of spatial states, is the dominant reasoning mechanism within a spatial world model. To test this hypothesis and systematically probe current VLM spatial reasoning mechanisms, we introduce SpatiaLite, a fully synthetic benchmark that jointly measures spatial reasoning accuracy and reasoning efficiency. Comprehensive experiments reveal three key findings. First, advanced VLMs predominantly rely on linguistic representations for reasoning and imagination, resulting in significant deficiencies on visual centric tasks that demand perceptual spatial relations and 3D geometry transformations such as mental rotation or projection prediction. Second, advanced VLMs exhibit severe inefficiency in their current spatial reasoning mechanisms, with token usage growing rapidly as transformation complexity increases. Third, we propose an Imagery Driven Framework (IDF) for data synthesis and training, which can implicitly construct an internal world model that is critical for spatial reasoning in VLMs. Building on SpatiaLite, this work delineates the spatial reasoning limits and patterns of advanced VLMs, identifies key shortcomings, and informs future advances

</details>


### [49] [KANGURA: Kolmogorov-Arnold Network-Based Geometry-Aware Learning with Unified Representation Attention for 3D Modeling of Complex Structures](https://arxiv.org/abs/2511.13798)
*Mohammad Reza Shafie,Morteza Hajiabadi,Hamed Khosravi,Mobina Noori,Imtiaz Ahmed*

Main category: cs.AI

TL;DR: KANGURA是一个基于Kolmogorov-Arnold网络的3D几何感知学习框架，用于优化微生物燃料电池阳极结构，在ModelNet40数据集上达到92.7%准确率，在MFC应用中达到97%准确率。


<details>
  <summary>Details</summary>
Motivation: 现有预测模型难以捕捉微生物燃料电池阳极结构的复杂几何依赖性，限制了性能优化。

Method: 采用KAN网络进行函数分解，通过几何解耦表示学习分离结构变化，并使用统一注意力机制动态增强关键几何区域。

Result: 在ModelNet40基准数据集上超越15个SOTA模型，在真实MFC阳极结构问题上达到97%准确率。

Conclusion: KANGURA为3D几何建模提供了稳健框架，为先进制造和质量驱动工程应用中的复杂结构优化开辟了新可能。

Abstract: Microbial Fuel Cells (MFCs) offer a promising pathway for sustainable energy generation by converting organic matter into electricity through microbial processes. A key factor influencing MFC performance is the anode structure, where design and material properties play a crucial role. Existing predictive models struggle to capture the complex geometric dependencies necessary to optimize these structures. To solve this problem, we propose KANGURA: Kolmogorov-Arnold Network-Based Geometry-Aware Learning with Unified Representation Attention. KANGURA introduces a new approach to three-dimensional (3D) machine learning modeling. It formulates prediction as a function decomposition problem, where Kolmogorov-Arnold Network (KAN)- based representation learning reconstructs geometric relationships without a conventional multi- layer perceptron (MLP). To refine spatial understanding, geometry-disentangled representation learning separates structural variations into interpretable components, while unified attention mechanisms dynamically enhance critical geometric regions. Experimental results demonstrate that KANGURA outperforms over 15 state-of-the-art (SOTA) models on the ModelNet40 benchmark dataset, achieving 92.7% accuracy, and excels in a real-world MFC anode structure problem with 97% accuracy. This establishes KANGURA as a robust framework for 3D geometric modeling, unlocking new possibilities for optimizing complex structures in advanced manufacturing and quality-driven engineering applications.

</details>


### [50] [When AI Does Science: Evaluating the Autonomous AI Scientist KOSMOS in Radiation Biology](https://arxiv.org/abs/2511.13825)
*Humza Nusrat,Omar Nusrat*

Main category: cs.AI

TL;DR: 评估KOSMOS自主AI科学家在辐射生物学中的表现，发现它产生了一个明确发现、一个不确定结果和一个错误假设，表明AI科学家能生成有用想法但需要严格验证。


<details>
  <summary>Details</summary>
Motivation: 评估自主AI科学家KOSMOS在辐射生物学问题上的表现，验证其生成假设的能力和可靠性。

Method: 使用简单随机基因零基准测试KOSMOS在三个辐射生物学问题上的表现：DNA损伤响应与p53转录响应关系、OGT和CDO1基因与辐射响应模块关系、12基因特征与前列腺癌放疗后生存预测。

Result: 假设1不支持（DDR评分与p53响应弱负相关）；OGT弱相关，CDO1明确异常；12基因特征一致性指数0.61但效应大小不唯一。

Conclusion: AI科学家能生成有用想法但需要严格审计和适当零模型验证，避免假阳性发现。

Abstract: Agentic AI "scientists" now use language models to search the literature, run analyses, and generate hypotheses. We evaluate KOSMOS, an autonomous AI scientist, on three problems in radiation biology using simple random-gene null benchmarks. Hypothesis 1: baseline DNA damage response (DDR) capacity across cell lines predicts the p53 transcriptional response after irradiation (GSE30240). Hypothesis 2: baseline expression of OGT and CDO1 predicts the strength of repressed and induced radiation-response modules in breast cancer cells (GSE59732). Hypothesis 3: a 12-gene expression signature predicts biochemical recurrence-free survival after prostate radiotherapy plus androgen deprivation therapy (GSE116918). The DDR-p53 hypothesis was not supported: DDR score and p53 response were weakly negatively correlated (Spearman rho = -0.40, p = 0.76), indistinguishable from random five-gene scores. OGT showed only a weak association (r = 0.23, p = 0.34), whereas CDO1 was a clear outlier (r = 0.70, empirical p = 0.0039). The 12-gene signature achieved a concordance index of 0.61 (p = 0.017) but a non-unique effect size. Overall, KOSMOS produced one well-supported discovery, one plausible but uncertain result, and one false hypothesis, illustrating that AI scientists can generate useful ideas but require rigorous auditing against appropriate null models.

</details>


### [51] [Causal computations in Semi Markovian Structural Causal Models using divide and conquer](https://arxiv.org/abs/2511.13852)
*Anna Rodum Bjøru,Rafael Cabañas,Helge Langseth,Antonio Salmerón*

Main category: cs.AI

TL;DR: 本文研究了将Bjøru等人提出的反事实概率边界计算方法从马尔可夫模型扩展到半马尔可夫结构因果模型的方法，解决了外生变量影响多个内生变量的情况。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅适用于马尔可夫模型，其中每个外生变量只影响单个内生变量。但在实际应用中，半马尔可夫模型能表示更复杂的混杂关系，因此需要扩展该方法以处理更一般的因果模型。

Method: 通过最小示例说明扩展挑战，提出多种替代解决方案策略，并进行理论和计算评估。

Result: 开发了适用于半马尔可夫SCMs的反事实概率边界计算方法，能够处理外生变量影响多个内生变量的情况。

Conclusion: 成功将反事实概率边界计算方法扩展到半马尔可夫结构因果模型，为处理更一般的因果推断问题提供了有效工具。

Abstract: Recently, Bjøru et al. proposed a novel divide-and-conquer algorithm for bounding counterfactual probabilities in structural causal models (SCMs). They assumed that the SCMs were learned from purely observational data, leading to an imprecise characterization of the marginal distributions of exogenous variables. Their method leveraged the canonical representation of structural equations to decompose a general SCM with high-cardinality exogenous variables into a set of sub-models with low-cardinality exogenous variables. These sub-models had precise marginals over the exogenous variables and therefore admitted efficient exact inference. The aggregated results were used to bound counterfactual probabilities in the original model. The approach was developed for Markovian models, where each exogenous variable affects only a single endogenous variable. In this paper, we investigate extending the methodology to \textit{semi-Markovian} SCMs, where exogenous variables may influence multiple endogenous variables. Such models are capable of representing confounding relationships that Markovian models cannot. We illustrate the challenges of this extension using a minimal example, which motivates a set of alternative solution strategies. These strategies are evaluated both theoretically and through a computational study.

</details>


### [52] [Jailbreaking Large Vision Language Models in Intelligent Transportation Systems](https://arxiv.org/abs/2511.13892)
*Badhan Chandra Das,Md Tasnim Jawad,Md Jueal Mia,M. Hadi Amini,Yanzhao Wu*

Main category: cs.AI

TL;DR: 本文系统分析了智能交通系统中大型视觉语言模型在精心设计的越狱攻击下的脆弱性，提出了基于图像排版操纵和多轮提示的新型越狱攻击方法，并开发了多层响应过滤防御技术。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在多模态推理和实际应用中表现出强大能力，但在智能交通系统等关键应用中存在严重的安全漏洞，容易受到越狱攻击，可能导致模型生成有害响应。

Method: 1) 构建与交通相关的有害查询数据集；2) 提出利用图像排版操纵和多轮提示的越狱攻击方法；3) 开发多层响应过滤防御技术防止模型生成不当响应。

Result: 通过对最先进的大型视觉语言模型进行广泛实验，使用GPT-4判断和人工验证评估攻击效果和防御能力，证明所提越狱攻击方法比现有技术更具威胁性。

Conclusion: 智能交通系统中集成的大型视觉语言模型存在严重安全风险，图像排版操纵和多轮提示的越狱攻击方法能够有效绕过安全机制，需要多层防御技术来保护系统安全。

Abstract: Large Vision Language Models (LVLMs) demonstrate strong capabilities in multimodal reasoning and many real-world applications, such as visual question answering. However, LVLMs are highly vulnerable to jailbreaking attacks. This paper systematically analyzes the vulnerabilities of LVLMs integrated in Intelligent Transportation Systems (ITS) under carefully crafted jailbreaking attacks. First, we carefully construct a dataset with harmful queries relevant to transportation, following OpenAI's prohibited categories to which the LVLMs should not respond. Second, we introduce a novel jailbreaking attack that exploits the vulnerabilities of LVLMs through image typography manipulation and multi-turn prompting. Third, we propose a multi-layered response filtering defense technique to prevent the model from generating inappropriate responses. We perform extensive experiments with the proposed attack and defense on the state-of-the-art LVLMs (both open-source and closed-source). To evaluate the attack method and defense technique, we use GPT-4's judgment to determine the toxicity score of the generated responses, as well as manual verification. Further, we compare our proposed jailbreaking method with existing jailbreaking techniques and highlight severe security risks involved with jailbreaking attacks with image typography manipulation and multi-turn prompting in the LVLMs integrated in ITS.

</details>


### [53] [CORGI: Efficient Pattern Matching With Quadratic Guarantees](https://arxiv.org/abs/2511.13942)
*Daniel Weitekamp*

Main category: cs.AI

TL;DR: CORGI是一种新的模式匹配算法，为实时AI系统和数据库查询提供二次时间和空间保证，避免传统RETE算法的指数级内存消耗问题。


<details>
  <summary>Details</summary>
Motivation: 解决基于规则系统中复杂模式匹配的指数时间和空间消耗问题，特别是在AI系统自动生成规则时容易产生最坏情况匹配模式，导致程序执行缓慢或内存溢出。

Method: 采用两步法：前向传递构建/维护接地关系图，后向迭代器按需生成匹配，避免传统RETE算法中β内存收集部分匹配的问题。

Result: 在性能评估中，CORGI在简单组合匹配任务上显著优于SOAR和OPS5的RETE实现。

Conclusion: CORGI算法通过消除填充完整冲突集导致的高延迟和内存溢出，使在线AI系统在无需手工工程约束的情况下保持实用性。

Abstract: Rule-based systems must solve complex matching problems within tight time constraints to be effective in real-time applications, such as planning and reactive control for AI agents, as well as low-latency relational database querying. Pattern-matching systems can encounter issues where exponential time and space are required to find matches for rules with many underconstrained variables, or which produce combinatorial intermediate partial matches (but are otherwise well-constrained). When online AI systems automatically generate rules from example-driven induction or code synthesis, they can easily produce worst-case matching patterns that slow or halt program execution by exceeding available memory. In our own work with cognitive systems that learn from example, we've found that aggressive forms of anti-unification-based generalization can easily produce these circumstances. To make these systems practical without hand-engineering constraints or succumbing to unpredictable failure modes, we introduce a new matching algorithm called CORGI (Collection-Oriented Relational Graph Iteration). Unlike RETE-based approaches, CORGI offers quadratic time and space guarantees for finding single satisficing matches, and the ability to iteratively stream subsequent matches without committing entire conflict sets to memory. CORGI differs from RETE in that it does not have a traditional $β$-memory for collecting partial matches. Instead, CORGI takes a two-step approach: a graph of grounded relations is built/maintained in a forward pass, and an iterator generates matches as needed by working backward through the graph. This approach eliminates the high-latency delays and memory overflows that can result from populating full conflict sets. In a performance evaluation, we demonstrate that CORGI significantly outperforms RETE implementations from SOAR and OPS5 on a simple combinatorial matching task.

</details>


### [54] [Scene Graph-Guided Generative AI Framework for Synthesizing and Evaluating Industrial Hazard Scenarios](https://arxiv.org/abs/2511.13970)
*Sanjay Acharjee,Abir Khan Ratul,Diego Patino,Md Nazmus Sakib*

Main category: cs.AI

TL;DR: 提出了一种基于场景图引导的生成AI框架，利用OSHA事故报告生成逼真的工作场所危险场景图像，并通过VQA框架评估生成数据的真实性和语义保真度。


<details>
  <summary>Details</summary>
Motivation: 获取真实工作场所危险场景图像数据集困难，因为捕捉实际发生的事故触发场景几乎不可能。

Method: 使用GPT-4o分析OSHA叙述提取结构化危险推理，转换为对象级场景图，指导文本到图像扩散模型生成构图准确的危险场景，并引入VQA框架评估生成数据。

Result: 提出的VQA图评分在四个最先进的生成模型中优于CLIP和BLIP指标，基于熵验证确认其具有更高的判别敏感性。

Conclusion: 该框架能够有效生成逼真的工作场所危险场景图像，为训练准确检测工作场所危险的视觉模型提供了可行解决方案。

Abstract: Training vision models to detect workplace hazards accurately requires realistic images of unsafe conditions that could lead to accidents. However, acquiring such datasets is difficult because capturing accident-triggering scenarios as they occur is nearly impossible. To overcome this limitation, this study presents a novel scene graph-guided generative AI framework that synthesizes photorealistic images of hazardous scenarios grounded in historical Occupational Safety and Health Administration (OSHA) accident reports. OSHA narratives are analyzed using GPT-4o to extract structured hazard reasoning, which is converted into object-level scene graphs capturing spatial and contextual relationships essential for understanding risk. These graphs guide a text-to-image diffusion model to generate compositionally accurate hazard scenes. To evaluate the realism and semantic fidelity of the generated data, a visual question answering (VQA) framework is introduced. Across four state-of-the-art generative models, the proposed VQA Graph Score outperforms CLIP and BLIP metrics based on entropy-based validation, confirming its higher discriminative sensitivity.

</details>


### [55] [Artificial Intelligence Agents in Music Analysis: An Integrative Perspective Based on Two Use Cases](https://arxiv.org/abs/2511.13987)
*Antonio Manuel Martínez-Heredia,Dolores Godrid Rodríguez,Andrés Ortiz García*

Main category: cs.AI

TL;DR: 本文综述并验证了AI代理在音乐分析和教育中的应用，从基于规则的模型发展到深度学习、多代理架构和RAG框架，通过双案例方法评估教学影响。


<details>
  <summary>Details</summary>
Motivation: 探索AI代理在音乐分析和教育中的潜力，解决传统自动化方法在可解释性和适应性方面的不足，推动计算音乐学和音乐教育的发展。

Method: 采用双案例方法：(1)在中学教育中使用生成式AI平台培养分析和创造技能；(2)设计用于符号音乐分析的多代理系统，实现模块化、可扩展和可解释的工作流程。

Result: 实验结果表明，AI代理在音乐模式识别、作曲参数化和教育反馈方面表现优异，在可解释性和适应性方面优于传统自动化方法。

Conclusion: 研究提出了一个统一框架，融合技术、教学和伦理考量，为计算音乐学和音乐教育中智能代理的设计和应用提供基于证据的指导。

Abstract: This paper presents an integrative review and experimental validation of artificial intelligence (AI) agents applied to music analysis and education. We synthesize the historical evolution from rule-based models to contemporary approaches involving deep learning, multi-agent architectures, and retrieval-augmented generation (RAG) frameworks. The pedagogical implications are evaluated through a dual-case methodology: (1) the use of generative AI platforms in secondary education to foster analytical and creative skills; (2) the design of a multiagent system for symbolic music analysis, enabling modular, scalable, and explainable workflows.
  Experimental results demonstrate that AI agents effectively enhance musical pattern recognition, compositional parameterization, and educational feedback, outperforming traditional automated methods in terms of interpretability and adaptability. The findings highlight key challenges concerning transparency, cultural bias, and the definition of hybrid evaluation metrics, emphasizing the need for responsible deployment of AI in educational environments.
  This research contributes to a unified framework that bridges technical, pedagogical, and ethical considerations, offering evidence-based guidance for the design and application of intelligent agents in computational musicology and music education.

</details>


### [56] [ALEX:A Light Editing-knowledge Extractor](https://arxiv.org/abs/2511.14018)
*Minghu Wang,Shuliang Zhao,Yuanyuan Zhao,Hongxia Xu*

Main category: cs.AI

TL;DR: ALEX是一个轻量级知识编辑框架，通过分层内存架构将知识更新组织为语义簇，将检索复杂度从O(N)降低到O(K+N/C)，显著提升多跳问答准确性和推理路径可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型中的知识是静态的，难以适应不断变化的信息，现有方法在处理需要多步推理的复杂多跳问题时面临可扩展性和检索效率的挑战。

Method: 提出ALEX框架，包含分层内存架构、推理查询合成模块和动态证据裁决引擎，通过语义聚类和两阶段检索过程优化知识编辑。

Result: 在MQUAKE基准测试中，多跳答案准确性和推理路径可靠性显著提升，搜索空间减少超过80%。

Conclusion: ALEX为构建可扩展、高效和准确的知识编辑系统提供了一条有前景的路径。

Abstract: The static nature of knowledge within Large Language Models (LLMs) makes it difficult for them to adapt to evolving information, rendering knowledge editing a critical task. However, existing methods struggle with challenges of scalability and retrieval efficiency, particularly when handling complex, multi-hop questions that require multi-step reasoning. To address these challenges, this paper introduces ALEX (A Light Editing-knowledge Extractor), a lightweight knowledge editing framework. The core innovation of ALEX is its hierarchical memory architecture, which organizes knowledge updates (edits) into semantic clusters. This design fundamentally reduces retrieval complexity from a linear O(N) to a highly scalable O(K+N/C). Furthermore, the framework integrates an Inferential Query Synthesis (IQS) module to bridge the semantic gap between queries and facts , and a Dynamic Evidence Adjudication (DEA) engine that executes an efficient two-stage retrieval process. Experiments on the MQUAKE benchmark demonstrate that ALEX significantly improves both the accuracy of multi-hop answers (MultiHop-ACC) and the reliability of reasoning paths (HopWise-ACC). It also reduces the required search space by over 80% , presenting a promising path toward building scalable, efficient, and accurate knowledge editing systems.

</details>


### [57] [Syn-STARTS: Synthesized START Triage Scenario Generation Framework for Scalable LLM Evaluation](https://arxiv.org/abs/2511.14023)
*Chiharu Hagiwara,Naoki Nonaka,Yuhta Hashimoto,Ryu Uchimido,Jun Seita*

Main category: cs.AI

TL;DR: Syn-STARTS框架使用LLMs生成大规模分类案例，解决了大规模伤亡事件中真实数据稀缺的问题，生成的合成数据在质量上与人工整理的真实数据集难以区分。


<details>
  <summary>Details</summary>
Motivation: 大规模伤亡事件中的分类决策至关重要，但真实数据难以收集，阻碍了AI模型的发展。需要高质量的基准数据集来训练和评估AI分类系统。

Method: 开发Syn-STARTS框架，利用大型语言模型生成分类案例，并与人工整理的TRIAGE开放数据集进行质量对比验证。

Result: Syn-STARTS生成的分类案例在质量上与人工整理的真实数据集难以区分，且在标准START分类方法下，LLM在不同类别（绿色、黄色、红色、黑色）的案例生成中表现高度稳定。

Conclusion: 合成数据在开发针对严重和危急医疗情况的高性能AI模型方面具有巨大潜力，能够解决真实数据稀缺的问题。

Abstract: Triage is a critically important decision-making process in mass casualty incidents (MCIs) to maximize victim survival rates. While the role of AI in such situations is gaining attention for making optimal decisions within limited resources and time, its development and performance evaluation require benchmark datasets of sufficient quantity and quality. However, MCIs occur infrequently, and sufficient records are difficult to accumulate at the scene, making it challenging to collect large-scale realworld data for research use. Therefore, we developed Syn-STARTS, a framework that uses LLMs to generate triage cases, and verified its effectiveness. The results showed that the triage cases generated by Syn-STARTS were qualitatively indistinguishable from the TRIAGE open dataset generated by manual curation from training materials. Furthermore, when evaluating the LLM accuracy using hundreds of cases each from the green, yellow, red, and black categories defined by the standard triage method START, the results were found to be highly stable. This strongly indicates the possibility of synthetic data in developing high-performance AI models for severe and critical medical situations.

</details>


### [58] [AISAC: An Integrated multi-agent System for Transparent, Retrieval-Grounded Scientific Assistance](https://arxiv.org/abs/2511.14043)
*Chandrachur Bhattacharya,Sibendu Som*

Main category: cs.AI

TL;DR: AISAC是一个集成多代理系统，专为科学和工程工作流设计，采用Router-Planner-Coordinator工作流，结合FAISS向量搜索和SQLite持久化，提供透明度和可追溯性。


<details>
  <summary>Details</summary>
Motivation: 开发一个透明、可追溯且适应科学工作流需求的集成多代理系统，以支持复杂的科学和工程任务。

Method: 使用LangGraph编排、FAISS进行向量搜索、SQLite持久化，采用Router-Planner-Coordinator工作流和提示工程代理，结合混合内存方法（FAISS+SQLite）实现语义检索和结构化对话历史。

Result: 系统已应用于阿贡国家实验室的多个研究领域，包括废物转化产品和能源过程安全等专业部署，展示了其跨领域适用性。

Conclusion: AISAC通过集成现有技术并注重透明度和可追溯性，成功构建了一个适用于科学工作流的灵活多代理系统原型。

Abstract: AI Scientific Assistant Core (AISAC) is an integrated multi-agent system developed at Argonne National Laboratory for scientific and engineering workflows. AISAC builds on established technologies - LangGraph for orchestration, FAISS for vector search, and SQLite for persistence - and integrates them into a unified system prototype focused on transparency, provenance tracking, and scientific adaptability.
  The system implements a Router-Planner-Coordinator workflow and an optional Evaluator role, using prompt-engineered agents coordinated via LangGraph's StateGraph and supported by helper agents such as a Researcher. Each role is defined through custom system prompts that enforce structured JSON outputs. A hybrid memory approach (FAISS + SQLite) enables both semantic retrieval and structured conversation history. An incremental indexing strategy based on file hashing minimizes redundant re-embedding when scientific corpora evolve. A configuration-driven project bootstrap layer allows research teams to customize tools, prompts, and data sources without modifying core code.
  All agent decisions, tool invocations, and retrievals are logged and visualized through a custom Gradio interface, providing step-by-step transparency for each reasoning episode. The authors have applied AISAC to multiple research areas at Argonne, including specialized deployments for waste-to-products research and energy process safety, as well as general-purpose scientific assistance, demonstrating its cross-domain applicability.

</details>


### [59] [Making Evidence Actionable in Adaptive Learning](https://arxiv.org/abs/2511.14052)
*Amirreza Mehrabi,Jason W. Morphew,Breejha Quezada,N. Sanjay Rebello*

Main category: cs.AI

TL;DR: 提出了一种教师主导的自适应学习反馈循环系统，通过概念级评估证据生成经过验证的微干预措施，解决了传统自适应学习诊断精准但干预薄弱的问题。


<details>
  <summary>Details</summary>
Motivation: 传统自适应学习系统虽然能够精确诊断学习问题，但提供的干预往往时机不当或内容不匹配，导致帮助效果有限。需要一种能够将诊断结果有效转化为针对性教学干预的方法。

Method: 开发了包含三个保障机制的自适应学习算法：充分性保证差距闭合、注意力作为时间和冗余的预算约束、多样性防止对单一资源的过拟合。将干预分配形式化为带约束的二元整数规划问题，使用贪婪选择、梯度松弛和混合方法三种求解器。

Result: 在模拟和1204名学生的物理课程部署中，两种求解器都能在有限观看时间内为几乎所有学习者实现完整的技能覆盖。梯度方法相比贪婪方法减少了约12%的冗余覆盖，并在难度分布上更加均衡。

Conclusion: 该系统提供了一个可追踪和可审计的控制器，能够闭合诊断-教学循环，在课堂规模上实现公平且负载感知的个性化学习。

Abstract: Adaptive learning often diagnoses precisely yet intervenes weakly, yielding help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted micro-interventions. The adaptive learning algorithm contains three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted constraint for time and redundancy, and diversity as protection against overfitting to a single resource. We formalize intervention assignment as a binary integer program with constraints for coverage, time, difficulty windows informed by ability estimates, prerequisites encoded by a concept matrix, and anti-redundancy enforced through diversity. Greedy selection serves low-richness and tight-latency regimes, gradient-based relaxation serves rich repositories, and a hybrid method transitions along a richness-latency frontier. In simulation and in an introductory physics deployment with one thousand two hundred four students, both solvers achieved full skill coverage for essentially all learners within bounded watch time. The gradient-based method reduced redundant coverage by approximately twelve percentage points relative to greedy and harmonized difficulty across slates, while greedy delivered comparable adequacy with lower computational cost in scarce settings. Slack variables localized missing content and supported targeted curation, sustaining sufficiency across subgroups. The result is a tractable and auditable controller that closes the diagnostic-pedagogical loop and delivers equitable, load-aware personalization at classroom scale.

</details>


### [60] [Collaborative QA using Interacting LLMs. Impact of Network Structure, Node Capability and Distributed Data](https://arxiv.org/abs/2511.14098)
*Adit Jain,Vikram Krishnamurthy,Yiming Zhang*

Main category: cs.AI

TL;DR: 本文研究了LLM网络在协作问答中的幻觉传播问题，提出了结合平均场动力学和随机效用模型的生成模型，分析了网络结构和激励对固定点行为的影响。


<details>
  <summary>Details</summary>
Motivation: LLM在缺乏直接证据时容易产生幻觉，而在交互网络中这种幻觉会传播，导致原本准确的LLM也开始产生幻觉。

Method: 结合网络科学的平均场动力学和经济学中的随机效用模型，构建生成模型。将LLM建模为具有潜在状态（真实/幻觉），分析有向网络中的信息扩散。

Result: 为具有两种潜在状态的LLM网络提出了固定点存在性和唯一性的充分条件，并分析了激励对固定点行为的影响。在100个开源LLM网络上进行了实验研究。

Conclusion: 该模型能够有效分析LLM网络中幻觉传播的动态特性，为理解网络结构和激励对协作问答性能的影响提供了理论框架。

Abstract: In this paper, we model and analyze how a network of interacting LLMs performs collaborative question-answering (CQA) in order to estimate a ground truth given a distributed set of documents. This problem is interesting because LLMs often hallucinate when direct evidence to answer a question is lacking, and these effects become more pronounced in a network of interacting LLMs. The hallucination spreads, causing previously accurate LLMs to hallucinate. We study interacting LLMs and their hallucination by combining novel ideas of mean-field dynamics (MFD) from network science and the randomized utility model from economics to construct a useful generative model. We model the LLM with a latent state that indicates if it is truthful or not with respect to the ground truth, and extend a tractable analytical model considering an MFD to model the diffusion of information in a directed network of LLMs. To specify the probabilities that govern the dynamics of the MFD, we propose a randomized utility model. For a network of LLMs, where each LLM has two possible latent states, we posit sufficient conditions for the existence and uniqueness of a fixed point and analyze the behavior of the fixed point in terms of the incentive (e.g., test-time compute) given to individual LLMs. We experimentally study and analyze the behavior of a network of $100$ open-source LLMs with respect to data heterogeneity, node capability, network structure, and sensitivity to framing on multiple semi-synthetic datasets.

</details>


### [61] [APD-Agents: A Large Language Model-Driven Multi-Agents Collaborative Framework for Automated Page Design](https://arxiv.org/abs/2511.14101)
*Xinpeng Chen,Xiaofeng Han,Kaihao Zhang,Guochao Ren,Yujie Wang,Wenhao Cao,Yang Zhou,Jianfeng Lu,Zhenbo Song*

Main category: cs.AI

TL;DR: APD-agents是一个基于大语言模型的多智能体框架，用于自动化移动应用页面设计，通过多个专业智能体协作将用户描述转换为完整的页面布局。


<details>
  <summary>Details</summary>
Motivation: 移动应用页面布局设计耗时且需要专业技能，现有设计软件学习成本高，跨页面协作设计需要额外时间确保风格一致性。

Method: 使用多智能体框架：OrchestratorAgent协调任务，SemanticParserAgent解析用户描述，PrimaryLayoutAgent生成粗粒度布局，TemplateRetrievalAgent检索相关示例，RecursiveComponentAgent递归生成细粒度子元素。

Result: 在RICO数据集上的实验结果表明，APD-agents达到了最先进的性能水平。

Conclusion: 该工作充分利用了大模型驱动的多智能体系统的自动协作能力，实现了高效的自动化页面设计。

Abstract: Layout design is a crucial step in developing mobile app pages. However, crafting satisfactory designs is time-intensive for designers: they need to consider which controls and content to present on the page, and then repeatedly adjust their size, position, and style for better aesthetics and structure. Although many design software can now help to perform these repetitive tasks, extensive training is needed to use them effectively. Moreover, collaborative design across app pages demands extra time to align standards and ensure consistent styling. In this work, we propose APD-agents, a large language model (LLM) driven multi-agent framework for automated page design in mobile applications. Our framework contains OrchestratorAgent, SemanticParserAgent, PrimaryLayoutAgent, TemplateRetrievalAgent, and RecursiveComponentAgent. Upon receiving the user's description of the page, the OrchestratorAgent can dynamically can direct other agents to accomplish users' design task. To be specific, the SemanticParserAgent is responsible for converting users' descriptions of page content into structured data. The PrimaryLayoutAgent can generate an initial coarse-grained layout of this page. The TemplateRetrievalAgent can fetch semantically relevant few-shot examples and enhance the quality of layout generation. Besides, a RecursiveComponentAgent can be used to decide how to recursively generate all the fine-grained sub-elements it contains for each element in the layout. Our work fully leverages the automatic collaboration capabilities of large-model-driven multi-agent systems. Experimental results on the RICO dataset show that our APD-agents achieve state-of-the-art performance.

</details>


### [62] [PRISM: Prompt-Refined In-Context System Modelling for Financial Retrieval](https://arxiv.org/abs/2511.14130)
*Chun Chet Ng,Jia Yu Lim,Wei Zeng Low*

Main category: cs.AI

TL;DR: 提出了PRISM框架，用于金融信息检索任务，包含文档排序和块排序两个任务。该框架整合了精炼系统提示、上下文学习和轻量级多代理系统，在FinAgentBench数据集上取得了0.71818的NDCG@5分数。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，金融信息检索成为重要的工业应用。从冗长的金融文件中提取任务相关信息对于运营和分析决策至关重要。

Method: PRISM是一个无需训练的框架，整合了三个组件：精炼系统提示提供精确的任务指令，上下文学习提供语义相关的少样本示例，轻量级多代理系统模拟协调评分行为。

Result: 在受限验证集上，最佳配置实现了0.71818的NDCG@5分数。PRISM被证明在生产规模的金融检索中是可行且稳健的。

Conclusion: PRISM的模块化、仅推理设计使其适用于实际应用场景。该框架为金融信息检索提供了实用的解决方案。

Abstract: With the rapid progress of large language models (LLMs), financial information retrieval has become a critical industrial application. Extracting task-relevant information from lengthy financial filings is essential for both operational and analytical decision-making. The FinAgentBench dataset formalizes this problem through two tasks: document ranking and chunk ranking. We present PRISM, a training-free framework that integrates refined system prompting, in-context learning (ICL), and a lightweight multi-agent system. Each component is examined extensively to reveal their synergies: prompt engineering provides precise task instructions, ICL supplies semantically relevant few-shot examples, and the multi-agent system models coordinated scoring behaviour. Our best configuration achieves an NDCG@5 of 0.71818 on the restricted validation split. We further demonstrate that PRISM is feasible and robust for production-scale financial retrieval. Its modular, inference-only design makes it practical for real-world use cases. The source code is released at https://bit.ly/prism-ailens.

</details>


### [63] [Run, Ruminate, and Regulate: A Dual-process Thinking System for Vision-and-Language Navigation](https://arxiv.org/abs/2511.14131)
*Yu Zhong,Zihao Zhang,Rui Zhang,Lingdong Huang,Haihan Gao,Shuo Wang,Da Li,Ruijian Han,Jiaming Guo,Shaohui Peng,Di Huang,Yunji Chen*

Main category: cs.AI

TL;DR: 提出R3双过程思维框架，将LLM的泛化能力与VLN专家知识结合，通过Runner、Ruminator和Regulator三个模块实现高效导航，在REVERIE基准上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在视觉语言导航中理解真实世界空间关联的困难，以及计算成本和推理延迟问题，同时弥补LLM方法与领域专家之间的性能差距。

Method: 采用双过程思维框架：Runner（轻量级专家模型负责常规导航）、Ruminator（多模态LLM进行结构化推理）、Regulator（监控导航进度并控制思维模式）。

Result: 在REVERIE基准上SPL和RGSPL分别超过3.28%和3.30%，显著优于其他最先进方法。

Conclusion: R3框架有效处理挑战性VLN任务，证明了将LLM泛化能力与领域专业知识结合的优越性。

Abstract: Vision-and-Language Navigation (VLN) requires an agent to dynamically explore complex 3D environments following human instructions. Recent research underscores the potential of harnessing large language models (LLMs) for VLN, given their commonsense knowledge and general reasoning capabilities. Despite their strengths, a substantial gap in task completion performance persists between LLM-based approaches and domain experts, as LLMs inherently struggle to comprehend real-world spatial correlations precisely. Additionally, introducing LLMs is accompanied with substantial computational cost and inference latency. To address these issues, we propose a novel dual-process thinking framework dubbed R3, integrating LLMs' generalization capabilities with VLN-specific expertise in a zero-shot manner. The framework comprises three core modules: Runner, Ruminator, and Regulator. The Runner is a lightweight transformer-based expert model that ensures efficient and accurate navigation under regular circumstances. The Ruminator employs a powerful multimodal LLM as the backbone and adopts chain-of-thought (CoT) prompting to elicit structured reasoning. The Regulator monitors the navigation progress and controls the appropriate thinking mode according to three criteria, integrating Runner and Ruminator harmoniously. Experimental results illustrate that R3 significantly outperforms other state-of-the-art methods, exceeding 3.28% and 3.30% in SPL and RGSPL respectively on the REVERIE benchmark. This pronounced enhancement highlights the effectiveness of our method in handling challenging VLN tasks.

</details>


### [64] [Beyond Accuracy: A Multi-Dimensional Framework for Evaluating Enterprise Agentic AI Systems](https://arxiv.org/abs/2511.14136)
*Sushant Mehta*

Main category: cs.AI

TL;DR: 提出了CLEAR评估框架，针对企业AI代理部署需求，弥补现有基准在成本效率、可靠性和运营稳定性方面的评估缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理基准主要关注任务完成准确率，但忽视了企业部署的关键需求，如成本效率、可靠性和运营稳定性。

Method: 通过系统分析12个主要基准和实证评估最先进的代理，提出了CLEAR（成本、延迟、效能、保证、可靠性）整体评估框架。

Result: 在300个企业任务上评估6个领先代理，发现仅优化准确率的代理比成本感知替代方案贵4.4-10.8倍；专家评估确认CLEAR能更好预测生产成功（ρ=0.83 vs 准确率评估的ρ=0.41）。

Conclusion: CLEAR框架为企业AI代理部署提供了更全面的评估标准，显著提升了生产环境成功的预测能力。

Abstract: Current agentic AI benchmarks predominantly evaluate task completion accuracy, while overlooking critical enterprise requirements such as cost-efficiency, reliability, and operational stability. Through systematic analysis of 12 main benchmarks and empirical evaluation of state-of-the-art agents, we identify three fundamental limitations: (1) absence of cost-controlled evaluation leading to 50x cost variations for similar precision, (2) inadequate reliability assessment where agent performance drops from 60\% (single run) to 25\% (8-run consistency), and (3) missing multidimensional metrics for security, latency, and policy compliance. We propose \textbf{CLEAR} (Cost, Latency, Efficacy, Assurance, Reliability), a holistic evaluation framework specifically designed for enterprise deployment. Evaluation of six leading agents on 300 enterprise tasks demonstrates that optimizing for accuracy alone yields agents 4.4-10.8x more expensive than cost-aware alternatives with comparable performance. Expert evaluation (N=15) confirms that CLEAR better predicts production success (correlation $ρ=0.83$) compared to accuracy-only evaluation ($ρ=0.41$).

</details>


### [65] [HFL-FlowLLM: Large Language Models for Network Traffic Flow Classification in Heterogeneous Federated Learning](https://arxiv.org/abs/2511.14199)
*Jiazhuo Tian,Yachao Yuan*

Main category: cs.AI

TL;DR: HFL-FlowLLM是首个将大语言模型应用于异构联邦学习网络流量分类的框架，相比现有方法平均F1分数提升约13%，训练成本降低约87%。


<details>
  <summary>Details</summary>
Motivation: 解决5G和物联网环境下传统集中式机器学习面临的数据分布和隐私问题，以及现有联邦学习方法成本高、泛化能力差的问题。

Method: 提出HFL-FlowLLM框架，将大语言模型应用于异构联邦学习中的网络流量分类任务。

Result: 相比现有异构联邦学习方法平均F1分数提升约13%；相比现有大语言模型联邦学习框架，在增加客户端数量时平均F1分数提升达5%，同时训练成本降低约87%。

Conclusion: HFL-FlowLLM在现代通信网络安全中具有巨大潜力和实用价值。

Abstract: In modern communication networks driven by 5G and the Internet of Things (IoT), effective network traffic flow classification is crucial for Quality of Service (QoS) management and security. Traditional centralized machine learning struggles with the distributed data and privacy concerns in these heterogeneous environments, while existing federated learning approaches suffer from high costs and poor generalization. To address these challenges, we propose HFL-FlowLLM, which to our knowledge is the first framework to apply large language models to network traffic flow classification in heterogeneous federated learning. Compared to state-of-the-art heterogeneous federated learning methods for network traffic flow classification, the proposed approach improves the average F1 score by approximately 13%, demonstrating compelling performance and strong robustness. When compared to existing large language models federated learning frameworks, as the number of clients participating in each training round increases, the proposed method achieves up to a 5% improvement in average F1 score while reducing the training costs by about 87%. These findings prove the potential and practical value of HFL-FlowLLM in modern communication networks security.

</details>


### [66] [Do Large Language Models (LLMs) Understand Chronology?](https://arxiv.org/abs/2511.14214)
*Pattaraphon Kenny Wongchamcharoen,Paul Glasserman*

Main category: cs.AI

TL;DR: 测试大型语言模型对时间顺序的理解能力，发现在金融应用中存在前瞻性偏差问题。模型在局部排序上表现良好，但在全局一致性时间线上存在困难。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在金融和经济学中日益应用，但基于提示的方法隐含假设模型理解时间顺序，需要验证这一基本问题。

Method: 设计了一系列时间顺序任务，包括时间排序、条件排序（先过滤后排序）和时代错误检测，评估GPT-4.1、Claude-3.7 Sonnet（有/无扩展思维）和GPT-5在不同推理强度设置下的表现。

Result: 随着序列长度增加，精确匹配率急剧下降，但排名相关性保持较高。在条件排序中，大多数失败源于过滤步骤而非排序步骤。时代错误检测是最简单的任务，但性能仍随时间线或实体重叠增加而下降。

Conclusion: 分配明确的推理预算有助于时间排序，GPT-5在中等/高推理强度下实现完美排序，而低/最小推理强度会随列表变长而退化。这些发现界定了当前LLM在时间任务上的限制，为金融实时应用提供了重要见解。

Abstract: Large language models (LLMs) are increasingly used in finance and economics, where prompt-based attempts against look-ahead bias implicitly assume that models understand chronology. We test this fundamental question with a series of chronological ordering tasks with increasing complexities over facts the model already knows from pre-training. Our tasks cover (1) chronological ordering, (2) conditional sorting (filter, then order), and (3) anachronism detection. We evaluate GPT-4.1, Claude-3.7 Sonnet, with and without Extended Thinking (ET), and GPT-5 across multiple reasoning-effort settings. Across models, Exact match rate drops sharply as sequences lengthen even while rank correlations stay high as LLMs largely preserve local order but struggle to maintain a single globally consistent timeline. In conditional sorting, most failures stem from the filtering step rather than the ordering step, but GPT-5 and Claude-3.7 Sonnet with Extended Thinking outshine normal models significantly. Lastly, anachronism detection is found to be the easiest task for the LLMs but performance still declines with increasingly overlapping timelines or entities. Overall, our main contribution is showing that allocating explicit reasoning budget helps with chronological ordering with GPT-5 at medium/high reasoning effort achieving flawless ordering at all lengths and perfect conditional sorting (both self-filtered and given-subset), whereas low/minimal effort degrades with longer lists, mirroring earlier models. Our findings delineate limits of current LLMs on chronological tasks, providing insights into task complexity, and demonstrate scenarios in which reasoning helps. These patterns are important for the real-time application of LLMs in finance. We release all code and evaluation templates to support full reproducibility.

</details>


### [67] [Listen Like a Teacher: Mitigating Whisper Hallucinations using Adaptive Layer Attention and Knowledge Distillation](https://arxiv.org/abs/2511.14219)
*Kumud Tripathi,Aditya Srinivas Menon,Aman Gaurav,Raj Prakash Gohil,Pankaj Wasnik*

Main category: cs.AI

TL;DR: 提出两阶段架构来减少Whisper模型的幻觉错误：第一阶段通过自适应层注意力增强编码器鲁棒性，第二阶段使用多目标知识蒸馏抑制幻觉。


<details>
  <summary>Details</summary>
Motivation: Whisper模型在噪声条件下经常出现幻觉错误，而现有方法主要关注音频预处理或转录后处理，对模型本身的修改探索不足。

Method: 1. 自适应层注意力(ALA)：通过层间相关性分析将编码器层分组，使用可学习多头注意力融合块表示；2. 多目标知识蒸馏(KD)：在噪声音频上训练学生模型，使其语义和注意力分布与处理干净输入的教师模型对齐。

Result: 在噪声语音基准测试中显著减少了幻觉和词错误率，同时保持了在干净语音上的性能。

Conclusion: ALA和KD提供了一种原则性策略，可提高Whisper在真实世界噪声条件下的可靠性。

Abstract: The Whisper model, an open-source automatic speech recognition system, is widely adopted for its strong performance across multilingual and zero-shot settings. However, it frequently suffers from hallucination errors, especially under noisy acoustic conditions. Previous works to reduce hallucinations in Whisper-style ASR systems have primarily focused on audio preprocessing or post-processing of transcriptions to filter out erroneous content. However, modifications to the Whisper model itself remain largely unexplored to mitigate hallucinations directly. To address this challenge, we present a two-stage architecture that first enhances encoder robustness through Adaptive Layer Attention (ALA) and further suppresses hallucinations using a multi-objective knowledge distillation (KD) framework. In the first stage, ALA groups encoder layers into semantically coherent blocks via inter-layer correlation analysis. A learnable multi-head attention module then fuses these block representations, enabling the model to jointly exploit low- and high-level features for more robust encoding. In the second stage, our KD framework trains the student model on noisy audio to align its semantic and attention distributions with a teacher model processing clean inputs. Our experiments on noisy speech benchmarks show notable reductions in hallucinations and word error rates, while preserving performance on clean speech. Together, ALA and KD offer a principled strategy to improve Whisper's reliability under real-world noisy conditions.

</details>


### [68] [DevPiolt: Operation Recommendation for IoT Devices at Xiaomi Home](https://arxiv.org/abs/2511.14227)
*Yuxiang Wang,Siwen Wang,Haowei Han,Ao Wang,Boya Liu,Yong Zhao,Chengbo Wu,Bin Zhu,Bin Qin,Xiaokai Zhou,Xiao Yan,Jiawei Jiang,Bo Du*

Main category: cs.AI

TL;DR: DevPiolt是一个基于大语言模型的物联网设备操作推荐系统，通过持续预训练、多任务微调、直接偏好优化和置信度控制机制，显著提升推荐性能，已在小米家庭应用中部署并取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 现有推荐模型在处理物联网设备操作时面临复杂操作逻辑、多样化用户偏好和对次优建议敏感等问题，限制了其在物联网设备操作推荐中的适用性。

Method: 1. 通过持续预训练和多任务微调为LLM注入物联网操作领域知识；2. 使用直接偏好优化使微调后的LLM与特定用户偏好对齐；3. 设计基于置信度的曝光控制机制避免低质量推荐带来的负面用户体验。

Result: 在多个数据集上显著优于基线模型，所有指标平均提升69.5%；在线部署一个季度，服务25.5万用户，独立访客设备覆盖率提升21.6%，页面浏览接受率提升29.1%。

Conclusion: DevPiolt通过结合领域知识注入、用户偏好对齐和置信度控制，有效解决了物联网设备操作推荐中的关键挑战，在实际应用中取得了显著成效。

Abstract: Operation recommendation for IoT devices refers to generating personalized device operations for users based on their context, such as historical operations, environment information, and device status. This task is crucial for enhancing user satisfaction and corporate profits. Existing recommendation models struggle with complex operation logic, diverse user preferences, and sensitive to suboptimal suggestions, limiting their applicability to IoT device operations. To address these issues, we propose DevPiolt, a LLM-based recommendation model for IoT device operations. Specifically, we first equip the LLM with fundamental domain knowledge of IoT operations via continual pre-training and multi-task fine-tuning. Then, we employ direct preference optimization to align the fine-tuned LLM with specific user preferences. Finally, we design a confidence-based exposure control mechanism to avoid negative user experiences from low-quality recommendations. Extensive experiments show that DevPiolt significantly outperforms baselines on all datasets, with an average improvement of 69.5% across all metrics. DevPiolt has been practically deployed in Xiaomi Home app for one quarter, providing daily operation recommendations to 255,000 users. Online experiment results indicate a 21.6% increase in unique visitor device coverage and a 29.1% increase in page view acceptance rates.

</details>


### [69] [Enhancing Regional Airbnb Trend Forecasting Using LLM-Based Embeddings of Accessibility and Human Mobility](https://arxiv.org/abs/2511.14248)
*Hongju Lee,Youngjun Park,Jisun An,Dongman Lee*

Main category: cs.AI

TL;DR: 提出基于LLM的区域级Airbnb市场预测框架，通过整合房源特征和外部因素生成区域嵌入，结合时间序列模型预测未来1-3个月的收入、预订天数和预订量，相比传统方法误差降低约48%。


<details>
  <summary>Details</summary>
Motivation: Airbnb等短租平台的扩张扰乱了当地住房市场，导致租金上涨和住房负担问题。准确预测区域Airbnb市场趋势可为政策制定者提供关键洞察，以缓解这些影响。

Method: 使用滑动窗口方法，将结构化表格数据转换为基于提示的LLM输入，生成综合区域嵌入，然后输入RNN、LSTM、Transformer等时间序列模型，捕捉复杂的时空动态。

Result: 在首尔Airbnb数据集上的实验表明，该方法相比传统统计和机器学习模型，平均RMSE和MAE降低了约48%。

Conclusion: 该框架不仅提高了预测准确性，还为检测供应过剩区域和支持数据驱动的城市政策决策提供了实用见解。

Abstract: The expansion of short-term rental platforms, such as Airbnb, has significantly disrupted local housing markets, often leading to increased rental prices and housing affordability issues. Accurately forecasting regional Airbnb market trends can thus offer critical insights for policymakers and urban planners aiming to mitigate these impacts. This study proposes a novel time-series forecasting framework to predict three key Airbnb indicators -- Revenue, Reservation Days, and Number of Reservations -- at the regional level. Using a sliding-window approach, the model forecasts trends 1 to 3 months ahead. Unlike prior studies that focus on individual listings at fixed time points, our approach constructs regional representations by integrating listing features with external contextual factors such as urban accessibility and human mobility. We convert structured tabular data into prompt-based inputs for a Large Language Model (LLM), producing comprehensive regional embeddings. These embeddings are then fed into advanced time-series models (RNN, LSTM, Transformer) to better capture complex spatio-temporal dynamics. Experiments on Seoul's Airbnb dataset show that our method reduces both average RMSE and MAE by approximately 48% compared to conventional baselines, including traditional statistical and machine learning models. Our framework not only improves forecasting accuracy but also offers practical insights for detecting oversupplied regions and supporting data-driven urban policy decisions.

</details>


### [70] [PathMind: A Retrieve-Prioritize-Reason Framework for Knowledge Graph Reasoning with Large Language Models](https://arxiv.org/abs/2511.14256)
*Yu Liu,Xixun Lin,Yanmin Shang,Yangxi Li,Shi Wang,Yanan Cao*

Main category: cs.AI

TL;DR: PathMind是一个新颖的知识图谱推理框架，通过选择性引导LLMs使用重要推理路径来增强忠实和可解释的推理。它采用"检索-优先化-推理"范式，包含路径优先化机制和双阶段训练策略，在复杂推理任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的KGR方法存在两个关键限制：1) 不加区分地提取推理路径，可能引入无关噪声误导LLMs；2) 动态探索推理路径需要高检索需求和频繁LLM调用。

Method: PathMind遵循"检索-优先化-推理"范式：1) 通过检索模块从KG中检索查询子图；2) 使用语义感知路径优先级函数识别重要推理路径，同时考虑累积成本和估计的未来成本；3) 通过双阶段训练策略（任务特定指令调优和路径偏好对齐）生成准确且逻辑一致的响应。

Result: 在基准数据集上的广泛实验表明，PathMind始终优于竞争基线，特别是在输入token较少的复杂推理任务中，通过识别基本推理路径实现更好性能。

Conclusion: PathMind通过选择性引导LLMs使用重要推理路径，有效解决了现有方法的局限性，在知识图谱推理任务中实现了更忠实和可解释的推理性能。

Abstract: Knowledge graph reasoning (KGR) is the task of inferring new knowledge by performing logical deductions on knowledge graphs. Recently, large language models (LLMs) have demonstrated remarkable performance in complex reasoning tasks. Despite promising success, current LLM-based KGR methods still face two critical limitations. First, existing methods often extract reasoning paths indiscriminately, without assessing their different importance, which may introduce irrelevant noise that misleads LLMs. Second, while many methods leverage LLMs to dynamically explore potential reasoning paths, they require high retrieval demands and frequent LLM calls. To address these limitations, we propose PathMind, a novel framework designed to enhance faithful and interpretable reasoning by selectively guiding LLMs with important reasoning paths. Specifically, PathMind follows a "Retrieve-Prioritize-Reason" paradigm. First, it retrieves a query subgraph from KG through the retrieval module. Next, it introduces a path prioritization mechanism that identifies important reasoning paths using a semantic-aware path priority function, which simultaneously considers the accumulative cost and the estimated future cost for reaching the target. Finally, PathMind generates accurate and logically consistent responses via a dual-phase training strategy, including task-specific instruction tuning and path-wise preference alignment. Extensive experiments on benchmark datasets demonstrate that PathMind consistently outperforms competitive baselines, particularly on complex reasoning tasks with fewer input tokens, by identifying essential reasoning paths.

</details>


### [71] [DataSage: Multi-agent Collaboration for Insight Discovery with External Knowledge Retrieval, Multi-role Debating, and Multi-path Reasoning](https://arxiv.org/abs/2511.14299)
*Xiaochuan Liu,Yuanfeng Song,Xiaoming Yin,Xing Chen*

Main category: cs.AI

TL;DR: DataSage是一个多智能体框架，通过外部知识检索、多角色辩论机制和多路径推理来解决现有数据洞察代理在领域知识利用不足、分析深度浅和代码生成错误方面的问题。


<details>
  <summary>Details</summary>
Motivation: 在数据驱动时代，全自动端到端数据分析特别是洞察发现对于组织决策至关重要。现有数据洞察代理在领域知识利用、分析深度和代码生成准确性方面存在不足。

Method: 提出DataSage多智能体框架，包含三个创新特性：外部知识检索丰富分析上下文、多角色辩论机制模拟不同分析视角、多路径推理提高代码和洞察生成的准确性。

Result: 在InsightBench上的广泛实验表明，DataSage在所有难度级别上都持续优于现有数据洞察代理。

Conclusion: DataSage为自动化数据洞察发现提供了一个有效的解决方案。

Abstract: In today's data-driven era, fully automated end-to-end data analytics, particularly insight discovery, is critical for discovering actionable insights that assist organizations in making effective decisions. With the rapid advancement of large language models (LLMs), LLM-driven agents have emerged as a promising paradigm for automating data analysis and insight discovery. However, existing data insight agents remain limited in several key aspects, often failing to deliver satisfactory results due to: (1) insufficient utilization of domain knowledge, (2) shallow analytical depth, and (3) error-prone code generation during insight generation. To address these issues, we propose DataSage, a novel multi-agent framework that incorporates three innovative features including external knowledge retrieval to enrich the analytical context, a multi-role debating mechanism to simulate diverse analytical perspectives and deepen analytical depth, and multi-path reasoning to improve the accuracy of the generated code and insights. Extensive experiments on InsightBench demonstrate that DataSage consistently outperforms existing data insight agents across all difficulty levels, offering an effective solution for automated data insight discovery.

</details>


### [72] [When Words Change the Model: Sensitivity of LLMs for Constraint Programming Modelling](https://arxiv.org/abs/2511.14334)
*Alessio Pellegrino,Jacopo Mauro*

Main category: cs.AI

TL;DR: LLMs在自动生成优化问题模型时，其表现可能主要来自训练数据中的问题重复而非真正的推理能力。通过重新表述和扰动经典CSPLib问题，研究发现LLMs对上下文和语言变化敏感，理解肤浅。


<details>
  <summary>Details</summary>
Motivation: 检验LLMs自动生成优化问题模型的能力是否源于真正的推理能力，还是仅仅因为训练数据中包含了这些经典问题（数据污染）。

Method: 系统性地重新表述和扰动一组著名的CSPLib问题，保持问题结构不变但修改上下文并引入误导元素，然后比较三个代表性LLM在原始和修改后描述下的模型生成表现。

Result: LLMs能够生成语法有效且语义合理的模型，但在上下文和语言变化下性能急剧下降，显示出浅层理解和对措辞的敏感性。

Conclusion: LLMs在自动生成优化模型方面的成功可能更多源于数据污染而非真正的推理能力，它们对问题的理解是肤浅且对语言表述敏感的。

Abstract: One of the long-standing goals in optimisation and constraint programming is to describe a problem in natural language and automatically obtain an executable, efficient model. Large language models appear to bring this vision closer, showing impressive results in automatically generating models for classical benchmarks. However, much of this apparent success may derive from data contamination rather than genuine reasoning: many standard CP problems are likely included in the training data of these models. To examine this hypothesis, we systematically rephrased and perturbed a set of well-known CSPLib problems to preserve their structure while modifying their context and introducing misleading elements. We then compared the models produced by three representative LLMs across original and modified descriptions. Our qualitative analysis shows that while LLMs can produce syntactically valid and semantically plausible models, their performance drops sharply under contextual and linguistic variation, revealing shallow understanding and sensitivity to wording.

</details>


### [73] [Operationalizing Pluralistic Values in Large Language Model Alignment Reveals Trade-offs in Safety, Inclusivity, and Model Behavior](https://arxiv.org/abs/2511.14476)
*Dalia Ali,Dora Zhao,Allison Koenecke,Orestis Papakyriakopoulos*

Main category: cs.AI

TL;DR: 本研究探讨了在LLM对齐过程中考虑多元社会价值观的重要性，发现人口统计特征和技术设计选择都会显著影响模型行为。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的对齐决策往往忽视人类社会的多样性，需要研究如何将多元价值观纳入对齐流程。

Method: 收集了来自美国和德国参与者的27,375个评分，在毒性、情感意识、敏感性、刻板印象偏见和帮助性五个维度上评估LLM回答。基于不同社会群体的偏好微调模型，并比较了评分尺度、分歧处理方法和优化技术的影响。

Result: 发现系统性人口统计效应：男性参与者对毒性的评分比女性低18%；保守派和黑人参与者对情感意识的评分分别比自由派和白人参与者高27.9%和44%。技术设计选择影响显著：保留评分者分歧比多数投票减少53%毒性；5点量表比二元格式减少22%毒性；DPO在多值优化中优于GRPO。

Conclusion: 这是回答关键问题的初步步骤：对齐应如何平衡专家驱动和用户驱动的信号，以确保安全性和公平代表性。

Abstract: Although large language models (LLMs) are increasingly trained using human feedback for safety and alignment with human values, alignment decisions often overlook human social diversity. This study examines how incorporating pluralistic values affects LLM behavior by systematically evaluating demographic variation and design parameters in the alignment pipeline. We collected alignment data from US and German participants (N = 1,095, 27,375 ratings) who rated LLM responses across five dimensions: Toxicity, Emotional Awareness (EA), Sensitivity, Stereotypical Bias, and Helpfulness. We fine-tuned multiple Large Language Models and Large Reasoning Models using preferences from different social groups while varying rating scales, disagreement handling methods, and optimization techniques. The results revealed systematic demographic effects: male participants rated responses 18% less toxic than female participants; conservative and Black participants rated responses 27.9% and 44% more emotionally aware than liberal and White participants, respectively. Models fine-tuned on group-specific preferences exhibited distinct behaviors. Technical design choices showed strong effects: the preservation of rater disagreement achieved roughly 53% greater toxicity reduction than majority voting, and 5-point scales yielded about 22% more reduction than binary formats; and Direct Preference Optimization (DPO) consistently outperformed Group Relative Policy Optimization (GRPO) in multi-value optimization. These findings represent a preliminary step in answering a critical question: How should alignment balance expert-driven and user-driven signals to ensure both safety and fair representation?

</details>


### [74] [A Neuro-Symbolic Framework for Reasoning under Perceptual Uncertainty: Bridging Continuous Perception and Discrete Symbolic Planning](https://arxiv.org/abs/2511.14533)
*Jiahao Wu,Shengwen Yu*

Main category: cs.AI

TL;DR: 提出一种神经符号框架，通过显式建模和传播从感知到规划的不确定性，将连续感知信号与离散符号推理连接起来。在桌面机器人操作任务中验证了有效性，在多个基准测试中达到90.7%的平均成功率，比最强POMDP基线提高10-14个百分点。


<details>
  <summary>Details</summary>
Motivation: 解决在不确定性下运行的AI系统中，连续感知信号与离散符号推理之间的桥梁问题，为这两个抽象层次提供原则性连接。

Method: 结合基于transformer的感知前端和图神经网络关系推理，从视觉观察中提取概率符号状态，并使用不确定性感知的符号规划器在置信度低时主动收集信息。

Result: 在10,047个PyBullet生成的场景（3-10个物体）上处理，输出具有校准置信度的概率谓词（总体F1=0.68）。在规划器中嵌入后，在Simple Stack、Deep Stack和Clear+Stack基准测试中分别达到94%/90%/88%的成功率（平均90.7%），比最强POMDP基线提高10-14个百分点，规划时间在15毫秒内。

Conclusion: 概率图模型分析建立了校准不确定性与规划收敛之间的定量联系，提供了理论保证并得到实证验证。该框架是通用的，可应用于任何需要从感知输入到符号规划的不确定性感知推理的领域。

Abstract: Bridging continuous perceptual signals and discrete symbolic reasoning is a fundamental challenge in AI systems that must operate under uncertainty. We present a neuro-symbolic framework that explicitly models and propagates uncertainty from perception to planning, providing a principled connection between these two abstraction levels. Our approach couples a transformer-based perceptual front-end with graph neural network (GNN) relational reasoning to extract probabilistic symbolic states from visual observations, and an uncertainty-aware symbolic planner that actively gathers information when confidence is low. We demonstrate the framework's effectiveness on tabletop robotic manipulation as a concrete application: the translator processes 10,047 PyBullet-generated scenes (3--10 objects) and outputs probabilistic predicates with calibrated confidences (overall F1=0.68). When embedded in the planner, the system achieves 94\%/90\%/88\% success on Simple Stack, Deep Stack, and Clear+Stack benchmarks (90.7\% average), exceeding the strongest POMDP baseline by 10--14 points while planning within 15\,ms. A probabilistic graphical-model analysis establishes a quantitative link between calibrated uncertainty and planning convergence, providing theoretical guarantees that are validated empirically. The framework is general-purpose and can be applied to any domain requiring uncertainty-aware reasoning from perceptual input to symbolic planning.

</details>


### [75] [Rate-Distortion Guided Knowledge Graph Construction from Lecture Notes Using Gromov-Wasserstein Optimal Transport](https://arxiv.org/abs/2511.14595)
*Yuan An,Ruhma Hashmi,Michelle Rogers,Jane Greenberg,Brian K. Smith*

Main category: cs.AI

TL;DR: 提出基于率失真理论和最优传输几何的知识图谱构建与优化框架，通过FGW耦合量化语义失真，使用细化操作最小化率失真拉格朗日量，生成紧凑且信息保留的知识图谱，显著提升多选题生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决将非结构化教育材料（如讲义和幻灯片）转换为捕捉关键教学内容的知识图谱的困难，为AI辅助教育系统提供高质量的多选题生成能力。

Method: 将讲座内容建模为度量-测度空间，使用融合Gromov-Wasserstein耦合量化语义失真，通过添加、合并、拆分、移除和重连等细化操作最小化率失真拉格朗日量。

Result: 在数据科学讲座上的原型应用显示，从优化后的知识图谱生成的多选题在15个质量指标上持续优于原始笔记生成的多选题。

Conclusion: 本研究为个性化教育和AI辅助教育中的信息论知识图谱优化建立了理论基础，证明了率失真框架在知识图谱构建中的有效性。

Abstract: Task-oriented knowledge graphs (KGs) enable AI-powered learning assistant systems to automatically generate high-quality multiple-choice questions (MCQs). Yet converting unstructured educational materials, such as lecture notes and slides, into KGs that capture key pedagogical content remains difficult. We propose a framework for knowledge graph construction and refinement grounded in rate-distortion (RD) theory and optimal transport geometry. In the framework, lecture content is modeled as a metric-measure space, capturing semantic and relational structure, while candidate KGs are aligned using Fused Gromov-Wasserstein (FGW) couplings to quantify semantic distortion. The rate term, expressed via the size of KG, reflects complexity and compactness. Refinement operators (add, merge, split, remove, rewire) minimize the rate-distortion Lagrangian, yielding compact, information-preserving KGs. Our prototype applied to data science lectures yields interpretable RD curves and shows that MCQs generated from refined KGs consistently surpass those from raw notes on fifteen quality criteria. This study establishes a principled foundation for information-theoretic KG optimization in personalized and AI-assisted education.

</details>


### [76] [AutoTool: Efficient Tool Selection for Large Language Model Agents](https://arxiv.org/abs/2511.14650)
*Jingyi Jia,Qinbin Li*

Main category: cs.AI

TL;DR: AutoTool是一个基于图的框架，通过利用工具使用惯性来减少LLM代理的推理成本，无需重复调用LLM进行工具选择。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理框架在工具选择时存在高推理成本问题，特别是像ReAct这样的方法需要反复调用LLM来决定每一步使用哪个工具。

Method: 构建基于历史代理轨迹的有向图，节点表示工具，边捕获转移概率，建模工具选择惯性，并集成参数级信息来优化工具输入生成。

Result: 在多样化代理任务上的广泛实验表明，AutoTool将推理成本降低高达30%，同时保持竞争力的任务完成率。

Conclusion: 这项工作展示了将统计结构集成到LLM代理设计中的前景，可以在不牺牲性能的情况下实现更高的效率。

Abstract: Large Language Model (LLM) agents have emerged as powerful tools for automating complex tasks by leveraging the reasoning and decision-making abilities of LLMs. However, a major bottleneck in current agent frameworks lies in the high inference cost of tool selection, especially in approaches like ReAct that repeatedly invoke the LLM to determine which tool to use at each step. In this work, we propose AutoTool, a novel graph-based framework that bypasses repeated LLM inference by exploiting a key empirical observation: tool usage inertia - the tendency of tool invocations to follow predictable sequential patterns. AutoTool constructs a directed graph from historical agent trajectories, where nodes represent tools and edges capture transition probabilities, effectively modeling the inertia in tool selection. It further integrates parameter-level information to refine tool input generation. By traversing this structured representation, AutoTool efficiently selects tools and their parameters with minimal reliance on LLM inference. Extensive experiments across diverse agent tasks demonstrate that AutoTool reduces inference costs by up to 30% while maintaining competitive task completion rates, offering a practical and scalable enhancement for inference-heavy frameworks. Our work highlights the promise of integrating statistical structure into LLM agent design for greater efficiency without sacrificing performance.

</details>


### [77] [SkillGen: Learning Domain Skills for In-Context Sequential Decision Making](https://arxiv.org/abs/2511.14670)
*Ruomeng Ding,Wei Cheng,Minglai Shao,Chen Zhao*

Main category: cs.AI

TL;DR: SkillGen是一个基于技能的上下文学习框架，通过构建动作中心图、识别高效用动作并检索逐步技能，为顺序决策任务生成细粒度的上下文感知提示，显著提升LLM在顺序决策任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有上下文学习方法在顺序决策任务中难以同时满足三个关键原则：关注决策关键信息、提供步骤级粒度、最小化专家标注依赖。

Method: SkillGen构建动作中心的领域级图，通过时间差分信用分配识别高效用动作，检索逐步技能来生成细粒度的上下文感知提示。

Result: 在ALFWorld、BabyAI和ScienceWorld数据集上，使用开源和专有LLM，SkillGen平均提升进度率5.9%-16.5%。

Conclusion: 关注高效用片段支持任务可识别性，并为更有效的ICL提示设计提供信息，SkillGen框架在顺序推理任务中实现了持续的性能提升。

Abstract: Large language models (LLMs) are increasingly applied to sequential decision-making through in-context learning (ICL), yet their effectiveness is highly sensitive to prompt quality. Effective prompts should meet three principles: focus on decision-critical information, provide step-level granularity, and minimize reliance on expert annotations through label efficiency. However, existing ICL methods often fail to satisfy all three criteria simultaneously. Motivated by these challenges, we introduce SkillGen, a skill-based ICL framework for structured sequential reasoning. It constructs an action-centric, domain-level graph from sampled trajectories, identifies high-utility actions via temporal-difference credit assignment, and retrieves step-wise skills to generate fine-grained, context-aware prompts. We further present a theoretical analysis showing that focusing on high-utility segments supports task identifiability and informs more effective ICL prompt design. Experiments on ALFWorld, BabyAI, and ScienceWorld, using both open-source and proprietary LLMs, show that SkillGen achieves consistent gains, improving progress rate by 5.9%-16.5% on average across models.

</details>


### [78] [Heterogeneous Multi-Agent Proximal Policy Optimization for Power Distribution System Restoration](https://arxiv.org/abs/2511.14730)
*Parya Dolatyabi,Mahdi Khodayar*

Main category: cs.AI

TL;DR: 本文应用异构智能体强化学习框架解决配电网大规模停电后的恢复问题，通过HAPPO算法实现互联微电网的协调恢复，相比传统方法具有更快收敛速度和更高恢复效率。


<details>
  <summary>Details</summary>
Motivation: 配电网大规模停电后的恢复需要处理非线性约束下的顺序开关操作和分布式能源协调，传统优化方法和基于价值的强化学习方法计算效率低且难以扩展。

Method: 采用异构智能体强化学习框架，通过HAPPO算法训练分散的智能体策略，每个智能体控制具有不同负载、DER容量和开关数量的微电网，使用集中式评论家计算优势值进行稳定策略更新。

Result: 在IEEE 123总线和IEEE 8500节点系统上的实验表明，HAPPO相比DQN、PPO等多种算法具有更快收敛速度、更高恢复功率和更平滑的多种子训练效果。

Conclusion: 在HARL框架中纳入微电网级别的异构性，为复杂配电网恢复问题提供了可扩展、稳定且约束感知的解决方案。

Abstract: Restoring power distribution systems (PDS) after large-scale outages requires sequential switching operations that reconfigure feeder topology and coordinate distributed energy resources (DERs) under nonlinear constraints such as power balance, voltage limits, and thermal ratings. These challenges make conventional optimization and value-based RL approaches computationally inefficient and difficult to scale. This paper applies a Heterogeneous-Agent Reinforcement Learning (HARL) framework, instantiated through Heterogeneous-Agent Proximal Policy Optimization (HAPPO), to enable coordinated restoration across interconnected microgrids. Each agent controls a distinct microgrid with different loads, DER capacities, and switch counts, introducing practical structural heterogeneity. Decentralized actor policies are trained with a centralized critic to compute advantage values for stable on-policy updates. A physics-informed OpenDSS environment provides full power flow feedback and enforces operational limits via differentiable penalty signals rather than invalid action masking. The total DER generation is capped at 2400 kW, and each microgrid must satisfy local supply-demand feasibility. Experiments on the IEEE 123-bus and IEEE 8500-node systems show that HAPPO achieves faster convergence, higher restored power, and smoother multi-seed training than DQN, PPO, MAES, MAGDPG, MADQN, Mean-Field RL, and QMIX. Results demonstrate that incorporating microgrid-level heterogeneity within the HARL framework yields a scalable, stable, and constraint-aware solution for complex PDS restoration.

</details>
