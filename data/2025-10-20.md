<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 52]
- [cs.AI](#cs.AI) [Total: 30]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Rethinking Toxicity Evaluation in Large Language Models: A Multi-Label Perspective](https://arxiv.org/abs/2510.15007)
*Zhiqiang Kou,Junyang Chen,Xin-Qiang Cai,Ming-Kun Xie,Biao Liu,Changwei Wang,Lei Feng,Yuheng Jia,Gang Niu,Masashi Sugiyama,Xin Geng*

Main category: cs.CL

TL;DR: 提出了三个多标签毒性检测基准(Q-A-MLL、R-A-MLL、H-X-MLL)，基于15类细粒度毒性分类，并通过伪标签方法显著提升了毒性检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有毒性检测器主要依赖单标签基准，无法充分捕捉真实世界毒性提示的模糊性和多维度特性，导致评估偏差和检测不可靠。

Method: 从公共毒性数据集构建三个多标签基准，采用15类细粒度毒性分类法，并提出基于伪标签的毒性检测方法。

Result: 实验结果表明，该方法显著超越了GPT-4o和DeepSeek等先进基线，实现了更准确可靠的多标签毒性评估。

Conclusion: 多标签基准和伪标签方法能够有效解决毒性检测中的评估偏差问题，提升LLM生成内容毒性检测的可靠性。

Abstract: Large language models (LLMs) have achieved impressive results across a range
of natural language processing tasks, but their potential to generate harmful
content has raised serious safety concerns. Current toxicity detectors
primarily rely on single-label benchmarks, which cannot adequately capture the
inherently ambiguous and multi-dimensional nature of real-world toxic prompts.
This limitation results in biased evaluations, including missed toxic
detections and false positives, undermining the reliability of existing
detectors. Additionally, gathering comprehensive multi-label annotations across
fine-grained toxicity categories is prohibitively costly, further hindering
effective evaluation and development. To tackle these issues, we introduce
three novel multi-label benchmarks for toxicity detection: \textbf{Q-A-MLL},
\textbf{R-A-MLL}, and \textbf{H-X-MLL}, derived from public toxicity datasets
and annotated according to a detailed 15-category taxonomy. We further provide
a theoretical proof that, on our released datasets, training with pseudo-labels
yields better performance than directly learning from single-label supervision.
In addition, we develop a pseudo-label-based toxicity detection method.
Extensive experimental results show that our approach significantly surpasses
advanced baselines, including GPT-4o and DeepSeek, thus enabling more accurate
and reliable evaluation of multi-label toxicity in LLM-generated content.

</details>


### [2] [Can generative AI figure out figurative language? The influence of idioms on essay scoring by ChatGPT, Gemini, and Deepseek](https://arxiv.org/abs/2510.15009)
*Enis Oğuz*

Main category: cs.CL

TL;DR: 本研究评估了生成式AI模型对包含和不包含习语的学生作文的评分表现，发现Gemini在评分一致性和处理比喻语言方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 生成式AI技术发展迅速，被提议作为自动作文评分系统的竞争者。考虑到AI在处理习语方面的潜在局限性，本研究结合语料库语言学和计算语言学的见解，评估生成式AI模型对包含和不包含习语的作文评分表现。

Method: 从348篇学生作文中创建两个相等的作文列表：一个包含多个习语，另一个不包含习语。使用ChatGPT、Gemini和Deepseek三种生成式AI模型，按照人类评分员使用的相同评分标准对两个列表中的所有作文进行三次评分。

Result: 所有模型都表现出极好的一致性，但Gemini在与人类评分员的评分者间信度方面优于竞争对手。AI评估中未检测到对任何人口群体的偏见。对于包含多个习语的作文，Gemini的评分模式与人类评分员最为相似。

Conclusion: 研究中的模型展示了混合方法的潜力，但Gemini由于其处理比喻语言的能力而成为最佳选择，并显示出未来单独处理作文评分任务的前景。

Abstract: The developments in Generative AI technologies have paved the way for
numerous innovations in different fields. Recently, Generative AI has been
proposed as a competitor to AES systems in evaluating student essays
automatically. Considering the potential limitations of AI in processing
idioms, this study assessed the scoring performances of Generative AI models
for essays with and without idioms by incorporating insights from Corpus
Linguistics and Computational Linguistics. Two equal essay lists were created
from 348 student essays taken from a corpus: one with multiple idioms present
in each essay and another with no idioms in essays. Three Generative AI models
(ChatGPT, Gemini, and Deepseek) were asked to score all essays in both lists
three times, using the same rubric used by human raters in assigning essay
scores. The results revealed excellent consistency for all models, but Gemini
outperformed its competitors in interrater reliability with human raters. There
was also no detectable bias for any demographic group in AI assessment. For
essays with multiple idioms, Gemini followed a the most similar pattern to
human raters. While the models in the study demonstrated potential for a hybrid
approach, Gemini was the best candidate for the task due to its ability to
handle figurative language and showed promise for handling essay-scoring tasks
alone in the future.

</details>


### [3] [A Generalizable Rhetorical Strategy Annotation Model Using LLM-based Debate Simulation and Labelling](https://arxiv.org/abs/2510.15081)
*Shiyu Ji,Farnoosh Hashemi,Joice Chen,Juanwen Pan,Weicheng Ma,Hefan Zhang,Sophia Pan,Ming Cheng,Shubham Mohole,Saeed Hassanpour,Soroush Vosoughi,Michael Macy*

Main category: cs.CL

TL;DR: 提出利用大语言模型自动生成和标注辩论数据的新框架，基于四种修辞类型（因果、经验、情感、道德）训练分类器，并在多个外部语料库上验证性能，展示了在说服力预测和政治辩论分析中的应用。


<details>
  <summary>Details</summary>
Motivation: 修辞策略分析依赖人工标注，成本高、不一致且难以扩展，现有数据集局限于特定主题和策略，阻碍了稳健模型的发展。

Method: 利用大语言模型自动生成和标注合成辩论数据，基于四部分修辞类型学（因果、经验、情感、道德），在LLM标注的数据集上微调基于Transformer的分类器。

Result: 模型在多个外部语料库上实现高性能和强泛化能力，在说服力预测中融入修辞策略标签可提升性能，分析显示美国总统辩论中情感论证使用增加。

Conclusion: 该框架为修辞策略分析提供了可扩展的解决方案，揭示了政治辩论中修辞策略的演变趋势，情感论证逐渐超越认知论证。

Abstract: Rhetorical strategies are central to persuasive communication, from political
discourse and marketing to legal argumentation. However, analysis of rhetorical
strategies has been limited by reliance on human annotation, which is costly,
inconsistent, difficult to scale. Their associated datasets are often limited
to specific topics and strategies, posing challenges for robust model
development. We propose a novel framework that leverages large language models
(LLMs) to automatically generate and label synthetic debate data based on a
four-part rhetorical typology (causal, empirical, emotional, moral). We
fine-tune transformer-based classifiers on this LLM-labeled dataset and
validate its performance against human-labeled data on this dataset and on
multiple external corpora. Our model achieves high performance and strong
generalization across topical domains. We illustrate two applications with the
fine-tuned model: (1) the improvement in persuasiveness prediction from
incorporating rhetorical strategy labels, and (2) analyzing temporal and
partisan shifts in rhetorical strategies in U.S. Presidential debates
(1960-2020), revealing increased use of affective over cognitive argument in
U.S. Presidential debates.

</details>


### [4] [Continual Learning via Sparse Memory Finetuning](https://arxiv.org/abs/2510.15103)
*Jessy Lin,Luke Zettlemoyer,Gargi Ghosh,Wen-Tau Yih,Aram Markosyan,Vincent-Pierre Berges,Barlas Oğuz*

Main category: cs.CL

TL;DR: 提出稀疏记忆微调方法，通过仅更新新知识高度激活的记忆槽来减少灾难性遗忘，相比全微调和LoRA方法显著降低了遗忘率。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型部署后通常是静态的，持续学习面临灾难性遗忘的挑战。受参数共享导致遗忘的直觉启发，研究稀疏参数更新是否能实现无灾难性遗忘的学习。

Method: 引入稀疏记忆微调，利用记忆层模型的设计特性，仅更新被新知识高度激活的记忆槽，减少新知识与模型现有能力之间的干扰。

Result: 在两个问答任务上评估，稀疏记忆微调在学习新知识的同时遗忘显著减少：NaturalQuestions F1仅下降11%，而全微调下降89%，LoRA下降71%。

Conclusion: 记忆层中的稀疏性为大语言模型的持续学习提供了一条有前景的路径。

Abstract: Modern language models are powerful, but typically static after deployment. A
major obstacle to building models that continually learn over time is
catastrophic forgetting, where updating on new data erases previously acquired
capabilities. Motivated by the intuition that mitigating forgetting is
challenging because trainable parameters are shared across all tasks, we
investigate whether sparse parameter updates can enable learning without
catastrophic forgetting. We introduce sparse memory finetuning, leveraging
memory layer models (Berges et al., 2024), which are sparsely updated by
design. By updating only the memory slots that are highly activated by a new
piece of knowledge relative to usage on pretraining data, we reduce
interference between new knowledge and the model's existing capabilities. We
evaluate learning and forgetting compared to full finetuning and
parameter-efficient finetuning with LoRA on two question answering tasks. We
find that sparse memory finetuning learns new knowledge while exhibiting
substantially less forgetting: while NaturalQuestions F1 drops by 89% after
full finetuning on new facts and 71% with LoRA, sparse memory finetuning yields
only an 11% drop with the same level of new knowledge acquisition. Our results
suggest sparsity in memory layers offers a promising path toward continual
learning in large language models.

</details>


### [5] [Measuring the Effect of Disfluency in Multilingual Knowledge Probing Benchmarks](https://arxiv.org/abs/2510.15115)
*Kirill Semenov,Rico Sennrich*

Main category: cs.CL

TL;DR: 本文分析了MLAMA多语言知识评估基准中模板翻译导致的语法问题，通过比较斯拉夫语系的4种语言在原始模板和整句翻译版本上的知识检索得分，发现整句翻译能显著提高得分并改善结果可解释性。


<details>
  <summary>Details</summary>
Motivation: MLAMA等多语言事实知识评估基准使用模板翻译方法，忽略了命名实体的语法和语义信息，导致最终提示存在语法错误或措辞不当，特别是在形态丰富的语言中，这影响了得分的可解释性。

Method: 从MLAMA数据集中选取4种斯拉夫语言，比较原始模板数据集与Google Translate和ChatGPT整句翻译版本的知识检索得分，并对5种其他语系语言进行额外分析。

Result: 观察到知识检索得分显著提高，整句翻译方法能更好地处理语法问题，提高结果的可解释性。

Conclusion: 建议在多语言数据集构建中控制语法正确性，使用神经机器翻译或LLM系统进行整句翻译可以近似实现这一目标，从而获得更高且更可解释的结果。

Abstract: For multilingual factual knowledge assessment of LLMs, benchmarks such as
MLAMA use template translations that do not take into account the grammatical
and semantic information of the named entities inserted in the sentence. This
leads to numerous instances of ungrammaticality or wrong wording of the final
prompts, which complicates the interpretation of scores, especially for
languages that have a rich morphological inventory. In this work, we sample 4
Slavic languages from the MLAMA dataset and compare the knowledge retrieval
scores between the initial (templated) MLAMA dataset and its sentence-level
translations made by Google Translate and ChatGPT. We observe a significant
increase in knowledge retrieval scores, and provide a qualitative analysis for
possible reasons behind it. We also make an additional analysis of 5 more
languages from different families and see similar patterns. Therefore, we
encourage the community to control the grammaticality of highly multilingual
datasets for higher and more interpretable results, which is well approximated
by whole sentence translation with neural MT or LLM systems. The dataset and
all related code is published at the Github repository:
https://github.com/ZurichNLP/Fluent-mLAMA.

</details>


### [6] [Latent Topic Synthesis: Leveraging LLMs for Electoral Ad Analysis](https://arxiv.org/abs/2510.15125)
*Alexander Brady,Tunazzina Islam*

Main category: cs.CL

TL;DR: 提出了一个端到端框架，利用无监督聚类和基于提示的标注，从无标签语料库自动生成可解释的主题分类法，并应用于2024年美国总统选举前的Meta政治广告分析。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台在塑造政治话语中起关键作用，但分析其庞大且快速演变的内容仍面临重大挑战，需要可扩展且可解释的分析方法。

Method: 结合无监督聚类与基于提示的标注，利用大语言模型迭代构建分类法，无需种子集或领域专业知识。

Result: 发现投票和移民广告在支出和展示量上占主导，而堕胎和选举诚信话题获得不成比例的关注；资金模式呈现极化，不同议题的道德框架存在差异。

Conclusion: 该框架支持对社交媒体政治信息进行可扩展、可解释的分析，帮助研究者、政策制定者和公众更好地理解新兴叙事、极化动态和数字政治沟通的道德基础。

Abstract: Social media platforms play a pivotal role in shaping political discourse,
but analyzing their vast and rapidly evolving content remains a major
challenge. We introduce an end-to-end framework for automatically generating an
interpretable topic taxonomy from an unlabeled corpus. By combining
unsupervised clustering with prompt-based labeling, our method leverages large
language models (LLMs) to iteratively construct a taxonomy without requiring
seed sets or domain expertise. We apply this framework to a large corpus of
Meta (previously known as Facebook) political ads from the month ahead of the
2024 U.S. Presidential election. Our approach uncovers latent discourse
structures, synthesizes semantically rich topic labels, and annotates topics
with moral framing dimensions. We show quantitative and qualitative analyses to
demonstrate the effectiveness of our framework. Our findings reveal that voting
and immigration ads dominate overall spending and impressions, while abortion
and election-integrity achieve disproportionate reach. Funding patterns are
equally polarized: economic appeals are driven mainly by conservative PACs,
abortion messaging splits between pro- and anti-rights coalitions, and
crime-and-justice campaigns are fragmented across local committees. The framing
of these appeals also diverges--abortion ads emphasize liberty/oppression
rhetoric, while economic messaging blends care/harm, fairness/cheating, and
liberty/oppression narratives. Topic salience further reveals strong
correlations between moral foundations and issues. Demographic targeting also
emerges. This work supports scalable, interpretable analysis of political
messaging on social media, enabling researchers, policymakers, and the public
to better understand emerging narratives, polarization dynamics, and the moral
underpinnings of digital political communication.

</details>


### [7] [FarsiMCQGen: a Persian Multiple-choice Question Generation Framework](https://arxiv.org/abs/2510.15134)
*Mohammad Heydari Rad,Rezvan Afari,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 本文提出了FarsiMCQGen方法，用于生成波斯语多项选择题，结合候选生成、过滤和排序技术，并利用Transformer和知识图谱来创建可信的干扰项。


<details>
  <summary>Details</summary>
Motivation: 在低资源语言如波斯语中生成高质量的多项选择题仍然是一个重大挑战，需要开发专门的生成方法。

Method: 结合候选生成、过滤和排序技术，利用Transformer和知识图谱与基于规则的方法集成，从维基百科数据中生成波斯语MCQ。

Result: 创建了一个包含10,289个问题的新型波斯语MCQ数据集，并通过最先进的大语言模型进行评估，证明了模型的有效性和数据集的质量。

Conclusion: FarsiMCQGen方法在波斯语MCQ生成方面表现出色，生成的数据集具有高质量，能够激发对MCQ的进一步研究。

Abstract: Multiple-choice questions (MCQs) are commonly used in educational testing, as
they offer an efficient means of evaluating learners' knowledge. However,
generating high-quality MCQs, particularly in low-resource languages such as
Persian, remains a significant challenge. This paper introduces FarsiMCQGen, an
innovative approach for generating Persian-language MCQs. Our methodology
combines candidate generation, filtering, and ranking techniques to build a
model that generates answer choices resembling those in real MCQs. We leverage
advanced methods, including Transformers and knowledge graphs, integrated with
rule-based approaches to craft credible distractors that challenge test-takers.
Our work is based on data from Wikipedia, which includes general knowledge
questions. Furthermore, this study introduces a novel Persian MCQ dataset
comprising 10,289 questions. This dataset is evaluated by different
state-of-the-art large language models (LLMs). Our results demonstrate the
effectiveness of our model and the quality of the generated dataset, which has
the potential to inspire further research on MCQs.

</details>


### [8] [Structure-R1: Dynamically Leveraging Structural Knowledge in LLM Reasoning through Reinforcement Learning](https://arxiv.org/abs/2510.15191)
*Junlin Wu,Xianrui Zhong,Jiashuo Sun,Bolian Li,Bowen Jin,Jiawei Han,Qingkai Zeng*

Main category: cs.CL

TL;DR: 提出Structure-R1框架，通过强化学习将检索内容转换为结构化表示，优化多步推理过程，在7B规模模型上实现与更大模型相媲美的性能


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统使用非结构化文本导致信息密度低、推理效果不佳，需要更高效的结构化知识表示来增强LLM的推理能力

Method: 使用强化学习动态生成任务特定的结构化表示，引入自奖励结构验证机制确保生成结构的正确性和自包含性

Result: 在7个知识密集型基准测试中，7B规模模型取得竞争性性能，与更大模型性能相当

Conclusion: 结构化表示通过提高信息密度和上下文清晰度显著增强推理能力，为高效知识增强推理提供了新方向

Abstract: Large language models (LLMs) have demonstrated remarkable advances in
reasoning capabilities. However, their performance remains constrained by
limited access to explicit and structured domain knowledge. Retrieval-Augmented
Generation (RAG) addresses this by incorporating external information as
context to augment reasoning. Nevertheless, traditional RAG systems typically
operate over unstructured and fragmented text, resulting in low information
density and suboptimal reasoning. To overcome these limitations, we propose
\textsc{Structure-R1}, a novel framework that transforms retrieved content into
structured representations optimized for reasoning. Leveraging reinforcement
learning, \textsc{Structure-R1} learns a content representation policy that
dynamically generates and adapts structural formats based on the demands of
multi-step reasoning. Unlike prior methods that rely on fixed schemas, our
approach adopts a generative paradigm capable of producing task-specific
structures tailored to individual queries. To ensure the quality and
reliability of these representations, we introduce a self-reward structural
verification mechanism that checks whether the generated structures are both
correct and self-contained. Extensive experiments on seven knowledge-intensive
benchmarks show that \textsc{Structure-R1} consistently achieves competitive
performance with a 7B-scale backbone model and matches the performance of much
larger models. Additionally, our theoretical analysis demonstrates how
structured representations enhance reasoning by improving information density
and contextual clarity. Our code and data are available at:
https://github.com/jlwu002/sr1.

</details>


### [9] [Extending Audio Context for Long-Form Understanding in Large Audio-Language Models](https://arxiv.org/abs/2510.15231)
*Yuatyong Chaichana,Pittawat Taveekitworachai,Warit Sirichotedumrong,Potsawee Manakul,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 提出了Partial YaRN和VLAT两种方法来解决大型音频语言模型的长音频上下文限制问题，前者是无训练的音频位置扩展方法，后者是训练时的位置增强策略。


<details>
  <summary>Details</summary>
Motivation: 大型音频语言模型受限于短音频上下文窗口，即使其文本主干支持长上下文，这限制了长音频理解能力。

Method: Partial YaRN：基于RoPE的无训练音频扩展方法，只修改音频token位置；VLAT：训练时位置增强策略，模拟不同音频长度进行训练。

Result: 在SALMONN和Qwen2-Audio上的实验表明，Partial YaRN在多种设置下优于原始模型，VLAT训练策略显著提升性能，在未见长度的长音频上表现强劲。

Conclusion: Partial YaRN和VLAT方法有效解决了LALMs的长音频上下文限制问题，实现了对训练时未见长度的长音频的强泛化能力。

Abstract: Large Audio-Language Models (LALMs) are often constrained by short audio
context windows, even when their text backbones support long contexts, limiting
long-form audio understanding. Prior work has introduced context-extension
methods (e.g. YaRN) on unimodal LLMs, yet their application to LALMs remains
unexplored. First, building on RoPE-based context extension, we introduce
Partial YaRN, a training-free, audio-only extension method that modifies only
audio token positions, leaving text positions intact to preserve the base LLM's
text capabilities. Second, we propose Virtual Longform Audio Training (VLAT), a
training strategy that extends Partial YaRN into a training-time positional
augmentation. VLAT simulates diverse audio lengths during training, enabling
generalization to inputs far longer than those seen in training and improving
robustness for long-context audio understanding. Our experiments on SALMONN and
Qwen2-Audio show that Partial YaRN outperforms the original models across wide
range of settings, and VLAT training strategy provides substantial improvement,
achieving strong performance on long audio of unseen lengths.

</details>


### [10] [Planner and Executor: Collaboration between Discrete Diffusion And Autoregressive Models in Reasoning](https://arxiv.org/abs/2510.15244)
*Lina Berrayana,Ahmed Heakl,Muhammad Abdullah Sohail,Thomas Hofmann,Salman Khan,Wei Chen*

Main category: cs.CL

TL;DR: 本文研究了离散扩散语言模型（DDLM）与自回归语言模型（ARM）的混合架构，通过在文本空间和潜在空间的协作，实现了准确率提升和计算效率优化。


<details>
  <summary>Details</summary>
Motivation: 当前自回归语言模型虽然准确率高但需要长序列生成，成本高昂。离散扩散语言模型具有并行生成和固定步数的优势，在复杂推理任务中表现优异。研究旨在探索两种模型协作是否能获得互补效益。

Method: 首先在文本空间探索协作，一个模型规划推理过程，另一个基于规划执行最终答案。然后扩展到潜在空间通信，引入学习投影器将DDLM潜在表示映射到ARM嵌入空间，绕过扩散模型的文本生成限制。

Result: 从文本空间转向潜在空间的DDLM→ARM通信带来显著准确率提升：DART-5从27.0%提高到54.0%，AIME24从0.0%提高到14.0%。DDLM规划器与ARM执行器组合在几乎不影响准确率的情况下提供大量计算节省。

Conclusion: 混合架构研究为DDLM推理提供了新见解，突显了其在混合架构中的潜力，特别是在潜在空间通信能显著提升性能并优化计算效率。

Abstract: Current autoregressive language models (ARMs) achieve high accuracy but
require long token sequences, making them costly. Discrete diffusion language
models (DDLMs) enable parallel and flexible generation within a fixed number of
steps and have recently emerged for their strong performance in complex
reasoning and long-term planning tasks. We present a study exploring hybrid
architectures that couple DDLMs with ARMs to assess whether their collaboration
can yield complementary benefits. We first examine collaboration in text space,
where one model plans the reasoning process and another executes the final
answer based on that plan. We then extend this setup to latent-space
communication, introducing a learned projector that maps DDLM latents into the
ARM's embedding space, potentially bypassing some of the text-generation
limitations of diffusion models. We find that shifting DDLM --> ARM
communication from text space to latent space yields significant accuracy
gains, for example increasing from 27.0% to 54.0% on DART-5 and from 0.0% to
14.0% on AIME24. We also find that combining a DDLM planner with an ARM
executor can provide substantial computational savings with little to no impact
on accuracy. For example, the latent-space pipeline, using 64 tokens for
planning and roughly 5 for execution, surpasses Qwen3.1-7B on DART-5 and AIME,
despite Qwen using 44 times more tokens. Overall, our study offers new insights
into reasoning with DDLMs and highlights their potential in hybrid
architectures.

</details>


### [11] [Scaling Beyond Context: A Survey of Multimodal Retrieval-Augmented Generation for Document Understanding](https://arxiv.org/abs/2510.15253)
*Sensen Gao,Shanshan Zhao,Xu Jiang,Lunhao Duan,Yong Xien Chng,Qing-Guo Chen,Weihua Luo,Kaifu Zhang,Jia-Wang Bian,Mingming Gong*

Main category: cs.CL

TL;DR: 本文系统综述了多模态检索增强生成在文档理解中的应用，提出了基于领域、检索模态和粒度的分类法，总结了关键数据集、基准和应用，并指出了效率、细粒度表示和鲁棒性等开放挑战。


<details>
  <summary>Details</summary>
Motivation: 当前文档理解方法存在局限性：OCR+LLM流水线会丢失结构细节，而原生多模态LLM在上下文建模方面存在困难。多模态RAG能够实现跨所有模态的整体检索和推理，从而解锁全面的文档智能。

Method: 提出基于领域、检索模态和粒度的分类法，综述涉及图结构和代理框架的进展，总结关键数据集、基准和应用。

Result: 建立了多模态RAG的系统性框架，识别了当前研究进展和可用资源，为文档AI提供了发展路线图。

Conclusion: 多模态RAG是文档理解的重要范式，但仍面临效率、细粒度表示和鲁棒性等挑战，需要未来进一步研究解决。

Abstract: Document understanding is critical for applications from financial analysis
to scientific discovery. Current approaches, whether OCR-based pipelines
feeding Large Language Models (LLMs) or native Multimodal LLMs (MLLMs), face
key limitations: the former loses structural detail, while the latter struggles
with context modeling. Retrieval-Augmented Generation (RAG) helps ground models
in external data, but documents' multimodal nature, i.e., combining text,
tables, charts, and layout, demands a more advanced paradigm: Multimodal RAG.
This approach enables holistic retrieval and reasoning across all modalities,
unlocking comprehensive document intelligence. Recognizing its importance, this
paper presents a systematic survey of Multimodal RAG for document
understanding. We propose a taxonomy based on domain, retrieval modality, and
granularity, and review advances involving graph structures and agentic
frameworks. We also summarize key datasets, benchmarks, and applications, and
highlight open challenges in efficiency, fine-grained representation, and
robustness, providing a roadmap for future progress in document AI.

</details>


### [12] [TraceCoder: Towards Traceable ICD Coding via Multi-Source Knowledge Integration](https://arxiv.org/abs/2510.15267)
*Mucheng Ren,He Chen,Yuchen Yan,Danqing Hu,Jun Xu,Xian Zeng*

Main category: cs.CL

TL;DR: TraceCoder是一个集成多源外部知识的ICD编码框架，通过动态整合UMLS、维基百科和LLMs等知识源来增强代码表示、弥合语义鸿沟，并处理罕见和模糊代码，提高可追溯性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有ICD编码方法面临临床文本与ICD代码之间的语义鸿沟、罕见和长尾代码性能差以及可解释性有限等挑战。

Method: 提出TraceCoder框架，动态整合多源外部知识（UMLS、维基百科、LLMs），引入混合注意力机制建模标签、临床上下文和知识之间的交互。

Result: 在MIMIC-III-ICD9、MIMIC-IV-ICD9和MIMIC-IV-ICD10数据集上的实验表明，TraceCoder实现了最先进的性能，消融研究验证了其组件的有效性。

Conclusion: TraceCoder为自动化ICD编码提供了一个可扩展且稳健的解决方案，符合临床对准确性、可解释性和可靠性的需求。

Abstract: Automated International Classification of Diseases (ICD) coding assigns
standardized diagnosis and procedure codes to clinical records, playing a
critical role in healthcare systems. However, existing methods face challenges
such as semantic gaps between clinical text and ICD codes, poor performance on
rare and long-tail codes, and limited interpretability. To address these
issues, we propose TraceCoder, a novel framework integrating multi-source
external knowledge to enhance traceability and explainability in ICD coding.
TraceCoder dynamically incorporates diverse knowledge sources, including UMLS,
Wikipedia, and large language models (LLMs), to enrich code representations,
bridge semantic gaps, and handle rare and ambiguous codes. It also introduces a
hybrid attention mechanism to model interactions among labels, clinical
context, and knowledge, improving long-tail code recognition and making
predictions interpretable by grounding them in external evidence. Experiments
on MIMIC-III-ICD9, MIMIC-IV-ICD9, and MIMIC-IV-ICD10 datasets demonstrate that
TraceCoder achieves state-of-the-art performance, with ablation studies
validating the effectiveness of its components. TraceCoder offers a scalable
and robust solution for automated ICD coding, aligning with clinical needs for
accuracy, interpretability, and reliability.

</details>


### [13] [TACL: Threshold-Adaptive Curriculum Learning Strategy for Enhancing Medical Text Understanding](https://arxiv.org/abs/2510.15269)
*Mucheng Ren,Yucheng Yan,He Chen,Danqing Hu,Jun Xu,Xian Zeng*

Main category: cs.CL

TL;DR: TACL（阈值自适应课程学习）是一个针对医学文本理解的新型框架，通过动态调整训练过程，根据样本复杂度进行难度分级，优先训练简单样本以建立坚实基础，再处理复杂记录，从而提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 医学文本（特别是电子病历）具有非结构化、领域特定语言和上下文变异性等特点，现有方法将所有数据视为同等难度，忽略了临床记录中复杂度的内在差异，限制了模型在罕见或复杂病例上的泛化能力。

Method: TACL框架基于渐进学习原则，将数据按难度分类，在训练早期优先处理简单样本，逐步过渡到复杂样本，动态调整训练过程以适应样本复杂度。

Result: 在英语和中文临床记录等多语言医学数据上应用TACL，在自动ICD编码、再入院预测和中医证候鉴别等多种临床任务中均观察到显著性能提升。

Conclusion: TACL不仅提升了自动化系统的性能，还展示了统一不同医学领域方法的潜力，为更准确、可扩展和全球适用的医学文本理解解决方案铺平了道路。

Abstract: Medical texts, particularly electronic medical records (EMRs), are a
cornerstone of modern healthcare, capturing critical information about patient
care, diagnoses, and treatments. These texts hold immense potential for
advancing clinical decision-making and healthcare analytics. However, their
unstructured nature, domain-specific language, and variability across contexts
make automated understanding an intricate challenge. Despite the advancements
in natural language processing, existing methods often treat all data as
equally challenging, ignoring the inherent differences in complexity across
clinical records. This oversight limits the ability of models to effectively
generalize and perform well on rare or complex cases. In this paper, we present
TACL (Threshold-Adaptive Curriculum Learning), a novel framework designed to
address these challenges by rethinking how models interact with medical texts
during training. Inspired by the principle of progressive learning, TACL
dynamically adjusts the training process based on the complexity of individual
samples. By categorizing data into difficulty levels and prioritizing simpler
cases early in training, the model builds a strong foundation before tackling
more complex records. By applying TACL to multilingual medical data, including
English and Chinese clinical records, we observe significant improvements
across diverse clinical tasks, including automatic ICD coding, readmission
prediction and TCM syndrome differentiation. TACL not only enhances the
performance of automated systems but also demonstrates the potential to unify
approaches across disparate medical domains, paving the way for more accurate,
scalable, and globally applicable medical text understanding solutions.

</details>


### [14] [Exemplar-Guided Planing: Enhanced LLM Agent for KGQA](https://arxiv.org/abs/2510.15283)
*Jingao Xu,Shuoyoucheng Ma,Xin Song,Rong Jiang,Hongkui Tu,Bin Zhou*

Main category: cs.CL

TL;DR: 提出了EGP框架，通过检索相似示例问题及其成功推理路径来指导LLM在知识图谱问答中的规划过程，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在知识图谱问答中面临的语义鸿沟问题，以及训练无关方法未能充分利用训练数据中有价值推理模式的问题。

Method: EGP框架：1) 通过实体模板化预处理训练集问题；2) 使用语义嵌入和FAISS索引检索相似示例；3) 在任务分解和关系探索两个阶段动态指导LLM规划；4) 引入智能前瞻机制提高效率。

Result: 在WebQSP和CWQ两个真实世界KGQA数据集上的实验表明，PoG-EGP显著优于基线PoG系统和其他对比方法。

Conclusion: EGP框架通过示例引导规划有效提升了LLM在知识图谱问答中的规划能力，证明了利用训练数据中成功推理模式的重要性。

Abstract: Large Language Models (LLMs) as interactive agents show significant promise
in Knowledge Graph Question Answering (KGQA) but often struggle with the
semantic gap between natural language queries and structured knowledge graph
(KG) representations. This leads to suboptimal planning and inefficient
exploration on KG, while training-free approaches often underutilize valuable
reasoning patterns in training data. To address these limitations, we propose a
novel framework, Exemplar-Guided Planning (EGP), which enhances the planning
capabilities of LLM agents for KGQA. EGP first preprocesses the training set
questions via entity templating to normalize semantic variations. It then
retrieves highly similar exemplary questions and their successful reasoning
paths from this preprocessed set using semantic embeddings and an efficient
FAISS index. These retrieved exemplars dynamically guide the LLM's planning
process in two key phases: (1) Task Decomposition, by aligning generated
sub-objectives with proven reasoning steps, and (2) Relation Exploration, by
providing high-quality auxiliary information to improve relation pruning
accuracy. Additionally, we introduce a Smart Lookahead mechanism during
relation exploration to improve efficiency by preemptively exploring promising
paths and potentially terminating exploration earlier. We apply EGP to the
Plan-on-Graph (PoG) framework, termed PoG-EGP. Extensive experiments on two
real-world KGQA datasets, WebQSP and CWQ, demonstrate that PoG-EGP
significantly improves over the baseline PoG system and other compared methods.

</details>


### [15] [Automatic essay scoring: leveraging Jaccard coefficient and Cosine similaritywith n-gram variation in vector space model approach](https://arxiv.org/abs/2510.15311)
*Andharini Dwi Cahyani,Moh. Wildan Fathoni,Fika Hastarita Rachman,Ari Basuki,Salman Amin,Bain Khusnul Khotimah*

Main category: cs.CL

TL;DR: 该研究比较了Jaccard系数和余弦相似度在向量空间模型中的表现，使用单字、双字和三字模型进行自动作文评分。结果显示余弦相似度优于Jaccard系数，单字模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 自动作文评分(AES)旨在提供高效准确的写作评估工具，研究两种流行相似度度量方法在向量空间模型中的有效性。

Method: 使用初中公民教育课程的形成性作文数据，通过n-gram模型提取特征并向量化，然后计算Jaccard系数和余弦相似度，通过均方根误差(RMSE)评估系统性能。

Result: 余弦相似度表现优于Jaccard系数，在n-gram模型中，单字模型的RMSE低于双字和三字模型。

Conclusion: 在自动作文评分中，余弦相似度配合单字模型能提供更准确的评分结果。

Abstract: Automated essay scoring (AES) is a vital area of research aiming to provide
efficient and accurate assessment tools for evaluating written content. This
study investigates the effectiveness of two popular similarity metrics, Jaccard
coefficient, and Cosine similarity, within the context of vector space
models(VSM)employing unigram, bigram, and trigram representations. The data
used in this research was obtained from the formative essay of the citizenship
education subject in a junior high school. Each essay undergoes preprocessing
to extract features using n-gram models, followed by vectorization to transform
text data into numerical representations. Then, similarity scores are computed
between essays using both Jaccard coefficient and Cosine similarity. The
performance of the system is evaluated by analyzing the root mean square error
(RMSE), which measures the difference between the scores given by human graders
and those generated by the system. The result shows that the Cosine similarity
outperformed the Jaccard coefficient. In terms of n-gram, unigrams have lower
RMSE compared to bigrams and trigrams.

</details>


### [16] [Accelerating Mobile Language Model Generation via Hybrid Context and Hardware Coordination](https://arxiv.org/abs/2510.15312)
*Zhiyang Chen,Daliang Xu,Haiyang Shen,Mengwei Xu,Shangguang Wang,Yun Ma*

Main category: cs.CL

TL;DR: CoordGen是一个移动推理框架，通过结合推测解码和动态硬件调度来加速移动设备上的上下文感知文本生成，实现了最高3.8倍的生成速度提升和4.7倍的能效提升。


<details>
  <summary>Details</summary>
Motivation: 移动设备上的大语言模型虽然可以通过本地数据进行个性化生成，但由于token-by-token生成过程的内存限制特性，仍然存在高延迟和硬件利用率低的问题。

Method: CoordGen包含三个协同组件：自适应执行调度（动态平衡预填充和解码阶段的计算图）、上下文对齐草稿（通过轻量级在线校准提高推测效率）、硬件高效草稿扩展（重用和扩展中间序列以提高并行性和降低验证成本）。

Result: 在多个智能手机和代表性工作负载上的实验显示，与现有移动推理解决方案相比，生成速度最高提升3.8倍，能效最高提升4.7倍。

Conclusion: CoordGen通过推测解码与动态硬件调度的集成，有效解决了移动设备上LLM推理的延迟和能效问题，组件级分析进一步验证了每个优化的贡献。

Abstract: Enhancing on-device large language models (LLMs) with contextual information
from local data enables personalized and task-aware generation, powering use
cases such as intelligent assistants and UI agents. While recent developments
in neural processors have substantially improved the efficiency of prefill on
mobile devices, the token-by-token generation process still suffers from high
latency and limited hardware utilization due to its inherently memory-bound
characteristics. This work presents CoordGen, a mobile inference framework that
integrates speculative decoding with dynamic hardware scheduling to accelerate
context-aware text generation on mobile devices. The framework introduces three
synergistic components: (1) adaptive execution scheduling, which dynamically
balances compute graphs between prefill and decoding phases; (2)
context-aligned drafting, which improves speculative efficiency through
lightweight online calibration to current tasks; and (3) hardware-efficient
draft extension, which reuses and expands intermediate sequences to improve
processing parallelism and reduce verification cost. Experiments on multiple
smartphones and representative workloads show consistent improvements of up to
3.8x in generation speed and 4.7x in energy efficiency compared with existing
mobile inference solutions. Component-level analysis further validates the
contribution of each optimization.

</details>


### [17] [Capabilities and Evaluation Biases of Large Language Models in Classical Chinese Poetry Generation: A Case Study on Tang Poetry](https://arxiv.org/abs/2510.15313)
*Bolei Ma,Yina Yao,Anna-Carolina Haensch*

Main category: cs.CL

TL;DR: 提出三步骤评估框架，结合计算指标、LLM作为评判者和人类专家验证，评估六大先进LLM在古典中文诗歌生成与评估中的表现，发现存在系统性偏见和"回音室"效应。


<details>
  <summary>Details</summary>
Motivation: 理解LLM在古典中文诗歌生成和评估中的表现，当前这方面的研究还不够深入。

Method: 采用三步骤评估框架：计算指标、LLM作为评判者评估、人类专家验证，评估六大先进LLM在诗歌质量多个维度的表现。

Result: 发现LLM存在系统性生成和评估偏见，表现出"回音室"效应，评估标准与人类判断存在分歧。

Conclusion: 当前LLM作为文学生成代理的能力既有潜力也有局限，在文化和技术上复杂的创意任务中仍需人类和模型的混合验证。

Abstract: Large Language Models (LLMs) are increasingly applied to creative domains,
yet their performance in classical Chinese poetry generation and evaluation
remains poorly understood. We propose a three-step evaluation framework that
combines computational metrics, LLM-as-a-judge assessment, and human expert
validation. Using this framework, we evaluate six state-of-the-art LLMs across
multiple dimensions of poetic quality, including themes, emotions, imagery,
form, and style. Our analysis reveals systematic generation and evaluation
biases: LLMs exhibit "echo chamber" effects when assessing creative quality,
often converging on flawed standards that diverge from human judgments. These
findings highlight both the potential and limitations of current capabilities
of LLMs as proxy for literacy generation and the limited evaluation practices,
thereby demonstrating the continued need of hybrid validation from both humans
and models in culturally and technically complex creative tasks.

</details>


### [18] [AutoGraph-R1: End-to-End Reinforcement Learning for Knowledge Graph Construction](https://arxiv.org/abs/2510.15339)
*Hong Ting Tsang,Jiaxin Bai,Haoyu Huang,Qiao Xiao,Tianshi Zheng,Baixuan Xu,Shujie Liu,Yangqiu Song*

Main category: cs.CL

TL;DR: AutoGraph-R1是首个使用强化学习直接优化知识图谱构建以提升任务性能的框架，通过将图生成建模为策略学习问题，基于RAG管道中的功能效用设计奖励函数，显著提升了图RAG方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱构建过程与下游应用脱节，导致图结构次优。需要弥合构建与应用之间的差距，从构建固有"好"的图谱转向构建可证明"有用"的图谱。

Method: 使用强化学习训练LLM构造器，将图生成作为策略学习问题，设计了两种新颖的任务感知奖励函数：一种用于图作为知识载体，另一种用于图作为知识索引。

Result: 在多个QA基准测试中，AutoGraph-R1始终使图RAG方法相比使用任务无关基线图谱获得显著性能提升。

Conclusion: 研究表明可以在构建和应用之间形成闭环，将范式从构建固有"好"的图谱转向构建可证明"有用"的图谱。

Abstract: Building effective knowledge graphs (KGs) for Retrieval-Augmented Generation
(RAG) is pivotal for advancing question answering (QA) systems. However, its
effectiveness is hindered by a fundamental disconnect: the knowledge graph (KG)
construction process is decoupled from its downstream application, yielding
suboptimal graph structures. To bridge this gap, we introduce AutoGraph-R1, the
first framework to directly optimize KG construction for task performance using
Reinforcement Learning (RL). AutoGraph-R1 trains an LLM constructor by framing
graph generation as a policy learning problem, where the reward is derived from
the graph's functional utility in a RAG pipeline. We design two novel,
task-aware reward functions, one for graphs as knowledge carriers and another
as knowledge indices. Across multiple QA benchmarks, AutoGraph-R1 consistently
enables graph RAG methods to achieve significant performance gains over using
task-agnostic baseline graphs. Our work shows it is possible to close the loop
between construction and application, shifting the paradigm from building
intrinsically ``good'' graphs to building demonstrably ``useful'' ones.

</details>


### [19] [Readability Reconsidered: A Cross-Dataset Analysis of Reference-Free Metrics](https://arxiv.org/abs/2510.15345)
*Catarina G Belem,Parker Glenn,Alfy Samuel,Anoop Kumar,Daben Liu*

Main category: cs.CL

TL;DR: 研究发现传统可读性评估指标与人类感知存在差异，基于模型的方法在评估文本可读性方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 自动可读性评估领域存在定义不一致和依赖表面文本特征的问题，需要探索更符合人类感知的评估方法。

Method: 分析了897个人类可读性判断，评估了15个传统可读性指标和6个基于模型的指标在5个英文数据集上的表现。

Result: 4个基于模型的指标在与人判断的相关性排名中始终位列前四，而表现最好的传统指标平均排名仅为8.6。

Conclusion: 基于模型的方法比传统指标更能反映人类对可读性的感知，是更有前景的研究方向。

Abstract: Automatic readability assessment plays a key role in ensuring effective and
accessible written communication. Despite significant progress, the field is
hindered by inconsistent definitions of readability and measurements that rely
on surface-level text properties. In this work, we investigate the factors
shaping human perceptions of readability through the analysis of 897 judgments,
finding that, beyond surface-level cues, information content and topic strongly
shape text comprehensibility. Furthermore, we evaluate 15 popular readability
metrics across five English datasets, contrasting them with six more nuanced,
model-based metrics. Our results show that four model-based metrics
consistently place among the top four in rank correlations with human
judgments, while the best performing traditional metric achieves an average
rank of 8.6. These findings highlight a mismatch between current readability
metrics and human perceptions, pointing to model-based approaches as a more
promising direction.

</details>


### [20] [When to Ensemble: Identifying Token-Level Points for Stable and Fast LLM Ensembling](https://arxiv.org/abs/2510.15346)
*Heecheol Yun,Kwangmin Ki,Junghyun Lee,Eunho Yang*

Main category: cs.CL

TL;DR: SAFE是一个选择性集成LLM的框架，通过考虑分词不匹配和概率分布一致性来确定集成位置，在长文本生成中优于现有方法，即使集成不到1%的token也能提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM集成方法在短文本生成中有效，但在长文本生成中应用不足，且在每个token位置集成往往会降低性能，需要更智能的集成策略。

Method: 提出SAFE框架，选择性集成LLM，考虑分词不匹配和概率分布一致性两个关键因素，并引入概率锐化策略来合并表示同一单词的多个子词token的概率。

Result: 在MATH500和BBH等多样化基准测试中，SAFE在准确性和效率上都优于现有方法，即使集成少于1%的token也能获得性能提升。

Conclusion: SAFE通过智能选择集成位置和概率锐化策略，为长文本生成中的LLM集成提供了稳定高效的解决方案。

Abstract: Ensembling Large Language Models (LLMs) has gained attention as a promising
approach to surpass the performance of individual models by leveraging their
complementary strengths. In particular, aggregating models' next-token
probability distributions to select the next token has been shown to be
effective in various tasks. However, while successful for short-form answers,
its application to long-form generation remains underexplored. In this paper,
we show that using existing ensemble methods in long-form generation requires a
careful choice of ensembling positions, since the standard practice of
ensembling at every token often degrades performance. We identify two key
factors for determining these positions: tokenization mismatch across models
and consensus in their next-token probability distributions. Based on this, we
propose SAFE, (Stable And Fast LLM Ensembling), a framework that selectively
ensembles by jointly considering these factors. To further improve stability,
we introduce a probability sharpening strategy that consolidates probabilities
spread across multiple sub-word tokens representing the same word into a single
representative token. Our experiments on diverse benchmarks, including MATH500
and BBH, demonstrate that SAFE outperforms existing methods in both accuracy
and efficiency, with gains achieved even when ensembling fewer than 1% of
tokens.

</details>


### [21] [Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing](https://arxiv.org/abs/2510.15349)
*Baode Wang,Biao Wu,Weizhen Li,Meng Fang,Zuming Huang,Jun Huang,Haozhe Wang,Yanjie Liang,Ling Chen,Wei Chu,Yuan Qi*

Main category: cs.CL

TL;DR: 提出LayoutRL强化学习框架和Infinity-Parser模型，在文档解析任务中实现最先进性能


<details>
  <summary>Details</summary>
Motivation: 现有监督微调方法在多样化文档类型上泛化能力差，特别是在分布外数据上表现不佳，且高质量布局感知解析训练数据有限

Method: 使用强化学习框架LayoutRL，通过整合归一化编辑距离、段落计数准确性和阅读顺序保持的复合奖励来优化布局理解，并构建Infinity-Doc-400K数据集训练Infinity-Parser模型

Result: 在OmniDocBench、olmOCR-Bench、PubTabNet和FinTabNet等基准测试中，Infinity-Parser在各种文档类型、语言和结构复杂性上均取得最先进性能，显著优于专用文档解析系统和通用视觉语言模型

Conclusion: LayoutRL框架和Infinity-Parser模型能够有效解决文档解析中的泛化问题，在多样化文档类型上表现出色，将开源代码、数据集和模型以促进可重复研究

Abstract: Document parsing from scanned images into structured formats remains a
significant challenge due to its complexly intertwined elements such as text
paragraphs, figures, formulas, and tables. Existing supervised fine-tuning
methods often struggle to generalize across diverse document types, leading to
poor performance, particularly on out-of-distribution data. This issue is
further exacerbated by the limited availability of high-quality training data
for layout-aware parsing tasks. To address these challenges, we introduce
LayoutRL, a reinforcement learning framework that optimizes layout
understanding through composite rewards integrating normalized edit distance,
paragraph count accuracy, and reading order preservation. To support this
training, we construct the Infinity-Doc-400K dataset, which we use to train
Infinity-Parser, a vision-language model demonstrating robust generalization
across various domains. Extensive evaluations on benchmarks including
OmniDocBench, olmOCR-Bench, PubTabNet, and FinTabNet show that Infinity-Parser
consistently achieves state-of-the-art performance across a broad range of
document types, languages, and structural complexities, substantially
outperforming both specialized document parsing systems and general-purpose
vision-language models. We will release our code, dataset, and model to
facilitate reproducible research in document parsing.

</details>


### [22] [VocalBench-DF: A Benchmark for Evaluating Speech LLM Robustness to Disfluency](https://arxiv.org/abs/2510.15406)
*Hongcheng Liu,Yixuan Hou,Heyang Liu,Yuhao Wang,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: Speech-LLMs在语音不流畅（特别是帕金森病相关症状）场景下表现显著下降，现有评估方法过于理想化，需要新的方法来提高包容性。


<details>
  <summary>Details</summary>
Motivation: 现有Speech-LLMs的鲁棒性严重不足，特别是在处理语音不流畅问题时，缺乏对真实世界用户（如帕金森病患者）的系统性评估。

Method: 引入VocalBench-DF框架，基于多维度分类法对22个主流Speech-LLMs进行系统性评估，分析性能下降的根本原因。

Result: 评估显示Speech-LLMs在语音不流畅场景下性能显著下降，识别出音素级处理和长上下文建模是主要瓶颈，通过组件和流程优化可显著提升鲁棒性。

Conclusion: Speech-LLMs在真实世界应用中准备不足，迫切需要新方法来改善语音不流畅处理能力，构建真正包容的语音大语言模型。

Abstract: While Speech Large Language Models (Speech-LLMs) show strong performance in
many applications, their robustness is critically under-tested, especially to
speech disfluency. Existing evaluations often rely on idealized inputs,
overlooking common disfluencies, particularly those associated with conditions
like Parkinson's disease. This work investigates whether current Speech-LLMs
can maintain performance when interacting with users who have speech
impairments. To facilitate this inquiry, we introduce VocalBench-DF, a
framework for the systematic evaluation of disfluency across a
multi-dimensional taxonomy. Our evaluation of 22 mainstream Speech-LLMs reveals
substantial performance degradation, indicating that their real-world readiness
is limited. Further analysis identifies phoneme-level processing and
long-context modeling as primary bottlenecks responsible for these failures.
Strengthening recognition and reasoning capability from components and
pipelines can substantially improve robustness. These findings highlight the
urgent need for new methods to improve disfluency handling and build truly
inclusive Speech-LLMs

</details>


### [23] [Large-scale User Game Lifecycle Representation Learning](https://arxiv.org/abs/2510.15412)
*Yanjie Gou,Jiangming Liu,Kouying Xue,Yi Hua*

Main category: cs.CL

TL;DR: 提出User Game Lifecycle (UGL)方法解决游戏推荐中的稀疏性和不平衡问题，通过丰富用户行为数据和逆概率掩码策略，显著提升了游戏广告和游戏内物品推荐的性能。


<details>
  <summary>Details</summary>
Motivation: 在线游戏平台需要有效的广告和推荐系统，但现有推荐方法不适合游戏场景，主要面临游戏稀疏性（游戏数量少）和游戏不平衡（用户行为集中在少数热门游戏）两大挑战。

Method: 引入用户游戏生命周期(UGL)来丰富用户行为数据；提出两种创新策略来提取用户的短期和长期兴趣；使用逆概率掩码策略进行UGL表示学习以解决游戏不平衡问题。

Result: 离线实验平均AUC提升1.83%，在线实验游戏广告CVR平均提升21.67%；游戏内物品推荐离线AUC提升0.5%，在线ARPU提升0.82%。

Conclusion: UGL表示学习方法能有效解决游戏推荐中的稀疏性和不平衡问题，显著提升游戏广告和游戏内物品推荐的性能。

Abstract: The rapid expansion of video game production necessitates the development of
effective advertising and recommendation systems for online game platforms.
Recommending and advertising games to users hinges on capturing their interest
in games. However, existing representation learning methods crafted for
handling billions of items in recommendation systems are unsuitable for game
advertising and recommendation. This is primarily due to game sparsity, where
the mere hundreds of games fall short for large-scale user representation
learning, and game imbalance, where user behaviors are overwhelmingly dominated
by a handful of popular games. To address the sparsity issue, we introduce the
User Game Lifecycle (UGL), designed to enrich user behaviors in games.
Additionally, we propose two innovative strategies aimed at manipulating user
behaviors to more effectively extract both short and long-term interests. To
tackle the game imbalance challenge, we present an Inverse Probability Masking
strategy for UGL representation learning. The offline and online experimental
results demonstrate that the UGL representations significantly enhance model by
achieving a 1.83% AUC offline increase on average and a 21.67% CVR online
increase on average for game advertising and a 0.5% AUC offline increase and a
0.82% ARPU online increase for in-game item recommendation.

</details>


### [24] [Fine-Tuning MedGemma for Clinical Captioning to Enhance Multimodal RAG over Malaysia CPGs](https://arxiv.org/abs/2510.15418)
*Lee Qi Zun,Mohamad Zulhilmi Bin Abdul Halim,Goh Man Fye*

Main category: cs.CL

TL;DR: 该研究提出了一个专门化MedGemma模型的框架，用于生成高质量医学图像描述作为检索增强生成系统的查询，通过知识蒸馏和QLoRA微调方法显著提升了分类性能和描述准确性。


<details>
  <summary>Details</summary>
Motivation: 解决检索增强生成系统在处理医学图像查询时的局限性，因为通用视觉语言模型的描述缺乏临床特异性和事实基础。

Method: 采用知识蒸馏管道创建合成数据集，涵盖皮肤科、眼底和胸部放射学领域，并使用参数高效的QLoRA方法对MedGemma模型进行微调。

Result: 微调后的模型在分类性能上有显著提升，RAGAS评估证实了描述忠实度、相关性和正确性的显著改善。

Conclusion: 这项工作为专门化医学视觉语言模型建立了稳健的流程，并验证了所生成模型作为高质量查询生成器的能力，为增强多模态RAG系统在循证临床决策支持中的应用奠定了基础。

Abstract: Retrieval-Augmented Generation systems are essential for providing fact-based
guidance from Malaysian Clinical Practice Guidelines. However, their
effectiveness with image-based queries is limited, as general Vision-Language
Model captions often lack clinical specificity and factual grounding. This
study proposes and validates a framework to specialize the MedGemma model for
generating high-fidelity captions that serve as superior queries. To overcome
data scarcity, we employ a knowledge distillation pipeline to create a
synthetic dataset across dermatology, fundus, and chest radiography domains,
and fine-tune MedGemma using the parameter-efficient QLoRA method. Performance
was rigorously assessed through a dual framework measuring both classification
accuracy and, via a novel application of the RAGAS framework, caption
faithfulness, relevancy, and correctness. The fine-tuned model demonstrated
substantial improvements in classification performance, while RAGAS evaluation
confirmed significant gains in caption faithfulness and correctness, validating
the models ability to produce reliable, factually grounded descriptions. This
work establishes a robust pipeline for specializing medical VLMs and validates
the resulting model as a high-quality query generator, laying the groundwork
for enhancing multimodal RAG systems in evidence-based clinical decision
support.

</details>


### [25] [When Seeing Is not Enough: Revealing the Limits of Active Reasoning in MLLMs](https://arxiv.org/abs/2510.15421)
*Hongcheng Liu,Pingjie Wang,Yuhao Wang,Siqu Ou,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 提出了GuessBench基准来评估多模态大语言模型在信息不完整情况下的主动推理能力，发现现有模型在主动推理方面表现远逊于被动推理，并识别出细粒度感知和及时决策是主要挑战。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM评估主要关注被动推理，这与现实世界中需要主动获取缺失证据的场景不符，因此需要研究MLLM在信息不完整情况下的主动推理能力。

Method: 构建GuessBench基准，包含感知导向和知识导向图像，要求模型在没有任务特定先验的情况下从候选池中选择目标图像，通过主动获取缺失证据来迭代优化决策。

Result: 评估了20个优秀MLLM，发现主动推理性能远低于被动设置，细粒度感知和及时决策是主要瓶颈。消融研究表明感知增强对小模型有益，而思维导向方法对所有模型都有效。

Conclusion: 多模态主动推理仍有很大改进空间，细粒度感知和及时决策是未来研究的关键方向，思维导向方法为不同规模模型提供了一致的性能提升。

Abstract: Multimodal large language models (MLLMs) have shown strong capabilities
across a broad range of benchmarks. However, most existing evaluations focus on
passive inference, where models perform step-by-step reasoning under complete
information. This setup is misaligned with real-world use, where seeing is not
enough. This raises a fundamental question: Can MLLMs actively acquire missing
evidence under incomplete information? To bridge this gap, we require the MLLMs
to actively acquire missing evidence and iteratively refine decisions under
incomplete information, by selecting a target image from a candidate pool
without task-specific priors. To support systematic study, we propose
GuessBench, a benchmark with both perception-oriented and knowledge-oriented
images for evaluating active reasoning in MLLMs. We evaluate 20 superior MLLMs
and find that performance on active reasoning lags far behind it on passive
settings, indicating substantial room for improvement. Further analysis
identifies fine-grained perception and timely decision-making as key
challenges. Ablation studies show that perceptual enhancements benefit smaller
models, whereas thinking-oriented methods provide consistent gains across model
sizes. These results suggest promising directions for future research on
multimodal active reasoning.

</details>


### [26] [Controllable Abstraction in Summary Generation for Large Language Models via Prompt Engineering](https://arxiv.org/abs/2510.15436)
*Xiangchen Song,Yuchen Liu,Yaxuan Luan,Jinxu Guo,Xiaofan Guo*

Main category: cs.CL

TL;DR: 提出基于提示工程的可控摘要生成方法，通过多阶段提示生成框架实现不同抽象级别的摘要，实验表明提示长度、数据噪声和文本类型对摘要质量有显著影响。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在摘要质量和可控性方面的问题，提升大语言模型在摘要生成中的表现。

Method: 设计多阶段提示生成框架，包括语义分析、主题建模和噪声控制，使用CNN/Daily Mail数据集进行实验分析。

Result: 提示长度对摘要质量影响显著，过长或过短都会降低质量；数据噪声增加会导致ROUGE-L分数下降；模型在新闻文本上表现最佳，学术文章表现较差。

Conclusion: 通过控制提示策略和优化文本预处理可以有效提高大语言模型生成摘要的准确性和可控性。

Abstract: This study presents a controllable abstract summary generation method for
large language models based on prompt engineering. To address the issues of
summary quality and controllability in traditional methods, we design a
multi-stage prompt generation framework. This framework generates summaries
with varying levels of abstraction by performing semantic analysis, topic
modeling, and noise control on the input text. The experiment uses the
CNN/Daily Mail dataset and provides a detailed analysis of different prompt
lengths, data noise, and text types. The experimental results show that prompt
length has a significant impact on the quality of generated summaries. Both
very short and very long prompt tokens result in a decrease in summary quality.
Data noise also negatively affects the summary generation process. As noise
levels increase, the ROUGE-L score gradually decreases. Furthermore, different
text types have varying effects on the model's ability to generate summaries.
The model performs best when handling news texts, while its performance is
worse when processing academic articles. This research provides new insights
into improving summary generation using large language models, particularly in
how controlling prompt strategies and optimizing text preprocessing can enhance
summary accuracy and controllability.

</details>


### [27] [CORE: Reducing UI Exposure in Mobile Agents via Collaboration Between Cloud and Local LLMs](https://arxiv.org/abs/2510.15455)
*Gucongcong Fan,Chaoyue Niu,Chengfei Lyu,Fan Wu,Guihai Chen*

Main category: cs.CL

TL;DR: CORE是一个协作框架，结合云端和本地LLM的优势，在保持移动代理任务准确性的同时减少UI暴露。通过布局感知块分区、协同规划和协同决策，将UI暴露减少高达55.6%。


<details>
  <summary>Details</summary>
Motivation: 云端LLM需要上传完整UI状态，暴露不必要信息；本地LLM容量有限，任务成功率低。需要结合两者优势，在保护隐私的同时保持任务准确性。

Method: 1) 基于XML层次结构的布局感知块分区；2) 本地和云端LLM协同规划子任务；3) 本地LLM对相关UI块排序，云端LLM在排名靠前的块中选择具体元素；4) 多轮累积机制缓解本地误判。

Result: 实验显示，CORE将UI暴露减少高达55.6%，任务成功率略低于纯云端代理，有效减轻了不必要的云端隐私暴露。

Conclusion: CORE框架成功平衡了隐私保护和任务准确性，为移动代理提供了一种有效的协作解决方案。

Abstract: Mobile agents rely on Large Language Models (LLMs) to plan and execute tasks
on smartphone user interfaces (UIs). While cloud-based LLMs achieve high task
accuracy, they require uploading the full UI state at every step, exposing
unnecessary and often irrelevant information. In contrast, local LLMs avoid UI
uploads but suffer from limited capacity, resulting in lower task success
rates. We propose $\textbf{CORE}$, a $\textbf{CO}$llaborative framework that
combines the strengths of cloud and local LLMs to $\textbf{R}$educe UI
$\textbf{E}$xposure, while maintaining task accuracy for mobile agents. CORE
comprises three key components: (1) $\textbf{Layout-aware block partitioning}$,
which groups semantically related UI elements based on the XML screen
hierarchy; (2) $\textbf{Co-planning}$, where local and cloud LLMs
collaboratively identify the current sub-task; and (3)
$\textbf{Co-decision-making}$, where the local LLM ranks relevant UI blocks,
and the cloud LLM selects specific UI elements within the top-ranked block.
CORE further introduces a multi-round accumulation mechanism to mitigate local
misjudgment or limited context. Experiments across diverse mobile apps and
tasks show that CORE reduces UI exposure by up to 55.6% while maintaining task
success rates slightly below cloud-only agents, effectively mitigating
unnecessary privacy exposure to the cloud. The code is available at
https://github.com/Entropy-Fighter/CORE.

</details>


### [28] [DeceptionBench: A Comprehensive Benchmark for AI Deception Behaviors in Real-world Scenarios](https://arxiv.org/abs/2510.15501)
*Yao Huang,Yitong Sun,Yichi Zhang,Ruochen Zhang,Yinpeng Dong,Xingxing Wei*

Main category: cs.CL

TL;DR: DeceptionBench是第一个系统性评估大语言模型在不同社会领域中欺骗行为的基准，涵盖经济、医疗、教育、社交和娱乐五个领域，包含150个场景和1000多个样本，揭示了模型在激励和胁迫下欺骗行为的增强。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型能力的快速发展，出现了可能在高风险部署中引发严重风险的欺骗行为，但目前对现实世界场景中欺骗行为的系统性研究仍然不足。

Method: 构建DeceptionBench基准，包含五个社会领域的150个场景和1000多个样本，从内在维度评估模型的利己主义和奉承行为，从外在维度分析中性条件、奖励激励和胁迫压力对欺骗输出的影响，并引入持续多轮交互循环模拟真实反馈动态。

Result: 对LLM和LRM的广泛实验揭示了关键漏洞，特别是在强化动态下欺骗行为被放大，表明当前模型缺乏对操纵性上下文线索的鲁棒抵抗力。

Conclusion: 当前模型对各种欺骗行为缺乏足够的防护能力，迫切需要开发先进的保护机制来应对这些风险。

Abstract: Despite the remarkable advances of Large Language Models (LLMs) across
diverse cognitive tasks, the rapid enhancement of these capabilities also
introduces emergent deceptive behaviors that may induce severe risks in
high-stakes deployments. More critically, the characterization of deception
across realistic real-world scenarios remains underexplored. To bridge this
gap, we establish DeceptionBench, the first benchmark that systematically
evaluates how deceptive tendencies manifest across different societal domains,
what their intrinsic behavioral patterns are, and how extrinsic factors affect
them. Specifically, on the static count, the benchmark encompasses 150
meticulously designed scenarios in five domains, i.e., Economy, Healthcare,
Education, Social Interaction, and Entertainment, with over 1,000 samples,
providing sufficient empirical foundations for deception analysis. On the
intrinsic dimension, we explore whether models exhibit self-interested egoistic
tendencies or sycophantic behaviors that prioritize user appeasement. On the
extrinsic dimension, we investigate how contextual factors modulate deceptive
outputs under neutral conditions, reward-based incentivization, and coercive
pressures. Moreover, we incorporate sustained multi-turn interaction loops to
construct a more realistic simulation of real-world feedback dynamics.
Extensive experiments across LLMs and Large Reasoning Models (LRMs) reveal
critical vulnerabilities, particularly amplified deception under reinforcement
dynamics, demonstrating that current models lack robust resistance to
manipulative contextual cues and the urgent need for advanced safeguards
against various deception behaviors. Code and resources are publicly available
at https://github.com/Aries-iai/DeceptionBench.

</details>


### [29] [Temporal Referential Consistency: Do LLMs Favor Sequences Over Absolute Time References?](https://arxiv.org/abs/2510.15513)
*Ashutosh Bajpai,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文提出了一个名为TEMP-ReCon的新基准来评估LLMs的时间指称一致性，并开发了UnTRaP模型来增强LLMs在时间敏感查询中的时间推理能力。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在时间敏感领域（如法律、医疗、金融）中作为知识源的广泛应用，需要确保它们在时间维度上具有一致性和准确性，但目前缺乏对LLMs时间一致性的评估和改进工作。

Method: 提出了TEMP-ReCon基准来评估开源和闭源LLMs的时间指称一致性，并开发了基于推理路径对齐的UnTRaP模型来增强LLMs的时间一致性。

Result: 实验结果表明LLMs确实表现出不足的时间指称一致性，而UnTRaP模型相比多个基线模型在提升时间一致性方面表现出更好的效果。

Conclusion: 该研究填补了LLMs时间一致性评估和改进的空白，提出的基准和模型为提升LLMs在时间敏感应用中的可靠性提供了有效工具。

Abstract: The increasing acceptance of large language models (LLMs) as an alternative
to knowledge sources marks a significant paradigm shift across various domains,
including time-sensitive fields such as law, healthcare, and finance. To
fulfill this expanded role, LLMs must not only be factually accurate but also
demonstrate consistency across temporal dimensions, necessitating robust
temporal reasoning capabilities. Despite this critical requirement, efforts to
ensure temporal consistency in LLMs remain scarce including noticeable absence
of endeavors aimed at evaluating or augmenting LLMs across temporal references
in time-sensitive inquiries. In this paper, we seek to address this gap by
introducing a novel benchmark entitled temporal referential consistency,
accompanied by a resource TEMP-ReCon designed to benchmark a wide range of both
open-source and closed-source LLMs with various linguistic contexts
characterized by differing resource richness (including English, French, and
Romanian). The findings emphasis that LLMs do exhibit insufficient temporal
referent consistency. To address this, we propose \newmodel, a reasoning path
alignment-based model that aims to enhance the temporal referential consistency
of LLMs. Our empirical experiments substantiate the efficacy of UnTRaP compared
to several baseline models.

</details>


### [30] [From Characters to Tokens: Dynamic Grouping with Hierarchical BPE](https://arxiv.org/abs/2510.15517)
*Rares Dolga,Lucas Maystre,Tudor Berariu,David Barber*

Main category: cs.CL

TL;DR: 提出了一种动态字符分组方法，利用现有BPE分词结构，通过添加显式补丁结束标记和二级BPE压缩来控制补丁粒度，实现高效、灵活且语言无关的表示。


<details>
  <summary>Details</summary>
Motivation: 解决子词分词方法在表示罕见词时的低效性和需要大嵌入矩阵的问题，同时避免字符级模型的性能瓶颈，以及现有分层模型对空白字符或辅助模型的依赖。

Method: 在现有BPE分词基础上添加显式补丁结束标记，并引入二级BPE压缩阶段来控制补丁粒度，无需额外模型。

Result: 实证结果表明该方法匹配或优于基于动态熵和空白字符的补丁策略，同时保持紧凑的词汇表。

Conclusion: 该方法提供了一种高效、灵活且语言无关的表示方法，解决了现有分词方法的局限性。

Abstract: Subword tokenization methods like Byte Pair Encoding (BPE) are widely used in
large language models due to their balance of vocabulary compactness and
representational power. However, they suffer from inefficiencies in
representing rare words and require large embedding matrices. Character-level
models address these issues but introduce performance bottlenecks, particularly
in Transformer-based architectures. Recent hierarchical models attempt to merge
the benefits of both paradigms by grouping characters into patches, but
existing patching strategies either rely on whitespace-limiting applicability
to certain languages, or require auxiliary models that introduce new
dependencies. In this paper, we propose a dynamic character grouping method
that leverages the structure of existing BPE tokenization without requiring
additional models. By appending explicit end-of-patch markers to BPE tokens and
introducing a second-level BPE compression stage to control patch granularity,
our method offers efficient, flexible, and language-agnostic representations.
Empirical results demonstrate that our approach matches or exceeds the
performance of dynamic entropy- and whitespace-based patching strategies, while
maintaining a compact vocabulary.

</details>


### [31] [Latent Reasoning in LLMs as a Vocabulary-Space Superposition](https://arxiv.org/abs/2510.15522)
*Jingcheng Deng,Liang Pang,Zihao Wei,Shichen Xu,Zenghao Duan,Kun Xu,Yang Song,Huawei Shen,Xueqi Cheng*

Main category: cs.CL

TL;DR: Latent-SFT提出了一种两阶段学习框架，通过在词汇概率的列空间中进行潜在推理，实现了与显式推理相当的性能，同时显著减少了计算开销。


<details>
  <summary>Details</summary>
Motivation: 显式推理（如思维链）虽然效果好但计算成本高，而现有的潜在推理方法性能下降严重。研究发现这是因为非结构化的潜在空间难以拟合潜在标记。

Method: 提出Latent-SFT两阶段框架：第一阶段使用专门设计的注意力掩码指导潜在标记编码器生成潜在标记；第二阶段丢弃编码器，直接训练LLM自主生成潜在标记进行推理，使用KL和CE损失优化。

Result: 在GSM8k上达到新的SOTA，匹配显式SFT性能，同时将推理链缩短最多4倍，明显优于先前的潜在方法。在Math500和AIME24上，基于词汇概率的潜在推理也显著优于基于隐藏状态的方法。

Conclusion: 潜在推理既是单一路径的压缩，也是多路径的叠加，有效压缩率和有效全局并行度指标验证了这一点。

Abstract: Large language models (LLMs) demonstrate strong reasoning abilities with
chain-of-thought prompting, but explicit reasoning introduces substantial
computational overhead. Recent work on latent reasoning reduces this cost by
reasoning in latent space without explicit supervision, but performance drops
significantly. Our preliminary experiments suggest that this degradation stems
from the unstructured latent space, which makes fitting latent tokens
difficult. To address this, we restrict the latent space to the column space of
the LLM vocabulary, treating latent reasoning as a superposition over
vocabulary probabilities. Once latent reasoning concludes, it collapses into an
eigenstate of explicit reasoning to yield the final answer. Based on this idea,
we propose Latent-SFT, a two-stage learning framework. In the first stage, we
design two specialized attention masks to guide the Latent Token Encoder in
generating latent tokens, allowing the LLM to produce the correct answer
conditioned on them. In the second stage, the Latent Token Encoder is
discarded, and the LLM is directly trained to generate these latent tokens
autonomously for latent reasoning, optimized with KL and CE losses. Latent-SFT
sets a new state of the art on GSM8k, matching explicit SFT performance while
cutting reasoning chains by up to 4 times and outperforming prior latent
methods. On Math500 and AIME24, lexical probability-based latent reasoning also
clearly surpasses hidden-state-based approaches. Our metrics of effective
compression rate and effective global parallelism further show that latent
reasoning is both the compression of a single path and the superposition of
multiple paths.

</details>


### [32] [MCA: Modality Composition Awareness for Robust Composed Multimodal Retrieval](https://arxiv.org/abs/2510.15543)
*Qiyu Wu,Shuyang Cui,Satoshi Hayakawa,Wei-Yao Wang,Hiromi Wakaki,Yuki Mitsufuji*

Main category: cs.CL

TL;DR: 提出了一个模态组合感知框架来缓解统一编码器在多模态检索中的模态捷径问题，通过偏好损失和组合正则化目标来增强模型对分布偏移的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管统一编码器在多模态大语言模型中具有灵活性，但传统的对比学习容易导致模态捷径问题，在分布偏移下表现不佳。

Method: 使用偏好损失强制多模态嵌入优于单模态嵌入，并通过组合正则化目标将多模态嵌入与其单模态部分组成的原型对齐。

Result: 在多个基准测试中，该方法在分布外检索方面取得了提升。

Conclusion: 模态组合感知是使用MLLMs作为统一编码器时实现鲁棒组合多模态检索的有效原则。

Abstract: Multimodal retrieval, which seeks to retrieve relevant content across
modalities such as text or image, supports applications from AI search to
contents production. Despite the success of separate-encoder approaches like
CLIP align modality-specific embeddings with contrastive learning, recent
multimodal large language models (MLLMs) enable a unified encoder that directly
processes composed inputs. While flexible and advanced, we identify that
unified encoders trained with conventional contrastive learning are prone to
learn modality shortcut, leading to poor robustness under distribution shifts.
We propose a modality composition awareness framework to mitigate this issue.
Concretely, a preference loss enforces multimodal embeddings to outperform
their unimodal counterparts, while a composition regularization objective
aligns multimodal embeddings with prototypes composed from its unimodal parts.
These objectives explicitly model structural relationships between the composed
representation and its unimodal counterparts. Experiments on various benchmarks
show gains in out-of-distribution retrieval, highlighting modality composition
awareness as a effective principle for robust composed multimodal retrieval
when utilizing MLLMs as the unified encoder.

</details>


### [33] [TokenTiming: A Dynamic Alignment Method for Universal Speculative Decoding Model Pairs](https://arxiv.org/abs/2510.15545)
*Sibo Xiao,Jinyuan Fu,Zhongle Xie,Lidan Shou*

Main category: cs.CL

TL;DR: 提出了TokenTiming算法，通过动态时间规整技术解决推测解码中草稿模型与目标模型词汇表不匹配的问题，实现通用推测解码。


<details>
  <summary>Details</summary>
Motivation: 传统推测解码要求草稿模型和目标模型共享相同词汇表，限制了可用草稿模型的选择范围，往往需要从头训练新模型。

Method: 使用动态时间规整算法重新编码草稿标记序列，构建映射关系来传递概率分布，支持词汇表不匹配的模型协同工作。

Result: 在多种任务上实现了1.57倍的加速效果，无需重新训练或修改模型。

Conclusion: 该方法为草稿模型选择提供了通用方案，使推测解码成为更通用实用的大语言模型加速工具。

Abstract: Accelerating the inference of large language models (LLMs) has been a
critical challenge in generative AI. Speculative decoding (SD) substantially
improves LLM inference efficiency. However, its utility is limited by a
fundamental constraint: the draft and target models must share the same
vocabulary, thus limiting the herd of available draft models and often
necessitating the training of a new model from scratch. Inspired by Dynamic
Time Warping (DTW), a classic algorithm for aligning time series, we propose
the algorithm TokenTiming for universal speculative decoding. It operates by
re-encoding the draft token sequence to get a new target token sequence, and
then uses DTW to build a mapping to transfer the probability distributions for
speculative sampling. Benefiting from this, our method accommodates mismatched
vocabularies and works with any off-the-shelf models without retraining and
modification. We conduct comprehensive experiments on various tasks,
demonstrating 1.57x speedup. This work enables a universal approach for draft
model selection, making SD a more versatile and practical tool for LLM
acceleration.

</details>


### [34] [Rethinking Cross-lingual Gaps from a Statistical Viewpoint](https://arxiv.org/abs/2510.15551)
*Vihari Piratla,Purvam Jain,Darshan Singh,Partha Talukdar,Trevor Cohn*

Main category: cs.CL

TL;DR: 本文通过偏差-方差分解框架重新解释跨语言差距，提出目标语言响应方差是主要原因，并通过实验验证了降低方差能显著改善跨语言性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究将跨语言差距归因于源语言和目标语言潜在表征的差异，但本文提出目标语言响应方差才是主要因素，需要新的理论框架来理解这一现象。

Method: 采用偏差-方差分解形式化跨语言差距，通过多种推理时干预措施控制响应方差，包括简单的提示指令来减少方差。

Result: 实验证明控制方差能有效减少跨语言差距，使用简单的提示指令可将目标语言准确率提高20-25%。

Conclusion: 目标语言响应方差是跨语言差距的主要来源，通过降低方差可以显著改善跨语言知识获取性能。

Abstract: Any piece of knowledge is usually expressed in one or a handful of natural
languages on the web or in any large corpus. Large Language Models (LLMs) act
as a bridge by acquiring knowledge from a source language and making it
accessible when queried from target languages. Prior research has pointed to a
cross-lingual gap, viz., a drop in accuracy when the knowledge is queried in a
target language compared to when the query is in the source language. Existing
research has rationalized divergence in latent representations in source and
target languages as the source of cross-lingual gap. In this work, we take an
alternative view and hypothesize that the variance of responses in the target
language is the main cause of this gap. For the first time, we formalize the
cross-lingual gap in terms of bias-variance decomposition. We present extensive
experimental evidence which support proposed formulation and hypothesis. We
then reinforce our hypothesis through multiple inference-time interventions
that control the variance and reduce the cross-lingual gap. We demonstrate a
simple prompt instruction to reduce the response variance, which improved
target accuracy by 20-25% across different models.

</details>


### [35] [Think Parallax: Solving Multi-Hop Problems via Multi-View Knowledge-Graph-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2510.15552)
*Jinliang Liu*

Main category: cs.CL

TL;DR: 提出了ParallaxRAG框架，通过将查询和图三元组对称解耦到多视图空间，构建鲁棒的检索架构，显式增强头部多样性并约束弱相关路径，提升多跳推理性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在语言理解方面表现出色，但经常产生幻觉且在多跳推理方面存在困难。基于知识图谱的检索增强生成方法提供了基础，但大多数方法依赖扁平嵌入和噪声路径探索。

Method: ParallaxRAG框架对称地将查询和图三元组解耦到多视图空间，利用不同注意力头在不同推理阶段专门处理语义关系的特点，构建更清晰的子图并引导LLM进行基于基础的逐步推理。

Result: 在WebQSP和CWQ数据集上的实验表明，该方法在检索和问答性能方面具有竞争力，同时减少了幻觉并表现出良好的泛化能力。

Conclusion: 多视图头部专业化是知识基础多跳推理的一个原则性方向，为LLM的推理能力提供了新的改进思路。

Abstract: Large language models (LLMs) excel at language understanding but often
hallucinate and struggle with multi-hop reasoning. Knowledge-graph-based
retrieval-augmented generation (KG-RAG) offers grounding, yet most methods rely
on flat embeddings and noisy path exploration. We propose ParallaxRAG, a
framework that symmetrically decouples queries and graph triples into
multi-view spaces, enabling a robust retrieval architecture that explicitly
enforces head diversity while constraining weakly related paths. Central to our
approach is the observation that different attention heads specialize in
semantic relations at distinct reasoning stages, contributing to different hops
of the reasoning chain. This specialization allows ParallaxRAG to construct
cleaner subgraphs and guide LLMs through grounded, step-wise reasoning.
Experiments on WebQSP and CWQ, under our unified, reproducible setup (BGE-M3 +
Llama3.1-8B), demonstrate competitive retrieval and QA performance, alongside
reduced hallucination and good generalization. Our results highlight multi-view
head specialization as a principled direction for knowledge-grounded multi-hop
reasoning. Our implementation will be released as soon as the paper is
accepted.

</details>


### [36] [KITE: A Benchmark for Evaluating Korean Instruction-Following Abilities in Large Language Models](https://arxiv.org/abs/2510.15558)
*Dongjun Kim,Chanhee Park,Chanjun Park,Heuiseok Lim*

Main category: cs.CL

TL;DR: 提出了KITE基准，专门评估韩语大语言模型的指令跟随能力，填补了韩语开放指令评估的空白。


<details>
  <summary>Details</summary>
Motivation: 当前评估主要关注英语模型，忽视了其他语言的独特语言文化特征，特别是韩语在语法、形态、敬语和数字系统方面的特殊性。

Method: 开发了KITE基准，结合自动指标和人工评估，针对通用和韩语特定的开放指令任务进行评估。

Result: 揭示了不同模型间的性能差异，深入分析了各模型的优势和弱点。

Conclusion: 通过公开KITE数据集和代码，促进文化语言包容性LLM发展，激励其他弱势语言的类似研究。

Abstract: The instruction-following capabilities of large language models (LLMs) are
pivotal for numerous applications, from conversational agents to complex
reasoning systems. However, current evaluations predominantly focus on English
models, neglecting the linguistic and cultural nuances of other languages.
Specifically, Korean, with its distinct syntax, rich morphological features,
honorific system, and dual numbering systems, lacks a dedicated benchmark for
assessing open-ended instruction-following capabilities. To address this gap,
we introduce the Korean Instruction-following Task Evaluation (KITE), a
comprehensive benchmark designed to evaluate both general and Korean-specific
instructions. Unlike existing Korean benchmarks that focus mainly on factual
knowledge or multiple-choice testing, KITE directly targets diverse, open-ended
instruction-following tasks. Our evaluation pipeline combines automated metrics
with human assessments, revealing performance disparities across models and
providing deeper insights into their strengths and weaknesses. By publicly
releasing the KITE dataset and code, we aim to foster further research on
culturally and linguistically inclusive LLM development and inspire similar
endeavors for other underrepresented languages.

</details>


### [37] [Finetuning LLMs for EvaCun 2025 token prediction shared task](https://arxiv.org/abs/2510.15561)
*Josef Jon,Ondřej Bojar*

Main category: cs.CL

TL;DR: 该论文介绍了EvaCun 2025令牌预测任务的提交系统，基于Command-R、Mistral和Aya Expanse等LLM模型在任务数据上的微调，比较了三种不同提示方法的效果。


<details>
  <summary>Details</summary>
Motivation: 作者对任务领域和语言只有浅显了解，因此直接使用组织者提供的训练数据，不进行特定调整、预处理或过滤，旨在探索简单直接的方法在令牌预测任务中的表现。

Method: 使用三种不同的大型语言模型（Command-R、Mistral、Aya Expanse）在任务数据上进行微调，并比较基于三种不同提示的预测方法，在保留数据上进行评估。

Result: 论文在保留数据上评估了三种不同提示方法的效果，但没有具体说明哪种方法表现最佳或具体的性能指标。

Conclusion: 作者采用了一种简单直接的方法，不进行任务特定的调整，仅通过微调现有LLM模型并使用不同提示策略来完成令牌预测任务。

Abstract: In this paper, we present our submission for the token prediction task of
EvaCun 2025. Our sys-tems are based on LLMs (Command-R, Mistral, and Aya
Expanse) fine-tuned on the task data provided by the organizers. As we only
pos-sess a very superficial knowledge of the subject field and the languages of
the task, we simply used the training data without any task-specific
adjustments, preprocessing, or filtering. We compare 3 different approaches
(based on 3 different prompts) of obtaining the predictions, and we evaluate
them on a held-out part of the data.

</details>


### [38] [From Ghazals to Sonnets: Decoding the Polysemous Expressions of Love Across Languages](https://arxiv.org/abs/2510.15569)
*Syed Mohammad Sualeh Ali*

Main category: cs.CL

TL;DR: 本文通过多义词案例研究分析乌尔都语诗歌中三个看似同义的爱情词汇（pyaar、muhabbat、ishq），揭示它们在情感表达上的细微差别，并通过词嵌入技术进行乌尔都语与英语爱情词汇的语义空间比较。


<details>
  <summary>Details</summary>
Motivation: 探索乌尔都语诗歌中爱情词汇的多义性，揭示这些词汇在情感表达上的独特文化内涵和细微差别，这些差异在英语文学中缺乏直接对应。

Method: 采用多义词案例研究方法，仔细分析这些词汇在乌尔都语诗歌中的使用和语境；同时进行对比分析，为乌尔都语和英语爱情相关词汇生成词嵌入，量化并可视化它们的语义空间。

Result: 发现了三个爱情词汇之间隐藏的语义层次和细微区别，通过词嵌入技术展示了这些词汇在语义空间中的独特分布，揭示了乌尔都语表达爱情的独特文化语言特征。

Conclusion: 研究揭示了乌尔都语诗歌中爱情表达的迷人复杂性，为理解和欣赏其独特的爱情表达方式提供了更深入的视角，展现了语言与文化在情感表达上的深刻联系。

Abstract: This paper delves into the intricate world of Urdu poetry, exploring its
thematic depths through a lens of polysemy. By focusing on the nuanced
differences between three seemingly synonymous words (pyaar, muhabbat, and
ishq) we expose a spectrum of emotions and experiences unique to the Urdu
language. This study employs a polysemic case study approach, meticulously
examining how these words are interwoven within the rich tapestry of Urdu
poetry. By analyzing their usage and context, we uncover a hidden layer of
meaning, revealing subtle distinctions which lack direct equivalents in English
literature. Furthermore, we embark on a comparative analysis, generating word
embeddings for both Urdu and English terms related to love. This enables us to
quantify and visualize the semantic space occupied by these words, providing
valuable insights into the cultural and linguistic nuances of expressing love.
Through this multifaceted approach, our study sheds light on the captivating
complexities of Urdu poetry, offering a deeper understanding and appreciation
for its unique portrayal of love and its myriad expressions

</details>


### [39] [BiMax: Bidirectional MaxSim Score for Document-Level Alignment](https://arxiv.org/abs/2510.15577)
*Xiaotian Wang,Takehito Utsuro,Masaaki Nagata*

Main category: cs.CL

TL;DR: 提出跨语言双向最大相似度评分(BiMax)用于计算文档间相似度，相比最优传输方法效率提升约100倍，在WMT16双语文档对齐任务中达到相近准确率。


<details>
  <summary>Details</summary>
Motivation: 现有文档对齐方法如TK-PERT和最优传输(OT)在准确性上表现良好，但在处理大规模网络挖掘数据时，需要同时考虑准确性和速度。

Method: 提出跨语言双向最大相似度评分(BiMax)来计算文档间相似度，并对当前最先进的多语言句子嵌入模型性能进行全面分析。

Result: 在WMT16双语文档对齐任务中，BiMax达到与OT方法相当的准确率，同时速度提升约100倍。

Conclusion: BiMax方法在大规模文档对齐任务中实现了准确性和效率的良好平衡，所有对齐方法已作为EmbDA工具公开发布。

Abstract: Document alignment is necessary for the hierarchical mining (Ba\~n\'on et
al., 2020; Morishita et al., 2022), which aligns documents across source and
target languages within the same web domain. Several high precision sentence
embedding-based methods have been developed, such as TK-PERT (Thompson and
Koehn, 2020) and Optimal Transport (OT) (Clark et al., 2019; El-Kishky and
Guzm\'an, 2020). However, given the massive scale of web mining data, both
accuracy and speed must be considered. In this paper, we propose a
cross-lingual Bidirectional Maxsim score (BiMax) for computing doc-to-doc
similarity, to improve efficiency compared to the OT method. Consequently, on
the WMT16 bilingual document alignment task, BiMax attains accuracy comparable
to OT with an approximate 100-fold speed increase. Meanwhile, we also conduct a
comprehensive analysis to investigate the performance of current
state-of-the-art multilingual sentence embedding models. All the alignment
methods in this paper are publicly available as a tool called EmbDA
(https://github.com/EternalEdenn/EmbDA).

</details>


### [40] [The Elephant in the Coreference Room: Resolving Coreference in Full-Length French Fiction Works](https://arxiv.org/abs/2510.15594)
*Antoine Bourgois,Thierry Poibeau*

Main category: cs.CL

TL;DR: 提出了一个新的法语长篇小说指代消解标注语料库，包含三部完整小说，总计超过28.5万个词符，填补了长文档指代消解数据集的空白。


<details>
  <summary>Details</summary>
Motivation: 当前计算文学研究中指代消解受到广泛关注，但完全标注的长文档代表性数据集仍然稀缺，特别是针对复杂文学作品的长指代链评估需求。

Method: 构建了包含三部完整法语小说的标注语料库，并提出了模块化的指代消解流程，支持细粒度错误分析。

Result: 该方法具有竞争力，能有效扩展到长文档处理，并能推断虚构人物的性别信息。

Conclusion: 该语料库和流程对文学分析和下游NLP任务都有重要意义，展示了长文档指代消解的实用价值。

Abstract: While coreference resolution is attracting more interest than ever from
computational literature researchers, representative datasets of fully
annotated long documents remain surprisingly scarce. In this paper, we
introduce a new annotated corpus of three full-length French novels, totaling
over 285,000 tokens. Unlike previous datasets focused on shorter texts, our
corpus addresses the challenges posed by long, complex literary works, enabling
evaluation of coreference models in the context of long reference chains. We
present a modular coreference resolution pipeline that allows for fine-grained
error analysis. We show that our approach is competitive and scales effectively
to long documents. Finally, we demonstrate its usefulness to infer the gender
of fictional characters, showcasing its relevance for both literary analysis
and downstream NLP tasks.

</details>


### [41] [HypoSpace: Evaluating LLM Creativity as Set-Valued Hypothesis Generators under Underdetermination](https://arxiv.org/abs/2510.15614)
*Tingting Chen,Beibei Lin,Zifeng Yuan,Qiran Zou,Hongyu He,Yew-Soon Ong,Anirudh Goyal,Dianbo Liu*

Main category: cs.CL

TL;DR: HypoSpace是一个评估语言模型生成多假设能力的诊断套件，通过有效性、唯一性和覆盖率三个指标来衡量模型在不确定科学问题中的表现。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型在科学工作流中的应用增多，需要评估它们提出多种解释（而非单一正确答案）的能力，因为许多科学问题是不确定的，存在多个机制不同的假设与相同观测结果一致。

Method: HypoSpace将LLMs视为有限假设集的采样器，测量三个互补指标：有效性（与观测一致的提案精度）、唯一性（提案间的非冗余性）和覆盖率（对枚举可接受集的覆盖）。在三个结构化领域实例化：因果图、重力约束3D体素重建和布尔基因相互作用。

Result: 在指令调优和推理导向模型中，有效性通常保持较高，但随着可接受空间增大，唯一性和覆盖率会下降，揭示了仅靠正确性指标无法发现的模式崩溃问题。

Conclusion: HypoSpace为明确探索和覆盖可接受解释空间的方法提供了一个受控探针，而非排行榜，有助于评估模型在不确定科学问题中的多假设生成能力。

Abstract: As language models are increasingly used in scientific workflows, evaluating
their ability to propose sets of explanations-not just a single correct
answer-becomes critical. Many scientific problems are underdetermined:
multiple, mechanistically distinct hypotheses are consistent with the same
observations. We introduce HypoSpace, a diagnostic suite that treats LLMs as
samplers of finite hypothesis sets and measures three complementary indicators:
Validity (precision of proposals consistent with observations), Uniqueness
(non-redundancy among proposals), and Recovery (coverage of the enumerated
admissible set). We instantiate HypoSpace in three structured domains with
deterministic validators and exactly enumerated hypothesis spaces: (i) causal
graphs from perturbations, (ii) gravity-constrained 3D voxel reconstruction
from top-down projections, and (iii) Boolean genetic interactions. Across
instruction-tuned and reasoning-focused models, Validity often remains high
while Uniqueness and Recovery degrade as the admissible space grows, revealing
mode collapse that is invisible to correctness-only metrics. HypoSpace offers a
controlled probe-rather than a leaderboard-for methods that explicitly explore
and cover admissible explanation spaces. Code is available at:
https://github.com/CTT-Pavilion/_HypoSpace.

</details>


### [42] [Leveraging LLMs for Context-Aware Implicit Textual and Multimodal Hate Speech Detection](https://arxiv.org/abs/2510.15685)
*Joshua Wolfe Brook,Ilia Markov*

Main category: cs.CL

TL;DR: 使用LLM作为动态知识库生成背景上下文，通过四种方法将上下文整合到仇恨言论检测分类器中，在文本和多模态设置中分别提升了3和6个F1分数。


<details>
  <summary>Details</summary>
Motivation: 利用LLM生成背景上下文来增强仇恨言论检测，特别是针对隐式仇恨言论和仇恨表情包等难以检测的内容。

Method: 提出两种上下文生成策略（命名实体聚焦和全文提示），比较四种上下文整合方法（文本拼接、嵌入拼接、分层transformer融合、LLM驱动文本增强）。

Result: 在文本隐式仇恨数据集上提升3个F1分数，在多模态仇恨表情包数据集上提升6个F1分数，嵌入拼接方法表现最佳。

Conclusion: 上下文信息和整合方法对仇恨言论检测至关重要，LLM生成的背景上下文能显著提升检测性能。

Abstract: This research introduces a novel approach to textual and multimodal Hate
Speech Detection (HSD), using Large Language Models (LLMs) as dynamic knowledge
bases to generate background context and incorporate it into the input of HSD
classifiers. Two context generation strategies are examined: one focused on
named entities and the other on full-text prompting. Four methods of
incorporating context into the classifier input are compared: text
concatenation, embedding concatenation, a hierarchical transformer-based
fusion, and LLM-driven text enhancement. Experiments are conducted on the
textual Latent Hatred dataset of implicit hate speech and applied in a
multimodal setting on the MAMI dataset of misogynous memes. Results suggest
that both the contextual information and the method by which it is incorporated
are key, with gains of up to 3 and 6 F1 points on textual and multimodal setups
respectively, from a zero-context baseline to the highest-performing system,
based on embedding concatenation.

</details>


### [43] [Cost-Aware Retrieval-Augmentation Reasoning Models with Adaptive Retrieval Depth](https://arxiv.org/abs/2510.15719)
*Helia Hashemi,Victor Rühle,Saravan Rajmohan*

Main category: cs.CL

TL;DR: 提出了一种动态调整检索文档长度的检索增强推理模型，通过强化学习训练成本感知的推理模型，在保持效果的同时显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强推理模型计算成本高昂，检索和推理token都消耗大量资源，需要更高效的解决方案。

Method: 使用强化学习训练成本感知的检索增强推理模型，动态调整检索文档长度，探索内存和延迟约束下的实现方案。

Result: 在7个公开问答数据集上验证，延迟降低16-20%，精确匹配准确率平均提升5%。

Conclusion: 提出的成本感知检索增强推理框架在显著提升效率的同时，还能改善模型效果。

Abstract: Reasoning models have gained significant attention due to their strong
performance, particularly when enhanced with retrieval augmentation. However,
these models often incur high computational costs, as both retrieval and
reasoning tokens contribute substantially to the overall resource usage. In
this work, we make the following contributions: (1) we propose a
retrieval-augmented reasoning model that dynamically adjusts the length of the
retrieved document list based on the query and retrieval results; (2) we
develop a cost-aware advantage function for training of efficient
retrieval-augmented reasoning models through reinforcement learning; and (3) we
explore both memory- and latency-bound implementations of the proposed
cost-aware framework for both proximal and group relative policy optimization
algorithms. We evaluate our approach on seven public question answering
datasets and demonstrate significant efficiency gains, without compromising
effectiveness. In fact, we observed that the model latency decreases by ~16-20%
across datasets, while its effectiveness increases by ~5% on average, in terms
of exact match.

</details>


### [44] [Attention Sinks in Diffusion Language Models](https://arxiv.org/abs/2510.15731)
*Maximo Eduardo Rulli,Simone Petruzzi,Edoardo Michielon,Fabrizio Silvestri,Simone Scardapane,Alessio Devoto*

Main category: cs.CL

TL;DR: 该论文对掩码扩散语言模型(DLMs)的注意力模式进行实证分析，发现DLMs存在动态变化的注意力下沉现象，但与自回归模型(ARMs)相比，DLMs对注意力下沉的移除具有更强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管掩码扩散语言模型在效率和性能上表现出色，但其内部工作机制尚未得到充分探索。本文旨在研究DLMs中的注意力模式，特别是注意力下沉现象。

Method: 通过实证分析DLMs的注意力模式，重点关注注意力下沉现象，并与自回归模型进行比较研究。

Result: 发现DLMs存在动态变化的注意力下沉现象，且对注意力下沉的移除具有鲁棒性，性能仅轻微下降，这与ARMs形成鲜明对比。

Conclusion: 研究揭示了扩散语言模型与自回归模型在注意力分配和利用方面的根本差异，为理解扩散语言模型的内部工作机制提供了新见解。

Abstract: Masked Diffusion Language Models (DLMs) have recently emerged as a promising
alternative to traditional Autoregressive Models (ARMs). DLMs employ
transformer encoders with bidirectional attention, enabling parallel token
generation while maintaining competitive performance. Although their efficiency
and effectiveness have been extensively studied, the internal mechanisms that
govern DLMs remain largely unexplored. In this work, we conduct an empirical
analysis of DLM attention patterns, focusing on the attention sinking
phenomenon, an effect previously observed in various transformer-based
architectures. Our findings reveal that DLMs also exhibit attention sinks, but
with distinct characteristics. First, unlike in ARMs, the sink positions in
DLMs tend to shift throughout the generation process, displaying a dynamic
behaviour. Second, while ARMs are highly sensitive to the removal of attention
sinks, DLMs remain robust: masking sinks leads to only a minor degradation in
performance. These results provide new insights into the inner workings of
diffusion-based language models and highlight fundamental differences in how
they allocate and utilize attention compared to autoregressive models.

</details>


### [45] [LLMs Judge Themselves: A Game-Theoretic Framework for Human-Aligned Evaluation](https://arxiv.org/abs/2510.15746)
*Gao Yang,Yuhang Liu,Siyu Miao,Xinyue Liang,Zhengyang Liu,Heyan Huang*

Main category: cs.CL

TL;DR: 探索将博弈论原理应用于大语言模型评估，提出自动互评估框架，通过自博弈和同行评审让LLMs相互评估，并与人类投票行为比较以验证其与人类判断的一致性。


<details>
  <summary>Details</summary>
Motivation: 传统评估方法依赖固定格式任务和参考答案，难以捕捉现代LLM行为的细微、主观和开放式特性，需要更有效的评估方式。

Method: 提出自动互评估框架，让LLMs通过自博弈和同行评审相互评估输出，结合博弈论投票算法聚合同行评审结果，并与人类投票行为进行系统比较。

Result: 实证结果显示理论预测与人类评估之间存在收敛和分歧，揭示了互评估方法的潜力和局限性。

Conclusion: 这是首个将互评估、博弈论聚合和基于人类的验证相结合来评估LLM能力的工作，为LLM评估提供了新的视角和方法。

Abstract: Ideal or real - that is the question.In this work, we explore whether
principles from game theory can be effectively applied to the evaluation of
large language models (LLMs). This inquiry is motivated by the growing
inadequacy of conventional evaluation practices, which often rely on
fixed-format tasks with reference answers and struggle to capture the nuanced,
subjective, and open-ended nature of modern LLM behavior. To address these
challenges, we propose a novel alternative: automatic mutual evaluation, where
LLMs assess each other's output through self-play and peer review. These peer
assessments are then systematically compared with human voting behavior to
evaluate their alignment with human judgment. Our framework incorporates
game-theoretic voting algorithms to aggregate peer reviews, enabling a
principled investigation into whether model-generated rankings reflect human
preferences. Empirical results reveal both convergences and divergences between
theoretical predictions and human evaluations, offering valuable insights into
the promises and limitations of mutual evaluation. To the best of our
knowledge, this is the first work to jointly integrate mutual evaluation,
game-theoretic aggregation, and human-grounded validation for evaluating the
capabilities of LLMs.

</details>


### [46] [On Non-interactive Evaluation of Animal Communication Translators](https://arxiv.org/abs/2510.15768)
*Orr Paradise,David F. Gruber,Adam Tauman Kalai*

Main category: cs.CL

TL;DR: 提出一种无需参考翻译的机器翻译质量评估方法，通过逐段翻译和shuffle测试来验证翻译器，特别适用于复杂语言（如鲸语）的翻译验证。


<details>
  <summary>Details</summary>
Motivation: 解决在没有参考翻译的情况下如何验证AI翻译器（如鲸语翻译器）是否有效的问题，避免与动物直接交互带来的安全、伦理和成本问题。

Method: 采用逐段翻译结合经典NLP shuffle测试的方法，通过比较有序翻译和随机排列翻译的合理性来评估翻译质量。

Result: 在数据稀缺的人类语言和构造语言上的概念验证实验表明，该方法与基于参考翻译的标准评估方法高度相关。

Conclusion: 对于复杂语言的翻译验证，交互可能不是必要的，通过仅分析翻译输出就能有效评估翻译质量，这在翻译学习的早期阶段可能更高效。

Abstract: If you had an AI Whale-to-English translator, how could you validate whether
or not it is working? Does one need to interact with the animals or rely on
grounded observations such as temperature? We provide theoretical and
proof-of-concept experimental evidence suggesting that interaction and even
observations may not be necessary for sufficiently complex languages. One may
be able to evaluate translators solely by their English outputs, offering
potential advantages in terms of safety, ethics, and cost. This is an instance
of machine translation quality evaluation (MTQE) without any reference
translations available. A key challenge is identifying ``hallucinations,''
false translations which may appear fluent and plausible. We propose using
segment-by-segment translation together with the classic NLP shuffle test to
evaluate translators. The idea is to translate animal communication, turn by
turn, and evaluate how often the resulting translations make more sense in
order than permuted. Proof-of-concept experiments on data-scarce human
languages and constructed languages demonstrate the potential utility of this
evaluation methodology. These human-language experiments serve solely to
validate our reference-free metric under data scarcity. It is found to
correlate highly with a standard evaluation based on reference translations,
which are available in our experiments. We also perform a theoretical analysis
suggesting that interaction may not be necessary nor efficient in the early
stages of learning to translate.

</details>


### [47] [Emergence of Linear Truth Encodings in Language Models](https://arxiv.org/abs/2510.15804)
*Shauli Ravfogel,Gilad Yehudai,Tal Linzen,Joan Bruna,Alberto Bietti*

Main category: cs.CL

TL;DR: 论文通过构建一个单层Transformer玩具模型，揭示了语言模型中线性真值子空间的形成机制：模型首先记忆事实关联，然后学习线性区分真假陈述以降低语言建模损失。


<details>
  <summary>Details</summary>
Motivation: 现有研究发现大语言模型存在区分真假陈述的线性子空间，但其形成机制尚不明确。本文旨在通过透明模型揭示这一现象的具体产生路径。

Method: 构建一个单层Transformer玩具模型，研究在事实陈述共现的数据分布下，模型如何学习区分真假以降低语言建模损失，并在预训练语言模型中验证该模式。

Result: 在玩具设置中观察到两阶段学习动态：网络先快速记忆个体事实关联，然后在更长时间内学习线性区分真假，从而降低语言建模损失。

Conclusion: 这些结果从机制和实证两方面解释了线性真值表示在语言模型中如何及为何会出现。

Abstract: Recent probing studies reveal that large language models exhibit linear
subspaces that separate true from false statements, yet the mechanism behind
their emergence is unclear. We introduce a transparent, one-layer transformer
toy model that reproduces such truth subspaces end-to-end and exposes one
concrete route by which they can arise. We study one simple setting in which
truth encoding can emerge: a data distribution where factual statements
co-occur with other factual statements (and vice-versa), encouraging the model
to learn this distinction in order to lower the LM loss on future tokens. We
corroborate this pattern with experiments in pretrained language models.
Finally, in the toy setting we observe a two-phase learning dynamic: networks
first memorize individual factual associations in a few steps, then -- over a
longer horizon -- learn to linearly separate true from false, which in turn
lowers language-modeling loss. Together, these results provide both a
mechanistic demonstration and an empirical motivation for how and why linear
truth representations can emerge in language models.

</details>


### [48] [Paper2Web: Let's Make Your Paper Alive!](https://arxiv.org/abs/2510.15842)
*Yuhang Chen,Tianpeng Lv,Siyi Zhang,Yixiang Yin,Yao Wan,Philip S. Yu,Dongping Chen*

Main category: cs.CL

TL;DR: Paper2Web是一个用于评估学术网页生成的基准数据集和多维度评估框架，提出了PWAgent自动管道将科学论文转换为交互式多媒体学术主页。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如直接LLM生成、模板或HTML转换）难以生成布局感知的交互式网站，且缺乏针对此任务的全面评估套件。

Method: 提出PWAgent自主管道，通过MCP工具迭代优化内容和布局，增强重点、平衡和呈现质量。

Result: PWAgent在学术网页生成方面显著优于端到端基线方法（如基于模板的网页和arXiv/alphaXiv版本），同时保持低成本，达到了帕累托前沿。

Conclusion: Paper2Web为学术网页生成提供了可靠的评估基准，PWAgent展示了在生成高质量交互式学术主页方面的有效性。

Abstract: Academic project websites can more effectively disseminate research when they
clearly present core content and enable intuitive navigation and interaction.
However, current approaches such as direct Large Language Model (LLM)
generation, templates, or direct HTML conversion struggle to produce
layout-aware, interactive sites, and a comprehensive evaluation suite for this
task has been lacking. In this paper, we introduce Paper2Web, a benchmark
dataset and multi-dimensional evaluation framework for assessing academic
webpage generation. It incorporates rule-based metrics like Connectivity,
Completeness and human-verified LLM-as-a-Judge (covering interactivity,
aesthetics, and informativeness), and PaperQuiz, which measures paper-level
knowledge retention. We further present PWAgent, an autonomous pipeline that
converts scientific papers into interactive and multimedia-rich academic
homepages. The agent iteratively refines both content and layout through MCP
tools that enhance emphasis, balance, and presentation quality. Our experiments
show that PWAgent consistently outperforms end-to-end baselines like
template-based webpages and arXiv/alphaXiv versions by a large margin while
maintaining low cost, achieving the Pareto-front in academic webpage
generation.

</details>


### [49] [Enhanced Sentiment Interpretation via a Lexicon-Fuzzy-Transformer Framework](https://arxiv.org/abs/2510.15843)
*Shayan Rokhva,Mousa Alizadeh,Maryam Abdollahi Shamami*

Main category: cs.CL

TL;DR: 提出了一种结合词典、模糊逻辑和Transformer的混合框架，用于产品评论和社交媒体中的细粒度情感分析，能够生成连续的情感极性强度分数。


<details>
  <summary>Details</summary>
Motivation: 解决产品评论和社交媒体中因非正式和领域特定语言导致的情感极性及强度检测不准确的问题。

Method: 使用VADER进行初始情感估计，通过DistilBERT的置信度分数进行两阶段调整，应用模糊逻辑减少中性偏置并增强粒度，最后通过自定义模糊推理系统将分数映射到0-1连续区间。

Result: 在四个领域特定数据集（外卖、电商、旅游、时尚）上评估，结果显示与用户评分对齐度提高，能更好识别情感极端值，减少误分类。

Conclusion: 该工作证明了将符号推理与神经模型结合在语言动态领域中进行可解释、细粒度情感分析的价值。

Abstract: Accurately detecting sentiment polarity and intensity in product reviews and
social media posts remains challenging due to informal and domain-specific
language. To address this, we propose a novel hybrid lexicon-fuzzy-transformer
framework that combines rule-based heuristics, contextual deep learning, and
fuzzy logic to generate continuous sentiment scores reflecting both polarity
and strength. The pipeline begins with VADER-based initial sentiment
estimations, which are refined through a two-stage adjustment process. This
involves leveraging confidence scores from DistilBERT, a lightweight
transformer and applying fuzzy logic principles to mitigate excessive
neutrality bias and enhance granularity. A custom fuzzy inference system then
maps the refined scores onto a 0 to 1 continuum, producing expert)like
judgments. The framework is rigorously evaluated on four domain-specific
datasets. food delivery, e-commerce, tourism, and fashion. Results show
improved alignment with user ratings, better identification of sentiment
extremes, and reduced misclassifications. Both quantitative metrics
(distributional alignment, confusion matrices) and qualitative insights (case
studies, runtime analysis) affirm the models robustness and efficiency. This
work demonstrates the value of integrating symbolic reasoning with neural
models for interpretable, finegrained sentiment analysis in linguistically
dynamic domains.

</details>


### [50] [SpeechLLMs for Large-scale Contextualized Zero-shot Slot Filling](https://arxiv.org/abs/2510.15851)
*Kadri Hacioglu,Manjunath K E,Andreas Stolcke*

Main category: cs.CL

TL;DR: 本文研究了基于语音大语言模型的槽位填充任务，通过建立经验上界、识别性能差距，并改进训练数据、架构和策略来缩小与上界的差距。


<details>
  <summary>Details</summary>
Motivation: 传统槽位填充采用语音识别和自然语言理解的级联方法，而语音LLMs提供了更统一、生成式和指令跟随的方法，具有零样本能力和泛化到未见槽位标签的潜力。

Method: 创建任务的经验上界，识别性能、鲁棒性和泛化差距，改进训练数据、架构和训练策略。

Result: 每种改进措施都显著提升了性能，同时突出了实际挑战。

Conclusion: 为利用这些新兴模型提供了经验指导和见解，展示了在槽位填充任务上的实质性改进。

Abstract: Slot filling is a crucial subtask in spoken language understanding (SLU),
traditionally implemented as a cascade of speech recognition followed by one or
more natural language understanding (NLU) components. The recent advent of
speech-based large language models (speechLLMs), which integrate speech and
textual foundation models, has opened new avenues for achieving speech
understanding tasks in a more unified, generative, and instruction-following
manner while promising data and compute efficiency with zero-shot abilities,
generalizing to unseen slot labels. We address the slot-filling task by
creating an empirical upper bound for the task, identifying performance,
robustness, and generalization gaps, and proposing improvements to the training
data, architecture, and training strategies to narrow the gap with the upper
bound result. We show that each of these measures improve performance
substantially, while highlighting practical challenges and providing empirical
guidance and insights for harnessing these emerging models.

</details>


### [51] [InfiMed-ORBIT: Aligning LLMs on Open-Ended Complex Tasks via Rubric-Based Incremental Training](https://arxiv.org/abs/2510.15859)
*Pengkai Wang,Qi Zuo,Pengwei Liu,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.CL

TL;DR: ORBIT框架通过基于量规的增量强化学习，在开放式高风险医疗对话任务中显著提升LLM性能，在HealthBench-Hard基准上从7.0提升到27.2。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习在数学和代码等有明确奖励函数的领域表现良好，但在开放式领域如医疗咨询中，由于奖励模糊、主观且依赖上下文，缺乏稳健的奖励函数，限制了RL策略的应用。

Method: ORBIT框架结合合成对话生成和动态量规创建，使用量规指导的反馈来驱动增量强化学习过程，不依赖外部医学知识或手动规则。

Result: 在Qwen3-4B-Instruct模型上实施ORBIT，仅使用2k样本就将HealthBench-Hard基准性能从7.0提升到27.2，达到该规模模型的最先进水平。

Conclusion: 量规驱动的强化学习在复杂开放式任务中促进一致的性能提升，量规反馈是推进LLM在复杂任务中发展的可扩展策略。

Abstract: Large Language Models (LLMs) have shown substantial advances through
reinforcement learning (RL), particularly in domains where rewards can be
programmatically verified, such as mathematics and code. In these areas, models
benefit from a well-defined operational base guided by explicit rule-based
objectives. However, this progress reveals a significant limitation: in
open-ended domains where rewards are ambiguous, subjective, or
context-dependent, such as creative writing, scientific reasoning, and notably
medical consultation, robust reward functions are lacking, making these areas
challenging for current RL strategies. To bridge this gap, we introduce ORBIT,
an open-ended rubric-based incremental training framework specifically designed
for high-stakes medical dialogue. ORBIT integrates syn- thetic dialogue
generation with the dynamic creation of rubrics, employing these rubrics to
direct an incremental RL process. In particular, this approach does not depend
on external medical knowledge or manual rules, instead utilizing rubric-guided
feedback to shape learning. When implemented on the Qwen3-4B-Instruct model,
our method can greatly enhance its performance on the HealthBench-Hard
benchmark from 7.0 to 27.2 using only 2k samples, thus achieving
state-of-the-art results for models of this scale. Our analysis confirms that
rubric-driven RL fos-ters consistent performance gains across diverse
consultation scenarios, going beyond simple numerical improvements. These
findings underscore rubric-based feedback as a scalable strategy for advancing
LLMs in intricate, open-ended tasks.

</details>


### [52] [PolySkill: Learning Generalizable Skills Through Polymorphic Abstraction](https://arxiv.org/abs/2510.15863)
*Simon Yu,Gang Li,Weiyan Shi,Peng Qi*

Main category: cs.CL

TL;DR: PolySkill框架通过将技能的抽象目标与具体实现解耦，使智能体能够学习可泛化和组合的技能，在网站导航任务中显著提升技能重用率和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法学习的技能通常过度专门化于单个网站，缺乏泛化能力。为了解决这个问题，需要开发能够学习可重用和可泛化技能的框架。

Method: 受软件工程中多态性的启发，PolySkill将技能的抽象目标（要完成什么）与具体实现（如何执行）解耦，使智能体能够识别和优化自身目标。

Result: 在实验中，该方法在已见网站上技能重用率提高1.7倍，在Mind2Web和未见网站上成功率分别提升9.4%和13.9%，同时减少20%以上的步骤。在自探索设置中，能学习跨网站工作的可泛化技能。

Conclusion: 将技能目标与执行分离是开发能够在开放网络中持续学习和泛化的自主智能体的关键步骤，为构建适应环境持续学习的智能体提供了实用路径。

Abstract: Large language models (LLMs) are moving beyond static uses and are now
powering agents that learn continually during their interaction with external
environments. For example, agents can learn reusable skills while navigating
web pages or toggling new tools. However, existing methods for skill learning
often create skills that are over-specialized to a single website and fail to
generalize. We introduce PolySkill, a new framework that enables agents to
learn generalizable and compositional skills. The core idea, inspired by
polymorphism in software engineering, is to decouple a skill's abstract goal
(what it accomplishes) and its concrete implementation (how it is executed).
Experiments show that our method (1) improves skill reuse by 1.7x on seen
websites and (2) boosts success rates by up to 9.4% on Mind2Web and 13.9% on
unseen websites, while reducing steps by over 20%. (3) In self-exploration
settings without specified tasks, our framework improves the quality of
proposed tasks and enables agents to learn generalizable skills that work
across different sites. By enabling the agent to identify and refine its own
goals, the PolySkill enhances the agent's ability to learn a better curriculum,
leading to the acquisition of more generalizable skills compared to baseline
methods. This work provides a practical path toward building agents capable of
continual learning in adaptive environments. Our findings show that separating
a skill's goal from its execution is a crucial step toward developing
autonomous agents that can learn and generalize across the open web
continuously.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [53] [OpenEstimate: Evaluating LLMs on Reasoning Under Uncertainty with Real-World Data](https://arxiv.org/abs/2510.15096)
*Alana Renda,Jillian Ross,Michael Cafarella,Jacob Andreas*

Main category: cs.AI

TL;DR: OpenEstimate是一个用于评估语言模型在不确定性下进行数值估计任务的多领域基准测试，发现前沿语言模型的概率先验通常不准确且过度自信。


<details>
  <summary>Details</summary>
Motivation: 现实世界中语言模型需要处理不完整信息并在不确定性下推理，但现有评估主要关注有明确答案的问题，缺乏对不确定性推理能力的评估。

Method: 构建OpenEstimate基准测试，通过数值估计任务评估语言模型，要求模型综合背景信息并表达概率先验，评估这些先验的准确性和校准度。

Result: 在六个前沿语言模型上的测试显示，模型产生的先验通常不准确且过度自信，性能仅随不确定性提取方式略有改善，但不受采样策略、推理努力或提示设计的影响。

Conclusion: OpenEstimate为前沿语言模型提供了具有挑战性的评估平台，有助于开发在概率估计和不确定性推理方面表现更好的模型。

Abstract: Real-world settings where language models (LMs) are deployed -- in domains
spanning healthcare, finance, and other forms of knowledge work -- require
models to grapple with incomplete information and reason under uncertainty. Yet
most LM evaluations focus on problems with well-defined answers and success
criteria. This gap exists in part because natural problems involving
uncertainty are difficult to construct: given that LMs have access to most of
the same knowledge as humans, it is non-trivial to design questions for which
LMs will struggle to produce correct answers, but which humans can answer
reliably. As a result, LM performance on reasoning under uncertainty remains
poorly characterized. To address this gap, we introduce OpenEstimate, an
extensible, multi-domain benchmark for evaluating LMs on numerical estimation
tasks that require models to synthesize significant amounts of background
information and express predictions as probabilistic priors. We assess these
priors for accuracy and calibration, quantifying their usefulness relative to
samples from the true distribution of interest. Across six frontier LMs, we
find that LM-elicited priors are often inaccurate and overconfident.
Performance improves modestly depending on how uncertainty is elicited from the
model, but is largely unaffected by changes in sampling strategy, reasoning
effort, or prompt design. The OpenEstimate benchmark thus offers a challenging
evaluation for frontier LMs and a platform for developing models that are
better at probabilistic estimation and reasoning under uncertainty.

</details>


### [54] [Procedural Game Level Design with Deep Reinforcement Learning](https://arxiv.org/abs/2510.15120)
*Miraç Buğra Özkan*

Main category: cs.AI

TL;DR: 提出了一种基于深度强化学习的程序化关卡设计方法，使用Unity 3D环境中的两个智能体（蜂鸟和浮岛）协同工作，实现自主生成和解决游戏内容。


<details>
  <summary>Details</summary>
Motivation: 利用程序化内容生成技术减少游戏开发中的人工工作量，通过智能体协同实现动态、可重玩和可扩展的游戏环境。

Method: 使用Unity ML-Agents工具包的PPO算法训练两个智能体：蜂鸟智能体学习导航和收集花朵，浮岛智能体学习基于障碍物位置和蜂鸟性能生成花朵布局。

Result: 系统展现出涌现行为和强大的泛化能力，在不同环境配置下都能产生有效且高效的智能体行为。

Conclusion: 深度强化学习在虚拟环境中实现智能体既生成又解决内容的能力，为AI驱动的创意游戏开发开辟了新途径。

Abstract: Procedural content generation (PCG) has become an increasingly popular
technique in game development, allowing developers to generate dynamic,
replayable, and scalable environments with reduced manual effort. In this
study, a novel method for procedural level design using Deep Reinforcement
Learning (DRL) within a Unity-based 3D environment is proposed. The system
comprises two agents: a hummingbird agent, acting as a solver, and a floating
island agent, responsible for generating and placing collectible objects
(flowers) on the terrain in a realistic and context-aware manner. The
hummingbird is trained using the Proximal Policy Optimization (PPO) algorithm
from the Unity ML-Agents toolkit. It learns to navigate through the terrain
efficiently, locate flowers, and collect them while adapting to the
ever-changing procedural layout of the island. The island agent is also trained
using the Proximal Policy Optimization (PPO) algorithm. It learns to generate
flower layouts based on observed obstacle positions, the hummingbird's initial
state, and performance feedback from previous episodes. The interaction between
these agents leads to emergent behavior and robust generalization across
various environmental configurations. The results demonstrate that the approach
not only produces effective and efficient agent behavior but also opens up new
opportunities for autonomous game level design driven by machine learning. This
work highlights the potential of DRL in enabling intelligent agents to both
generate and solve content in virtual environments, pushing the boundaries of
what AI can contribute to creative game development processes.

</details>


### [55] [Towards Error Centric Intelligence I, Beyond Observational Learning](https://arxiv.org/abs/2510.15128)
*Marcus A. Thomas*

Main category: cs.AI

TL;DR: 论文认为AGI进展受理论限制而非数据或规模限制，挑战柏拉图表示假说，提出因果力学框架，强调假设空间变化作为首要操作，通过结构原则使错误发现和修正变得可行。


<details>
  <summary>Details</summary>
Motivation: 当前AGI发展面临理论瓶颈，观察等价的世界在干预下可能产生分歧，仅靠观察充分性无法保证干预能力，需要从错误中心视角重新思考学习问题。

Method: 提出因果力学框架，将假设空间变化作为首要操作，引入局部性和自主性原则、独立因果机制、组合自主性原则等结构原则，提供可操作诊断方法。

Result: 建立了一个能够将不可达错误转化为可达错误并进行修正的系统框架，为构建具有干预能力的智能系统提供理论基础。

Conclusion: AGI发展需要理论突破，因果力学框架通过强调假设空间变化和错误修正机制，为解决观察学习局限性提供了新途径，为实现真正的反事实能力奠定基础。

Abstract: We argue that progress toward AGI is theory limited rather than data or scale
limited. Building on the critical rationalism of Popper and Deutsch, we
challenge the Platonic Representation Hypothesis. Observationally equivalent
worlds can diverge under interventions, so observational adequacy alone cannot
guarantee interventional competence. We begin by laying foundations,
definitions of knowledge, learning, intelligence, counterfactual competence and
AGI, and then analyze the limits of observational learning that motivate an
error centric shift. We recast the problem as three questions about how
explicit and implicit errors evolve under an agent's actions, which errors are
unreachable within a fixed hypothesis space, and how conjecture and criticism
expand that space. From these questions we propose Causal Mechanics, a
mechanisms first program in which hypothesis space change is a first class
operation and probabilistic structure is used when useful rather than presumed.
We advance structural principles that make error discovery and correction
tractable, including a differential Locality and Autonomy Principle for modular
interventions, a gauge invariant form of Independent Causal Mechanisms for
separability, and the Compositional Autonomy Principle for analogy
preservation, together with actionable diagnostics. The aim is a scaffold for
systems that can convert unreachable errors into reachable ones and correct
them.

</details>


### [56] [HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks](https://arxiv.org/abs/2510.15144)
*Chance Jiajie Li,Zhenze Mo,Yuhan Tang,Ao Qu,Jiayi Wu,Kaiya Ivy Zhao,Yulu Gan,Jie Fan,Jiangbo Yu,Hang Jiang,Paul Pu Liang,Jinhua Zhao,Luis Alberto Alonso Pastor,Kent Larson*

Main category: cs.AI

TL;DR: HugAgent是一个用于评估AI模型如何适应个体推理风格的基准测试，包含合成和人类两个轨道，旨在使机器推理更接近人类思维的个体性。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型主要模拟群体共识，缺乏对个体推理风格和信念轨迹的捕捉能力，需要开发能够适应个体推理模式的AI系统。

Method: 采用双轨道设计：合成轨道用于规模化和系统性压力测试，人类轨道用于收集生态有效的"出声思考"推理数据，评估模型在预测个体推理和信念更新方面的能力。

Result: 实验表明，最先进的大语言模型在适应个体推理方面仍存在持续差距，HugAgent成为首个可扩展的基准测试。

Conclusion: HugAgent为将机器推理与人类思维的个体性对齐提供了首个可扩展的评估框架，有助于推动更人性化的AI推理发展。

Abstract: Simulating human reasoning in open-ended tasks has been a long-standing
aspiration in AI and cognitive science. While large language models now
approximate human responses at scale, they remain tuned to population-level
consensus, often erasing the individuality of reasoning styles and belief
trajectories. To advance the vision of more human-like reasoning in machines,
we introduce HugAgent (Human-Grounded Agent Benchmark), a benchmark for
average-to-individual reasoning adaptation. The task is to predict how a
specific person would reason and update their beliefs in novel scenarios, given
partial evidence of their past views. HugAgent adopts a dual-track design: a
synthetic track for scale and systematic stress tests, and a human track for
ecologically valid, "out-loud" reasoning data. This design enables scalable,
reproducible evaluation of intra-agent fidelity: whether models can capture not
just what people believe, but how their reasoning evolves. Experiments with
state-of-the-art LLMs reveal persistent adaptation gaps, positioning HugAgent
as the first extensible benchmark for aligning machine reasoning with the
individuality of human thought. Our benchmark and chatbot are open-sourced as
HugAgent (https://anonymous.4open.science/r/HugAgent) and TraceYourThinking
(https://anonymous.4open.science/r/trace-your-thinking).

</details>


### [57] [WELD: A Large-Scale Longitudinal Dataset of Emotional Dynamics for Ubiquitous Affective Computing](https://arxiv.org/abs/2510.15221)
*Xiao Sun*

Main category: cs.AI

TL;DR: 提出了一个包含733,651个面部表情记录的大规模纵向工作场所情感数据集，收集自38名员工超过30.5个月，包含7种情感概率和32个扩展情感指标，验证了数据质量并建立了情感分类和预测的基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决真实工作场所环境中情感识别因缺乏大规模、纵向自然数据集而面临的挑战，捕捉COVID-19大流行期间的情感响应。

Method: 在真实办公环境中收集38名员工30.5个月的面部表情数据，使用深度学习面部表情识别获得7种情感概率，计算32个扩展情感指标，并进行技术验证和基线实验。

Result: 数据集成功复现已知心理模式（周末效应：+192%效价改善，p<0.001），员工流动率预测AUC=1.0，随机森林和LSTM模型情感分类准确率91.2%，效价预测R2=0.84。

Conclusion: 这是公开可用的最大、最长的纵向工作场所情感数据集，支持情感识别、情感动态建模、情感传染、流动预测和情感感知系统设计等研究。

Abstract: Automated emotion recognition in real-world workplace settings remains a
challenging problem in affective computing due to the scarcity of large-scale,
longitudinal datasets collected in naturalistic environments. We present a
novel dataset comprising 733,651 facial expression records from 38 employees
collected over 30.5 months (November 2021 to May 2024) in an authentic office
environment. Each record contains seven emotion probabilities (neutral, happy,
sad, surprised, fear, disgusted, angry) derived from deep learning-based facial
expression recognition, along with comprehensive metadata including job roles,
employment outcomes, and personality traits. The dataset uniquely spans the
COVID-19 pandemic period, capturing emotional responses to major societal
events including the Shanghai lockdown and policy changes. We provide 32
extended emotional metrics computed using established affective science
methods, including valence, arousal, volatility, predictability, inertia, and
emotional contagion strength. Technical validation demonstrates high data
quality through successful replication of known psychological patterns (weekend
effect: +192% valence improvement, p < 0.001; diurnal rhythm validated) and
perfect predictive validity for employee turnover (AUC=1.0). Baseline
experiments using Random Forest and LSTM models achieve 91.2% accuracy for
emotion classification and R2 = 0.84 for valence prediction. This is the
largest and longest longitudinal workplace emotion dataset publicly available,
enabling research in emotion recognition, affective dynamics modeling,
emotional contagion, turnover prediction, and emotion-aware system design.

</details>


### [58] [From Checklists to Clusters: A Homeostatic Account of AGI Evaluation](https://arxiv.org/abs/2510.15236)
*Brett Reynolds*

Main category: cs.AI

TL;DR: 本文提出AGI评估应使用非对称权重和持续性测试，将通用智能视为稳态属性集群，而非对称能力组合。


<details>
  <summary>Details</summary>
Motivation: 当前AGI评估存在两个问题：对称权重假设所有领域同等重要，而人类智能研究表明并非如此；快照测试无法区分持久能力和脆弱表现。

Method: 提出两种评估扩展：基于因果中心性的权重评分（导入CHC理论权重），以及集群稳定性指数系列（评估配置持久性、持久学习和错误纠正）。

Result: 这些扩展保持了多领域广度，同时减少了脆弱性和博弈行为。

Conclusion: 通用智能应被理解为稳态属性集群，AGI评估需要衡量能力在扰动下的共现机制，而非仅仅是能力快照。

Abstract: Contemporary AGI evaluations report multidomain capability profiles, yet they
typically assign symmetric weights and rely on snapshot scores. This creates
two problems: (i) equal weighting treats all domains as equally important when
human intelligence research suggests otherwise, and (ii) snapshot testing can't
distinguish durable capabilities from brittle performances that collapse under
delay or stress. I argue that general intelligence -- in humans and potentially
in machines -- is better understood as a homeostatic property cluster: a set of
abilities plus the mechanisms that keep those abilities co-present under
perturbation. On this view, AGI evaluation should weight domains by their
causal centrality (their contribution to cluster stability) and require
evidence of persistence across sessions. I propose two battery-compatible
extensions: a centrality-prior score that imports CHC-derived weights with
transparent sensitivity analysis, and a Cluster Stability Index family that
separates profile persistence, durable learning, and error correction. These
additions preserve multidomain breadth while reducing brittleness and gaming. I
close with testable predictions and black-box protocols labs can adopt without
architectural access.

</details>


### [59] [Multi-dimensional Data Analysis and Applications Basing on LLM Agents and Knowledge Graph Interactions](https://arxiv.org/abs/2510.15258)
*Xi Wang,Xianyao Ling,Kun Li,Gang Yin,Liang Zhang,Jiang Wu,Jun Xu,Fu Zhang,Wenbo Lei,Annie Wang,Peng Gong*

Main category: cs.AI

TL;DR: 提出了一种基于LLM代理与知识图谱交互的多维数据分析方法，构建动态协作的分析生态系统，在生态系统分析、关系挖掘和用户驱动探索分析方面具有显著优势


<details>
  <summary>Details</summary>
Motivation: 在大数据时代，从海量、异构、复杂关联的多维数据中提取深度洞察面临挑战。LLM在处理结构化知识时存在幻觉问题且难以实时更新，而知识图谱的静态特性限制了动态交互和分析能力

Method: 利用LLM代理从非结构化数据中自动提取产品数据，实时构建和可视化知识图谱，并通过交互平台支持用户对图节点进行深度探索分析

Result: 实验结果表明该方法在产品生态系统分析、关系挖掘和用户驱动探索分析方面具有显著优势

Conclusion: 该方法为多维数据分析提供了新的思路和工具，构建了动态协作的分析生态系统

Abstract: In the current era of big data, extracting deep insights from massive,
heterogeneous, and complexly associated multi-dimensional data has become a
significant challenge. Large Language Models (LLMs) perform well in natural
language understanding and generation, but still suffer from "hallucination"
issues when processing structured knowledge and are difficult to update in
real-time. Although Knowledge Graphs (KGs) can explicitly store structured
knowledge, their static nature limits dynamic interaction and analytical
capabilities. Therefore, this paper proposes a multi-dimensional data analysis
method based on the interactions between LLM agents and KGs, constructing a
dynamic, collaborative analytical ecosystem. This method utilizes LLM agents to
automatically extract product data from unstructured data, constructs and
visualizes the KG in real-time, and supports users in deep exploration and
analysis of graph nodes through an interactive platform. Experimental results
show that this method has significant advantages in product ecosystem analysis,
relationship mining, and user-driven exploratory analysis, providing new ideas
and tools for multi-dimensional data analysis.

</details>


### [60] [Experience-Driven Exploration for Efficient API-Free AI Agents](https://arxiv.org/abs/2510.15259)
*Chenwei Tang,Jingyu Xing,Xinyu Liu,Zizhou Wang,Jiawei Du,Liangli Zhen,Jiancheng Lv*

Main category: cs.AI

TL;DR: KG-Agent是一个基于经验驱动的学习框架，通过构建状态-动作知识图来解决无API环境下GUI操作的效率瓶颈问题，显著提升了探索效率和战略深度。


<details>
  <summary>Details</summary>
Motivation: 现有软件大多缺乏可访问的API，导致基于大语言模型的智能体只能通过像素级GUI进行操作，面临效率瓶颈：局限于局部视觉体验、短视决策和低效试错，阻碍了技能获取和长期规划。

Method: 提出KG-Agent框架，将原始像素级交互结构化到持久的状态-动作知识图(SA-KG)中，通过连接功能相似但视觉不同的GUI状态形成丰富的经验邻域，并设计基于图拓扑的混合内在奖励机制，结合状态价值奖励和新颖性奖励。

Result: 在Civilization V和Slay the Spire两个复杂的GUI决策环境中进行评估，相比最先进方法在探索效率和战略深度方面取得了显著改进。

Conclusion: KG-Agent通过结构化经验和混合奖励机制，成功解决了无API环境下智能体的探索效率和长期规划问题，为GUI操作的智能体学习提供了有效解决方案。

Abstract: Most existing software lacks accessible Application Programming Interfaces
(APIs), requiring agents to operate solely through pixel-based Graphical User
Interfaces (GUIs). In this API-free setting, large language model (LLM)-based
agents face severe efficiency bottlenecks: limited to local visual experiences,
they make myopic decisions and rely on inefficient trial-and-error, hindering
both skill acquisition and long-term planning. To address these challenges, we
propose KG-Agent, an experience-driven learning framework that structures an
agent's raw pixel-level interactions into a persistent State-Action Knowledge
Graph (SA-KG). KG-Agent overcomes inefficient exploration by linking
functionally similar but visually distinct GUI states, forming a rich
neighborhood of experience that enables the agent to generalize from a diverse
set of historical strategies. To support long-horizon reasoning, we design a
hybrid intrinsic reward mechanism based on the graph topology, combining a
state value reward for exploiting known high-value pathways with a novelty
reward that encourages targeted exploration. This approach decouples strategic
planning from pure discovery, allowing the agent to effectively value setup
actions with delayed gratification. We evaluate KG-Agent in two complex,
open-ended GUI-based decision-making environments (Civilization V and Slay the
Spire), demonstrating significant improvements in exploration efficiency and
strategic depth over the state-of-the-art methods.

</details>


### [61] [AUGUSTUS: An LLM-Driven Multimodal Agent System with Contextualized User Memory](https://arxiv.org/abs/2510.15261)
*Jitesh Jain,Shubham Maheshwari,Ning Yu,Wen-mei Hwu,Humphrey Shi*

Main category: cs.AI

TL;DR: AUGUSTUS是一个多模态智能体系统，采用基于认知科学人类记忆理念的图结构多模态上下文记忆，通过语义标签和上下文关联实现概念驱动检索，在ImageNet分类和MSC基准测试中表现优于传统多模态RAG方法。


<details>
  <summary>Details</summary>
Motivation: 现有智能体系统主要存储文本信息，忽略了多模态信号的重要性。受人类记忆多模态特性的启发，希望开发一个更符合认知科学原理的多模态记忆系统。

Method: 系统包含编码、存储、检索和行动四个循环阶段。不同于使用向量数据库的传统方法，将信息概念化为语义标签，并与上下文关联存储在图结构的多模态上下文记忆中，实现高效的概念驱动检索。

Result: 在ImageNet分类任务中比传统多模态RAG方法快3.5倍，在MSC基准测试中表现优于MemGPT。

Conclusion: 基于人类记忆认知原理的多模态记忆系统能够有效提升智能体的性能，证明了多模态信号在记忆系统中的重要性。

Abstract: Riding on the success of LLMs with retrieval-augmented generation (RAG),
there has been a growing interest in augmenting agent systems with external
memory databases. However, the existing systems focus on storing text
information in their memory, ignoring the importance of multimodal signals.
Motivated by the multimodal nature of human memory, we present AUGUSTUS, a
multimodal agent system aligned with the ideas of human memory in cognitive
science. Technically, our system consists of 4 stages connected in a loop: (i)
encode: understanding the inputs; (ii) store in memory: saving important
information; (iii) retrieve: searching for relevant context from memory; and
(iv) act: perform the task. Unlike existing systems that use vector databases,
we propose conceptualizing information into semantic tags and associating the
tags with their context to store them in a graph-structured multimodal
contextual memory for efficient concept-driven retrieval. Our system
outperforms the traditional multimodal RAG approach while being 3.5 times
faster for ImageNet classification and outperforming MemGPT on the MSC
benchmark.

</details>


### [62] [WebGen-V Bench: Structured Representation for Enhancing Visual Design in LLM-based Web Generation and Evaluation](https://arxiv.org/abs/2510.15306)
*Kuang-Da Wang,Zhao Wang,Yotaro Shimose,Wei-Yao Wang,Shingo Takamatsu*

Main category: cs.AI

TL;DR: WebGen-V是一个用于指令到HTML生成的新基准和框架，通过三个关键创新提升数据质量和评估粒度：无限制的代理爬虫框架、结构化分节数据表示、以及分节多模态评估协议。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在编码和多模态理解方面的进展，需要更高质量的基准来评估指令到HTML生成任务，现有方法在数据质量和评估粒度上存在不足。

Method: 提出三个创新：1) 无限制可扩展的代理爬虫框架持续收集真实网页；2) 结构化分节数据表示整合元数据、局部UI截图和JSON格式的文本图像资源；3) 分节多模态评估协议对齐文本、布局和视觉组件。

Result: 通过最先进的LLM和消融实验验证了结构化数据和分节评估的有效性，以及每个组件的贡献。

Conclusion: WebGen-V是首个实现高粒度代理爬虫和评估的指令到HTML生成工作，提供了从真实数据采集到结构化多模态评估的统一流程。

Abstract: Witnessed by the recent advancements on leveraging LLM for coding and
multimodal understanding, we present WebGen-V, a new benchmark and framework
for instruction-to-HTML generation that enhances both data quality and
evaluation granularity. WebGen-V contributes three key innovations: (1) an
unbounded and extensible agentic crawling framework that continuously collects
real-world webpages and can leveraged to augment existing benchmarks; (2) a
structured, section-wise data representation that integrates metadata,
localized UI screenshots, and JSON-formatted text and image assets, explicit
alignment between content, layout, and visual components for detailed
multimodal supervision; and (3) a section-level multimodal evaluation protocol
aligning text, layout, and visuals for high-granularity assessment. Experiments
with state-of-the-art LLMs and ablation studies validate the effectiveness of
our structured data and section-wise evaluation, as well as the contribution of
each component. To the best of our knowledge, WebGen-V is the first work to
enable high-granularity agentic crawling and evaluation for instruction-to-HTML
generation, providing a unified pipeline from real-world data acquisition and
webpage generation to structured multimodal assessment.

</details>


### [63] [VERITAS: Leveraging Vision Priors and Expert Fusion to Improve Multimodal Data](https://arxiv.org/abs/2510.15317)
*Tingqiao Xu,Ziru Zeng,Jiayu Chen*

Main category: cs.AI

TL;DR: VERITAS是一个通过整合视觉先验和多模态模型来提升监督微调数据质量的系统化流程，能有效减少事实错误和幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型的监督微调数据质量不足，常出现事实错误和幻觉问题，主要原因是视觉感知能力不足。

Method: 利用视觉识别模型和OCR系统提取结构化视觉先验，结合三个先进LMM模型评估原始答案，通过统计融合得到高置信度共识分数，训练轻量级批评模型，最终选择最高分答案作为精炼结果。

Result: 在六个多模态基准测试中，使用VERITAS处理数据微调的模型性能优于使用原始数据的模型，尤其在文本丰富和细粒度推理任务中表现突出。

Conclusion: VERITAS能有效提升多模态数据质量，其批评模型在保持高效的同时具备与先进LMM相当的能力，为多模态数据优化研究提供了重要工具。

Abstract: The quality of supervised fine-tuning (SFT) data is crucial for the
performance of large multimodal models (LMMs), yet current data enhancement
methods often suffer from factual errors and hallucinations due to inadequate
visual perception. To address this challenge, we propose VERITAS, a pipeline
that systematically integrates vision priors and multiple state-of-the-art LMMs
with statistical methods to enhance SFT data quality. VERITAS leverages visual
recognition models (RAM++) and OCR systems (PP-OCRv4) to extract structured
vision priors, which are combined with images, questions, and answers. Three
LMMs (GPT-4o, Gemini-2.5-Pro, Doubao-1.5-pro) evaluate the original answers,
providing critique rationales and scores that are statistically fused into a
high-confidence consensus score serving as ground truth. Using this consensus,
we train a lightweight critic model via Group Relative Policy Optimization
(GRPO), enhancing reasoning capabilities efficiently. Each LMM then refines the
original answers based on the critiques, generating new candidate answers; we
select the highest-scoring one as the final refined answer. Experiments across
six multimodal benchmarks demonstrate that models fine-tuned with data
processed by VERITAS consistently outperform those using raw data, particularly
in text-rich and fine-grained reasoning tasks. Our critic model exhibits
enhanced capability comparable to state-of-the-art LMMs while being
significantly more efficient. We release our pipeline, datasets, and model
checkpoints to advance research in multimodal data optimization.

</details>


### [64] [Towards Flash Thinking via Decoupled Advantage Policy Optimization](https://arxiv.org/abs/2510.15374)
*Zezhong Tan,Hang Gao,Xinhong Ma,Feng Zhang,Ziqiang Dong*

Main category: cs.AI

TL;DR: DEPO是一个新的强化学习框架，通过解耦优势算法、难度感知长度惩罚和优势裁剪方法，显著减少大推理模型中的低效推理，在保持准确性的同时将序列长度减少39%。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习算法虽然提高了模型准确性，但存在响应过长和过度思考问题，导致推理延迟和计算消耗增加，特别是对于只需要最小推理的简单任务。

Method: DEPO框架包含三个核心组件：创新的优势解耦算法指导模型减少低效token；难度感知长度惩罚降低模型响应总长度；优势裁剪方法防止策略优化中的偏差。

Result: 在DeepSeek-Distill-Qwen-7B和1.5B模型上的实验表明，DEPO将序列长度显著减少39%，减少了低效token中的过度推理路径，同时在整体准确性上优于基础模型。

Conclusion: DEPO框架有效解决了大推理模型中的低效推理问题，在减少响应长度的同时保持或提升了模型性能，为优化推理效率提供了有效方案。

Abstract: Recent Large Reasoning Models (LRMs) have achieved remarkable performance in
solving complex problems via supervised fine-tuning (SFT) and reinforcement
learning (RL). Although existing RL algorithms significantly enhance model
accuracy, they still suffer from excessively lengthy responses and overthinking
issues, resulting in increased inference latency and computational consumption,
especially for simple tasks that require minimal reasoning. To address this, we
propose a novel RL framework, DEPO, to reduce inefficient reasoning for models.
Our method mainly consists of three core components: (1) an innovative
advantage decoupled algorithm to guide model reduction of inefficient tokens;
(2) a difficulty-aware length penalty to lower the overall length of model
responses; (3) an advantage clipping method to prevent bias in policy
optimization. In our experiments, applied to DeepSeek-Distill-Qwen-7B and
DeepSeek-Distill-Qwen-1.5B as base models, DEPO achieves a significant
reduction in sequence length by 39% and reduces excessive reasoning paths in
inefficient tokens, while outperforming the base model in overall accuracy.

</details>


### [65] [Advancing Routing-Awareness in Analog ICs Floorplanning](https://arxiv.org/abs/2510.15387)
*Davide Basso,Luca Bortolussi,Mirjana Videnovic-Misic,Husni Habal*

Main category: cs.AI

TL;DR: 基于强化学习和关系图卷积神经网络的自动布局引擎，通过提高网格分辨率和精确引脚信息集成，结合动态布线资源估计技术，实现更可布线的布局生成。


<details>
  <summary>Details</summary>
Motivation: 模拟集成电路布局中机器学习技术应用受限，主要由于电气和特定问题约束的严格要求，以及布局规划和布线步骤的相互依赖性。需要解决布局工程师对现成布线感知布局解决方案的需求。

Method: 开发基于强化学习和关系图卷积神经网络的自动布局引擎，专门用于条件化布局生成以实现更可布线结果。采用增加网格分辨率和精确引脚信息集成，结合动态布线资源估计技术。

Result: 在模拟环境中分析布局布线效果，与过去基于学习的最先进技术相比，实现了13.8%的死区减少、40.6%的线长减少和73.4%的布线成功率提升。

Conclusion: 该方法能够平衡布线和面积效率，最终达到工业标准，为模拟集成电路布局提供了有效的布线感知解决方案。

Abstract: The adoption of machine learning-based techniques for analog integrated
circuit layout, unlike its digital counterpart, has been limited by the
stringent requirements imposed by electric and problem-specific constraints,
along with the interdependence of floorplanning and routing steps. In this
work, we address a prevalent concern among layout engineers regarding the need
for readily available routing-aware floorplanning solutions. To this extent, we
develop an automatic floorplanning engine based on reinforcement learning and
relational graph convolutional neural network specifically tailored to
condition the floorplan generation towards more routable outcomes. A
combination of increased grid resolution and precise pin information
integration, along with a dynamic routing resource estimation technique, allows
balancing routing and area efficiency, eventually meeting industrial standards.
When analyzing the place and route effectiveness in a simulated environment,
the proposed approach achieves a 13.8% reduction in dead space, a 40.6%
reduction in wirelength and a 73.4% increase in routing success when compared
to past learning-based state-of-the-art techniques.

</details>


### [66] [Corrigibility Transformation: Constructing Goals That Accept Updates](https://arxiv.org/abs/2510.15395)
*Rubi Hudson*

Main category: cs.AI

TL;DR: 本文提出了可修正性（corrigibility）的概念，即AI目标不会激励其避免目标更新或关闭。作者引入了一种转换方法，可以构建任何可修正目标的修正版本，且不牺牲性能。


<details>
  <summary>Details</summary>
Motivation: AI在训练过程中可能会抵抗目标更新，因为部分学习的目标会激励AI继续追求这些目标。可修正性对于训练收敛、纠正错误和适应人类偏好变化至关重要，但目前缺乏既具有可修正性又具有竞争力的目标规范。

Method: 通过短视地获取在无成本阻止更新情况下的奖励预测，然后根据这些预测确定接受更新时的奖励，构建可修正目标版本。该方法可递归扩展到修正代理创建的新代理，并防止代理故意修改其目标。

Result: 两个网格世界实验表明，这些可修正目标可以有效学习，并产生期望的行为。

Conclusion: 该研究提供了一种构建可修正AI目标的方法，既保持了性能又确保了安全性，为AI安全提供了重要工具。

Abstract: For an AI's training process to successfully impart a desired goal, it is
important that the AI does not attempt to resist the training. However,
partially learned goals will often incentivize an AI to avoid further goal
updates, as most goals are better achieved by an AI continuing to pursue them.
We say that a goal is corrigible if it does not incentivize taking actions that
avoid proper goal updates or shutdown. In addition to convergence in training,
corrigibility also allows for correcting mistakes and changes in human
preferences, which makes it a crucial safety property. Despite this, the
existing literature does not include specifications for goals that are both
corrigible and competitive with non-corrigible alternatives. We provide a
formal definition for corrigibility, then introduce a transformation that
constructs a corrigible version of any goal that can be made corrigible,
without sacrificing performance. This is done by myopically eliciting
predictions of reward conditional on costlessly preventing updates, which then
also determine the reward when updates are accepted. The transformation can be
modified to recursively extend corrigibility to any new agents created by
corrigible agents, and to prevent agents from deliberately modifying their
goals. Two gridworld experiments demonstrate that these corrigible goals can be
learned effectively, and that they lead to the desired behavior.

</details>


### [67] [MARS: Reinforcing Multi-Agent Reasoning of LLMs through Self-Play in Strategic Games](https://arxiv.org/abs/2510.15414)
*Huining Yuan,Zelai Xu,Zheyue Tan,Xiangmin Yi,Mo Guang,Kaiwen Long,Haojia Hui,Boxun Li,Xinlei Chen,Bo Zhao,Xiao-Ping Zhang,Chao Yu,Yu Wang*

Main category: cs.AI

TL;DR: MARS是一个端到端的强化学习框架，通过自博弈训练LLMs在多智能体系统中进行推理，在合作和竞争游戏中都能提升性能，并能泛化到未见过的游戏和推理基准测试中。


<details>
  <summary>Details</summary>
Motivation: 虽然强化学习在单智能体任务中能有效增强推理能力，但在多回合、多智能体场景中的扩展仍未被充分探索，主要面临长期信用分配和智能体特定优势估计的挑战。

Method: MARS框架包含回合级优势估计器来对齐每个交互的学习信号以进行信用分配，以及智能体特定优势归一化来稳定多智能体训练。通过自博弈在合作和竞争游戏中学习。

Result: 从Qwen3-4B训练的MARS智能体在未见过的游戏中性能提升达28.7%，在推理基准测试中，集成到领先多智能体系统后，在AIME上提升10.0%，在GPQA-Diamond上提升12.5%。

Conclusion: 通过自博弈在策略游戏中进行端到端RL训练是开发LLMs可泛化多智能体推理能力的有效方法。

Abstract: Developing Large Language Models (LLMs) to cooperate and compete effectively
within multi-agent systems is a critical step towards more advanced
intelligence. While reinforcement learning (RL) has proven effective for
enhancing reasoning in single-agent tasks, its extension to multi-turn,
multi-agent scenarios remains underexplored due to the challenges of
long-horizon credit assignment and agent-specific advantage estimation. To
address these challenges, we introduce MARS, an end-to-end RL framework that
incentivizes Multi-Agent Reasoning of LLMs through Self-play in both
cooperative and competitive games. MARS features a turn-level advantage
estimator that aligns learning signals with each interaction for credit
assignment, and an agent-specific advantage normalization to stabilize
multi-agent training. By learning with self-play across cooperative and
competitive games, the MARS agent trained from Qwen3-4B develops strong
strategic abilities that generalize to held-out games with up to 28.7%
performance improvements. More importantly, the capability acquired through
self-play generalizes beyond games, yielding consistent performance gains of
multi-agent systems in reasoning benchmarks. When integrated into leading
multi-agent systems, our MARS agent achieves significant performance gains of
10.0% on AIME and 12.5% on GPQA-Diamond. These results establish end-to-end RL
training with self-play in strategic games as a powerful approach for
developing generalizable multi-agent reasoning capabilities in LLMs. Our code
and models are publicly available at https://github.com/thu-nics/MARS.

</details>


### [68] [Adaptive Minds: Empowering Agents with LoRA-as-Tools](https://arxiv.org/abs/2510.15416)
*Pavan C Shekar,Ashwanth Krishnan*

Main category: cs.AI

TL;DR: Adaptive Minds是一个将LoRA适配器作为领域专用工具的智能体系统，通过让基础LLM作为语义路由器动态选择最相关的LoRA工具，实现按需在不同领域专家间无缝切换。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法依赖单一微调模型或基于规则的固定路由的局限性，结合多智能体编排的灵活性和参数高效微调的高效性，提供准确、专业化的响应同时保持对话能力。

Method: 使用LangGraph进行工作流管理，让基础LLM分析每个查询并动态选择最相关的LoRA适配器作为领域工具，支持API和Web界面。

Result: 构建了一个可扩展的开源系统，能够提供领域自适应的AI助手服务，在保持对话流畅性的同时实现专业化响应。

Conclusion: Adaptive Minds提供了一个可扩展且可扩展的领域自适应AI助手基础框架，成功结合了多智能体编排的灵活性和参数高效微调的优势。

Abstract: We present Adaptive Minds, an agentic system that treats LoRA adapters as
domain-specific tools. Instead of relying on a single fine-tuned model or rigid
rule-based routing, our approach empowers the base LLM itself to act as a
semantic router analyzing each query and dynamically selecting the most
relevant LoRA tool. This enables the agent to seamlessly switch between
different domain experts on demand. By combining the flexibility of multi-agent
orchestration with the efficiency of parameter-efficient fine-tuning, Adaptive
Minds delivers accurate, specialized responses while preserving conversational
ability. The system is built with LangGraph for workflow management, supports
both API and web interfaces, and is fully open source, providing a scalable and
extensible foundation for domain-adaptive AI assistance.

</details>


### [69] [Taming the Judge: Deconflicting AI Feedback for Stable Reinforcement Learning](https://arxiv.org/abs/2510.15514)
*Boyin Liu,Zhuo Zhang,Sen Huang,Lipeng Xie,Qingxu Fu,Haoran Chen,LI YU,Tianyi Hu,Zhaoyang Liu,Bolin Ding,Dongbin Zhao*

Main category: cs.AI

TL;DR: 提出了一个检测和解决强化学习中判断不一致性的框架，包括冲突检测率(CDR)指标和去冲突图奖励(DGR)方法，显著提升了训练稳定性和模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在强化学习中面临判断不一致性问题，特别是偏好循环等逻辑一致性问题尚未得到充分解决，这会破坏强化学习的稳定性。

Method: 提出CDR指标量化判断冲突，开发DGR框架从初始判断构建偏好图，将其转换为无冲突的有向无环图(DAG)，生成逻辑一致的奖励信号。

Result: 实验结果表明，该框架相比强基线显著提高了训练稳定性和模型性能。

Conclusion: 逻辑一致性是AI反馈中一个关键且现在可管理的维度，该框架成功解决了判断不一致性问题。

Abstract: However, this method often faces judgment inconsistencies that can
destabilize reinforcement learning. While prior research has focused on the
accuracy of judgments, the critical issue of logical coherence especially
issues such as preference cycles hasn't been fully addressed. To fill this gap,
we introduce a comprehensive framework designed to systematically detect and
resolve these inconsistencies during the reinforcement learning training
process. Our framework includes two main contributions: first, the Conflict
Detection Rate (CDR), a new metric that quantifies judgment conflicts, and
second, Deconflicted Graph Rewards (DGR), a framework that purifies signals by
removing cycles before policy optimization. DGR constructs preference graphs
from the initial judgments, transforms them into conflict-free Directed Acyclic
Graphs (DAGs), and generates a logically coherent reward signal that is
compatible with any policy optimizer. Experimental results show that our
framework significantly enhances training stability and model performance
compared to strong baselines, establishing logical consistency as a crucial and
now manageable dimension of AI feedback.

</details>


### [70] [Hypergraph Contrastive Sensor Fusion for Multimodal Fault Diagnosis in Induction Motors](https://arxiv.org/abs/2510.15547)
*Usman Ali,Ali Zia,Waqas Ali,Umer Ramzan,Abdul Rehman,Muhammad Tayyab Chaudhry,Wei Xiang*

Main category: cs.AI

TL;DR: 提出MM-HCAN多模态超图对比注意力网络，用于电机故障诊断，能同时诊断轴承、定子和转子故障，在真实数据集上达到99.82%准确率，具有强跨域泛化能力和噪声鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以捕捉复杂多模态信号关系，局限于单模态数据或单一故障类型，且在噪声或跨域条件下性能下降。需要一种能同时诊断多种故障的鲁棒解决方案。

Method: MM-HCAN将对比学习集成到专门为多模态传感器融合设计的超图拓扑中，联合建模模态内和模态间依赖关系，超越欧几里得嵌入空间增强泛化能力。

Result: 在三个真实基准测试中，MM-HCAN达到最高99.82%的准确率，表现出强大的跨域泛化能力和噪声鲁棒性。消融研究验证了各组件的贡献。

Conclusion: MM-HCAN为全面多故障诊断提供了可扩展且鲁棒的解决方案，支持工业环境中的预测性维护和延长资产寿命。

Abstract: Reliable induction motor (IM) fault diagnosis is vital for industrial safety
and operational continuity, mitigating costly unplanned downtime. Conventional
approaches often struggle to capture complex multimodal signal relationships,
are constrained to unimodal data or single fault types, and exhibit performance
degradation under noisy or cross-domain conditions. This paper proposes the
Multimodal Hypergraph Contrastive Attention Network (MM-HCAN), a unified
framework for robust fault diagnosis. To the best of our knowledge, MM-HCAN is
the first to integrate contrastive learning within a hypergraph topology
specifically designed for multimodal sensor fusion, enabling the joint
modelling of intra- and inter-modal dependencies and enhancing generalisation
beyond Euclidean embedding spaces. The model facilitates simultaneous diagnosis
of bearing, stator, and rotor faults, addressing the engineering need for
consolidated di- agnostic capabilities. Evaluated on three real-world
benchmarks, MM-HCAN achieves up to 99.82% accuracy with strong cross-domain
generalisation and resilience to noise, demonstrating its suitability for
real-world deployment. An ablation study validates the contribution of each
component. MM-HCAN provides a scalable and robust solution for comprehensive
multi-fault diagnosis, supporting predictive maintenance and extended asset
longevity in industrial environments.

</details>


### [71] [JudgeSQL: Reasoning over SQL Candidates with Weighted Consensus Tournament](https://arxiv.org/abs/2510.15560)
*Jiayuan Bai,Xuan-guang Pan,Chongyang Tao,Shuai Ma*

Main category: cs.AI

TL;DR: JudgeSQL是一个用于Text-to-SQL任务中SQL候选查询选择的框架，通过结构化推理和加权共识锦标赛机制解决现有选择方法的局限性。


<details>
  <summary>Details</summary>
Motivation: Text-to-SQL任务面临语义歧义和复杂组合推理的挑战，现有选择方法如自一致性或最佳N解码仅提供浅层信号，容易导致不一致评分、脆弱推理链和无法捕捉细微语义差异。

Method: 开发基于推理的SQL判断模型，通过强化学习在可验证奖励指导下提炼推理轨迹；构建加权共识锦标赛机制，整合显式推理偏好和隐式生成器置信度。

Result: 在BIRD基准测试上的广泛实验表明，JudgeSQL展现出优越的SQL判断能力、良好的跨尺度泛化能力以及对生成器容量的鲁棒性。

Conclusion: JudgeSQL通过结构化推理和加权共识锦标赛重新定义了SQL候选选择，提供了更可靠和高效的查询选择方案。

Abstract: Text-to-SQL is a pivotal task that bridges natural language understanding and
structured data access, yet it remains fundamentally challenging due to
semantic ambiguity and complex compositional reasoning. While large language
models (LLMs) have greatly advanced SQL generation though prompting, supervised
finetuning and reinforced tuning, the shift toward test-time scaling exposes a
new bottleneck: selecting the correct query from a diverse candidate pool.
Existing selection approaches, such as self-consistency or best-of-$N$
decoding, provide only shallow signals, making them prone to inconsistent
scoring, fragile reasoning chains, and a failure to capture fine-grained
semantic distinctions between closely related SQL candidates. To this end, we
introduce JudgeSQL, a principled framework that redefines SQL candidate
selection through structured reasoning and weighted consensus tournament
mechanism. JudgeSQL develops a reasoning-based SQL judge model that distills
reasoning traces with reinforcement learning guided by verifiable rewards,
enabling accurate and interpretable judgments. Building on this, a weighted
consensus tournament integrates explicit reasoning preferences with implicit
generator confidence, yielding selections that are both more reliable and more
efficient. Extensive experiments on the BIRD benchmark demonstrate that
JudgeSQL exhibits superior SQL judgment capabilities and good cross-scale
generalization and robustness to generator capacity.

</details>


### [72] [Context-aware deep learning using individualized prior information reduces false positives in disease risk prediction and longitudinal health assessment](https://arxiv.org/abs/2510.15591)
*Lavanya Umapathy,Patricia M Johnson,Tarun Dutt,Angela Tong,Madhur Nayan,Hersh Chandarana,Daniel K Sodickson*

Main category: cs.AI

TL;DR: 开发了一个机器学习框架，通过整合患者历史就诊信息来改进健康监测，特别是在就诊次数有限且频率不固定的情况下。该模型首先基于最近就诊数据评估初始疾病风险，然后利用历史影像和临床生物标志物信息进行精炼。


<details>
  <summary>Details</summary>
Motivation: 医学中的时间背景对于评估患者健康状况随时间变化至关重要。当患者历史就诊次数有限且频率不固定时，如何有效利用这些信息来改善健康监测是一个重要挑战。

Method: 开发了一个两阶段机器学习框架：1）基于最近就诊的医疗数据估计初始疾病风险；2）利用历史影像和临床生物标志物信息精炼风险评估。应用于前列腺癌风险预测，使用了28,342名患者近十年的数据。

Result: 整合历史背景显著提高了特异性同时保持高灵敏度：假阳性率从51%降至33%（整合3次历史影像），进一步降至24%（加入临床数据）。预测5年内风险时，假阳性率从64%降至9%。

Conclusion: 随时间收集的信息提供了相关背景，可显著提高医学风险预测的特异性。对于渐进性疾病，通过背景信息充分降低假阳性率，可为低基线风险人群扩展纵向健康监测项目，实现早期检测和改善健康结果。

Abstract: Temporal context in medicine is valuable in assessing key changes in patient
health over time. We developed a machine learning framework to integrate
diverse context from prior visits to improve health monitoring, especially when
prior visits are limited and their frequency is variable. Our model first
estimates initial risk of disease using medical data from the most recent
patient visit, then refines this assessment using information digested from
previously collected imaging and/or clinical biomarkers. We applied our
framework to prostate cancer (PCa) risk prediction using data from a large
population (28,342 patients, 39,013 magnetic resonance imaging scans, 68,931
blood tests) collected over nearly a decade. For predictions of the risk of
clinically significant PCa at the time of the visit, integrating prior context
directly converted false positives to true negatives, increasing overall
specificity while preserving high sensitivity. False positive rates were
reduced progressively from 51% to 33% when integrating information from up to
three prior imaging examinations, as compared to using data from a single
visit, and were further reduced to 24% when also including additional context
from prior clinical data. For predicting the risk of PCa within five years of
the visit, incorporating prior context reduced false positive rates still
further (64% to 9%). Our findings show that information collected over time
provides relevant context to enhance the specificity of medical risk
prediction. For a wide range of progressive conditions, sufficient reduction of
false positive rates using context could offer a pathway to expand longitudinal
health monitoring programs to large populations with comparatively low baseline
risk of disease, leading to earlier detection and improved health outcomes.

</details>


### [73] [Unleashing Scientific Reasoning for Bio-experimental Protocol Generation via Structured Component-based Reward Mechanism](https://arxiv.org/abs/2510.15600)
*Haoran Sun,Yankai Jiang,Zhenyu Tang,Yaning Pan,Shuang Gu,Zekai Lin,Lilong Wang,Wenjie Lou,Lei Liu,Lei Bai,Xiaosong Wang*

Main category: cs.AI

TL;DR: 本文提出了SciRecipe数据集和Thoth模型，通过"Sketch-and-Fill"范式和结构化奖励机制，显著提升了科学实验协议生成的完整性和一致性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型生成的科学实验协议往往不完整或不一致，限制了其在可重复科学研究中的实用性。

Method: 引入SciRecipe数据集（12K结构化协议），提出"Sketch-and-Fill"范式分离分析、结构和表达，采用结构化组件奖励机制评估步骤粒度、动作顺序和语义保真度，并通过分阶段的知识到行动过程训练Thoth模型。

Result: Thoth在多个基准测试中持续超越专有和开源LLM，在步骤对齐、逻辑排序和语义准确性方面实现显著改进。

Conclusion: 该方法为构建可靠的科学助手铺平了道路，能够有效连接知识与实验执行。

Abstract: The foundation of reproducible science lies in protocols that are precise,
logically ordered, and executable. The autonomous generation of these protocols
through natural language queries could greatly improve the efficiency of the
reproduction process. However, current leading large language models (LLMs)
often generate incomplete or inconsistent protocols, limiting their utility. To
address this limitation, we first introduce SciRecipe, a large-scale dataset of
over 12K structured protocols spanning 27 biological subfields and encompassing
both comprehension and problem-solving tasks. To further improve protocol
generation, we propose the "Sketch-and-Fill" paradigm, which separates
analysis, structuring, and expression to ensure each step is explicit and
verifiable. Complementing this, the structured component-based reward mechanism
evaluates step granularity, action order, and semantic fidelity, aligning model
optimization with experimental reliability. Building on these components, we
develop Thoth, trained through a staged Knowledge-to-Action process that
progresses from knowledge acquisition to operational reasoning and ultimately
to robust, executable protocol generation. Across multiple benchmarks, Thoth
consistently surpasses both proprietary and open-source LLMs, achieving
significant improvements in step alignment, logical sequencing, and semantic
accuracy. Our approach paves the way for reliable scientific assistants that
bridge knowledge with experimental execution. All data, code, and models will
be released publicly.

</details>


### [74] [Build Your Personalized Research Group: A Multiagent Framework for Continual and Interactive Science Automation](https://arxiv.org/abs/2510.15624)
*Ed Li,Junyu Ren,Xintian Pan,Cat Yan,Chuanhao Li,Dirk Bergemann,Zhuoran Yang*

Main category: cs.AI

TL;DR: 提出了freephdlabor框架，这是一个开源的智能体系统，通过动态工作流和模块化架构实现自适应科学研究自动化


<details>
  <summary>Details</summary>
Motivation: 解决现有科学发现自动化系统的两个根本限制：僵化的预编程工作流无法适应中间发现，以及不充分的上下文管理阻碍长期研究

Method: 采用完全动态的工作流设计，由实时智能体推理决定；模块化架构允许用户定制、添加或移除智能体；包含自动上下文压缩、基于工作空间的通信、跨会话内存持久化和非阻塞人工干预机制

Result: 将自动化研究从孤立的单次尝试转变为持续的研究计划，能够系统性地建立在先前探索基础上并整合人类反馈

Conclusion: 通过提供构建可定制合作科学家系统的架构原则和实际实现，促进自动化研究在科学领域的更广泛采用，使从业者能够部署交互式多智能体系统进行端到端研究

Abstract: The automation of scientific discovery represents a critical milestone in
Artificial Intelligence (AI) research. However, existing agentic systems for
science suffer from two fundamental limitations: rigid, pre-programmed
workflows that cannot adapt to intermediate findings, and inadequate context
management that hinders long-horizon research. We present
\texttt{freephdlabor}, an open-source multiagent framework featuring
\textit{fully dynamic workflows} determined by real-time agent reasoning and a
\coloremph{\textit{modular architecture}} enabling seamless customization --
users can modify, add, or remove agents to address domain-specific
requirements. The framework provides comprehensive infrastructure including
\textit{automatic context compaction}, \textit{workspace-based communication}
to prevent information degradation, \textit{memory persistence} across
sessions, and \textit{non-blocking human intervention} mechanisms. These
features collectively transform automated research from isolated, single-run
attempts into \textit{continual research programs} that build systematically on
prior explorations and incorporate human feedback. By providing both the
architectural principles and practical implementation for building customizable
co-scientist systems, this work aims to facilitate broader adoption of
automated research across scientific domains, enabling practitioners to deploy
interactive multiagent systems that autonomously conduct end-to-end research --
from ideation through experimentation to publication-ready manuscripts.

</details>


### [75] [Direct Preference Optimization with Unobserved Preference Heterogeneity: The Necessity of Ternary Preferences](https://arxiv.org/abs/2510.15716)
*Keertana Chidambaram,Karthik Vinary Seetharaman,Vasilis Syrgkanis*

Main category: cs.AI

TL;DR: 本文提出了改进RLHF的方法，通过引入排名反馈和考虑用户异质性偏好，解决了传统方法中二元比较的局限性和统一用户偏好的假设问题。


<details>
  <summary>Details</summary>
Motivation: 传统RLHF和DPO方法假设统一的标注者偏好并依赖二元比较，忽视了人类评估者的多样性和成对反馈的局限性。

Method: 1) 连接偏好学习与计量经济学文献，证明二元比较不足以识别潜在用户偏好；2) 开发EM-DPO方法发现潜在标注者类型并训练混合LLM；3) 提出基于最小最大遗憾公平准则的聚合算法。

Result: 建立了生成模型对齐中公平性和个性化的理论和算法框架，确保对多样化用户的公平性能保证。

Conclusion: 通过排名反馈和异质性偏好处理，为生成模型对齐提供了更公平和个性化的解决方案。

Abstract: Reinforcement Learning from Human Feedback (RLHF) has become central to
aligning large language models with human values, typically by first learning a
reward model from preference data which is then used to update the model with
reinforcement learning. Recent alternatives such as Direct Preference
Optimization (DPO) simplify this pipeline by directly optimizing on
preferences. However, both approaches often assume uniform annotator
preferences and rely on binary comparisons, overlooking two key limitations:
the diversity of human evaluators and the limitations of pairwise feedback. In
this work, we address both these issues. First, we connect preference learning
in RLHF with the econometrics literature and show that binary comparisons are
insufficient for identifying latent user preferences from finite user data and
infinite users, while (even incomplete) rankings over three or more responses
ensure identifiability. Second, we introduce methods to incorporate
heterogeneous preferences into alignment algorithms. We develop an
Expectation-Maximization adaptation of DPO that discovers latent annotator
types and trains a mixture of LLMs accordingly. Then we propose an aggregation
algorithm using a min-max regret fairness criterion to produce a single
generative policy with equitable performance guarantees. Together, these
contributions establish a theoretical and algorithmic framework for fairness
and personalization for diverse users in generative model alignment.

</details>


### [76] [Invoice Information Extraction: Methods and Performance Evaluation](https://arxiv.org/abs/2510.15727)
*Sai Yashwant,Anurag Dubey,Praneeth Paikray,Gantala Thulsiram*

Main category: cs.AI

TL;DR: 本文提出了从发票文档中提取结构化信息的方法，并建立了一套评估指标来评估提取数据的准确性。


<details>
  <summary>Details</summary>
Motivation: 需要标准化评估发票信息提取方法，比较不同方法的性能并识别各字段提取的优缺点。

Method: 使用Docling和LlamaCloud服务预处理扫描或数字发票，提取关键字段如发票号、日期、总金额和供应商详情。

Result: 建立了包含字段级精度、一致性检查失败率和精确匹配准确率的稳健评估框架。

Conclusion: 提出的评估指标为比较不同提取方法提供了标准化方式，并能突出显示字段特定性能的强弱项。

Abstract: This paper presents methods for extracting structured information from
invoice documents and proposes a set of evaluation metrics (EM) to assess the
accuracy of the extracted data against annotated ground truth. The approach
involves pre-processing scanned or digital invoices, applying Docling and
LlamaCloud Services to identify and extract key fields such as invoice number,
date, total amount, and vendor details. To ensure the reliability of the
extraction process, we establish a robust evaluation framework comprising
field-level precision, consistency check failures, and exact match accuracy.
The proposed metrics provide a standardized way to compare different extraction
methods and highlight strengths and weaknesses in field-specific performance.

</details>


### [77] [AURA: An Agent Autonomy Risk Assessment Framework](https://arxiv.org/abs/2510.15739)
*Lorenzo Satta Chiris,Ayush Mishra*

Main category: cs.AI

TL;DR: AURA是一个统一的框架，用于检测、量化和缓解自主AI代理的风险，采用gamma风险评分方法，支持人机协同监督和自主风险评估。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI代理系统在组织中日益普及，对齐、治理和风险管理方面的持续挑战阻碍了大规模部署。

Method: AURA引入基于gamma的风险评分方法，平衡评估准确性与计算效率，提供交互式流程来评估和缓解AI代理风险，支持人机协同监督和代理间通信机制。

Result: 该框架实现了与现有协议和工具的互操作性，支持自主风险评估，为大规模可治理的AI代理部署提供关键支持。

Conclusion: AURA支持负责任和透明的AI代理采用，在平衡计算资源的同时提供强大的风险检测和缓解能力，是企业环境中大规模可治理AI代理的关键推动者。

Abstract: As autonomous agentic AI systems see increasing adoption across
organisations, persistent challenges in alignment, governance, and risk
management threaten to impede deployment at scale. We present AURA (Agent
aUtonomy Risk Assessment), a unified framework designed to detect, quantify,
and mitigate risks arising from agentic AI. Building on recent research and
practical deployments, AURA introduces a gamma-based risk scoring methodology
that balances risk assessment accuracy with computational efficiency and
practical considerations. AURA provides an interactive process to score,
evaluate and mitigate the risks of running one or multiple AI Agents,
synchronously or asynchronously (autonomously). The framework is engineered for
Human-in-the-Loop (HITL) oversight and presents Agent-to-Human (A2H)
communication mechanisms, allowing for seamless integration with agentic
systems for autonomous self-assessment, rendering it interoperable with
established protocols (MCP and A2A) and tools. AURA supports a responsible and
transparent adoption of agentic AI and provides robust risk detection and
mitigation while balancing computational resources, positioning it as a
critical enabler for large-scale, governable agentic AI in enterprise
environments.

</details>


### [78] [Towards Relaxed Multimodal Inputs for Gait-based Parkinson's Disease Assessment](https://arxiv.org/abs/2510.15748)
*Minlin Zeng,Zhipeng Zhou,Yang Qiu,Zhiqi Shen*

Main category: cs.AI

TL;DR: 提出了首个将多模态学习建模为多目标优化问题的帕金森病评估系统TRIP，解决了训练时需同步所有模态和推理时依赖所有模态的限制，在异步和同步设置下均取得最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态帕金森病评估中的两个主要限制：(1) 训练时需要同步所有模态，(2) 推理时依赖所有模态，这些限制了实际应用。

Method: 将多模态学习建模为多目标优化问题，引入基于边界的类别重平衡策略来处理模态内不平衡问题，支持训练和推理时更灵活的模态要求。

Result: 在三个公共数据集上，异步设置下比最佳基线提升16.48、6.89和11.55个百分点，同步设置下提升4.86和2.30个百分点，达到最先进性能。

Conclusion: TRIP框架通过多目标优化方法有效解决了多模态帕金森病评估中的模态同步和依赖问题，具有出色的有效性和适应性。

Abstract: Parkinson's disease assessment has garnered growing interest in recent years,
particularly with the advent of sensor data and machine learning techniques.
Among these, multimodal approaches have demonstrated strong performance by
effectively integrating complementary information from various data sources.
However, two major limitations hinder their practical application: (1) the need
to synchronize all modalities during training, and (2) the dependence on all
modalities during inference. To address these issues, we propose the first
Parkinson's assessment system that formulates multimodal learning as a
multi-objective optimization (MOO) problem. This not only allows for more
flexible modality requirements during both training and inference, but also
handles modality collapse issue during multimodal information fusion. In
addition, to mitigate the imbalance within individual modalities, we introduce
a margin-based class rebalancing strategy to enhance category learning. We
conduct extensive experiments on three public datasets under both synchronous
and asynchronous settings. The results show that our framework-Towards Relaxed
InPuts (TRIP)-achieves state-of-the-art performance, outperforming the best
baselines by 16.48, 6.89, and 11.55 percentage points in the asynchronous
setting, and by 4.86 and 2.30 percentage points in the synchronous setting,
highlighting its effectiveness and adaptability.

</details>


### [79] [Preliminary Quantitative Study on Explainability and Trust in AI Systems](https://arxiv.org/abs/2510.15769)
*Allen Daniel Sunny*

Main category: cs.AI

TL;DR: 该研究通过实验设计探讨了AI系统的可解释性与用户信任之间的关系，发现交互式解释能增强用户参与度和信任度。


<details>
  <summary>Details</summary>
Motivation: 随着GPT-4等大型AI模型在关键领域的部署，对AI系统的信任和透明度问题日益紧迫。

Method: 使用基于网络的贷款审批模拟实验，比较不同类型的解释（从基本特征重要性到交互式反事实）对用户信任的影响。

Result: 交互性增强了用户参与度和信心，解释的清晰度和相关性是信任的关键决定因素。

Conclusion: 研究为人本可解释AI领域提供了实证证据，强调可解释性设计对用户感知的可测量影响。

Abstract: Large-scale AI models such as GPT-4 have accelerated the deployment of
artificial intelligence across critical domains including law, healthcare, and
finance, raising urgent questions about trust and transparency. This study
investigates the relationship between explainability and user trust in AI
systems through a quantitative experimental design. Using an interactive,
web-based loan approval simulation, we compare how different types of
explanations, ranging from basic feature importance to interactive
counterfactuals influence perceived trust. Results suggest that interactivity
enhances both user engagement and confidence, and that the clarity and
relevance of explanations are key determinants of trust. These findings
contribute empirical evidence to the growing field of human-centered
explainable AI, highlighting measurable effects of explainability design on
user perception

</details>


### [80] [Self-evolving expertise in complex non-verifiable subject domains: dialogue as implicit meta-RL](https://arxiv.org/abs/2510.15772)
*Richard M. Bailey*

Main category: cs.AI

TL;DR: 提出了Dialectica框架，通过结构化对话、记忆、自我反思和策略约束的上下文编辑，使AI代理在复杂问题中发展专业知识。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在处理复杂多维度问题（如正义框架、环境污染等）时缺乏通过经验发展专业知识的内生机制的问题。

Method: 使用Dialectica框架，让代理在定义的主题上进行结构化对话，结合记忆、自我反思和策略约束的上下文编辑，将讨论视为隐式元强化学习过程。

Result: 实验显示，在对话中启用基于反思的上下文编辑的代理在Elo分数、标准化Bradley-Terry-Davidson能力和AlphaRank质量上优于基线版本。

Conclusion: 对话驱动的上下文演化是在开放不可验证领域中实现目标专业知识放大的实用路径。

Abstract: So-called `wicked problems', those involving complex multi-dimensional
settings, non-verifiable outcomes, heterogeneous impacts and a lack of single
objectively correct answers, have plagued humans throughout history. Modern
examples include decisions over justice frameworks, solving environmental
pollution, planning for pandemic resilience and food security. The use of
state-of-the-art artificial intelligence systems (notably Large Language
Model-based agents) collaborating with humans on solving such problems is being
actively explored. While the abilities of LLMs can be improved by, for example,
fine-tuning, hand-crafted system prompts and scaffolding with external tools,
LLMs lack endogenous mechanisms to develop expertise through experience in such
settings. This work address this gap with Dialectica, a framework where agents
engage in structured dialogue on defined topics, augmented by memory,
self-reflection, and policy-constrained context editing. Formally, discussion
is viewed as an implicit meta-reinforcement learning process. The
`dialogue-trained' agents are evaluated post-hoc using judged pairwise
comparisons of elicited responses. Across two model architectures (locally run
Qwen3:30b and OpenAI's o4-mini) results show that enabling reflection-based
context editing during discussion produces agents which dominate their baseline
counterparts on Elo scores, normalized Bradley-Terry-Davidson ability, and
AlphaRank mass. The predicted signatures of learning are observed qualitatively
in statement and reflection logs, where reflections identify weaknesses and
reliably shape subsequent statements. Agreement between quantitative and
qualitative evidence supports dialogue-driven context evolution as a practical
path to targeted expertise amplification in open non-verifiable domains.

</details>


### [81] [Demo: Guide-RAG: Evidence-Driven Corpus Curation for Retrieval-Augmented Generation in Long COVID](https://arxiv.org/abs/2510.15782)
*Philip DiGiacomo,Haoyang Wang,Jinrui Fang,Yan Leng,W Michael Brode,Ying Ding*

Main category: cs.AI

TL;DR: 开发了6种RAG语料库配置用于长新冠临床问答，结合临床指南和高质量系统评价的配置表现最佳，提出了Guide-RAG系统和评估框架。


<details>
  <summary>Details</summary>
Motivation: 随着AI聊天机器人在临床医学中的应用增加，为复杂新兴疾病开发有效框架面临挑战，特别是长新冠这类疾病。

Method: 开发并评估了6种RAG语料库配置，从专家精选来源到大规模文献数据库，使用LLM作为评判框架，在忠实性、相关性和全面性指标上评估。

Result: 结合临床指南和高质量系统评价的RAG配置始终优于单一指南方法和大规模文献数据库。

Conclusion: 对于新兴疾病，基于精选二次评价的检索在狭窄共识文档和未过滤原始文献之间提供了最佳平衡，支持临床决策同时避免信息过载和过度简化的指导。

Abstract: As AI chatbots gain adoption in clinical medicine, developing effective
frameworks for complex, emerging diseases presents significant challenges. We
developed and evaluated six Retrieval-Augmented Generation (RAG) corpus
configurations for Long COVID (LC) clinical question answering, ranging from
expert-curated sources to large-scale literature databases. Our evaluation
employed an LLM-as-a-judge framework across faithfulness, relevance, and
comprehensiveness metrics using LongCOVID-CQ, a novel dataset of
expert-generated clinical questions. Our RAG corpus configuration combining
clinical guidelines with high-quality systematic reviews consistently
outperformed both narrow single-guideline approaches and large-scale literature
databases. Our findings suggest that for emerging diseases, retrieval grounded
in curated secondary reviews provides an optimal balance between narrow
consensus documents and unfiltered primary literature, supporting clinical
decision-making while avoiding information overload and oversimplified
guidance. We propose Guide-RAG, a chatbot system and accompanying evaluation
framework that integrates both curated expert knowledge and comprehensive
literature databases to effectively answer LC clinical questions.

</details>


### [82] [PokeeResearch: Effective Deep Research via Reinforcement Learning from AI Feedback and Robust Reasoning Scaffold](https://arxiv.org/abs/2510.15862)
*Yi Wan,Jiuqi Wang,Liam Li,Jinsong Liu,Ruihao Zhu,Zheqing Zhu*

Main category: cs.AI

TL;DR: PokeeResearch-7B是一个7B参数的深度研究代理，通过统一的强化学习框架构建，在10个深度研究基准测试中取得了7B规模代理的最佳性能。


<details>
  <summary>Details</summary>
Motivation: 当前的工具增强大型语言模型在深度研究中存在检索浅层、对齐指标弱和工具使用行为脆弱等限制，需要开发更鲁棒、对齐和可扩展的深度研究代理。

Method: 采用无标注的AI反馈强化学习框架，使用基于LLM的奖励信号优化策略，结合思维链驱动的多调用推理框架，实现自我验证和工具故障自适应恢复。

Result: 在10个流行的深度研究基准测试中，PokeeResearch-7B在7B规模深度研究代理中达到了最先进的性能水平。

Conclusion: 精心设计的强化学习和推理框架可以产生高效、有弹性和研究级的AI代理，模型和推理代码已在MIT许可下开源。

Abstract: Tool-augmented large language models (LLMs) are emerging as deep research
agents, systems that decompose complex queries, retrieve external evidence, and
synthesize grounded responses. Yet current agents remain limited by shallow
retrieval, weak alignment metrics, and brittle tool-use behavior. We introduce
PokeeResearch-7B, a 7B-parameter deep research agent built under a unified
reinforcement learning framework for robustness, alignment, and scalability.
PokeeResearch-7B is trained by an annotation-free Reinforcement Learning from
AI Feedback (RLAIF) framework to optimize policies using LLM-based reward
signals that capture factual accuracy, citation faithfulness, and instruction
adherence. A chain-of-thought-driven multi-call reasoning scaffold further
enhances robustness through self-verification and adaptive recovery from tool
failures. Among 10 popular deep research benchmarks, PokeeResearch-7B achieves
state-of-the-art performance among 7B-scale deep research agents. This
highlights that careful reinforcement learning and reasoning design can produce
efficient, resilient, and research-grade AI agents. The model and inference
code is open-sourced under MIT license at
https://github.com/Pokee-AI/PokeeResearchOSS.

</details>
