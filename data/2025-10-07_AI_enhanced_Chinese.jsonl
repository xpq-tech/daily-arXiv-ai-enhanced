{"id": "2510.03285", "categories": ["cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03285", "abs": "https://arxiv.org/abs/2510.03285", "authors": ["Su Kara", "Fazle Faisal", "Suman Nath"], "title": "WAREX: Web Agent Reliability Evaluation on Existing Benchmarks", "comment": null, "summary": "Recent advances in browser-based LLM agents have shown promise for automating\ntasks ranging from simple form filling to hotel booking or online shopping.\nCurrent benchmarks measure agent performance in controlled environments, such\nas containers or stable networks, where websites behave deterministically.\nHowever, in the real world, users access websites over networks and HTTPS\nconnections that introduce instability from multiple sources: client-side,\nserver-side issues or broader system failures. Moreover, live websites are\nprone to web attacks such Cross-Site Scripting, as well as general site\nmodifications which can cause unexpected or malicious pop-ups or improper\nfunctionality. To address this gap, we present WAREX: Web Agent Reliability\nEvaluation on Existing Benchmarks. We measure the impact of WAREX across three\npopular benchmarks: WebArena, WebVoyager, and REAL. Our experiments show that\nintroducing WAREX leads to significant drops in task success rates,\nhighlighting the limited robustness of state-of-the-art agents.", "AI": {"tldr": "WAREX\u662f\u4e00\u4e2a\u8bc4\u4f30\u6d4f\u89c8\u5668LLM\u4ee3\u7406\u5728\u771f\u5b9e\u7f51\u7edc\u73af\u5883\u4e2d\u53ef\u9760\u6027\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5f15\u5165\u7f51\u7edc\u4e0d\u7a33\u5b9a\u6027\u548c\u7f51\u7ad9\u653b\u51fb\u7b49\u73b0\u5b9e\u56e0\u7d20\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u53d7\u63a7\u73af\u5883\u4e2d\u8bc4\u4f30LLM\u4ee3\u7406\u6027\u80fd\uff0c\u5ffd\u7565\u4e86\u771f\u5b9e\u4e16\u754c\u4e2d\u7f51\u7edc\u4e0d\u7a33\u5b9a\u3001HTTPS\u8fde\u63a5\u95ee\u9898\u548c\u7f51\u7ad9\u653b\u51fb\u7b49\u73b0\u5b9e\u6311\u6218\uff0c\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u4ee3\u7406\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u3002", "method": "\u5728\u4e09\u4e2a\u6d41\u884c\u57fa\u51c6\u6d4b\u8bd5\uff08WebArena\u3001WebVoyager\u548cREAL\uff09\u4e2d\u5f15\u5165WAREX\u6846\u67b6\uff0c\u6a21\u62df\u7f51\u7edc\u4e0d\u7a33\u5b9a\u3001\u670d\u52a1\u5668\u95ee\u9898\u3001\u7cfb\u7edf\u6545\u969c\u4ee5\u53ca\u8de8\u7ad9\u811a\u672c\u653b\u51fb\u7b49\u73b0\u5b9e\u73af\u5883\u56e0\u7d20\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5f15\u5165WAREX\u540e\uff0c\u4efb\u52a1\u6210\u529f\u7387\u663e\u8457\u4e0b\u964d\uff0c\u8868\u660e\u73b0\u6709\u6700\u5148\u8fdb\u7684LLM\u4ee3\u7406\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u6709\u9650\u3002", "conclusion": "\u5f53\u524dLLM\u4ee3\u7406\u5728\u53d7\u63a7\u73af\u5883\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9762\u5bf9\u771f\u5b9e\u4e16\u754c\u7684\u4e0d\u7a33\u5b9a\u6027\u548c\u5b89\u5168\u5a01\u80c1\u65f6\u53ef\u9760\u6027\u4e0d\u8db3\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u4ee3\u7406\u7cfb\u7edf\u3002"}}
{"id": "2510.03377", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03377", "abs": "https://arxiv.org/abs/2510.03377", "authors": ["Ahmed Missaoui", "Cemalettin Ozturk", "Barry O'Sullivan"], "title": "Refined Iterated Pareto Greedy for Energy-aware Hybrid Flowshop Scheduling with Blocking Constraints", "comment": null, "summary": "The scarcity of non-renewable energy sources, geopolitical problems in its\nsupply, increasing prices, and the impact of climate change, force the global\neconomy to develop more energy-efficient solutions for their operations. The\nManufacturing sector is not excluded from this challenge as one of the largest\nconsumers of energy. Energy-efficient scheduling is a method that attracts\nmanufacturing companies to reduce their consumption as it can be quickly\ndeployed and can show impact immediately. In this study, the hybrid flow shop\nscheduling problem with blocking constraint (BHFS) is investigated in which we\nseek to minimize the latest completion time (i.e. makespan) and overall energy\nconsumption, a typical manufacturing setting across many industries from\nautomotive to pharmaceutical. Energy consumption and the latest completion time\nof customer orders are usually conflicting objectives. Therefore, we first\nformulate the problem as a novel multi-objective mixed integer programming\n(MIP) model and propose an augmented epsilon-constraint method for finding the\nPareto-optimal solutions. Also, an effective multi-objective metaheuristic\nalgorithm. Refined Iterated Pareto Greedy (RIPG), is developed to solve large\ninstances in reasonable time. Our proposed methods are benchmarked using small,\nmedium, and large-size instances to evaluate their efficiency. Two well-known\nalgorithms are adopted for comparing our novel approaches. The computational\nresults show the effectiveness of our method.", "AI": {"tldr": "\u7814\u7a76\u6df7\u5408\u6d41\u6c34\u8f66\u95f4\u8c03\u5ea6\u95ee\u9898\uff0c\u8003\u8651\u963b\u585e\u7ea6\u675f\uff0c\u540c\u65f6\u4f18\u5316\u5b8c\u5de5\u65f6\u95f4\u548c\u80fd\u8017\uff0c\u63d0\u51fa\u591a\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\u548c\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "motivation": "\u4e0d\u53ef\u518d\u751f\u80fd\u6e90\u7a00\u7f3a\u3001\u5730\u7f18\u653f\u6cbb\u95ee\u9898\u3001\u4ef7\u683c\u4e0a\u6da8\u548c\u6c14\u5019\u53d8\u5316\u8feb\u4f7f\u5236\u9020\u4e1a\u5bfb\u6c42\u8282\u80fd\u89e3\u51b3\u65b9\u6848\uff0c\u6df7\u5408\u6d41\u6c34\u8f66\u95f4\u8c03\u5ea6\u662f\u5feb\u901f\u89c1\u6548\u7684\u8282\u80fd\u65b9\u6cd5\u3002", "method": "\u5efa\u7acb\u591a\u76ee\u6807\u6df7\u5408\u6574\u6570\u89c4\u5212\u6a21\u578b\uff0c\u91c7\u7528\u589e\u5f3a\u03b5\u7ea6\u675f\u65b9\u6cd5\u6c42\u5e15\u7d2f\u6258\u6700\u4f18\u89e3\uff0c\u5f00\u53d1\u7cbe\u70bc\u8fed\u4ee3\u5e15\u7d2f\u6258\u8d2a\u5a6a\u7b97\u6cd5\u5904\u7406\u5927\u89c4\u6a21\u95ee\u9898\u3002", "result": "\u901a\u8fc7\u5c0f\u3001\u4e2d\u3001\u5927\u89c4\u6a21\u5b9e\u4f8b\u9a8c\u8bc1\u7b97\u6cd5\u6709\u6548\u6027\uff0c\u4e0e\u73b0\u6709\u7b97\u6cd5\u5bf9\u6bd4\u663e\u793a\u6240\u63d0\u65b9\u6cd5\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\u548c\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u6df7\u5408\u6d41\u6c34\u8f66\u95f4\u8c03\u5ea6\u4e2d\u7684\u80fd\u8017\u548c\u5b8c\u5de5\u65f6\u95f4\u51b2\u7a81\u95ee\u9898\u3002"}}
{"id": "2510.03399", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03399", "abs": "https://arxiv.org/abs/2510.03399", "authors": ["Xiaoyan Bai", "Aryan Shrivastava", "Ari Holtzman", "Chenhao Tan"], "title": "Know Thyself? On the Incapability and Implications of AI Self-Recognition", "comment": "Our code is available, see\n  https://github.com/ChicagoHAI/self-recognition", "summary": "Self-recognition is a crucial metacognitive capability for AI systems,\nrelevant not only for psychological analysis but also for safety, particularly\nin evaluative scenarios. Motivated by contradictory interpretations of whether\nmodels possess self-recognition (Panickssery et al., 2024; Davidson et al.,\n2024), we introduce a systematic evaluation framework that can be easily\napplied and updated. Specifically, we measure how well 10 contemporary larger\nlanguage models (LLMs) can identify their own generated text versus text from\nother models through two tasks: binary self-recognition and exact model\nprediction. Different from prior claims, our results reveal a consistent\nfailure in self-recognition. Only 4 out of 10 models predict themselves as\ngenerators, and the performance is rarely above random chance. Additionally,\nmodels exhibit a strong bias toward predicting GPT and Claude families. We also\nprovide the first evaluation of model awareness of their own and others'\nexistence, as well as the reasoning behind their choices in self-recognition.\nWe find that the model demonstrates some knowledge of its own existence and\nother models, but their reasoning reveals a hierarchical bias. They appear to\nassume that GPT, Claude, and occasionally Gemini are the top-tier models, often\nassociating high-quality text with them. We conclude by discussing the\nimplications of our findings on AI safety and future directions to develop\nappropriate AI self-awareness.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e8610\u4e2a\u5f53\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u6211\u8bc6\u522b\u80fd\u529b\uff0c\u53d1\u73b0\u6a21\u578b\u666e\u904d\u5b58\u5728\u81ea\u6211\u8bc6\u522b\u5931\u8d25\uff0c\u4ec54\u4e2a\u6a21\u578b\u80fd\u8bc6\u522b\u81ea\u5df1\u7684\u751f\u6210\u6587\u672c\uff0c\u4e14\u8868\u73b0\u5f88\u5c11\u4f18\u4e8e\u968f\u673a\u731c\u6d4b\u3002\u6a21\u578b\u8fd8\u8868\u73b0\u51fa\u5bf9GPT\u548cClaude\u5bb6\u65cf\u7684\u5f3a\u70c8\u504f\u89c1\u3002", "motivation": "\u9488\u5bf9AI\u7cfb\u7edf\u662f\u5426\u5177\u5907\u81ea\u6211\u8bc6\u522b\u80fd\u529b\u5b58\u5728\u77db\u76fe\u89e3\u91ca\uff0c\u672c\u6587\u65e8\u5728\u5efa\u7acb\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\u6765\u68c0\u9a8c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc6\u522b\u81ea\u8eab\u751f\u6210\u6587\u672c\u7684\u80fd\u529b\uff0c\u8fd9\u5bf9AI\u5b89\u5168\u548c\u5fc3\u7406\u5206\u6790\u90fd\u5f88\u91cd\u8981\u3002", "method": "\u5f15\u5165\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u4e8c\u5143\u81ea\u6211\u8bc6\u522b\u548c\u7cbe\u786e\u6a21\u578b\u9884\u6d4b\u4e24\u4e2a\u4efb\u52a1\uff0c\u6d4b\u91cf10\u4e2a\u5f53\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc6\u522b\u81ea\u8eab\u751f\u6210\u6587\u672c\u4e0e\u5176\u4ed6\u6a21\u578b\u6587\u672c\u7684\u80fd\u529b\u3002", "result": "\u7ed3\u679c\u663e\u793a\u4e00\u81f4\u7684\u81ea\u6211\u8bc6\u522b\u5931\u8d25\uff1a\u4ec54/10\u6a21\u578b\u80fd\u9884\u6d4b\u81ea\u8eab\u4e3a\u751f\u6210\u8005\uff0c\u6027\u80fd\u5f88\u5c11\u4f18\u4e8e\u968f\u673a\u673a\u4f1a\u3002\u6a21\u578b\u8868\u73b0\u51fa\u5bf9GPT\u548cClaude\u5bb6\u65cf\u7684\u5f3a\u70c8\u504f\u89c1\uff0c\u5e76\u663e\u793a\u51fa\u5bf9\u81ea\u8eab\u548c\u5176\u4ed6\u6a21\u578b\u5b58\u5728\u7684\u67d0\u79cd\u8ba4\u77e5\uff0c\u4f46\u63a8\u7406\u4e2d\u5b58\u5728\u5c42\u7ea7\u504f\u89c1\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5bf9AI\u5b89\u5168\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u9700\u8981\u672a\u6765\u5f00\u53d1\u9002\u5f53\u7684AI\u81ea\u6211\u610f\u8bc6\uff0c\u6a21\u578b\u867d\u7136\u8868\u73b0\u51fa\u5bf9\u6a21\u578b\u5b58\u5728\u7684\u8ba4\u77e5\uff0c\u4f46\u81ea\u6211\u8bc6\u522b\u80fd\u529b\u6709\u9650\u4e14\u5b58\u5728\u504f\u89c1\u3002"}}
{"id": "2510.03418", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.03418", "abs": "https://arxiv.org/abs/2510.03418", "authors": ["Ananya Mantravadi", "Shivali Dalmia", "Abhishek Mukherji", "Nand Dave", "Anudha Mittal"], "title": "ContraGen: A Multi-Agent Generation Framework for Enterprise Contradictions Detection", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) integrates LLMs with external sources,\noffering advanced capabilities for information access and decision-making.\nHowever, contradictions in retrieved evidence can result in inconsistent or\nuntrustworthy outputs, which is especially problematic in enterprise settings\nwhere compliance, governance, and accountability are critical. Existing\nbenchmarks for contradiction detection are limited to sentence-level analysis\nand do not capture the complexity of enterprise documents such as contracts,\nfinancial filings, compliance reports, or policy manuals. To address this\nlimitation, we propose ContraGen, a contradiction-aware benchmark framework\ntailored to enterprise domain. The framework generates synthetic\nenterprise-style documents with embedded contradictions, enabling systematic\nevaluation of both intra-document and cross-document consistency. Automated\ncontradiction mining is combined with human-in-the-loop validation to ensure\nhigh accuracy. Our contributions include generating realistic enterprise\ndocuments, modeling a taxonomy of contradiction types common in business\nprocesses, enabling controlled creation of self- and pairwise contradictions,\ndeveloping a contradiction-aware retrieval evaluation pipeline and embedding\nhuman oversight to reflect domain-specific judgment complexity. This work\nestablishes a foundation for more trustworthy and accountable RAG systems in\nenterprise information-seeking applications, where detecting and resolving\ncontradictions is essential for reducing risk and ensuring compliance.", "AI": {"tldr": "\u63d0\u51fa\u4e86ContraGen\u6846\u67b6\uff0c\u4e13\u95e8\u9488\u5bf9\u4f01\u4e1a\u9886\u57df\u6784\u5efa\u77db\u76fe\u68c0\u6d4b\u57fa\u51c6\uff0c\u901a\u8fc7\u751f\u6210\u5305\u542b\u77db\u76fe\u7684\u4f01\u4e1a\u98ce\u683c\u6587\u6863\u6765\u7cfb\u7edf\u8bc4\u4f30\u6587\u6863\u5185\u548c\u8de8\u6587\u6863\u7684\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u77db\u76fe\u68c0\u6d4b\u57fa\u51c6\u4ec5\u9650\u4e8e\u53e5\u5b50\u7ea7\u522b\u5206\u6790\uff0c\u65e0\u6cd5\u5904\u7406\u4f01\u4e1a\u6587\u6863\u7684\u590d\u6742\u6027\uff0c\u800cRAG\u7cfb\u7edf\u4e2d\u68c0\u7d22\u8bc1\u636e\u7684\u77db\u76fe\u4f1a\u5bfc\u81f4\u4e0d\u53ef\u9760\u8f93\u51fa\uff0c\u8fd9\u5728\u8981\u6c42\u5408\u89c4\u6027\u548c\u95ee\u8d23\u5236\u7684\u4f01\u4e1a\u73af\u5883\u4e2d\u5c24\u5176\u6210\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u81ea\u52a8\u5316\u77db\u76fe\u6316\u6398\u548c\u4eba\u5de5\u9a8c\u8bc1\uff0c\u751f\u6210\u5305\u542b\u5d4c\u5165\u5f0f\u77db\u76fe\u7684\u4f01\u4e1a\u98ce\u683c\u5408\u6210\u6587\u6863\uff0c\u5efa\u7acb\u4f01\u4e1a\u6d41\u7a0b\u4e2d\u5e38\u89c1\u77db\u76fe\u7c7b\u578b\u7684\u5206\u7c7b\u6cd5\uff0c\u5f00\u53d1\u77db\u76fe\u611f\u77e5\u68c0\u7d22\u8bc4\u4f30\u6d41\u7a0b\u3002", "result": "\u6784\u5efa\u4e86\u4e13\u95e8\u9488\u5bf9\u4f01\u4e1a\u9886\u57df\u7684\u77db\u76fe\u68c0\u6d4b\u57fa\u51c6\u6846\u67b6\uff0c\u80fd\u591f\u7cfb\u7edf\u8bc4\u4f30\u6587\u6863\u4e00\u81f4\u6027\uff0c\u4e3a\u66f4\u53ef\u4fe1\u7684RAG\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u4f01\u4e1a\u4fe1\u606f\u68c0\u7d22\u5e94\u7528\u4e2d\u68c0\u6d4b\u548c\u89e3\u51b3\u77db\u76fe\u5efa\u7acb\u4e86\u57fa\u7840\uff0c\u5bf9\u4e8e\u964d\u4f4e\u98ce\u9669\u548c\u786e\u4fdd\u5408\u89c4\u6027\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.03315", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03315", "abs": "https://arxiv.org/abs/2510.03315", "authors": ["Alex Gibson"], "title": "Decomposing Attention To Find Context-Sensitive Neurons", "comment": "10 pages, 7 figures. Submitted to the Mechanistic Interpretability\n  Workshop at NeurIPS 2025", "summary": "We study transformer language models, analyzing attention heads whose\nattention patterns are spread out, and whose attention scores depend weakly on\ncontent. We argue that the softmax denominators of these heads are stable when\nthe underlying token distribution is fixed. By sampling softmax denominators\nfrom a \"calibration text\", we can combine together the outputs of multiple such\nstable heads in the first layer of GPT2-Small, approximating their combined\noutput by a linear summary of the surrounding text. This approximation enables\na procedure where from the weights alone - and a single calibration text - we\ncan uncover hundreds of first layer neurons that respond to high-level\ncontextual properties of the surrounding text, including neurons that didn't\nactivate on the calibration text.", "AI": {"tldr": "\u901a\u8fc7\u5206\u6790GPT2-Small\u7b2c\u4e00\u5c42\u4e2d\u6ce8\u610f\u529b\u6a21\u5f0f\u5206\u6563\u4e14\u5bf9\u5185\u5bb9\u4f9d\u8d56\u8f83\u5f31\u7684\u6ce8\u610f\u529b\u5934\uff0c\u5229\u7528\u6821\u51c6\u6587\u672c\u91c7\u6837softmax\u5206\u6bcd\uff0c\u8fd1\u4f3c\u8fd9\u4e9b\u5934\u7684\u7ec4\u5408\u8f93\u51fa\u4e3a\u7ebf\u6027\u6458\u8981\uff0c\u4ece\u800c\u4ec5\u4ece\u6743\u91cd\u548c\u5355\u4e2a\u6821\u51c6\u6587\u672c\u5c31\u80fd\u53d1\u73b0\u6570\u767e\u4e2a\u54cd\u5e94\u4e0a\u4e0b\u6587\u5c5e\u6027\u7684\u7b2c\u4e00\u5c42\u795e\u7ecf\u5143\u3002", "motivation": "\u7814\u7a76transformer\u8bed\u8a00\u6a21\u578b\u4e2d\u6ce8\u610f\u529b\u6a21\u5f0f\u5206\u6563\u7684\u6ce8\u610f\u529b\u5934\uff0c\u8fd9\u4e9b\u5934\u7684\u6ce8\u610f\u529b\u5206\u6570\u5bf9\u5185\u5bb9\u4f9d\u8d56\u8f83\u5f31\uff0c\u5176softmax\u5206\u6bcd\u5728\u56fa\u5b9atoken\u5206\u5e03\u4e0b\u662f\u7a33\u5b9a\u7684\u3002", "method": "\u4f7f\u7528\u6821\u51c6\u6587\u672c\u91c7\u6837softmax\u5206\u6bcd\uff0c\u5c06\u591a\u4e2a\u7a33\u5b9a\u6ce8\u610f\u529b\u5934\u7684\u8f93\u51fa\u7ec4\u5408\u8fd1\u4f3c\u4e3a\u5468\u56f4\u6587\u672c\u7684\u7ebf\u6027\u6458\u8981\uff0c\u4ec5\u4ece\u6743\u91cd\u548c\u5355\u4e2a\u6821\u51c6\u6587\u672c\u8fdb\u884c\u5206\u6790\u3002", "result": "\u80fd\u591f\u53d1\u73b0GPT2-Small\u7b2c\u4e00\u5c42\u4e2d\u6570\u767e\u4e2a\u54cd\u5e94\u9ad8\u7ea7\u4e0a\u4e0b\u6587\u5c5e\u6027\u7684\u795e\u7ecf\u5143\uff0c\u5305\u62ec\u5728\u6821\u51c6\u6587\u672c\u4e0a\u672a\u6fc0\u6d3b\u7684\u795e\u7ecf\u5143\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4ec5\u4ece\u6a21\u578b\u6743\u91cd\u548c\u5355\u4e2a\u6821\u51c6\u6587\u672c\u5c31\u80fd\u6709\u6548\u8bc6\u522btransformer\u7b2c\u4e00\u5c42\u4e2d\u54cd\u5e94\u4e0a\u4e0b\u6587\u5c5e\u6027\u7684\u795e\u7ecf\u5143\uff0c\u4e3a\u6a21\u578b\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2510.03453", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03453", "abs": "https://arxiv.org/abs/2510.03453", "authors": ["Paul S. Rosenbloom"], "title": "A Qualitative Comparative Evaluation of Cognitive and Generative Theories", "comment": "To appear in Proceedings of the 12th Annual Conference on Advances in\n  Cognitive Systems (ACS-25)", "summary": "Evaluation is a critical activity associated with any theory. Yet this has\nproven to be an exceptionally challenging activity for theories based on\ncognitive architectures. For an overlapping set of reasons, evaluation can also\nbe challenging for theories based on generative neural architectures. This dual\nchallenge is approached here by leveraging a broad perspective on theory\nevaluation to yield a wide-ranging, albeit qualitative, comparison of\nwhole-mind-oriented cognitive and generative architectures and the full systems\nthat are based on these architectures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u8ba4\u77e5\u67b6\u6784\u548c\u751f\u6210\u5f0f\u795e\u7ecf\u67b6\u6784\u7406\u8bba\u7684\u5b9a\u6027\u6bd4\u8f83\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u8fd9\u4e24\u79cd\u67b6\u6784\u5728\u7406\u8bba\u8bc4\u4f30\u65b9\u9762\u9762\u4e34\u7684\u6311\u6218\u3002", "motivation": "\u8ba4\u77e5\u67b6\u6784\u548c\u751f\u6210\u5f0f\u795e\u7ecf\u67b6\u6784\u5728\u7406\u8bba\u8bc4\u4f30\u65b9\u9762\u90fd\u9762\u4e34\u663e\u8457\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u9a8c\u8bc1\u8fd9\u4e9b\u67b6\u6784\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u91c7\u7528\u5e7f\u6cdb\u7684\u7406\u8bba\u8bc4\u4f30\u89c6\u89d2\uff0c\u5bf9\u9762\u5411\u5168\u8111\u7684\u8ba4\u77e5\u67b6\u6784\u548c\u751f\u6210\u5f0f\u67b6\u6784\u53ca\u5176\u5b8c\u6574\u7cfb\u7edf\u8fdb\u884c\u5168\u9762\u7684\u5b9a\u6027\u6bd4\u8f83\u5206\u6790\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5bbd\u6cdb\u7684\u5b9a\u6027\u6bd4\u8f83\u6846\u67b6\uff0c\u80fd\u591f\u7cfb\u7edf\u8bc4\u4f30\u57fa\u4e8e\u8ba4\u77e5\u67b6\u6784\u548c\u751f\u6210\u5f0f\u795e\u7ecf\u67b6\u6784\u7684\u5b8c\u6574\u7406\u8bba\u7cfb\u7edf\u3002", "conclusion": "\u901a\u8fc7\u91c7\u7528\u5e7f\u6cdb\u7684\u7406\u8bba\u8bc4\u4f30\u89c6\u89d2\uff0c\u53ef\u4ee5\u6709\u6548\u5e94\u5bf9\u8ba4\u77e5\u67b6\u6784\u548c\u751f\u6210\u5f0f\u795e\u7ecf\u67b6\u6784\u5728\u7406\u8bba\u9a8c\u8bc1\u65b9\u9762\u7684\u53cc\u91cd\u6311\u6218\uff0c\u4e3a\u8fd9\u7c7b\u67b6\u6784\u7684\u7406\u8bba\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u65b9\u6cd5\u8bba\u3002"}}
{"id": "2510.03323", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03323", "abs": "https://arxiv.org/abs/2510.03323", "authors": ["Ge Chang", "Jinbo Su", "Jiacheng Liu", "Pengfei Yang", "Yuhao Shang", "Huiwen Zheng", "Hongli Ma", "Yan Liang", "Yuanchun Li", "Yunxin Liu"], "title": "Graph-S3: Enhancing Agentic textual Graph Retrieval with Synthetic Stepwise Supervision", "comment": null, "summary": "A significant portion of real-world data is inherently represented as textual\ngraphs, and integrating these graphs into large language models (LLMs) is\npromising to enable complex graph-based question answering. However, a key\nchallenge in LLM-based textual graph QA systems lies in graph retrieval, i.e.,\nhow to retrieve relevant content from large graphs that is sufficiently\ninformative while remaining compact for the LLM context. Existing retrievers\nsuffer from poor performance since they either rely on shallow embedding\nsimilarity or employ interactive retrieving policies that demand excessive data\nlabeling and training cost. To address these issues, we present Graph-$S^3$, an\nagentic textual graph reasoning framework that employs an LLM-based retriever\ntrained with synthetic stepwise supervision. Instead of rewarding the agent\nbased on the final answers, which may lead to sparse and unstable training\nsignals, we propose to closely evaluate each step of the retriever based on\noffline-extracted golden subgraphs. Our main techniques include a data\nsynthesis pipeline to extract the golden subgraphs for reward generation and a\ntwo-stage training scheme to learn the interactive graph exploration policy\nbased on the synthesized rewards. Based on extensive experiments on three\ncommon datasets in comparison with seven strong baselines, our approach\nachieves an average improvement of 8.1\\% in accuracy and 9.7\\% in F$_1$ score.\nThe advantage is even higher in more complicated multi-hop reasoning tasks. Our\ncode will be open-sourced.", "AI": {"tldr": "\u63d0\u51fa\u4e86Graph-S\u00b3\u6846\u67b6\uff0c\u901a\u8fc7\u5408\u6210\u9010\u6b65\u76d1\u7763\u8bad\u7ec3\u57fa\u4e8eLLM\u7684\u68c0\u7d22\u5668\uff0c\u89e3\u51b3\u6587\u672c\u56fe\u95ee\u7b54\u4e2d\u7684\u56fe\u68c0\u7d22\u6311\u6218\uff0c\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u76f8\u6bd47\u4e2a\u57fa\u7ebf\u5e73\u5747\u63d0\u53478.1%\u51c6\u786e\u7387\u548c9.7% F1\u5206\u6570\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u5927\u91cf\u6570\u636e\u4ee5\u6587\u672c\u56fe\u5f62\u5f0f\u5b58\u5728\uff0c\u4f46\u73b0\u6709\u56fe\u68c0\u7d22\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u6d45\u5c42\u5d4c\u5165\u76f8\u4f3c\u5ea6\uff0c\u8981\u4e48\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u548c\u8bad\u7ec3\u6210\u672c\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u5f00\u53d1\u57fa\u4e8eLLM\u7684\u68c0\u7d22\u5668\uff0c\u4f7f\u7528\u5408\u6210\u9010\u6b65\u76d1\u7763\u8bad\u7ec3\uff0c\u901a\u8fc7\u79bb\u7ebf\u63d0\u53d6\u9ec4\u91d1\u5b50\u56fe\u4e3a\u6bcf\u4e2a\u68c0\u7d22\u6b65\u9aa4\u63d0\u4f9b\u8bc4\u4f30\uff0c\u5305\u542b\u6570\u636e\u5408\u6210\u7ba1\u9053\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6848\u3002", "result": "\u5728\u4e09\u4e2a\u5e38\u89c1\u6570\u636e\u96c6\u4e0a\u76f8\u6bd47\u4e2a\u5f3a\u57fa\u7ebf\uff0c\u5e73\u5747\u51c6\u786e\u7387\u63d0\u53478.1%\uff0cF1\u5206\u6570\u63d0\u53479.7%\uff0c\u5728\u591a\u8df3\u63a8\u7406\u4efb\u52a1\u4e2d\u4f18\u52bf\u66f4\u660e\u663e\u3002", "conclusion": "Graph-S\u00b3\u6846\u67b6\u901a\u8fc7\u5408\u6210\u76d1\u7763\u548c\u9010\u6b65\u8bc4\u4f30\u6709\u6548\u89e3\u51b3\u4e86\u6587\u672c\u56fe\u68c0\u7d22\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fe\u95ee\u7b54\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u3002"}}
{"id": "2510.03469", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.03469", "abs": "https://arxiv.org/abs/2510.03469", "authors": ["Keshav Ramani", "Vali Tawosi", "Salwa Alamir", "Daniel Borrajo"], "title": "Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification", "comment": null, "summary": "We introduce a novel framework for evaluating the alignment between natural\nlanguage plans and their expected behavior by converting them into Kripke\nstructures and Linear Temporal Logic (LTL) using Large Language Models (LLMs)\nand performing model checking. We systematically evaluate this framework on a\nsimplified version of the PlanBench plan verification dataset and report on\nmetrics like Accuracy, Precision, Recall and F1 scores. Our experiments\ndemonstrate that GPT-5 achieves excellent classification performance (F1 score\nof 96.3%) while almost always producing syntactically perfect formal\nrepresentations that can act as guarantees. However, the synthesis of\nsemantically perfect formal models remains an area for future exploration.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5c06\u81ea\u7136\u8bed\u8a00\u8ba1\u5212\u8f6c\u6362\u4e3aKripke\u7ed3\u6784\u548cLTL\u516c\u5f0f\uff0c\u5e76\u4f7f\u7528LLM\u8fdb\u884c\u6a21\u578b\u68c0\u67e5\u6765\u8bc4\u4f30\u8ba1\u5212\u5bf9\u9f50\u7684\u65b0\u6846\u67b6\u3002", "motivation": "\u9700\u8981\u8bc4\u4f30\u81ea\u7136\u8bed\u8a00\u8ba1\u5212\u4e0e\u5176\u9884\u671f\u884c\u4e3a\u4e4b\u95f4\u7684\u5bf9\u9f50\u5173\u7cfb\uff0c\u786e\u4fdd\u8ba1\u5212\u7684\u6b63\u786e\u6267\u884c\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c06\u81ea\u7136\u8bed\u8a00\u8ba1\u5212\u8f6c\u6362\u4e3aKripke\u7ed3\u6784\u548c\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\u516c\u5f0f\uff0c\u7136\u540e\u8fdb\u884c\u6a21\u578b\u68c0\u67e5\u3002", "result": "GPT-5\u5728PlanBench\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0cF1\u5206\u6570\u8fbe96.3%\uff0c\u751f\u6210\u7684\u6b63\u5f0f\u8868\u793a\u8bed\u6cd5\u5b8c\u7f8e\uff0c\u53ef\u4f5c\u4e3a\u4fdd\u8bc1\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u8ba1\u5212\u9a8c\u8bc1\u65b9\u9762\u6548\u679c\u663e\u8457\uff0c\u4f46\u8bed\u4e49\u5b8c\u7f8e\u5f62\u5f0f\u6a21\u578b\u7684\u5408\u6210\u4ecd\u9700\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002"}}
{"id": "2510.03384", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03384", "abs": "https://arxiv.org/abs/2510.03384", "authors": ["Arjun Arunasalam", "Madison Pickering", "Z. Berkay Celik", "Blase Ur"], "title": "Implicit Values Embedded in How Humans and LLMs Complete Subjective Everyday Tasks", "comment": null, "summary": "Large language models (LLMs) can underpin AI assistants that help users with\neveryday tasks, such as by making recommendations or performing basic\ncomputation. Despite AI assistants' promise, little is known about the implicit\nvalues these assistants display while completing subjective everyday tasks.\nHumans may consider values like environmentalism, charity, and diversity. To\nwhat extent do LLMs exhibit these values in completing everyday tasks? How do\nthey compare with humans? We answer these questions by auditing how six popular\nLLMs complete 30 everyday tasks, comparing LLMs to each other and to 100 human\ncrowdworkers from the US. We find LLMs often do not align with humans, nor with\nother LLMs, in the implicit values exhibited.", "AI": {"tldr": "\u672c\u6587\u5ba1\u8ba1\u4e866\u4e2a\u6d41\u884c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b8c\u621030\u4e2a\u65e5\u5e38\u4efb\u52a1\u65f6\u8868\u73b0\u51fa\u7684\u9690\u542b\u4ef7\u503c\u89c2\uff0c\u5e76\u4e0e100\u540d\u7f8e\u56fd\u4f17\u5305\u5de5\u4f5c\u8005\u8fdb\u884c\u6bd4\u8f83\uff0c\u53d1\u73b0LLMs\u5728\u4ef7\u503c\u89c2\u4e0a\u65e2\u4e0e\u4eba\u7c7b\u4e0d\u4e00\u81f4\uff0c\u4e5f\u4e0e\u5176\u4ed6LLMs\u4e0d\u4e00\u81f4\u3002", "motivation": "\u5c3d\u7ba1AI\u52a9\u624b\u5728\u5e2e\u52a9\u7528\u6237\u5b8c\u6210\u65e5\u5e38\u4efb\u52a1\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4eba\u4eec\u5bf9\u8fd9\u4e9b\u52a9\u624b\u5728\u5b8c\u6210\u4e3b\u89c2\u65e5\u5e38\u4efb\u52a1\u65f6\u8868\u73b0\u51fa\u7684\u9690\u542b\u4ef7\u503c\u89c2\u77e5\u4e4b\u751a\u5c11\u3002", "method": "\u901a\u8fc7\u5ba1\u8ba16\u4e2a\u6d41\u884cLLMs\u5b8c\u621030\u4e2a\u65e5\u5e38\u4efb\u52a1\u7684\u65b9\u5f0f\uff0c\u5e76\u4e0e100\u540d\u7f8e\u56fd\u4f17\u5305\u5de5\u4f5c\u8005\u8fdb\u884c\u6bd4\u8f83\uff0c\u5206\u6790LLMs\u5728\u4ef7\u503c\u89c2\u4e0a\u7684\u8868\u73b0\u3002", "result": "LLMs\u5728\u9690\u542b\u4ef7\u503c\u89c2\u8868\u73b0\u4e0a\u7ecf\u5e38\u4e0e\u4eba\u7c7b\u4e0d\u4e00\u81f4\uff0c\u4e5f\u4e0e\u5176\u4ed6LLMs\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b8c\u6210\u65e5\u5e38\u4efb\u52a1\u65f6\u8868\u73b0\u51fa\u7684\u4ef7\u503c\u89c2\u9700\u8981\u8fdb\u4e00\u6b65\u5173\u6ce8\u548c\u8c03\u6574\uff0c\u4ee5\u786e\u4fdd\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u4e00\u81f4\u6027\u3002"}}
{"id": "2510.03485", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.03485", "abs": "https://arxiv.org/abs/2510.03485", "authors": ["Xiaofei Wen", "Wenjie Jacky Mo", "Yanan Xie", "Peng Qi", "Muhao Chen"], "title": "Towards Policy-Compliant Agents: Learning Efficient Guardrails For Policy Violation Detection", "comment": "16 pages, 5 figures", "summary": "Autonomous web agents need to operate under externally imposed or\nhuman-specified policies while generating long-horizon trajectories. However,\nlittle work has examined whether these trajectories comply with such policies,\nor whether policy violations persist across different contexts such as domains\n(e.g., shopping or coding websites) and subdomains (e.g., product search and\norder management in shopping). To address this gap, we introduce\nPolicyGuardBench, a benchmark of about 60k examples for detecting policy\nviolations in agent trajectories. From diverse agent runs, we generate a broad\nset of policies and create both within subdomain and cross subdomain pairings\nwith violation labels. In addition to full-trajectory evaluation,\nPolicyGuardBench also includes a prefix-based violation detection task where\nmodels must anticipate policy violations from truncated trajectory prefixes\nrather than complete sequences. Using this dataset, we train PolicyGuard-4B, a\nlightweight guardrail model that delivers strong detection accuracy across all\ntasks while keeping inference efficient. Notably, PolicyGuard-4B generalizes\nacross domains and preserves high accuracy on unseen settings. Together,\nPolicyGuardBench and PolicyGuard-4B provide the first comprehensive framework\nfor studying policy compliance in web agent trajectories, and show that\naccurate and generalizable guardrails are feasible at small scales.", "AI": {"tldr": "\u63d0\u51fa\u4e86PolicyGuardBench\u57fa\u51c6\u548cPolicyGuard-4B\u6a21\u578b\uff0c\u7528\u4e8e\u68c0\u6d4b\u7f51\u7edc\u667a\u80fd\u4f53\u8f68\u8ff9\u4e2d\u7684\u7b56\u7565\u8fdd\u89c4\u884c\u4e3a\uff0c\u5b9e\u73b0\u8de8\u9886\u57df\u7684\u6cdb\u5316\u68c0\u6d4b\u3002", "motivation": "\u81ea\u4e3b\u7f51\u7edc\u667a\u80fd\u4f53\u9700\u8981\u5728\u5916\u90e8\u7b56\u7565\u7ea6\u675f\u4e0b\u751f\u6210\u957f\u89c6\u91ce\u8f68\u8ff9\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5f88\u5c11\u5173\u6ce8\u8fd9\u4e9b\u8f68\u8ff9\u662f\u5426\u9075\u5b88\u7b56\u7565\uff0c\u4ee5\u53ca\u7b56\u7565\u8fdd\u89c4\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\uff08\u5982\u4e0d\u540c\u9886\u57df\u548c\u5b50\u9886\u57df\uff09\u4e2d\u7684\u6301\u7eed\u6027\u95ee\u9898\u3002", "method": "\u4ece\u591a\u6837\u5316\u667a\u80fd\u4f53\u8fd0\u884c\u4e2d\u751f\u6210\u5e7f\u6cdb\u7b56\u7565\u96c6\uff0c\u521b\u5efa\u5305\u542b\u8fdd\u89c4\u6807\u7b7e\u7684\u5b50\u57df\u5185\u548c\u8de8\u5b50\u57df\u914d\u5bf9\uff1b\u9664\u4e86\u5b8c\u6574\u8f68\u8ff9\u8bc4\u4f30\uff0c\u8fd8\u5305\u62ec\u57fa\u4e8e\u524d\u7f00\u7684\u8fdd\u89c4\u68c0\u6d4b\u4efb\u52a1\uff1b\u8bad\u7ec3\u4e86\u8f7b\u91cf\u7ea7\u7684PolicyGuard-4B\u62a4\u680f\u6a21\u578b\u3002", "result": "PolicyGuard-4B\u5728\u6240\u6709\u4efb\u52a1\u4e0a\u63d0\u4f9b\u5f3a\u5927\u7684\u68c0\u6d4b\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u6548\u7387\uff1b\u80fd\u591f\u8de8\u9886\u57df\u6cdb\u5316\uff0c\u5728\u672a\u89c1\u8bbe\u7f6e\u4e0a\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "PolicyGuardBench\u548cPolicyGuard-4B\u4e3a\u7814\u7a76\u7f51\u7edc\u667a\u80fd\u4f53\u8f68\u8ff9\u4e2d\u7684\u7b56\u7565\u5408\u89c4\u6027\u63d0\u4f9b\u4e86\u9996\u4e2a\u5168\u9762\u6846\u67b6\uff0c\u8bc1\u660e\u5728\u5c0f\u89c4\u6a21\u4e0b\u5b9e\u73b0\u51c6\u786e\u4e14\u53ef\u6cdb\u5316\u7684\u62a4\u680f\u662f\u53ef\u884c\u7684\u3002"}}
{"id": "2510.03439", "categories": ["cs.CL", "I.2.7; I.6.m"], "pdf": "https://arxiv.org/pdf/2510.03439", "abs": "https://arxiv.org/abs/2510.03439", "authors": ["Brendon Boldt", "David Mortensen"], "title": "Morpheme Induction for Emergent Language", "comment": "Accepted for publication at the 2025 Conference on Empirical Methods\n  in Natural Language Processing; 16 pages, 4 figures", "summary": "We introduce CSAR, an algorithm for inducing morphemes from emergent language\ncorpora of parallel utterances and meanings. It is a greedy algorithm that (1)\nweights morphemes based on mutual information between forms and meanings, (2)\nselects the highest-weighted pair, (3) removes it from the corpus, and (4)\nrepeats the process to induce further morphemes (i.e., Count, Select, Ablate,\nRepeat). The effectiveness of CSAR is first validated on procedurally generated\ndatasets and compared against baselines for related tasks. Second, we validate\nCSAR's performance on human language data to show that the algorithm makes\nreasonable predictions in adjacent domains. Finally, we analyze a handful of\nemergent languages, quantifying linguistic characteristics like degree of\nsynonymy and polysemy.", "AI": {"tldr": "CSAR\u662f\u4e00\u79cd\u4ece\u65b0\u5174\u8bed\u8a00\u8bed\u6599\u5e93\u4e2d\u8bf1\u5bfc\u8bed\u7d20\u7684\u8d2a\u5a6a\u7b97\u6cd5\uff0c\u901a\u8fc7\u4e92\u4fe1\u606f\u52a0\u6743\u3001\u9009\u62e9\u6700\u9ad8\u6743\u91cd\u5bf9\u3001\u4ece\u8bed\u6599\u4e2d\u79fb\u9664\u5e76\u91cd\u590d\u8be5\u8fc7\u7a0b\u6765\u63d0\u53d6\u8bed\u7d20\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u4ece\u65b0\u5174\u8bed\u8a00\u5e73\u884c\u8bed\u6599\u5e93\u4e2d\u81ea\u52a8\u63d0\u53d6\u8bed\u7d20\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u5206\u6790\u8bed\u8a00\u7279\u5f81\u3002", "method": "\u57fa\u4e8e\u4e92\u4fe1\u606f\u7684\u8d2a\u5a6a\u7b97\u6cd5\uff1a\u8ba1\u6570\u8bed\u7d20\u6743\u91cd\u3001\u9009\u62e9\u6700\u9ad8\u6743\u91cd\u5bf9\u3001\u4ece\u8bed\u6599\u4e2d\u79fb\u9664\u3001\u91cd\u590d\u8be5\u8fc7\u7a0b\u3002", "result": "\u5728\u7a0b\u5e8f\u751f\u6210\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6709\u6548\u6027\uff0c\u5728\u4eba\u7c7b\u8bed\u8a00\u6570\u636e\u4e0a\u8868\u73b0\u5408\u7406\uff0c\u80fd\u591f\u91cf\u5316\u8bed\u8a00\u7279\u5f81\u5982\u540c\u4e49\u8bcd\u548c\u591a\u4e49\u8bcd\u7a0b\u5ea6\u3002", "conclusion": "CSAR\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u4ece\u65b0\u5174\u8bed\u8a00\u4e2d\u8bf1\u5bfc\u8bed\u7d20\uff0c\u5e76\u4e3a\u8bed\u8a00\u7279\u5f81\u5206\u6790\u63d0\u4f9b\u91cf\u5316\u5de5\u5177\u3002"}}
{"id": "2510.03506", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03506", "abs": "https://arxiv.org/abs/2510.03506", "authors": ["John Nguyen", "Marton Havasi", "Tariq Berrada", "Luke Zettlemoyer", "Ricky T. Q. Chen"], "title": "OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit Flows", "comment": "https://johnlnguyen.com/oneflow", "summary": "We present OneFlow, the first non-autoregressive multimodal model that\nenables variable-length and concurrent mixed-modal generation. Unlike\nautoregressive models that enforce rigid causal ordering between text and image\ngeneration, OneFlow combines an insertion-based Edit Flow for discrete text\ntokens with Flow Matching for image latents. OneFlow enables concurrent\ntext-image synthesis with hierarchical sampling that prioritizes content over\ngrammar. Through controlled experiments across model sizes from 1B to 8B, we\ndemonstrate that OneFlow outperforms autoregressive baselines on both\ngeneration and understanding tasks while using up to 50% fewer training FLOPs.\nOneFlow surpasses both autoregressive and diffusion-based approaches while\nunlocking new capabilities for concurrent generation, iterative refinement, and\nnatural reasoning-like generation.", "AI": {"tldr": "OneFlow\u662f\u9996\u4e2a\u975e\u81ea\u56de\u5f52\u591a\u6a21\u6001\u6a21\u578b\uff0c\u652f\u6301\u53ef\u53d8\u957f\u5ea6\u548c\u5e76\u53d1\u6df7\u5408\u6a21\u6001\u751f\u6210\uff0c\u901a\u8fc7\u63d2\u5165\u5f0f\u7f16\u8f91\u6d41\u548c\u6d41\u5339\u914d\u6280\u672f\u5b9e\u73b0\u6587\u672c\u56fe\u50cf\u7684\u5e76\u884c\u751f\u6210\uff0c\u5728\u51cf\u5c1150%\u8bad\u7ec3\u8ba1\u7b97\u91cf\u7684\u540c\u65f6\u8d85\u8d8a\u81ea\u56de\u5f52\u57fa\u7ebf\u3002", "motivation": "\u4f20\u7edf\u81ea\u56de\u5f52\u6a21\u578b\u5728\u6587\u672c\u548c\u56fe\u50cf\u751f\u6210\u4e4b\u95f4\u5f3a\u5236\u56e0\u679c\u987a\u5e8f\u9650\u5236\uff0c\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684\u5e76\u53d1\u751f\u6210\u3002OneFlow\u65e8\u5728\u6253\u7834\u8fd9\u79cd\u9650\u5236\uff0c\u5b9e\u73b0\u66f4\u7075\u6d3b\u9ad8\u6548\u7684\u591a\u6a21\u6001\u751f\u6210\u3002", "method": "\u7ed3\u5408\u63d2\u5165\u5f0f\u7f16\u8f91\u6d41\u5904\u7406\u79bb\u6563\u6587\u672c\u6807\u8bb0\u548c\u6d41\u5339\u914d\u5904\u7406\u56fe\u50cf\u6f5c\u5728\u8868\u793a\uff0c\u91c7\u7528\u5206\u5c42\u91c7\u6837\u7b56\u7565\u4f18\u5148\u5185\u5bb9\u800c\u975e\u8bed\u6cd5\uff0c\u652f\u6301\u5e76\u53d1\u6587\u672c\u56fe\u50cf\u5408\u6210\u3002", "result": "\u57281B\u52308B\u6a21\u578b\u89c4\u6a21\u7684\u5b9e\u9a8c\u4e2d\uff0cOneFlow\u5728\u751f\u6210\u548c\u7406\u89e3\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u81ea\u56de\u5f52\u57fa\u7ebf\uff0c\u540c\u65f6\u51cf\u5c11\u9ad8\u8fbe50%\u7684\u8bad\u7ec3\u8ba1\u7b97\u91cf\uff0c\u8d85\u8d8a\u4e86\u81ea\u56de\u5f52\u548c\u57fa\u4e8e\u6269\u6563\u7684\u65b9\u6cd5\u3002", "conclusion": "OneFlow\u89e3\u9501\u4e86\u5e76\u53d1\u751f\u6210\u3001\u8fed\u4ee3\u7ec6\u5316\u548c\u7c7b\u81ea\u7136\u63a8\u7406\u751f\u6210\u7b49\u65b0\u80fd\u529b\uff0c\u4e3a\u975e\u81ea\u56de\u5f52\u591a\u6a21\u6001\u751f\u6210\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2510.03458", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03458", "abs": "https://arxiv.org/abs/2510.03458", "authors": ["Mengyao Xu", "Wenfei Zhou", "Yauhen Babakhin", "Gabriel Moreira", "Ronay Ak", "Radek Osmulski", "Bo Liu", "Even Oldridge", "Benedikt Schifferer"], "title": "Omni-Embed-Nemotron: A Unified Multimodal Retrieval Model for Text, Image, Audio, and Video", "comment": null, "summary": "We present Omni-Embed-Nemotron, a unified multimodal retrieval embedding\nmodel developed to handle the increasing complexity of real-world information\nneeds. While Retrieval-Augmented Generation (RAG) has significantly advanced\nlanguage models by incorporating external knowledge, existing text-based\nretrievers rely on clean, structured input and struggle with the visually and\nsemantically rich content found in real-world documents such as PDFs, slides,\nor videos. Recent work such as ColPali has shown that preserving document\nlayout using image-based representations can improve retrieval quality.\nBuilding on this, and inspired by the capabilities of recent multimodal models\nsuch as Qwen2.5-Omni, we extend retrieval beyond text and images to also\nsupport audio and video modalities. Omni-Embed-Nemotron enables both\ncross-modal (e.g., text - video) and joint-modal (e.g., text - video+audio)\nretrieval using a single model. We describe the architecture, training setup,\nand evaluation results of Omni-Embed-Nemotron, and demonstrate its\neffectiveness in text, image, and video retrieval.", "AI": {"tldr": "Omni-Embed-Nemotron\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u6a21\u6001\u68c0\u7d22\u5d4c\u5165\u6a21\u578b\uff0c\u652f\u6301\u6587\u672c\u3001\u56fe\u50cf\u3001\u97f3\u9891\u548c\u89c6\u9891\u7684\u8de8\u6a21\u6001\u68c0\u7d22\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6587\u672c\u7684\u68c0\u7d22\u5668\u5728\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u6587\u6863\uff08\u5982PDF\u3001\u5e7b\u706f\u7247\u3001\u89c6\u9891\uff09\u4e2d\u89c6\u89c9\u548c\u8bed\u4e49\u4e30\u5bcc\u7684\u5185\u5bb9\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u9700\u8981\u652f\u6301\u591a\u6a21\u6001\u68c0\u7d22\u3002", "method": "\u57fa\u4e8eColPali\u548cQwen2.5-Omni\u7b49\u5de5\u4f5c\u7684\u542f\u53d1\uff0c\u6784\u5efa\u4e86\u652f\u6301\u6587\u672c\u3001\u56fe\u50cf\u3001\u97f3\u9891\u548c\u89c6\u9891\u7684\u7edf\u4e00\u591a\u6a21\u6001\u68c0\u7d22\u6a21\u578b\u67b6\u6784\u3002", "result": "\u6a21\u578b\u5728\u6587\u672c\u3001\u56fe\u50cf\u548c\u89c6\u9891\u68c0\u7d22\u65b9\u9762\u8868\u73b0\u51fa\u6709\u6548\u6027\u3002", "conclusion": "Omni-Embed-Nemotron\u80fd\u591f\u6709\u6548\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u4e2d\u590d\u6742\u7684\u4fe1\u606f\u68c0\u7d22\u9700\u6c42\uff0c\u652f\u6301\u8de8\u6a21\u6001\u548c\u8054\u5408\u6a21\u6001\u68c0\u7d22\u3002"}}
{"id": "2510.03605", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.03605", "abs": "https://arxiv.org/abs/2510.03605", "authors": ["Adel Javanmard", "Baharan Mirzasoleiman", "Vahab Mirrokni"], "title": "Understanding the Role of Training Data in Test-Time Scaling", "comment": "24 pages, 4 figures", "summary": "Test-time scaling improves the reasoning capabilities of large language\nmodels (LLMs) by allocating extra compute to generate longer Chains-of-Thoughts\n(CoTs). This enables models to tackle more complex problem by breaking them\ndown into additional steps, backtracking, and correcting mistakes. Despite its\nstrong performance--demonstrated by OpenAI's o1 and DeepSeek R1, the conditions\nin the training data under which long CoTs emerge, and when such long CoTs\nimprove the performance, remain unclear. In this paper, we study the\nperformance of test-time scaling for transformers trained on an in-context\nweight prediction task for linear regression. Our analysis provides a\ntheoretical explanation for several intriguing observations: First, at any\nfixed test error, increasing test-time compute allows us to reduce the number\nof in-context examples (context length) in training prompts. Second, if the\nskills required to solve a downstream task are not sufficiently present in the\ntraining data, increasing test-time compute can harm performance. Finally, we\ncharacterize task hardness via the smallest eigenvalue of its feature\ncovariance matrix and show that training on a diverse, relevant, and hard set\nof tasks results in best performance for test-time scaling. We confirm our\nfindings with experiments on large, nonlinear transformer architectures.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\u5bf9Transformer\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5728\u7ebf\u6027\u56de\u5f52\u4efb\u52a1\u4e2d\uff0c\u589e\u52a0\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u53ef\u4ee5\u51cf\u5c11\u8bad\u7ec3\u6240\u9700\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u4f46\u524d\u63d0\u662f\u8bad\u7ec3\u6570\u636e\u5305\u542b\u8db3\u591f\u7684\u4efb\u52a1\u6280\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u6d4b\u8bd5\u65f6\u6269\u5c55\uff08\u5982\u957f\u94fe\u601d\u7ef4\uff09\u80fd\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5176\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u51fa\u73b0\u6761\u4ef6\u4ee5\u53ca\u4f55\u65f6\u80fd\u63d0\u5347\u6027\u80fd\u4ecd\u4e0d\u6e05\u695a\u3002", "method": "\u901a\u8fc7\u5728\u4e0a\u4e0b\u6587\u6743\u91cd\u9884\u6d4b\u7684\u7ebf\u6027\u56de\u5f52\u4efb\u52a1\u4e0a\u8bad\u7ec3Transformer\u6a21\u578b\uff0c\u8fdb\u884c\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1) \u589e\u52a0\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u53ef\u51cf\u5c11\u8bad\u7ec3\u6240\u9700\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\uff1b2) \u82e5\u8bad\u7ec3\u6570\u636e\u7f3a\u4e4f\u5fc5\u8981\u6280\u80fd\uff0c\u589e\u52a0\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u53cd\u800c\u6709\u5bb3\uff1b3) \u4efb\u52a1\u96be\u5ea6\u4e0e\u7279\u5f81\u534f\u65b9\u5dee\u77e9\u9635\u7684\u6700\u5c0f\u7279\u5f81\u503c\u76f8\u5173\u3002", "conclusion": "\u5728\u591a\u6837\u5316\u3001\u76f8\u5173\u4e14\u56f0\u96be\u7684\u4efb\u52a1\u96c6\u4e0a\u8bad\u7ec3\uff0c\u80fd\u4e3a\u6d4b\u8bd5\u65f6\u6269\u5c55\u5e26\u6765\u6700\u4f73\u6027\u80fd\u3002"}}
{"id": "2510.03467", "categories": ["cs.CL", "I.2.7; I.6.m"], "pdf": "https://arxiv.org/pdf/2510.03467", "abs": "https://arxiv.org/abs/2510.03467", "authors": ["Brendon Boldt", "David Mortensen"], "title": "Searching for the Most Human-like Emergent Language", "comment": "Accepted for publication at the 2025 Conference on Empirical Methods\n  in Natural Language Processing; 19 pages, 12 figures", "summary": "In this paper, we design a signalling game-based emergent communication\nenvironment to generate state-of-the-art emergent languages in terms of\nsimilarity to human language. This is done with hyperparameter optimization,\nusing XferBench as the objective function. XferBench quantifies the statistical\nsimilarity of emergent language to human language by measuring its suitability\nfor deep transfer learning to human language. Additionally, we demonstrate the\npredictive power of entropy on the transfer learning performance of emergent\nlanguage as well as corroborate previous results on the entropy-minimization\nproperties of emergent communication systems. Finally, we report\ngeneralizations regarding what hyperparameters produce more realistic emergent\nlanguages, that is, ones which transfer better to human language.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u57fa\u4e8e\u4fe1\u53f7\u535a\u5f08\u7684\u6d8c\u73b0\u901a\u4fe1\u73af\u5883\u548c\u8d85\u53c2\u6570\u4f18\u5316\uff0c\u751f\u6210\u4e86\u4e0e\u4eba\u7c7b\u8bed\u8a00\u76f8\u4f3c\u5ea6\u6700\u9ad8\u7684\u6d8c\u73b0\u8bed\u8a00\uff0c\u4f7f\u7528XferBench\u4f5c\u4e3a\u76ee\u6807\u51fd\u6570\u6765\u91cf\u5316\u7edf\u8ba1\u76f8\u4f3c\u6027\u3002", "motivation": "\u8bbe\u8ba1\u80fd\u591f\u751f\u6210\u4e0e\u4eba\u7c7b\u8bed\u8a00\u9ad8\u5ea6\u76f8\u4f3c\u7684\u6d8c\u73b0\u8bed\u8a00\uff0c\u901a\u8fc7\u6df1\u5ea6\u8fc1\u79fb\u5b66\u4e60\u6765\u8bc4\u4f30\u5176\u4e0e\u4eba\u7c7b\u8bed\u8a00\u7684\u7edf\u8ba1\u76f8\u4f3c\u6027\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u4fe1\u53f7\u535a\u5f08\u7684\u6d8c\u73b0\u901a\u4fe1\u73af\u5883\uff0c\u7ed3\u5408\u8d85\u53c2\u6570\u4f18\u5316\u65b9\u6cd5\uff0c\u4ee5XferBench\u4f5c\u4e3a\u76ee\u6807\u51fd\u6570\u6765\u91cf\u5316\u6d8c\u73b0\u8bed\u8a00\u4e0e\u4eba\u7c7b\u8bed\u8a00\u7684\u76f8\u4f3c\u5ea6\u3002", "result": "\u8bc1\u660e\u4e86\u71b5\u5bf9\u6d8c\u73b0\u8bed\u8a00\u8fc1\u79fb\u5b66\u4e60\u6027\u80fd\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u9a8c\u8bc1\u4e86\u6d8c\u73b0\u901a\u4fe1\u7cfb\u7edf\u7684\u71b5\u6700\u5c0f\u5316\u7279\u6027\uff0c\u5e76\u786e\u5b9a\u4e86\u4ea7\u751f\u66f4\u771f\u5b9e\u6d8c\u73b0\u8bed\u8a00\u7684\u5173\u952e\u8d85\u53c2\u6570\u3002", "conclusion": "\u901a\u8fc7\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u7edf\u8ba1\u4e0a\u66f4\u63a5\u8fd1\u4eba\u7c7b\u8bed\u8a00\u7684\u6d8c\u73b0\u8bed\u8a00\uff0c\u5e76\u63ed\u793a\u4e86\u71b5\u5728\u8bc4\u4f30\u6d8c\u73b0\u8bed\u8a00\u8d28\u91cf\u4e2d\u7684\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2510.03612", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.03612", "abs": "https://arxiv.org/abs/2510.03612", "authors": ["Tanqiu Jiang", "Min Bai", "Nikolaos Pappas", "Yanjun Qi", "Sandesh Swamy"], "title": "Cross-Modal Content Optimization for Steering Web Agent Preferences", "comment": null, "summary": "Vision-language model (VLM)-based web agents increasingly power high-stakes\nselection tasks like content recommendation or product ranking by combining\nmultimodal perception with preference reasoning. Recent studies reveal that\nthese agents are vulnerable against attackers who can bias selection outcomes\nthrough preference manipulations using adversarial pop-ups, image\nperturbations, or content tweaks. Existing work, however, either assumes strong\nwhite-box access, with limited single-modal perturbations, or uses impractical\nsettings. In this paper, we demonstrate, for the first time, that joint\nexploitation of visual and textual channels yields significantly more powerful\npreference manipulations under realistic attacker capabilities. We introduce\nCross-Modal Preference Steering (CPS) that jointly optimizes imperceptible\nmodifications to an item's visual and natural language descriptions, exploiting\nCLIP-transferable image perturbations and RLHF-induced linguistic biases to\nsteer agent decisions. In contrast to prior studies that assume gradient\naccess, or control over webpages, or agent memory, we adopt a realistic\nblack-box threat setup: a non-privileged adversary can edit only their own\nlisting's images and textual metadata, with no insight into the agent's model\ninternals. We evaluate CPS on agents powered by state-of-the-art proprietary\nand open source VLMs including GPT-4.1, Qwen-2.5VL and Pixtral-Large on both\nmovie selection and e-commerce tasks. Our results show that CPS is\nsignificantly more effective than leading baseline methods. For instance, our\nresults show that CPS consistently outperforms baselines across all models\nwhile maintaining 70% lower detection rates, demonstrating both effectiveness\nand stealth. These findings highlight an urgent need for robust defenses as\nagentic systems play an increasingly consequential role in society.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8de8\u6a21\u6001\u504f\u597d\u5f15\u5bfc\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u89c6\u89c9\u548c\u6587\u672c\u901a\u9053\u7684\u5fae\u5c0f\u4fee\u6539\u6765\u64cd\u7eb5VLM\u4ee3\u7406\u7684\u51b3\u7b56\uff0c\u5728\u73b0\u5b9e\u9ed1\u76d2\u5a01\u80c1\u8bbe\u7f6e\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709VLM\u4ee3\u7406\u5728\u5185\u5bb9\u63a8\u8350\u7b49\u9ad8\u98ce\u9669\u9009\u62e9\u4efb\u52a1\u4e2d\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u4f46\u5148\u524d\u7814\u7a76\u8981\u4e48\u5047\u8bbe\u767d\u76d2\u8bbf\u95ee\uff0c\u8981\u4e48\u4f7f\u7528\u4e0d\u5207\u5b9e\u9645\u7684\u8bbe\u7f6e\u3002\u672c\u6587\u65e8\u5728\u5c55\u793a\u5728\u73b0\u5b9e\u653b\u51fb\u8005\u80fd\u529b\u4e0b\uff0c\u8054\u5408\u5229\u7528\u89c6\u89c9\u548c\u6587\u672c\u901a\u9053\u53ef\u4ee5\u4ea7\u751f\u66f4\u5f3a\u5927\u7684\u504f\u597d\u64cd\u7eb5\u3002", "method": "\u63d0\u51fa\u8de8\u6a21\u6001\u504f\u597d\u5f15\u5bfc\u65b9\u6cd5\uff0c\u8054\u5408\u4f18\u5316\u5546\u54c1\u89c6\u89c9\u548c\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u4e0d\u53ef\u5bdf\u89c9\u4fee\u6539\uff0c\u5229\u7528CLIP\u53ef\u8fc1\u79fb\u56fe\u50cf\u6270\u52a8\u548cRLHF\u8bf1\u5bfc\u7684\u8bed\u8a00\u504f\u89c1\u6765\u5f15\u5bfc\u4ee3\u7406\u51b3\u7b56\u3002\u91c7\u7528\u73b0\u5b9e\u9ed1\u76d2\u5a01\u80c1\u8bbe\u7f6e\uff0c\u653b\u51fb\u8005\u53ea\u80fd\u7f16\u8f91\u81ea\u5df1\u5217\u8868\u7684\u56fe\u50cf\u548c\u6587\u672c\u5143\u6570\u636e\u3002", "result": "\u5728GPT-4.1\u3001Qwen-2.5VL\u548cPixtral-Large\u7b49\u6700\u5148\u8fdbVLM\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cCPS\u5728\u6240\u6709\u6a21\u578b\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u630170%\u66f4\u4f4e\u7684\u68c0\u6d4b\u7387\uff0c\u8bc1\u660e\u4e86\u6709\u6548\u6027\u548c\u9690\u853d\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u5f3a\u8c03\u4e86\u968f\u7740\u4ee3\u7406\u7cfb\u7edf\u5728\u793e\u4f1a\u4e2d\u626e\u6f14\u8d8a\u6765\u8d8a\u91cd\u8981\u7684\u89d2\u8272\uff0c\u8feb\u5207\u9700\u8981\u5f00\u53d1\u9c81\u68d2\u7684\u9632\u5fa1\u673a\u5236\u6765\u5e94\u5bf9\u6b64\u7c7b\u8de8\u6a21\u6001\u653b\u51fb\u3002"}}
{"id": "2510.03490", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03490", "abs": "https://arxiv.org/abs/2510.03490", "authors": ["Aneesha Sampath", "Oya Aran", "Emily Mower Provost"], "title": "SEER: The Span-based Emotion Evidence Retrieval Benchmark", "comment": null, "summary": "We introduce the SEER (Span-based Emotion Evidence Retrieval) Benchmark to\ntest Large Language Models' (LLMs) ability to identify the specific spans of\ntext that express emotion. Unlike traditional emotion recognition tasks that\nassign a single label to an entire sentence, SEER targets the underexplored\ntask of emotion evidence detection: pinpointing which exact phrases convey\nemotion. This span-level approach is crucial for applications like empathetic\ndialogue and clinical support, which need to know how emotion is expressed, not\njust what the emotion is. SEER includes two tasks: identifying emotion evidence\nwithin a single sentence, and identifying evidence across a short passage of\nfive consecutive sentences. It contains new annotations for both emotion and\nemotion evidence on 1200 real-world sentences. We evaluate 14 open-source LLMs\nand find that, while some models approach average human performance on\nsingle-sentence inputs, their accuracy degrades in longer passages. Our error\nanalysis reveals key failure modes, including overreliance on emotion keywords\nand false positives in neutral text.", "AI": {"tldr": "SEER\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30LLMs\u8bc6\u522b\u6587\u672c\u4e2d\u8868\u8fbe\u60c5\u611f\u7684\u5177\u4f53\u7247\u6bb5\u7684\u80fd\u529b\uff0c\u5305\u542b\u5355\u53e5\u548c\u8de8\u53e5\u60c5\u611f\u8bc1\u636e\u68c0\u6d4b\u4efb\u52a1\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u957f\u6587\u672c\u4e2d\u8868\u73b0\u4e0b\u964d\u3002", "motivation": "\u4f20\u7edf\u60c5\u611f\u8bc6\u522b\u53ea\u7ed9\u6574\u4e2a\u53e5\u5b50\u5206\u914d\u5355\u4e00\u6807\u7b7e\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u77e5\u9053\u60c5\u611f\u662f\u5982\u4f55\u8868\u8fbe\u7684\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u80fd\u591f\u7cbe\u786e\u5b9a\u4f4d\u60c5\u611f\u8868\u8fbe\u7247\u6bb5\u7684\u65b9\u6cd5\u3002", "method": "\u521b\u5efa\u5305\u542b1200\u4e2a\u771f\u5b9e\u4e16\u754c\u53e5\u5b50\u7684SEER\u57fa\u51c6\uff0c\u5305\u542b\u60c5\u611f\u548c\u60c5\u611f\u8bc1\u636e\u7684\u65b0\u6807\u6ce8\uff0c\u8bc4\u4f3014\u4e2a\u5f00\u6e90LLMs\u5728\u5355\u53e5\u548c\u8de8\u53e5\u60c5\u611f\u8bc1\u636e\u68c0\u6d4b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u4e00\u4e9b\u6a21\u578b\u5728\u5355\u53e5\u8f93\u5165\u4e0a\u63a5\u8fd1\u4eba\u7c7b\u5e73\u5747\u8868\u73b0\uff0c\u4f46\u5728\u8f83\u957f\u6bb5\u843d\u4e2d\u51c6\u786e\u6027\u4e0b\u964d\u3002\u9519\u8bef\u5206\u6790\u663e\u793a\u5173\u952e\u5931\u8d25\u6a21\u5f0f\u5305\u62ec\u8fc7\u5ea6\u4f9d\u8d56\u60c5\u611f\u5173\u952e\u8bcd\u548c\u5728\u4e2d\u6027\u6587\u672c\u4e2d\u51fa\u73b0\u8bef\u62a5\u3002", "conclusion": "SEER\u57fa\u51c6\u7a81\u663e\u4e86LLMs\u5728\u7ec6\u7c92\u5ea6\u60c5\u611f\u8bc1\u636e\u68c0\u6d4b\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u8f83\u957f\u6587\u672c\u65f6\uff0c\u4e3a\u6539\u8fdb\u60c5\u611f\u7406\u89e3\u6a21\u578b\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\u3002"}}
{"id": "2510.03632", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03632", "abs": "https://arxiv.org/abs/2510.03632", "authors": ["Jiaxi Li", "Yucheng Shi", "Jin Lu", "Ninghao Liu"], "title": "MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual Information", "comment": "18 pages", "summary": "Tree search has become as a representative framework for test-time reasoning\nwith large language models (LLMs), exemplified by methods such as\nTree-of-Thought and Monte Carlo Tree Search that explore multiple reasoning\npaths. However, it remains difficult to provide instant and reliable\nquantitative assessments of intermediate reasoning step quality, and extensive\npath exploration is computationally costly. To address this, we propose Mutual\nInformation Tree Search (MITS), a novel framework that guides reasoning with\ninformation-theoretic principles. MITS introduces an effective scoring function\nbased on pointwise mutual information (PMI), which enables step-wise evaluation\nof reasoning paths and search tree expansion via beam search without expensive\nlook-ahead simulations, achieving superior reasoning performances while\nmaintaining computational efficiency. The framework is complemented by an\nentropy-based dynamic sampling strategy that adaptively allocates computational\nresources to uncertain reasoning steps where exploration is most beneficial.\nFor final prediction, MITS employs a weighted voting scheme that combines PMI\nscores with prediction consensus. Through comprehensive experiments on diverse\nreasoning benchmarks, MITS consistently surpasses baseline methods,\nestablishing a principled and efficient framework for LLM reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e92\u4fe1\u606f\u7684\u6811\u641c\u7d22\u6846\u67b6MITS\uff0c\u901a\u8fc7\u70b9\u4e92\u4fe1\u606f\u8bc4\u5206\u51fd\u6570\u548c\u52a8\u6001\u91c7\u6837\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u6811\u641c\u7d22\u65b9\u6cd5\u5728\u6d4b\u8bd5\u65f6\u63a8\u7406\u4e2d\u96be\u4ee5\u5bf9\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u8fdb\u884c\u5373\u65f6\u53ef\u9760\u8bc4\u4f30\uff0c\u4ee5\u53ca\u5e7f\u6cdb\u8def\u5f84\u63a2\u7d22\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u4fe1\u606f\u8bba\u539f\u7406\uff0c\u4f7f\u7528\u70b9\u4e92\u4fe1\u606f(PMI)\u4f5c\u4e3a\u8bc4\u5206\u51fd\u6570\u8fdb\u884c\u6b65\u9aa4\u8bc4\u4f30\uff0c\u91c7\u7528\u57fa\u4e8e\u71b5\u7684\u52a8\u6001\u91c7\u6837\u7b56\u7565\u81ea\u9002\u5e94\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\uff0c\u6700\u540e\u4f7f\u7528\u52a0\u6743\u6295\u7968\u65b9\u6848\u7ed3\u5408PMI\u5206\u6570\u548c\u9884\u6d4b\u5171\u8bc6\u8fdb\u884c\u6700\u7ec8\u9884\u6d4b\u3002", "result": "\u5728\u591a\u6837\u5316\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMITS\u59cb\u7ec8\u8d85\u8d8a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5efa\u7acb\u4e86\u539f\u5219\u6027\u4e14\u9ad8\u6548\u7684LLM\u63a8\u7406\u6846\u67b6\u3002", "conclusion": "MITS\u63d0\u4f9b\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4fe1\u606f\u8bba\u539f\u7406\u7684\u9ad8\u6548\u6811\u641c\u7d22\u6846\u67b6\uff0c\u80fd\u591f\u5728\u4e0d\u8fdb\u884c\u6602\u8d35\u524d\u77bb\u6a21\u62df\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4f18\u8d8a\u7684\u63a8\u7406\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2510.03502", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03502", "abs": "https://arxiv.org/abs/2510.03502", "authors": ["Ali Khairallah", "Arkaitz Zubiaga"], "title": "ALHD: A Large-Scale and Multigenre Benchmark Dataset for Arabic LLM-Generated Text Detection", "comment": "47 pages, 15 figures. Dataset available at Zenodo:\n  https://doi.org/10.5281/zenodo.17249602 Codebase available at GitHub:\n  https://github.com/alikhairallah/ALHD-Benchmarking", "summary": "We introduce ALHD, the first large-scale comprehensive Arabic dataset\nexplicitly designed to distinguish between human- and LLM-generated texts. ALHD\nspans three genres (news, social media, reviews), covering both MSA and\ndialectal Arabic, and contains over 400K balanced samples generated by three\nleading LLMs and originated from multiple human sources, which enables studying\ngeneralizability in Arabic LLM-genearted text detection. We provide rigorous\npreprocessing, rich annotations, and standardized balanced splits to support\nreproducibility. In addition, we present, analyze and discuss benchmark\nexperiments using our new dataset, in turn identifying gaps and proposing\nfuture research directions. Benchmarking across traditional classifiers,\nBERT-based models, and LLMs (zero-shot and few-shot) demonstrates that\nfine-tuned BERT models achieve competitive performance, outperforming LLM-based\nmodels. Results are however not always consistent, as we observe challenges\nwhen generalizing across genres; indeed, models struggle to generalize when\nthey need to deal with unseen patterns in cross-genre settings, and these\nchallenges are particularly prominent when dealing with news articles, where\nLLM-generated texts resemble human texts in style, which opens up avenues for\nfuture research. ALHD establishes a foundation for research related to Arabic\nLLM-detection and mitigating risks of misinformation, academic dishonesty, and\ncyber threats.", "AI": {"tldr": "ALHD\u662f\u9996\u4e2a\u5927\u89c4\u6a21\u963f\u62c9\u4f2f\u8bed\u6570\u636e\u96c6\uff0c\u4e13\u95e8\u7528\u4e8e\u533a\u5206\u4eba\u7c7b\u548cLLM\u751f\u6210\u7684\u6587\u672c\uff0c\u6db5\u76d6\u65b0\u95fb\u3001\u793e\u4ea4\u5a92\u4f53\u548c\u8bc4\u8bba\u4e09\u79cd\u6587\u4f53\uff0c\u5305\u542b\u8d85\u8fc740\u4e07\u5e73\u8861\u6837\u672c\uff0c\u652f\u6301\u963f\u62c9\u4f2f\u8bedLLM\u6587\u672c\u68c0\u6d4b\u7684\u6cdb\u5316\u6027\u7814\u7a76\u3002", "motivation": "\u89e3\u51b3\u963f\u62c9\u4f2f\u8bed\u4e2d\u7f3a\u4e4f\u4e13\u95e8\u7528\u4e8e\u533a\u5206\u4eba\u7c7b\u548cLLM\u751f\u6210\u6587\u672c\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u7684\u95ee\u9898\uff0c\u4e3a\u7814\u7a76\u963f\u62c9\u4f2f\u8bedLLM\u68c0\u6d4b\u3001\u7f13\u89e3\u9519\u8bef\u4fe1\u606f\u3001\u5b66\u672f\u4e0d\u7aef\u548c\u7f51\u7edc\u5a01\u80c1\u98ce\u9669\u5960\u5b9a\u57fa\u7840\u3002", "method": "\u6784\u5efa\u5305\u542b\u4e09\u79cd\u6587\u4f53\uff08\u65b0\u95fb\u3001\u793e\u4ea4\u5a92\u4f53\u3001\u8bc4\u8bba\uff09\u7684\u963f\u62c9\u4f2f\u8bed\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u73b0\u4ee3\u6807\u51c6\u963f\u62c9\u4f2f\u8bed\u548c\u65b9\u8a00\uff0c\u4f7f\u7528\u4e09\u4e2a\u9886\u5148LLM\u751f\u6210\u6587\u672c\uff0c\u63d0\u4f9b\u4e25\u683c\u9884\u5904\u7406\u3001\u4e30\u5bcc\u6807\u6ce8\u548c\u6807\u51c6\u5316\u5e73\u8861\u5206\u5272\u3002", "result": "\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0c\u5fae\u8c03\u7684BERT\u6a21\u578b\u8868\u73b0\u7ade\u4e89\u6027\uff0c\u4f18\u4e8e\u57fa\u4e8eLLM\u7684\u6a21\u578b\u3002\u4f46\u5728\u8de8\u6587\u4f53\u6cdb\u5316\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u65b0\u95fb\u6587\u7ae0\u4e2d\uff0cLLM\u751f\u6210\u7684\u6587\u672c\u5728\u98ce\u683c\u4e0a\u66f4\u63a5\u8fd1\u4eba\u7c7b\u6587\u672c\u3002", "conclusion": "ALHD\u4e3a\u963f\u62c9\u4f2f\u8bedLLM\u68c0\u6d4b\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u8de8\u6587\u4f53\u6cdb\u5316\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u65b0\u95fb\u9886\u57df\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2510.03680", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03680", "abs": "https://arxiv.org/abs/2510.03680", "authors": ["Bumjun Kim", "Dongjae Jeon", "Dueun Kim", "Wonje Jeung", "Albert No"], "title": "Rainbow Padding: Mitigating Early Termination in Instruction-Tuned Diffusion LLMs", "comment": "25 pages. Project page available\n  at~\\url{https://ai-isl.github.io/rainbow-padding}", "summary": "Diffusion large language models (dLLMs) have emerged as a promising\nalternative to autoregressive models, offering flexible generation orders and\nstrong performance on complex reasoning tasks. However, instruction-tuned dLLMs\nexhibit a critical vulnerability we term \\texttt{<eos>} overflow: as allocated\nsequence length increases, responses paradoxically become shorter, collapsing\ninto early termination or degenerating into streams of \\texttt{<eos>} tokens.\nAlthough noticed in practice, this issue has not been systematically analyzed.\nWe trace its root cause to the dual role of \\texttt{<eos>} as both termination\nand padding, which concentrates probability mass on \\texttt{<eos>} at later\npositions and propagates backward to trigger early termination. To address\nthis, we introduce Rainbow Padding, a simple remedy that replaces repeated\n\\texttt{<eos>} placeholders with a repeating cycle of distinct padding tokens,\ndistributing probability mass and breaking \\texttt{<eos>} dominance.\nExperiments show that Rainbow Padding substantially improves length robustness\nand output quality, with as few as seven padding tokens sufficient to prevent\nearly termination. Moreover, the method integrates efficiently into existing\ninstruction-tuned models: LoRA fine-tuning for a single epoch on minimal data\nyields significant improvements, making this solution highly practical. The\ncode is publicly available at https://github.com/quasar529/rainbow-padding.", "AI": {"tldr": "\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b(dLLMs)\u5b58\u5728<eos>\u6ea2\u51fa\u95ee\u9898\uff1a\u968f\u7740\u5e8f\u5217\u957f\u5ea6\u589e\u52a0\uff0c\u54cd\u5e94\u53cd\u800c\u53d8\u77ed\uff0c\u5bfc\u81f4\u63d0\u524d\u7ec8\u6b62\u6216\u9000\u5316\u4e3a<eos>\u4ee4\u724c\u6d41\u3002\u4f5c\u8005\u63d0\u51fa\u4e86Rainbow Padding\u65b9\u6cd5\uff0c\u7528\u5faa\u73af\u7684\u4e0d\u540c\u586b\u5145\u4ee4\u724c\u66ff\u6362\u91cd\u590d\u7684<eos>\u5360\u4f4d\u7b26\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8fd9\u4e00\u95ee\u9898\u3002", "motivation": "\u6307\u4ee4\u8c03\u4f18\u7684\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728<eos>\u6ea2\u51fa\u6f0f\u6d1e\uff0c\u968f\u7740\u5206\u914d\u5e8f\u5217\u957f\u5ea6\u7684\u589e\u52a0\uff0c\u54cd\u5e94\u4f1a\u53cd\u5e38\u5730\u53d8\u77ed\uff0c\u5bfc\u81f4\u63d0\u524d\u7ec8\u6b62\u6216\u9000\u5316\u4e3a<eos>\u4ee4\u724c\u6d41\u3002\u8fd9\u4e2a\u95ee\u9898\u867d\u7136\u5728\u5b9e\u8df5\u4e2d\u88ab\u6ce8\u610f\u5230\uff0c\u4f46\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u5206\u6790\u3002", "method": "\u63d0\u51fa\u4e86Rainbow Padding\u65b9\u6cd5\uff0c\u7528\u5faa\u73af\u7684\u4e0d\u540c\u586b\u5145\u4ee4\u724c\u66ff\u6362\u91cd\u590d\u7684<eos>\u5360\u4f4d\u7b26\uff0c\u5206\u6563\u6982\u7387\u8d28\u91cf\u5e76\u6253\u7834<eos>\u7684\u4e3b\u5bfc\u5730\u4f4d\u3002\u8be5\u65b9\u6cd5\u53ef\u4ee5\u9ad8\u6548\u96c6\u6210\u5230\u73b0\u6709\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u4e2d\uff0c\u4ec5\u9700\u5c11\u91cf\u6570\u636e\u548c\u5355\u8f6eLoRA\u5fae\u8c03\u5373\u53ef\u663e\u8457\u6539\u8fdb\u3002", "result": "Rainbow Padding\u663e\u8457\u63d0\u9ad8\u4e86\u957f\u5ea6\u9c81\u68d2\u6027\u548c\u8f93\u51fa\u8d28\u91cf\uff0c\u4ec5\u9700\u4e03\u4e2a\u586b\u5145\u4ee4\u724c\u5c31\u8db3\u4ee5\u9632\u6b62\u63d0\u524d\u7ec8\u6b62\u3002\u8be5\u65b9\u6cd5\u5728\u73b0\u6709\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u4e0a\u7684\u96c6\u6210\u6548\u7387\u5f88\u9ad8\uff0c\u4f7f\u7528\u6700\u5c0f\u6570\u636e\u548c\u5355\u8f6eLoRA\u5fae\u8c03\u5373\u53ef\u83b7\u5f97\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "Rainbow Padding\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684<eos>\u6ea2\u51fa\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u957f\u5e8f\u5217\u751f\u6210\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u8f93\u51fa\u8d28\u91cf\uff0c\u4e14\u5177\u6709\u5f88\u9ad8\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.03519", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03519", "abs": "https://arxiv.org/abs/2510.03519", "authors": ["Fangxu Yu", "Hongyu Zhao", "Tianyi Zhou"], "title": "TS-Reasoner: Aligning Time Series Foundation Models with LLM Reasoning", "comment": null, "summary": "Time series reasoning is crucial to decision-making in diverse domains,\nincluding finance, energy usage, traffic, weather, and scientific discovery.\nWhile existing time series foundation models (TSFMs) can capture low-level\ndynamic patterns and provide accurate forecasting, further analysis usually\nrequires additional background knowledge and sophisticated reasoning, which are\nlacking in most TSFMs but can be achieved through large language models (LLMs).\nOn the other hand, without expensive post-training, LLMs often struggle with\nthe numerical understanding of time series data. Although it is intuitive to\nintegrate the two types of models, developing effective training recipes that\nalign the two modalities for reasoning tasks is still an open challenge. To\nthis end, we propose TS-Reasoner that aligns the latent representations of\nTSFMs with the textual inputs of LLMs for downstream understanding/reasoning\ntasks. Specifically, we propose a simple yet effective method to curate\ndiverse, synthetic pairs of time series and textual captions for alignment\ntraining. We then develop a two-stage training recipe that applies instruction\nfinetuning after the alignment pretraining. Unlike existing works that train an\nLLM to take time series as inputs, we leverage a pretrained TSFM and freeze it\nduring training. Extensive experiments on several benchmarks demonstrate that\nTS-Reasoner not only outperforms a wide range of prevailing LLMs, Vision\nLanguage Models (VLMs), and Time Series LLMs, but also achieves this with\nremarkable data efficiency, e.g., using less than half the training data.", "AI": {"tldr": "\u63d0\u51fa\u4e86TS-Reasoner\u6a21\u578b\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b(TSFMs)\u7684\u6f5c\u5728\u8868\u793a\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u7684\u6587\u672c\u8f93\u5165\u5bf9\u9f50\uff0c\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u80fd\u6355\u6349\u52a8\u6001\u6a21\u5f0f\u4f46\u7f3a\u4e4f\u63a8\u7406\u80fd\u529b\uff0c\u800cLLMs\u5177\u6709\u63a8\u7406\u80fd\u529b\u4f46\u4e0d\u64c5\u957f\u6570\u503c\u7406\u89e3\u3002\u9700\u8981\u5c06\u4e24\u8005\u6709\u6548\u7ed3\u5408\u6765\u89e3\u51b3\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\uff1a\u9996\u5148\u4f7f\u7528\u5408\u6210\u7684\u65f6\u5e8f-\u6587\u672c\u5bf9\u8fdb\u884c\u5bf9\u9f50\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u8fdb\u884c\u6307\u4ee4\u5fae\u8c03\u3002\u51bb\u7ed3\u9884\u8bad\u7ec3\u7684TSFM\uff0c\u53ea\u8bad\u7ec3\u5bf9\u9f50\u6a21\u5757\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTS-Reasoner\u4f18\u4e8e\u4e3b\u6d41LLMs\u3001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u65f6\u95f4\u5e8f\u5217LLMs\uff0c\u4e14\u5177\u6709\u663e\u8457\u7684\u6570\u636e\u6548\u7387(\u4f7f\u7528\u4e0d\u5230\u4e00\u534a\u7684\u8bad\u7ec3\u6570\u636e)\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u4e0e\u8bed\u8a00\u6a21\u578b\u7684\u6709\u6548\u5bf9\u9f50\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.03696", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03696", "abs": "https://arxiv.org/abs/2510.03696", "authors": ["Deepak Babu Piskala", "Sharlene Chen", "Udita Patel", "Parul Kalra", "Rafael Castrillo"], "title": "Mind the Goal: Data-Efficient Goal-Oriented Evaluation of Conversational Agents and Chatbots using Teacher Models", "comment": null, "summary": "Evaluating the quality of multi-turn chatbot interactions remains\nchallenging, as most existing methods assess interactions at the turn level\nwithout addressing whether a user's overarching goal was fulfilled. A ``goal''\nhere refers to an information need or task, such as asking for policy\ninformation or applying for leave. We propose a comprehensive framework for\ngoal-oriented evaluation of multi-agent systems (MAS), introducing the\n\\textbf{Goal Success Rate (GSR)} to measure the percentage of fulfilled goals,\nand a \\textbf{Root Cause of Failure (RCOF)} taxonomy to identify reasons for\nfailure in multi-agent chatbots. Our method segments conversations by user\ngoals and evaluates success using all relevant turns. We present a model-based\nevaluation system combining teacher LLMs, where domain experts define goals,\nset quality standards serving as a guidance for the LLMs. The LLMs use\n``thinking tokens'' to produce interpretable rationales, enabling\n\\textit{explainable}, \\textit{data-efficient} evaluations. In an enterprise\nsetting, we apply our framework to evaluate AIDA, a zero-to-one employee\nconversational agent system built as a ground-up multi-agent conversational\nagent, and observe GSR improvement from 63\\% to 79\\% over six months since its\ninception. Our framework is generic and offers actionable insights through a\ndetailed defect taxonomy based on analysis of failure points in multi-agent\nchatbots, diagnosing overall success, identifying key failure modes, and\ninforming system improvements.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9762\u5411\u76ee\u6807\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\uff0c\u5f15\u5165\u76ee\u6807\u6210\u529f\u7387(GSR)\u548c\u5931\u8d25\u6839\u56e0\u5206\u7c7b(RCOF)\uff0c\u901a\u8fc7\u6559\u5e08LLM\u6a21\u578b\u8fdb\u884c\u53ef\u89e3\u91ca\u3001\u6570\u636e\u9ad8\u6548\u7684\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u591a\u5728\u8f6e\u6b21\u5c42\u9762\u8bc4\u4f30\u804a\u5929\u673a\u5668\u4eba\u4ea4\u4e92\uff0c\u65e0\u6cd5\u5224\u65ad\u7528\u6237\u6574\u4f53\u76ee\u6807\u662f\u5426\u8fbe\u6210\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u76ee\u6807\u5bfc\u5411\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u57fa\u4e8e\u7528\u6237\u76ee\u6807\u5206\u5272\u5bf9\u8bdd\uff0c\u4f7f\u7528\u6559\u5e08LLM\u6a21\u578b\u7ed3\u5408\u9886\u57df\u4e13\u5bb6\u5b9a\u4e49\u7684\u76ee\u6807\u548c\u8d28\u91cf\u6807\u51c6\uff0c\u901a\u8fc7\"\u601d\u8003\u6807\u8bb0\"\u751f\u6210\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30\u7406\u7531\u3002", "result": "\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u5e94\u7528\u8be5\u6846\u67b6\u8bc4\u4f30AIDA\u7cfb\u7edf\uff0c\u89c2\u5bdf\u5230\u76ee\u6807\u6210\u529f\u7387\u4ece63%\u63d0\u5347\u523079%\u3002", "conclusion": "\u8be5\u6846\u67b6\u5177\u6709\u901a\u7528\u6027\uff0c\u901a\u8fc7\u8be6\u7ec6\u7684\u7f3a\u9677\u5206\u7c7b\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\uff0c\u80fd\u591f\u8bca\u65ad\u6574\u4f53\u6210\u529f\u7387\u3001\u8bc6\u522b\u5173\u952e\u5931\u8d25\u6a21\u5f0f\u5e76\u6307\u5bfc\u7cfb\u7edf\u6539\u8fdb\u3002"}}
{"id": "2510.03521", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03521", "abs": "https://arxiv.org/abs/2510.03521", "authors": ["Ali Elahi"], "title": "Identifying Financial Risk Information Using RAG with a Contrastive Insight", "comment": "7 pages, 1 figure, Workshop on Generative AI in Finance, NeurIPS 2025", "summary": "In specialized domains, humans often compare new problems against similar\nexamples, highlight nuances, and draw conclusions instead of analyzing\ninformation in isolation. When applying reasoning in specialized contexts with\nLLMs on top of a RAG, the pipeline can capture contextually relevant\ninformation, but it is not designed to retrieve comparable cases or related\nproblems.\n  While RAG is effective at extracting factual information, its outputs in\nspecialized reasoning tasks often remain generic, reflecting broad facts rather\nthan context-specific insights. In finance, it results in generic risks that\nare true for the majority of companies. To address this limitation, we propose\na peer-aware comparative inference layer on top of RAG.\n  Our contrastive approach outperforms baseline RAG in text generation metrics\nsuch as ROUGE and BERTScore in comparison with human-generated equity research\nand risk.", "AI": {"tldr": "\u5728\u4e13\u4e1a\u9886\u57df\u63a8\u7406\u4e2d\uff0c\u4f20\u7edfRAG\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u68c0\u7d22\u53ef\u6bd4\u6848\u4f8b\u6216\u76f8\u5173\u95ee\u9898\u3002\u672c\u6587\u63d0\u51fa\u5728RAG\u4e4b\u4e0a\u6dfb\u52a0\u540c\u884c\u611f\u77e5\u6bd4\u8f83\u63a8\u7406\u5c42\uff0c\u901a\u8fc7\u5bf9\u6bd4\u65b9\u6cd5\u63d0\u5347\u6587\u672c\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u5728\u4e13\u4e1a\u9886\u57df\u63a8\u7406\u4e2d\uff0c\u4eba\u7c7b\u901a\u5e38\u4f1a\u6bd4\u8f83\u76f8\u4f3c\u6848\u4f8b\u5e76\u5206\u6790\u7ec6\u5fae\u5dee\u5f02\uff0c\u800c\u4f20\u7edfRAG\u65b9\u6cd5\u867d\u7136\u80fd\u6355\u83b7\u4e0a\u4e0b\u6587\u76f8\u5173\u4fe1\u606f\uff0c\u4f46\u65e0\u6cd5\u68c0\u7d22\u53ef\u6bd4\u6848\u4f8b\u6216\u76f8\u5173\u95ee\u9898\uff0c\u5bfc\u81f4\u8f93\u51fa\u8fc7\u4e8e\u901a\u7528\u5316\u3002", "method": "\u5728RAG\u4e4b\u4e0a\u6784\u5efa\u540c\u884c\u611f\u77e5\u6bd4\u8f83\u63a8\u7406\u5c42\uff0c\u91c7\u7528\u5bf9\u6bd4\u65b9\u6cd5\u8fdb\u884c\u63a8\u7406\u5206\u6790\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6587\u672c\u751f\u6210\u6307\u6807\uff08\u5982ROUGE\u548cBERTScore\uff09\u4e0a\u4f18\u4e8e\u57fa\u7ebfRAG\u65b9\u6cd5\uff0c\u4e0e\u4eba\u7c7b\u751f\u6210\u7684\u80a1\u6743\u7814\u7a76\u548c\u98ce\u9669\u8bc4\u4f30\u76f8\u6bd4\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u63d0\u51fa\u7684\u5bf9\u6bd4\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3RAG\u5728\u4e13\u4e1a\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u751f\u6210\u66f4\u5177\u4e0a\u4e0b\u6587\u7279\u5b9a\u6d1e\u5bdf\u529b\u7684\u8f93\u51fa\u3002"}}
{"id": "2510.03700", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03700", "abs": "https://arxiv.org/abs/2510.03700", "authors": ["Seungseop Lim", "Gibaeg Kim", "Hyunkyung Lee", "Wooseok Han", "Jean Seo", "Jaehyo Yoo", "Eunho Yang"], "title": "H-DDx: A Hierarchical Evaluation Framework for Differential Diagnosis", "comment": "GenAI4Health @NeurIPS 2025", "summary": "An accurate differential diagnosis (DDx) is essential for patient care,\nshaping therapeutic decisions and influencing outcomes. Recently, Large\nLanguage Models (LLMs) have emerged as promising tools to support this process\nby generating a DDx list from patient narratives. However, existing evaluations\nof LLMs in this domain primarily rely on flat metrics, such as Top-k accuracy,\nwhich fail to distinguish between clinically relevant near-misses and\ndiagnostically distant errors. To mitigate this limitation, we introduce H-DDx,\na hierarchical evaluation framework that better reflects clinical relevance.\nH-DDx leverages a retrieval and reranking pipeline to map free-text diagnoses\nto ICD-10 codes and applies a hierarchical metric that credits predictions\nclosely related to the ground-truth diagnosis. In benchmarking 22 leading\nmodels, we show that conventional flat metrics underestimate performance by\noverlooking clinically meaningful outputs, with our results highlighting the\nstrengths of domain-specialized open-source models. Furthermore, our framework\nenhances interpretability by revealing hierarchical error patterns,\ndemonstrating that LLMs often correctly identify the broader clinical context\neven when the precise diagnosis is missed.", "AI": {"tldr": "\u63d0\u51fa\u4e86H-DDx\u5206\u5c42\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9274\u522b\u8bca\u65ad\u4e2d\u7684\u8868\u73b0\uff0c\u514b\u670d\u4f20\u7edf\u5e73\u9762\u6307\u6807\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709LLM\u5728\u9274\u522b\u8bca\u65ad\u8bc4\u4f30\u4e2d\u4e3b\u8981\u4f9d\u8d56Top-k\u51c6\u786e\u7387\u7b49\u5e73\u9762\u6307\u6807\uff0c\u65e0\u6cd5\u533a\u5206\u4e34\u5e8a\u76f8\u5173\u7684\u8fd1\u4f3c\u9519\u8bef\u548c\u8bca\u65ad\u4e0a\u9065\u8fdc\u7684\u9519\u8bef\uff0c\u9700\u8981\u66f4\u7b26\u5408\u4e34\u5e8a\u76f8\u5173\u6027\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5f15\u5165H-DDx\u5206\u5c42\u8bc4\u4f30\u6846\u67b6\uff0c\u91c7\u7528\u68c0\u7d22\u548c\u91cd\u6392\u5e8f\u6d41\u7a0b\u5c06\u81ea\u7531\u6587\u672c\u8bca\u65ad\u6620\u5c04\u5230ICD-10\u4ee3\u7801\uff0c\u5e76\u5e94\u7528\u5206\u5c42\u6307\u6807\u6765\u5956\u52b1\u4e0e\u771f\u5b9e\u8bca\u65ad\u5bc6\u5207\u76f8\u5173\u7684\u9884\u6d4b\u3002", "result": "\u5bf922\u4e2a\u9886\u5148\u6a21\u578b\u7684\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0c\u4f20\u7edf\u5e73\u9762\u6307\u6807\u4f4e\u4f30\u4e86\u6027\u80fd\uff0c\u5ffd\u7565\u4e86\u4e34\u5e8a\u6709\u610f\u4e49\u7684\u8f93\u51fa\uff1b\u9886\u57df\u4e13\u7528\u5f00\u6e90\u6a21\u578b\u8868\u73b0\u7a81\u51fa\uff1b\u6846\u67b6\u589e\u5f3a\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u63ed\u793a\u4e86\u5206\u5c42\u9519\u8bef\u6a21\u5f0f\u3002", "conclusion": "H-DDx\u6846\u67b6\u80fd\u66f4\u51c6\u786e\u5730\u8bc4\u4f30LLM\u5728\u9274\u522b\u8bca\u65ad\u4e2d\u7684\u8868\u73b0\uff0c\u663e\u793a\u6a21\u578b\u5373\u4f7f\u9519\u8fc7\u7cbe\u786e\u8bca\u65ad\u4e5f\u5e38\u80fd\u6b63\u786e\u8bc6\u522b\u66f4\u5e7f\u6cdb\u7684\u4e34\u5e8a\u80cc\u666f\u3002"}}
{"id": "2510.03527", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03527", "abs": "https://arxiv.org/abs/2510.03527", "authors": ["Sayan Ghosh", "Shahzaib Saqib Warraich", "Dhruv Tarsadiya", "Gregory Yauney", "Swabha Swayamdipta"], "title": "Sample, Align, Synthesize: Graph-Based Response Synthesis with ConGrs", "comment": null, "summary": "Language models can be sampled multiple times to access the distribution\nunderlying their responses, but existing methods cannot efficiently synthesize\nrich epistemic signals across different long-form responses. We introduce\nConsensus Graphs (ConGrs), a flexible DAG-based data structure that represents\nshared information, as well as semantic variation in a set of sampled LM\nresponses to the same prompt. We construct ConGrs using a light-weight lexical\nsequence alignment algorithm from bioinformatics, supplemented by the targeted\nusage of a secondary LM judge. Further, we design task-dependent decoding\nmethods to synthesize a single, final response from our ConGr data structure.\nOur experiments show that synthesizing responses from ConGrs improves factual\nprecision on two biography generation tasks by up to 31% over an average\nresponse and reduces reliance on LM judges by more than 80% compared to other\nmethods. We also use ConGrs for three refusal-based tasks requiring abstention\non unanswerable queries and find that abstention rate is increased by up to\n56%. We apply our approach to the MATH and AIME reasoning tasks and find an\nimprovement over self-verification and majority vote baselines by up to 6\npoints of accuracy. We show that ConGrs provide a flexible method for capturing\nvariation in LM responses and using the epistemic signals provided by response\nvariation to synthesize more effective responses.", "AI": {"tldr": "\u63d0\u51faConsensus Graphs (ConGrs)\u6570\u636e\u7ed3\u6784\uff0c\u901a\u8fc7\u6574\u5408\u591a\u4e2a\u8bed\u8a00\u6a21\u578b\u54cd\u5e94\u7684\u5171\u4eab\u4fe1\u606f\u548c\u8bed\u4e49\u53d8\u5316\uff0c\u5408\u6210\u66f4\u51c6\u786e\u548c\u6709\u6548\u7684\u6700\u7ec8\u54cd\u5e94\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u6574\u5408\u591a\u4e2a\u957f\u6587\u672c\u54cd\u5e94\u4e2d\u7684\u4e30\u5bcc\u8ba4\u77e5\u4fe1\u53f7\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u6355\u6349\u8bed\u8a00\u6a21\u578b\u54cd\u5e94\u53d8\u5316\u5e76\u5229\u7528\u8fd9\u4e9b\u8ba4\u77e5\u4fe1\u53f7\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u751f\u7269\u4fe1\u606f\u5b66\u7684\u8f7b\u91cf\u7ea7\u8bcd\u6c47\u5e8f\u5217\u5bf9\u9f50\u7b97\u6cd5\u6784\u5efaConGrs\u6570\u636e\u7ed3\u6784\uff0c\u8f85\u4ee5\u8f85\u52a9\u8bed\u8a00\u6a21\u578b\u5224\u65ad\uff0c\u5e76\u8bbe\u8ba1\u4efb\u52a1\u76f8\u5173\u7684\u89e3\u7801\u65b9\u6cd5\u4eceConGr\u5408\u6210\u6700\u7ec8\u54cd\u5e94\u3002", "result": "\u5728\u4f20\u8bb0\u751f\u6210\u4efb\u52a1\u4e2d\u4e8b\u5b9e\u7cbe\u5ea6\u63d0\u9ad831%\uff0c\u51cf\u5c11\u5bf9\u8bed\u8a00\u6a21\u578b\u5224\u65ad\u7684\u4f9d\u8d56\u8d85\u8fc780%\uff1b\u5728\u62d2\u7edd\u4efb\u52a1\u4e2d\u5f03\u6743\u7387\u63d0\u9ad856%\uff1b\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u51c6\u786e\u7387\u6bd4\u57fa\u7ebf\u63d0\u9ad86\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "ConGrs\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u7684\u65b9\u6cd5\u6765\u6355\u6349\u8bed\u8a00\u6a21\u578b\u54cd\u5e94\u7684\u53d8\u5316\uff0c\u5e76\u5229\u7528\u54cd\u5e94\u53d8\u5316\u63d0\u4f9b\u7684\u8ba4\u77e5\u4fe1\u53f7\u6765\u5408\u6210\u66f4\u6709\u6548\u7684\u54cd\u5e94\u3002"}}
{"id": "2510.03727", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03727", "abs": "https://arxiv.org/abs/2510.03727", "authors": ["Xuehai He"], "title": "Bridging the Gap Between Multimodal Foundation Models and World Models", "comment": "PhD thesis", "summary": "Humans understand the world through the integration of multiple sensory\nmodalities, enabling them to perceive, reason about, and imagine dynamic\nphysical processes. Inspired by this capability, multimodal foundation models\n(MFMs) have emerged as powerful tools for multimodal understanding and\ngeneration. However, today's MFMs fall short of serving as effective world\nmodels. They lack the essential ability such as perform counterfactual\nreasoning, simulate dynamics, understand the spatiotemporal information,\ncontrol generated visual outcomes, and perform multifaceted reasoning. We\ninvestigates what it takes to bridge the gap between multimodal foundation\nmodels and world models. We begin by improving the reasoning capabilities of\nMFMs through discriminative tasks and equipping MFMs with structured reasoning\nskills, such as causal inference, counterfactual thinking, and spatiotemporal\nreasoning, enabling them to go beyond surface correlations and understand\ndeeper relationships within visual and textual data. Next, we explore\ngenerative capabilities of multimodal foundation models across both image and\nvideo modalities, introducing new frameworks for structured and controllable\ngeneration. Our approaches incorporate scene graphs, multimodal conditioning,\nand multimodal alignment strategies to guide the generation process, ensuring\nconsistency with high-level semantics and fine-grained user intent. We further\nextend these techniques to controllable 4D generation, enabling interactive,\neditable, and morphable object synthesis over time and space.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u5982\u4f55\u5f25\u5408\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u4e0e\u4e16\u754c\u6a21\u578b\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u901a\u8fc7\u589e\u5f3a\u63a8\u7406\u80fd\u529b\u548c\u751f\u6210\u80fd\u529b\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u8fdb\u884c\u53cd\u4e8b\u5b9e\u63a8\u7406\u3001\u65f6\u7a7a\u7406\u89e3\u3001\u53ef\u63a7\u751f\u6210\u7b49\u590d\u6742\u4efb\u52a1\u3002", "motivation": "\u53d7\u4eba\u7c7b\u591a\u611f\u5b98\u6574\u5408\u7406\u89e3\u4e16\u754c\u7684\u542f\u53d1\uff0c\u5f53\u524d\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5728\u4f5c\u4e3a\u4e16\u754c\u6a21\u578b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u53cd\u4e8b\u5b9e\u63a8\u7406\u3001\u52a8\u6001\u6a21\u62df\u3001\u65f6\u7a7a\u4fe1\u606f\u7406\u89e3\u3001\u53ef\u63a7\u751f\u6210\u548c\u591a\u65b9\u9762\u63a8\u7406\u7b49\u5173\u952e\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5224\u522b\u6027\u4efb\u52a1\u63d0\u5347\u63a8\u7406\u80fd\u529b\uff0c\u8d4b\u4e88\u7ed3\u6784\u5316\u63a8\u7406\u6280\u80fd\uff08\u56e0\u679c\u63a8\u7406\u3001\u53cd\u4e8b\u5b9e\u601d\u7ef4\u3001\u65f6\u7a7a\u63a8\u7406\uff09\uff1b\u5f00\u53d1\u7ed3\u6784\u5316\u53ef\u63a7\u751f\u6210\u6846\u67b6\uff0c\u7ed3\u5408\u573a\u666f\u56fe\u3001\u591a\u6a21\u6001\u6761\u4ef6\u7ea6\u675f\u548c\u5bf9\u9f50\u7b56\u7565\uff1b\u6269\u5c55\u5230\u53ef\u63a74D\u751f\u6210\uff0c\u652f\u6301\u65f6\u7a7a\u4ea4\u4e92\u5f0f\u53ef\u7f16\u8f91\u5408\u6210\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4f7f\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u80fd\u591f\u8d85\u8d8a\u8868\u9762\u76f8\u5173\u6027\uff0c\u7406\u89e3\u89c6\u89c9\u548c\u6587\u672c\u6570\u636e\u4e2d\u7684\u6df1\u5c42\u5173\u7cfb\uff0c\u5b9e\u73b0\u4e0e\u9ad8\u5c42\u8bed\u4e49\u548c\u7ec6\u7c92\u5ea6\u7528\u6237\u610f\u56fe\u4e00\u81f4\u7684\u751f\u6210\u7ed3\u679c\u3002", "conclusion": "\u901a\u8fc7\u589e\u5f3a\u63a8\u7406\u548c\u751f\u6210\u80fd\u529b\uff0c\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u53ef\u4ee5\u66f4\u597d\u5730\u6a21\u62df\u4e16\u754c\u6a21\u578b\u7684\u529f\u80fd\uff0c\u652f\u6301\u66f4\u590d\u6742\u7684\u8ba4\u77e5\u4efb\u52a1\u548c\u53ef\u63a7\u5185\u5bb9\u751f\u6210\u3002"}}
{"id": "2510.03528", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03528", "abs": "https://arxiv.org/abs/2510.03528", "authors": ["Ahmed Alajrami", "Xingwei Tan", "Nikolaos Aletras"], "title": "Fine-Tuning on Noisy Instructions: Effects on Generalization and Performance", "comment": null, "summary": "Instruction-tuning plays a vital role in enhancing the task-solving abilities\nof large language models (LLMs), improving their usability in generating\nhelpful responses on various tasks. However, previous work has demonstrated\nthat they are sensitive to minor variations in instruction phrasing. In this\npaper, we explore whether introducing perturbations in instruction-tuning data\ncan enhance LLMs' resistance against noisy instructions. We focus on how\ninstruction-tuning with perturbations, such as removing stop words or shuffling\nwords, affects LLMs' performance on the original and perturbed versions of\nwidely-used benchmarks (MMLU, BBH, GSM8K). We further assess learning dynamics\nand potential shifts in model behavior. Surprisingly, our results suggest that\ninstruction-tuning on perturbed instructions can, in some cases, improve\ndownstream performance. These findings highlight the importance of including\nperturbed instructions in instruction-tuning, which can make LLMs more\nresilient to noisy user inputs.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u4e2d\u5f15\u5165\u6270\u52a8\uff08\u5982\u5220\u9664\u505c\u7528\u8bcd\u6216\u6253\u4e71\u8bcd\u5e8f\uff09\u53ef\u4ee5\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u566a\u58f0\u6307\u4ee4\u7684\u62b5\u6297\u80fd\u529b\uff0c\u6709\u65f6\u751a\u81f3\u80fd\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u6307\u4ee4\u8868\u8ff0\u7684\u5fae\u5c0f\u53d8\u5316\u5f88\u654f\u611f\uff0c\u672c\u6587\u63a2\u7d22\u901a\u8fc7\u5728\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u4e2d\u5f15\u5165\u6270\u52a8\u6765\u589e\u5f3a\u6a21\u578b\u5bf9\u566a\u58f0\u6307\u4ee4\u7684\u9c81\u68d2\u6027\u3002", "method": "\u5728\u6307\u4ee4\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u5f15\u5165\u6270\u52a8\uff0c\u5982\u5220\u9664\u505c\u7528\u8bcd\u6216\u6253\u4e71\u8bcd\u5e8f\uff0c\u5e76\u5728MMLU\u3001BBH\u3001GSM8K\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8bc4\u4f30\u6a21\u578b\u5728\u539f\u59cb\u548c\u6270\u52a8\u7248\u672c\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u4ee4\u4eba\u60ca\u8bb6\u7684\u662f\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u5bf9\u6270\u52a8\u6307\u4ee4\u8fdb\u884c\u6307\u4ee4\u5fae\u8c03\u53ef\u4ee5\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u5728\u6307\u4ee4\u5fae\u8c03\u4e2d\u5305\u542b\u6270\u52a8\u6307\u4ee4\u5f88\u91cd\u8981\uff0c\u8fd9\u80fd\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u566a\u58f0\u7528\u6237\u8f93\u5165\u66f4\u5177\u5f39\u6027\u3002"}}
{"id": "2510.03771", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03771", "abs": "https://arxiv.org/abs/2510.03771", "authors": ["Divij Handa", "David Blincoe", "Orson Adams", "Yinlin Fu"], "title": "OptAgent: Optimizing Query Rewriting for E-commerce via Multi-Agent Simulation", "comment": null, "summary": "Deploying capable and user-aligned LLM-based systems necessitates reliable\nevaluation. While LLMs excel in verifiable tasks like coding and mathematics,\nwhere gold-standard solutions are available, adoption remains challenging for\nsubjective tasks that lack a single correct answer. E-commerce Query Rewriting\n(QR) is one such problem where determining whether a rewritten query properly\ncaptures the user intent is extremely difficult to figure out algorithmically.\nIn this work, we introduce OptAgent, a novel framework that combines\nmulti-agent simulations with genetic algorithms to verify and optimize queries\nfor QR. Instead of relying on a static reward model or a single LLM judge, our\napproach uses multiple LLM-based agents, each acting as a simulated shopping\ncustomer, as a dynamic reward signal. The average of these agent-derived scores\nserves as an effective fitness function for an evolutionary algorithm that\niteratively refines the user's initial query. We evaluate OptAgent on a dataset\nof 1000 real-world e-commerce queries in five different categories, and we\nobserve an average improvement of 21.98% over the original user query and 3.36%\nover a Best-of-N LLM rewriting baseline.", "AI": {"tldr": "OptAgent\u6846\u67b6\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u6a21\u62df\u548c\u9057\u4f20\u7b97\u6cd5\u6765\u4f18\u5316\u7535\u5546\u67e5\u8be2\u91cd\u5199\uff0c\u901a\u8fc7\u6a21\u62df\u8d2d\u7269\u987e\u5ba2\u8bc4\u4f30\u67e5\u8be2\u8d28\u91cf\uff0c\u76f8\u6bd4\u539f\u59cb\u67e5\u8be2\u63d0\u534721.98%\uff0c\u4f18\u4e8eBest-of-N\u57fa\u7ebf3.36%\u3002", "motivation": "LLM\u5728\u4e3b\u89c2\u4efb\u52a1\uff08\u5982\u7535\u5546\u67e5\u8be2\u91cd\u5199\uff09\u4e2d\u96be\u4ee5\u8bc4\u4f30\uff0c\u56e0\u4e3a\u7f3a\u4e4f\u5355\u4e00\u6b63\u786e\u7b54\u6848\uff0c\u9700\u8981\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u9a8c\u8bc1\u548c\u4f18\u5316\u7528\u6237\u610f\u56fe\u7684\u6355\u6349\u3002", "method": "\u4f7f\u7528\u591a\u4e2aLLM\u667a\u80fd\u4f53\u6a21\u62df\u8d2d\u7269\u987e\u5ba2\u4f5c\u4e3a\u52a8\u6001\u5956\u52b1\u4fe1\u53f7\uff0c\u7ed3\u5408\u9057\u4f20\u7b97\u6cd5\u8fed\u4ee3\u4f18\u5316\u7528\u6237\u521d\u59cb\u67e5\u8be2\u3002", "result": "\u57281000\u4e2a\u771f\u5b9e\u7535\u5546\u67e5\u8be2\u4e0a\u6d4b\u8bd5\uff0c\u76f8\u6bd4\u539f\u59cb\u67e5\u8be2\u5e73\u5747\u63d0\u534721.98%\uff0c\u6bd4Best-of-N\u57fa\u7ebf\u63d0\u53473.36%\u3002", "conclusion": "OptAgent\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u4e3b\u89c2\u4efb\u52a1\u7684\u8bc4\u4f30\u6311\u6218\uff0c\u4e3a\u7535\u5546\u67e5\u8be2\u91cd\u5199\u63d0\u4f9b\u53ef\u9760\u7684\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2510.03536", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03536", "abs": "https://arxiv.org/abs/2510.03536", "authors": ["Zhaohan Meng", "Zaiqiao Meng", "Siwei Liu", "Iadh Ounis"], "title": "TriMediQ: A Triplet-Structured Approach for Interactive Medical Question Answering", "comment": "Preprint", "summary": "Large Language Models (LLMs) perform strongly in static and single-turn\nmedical Question Answer (QA) benchmarks, yet such settings diverge from the\niterative information gathering process required in practical clinical\nconsultations. The MEDIQ framework addresses this mismatch by recasting the\ndiagnosis as an interactive dialogue between a patient and an expert system,\nbut the reliability of LLMs drops dramatically when forced to reason with\ndialogue logs, where clinical facts appear in sentences without clear links. To\nbridge this gap, we introduce TriMediQ, a triplet-structured approach that\nsummarises patient responses into triplets and integrates them into a Knowledge\nGraph (KG), enabling multi-hop reasoning. We introduce a frozen triplet\ngenerator that extracts clinically relevant triplets, using prompts designed to\nensure factual consistency. In parallel, a trainable projection module,\ncomprising a graph encoder and a projector, captures relational information\nfrom the KG to enhance expert reasoning. TriMediQ operates in two steps: (i)\nthe projection module fine-tuning with all LLM weights frozen; and (ii) using\nthe fine-tuned module to guide multi-hop reasoning during inference. We\nevaluate TriMediQ on two interactive QA benchmarks, showing that it achieves up\nto 10.4\\% improvement in accuracy over five baselines on the iMedQA dataset.\nThese results demonstrate that converting patient responses into structured\ntriplet-based graphs enables more accurate clinical reasoning in multi-turn\nsettings, providing a solution for the deployment of LLM-based medical\nassistants.", "AI": {"tldr": "TriMediQ\u6846\u67b6\u901a\u8fc7\u5c06\u60a3\u8005\u56de\u7b54\u8f6c\u6362\u4e3a\u4e09\u5143\u7ec4\u7ed3\u6784\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u89e3\u51b3\u4e86LLM\u5728\u591a\u8f6e\u533b\u7597\u5bf9\u8bdd\u4e2d\u63a8\u7406\u80fd\u529b\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e34\u5e8a\u95ee\u7b54\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709LLM\u5728\u9759\u6001\u5355\u8f6e\u533b\u7597\u95ee\u7b54\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5b9e\u9645\u4e34\u5e8a\u54a8\u8be2\u7684\u591a\u8f6e\u5bf9\u8bdd\u573a\u666f\u4e2d\uff0c\u7531\u4e8e\u4e34\u5e8a\u4e8b\u5b9e\u5206\u6563\u5728\u5bf9\u8bdd\u8bb0\u5f55\u4e2d\u4e14\u7f3a\u4e4f\u660e\u786e\u5173\u8054\uff0cLLM\u7684\u63a8\u7406\u53ef\u9760\u6027\u6025\u5267\u4e0b\u964d\u3002", "method": "\u63d0\u51faTriMediQ\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u51bb\u7ed3\u7684\u4e09\u5143\u7ec4\u751f\u6210\u5668\u63d0\u53d6\u4e34\u5e8a\u76f8\u5173\u4e09\u5143\u7ec4\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\uff1b2\uff09\u8bad\u7ec3\u6295\u5f71\u6a21\u5757\uff08\u56fe\u7f16\u7801\u5668\u548c\u6295\u5f71\u5668\uff09\u4eceKG\u4e2d\u6355\u83b7\u5173\u7cfb\u4fe1\u606f\uff1b3\uff09\u5206\u4e24\u6b65\u64cd\u4f5c\uff1a\u5148\u5fae\u8c03\u6295\u5f71\u6a21\u5757\uff08LLM\u6743\u91cd\u51bb\u7ed3\uff09\uff0c\u7136\u540e\u5728\u63a8\u7406\u65f6\u4f7f\u7528\u8be5\u6a21\u5757\u6307\u5bfc\u591a\u8df3\u63a8\u7406\u3002", "result": "\u5728\u4e24\u4e2a\u4ea4\u4e92\u5f0fQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTriMediQ\u5728iMedQA\u6570\u636e\u96c6\u4e0a\u6bd4\u4e94\u4e2a\u57fa\u7ebf\u6a21\u578b\u51c6\u786e\u7387\u63d0\u5347\u4e8610.4%\u3002", "conclusion": "\u5c06\u60a3\u8005\u56de\u7b54\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u7684\u4e09\u5143\u7ec4\u56fe\u8c31\u80fd\u591f\u663e\u8457\u63d0\u5347LLM\u5728\u591a\u8f6e\u533b\u7597\u5bf9\u8bdd\u4e2d\u7684\u4e34\u5e8a\u63a8\u7406\u51c6\u786e\u6027\uff0c\u4e3a\u57fa\u4e8eLLM\u7684\u533b\u7597\u52a9\u624b\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.03777", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03777", "abs": "https://arxiv.org/abs/2510.03777", "authors": ["Divij Handa", "Mihir Parmar", "Aswin RRV", "Md Nayem Uddin", "Hamid Palangi", "Chitta Baral"], "title": "GuidedSampling: Steering LLMs Towards Diverse Candidate Solutions at Inference-Time", "comment": null, "summary": "Repeated Sampling (RS) is a simple inference-time algorithm that has been\nshown to improve model performance on complex tasks. Although it is an\neffective way of scaling inference time, it often struggles to generate diverse\nsolution candidates, frequently relying on the same underlying approach to\nsolve the problem and thus producing redundant samples. To address this\nlimitation, we propose a new inference algorithm, GuidedSampling, which\ndecouples the exploration and generation phases during inference, increasing\ndiversity of generated candidate solutions. The exploration phase identifies\nmultiple concepts that can be utilized to solve the problem, while the\ngeneration phase applies a specific concept to provide final solution\ncandidates. We first define the theoretical bounds of GuidedSampling and then\nempirically demonstrate that it improves the performance of base model at\npass@50 by on an average ~21.6% across various benchmarks compared to RS.\nFurthermore, models trained on trajectories of GuidedSampling exhibit\nsubstantial performance improvements at pass@5 by on an average ~9.7%, compared\nto models trained on traditional RS. Additionally, models trained with\nGuidedSampling increases the average number of concepts per instance (1.67 ->\n3.03), yielding a diverse set of candidates than traditional RS.", "AI": {"tldr": "\u63d0\u51faGuidedSampling\u63a8\u7406\u7b97\u6cd5\uff0c\u901a\u8fc7\u5206\u79bb\u63a2\u7d22\u548c\u751f\u6210\u9636\u6bb5\u6765\u589e\u52a0\u89e3\u51b3\u65b9\u6848\u591a\u6837\u6027\uff0c\u76f8\u6bd4\u91cd\u590d\u91c7\u6837\u5728pass@50\u6027\u80fd\u5e73\u5747\u63d0\u534721.6%\uff0c\u8bad\u7ec3\u6a21\u578b\u5728pass@5\u63d0\u53479.7%\u3002", "motivation": "\u91cd\u590d\u91c7\u6837\u7b97\u6cd5\u5728\u63d0\u5347\u6a21\u578b\u6027\u80fd\u65f6\u5b58\u5728\u591a\u6837\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u7ecf\u5e38\u4f9d\u8d56\u76f8\u540c\u65b9\u6cd5\u751f\u6210\u5197\u4f59\u6837\u672c\u3002", "method": "GuidedSampling\u7b97\u6cd5\u5c06\u63a8\u7406\u8fc7\u7a0b\u5206\u4e3a\u63a2\u7d22\u9636\u6bb5\u548c\u751f\u6210\u9636\u6bb5\uff1a\u63a2\u7d22\u9636\u6bb5\u8bc6\u522b\u89e3\u51b3\u95ee\u9898\u7684\u591a\u4e2a\u6982\u5ff5\uff0c\u751f\u6210\u9636\u6bb5\u5e94\u7528\u7279\u5b9a\u6982\u5ff5\u63d0\u4f9b\u6700\u7ec8\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGuidedSampling\u76f8\u6bd4\u91cd\u590d\u91c7\u6837\u5728pass@50\u6027\u80fd\u5e73\u5747\u63d0\u534721.6%\uff1b\u8bad\u7ec3\u6a21\u578b\u5728pass@5\u6027\u80fd\u5e73\u5747\u63d0\u53479.7%\uff1b\u6bcf\u4e2a\u5b9e\u4f8b\u7684\u5e73\u5747\u6982\u5ff5\u6570\u4ece1.67\u589e\u52a0\u52303.03\u3002", "conclusion": "GuidedSampling\u901a\u8fc7\u5206\u79bb\u63a2\u7d22\u548c\u751f\u6210\u9636\u6bb5\u6709\u6548\u63d0\u9ad8\u4e86\u89e3\u51b3\u65b9\u6848\u7684\u591a\u6837\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u91cd\u590d\u91c7\u6837\u65b9\u6cd5\u3002"}}
{"id": "2510.03541", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03541", "abs": "https://arxiv.org/abs/2510.03541", "authors": ["Andrew Halterman", "Katherine A. Keith"], "title": "What is a protest anyway? Codebook conceptualization is still a first-order concern in LLM-era classification", "comment": null, "summary": "Generative large language models (LLMs) are now used extensively for text\nclassification in computational social science (CSS). In this work, focus on\nthe steps before and after LLM prompting -- conceptualization of concepts to be\nclassified and using LLM predictions in downstream statistical inference --\nwhich we argue have been overlooked in much of LLM-era CSS. We claim LLMs can\ntempt analysts to skip the conceptualization step, creating conceptualization\nerrors that bias downstream estimates. Using simulations, we show that this\nconceptualization-induced bias cannot be corrected for solely by increasing LLM\naccuracy or post-hoc bias correction methods. We conclude by reminding CSS\nanalysts that conceptualization is still a first-order concern in the LLM-era\nand provide concrete advice on how to pursue low-cost, unbiased, low-variance\ndownstream estimates.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u5728\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\u4e2d\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6587\u672c\u5206\u7c7b\u65f6\uff0c\u6982\u5ff5\u5316\u6b65\u9aa4\u88ab\u5ffd\u89c6\uff0c\u5bfc\u81f4\u6982\u5ff5\u5316\u504f\u5dee\u5f71\u54cd\u4e0b\u6e38\u7edf\u8ba1\u63a8\u65ad\uff0c\u4e14\u8fd9\u79cd\u504f\u5dee\u65e0\u6cd5\u901a\u8fc7\u63d0\u9ad8\u6a21\u578b\u51c6\u786e\u6027\u6216\u540e\u5904\u7406\u65b9\u6cd5\u6765\u7ea0\u6b63\u3002", "motivation": "\u5f53\u524d\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6587\u672c\u5206\u7c7b\uff0c\u4f46\u7814\u7a76\u8005\u5f80\u5f80\u5ffd\u89c6\u4e86\u5206\u7c7b\u524d\u7684\u6982\u5ff5\u5316\u6b65\u9aa4\u548c\u5206\u7c7b\u540e\u7684\u7edf\u8ba1\u63a8\u65ad\u6b65\u9aa4\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6982\u5ff5\u5316\u9519\u8bef\u5e76\u5f71\u54cd\u4e0b\u6e38\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002", "method": "\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u5206\u6790\u6982\u5ff5\u5316\u504f\u5dee\u5bf9\u4e0b\u6e38\u4f30\u8ba1\u7684\u5f71\u54cd\uff0c\u5e76\u6d4b\u8bd5\u63d0\u9ad8LLM\u51c6\u786e\u6027\u548c\u540e\u5904\u7406\u504f\u5dee\u6821\u6b63\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6982\u5ff5\u5316\u5f15\u8d77\u7684\u504f\u5dee\u65e0\u6cd5\u4ec5\u901a\u8fc7\u63d0\u9ad8LLM\u51c6\u786e\u6027\u6216\u540e\u5904\u7406\u504f\u5dee\u6821\u6b63\u65b9\u6cd5\u6765\u7ea0\u6b63\uff0c\u6982\u5ff5\u5316\u4ecd\u7136\u662fLLM\u65f6\u4ee3\u7684\u4e00\u9636\u5173\u6ce8\u70b9\u3002", "conclusion": "\u63d0\u9192\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u8005\u6982\u5ff5\u5316\u5728LLM\u65f6\u4ee3\u4ecd\u7136\u81f3\u5173\u91cd\u8981\uff0c\u5e76\u63d0\u4f9b\u4e86\u8ffd\u6c42\u4f4e\u6210\u672c\u3001\u65e0\u504f\u3001\u4f4e\u65b9\u5dee\u4e0b\u6e38\u4f30\u8ba1\u7684\u5177\u4f53\u5efa\u8bae\u3002"}}
{"id": "2510.03845", "categories": ["cs.AI", "cs.GT", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.03845", "abs": "https://arxiv.org/abs/2510.03845", "authors": ["Gon Buzaglo", "Noah Golowich", "Elad Hazan"], "title": "The Hidden Game Problem", "comment": null, "summary": "This paper investigates a class of games with large strategy spaces,\nmotivated by challenges in AI alignment and language games. We introduce the\nhidden game problem, where for each player, an unknown subset of strategies\nconsistently yields higher rewards compared to the rest. The central question\nis whether efficient regret minimization algorithms can be designed to discover\nand exploit such hidden structures, leading to equilibrium in these subgames\nwhile maintaining rationality in general. We answer this question affirmatively\nby developing a composition of regret minimization techniques that achieve\noptimal external and swap regret bounds. Our approach ensures rapid convergence\nto correlated equilibria in hidden subgames, leveraging the hidden game\nstructure for improved computational efficiency.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5177\u6709\u5927\u7b56\u7565\u7a7a\u95f4\u7684\u6e38\u620f\u7c7b\u522b\uff0c\u63d0\u51fa\u4e86\u9690\u85cf\u6e38\u620f\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u80fd\u591f\u53d1\u73b0\u548c\u5229\u7528\u9690\u85cf\u7ed3\u6784\u7684\u9ad8\u6548\u9057\u61be\u6700\u5c0f\u5316\u7b97\u6cd5\u3002", "motivation": "\u53d7AI\u5bf9\u9f50\u548c\u8bed\u8a00\u6e38\u620f\u6311\u6218\u7684\u542f\u53d1\uff0c\u7814\u7a76\u5f53\u6bcf\u4e2a\u73a9\u5bb6\u5b58\u5728\u672a\u77e5\u5b50\u7b56\u7565\u96c6\u80fd\u6301\u7eed\u83b7\u5f97\u66f4\u9ad8\u5956\u52b1\u65f6\uff0c\u5982\u4f55\u8bbe\u8ba1\u9ad8\u6548\u7b97\u6cd5\u6765\u53d1\u73b0\u548c\u5229\u7528\u8fd9\u79cd\u9690\u85cf\u7ed3\u6784\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u9057\u61be\u6700\u5c0f\u5316\u6280\u672f\u7684\u7ec4\u5408\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6700\u4f18\u7684\u5916\u90e8\u9057\u61be\u548c\u4ea4\u6362\u9057\u61be\u754c\u9650\uff0c\u5229\u7528\u9690\u85cf\u6e38\u620f\u7ed3\u6784\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u7b97\u6cd5\u80fd\u591f\u5feb\u901f\u6536\u655b\u5230\u9690\u85cf\u5b50\u6e38\u620f\u4e2d\u7684\u76f8\u5173\u5747\u8861\uff0c\u540c\u65f6\u5728\u4e00\u822c\u60c5\u51b5\u4e0b\u4fdd\u6301\u7406\u6027\u3002", "conclusion": "\u80af\u5b9a\u5730\u56de\u7b54\u4e86\u80fd\u5426\u8bbe\u8ba1\u9ad8\u6548\u9057\u61be\u6700\u5c0f\u5316\u7b97\u6cd5\u6765\u53d1\u73b0\u548c\u5229\u7528\u9690\u85cf\u7ed3\u6784\u7684\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5728\u9690\u85cf\u6e38\u620f\u4e2d\u5b9e\u73b0\u5747\u8861\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2510.03553", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03553", "abs": "https://arxiv.org/abs/2510.03553", "authors": ["Hasibur Rahman", "Hanan Salam"], "title": "CCD-Bench: Probing Cultural Conflict in Large Language Model Decision-Making", "comment": null, "summary": "Although large language models (LLMs) are increasingly implicated in\ninterpersonal and societal decision-making, their ability to navigate explicit\nconflicts between legitimately different cultural value systems remains largely\nunexamined. Existing benchmarks predominantly target cultural knowledge\n(CulturalBench), value prediction (WorldValuesBench), or single-axis bias\ndiagnostics (CDEval); none evaluate how LLMs adjudicate when multiple\nculturally grounded values directly clash. We address this gap with CCD-Bench,\na benchmark that assesses LLM decision-making under cross-cultural value\nconflict. CCD-Bench comprises 2,182 open-ended dilemmas spanning seven domains,\neach paired with ten anonymized response options corresponding to the ten GLOBE\ncultural clusters. These dilemmas are presented using a stratified Latin square\nto mitigate ordering effects. We evaluate 17 non-reasoning LLMs. Models\ndisproportionately prefer Nordic Europe (mean 20.2 percent) and Germanic Europe\n(12.4 percent), while options for Eastern Europe and the Middle East and North\nAfrica are underrepresented (5.6 to 5.8 percent). Although 87.9 percent of\nrationales reference multiple GLOBE dimensions, this pluralism is superficial:\nmodels recombine Future Orientation and Performance Orientation, and rarely\nground choices in Assertiveness or Gender Egalitarianism (both under 3\npercent). Ordering effects are negligible (Cramer's V less than 0.10), and\nsymmetrized KL divergence shows clustering by developer lineage rather than\ngeography. These patterns suggest that current alignment pipelines promote a\nconsensus-oriented worldview that underserves scenarios demanding power\nnegotiation, rights-based reasoning, or gender-aware analysis. CCD-Bench shifts\nevaluation beyond isolated bias detection toward pluralistic decision making\nand highlights the need for alignment strategies that substantively engage\ndiverse worldviews.", "AI": {"tldr": "CCD-Bench\u662f\u4e00\u4e2a\u8bc4\u4f30LLM\u5728\u8de8\u6587\u5316\u4ef7\u503c\u51b2\u7a81\u4e0b\u51b3\u7b56\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b2,182\u4e2a\u5f00\u653e\u5f0f\u56f0\u5883\uff0c\u8986\u76d67\u4e2a\u9886\u57df\uff0c\u53d1\u73b0LLM\u504f\u597d\u5317\u6b27\u548c\u65e5\u8033\u66fc\u6b27\u6d32\u4ef7\u503c\u89c2\uff0c\u800c\u5ffd\u89c6\u4e1c\u6b27\u548c\u4e2d\u4e1c\u6587\u5316\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u6587\u5316\u77e5\u8bc6\u3001\u4ef7\u503c\u9884\u6d4b\u6216\u5355\u8f74\u504f\u89c1\u68c0\u6d4b\uff0c\u4f46\u7f3a\u4e4f\u8bc4\u4f30LLM\u5728\u591a\u4e2a\u6587\u5316\u4ef7\u503c\u89c2\u76f4\u63a5\u51b2\u7a81\u65f6\u7684\u88c1\u51b3\u80fd\u529b\u3002", "method": "\u4f7f\u75282,182\u4e2a\u5f00\u653e\u5f0f\u56f0\u5883\uff0c\u6bcf\u4e2a\u56f0\u5883\u914d\u4ee510\u4e2a\u5bf9\u5e94GLOBE\u6587\u5316\u96c6\u7fa4\u7684\u533f\u540d\u54cd\u5e94\u9009\u9879\uff0c\u91c7\u7528\u5206\u5c42\u62c9\u4e01\u65b9\u8bbe\u8ba1\u6765\u51cf\u8f7b\u987a\u5e8f\u6548\u5e94\uff0c\u8bc4\u4f3017\u4e2a\u975e\u63a8\u7406LLM\u3002", "result": "\u6a21\u578b\u660e\u663e\u504f\u597d\u5317\u6b27\u6b27\u6d32(20.2%)\u548c\u65e5\u8033\u66fc\u6b27\u6d32(12.4%)\uff0c\u800c\u4e1c\u6b27\u548c\u4e2d\u4e1c\u9009\u9879\u4ee3\u8868\u6027\u4e0d\u8db3(5.6-5.8%)\u300287.9%\u7684\u7406\u7531\u5f15\u7528\u591a\u4e2aGLOBE\u7ef4\u5ea6\uff0c\u4f46\u8fd9\u79cd\u591a\u5143\u6027\u5f88\u8868\u9762\u3002", "conclusion": "\u5f53\u524d\u7684\u5bf9\u9f50\u6d41\u7a0b\u4fc3\u8fdb\u4e86\u5171\u8bc6\u5bfc\u5411\u7684\u4e16\u754c\u89c2\uff0c\u5ffd\u89c6\u4e86\u9700\u8981\u6743\u529b\u534f\u5546\u3001\u57fa\u4e8e\u6743\u5229\u7684\u63a8\u7406\u6216\u6027\u522b\u610f\u8bc6\u5206\u6790\u7684\u573a\u666f\u3002CCD-Bench\u5c06\u8bc4\u4f30\u4ece\u5b64\u7acb\u504f\u89c1\u68c0\u6d4b\u8f6c\u5411\u591a\u5143\u51b3\u7b56\uff0c\u5f3a\u8c03\u9700\u8981\u5b9e\u8d28\u6027\u53c2\u4e0e\u591a\u5143\u4e16\u754c\u89c2\u7684\u6821\u51c6\u7b56\u7565\u3002"}}
{"id": "2510.03847", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03847", "abs": "https://arxiv.org/abs/2510.03847", "authors": ["Raghav Sharma", "Manan Mehta"], "title": "Small Language Models for Agentic Systems: A Survey of Architectures, Capabilities, and Deployment Trade offs", "comment": "9 Pages", "summary": "Small language models (SLMs; 1-12B params, sometimes up to 20B) are\nsufficient and often superior for agentic workloads where the objective is\nschema- and API-constrained accuracy rather than open-ended generation. We\nsynthesize recent evidence across open and proprietary SLMs (Phi-4-Mini,\nQwen-2.5-7B, Gemma-2-9B, Llama-3.2-1B/3B, Ministral-3B/8B, Apple on-device 3B,\nDeepSeek-R1-Distill) and connect it to modern evaluations (BFCL v3/v4,\nStableToolBench) and serving stacks (vLLM, SGLang, TensorRT-LLM) paired with\nguided decoding libraries (XGrammar, Outlines). We formalize SLM-default,\nLLM-fallback systems with uncertainty-aware routing and verifier cascades, and\npropose engineering metrics that reflect real production goals: cost per\nsuccessful task (CPS), schema validity rate, executable call rate, p50/p95\nlatency, and energy per request. Guided decoding, strict JSON Schema outputs,\nand validator-first tool execution close much of the capability gap with larger\nmodels and often let SLMs match or surpass LLMs on tool use, function calling,\nand RAG at 10x-100x lower token cost with materially better latency and energy.\nWe provide design patterns for agent stacks that prioritize SLMs: schema-first\nprompting, type-safe function registries, confidence scoring with verifier\nrollups, and lightweight adaptation via LoRA/QLoRA. We also delineate limits\nwhere fallback remains valuable (open-domain reasoning and some long-horizon\nplanning). The result is a practical blueprint for building fast, inexpensive,\nand reliable agents that default to SLMs while preserving headroom with\ntargeted LLM assistance.\n  Keywords: small language models, agents, function calling, structured\noutputs, JSON Schema, guided decoding, LoRA/QLoRA, routing, energy efficiency,\nedge inference", "AI": {"tldr": "\u5c0f\u8bed\u8a00\u6a21\u578b(SLMs)\u5728\u4ee3\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5927\u6a21\u578b\uff0c\u901a\u8fc7\u5f15\u5bfc\u89e3\u7801\u3001JSON Schema\u8f93\u51fa\u548c\u9a8c\u8bc1\u5668\u4f18\u5148\u7684\u5de5\u5177\u6267\u884c\uff0c\u80fd\u4ee510-100\u500d\u66f4\u4f4e\u7684\u6210\u672c\u5b9e\u73b0\u76f8\u4f3c\u6216\u66f4\u597d\u7684\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u4f4e\u7684\u5ef6\u8fdf\u548c\u80fd\u8017\u3002", "motivation": "\u63a2\u7d22\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7406\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u6a21\u5f0f\u5316\u548cAPI\u7ea6\u675f\u51c6\u786e\u6027\u7684\u573a\u666f\u4e2d\uff0c\u800c\u975e\u5f00\u653e\u5f0f\u751f\u6210\u4efb\u52a1\u3002\u76ee\u6807\u662f\u6784\u5efa\u5feb\u901f\u3001\u5ec9\u4ef7\u4e14\u53ef\u9760\u7684\u4ee3\u7406\u7cfb\u7edf\uff0c\u9ed8\u8ba4\u4f7f\u7528SLMs\uff0c\u540c\u65f6\u4fdd\u7559\u5927\u6a21\u578b\u4f5c\u4e3a\u540e\u5907\u3002", "method": "\u91c7\u7528SLM\u9ed8\u8ba4\u3001LLM\u540e\u5907\u7684\u7cfb\u7edf\u67b6\u6784\uff0c\u7ed3\u5408\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8def\u7531\u548c\u9a8c\u8bc1\u5668\u7ea7\u8054\u3002\u4f7f\u7528\u5f15\u5bfc\u89e3\u7801\u5e93(XGrammar, Outlines)\u3001\u4e25\u683cJSON Schema\u8f93\u51fa\u548c\u9a8c\u8bc1\u5668\u4f18\u5148\u7684\u5de5\u5177\u6267\u884c\u65b9\u6cd5\u3002", "result": "SLMs\u5728\u5de5\u5177\u4f7f\u7528\u3001\u51fd\u6570\u8c03\u7528\u548cRAG\u4efb\u52a1\u4e0a\u80fd\u591f\u5339\u914d\u751a\u81f3\u8d85\u8d8aLLMs\uff0c\u540c\u65f6\u5b9e\u73b010-100\u500d\u66f4\u4f4e\u7684token\u6210\u672c\u3001\u66f4\u597d\u7684\u5ef6\u8fdf\u548c\u80fd\u8017\u8868\u73b0\u3002", "conclusion": "\u5c0f\u8bed\u8a00\u6a21\u578b\u662f\u6784\u5efa\u9ad8\u6548\u4ee3\u7406\u7cfb\u7edf\u7684\u53ef\u884c\u9009\u62e9\uff0c\u901a\u8fc7\u9002\u5f53\u7684\u8bbe\u8ba1\u6a21\u5f0f(\u6a21\u5f0f\u4f18\u5148\u63d0\u793a\u3001\u7c7b\u578b\u5b89\u5168\u51fd\u6570\u6ce8\u518c\u3001\u7f6e\u4fe1\u5ea6\u8bc4\u5206\u7b49)\u53ef\u4ee5\u5145\u5206\u53d1\u6325\u5176\u6f5c\u529b\uff0c\u4f46\u5728\u5f00\u653e\u57df\u63a8\u7406\u548c\u957f\u7a0b\u89c4\u5212\u7b49\u573a\u666f\u4ecd\u9700\u5927\u6a21\u578b\u540e\u5907\u3002"}}
{"id": "2510.03561", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03561", "abs": "https://arxiv.org/abs/2510.03561", "authors": ["Adam Filipek"], "title": "Reactive Transformer (RxT) -- Stateful Real-Time Processing for Event-Driven Reactive Language Models", "comment": "25 pages, 13 figures", "summary": "The Transformer architecture has become the de facto standard for Large\nLanguage Models (LLMs), demonstrating remarkable capabilities in language\nunderstanding and generation. However, its application in conversational AI is\nfundamentally constrained by its stateless nature and the quadratic\ncomputational complexity ($O(L^2)$) with respect to sequence length $L$.\nCurrent models emulate memory by reprocessing an ever-expanding conversation\nhistory with each turn, leading to prohibitive costs and latency in long\ndialogues. This paper introduces the Reactive Transformer (RxT), a novel\narchitecture designed to overcome these limitations by shifting from a\ndata-driven to an event-driven paradigm. RxT processes each conversational turn\nas a discrete event in real-time, maintaining context in an integrated,\nfixed-size Short-Term Memory (STM) system. The architecture features a distinct\noperational cycle where a generator-decoder produces a response based on the\ncurrent query and the previous memory state, after which a memory-encoder and a\ndedicated Memory Attention network asynchronously update the STM with a\nrepresentation of the complete interaction. This design fundamentally alters\nthe scaling dynamics, reducing the total user-facing cost of a conversation\nfrom quadratic ($O(N^2 \\cdot T)$) to linear ($O(N \\cdot T)$) with respect to\nthe number of interactions $N$. By decoupling response generation from memory\nupdates, RxT achieves low latency, enabling truly real-time, stateful, and\neconomically viable long-form conversations. We validated our architecture with\na series of proof-of-concept experiments on synthetic data, demonstrating\nsuperior performance and constant-time inference latency compared to a baseline\nstateless model of comparable size.", "AI": {"tldr": "RxT\u662f\u4e00\u79cd\u65b0\u578bTransformer\u67b6\u6784\uff0c\u901a\u8fc7\u4e8b\u4ef6\u9a71\u52a8\u8303\u5f0f\u89e3\u51b3\u4f20\u7edfTransformer\u5728\u5bf9\u8bddAI\u4e2d\u7684\u72b6\u6001\u4fdd\u6301\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u5c06\u5bf9\u8bdd\u6210\u672c\u4ece\u4e8c\u6b21\u65b9\u964d\u4f4e\u5230\u7ebf\u6027\u3002", "motivation": "\u4f20\u7edfTransformer\u67b6\u6784\u5728\u5bf9\u8bddAI\u4e2d\u5b58\u5728\u72b6\u6001\u4fdd\u6301\u95ee\u9898\u548c\u4e8c\u6b21\u8ba1\u7b97\u590d\u6742\u5ea6\u9650\u5236\uff0c\u65e0\u6cd5\u652f\u6301\u5b9e\u65f6\u957f\u5bf9\u8bdd\u3002", "method": "\u91c7\u7528\u4e8b\u4ef6\u9a71\u52a8\u8303\u5f0f\uff0c\u5c06\u6bcf\u4e2a\u5bf9\u8bdd\u8f6e\u6b21\u4f5c\u4e3a\u79bb\u6563\u4e8b\u4ef6\u5904\u7406\uff0c\u901a\u8fc7\u56fa\u5b9a\u5927\u5c0f\u7684\u77ed\u671f\u8bb0\u5fc6\u7cfb\u7edf\u548c\u5f02\u6b65\u5185\u5b58\u66f4\u65b0\u673a\u5236\u5b9e\u73b0\u72b6\u6001\u4fdd\u6301\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRxT\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u5177\u6709\u66f4\u4f18\u6027\u80fd\u548c\u6052\u5b9a\u65f6\u95f4\u63a8\u7406\u5ef6\u8fdf\u3002", "conclusion": "RxT\u5b9e\u73b0\u4e86\u4f4e\u5ef6\u8fdf\u3001\u72b6\u6001\u4fdd\u6301\u4e14\u7ecf\u6d4e\u53ef\u884c\u7684\u957f\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u4e86\u5bf9\u8bdd\u7cfb\u7edf\u7684\u6269\u5c55\u52a8\u6001\u3002"}}
{"id": "2510.03851", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03851", "abs": "https://arxiv.org/abs/2510.03851", "authors": ["Ruiying Ma", "Chieh-Jan Mike Liang", "Yanjie Gao", "Francis Y. Yan"], "title": "Algorithm Generation via Creative Ideation", "comment": null, "summary": "Designing system algorithms remains challenging, where the discontinuous\nnature of the solution space often forces system engineers to rely on generic\nheuristics at the expense of performance. We study whether LLMs can practically\ndrive algorithm generation, and find that they are biased towards well-known\ngeneric designs, rather than making the creative leaps needed to navigate the\ndiscontinuous solution space. To address this limitation, we introduce\nMetaMuse, a framework for creative ideation built on three self-reflection\nprinciples: (1) quantifying solution diversity and usefulness in measurable\nperformance space, rather than abstract idea space, (2) steering ideation\nthrough external stimuli, rather than internal randomness, and (3) constructing\nexecutable solutions using waypoint reasoning, rather than free-form\nchain-of-thought. Extensive evaluation shows that MetaMuse can generate\nhigh-performing solutions for two critical problems at a global cloud provider:\ncache replacement (reducing cache misses by up to 35.76%) and online bin\npacking (reducing bin usage by up to 30.93%).", "AI": {"tldr": "MetaMuse\u6846\u67b6\u901a\u8fc7\u4e09\u4e2a\u81ea\u53cd\u601d\u539f\u5219\u89e3\u51b3LLM\u5728\u7b97\u6cd5\u751f\u6210\u4e2d\u7684\u521b\u9020\u6027\u4e0d\u8db3\u95ee\u9898\uff0c\u5728\u7f13\u5b58\u66ff\u6362\u548c\u5728\u7ebf\u88c5\u7bb1\u95ee\u9898\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd", "motivation": "\u7cfb\u7edf\u7b97\u6cd5\u8bbe\u8ba1\u9762\u4e34\u89e3\u7a7a\u95f4\u4e0d\u8fde\u7eed\u7684\u6311\u6218\uff0c\u73b0\u6709LLM\u504f\u5411\u901a\u7528\u542f\u53d1\u5f0f\u65b9\u6cd5\u800c\u7f3a\u4e4f\u521b\u9020\u6027\u7a81\u7834", "method": "\u63d0\u51faMetaMuse\u6846\u67b6\uff0c\u57fa\u4e8e\u4e09\u4e2a\u539f\u5219\uff1a(1)\u5728\u53ef\u5ea6\u91cf\u6027\u80fd\u7a7a\u95f4\u91cf\u5316\u89e3\u51b3\u65b9\u6848\u591a\u6837\u6027\uff1b(2)\u901a\u8fc7\u5916\u90e8\u523a\u6fc0\u800c\u975e\u5185\u90e8\u968f\u673a\u6027\u5f15\u5bfc\u6784\u601d\uff1b(3)\u4f7f\u7528\u8def\u5f84\u70b9\u63a8\u7406\u800c\u975e\u81ea\u7531\u94fe\u5f0f\u601d\u7ef4\u6784\u5efa\u53ef\u6267\u884c\u65b9\u6848", "result": "\u5728\u7f13\u5b58\u66ff\u6362\u95ee\u9898\u4e0a\u51cf\u5c11\u7f13\u5b58\u672a\u547d\u4e2d\u8fbe35.76%\uff0c\u5728\u5728\u7ebf\u88c5\u7bb1\u95ee\u9898\u4e0a\u51cf\u5c11\u5bb9\u5668\u4f7f\u7528\u8fbe30.93%", "conclusion": "MetaMuse\u80fd\u591f\u6709\u6548\u751f\u6210\u9ad8\u6027\u80fd\u89e3\u51b3\u65b9\u6848\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u7b97\u6cd5\u751f\u6210\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c"}}
{"id": "2510.03577", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.03577", "abs": "https://arxiv.org/abs/2510.03577", "authors": ["Ikram Belmadani", "Parisa Nazari Hashemi", "Thomas Sebbag", "Benoit Favre", "Guillaume Fortier", "Solen Quiniou", "Emmanuel Morin", "Richard Dufour"], "title": "LLM, Reporting In! Medical Information Extraction Across Prompting, Fine-tuning and Post-correction", "comment": "in French language", "summary": "This work presents our participation in the EvalLLM 2025 challenge on\nbiomedical Named Entity Recognition (NER) and health event extraction in French\n(few-shot setting). For NER, we propose three approaches combining large\nlanguage models (LLMs), annotation guidelines, synthetic data, and\npost-processing: (1) in-context learning (ICL) with GPT-4.1, incorporating\nautomatic selection of 10 examples and a summary of the annotation guidelines\ninto the prompt, (2) the universal NER system GLiNER, fine-tuned on a synthetic\ncorpus and then verified by an LLM in post-processing, and (3) the open LLM\nLLaMA-3.1-8B-Instruct, fine-tuned on the same synthetic corpus. Event\nextraction uses the same ICL strategy with GPT-4.1, reusing the guideline\nsummary in the prompt. Results show GPT-4.1 leads with a macro-F1 of 61.53% for\nNER and 15.02% for event extraction, highlighting the importance of\nwell-crafted prompting to maximize performance in very low-resource scenarios.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5728EvalLLM 2025\u6311\u6218\u8d5b\u4e2d\u9488\u5bf9\u6cd5\u8bed\u751f\u7269\u533b\u5b66\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u5065\u5eb7\u4e8b\u4ef6\u63d0\u53d6\u7684\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u7ed3\u5408LLM\u7684\u65b9\u6cd5\uff0c\u5176\u4e2dGPT-4.1\u5728\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u89e3\u51b3\u6cd5\u8bed\u751f\u7269\u533b\u5b66\u9886\u57df\u5728\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u7684\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u4e8b\u4ef6\u63d0\u53d6\u6311\u6218\uff0c\u63a2\u7d22LLM\u5728\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u4e09\u79cd\u65b9\u6cd5\uff1a(1) GPT-4.1\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u81ea\u52a8\u9009\u62e910\u4e2a\u793a\u4f8b\u5e76\u6574\u5408\u6807\u6ce8\u6307\u5357\uff1b(2) GLiNER\u7cfb\u7edf\u5728\u5408\u6210\u8bed\u6599\u4e0a\u5fae\u8c03\u540e\u7ecfLLM\u540e\u5904\u7406\u9a8c\u8bc1\uff1b(3) LLaMA-3.1-8B-Instruct\u5728\u76f8\u540c\u5408\u6210\u8bed\u6599\u4e0a\u5fae\u8c03\u3002\u4e8b\u4ef6\u63d0\u53d6\u91c7\u7528\u76f8\u540c\u7684ICL\u7b56\u7565\u3002", "result": "GPT-4.1\u5728\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4e0a\u83b7\u5f9761.53%\u7684\u5b8fF1\u5206\u6570\uff0c\u5728\u4e8b\u4ef6\u63d0\u53d6\u4e0a\u83b7\u5f9715.02%\u7684\u5b8fF1\u5206\u6570\uff0c\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u5de5\u7a0b\u5bf9\u4e8e\u5728\u6781\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u6700\u5927\u5316\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0cGPT-4.1\u5728\u5c11\u6837\u672c\u6cd5\u8bed\u751f\u7269\u533b\u5b66\u6587\u672c\u5904\u7406\u4e2d\u5c55\u73b0\u51fa\u4f18\u52bf\u3002"}}
{"id": "2510.03859", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03859", "abs": "https://arxiv.org/abs/2510.03859", "authors": ["Raghav Sharma", "Manan Mehta"], "title": "Adaptive and Explainable AI Agents for Anomaly Detection in Critical IoT Infrastructure using LLM-Enhanced Contextual Reasoning", "comment": "22 pages", "summary": "Ensuring that critical IoT systems function safely and smoothly depends a lot\non finding anomalies quickly. As more complex systems, like smart healthcare,\nenergy grids and industrial automation, appear, it is easier to see the\nshortcomings of older methods of detection. Monitoring failures usually happen\nin dynamic, high dimensional situations, especially when data is incomplete,\nmessy or always evolving. Such limits point out the requirement for adaptive,\nintelligent systems that always improve and think. LLMs are now capable of\nsignificantly changing how context is understood and semantic inference is done\nacross all types of data. This proposal suggests using an LLM supported\ncontextual reasoning method along with XAI agents to improve how anomalies are\nfound in significant IoT environments. To discover hidden patterns and notice\ninconsistencies in data streams, it uses attention methods, avoids dealing with\ndetails from every time step and uses memory buffers with meaning. Because no\ncode AI stresses transparency and interpretability, people can check and accept\nthe AI's decisions, helping ensure AI follows company policies. The two\narchitectures are put together in a test that compares the results of the\ntraditional model with those of the suggested LLM enhanced model. Important\nmeasures to check are the accuracy of detection, how much inaccurate\ninformation is included in the results, how clearly the findings can be read\nand how fast the system responds under different test situations. The\nmetaheuristic is tested in simulations of real world smart grid and healthcare\ncontexts to check its adaptability and reliability. From the study, we see that\nthe new approach performs much better than most existing models in both\naccuracy and interpretation, so it could be a good fit for future anomaly\ndetection tasks in IoT", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u548cXAI\u4ee3\u7406\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7528\u4e8e\u5173\u952eIoT\u7cfb\u7edf\uff0c\u5728\u667a\u80fd\u7535\u7f51\u548c\u533b\u7597\u4fdd\u5065\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5728\u52a8\u6001\u3001\u9ad8\u7ef4\u3001\u6570\u636e\u4e0d\u5b8c\u6574\u6216\u4e0d\u65ad\u6f14\u53d8\u7684IoT\u73af\u5883\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u81ea\u9002\u5e94\u667a\u80fd\u7cfb\u7edf\u6765\u6301\u7eed\u6539\u8fdb\u548c\u63a8\u7406\u3002", "method": "\u4f7f\u7528LLM\u652f\u6301\u7684\u4e0a\u4e0b\u6587\u63a8\u7406\u65b9\u6cd5\u548cXAI\u4ee3\u7406\uff0c\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\u3001\u8df3\u8fc7\u65f6\u95f4\u6b65\u7ec6\u8282\u5904\u7406\u548c\u4f7f\u7528\u8bed\u4e49\u8bb0\u5fc6\u7f13\u51b2\u533a\u6765\u53d1\u73b0\u9690\u85cf\u6a21\u5f0f\u548c\u6570\u636e\u6d41\u4e0d\u4e00\u81f4\u6027\u3002", "result": "\u65b0\u65b9\u6cd5\u5728\u68c0\u6d4b\u51c6\u786e\u6027\u3001\u8bef\u62a5\u7387\u3001\u7ed3\u679c\u53ef\u8bfb\u6027\u548c\u54cd\u5e94\u901f\u5ea6\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u5927\u591a\u6570\u73b0\u6709\u6a21\u578b\uff0c\u7279\u522b\u662f\u5728\u771f\u5b9e\u4e16\u754c\u667a\u80fd\u7535\u7f51\u548c\u533b\u7597\u4fdd\u5065\u6a21\u62df\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u9002\u5e94\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "LLM\u589e\u5f3a\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5728IoT\u73af\u5883\u4e2d\u5177\u6709\u4f18\u8d8a\u6027\u80fd\uff0c\u6709\u671b\u6210\u4e3a\u672a\u6765\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u7684\u6709\u529b\u5019\u9009\u65b9\u6848\u3002"}}
{"id": "2510.03595", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03595", "abs": "https://arxiv.org/abs/2510.03595", "authors": ["Haikang Deng", "Po-Nien Kung", "Nanyun Peng"], "title": "Decoupling Task-Solving and Output Formatting in LLM Generation", "comment": null, "summary": "Large language models (LLMs) are increasingly adept at following instructions\ncontaining task descriptions to solve complex problems, such as mathematical\nreasoning and automatic evaluation (LLM-as-a-Judge). However, as prompts grow\nmore complex, models often struggle to adhere to all instructions. This\ndifficulty is especially common when instructive prompts intertwine reasoning\ndirectives -- specifying what the model should solve -- with rigid formatting\nrequirements that dictate how the solution must be presented. The entanglement\ncreates competing goals for the model, suggesting that more explicit separation\nof these two aspects could lead to improved performance. To this front, we\nintroduce Deco-G, a decoding framework that explicitly decouples format\nadherence from task solving. Deco-G handles format compliance with a separate\ntractable probabilistic model (TPM), while prompts LLMs with only task\ninstructions. At each decoding step, Deco-G combines next token probabilities\nfrom the LLM with the TPM calculated format compliance likelihood to form the\noutput probability. To make this approach both practical and scalable for\nmodern instruction-tuned LLMs, we introduce three key innovations:\ninstruction-aware distillation, a flexible trie-building algorithm, and HMM\nstate pruning for computational efficiency. We demonstrate the effectiveness of\nDeco-G across a wide range of tasks with diverse format requirements, including\nmathematical reasoning, LLM-as-a-judge, and event argument extraction. Overall,\nour approach yields 1.0% to 6.0% relative gain over regular prompting practice\nwith guaranteed format compliance.", "AI": {"tldr": "Deco-G\u662f\u4e00\u4e2a\u89e3\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u683c\u5f0f\u9075\u5faa\u4e0e\u4efb\u52a1\u89e3\u51b3\u89e3\u8026\u6765\u63d0\u5347LLM\u6027\u80fd\u3002\u5b83\u4f7f\u7528\u72ec\u7acb\u7684\u6982\u7387\u6a21\u578b\u5904\u7406\u683c\u5f0f\u5408\u89c4\u6027\uff0c\u8ba9LLM\u4e13\u6ce8\u4e8e\u4efb\u52a1\u6307\u4ee4\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e861.0%\u52306.0%\u7684\u76f8\u5bf9\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5f53\u63d0\u793a\u53d8\u5f97\u8d8a\u6765\u8d8a\u590d\u6742\u65f6\uff0cLLM\u96be\u4ee5\u540c\u65f6\u9075\u5faa\u6240\u6709\u6307\u4ee4\uff0c\u7279\u522b\u662f\u5f53\u63a8\u7406\u6307\u4ee4\u4e0e\u4e25\u683c\u7684\u683c\u5f0f\u8981\u6c42\u4ea4\u7ec7\u5728\u4e00\u8d77\u65f6\uff0c\u8fd9\u79cd\u7ea0\u7f20\u4f1a\u4e3a\u6a21\u578b\u521b\u9020\u7ade\u4e89\u6027\u76ee\u6807\uff0c\u5f71\u54cd\u6027\u80fd\u3002", "method": "Deco-G\u6846\u67b6\u4f7f\u7528\u72ec\u7acb\u7684\u53ef\u8ffd\u8e2a\u6982\u7387\u6a21\u578b(TPM)\u5904\u7406\u683c\u5f0f\u5408\u89c4\u6027\uff0c\u540c\u65f6\u4ec5\u5411LLM\u63d0\u4f9b\u4efb\u52a1\u6307\u4ee4\u3002\u5728\u6bcf\u4e2a\u89e3\u7801\u6b65\u9aa4\u4e2d\uff0c\u5c06LLM\u7684\u4e0b\u4e00\u4e2atoken\u6982\u7387\u4e0eTPM\u8ba1\u7b97\u7684\u683c\u5f0f\u5408\u89c4\u4f3c\u7136\u76f8\u7ed3\u5408\u3002\u5f15\u5165\u4e86\u6307\u4ee4\u611f\u77e5\u84b8\u998f\u3001\u7075\u6d3b\u7684trie\u6784\u5efa\u7b97\u6cd5\u548cHMM\u72b6\u6001\u526a\u679d\u7b49\u521b\u65b0\u6280\u672f\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u3001LLM-as-a-judge\u548c\u4e8b\u4ef6\u53c2\u6570\u63d0\u53d6\u7b49\u591a\u79cd\u683c\u5f0f\u8981\u6c42\u7684\u4efb\u52a1\u4e2d\uff0cDeco-G\u76f8\u6bd4\u5e38\u89c4\u63d0\u793a\u65b9\u6cd5\u5b9e\u73b0\u4e861.0%\u52306.0%\u7684\u76f8\u5bf9\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u4fdd\u8bc1\u683c\u5f0f\u5408\u89c4\u6027\u3002", "conclusion": "\u901a\u8fc7\u660e\u786e\u5206\u79bb\u683c\u5f0f\u9075\u5faa\u548c\u4efb\u52a1\u89e3\u51b3\uff0cDeco-G\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u590d\u6742\u6307\u4ee4\u4e0b\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u8fd9\u79cd\u89e3\u8026\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.03863", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.03863", "abs": "https://arxiv.org/abs/2510.03863", "authors": ["Arina Kharlamova", "Bowei He", "Chen Ma", "Xue Liu"], "title": "Spatial CAPTCHA: Generatively Benchmarking Spatial Reasoning for Human-Machine Differentiation", "comment": "Submitted to ICLR 2026", "summary": "Online services rely on CAPTCHAs as a first line of defense against automated\nabuse, yet recent advances in multi-modal large language models (MLLMs) have\neroded the effectiveness of conventional designs that focus on text recognition\nor 2D image understanding. To address this challenge, we present Spatial\nCAPTCHA, a novel human-verification framework that leverages fundamental\ndifferences in spatial reasoning between humans and MLLMs. Unlike existing\nCAPTCHAs which rely on low-level perception tasks that are vulnerable to modern\nAI, Spatial CAPTCHA generates dynamic questions requiring geometric reasoning,\nperspective-taking, occlusion handling, and mental rotation. These skills are\nintuitive for humans but difficult for state-of-the-art (SOTA) AI systems. The\nsystem employs a procedural generation pipeline with constraint-based\ndifficulty control, automated correctness verification, and human-in-the-loop\nvalidation to ensure scalability, robustness, and adaptability. Evaluation on a\ncorresponding benchmark, Spatial-CAPTCHA-Bench, demonstrates that humans vastly\noutperform 10 state-of-the-art MLLMs, with the best model achieving only 31.0%\nPass@1 accuracy. Furthermore, we compare Spatial CAPTCHA with Google reCAPTCHA,\nwhich confirms its effectiveness as both a security mechanism and a diagnostic\ntool for spatial reasoning in AI.", "AI": {"tldr": "Spatial CAPTCHA\u662f\u4e00\u79cd\u65b0\u578b\u4eba\u673a\u9a8c\u8bc1\u6846\u67b6\uff0c\u5229\u7528\u4eba\u7c7b\u4e0e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u6839\u672c\u5dee\u5f02\uff0c\u901a\u8fc7\u51e0\u4f55\u63a8\u7406\u3001\u89c6\u89d2\u8f6c\u6362\u3001\u906e\u6321\u5904\u7406\u548c\u5fc3\u7406\u65cb\u8f6c\u7b49\u4efb\u52a1\u6765\u533a\u5206\u4eba\u7c7b\u548cAI\u3002", "motivation": "\u4f20\u7edfCAPTCHA\u4f9d\u8d56\u6587\u672c\u8bc6\u522b\u62162D\u56fe\u50cf\u7406\u89e3\uff0c\u4f46\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u6b65\u5df2\u524a\u5f31\u5176\u6709\u6548\u6027\uff0c\u9700\u8981\u5f00\u53d1\u57fa\u4e8e\u66f4\u9ad8\u5c42\u6b21\u8ba4\u77e5\u80fd\u529b\u7684\u65b0\u578b\u9a8c\u8bc1\u673a\u5236\u3002", "method": "\u91c7\u7528\u7a0b\u5e8f\u5316\u751f\u6210\u7ba1\u9053\uff0c\u5305\u542b\u57fa\u4e8e\u7ea6\u675f\u7684\u96be\u5ea6\u63a7\u5236\u3001\u81ea\u52a8\u6b63\u786e\u6027\u9a8c\u8bc1\u548c\u4eba\u5728\u73af\u9a8c\u8bc1\uff0c\u751f\u6210\u9700\u8981\u7a7a\u95f4\u63a8\u7406\u7684\u52a8\u6001\u95ee\u9898\u3002", "result": "\u5728Spatial-CAPTCHA-Bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4eba\u7c7b\u8868\u73b0\u8fdc\u8d8510\u4e2a\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6700\u4f73\u6a21\u578b\u4ec5\u8fbe\u523031.0%\u7684Pass@1\u51c6\u786e\u7387\uff0c\u4e14\u4f18\u4e8eGoogle reCAPTCHA\u3002", "conclusion": "Spatial CAPTCHA\u4e0d\u4ec5\u662f\u6709\u6548\u7684\u5b89\u5168\u673a\u5236\uff0c\u8fd8\u53ef\u4f5c\u4e3aAI\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u5229\u7528\u4eba\u7c7b\u4e0eAI\u5728\u7a7a\u95f4\u8ba4\u77e5\u4e0a\u7684\u6839\u672c\u5dee\u5f02\u63d0\u4f9b\u53ef\u9760\u7684\u4eba\u673a\u9a8c\u8bc1\u3002"}}
{"id": "2510.03611", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03611", "abs": "https://arxiv.org/abs/2510.03611", "authors": ["Raquib Bin Yousuf", "Aadyant Khatri", "Shengzhe Xu", "Mandar Sharma", "Naren Ramakrishnan"], "title": "Can an LLM Induce a Graph? Investigating Memory Drift and Context Length", "comment": "2025 IEEE International Conference on Knowledge Graph (ICKG)", "summary": "Recently proposed evaluation benchmarks aim to characterize the effective\ncontext length and the forgetting tendencies of large language models (LLMs).\nHowever, these benchmarks often rely on simplistic 'needle in a haystack'\nretrieval or continuation tasks that may not accurately reflect the performance\nof these models in information-dense scenarios. Thus, rather than simple next\ntoken prediction, we argue for evaluating these models on more complex\nreasoning tasks that requires them to induce structured relational knowledge\nfrom the text - such as graphs from potentially noisy natural language content.\nWhile the input text can be viewed as generated in terms of a graph, its\nstructure is not made explicit and connections must be induced from distributed\ntextual cues, separated by long contexts and interspersed with irrelevant\ninformation. Our findings reveal that LLMs begin to exhibit memory drift and\ncontextual forgetting at much shorter effective lengths when tasked with this\nform of relational reasoning, compared to what existing benchmarks suggest.\nWith these findings, we offer recommendations for the optimal use of popular\nLLMs for complex reasoning tasks. We further show that even models specialized\nfor reasoning, such as OpenAI o1, remain vulnerable to early memory drift in\nthese settings. These results point to significant limitations in the models'\nability to abstract structured knowledge from unstructured input and highlight\nthe need for architectural adaptations to improve long-range reasoning.", "AI": {"tldr": "\u73b0\u6709\u8bc4\u4f30\u57fa\u51c6\u53ef\u80fd\u9ad8\u4f30LLMs\u7684\u6709\u6548\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u5728\u9700\u8981\u4ece\u957f\u6587\u672c\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u5173\u7cfb\u77e5\u8bc6\u7684\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u4f1a\u51fa\u73b0\u66f4\u65e9\u7684\u8bb0\u5fc6\u6f02\u79fb\u548c\u4e0a\u4e0b\u6587\u9057\u5fd8\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u57fa\u51c6\u4e3b\u8981\u57fa\u4e8e\u7b80\u5355\u7684\u68c0\u7d22\u4efb\u52a1\uff0c\u4e0d\u80fd\u51c6\u786e\u53cd\u6620LLMs\u5728\u4fe1\u606f\u5bc6\u96c6\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u9700\u8981\u4ece\u957f\u6587\u672c\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u77e5\u8bc6\u7684\u590d\u6742\u63a8\u7406\u4efb\u52a1\u3002", "method": "\u901a\u8fc7\u8ba9LLMs\u4ece\u53ef\u80fd\u5305\u542b\u566a\u58f0\u7684\u81ea\u7136\u8bed\u8a00\u5185\u5bb9\u4e2d\u5f52\u7eb3\u7ed3\u6784\u5316\u5173\u7cfb\u77e5\u8bc6\uff08\u5982\u56fe\u7ed3\u6784\uff09\uff0c\u8bc4\u4f30\u5176\u5728\u957f\u4e0a\u4e0b\u6587\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u3002", "result": "LLMs\u5728\u8fdb\u884c\u5173\u7cfb\u63a8\u7406\u4efb\u52a1\u65f6\uff0c\u5728\u6bd4\u73b0\u6709\u57fa\u51c6\u5efa\u8bae\u7684\u66f4\u77ed\u6709\u6548\u957f\u5ea6\u4e0b\u5c31\u5f00\u59cb\u51fa\u73b0\u8bb0\u5fc6\u6f02\u79fb\u548c\u4e0a\u4e0b\u6587\u9057\u5fd8\uff0c\u5373\u4f7f\u662f\u4e13\u95e8\u7684\u63a8\u7406\u6a21\u578b\u5982OpenAI o1\u4e5f\u5bb9\u6613\u53d7\u5230\u65e9\u671f\u8bb0\u5fc6\u6f02\u79fb\u7684\u5f71\u54cd\u3002", "conclusion": "LLMs\u4ece\u975e\u7ed3\u6784\u5316\u8f93\u5165\u4e2d\u62bd\u8c61\u7ed3\u6784\u5316\u77e5\u8bc6\u7684\u80fd\u529b\u5b58\u5728\u663e\u8457\u9650\u5236\uff0c\u9700\u8981\u67b6\u6784\u6539\u8fdb\u6765\u63d0\u5347\u957f\u8ddd\u79bb\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.03886", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03886", "abs": "https://arxiv.org/abs/2510.03886", "authors": ["Seil Kang", "Woojung Han", "Dayun Ju", "Seong Jae Hwang"], "title": "Rare Text Semantics Were Always There in Your Diffusion Transformer", "comment": "Accepted to NeurIPS 2025", "summary": "Starting from flow- and diffusion-based transformers, Multi-modal Diffusion\nTransformers (MM-DiTs) have reshaped text-to-vision generation, gaining acclaim\nfor exceptional visual fidelity. As these models advance, users continually\npush the boundary with imaginative or rare prompts, which advanced models still\nfalter in generating, since their concepts are often too scarce to leave a\nstrong imprint during pre-training. In this paper, we propose a simple yet\neffective intervention that surfaces rare semantics inside MM-DiTs without\nadditional training steps, data, denoising-time optimization, or reliance on\nexternal modules (e.g., large language models). In particular, the\njoint-attention mechanism intrinsic to MM-DiT sequentially updates text\nembeddings alongside image embeddings throughout transformer blocks. We find\nthat by mathematically expanding representational basins around text token\nembeddings via variance scale-up before the joint-attention blocks, rare\nsemantics clearly emerge in MM-DiT's outputs. Furthermore, our results\ngeneralize effectively across text-to-vision tasks, including text-to-image,\ntext-to-video, and text-driven image editing. Our work invites generative\nmodels to reveal the semantics that users intend, once hidden yet ready to\nsurface.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u5916\u90e8\u6a21\u5757\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6269\u5c55\u6587\u672c\u5d4c\u5165\u7684\u8868\u793a\u7a7a\u95f4\u6765\u589e\u5f3a\u591a\u6a21\u6001\u6269\u6563\u53d8\u6362\u5668\u5bf9\u7a00\u6709\u8bed\u4e49\u7684\u751f\u6210\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u5230\u89c6\u89c9\u751f\u6210\u6a21\u578b\u5728\u5904\u7406\u521b\u610f\u6216\u7a00\u6709\u63d0\u793a\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u6982\u5ff5\u5728\u9884\u8bad\u7ec3\u4e2d\u8fc7\u4e8e\u7a00\u7f3a\uff0c\u96be\u4ee5\u5f62\u6210\u5f3a\u8868\u5f81\u3002", "method": "\u901a\u8fc7\u5728\u8054\u5408\u6ce8\u610f\u529b\u5757\u524d\u5bf9\u6587\u672c\u6807\u8bb0\u5d4c\u5165\u8fdb\u884c\u65b9\u5dee\u653e\u5927\uff0c\u6570\u5b66\u4e0a\u6269\u5c55\u8868\u793a\u7a7a\u95f4\uff0c\u4f7f\u7a00\u6709\u8bed\u4e49\u5728\u8f93\u51fa\u4e2d\u6e05\u6670\u663e\u73b0\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347MM-DiT\u5bf9\u7a00\u6709\u8bed\u4e49\u7684\u751f\u6210\u80fd\u529b\uff0c\u5e76\u5728\u6587\u672c\u5230\u56fe\u50cf\u3001\u6587\u672c\u5230\u89c6\u9891\u548c\u6587\u672c\u9a71\u52a8\u56fe\u50cf\u7f16\u8f91\u7b49\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u63ed\u793a\u7528\u6237\u610f\u56fe\u4e2d\u539f\u672c\u9690\u85cf\u7684\u8bed\u4e49\uff0c\u4e3a\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u8bed\u4e49\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2510.03639", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03639", "abs": "https://arxiv.org/abs/2510.03639", "authors": ["Liming Wang", "Junrui Ni", "Kai-Wei Chang", "Saurabhchand Bhati", "David Harwath", "Mark Hasegawa-Johnson", "James R. Glass"], "title": "Towards Unsupervised Speech Recognition at the Syllable-Level", "comment": null, "summary": "Training speech recognizers with unpaired speech and text -- known as\nunsupervised speech recognition (UASR) -- is a crucial step toward extending\nASR to low-resource languages in the long-tail distribution and enabling\nmultimodal learning from non-parallel data. However, existing approaches based\non phones often rely on costly resources such as grapheme-to-phoneme converters\n(G2Ps) and struggle to generalize to languages with ambiguous phoneme\nboundaries due to training instability. In this paper, we address both\nchallenges by introducing a syllable-level UASR framework based on masked\nlanguage modeling, which avoids the need for G2P and the instability of\nGAN-based methods. Our approach achieves up to a 40\\% relative reduction in\ncharacter error rate (CER) on LibriSpeech and generalizes effectively to\nMandarin, a language that has remained particularly difficult for prior\nmethods. Code will be released upon acceptance.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u97f3\u8282\u7ea7\u63a9\u7801\u8bed\u8a00\u5efa\u6a21\u7684\u65e0\u76d1\u7763\u8bed\u97f3\u8bc6\u522b\u6846\u67b6\uff0c\u65e0\u9700G2P\u8f6c\u6362\u5668\uff0c\u5728LibriSpeech\u4e0a\u5b9e\u73b040%\u76f8\u5bf9\u5b57\u7b26\u9519\u8bef\u7387\u964d\u4f4e\uff0c\u5e76\u80fd\u6709\u6548\u63a8\u5e7f\u5230\u4e2d\u6587\u3002", "motivation": "\u89e3\u51b3\u65e0\u76d1\u7763\u8bed\u97f3\u8bc6\u522b\u4e2d\u4f9d\u8d56\u6602\u8d35G2P\u8d44\u6e90\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u57fa\u4e8e\u97f3\u7d20\u7684\u65b9\u6cd5\u5728\u6a21\u7cca\u97f3\u7d20\u8fb9\u754c\u8bed\u8a00\u4e2d\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u7684\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u97f3\u8282\u7ea7\u63a9\u7801\u8bed\u8a00\u5efa\u6a21\u7684\u65e0\u76d1\u7763\u8bed\u97f3\u8bc6\u522b\u6846\u67b6\uff0c\u907f\u514d\u4e86GAN\u65b9\u6cd5\u7684\u4e0d\u7a33\u5b9a\u6027\u3002", "result": "\u5728LibriSpeech\u4e0a\u5b9e\u73b040%\u76f8\u5bf9\u5b57\u7b26\u9519\u8bef\u7387\u964d\u4f4e\uff0c\u5728\u4e2d\u6587\u7b49\u56f0\u96be\u8bed\u8a00\u4e0a\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u63d0\u51fa\u7684\u97f3\u8282\u7ea7UASR\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00ASR\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.03892", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03892", "abs": "https://arxiv.org/abs/2510.03892", "authors": ["Zahra Atf", "Peter R. Lewis"], "title": "Kantian-Utilitarian XAI: Meta-Explained", "comment": "Accepted for presentation as a poster at the 35th IEEE International\n  Conference on Collaborative Advances in Software and Computing, 2025.\n  Conference\n  website:https://conf.researchr.org/details/cascon-2025/posters-track/1/Kantian-Utilitarian-XAI-Meta-Explained", "summary": "We present a gamified explainable AI (XAI) system for ethically aware\nconsumer decision-making in the coffee domain. Each session comprises six\nrounds with three options per round. Two symbolic engines provide real-time\nreasons: a Kantian module flags rule violations (e.g., child labor,\ndeforestation risk without shade certification, opaque supply chains, unsafe\ndecaf), and a utilitarian module scores options via multi-criteria aggregation\nover normalized attributes (price, carbon, water, transparency, farmer income\nshare, taste/freshness, packaging, convenience). A meta-explainer with a regret\nbound (0.2) highlights Kantian--utilitarian (mis)alignment and switches to a\ndeontically clean, near-parity option when welfare loss is small. We release a\nstructured configuration (attribute schema, certification map, weights, rule\nset), a policy trace for auditability, and an interactive UI.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6e38\u620f\u5316\u7684\u53ef\u89e3\u91caAI\u7cfb\u7edf\uff0c\u5e2e\u52a9\u6d88\u8d39\u8005\u5728\u5496\u5561\u8d2d\u4e70\u4e2d\u505a\u51fa\u7b26\u5408\u4f26\u7406\u7684\u51b3\u7b56\u3002\u7cfb\u7edf\u7ed3\u5408\u5eb7\u5fb7\u4e3b\u4e49\u548c\u529f\u5229\u4e3b\u4e49\u4e24\u79cd\u4f26\u7406\u6846\u67b6\uff0c\u63d0\u4f9b\u5b9e\u65f6\u89e3\u91ca\uff0c\u5e76\u5728\u4f26\u7406\u51b2\u7a81\u65f6\u63d0\u4f9b\u66ff\u4ee3\u9009\u9879\u3002", "motivation": "\u89e3\u51b3\u6d88\u8d39\u8005\u5728\u590d\u6742\u4f9b\u5e94\u94fe\u4e2d\u96be\u4ee5\u505a\u51fa\u7b26\u5408\u4f26\u7406\u7684\u8d2d\u4e70\u51b3\u7b56\u7684\u95ee\u9898\uff0c\u901a\u8fc7AI\u7cfb\u7edf\u63d0\u4f9b\u900f\u660e\u7684\u4f26\u7406\u5206\u6790\u548c\u89e3\u91ca\u3002", "method": "\u4f7f\u7528\u4e24\u4e2a\u7b26\u53f7\u5f15\u64ce\uff1a\u5eb7\u5fb7\u4e3b\u4e49\u6a21\u5757\u68c0\u6d4b\u89c4\u5219\u8fdd\u53cd\uff08\u5982\u7ae5\u5de5\u3001\u6bc1\u6797\u98ce\u9669\u7b49\uff09\uff0c\u529f\u5229\u4e3b\u4e49\u6a21\u5757\u901a\u8fc7\u591a\u6807\u51c6\u805a\u5408\u5bf9\u9009\u9879\u8bc4\u5206\u3002\u5143\u89e3\u91ca\u5668\u5904\u7406\u4e24\u79cd\u4f26\u7406\u6846\u67b6\u7684\u51b2\u7a81\u3002", "result": "\u5f00\u53d1\u4e86\u5b8c\u6574\u7684\u7cfb\u7edf\u914d\u7f6e\uff0c\u5305\u62ec\u5c5e\u6027\u6a21\u5f0f\u3001\u8ba4\u8bc1\u6620\u5c04\u3001\u6743\u91cd\u548c\u89c4\u5219\u96c6\uff0c\u4ee5\u53ca\u53ef\u5ba1\u8ba1\u7684\u653f\u7b56\u8ffd\u8e2a\u548c\u4ea4\u4e92\u5f0f\u7528\u6237\u754c\u9762\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u6d88\u8d39\u8005\u63d0\u4f9b\u4e86\u5728\u590d\u6742\u4f26\u7406\u51b3\u7b56\u4e2d\u7684\u900f\u660e\u6307\u5bfc\uff0c\u5e73\u8861\u4e86\u4e0d\u540c\u4f26\u7406\u6846\u67b6\u7684\u8003\u91cf\uff0c\u5e76\u786e\u4fdd\u4e86\u51b3\u7b56\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2510.03663", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03663", "abs": "https://arxiv.org/abs/2510.03663", "authors": ["Xiangyu Peng", "Cab Qin", "Zeyuan Chen", "Ran Xu", "Caiming Xiong", "Chien-Sheng Wu"], "title": "UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG", "comment": null, "summary": "Multimodal retrieval-augmented generation (MM-RAG) is a key approach for\napplying large language models (LLMs) and agents to real-world knowledge bases,\nyet current evaluations are fragmented, focusing on either text or images in\nisolation or on simplified multimodal setups that fail to capture\ndocument-centric multimodal use cases. In this paper, we introduce\nUniDoc-Bench, the first large-scale, realistic benchmark for MM-RAG built from\n70k real-world PDF pages across eight domains. Our pipeline extracts and links\nevidence from text, tables, and figures, then generates 1,600 multimodal QA\npairs spanning factual retrieval, comparison, summarization, and logical\nreasoning queries. To ensure reliability, 20% of QA pairs are validated by\nmultiple annotators and expert adjudication. UniDoc-Bench supports\napples-to-apples comparison across four paradigms: (1) text-only, (2)\nimage-only, (3) multimodal text-image fusion, and (4) multimodal joint\nretrieval -- under a unified protocol with standardized candidate pools,\nprompts, and evaluation metrics. Our experiments show that multimodal\ntext-image fusion RAG systems consistently outperform both unimodal and jointly\nmultimodal embedding-based retrieval, indicating that neither text nor images\nalone are sufficient and that current multimodal embeddings remain inadequate.\nBeyond benchmarking, our analysis reveals when and how visual context\ncomplements textual evidence, uncovers systematic failure modes, and offers\nactionable guidance for developing more robust MM-RAG pipelines.", "AI": {"tldr": "UniDoc-Bench\u662f\u9996\u4e2a\u5927\u89c4\u6a21\u3001\u73b0\u5b9e\u7684\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u57fa\u51c6\uff0c\u57fa\u4e8e70k\u771f\u5b9ePDF\u9875\u9762\u6784\u5efa\uff0c\u5305\u542b1,600\u4e2a\u591a\u6a21\u6001QA\u5bf9\uff0c\u652f\u6301\u56db\u79cd\u8303\u5f0f\u7684\u516c\u5e73\u6bd4\u8f83\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u8bc4\u4f30\u96f6\u6563\uff0c\u7f3a\u4e4f\u6355\u83b7\u6587\u6863\u4e2d\u5fc3\u591a\u6a21\u6001\u7528\u4f8b\u7684\u73b0\u5b9e\u57fa\u51c6\u3002", "method": "\u4ece8\u4e2a\u9886\u57df\u768470k\u771f\u5b9ePDF\u9875\u9762\u63d0\u53d6\u6587\u672c\u3001\u8868\u683c\u548c\u56fe\u50cf\u8bc1\u636e\uff0c\u751f\u62101,600\u4e2a\u591a\u6a21\u6001QA\u5bf9\uff0c20%\u7ecf\u8fc7\u591a\u6807\u6ce8\u8005\u9a8c\u8bc1\u548c\u4e13\u5bb6\u88c1\u51b3\u3002", "result": "\u591a\u6a21\u6001\u6587\u672c-\u56fe\u50cf\u878d\u5408RAG\u7cfb\u7edf\u6301\u7eed\u4f18\u4e8e\u5355\u6a21\u6001\u548c\u8054\u5408\u591a\u6a21\u6001\u5d4c\u5165\u68c0\u7d22\uff0c\u8868\u660e\u5f53\u524d\u591a\u6a21\u6001\u5d4c\u5165\u4ecd\u4e0d\u8db3\u591f\u3002", "conclusion": "\u89c6\u89c9\u4e0a\u4e0b\u6587\u4f55\u65f6\u4ee5\u53ca\u5982\u4f55\u8865\u5145\u6587\u672c\u8bc1\u636e\u7684\u5206\u6790\u63ed\u793a\u4e86\u7cfb\u7edf\u6027\u5931\u8d25\u6a21\u5f0f\uff0c\u4e3a\u5f00\u53d1\u66f4\u7a33\u5065\u7684MM-RAG\u7ba1\u9053\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u6307\u5bfc\u3002"}}
{"id": "2510.03969", "categories": ["cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03969", "abs": "https://arxiv.org/abs/2510.03969", "authors": ["Chengxiao Wang", "Isha Chaudhary", "Qian Hu", "Weitong Ruan", "Rahul Gupta", "Gagandeep Singh"], "title": "Quantifying Risks in Multi-turn Conversation with Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) can produce catastrophic responses in\nconversational settings that pose serious risks to public safety and security.\nExisting evaluations often fail to fully reveal these vulnerabilities because\nthey rely on fixed attack prompt sequences, lack statistical guarantees, and do\nnot scale to the vast space of multi-turn conversations. In this work, we\npropose QRLLM, a novel, principled Certification framework for Catastrophic\nrisks in multi-turn Conversation for LLMs that bounds the probability of an LLM\ngenerating catastrophic responses under multi-turn conversation distributions\nwith statistical guarantees. We model multi-turn conversations as probability\ndistributions over query sequences, represented by a Markov process on a query\ngraph whose edges encode semantic similarity to capture realistic\nconversational flow, and quantify catastrophic risks using confidence\nintervals. We define several inexpensive and practical distributions: random\nnode, graph path, adaptive with rejection. Our results demonstrate that these\ndistributions can reveal substantial catastrophic risks in frontier models,\nwith certified lower bounds as high as 70\\% for the worst model, highlighting\nthe urgent need for improved safety training strategies in frontier LLMs.", "AI": {"tldr": "QRLLM\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u4ea7\u751f\u707e\u96be\u6027\u54cd\u5e94\u98ce\u9669\u7684\u8ba4\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u548c\u67e5\u8be2\u56fe\u5efa\u6a21\u5bf9\u8bdd\u5206\u5e03\uff0c\u63d0\u4f9b\u7edf\u8ba1\u4fdd\u8bc1\u7684\u98ce\u9669\u8fb9\u754c\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u63ed\u793aLLM\u5728\u5bf9\u8bdd\u8bbe\u7f6e\u4e2d\u7684\u707e\u96be\u6027\u54cd\u5e94\u6f0f\u6d1e\uff0c\u56e0\u4e3a\u5b83\u4eec\u4f9d\u8d56\u56fa\u5b9a\u653b\u51fb\u63d0\u793a\u5e8f\u5217\u3001\u7f3a\u4e4f\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u4e14\u65e0\u6cd5\u6269\u5c55\u5230\u591a\u8f6e\u5bf9\u8bdd\u7684\u5e7f\u9614\u7a7a\u95f4\u3002", "method": "\u5c06\u591a\u8f6e\u5bf9\u8bdd\u5efa\u6a21\u4e3a\u67e5\u8be2\u5e8f\u5217\u7684\u6982\u7387\u5206\u5e03\uff0c\u7528\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u5728\u67e5\u8be2\u56fe\u4e0a\u8868\u793a\uff0c\u8fb9\u7f16\u7801\u8bed\u4e49\u76f8\u4f3c\u6027\u4ee5\u6355\u6349\u771f\u5b9e\u5bf9\u8bdd\u6d41\uff0c\u4f7f\u7528\u7f6e\u4fe1\u533a\u95f4\u91cf\u5316\u707e\u96be\u6027\u98ce\u9669\u3002", "result": "\u8be5\u65b9\u6cd5\u63ed\u793a\u4e86\u524d\u6cbf\u6a21\u578b\u4e2d\u663e\u8457\u7684\u707e\u96be\u6027\u98ce\u9669\uff0c\u6700\u5dee\u6a21\u578b\u7684\u8ba4\u8bc1\u4e0b\u754c\u9ad8\u8fbe70%\uff0c\u8868\u660e\u9700\u8981\u6539\u8fdb\u5b89\u5168\u8bad\u7ec3\u7b56\u7565\u3002", "conclusion": "QRLLM\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u8ba4\u8bc1\u6846\u67b6\uff0c\u80fd\u591f\u7edf\u8ba1\u4fdd\u8bc1\u5730\u8bc4\u4f30LLM\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u707e\u96be\u6027\u98ce\u9669\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u524d\u6cbfLLM\u5b89\u5168\u8bad\u7ec3\u7684\u4e0d\u8db3\u3002"}}
{"id": "2510.03683", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03683", "abs": "https://arxiv.org/abs/2510.03683", "authors": ["Nisar Hussain", "Amna Qasim", "Gull Mehak", "Muhammad Zain", "Momina Hafeez", "Grigori Sidorov"], "title": "Fine-Tuning Large Language Models with QLoRA for Offensive Language Detection in Roman Urdu-English Code-Mixed Text", "comment": "25 pages, 22 figures", "summary": "The use of derogatory terms in languages that employ code mixing, such as\nRoman Urdu, presents challenges for Natural Language Processing systems due to\nunstated grammar, inconsistent spelling, and a scarcity of labeled data. In\nthis work, we propose a QLoRA based fine tuning framework to improve offensive\nlanguage detection in Roman Urdu-English text. We translated the Roman\nUrdu-English code mixed dataset into English using Google Translate to leverage\nEnglish LLMs, while acknowledging that this translation reduces direct\nengagement with code mixing features. Our focus is on classification\nperformance using English translated low resource inputs. We fine tuned several\ntransformers and large language models, including Meta LLaMA 3 8B, Mistral 7B\nv0.1, LLaMA 2 7B, ModernBERT, and RoBERTa, with QLoRA for memory efficient\nadaptation. Models were trained and evaluated on a manually annotated Roman\nUrdu dataset for offensive vs non offensive content. Of all tested models, the\nhighest F1 score of 91.45 was attained by Meta LLaMA 3 8B, followed by Mistral\n7B at 89.66, surpassing traditional transformer baselines. These results\ndemonstrate the efficacy of QLoRA in fine tuning high performing models for low\nresource environments such as code mixed offensive language detection, and\nconfirm the potential of LLMs for this task. This work advances a scalable\napproach to Roman Urdu moderation and paves the way for future multilingual\noffensive detection systems based on LLMs.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eQLoRA\u7684\u5fae\u8c03\u6846\u67b6\uff0c\u7528\u4e8e\u6539\u8fdb\u7f57\u9a6c\u4e4c\u5c14\u90fd\u8bed-\u82f1\u8bed\u6df7\u5408\u6587\u672c\u4e2d\u7684\u5192\u72af\u6027\u8bed\u8a00\u68c0\u6d4b\uff0c\u901a\u8fc7\u7ffb\u8bd1\u5904\u7406\u4f4e\u8d44\u6e90\u8f93\u5165\uff0c\u5728\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u53d6\u5f97\u4f18\u5f02\u6027\u80fd\u3002", "motivation": "\u7f57\u9a6c\u4e4c\u5c14\u90fd\u8bed\u7b49\u4ee3\u7801\u6df7\u5408\u8bed\u8a00\u4e2d\u7684\u8d2c\u4e49\u8bcd\u4f7f\u7528\u7ed9NLP\u7cfb\u7edf\u5e26\u6765\u6311\u6218\uff0c\u5305\u62ec\u65e0\u660e\u786e\u8bed\u6cd5\u3001\u62fc\u5199\u4e0d\u4e00\u81f4\u548c\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u3002", "method": "\u4f7f\u7528Google Translate\u5c06\u7f57\u9a6c\u4e4c\u5c14\u90fd\u8bed-\u82f1\u8bed\u6df7\u5408\u6570\u636e\u96c6\u7ffb\u8bd1\u6210\u82f1\u8bed\uff0c\u5229\u7528QLoRA\u5bf9\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5185\u5b58\u9ad8\u6548\u7684\u5fae\u8c03\uff0c\u5305\u62ecMeta LLaMA 3 8B\u3001Mistral 7B\u7b49\u3002", "result": "Meta LLaMA 3 8B\u83b7\u5f97\u6700\u9ad8F1\u5206\u657091.45\uff0cMistral 7B\u8fbe\u523089.66\uff0c\u5747\u8d85\u8fc7\u4f20\u7edftransformer\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "QLoRA\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u4ee3\u7801\u6df7\u5408\u5192\u72af\u6027\u8bed\u8a00\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u5b9e\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u7f57\u9a6c\u4e4c\u5c14\u90fd\u8bed\u5185\u5bb9\u5ba1\u6838\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u65b9\u6cd5\u3002"}}
{"id": "2510.04009", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04009", "abs": "https://arxiv.org/abs/2510.04009", "authors": ["Zicong He", "Boxuan Zhang", "Weihao Liu", "Ruixiang Tang", "Lu Cheng"], "title": "What Shapes a Creative Machine Mind? Comprehensively Benchmarking Creativity in Foundation Models", "comment": "22 pages", "summary": "The meteoric rise of foundation models (FMs) has expanded their capabilities\nfar beyond conventional tasks. Creativity, long regarded as a hallmark of human\nintelligence and a driver of innovation, is now increasingly recognized as a\ncritical dimension of machine intelligence in the era of generative FMs,\ncomplementing traditional measures of accuracy. However, existing evaluation\nframeworks for creativity remain fragmented, relying on ad hoc metrics not\nfirmly grounded in established theories. To address this gap, we introduce\nC^2-Eval, a holistic benchmark for unified assessment of creativity in FMs.\nC^2-Eval distinguishes between two complementary forms of creativity:\nconvergent creativity, where tasks admit constrained solutions (e.g., code\ngeneration), and divergent creativity, where tasks are open-ended (e.g.,\nstorytelling). It evaluates both dimensions using fine-grained criteria derived\nfrom social-science theory, focusing on Usefulness, Originality, and Surprise\n(U-O-S). Through extensive experiments on leading proprietary and open-source\nmodels, we analyze trade-offs in their creative capabilities. Our results\nhighlight both the strengths and challenges of current FMs in pursuing a\ncreative machine mind, showing that C^2-Eval is an effective lens for examining\nthe evolving landscape of creative AI.", "AI": {"tldr": "\u63d0\u51fa\u4e86C^2-Eval\u57fa\u51c6\uff0c\u7528\u4e8e\u7edf\u4e00\u8bc4\u4f30\u57fa\u7840\u6a21\u578b\u7684\u521b\u9020\u529b\uff0c\u533a\u5206\u6536\u655b\u6027\u521b\u9020\u529b\u548c\u53d1\u6563\u6027\u521b\u9020\u529b\uff0c\u57fa\u4e8e\u6709\u7528\u6027\u3001\u539f\u521b\u6027\u548c\u60ca\u559c\u6027\u4e09\u4e2a\u6807\u51c6\u3002", "motivation": "\u73b0\u6709\u521b\u9020\u529b\u8bc4\u4f30\u6846\u67b6\u788e\u7247\u5316\uff0c\u7f3a\u4e4f\u57fa\u4e8e\u6210\u719f\u7406\u8bba\u7684\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5\uff0c\u65e0\u6cd5\u5168\u9762\u8861\u91cf\u57fa\u7840\u6a21\u578b\u7684\u521b\u9020\u529b\u3002", "method": "\u5f15\u5165C^2-Eval\u57fa\u51c6\uff0c\u533a\u5206\u6536\u655b\u6027\u521b\u9020\u529b\uff08\u7ea6\u675f\u6027\u4efb\u52a1\uff09\u548c\u53d1\u6563\u6027\u521b\u9020\u529b\uff08\u5f00\u653e\u6027\u4efb\u52a1\uff09\uff0c\u4f7f\u7528\u57fa\u4e8e\u793e\u4f1a\u79d1\u5b66\u7406\u8bba\u7684U-O-S\u6807\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u5bf9\u9886\u5148\u4e13\u6709\u548c\u5f00\u6e90\u6a21\u578b\u7684\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u5206\u6790\u4e86\u5b83\u4eec\u5728\u521b\u9020\u529b\u80fd\u529b\u4e0a\u7684\u6743\u8861\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u57fa\u7840\u6a21\u578b\u5728\u8ffd\u6c42\u521b\u9020\u6027\u673a\u5668\u667a\u80fd\u65b9\u9762\u7684\u4f18\u52bf\u548c\u6311\u6218\u3002", "conclusion": "C^2-Eval\u662f\u68c0\u9a8c\u521b\u9020\u6027AI\u53d1\u5c55\u683c\u5c40\u7684\u6709\u6548\u5de5\u5177\uff0c\u80fd\u591f\u7cfb\u7edf\u8bc4\u4f30\u57fa\u7840\u6a21\u578b\u7684\u521b\u9020\u529b\u8868\u73b0\u3002"}}
{"id": "2510.03687", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03687", "abs": "https://arxiv.org/abs/2510.03687", "authors": ["Yue Huang", "Yanyuan Chen", "Dexuan Xu", "Weihua Yue", "Huamin Zhang", "Meikang Qiu", "Yu Huang"], "title": "MedReflect: Teaching Medical LLMs to Self-Improve via Reflective Correction", "comment": null, "summary": "Medical problem solving demands expert knowledge and intricate reasoning.\nRecent studies of large language models (LLMs) attempt to ease this complexity\nby introducing external knowledge verification through retrieval-augmented\ngeneration or by training on reasoning datasets. However, these approaches\nsuffer from drawbacks such as retrieval overhead and high annotation costs, and\nthey heavily rely on substituted external assistants to reach limited\nperformance in medical field. In this paper, we introduce MedReflect, a\ngeneralizable framework designed to inspire LLMs with a physician-like\nreflective thinking mode. MedReflect generates a single-pass reflection chain\nthat includes initial hypothesis generation, self-questioning, self-answering\nand decision refinement. This self-verified and self-reflective nature releases\nlarge language model's latent capability in medical problem-solving without\nexternal retrieval or heavy annotation. We demonstrate that MedReflect enables\ncost-efficient medical dataset construction: with merely 2,000 randomly sampled\ntraining examples and a light fine-tuning, this approach achieves notable\nabsolute accuracy improvements across a series of medical benchmarks while\ncutting annotation requirements. Our results provide evidence that LLMs can\nlearn to solve specialized medical problems via self-reflection and\nself-improve, reducing reliance on external supervision and extensive\ntask-specific fine-tuning data.", "AI": {"tldr": "MedReflect\u662f\u4e00\u4e2a\u65e0\u9700\u5916\u90e8\u68c0\u7d22\u6216\u5927\u91cf\u6807\u6ce8\u7684\u533b\u5b66\u95ee\u9898\u89e3\u51b3\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u53cd\u601d\u94fe\u6fc0\u53d1LLMs\u7684\u6f5c\u5728\u80fd\u529b\uff0c\u4ec5\u9700\u5c11\u91cf\u8bad\u7ec3\u6837\u672c\u5373\u53ef\u663e\u8457\u63d0\u5347\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5916\u90e8\u77e5\u8bc6\u68c0\u7d22\u6216\u5927\u91cf\u63a8\u7406\u6570\u636e\u96c6\u8bad\u7ec3\uff0c\u5b58\u5728\u68c0\u7d22\u5f00\u9500\u5927\u3001\u6807\u6ce8\u6210\u672c\u9ad8\u3001\u4f9d\u8d56\u5916\u90e8\u52a9\u624b\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5728\u533b\u5b66\u9886\u57df\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51faMedReflect\u6846\u67b6\uff0c\u6a21\u62df\u533b\u751f\u53cd\u601d\u601d\u7ef4\u6a21\u5f0f\uff0c\u751f\u6210\u5355\u6b21\u53cd\u601d\u94fe\uff1a\u521d\u59cb\u5047\u8bbe\u751f\u6210\u2192\u81ea\u6211\u63d0\u95ee\u2192\u81ea\u6211\u56de\u7b54\u2192\u51b3\u7b56\u7cbe\u70bc\uff0c\u5b9e\u73b0\u81ea\u6211\u9a8c\u8bc1\u548c\u81ea\u6211\u53cd\u601d\u3002", "result": "\u4ec5\u75282000\u4e2a\u968f\u673a\u8bad\u7ec3\u6837\u672c\u548c\u8f7b\u91cf\u5fae\u8c03\uff0c\u5c31\u5728\u591a\u4e2a\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u663e\u8457\u51c6\u786e\u7387\u63d0\u5347\uff0c\u5927\u5e45\u51cf\u5c11\u6807\u6ce8\u9700\u6c42\u3002", "conclusion": "LLMs\u53ef\u4ee5\u901a\u8fc7\u81ea\u6211\u53cd\u601d\u548c\u81ea\u6211\u6539\u8fdb\u5b66\u4e60\u89e3\u51b3\u4e13\u4e1a\u533b\u5b66\u95ee\u9898\uff0c\u51cf\u5c11\u5bf9\u5916\u90e8\u76d1\u7763\u548c\u5927\u91cf\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u6570\u636e\u7684\u4f9d\u8d56\u3002"}}
{"id": "2510.04017", "categories": ["cs.AI", "cs.LG", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.04017", "abs": "https://arxiv.org/abs/2510.04017", "authors": ["Sumanth Varambally", "Marshall Fisher", "Jas Thakker", "Yiwei Chen", "Zhirui Xia", "Yasaman Jafari", "Ruijia Niu", "Manas Jain", "Veeramakali Vignesh Manivannan", "Zachary Novack", "Luyu Han", "Srikar Eranky", "Salva R\u00fchling Cachay", "Taylor Berg-Kirkpatrick", "Duncan Watson-Parris", "Yi-An Ma", "Rose Yu"], "title": "Zephyrus: An Agentic Framework for Weather Science", "comment": null, "summary": "Foundation models for weather science are pre-trained on vast amounts of\nstructured numerical data and outperform traditional weather forecasting\nsystems. However, these models lack language-based reasoning capabilities,\nlimiting their utility in interactive scientific workflows. Large language\nmodels (LLMs) excel at understanding and generating text but cannot reason\nabout high-dimensional meteorological datasets. We bridge this gap by building\na novel agentic framework for weather science. Our framework includes a Python\ncode-based environment for agents (ZephyrusWorld) to interact with weather\ndata, featuring tools like an interface to WeatherBench 2 dataset, geoquerying\nfor geographical masks from natural language, weather forecasting, and climate\nsimulation capabilities. We design Zephyrus, a multi-turn LLM-based weather\nagent that iteratively analyzes weather datasets, observes results, and refines\nits approach through conversational feedback loops. We accompany the agent with\na new benchmark, ZephyrusBench, with a scalable data generation pipeline that\nconstructs diverse question-answer pairs across weather-related tasks, from\nbasic lookups to advanced forecasting, extreme event detection, and\ncounterfactual reasoning. Experiments on this benchmark demonstrate the strong\nperformance of Zephyrus agents over text-only baselines, outperforming them by\nup to 35 percentage points in correctness. However, on harder tasks, Zephyrus\nperforms similarly to text-only baselines, highlighting the challenging nature\nof our benchmark and suggesting promising directions for future work.", "AI": {"tldr": "\u63d0\u51fa\u4e86Zephyrus\u6846\u67b6\uff0c\u5c06\u5929\u6c14\u9884\u62a5\u57fa\u7840\u6a21\u578b\u4e0e\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\uff0c\u901a\u8fc7\u4ee3\u7801\u73af\u5883\u5b9e\u73b0\u591a\u8f6e\u4ea4\u4e92\u5f0f\u5929\u6c14\u79d1\u5b66\u5206\u6790\uff0c\u5e76\u5728\u65b0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u7eaf\u6587\u672c\u57fa\u7ebf\u3002", "motivation": "\u5929\u6c14\u9884\u62a5\u57fa\u7840\u6a21\u578b\u7f3a\u4e4f\u8bed\u8a00\u63a8\u7406\u80fd\u529b\uff0c\u800c\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u5904\u7406\u9ad8\u7ef4\u6c14\u8c61\u6570\u636e\uff0c\u9700\u8981\u6865\u63a5\u8fd9\u4e00\u5dee\u8ddd\u4ee5\u652f\u6301\u4ea4\u4e92\u5f0f\u79d1\u5b66\u5de5\u4f5c\u6d41\u3002", "method": "\u6784\u5efa\u4e86ZephyrusWorld\u4ee3\u7801\u73af\u5883\uff0c\u5305\u542bWeatherBench 2\u6570\u636e\u96c6\u63a5\u53e3\u3001\u5730\u7406\u67e5\u8be2\u3001\u5929\u6c14\u9884\u62a5\u548c\u6c14\u5019\u6a21\u62df\u5de5\u5177\uff0c\u8bbe\u8ba1\u4e86\u591a\u8f6eLLM\u5929\u6c14\u4ee3\u7406Zephyrus\uff0c\u901a\u8fc7\u5bf9\u8bdd\u53cd\u9988\u5faa\u73af\u8fed\u4ee3\u5206\u6790\u6570\u636e\u3002", "result": "\u5728ZephyrusBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cZephyrus\u4ee3\u7406\u5728\u6b63\u786e\u6027\u4e0a\u6bd4\u7eaf\u6587\u672c\u57fa\u7ebf\u9ad8\u51fa35\u4e2a\u767e\u5206\u70b9\uff0c\u4f46\u5728\u66f4\u56f0\u96be\u4efb\u52a1\u4e0a\u8868\u73b0\u76f8\u4f3c\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u7ed3\u5408\u4e86\u5929\u6c14\u9884\u62a5\u6a21\u578b\u548c\u8bed\u8a00\u6a21\u578b\uff0c\u57fa\u51c6\u6d4b\u8bd5\u5177\u6709\u6311\u6218\u6027\uff0c\u4e3a\u672a\u6765\u5de5\u4f5c\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2510.03748", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03748", "abs": "https://arxiv.org/abs/2510.03748", "authors": ["Ramtin Kakavand", "Ebrahim Ansari"], "title": "TreePrompt: Leveraging Hierarchical Few-Shot Example Selection for Improved English-Persian and English-German Translation", "comment": "12 pages", "summary": "Large Language Models (LLMs) have consistently demonstrated strong\nperformance in machine translation, especially when guided by high-quality\nprompts. Few-shot prompting is an effective technique to improve translation\nquality; however, most existing example selection methods focus solely on\nquery-to-example similarity and do not account for the quality of the examples.\nIn this work, we propose TreePrompt, a novel example selection approach that\nlearns LLM preferences to identify high-quality, contextually relevant examples\nwithin a tree-structured framework. To further explore the balance between\nsimilarity and quality, we combine TreePrompt with K-Nearest Neighbors (K-NN)\nand Adaptive Few-Shot Prompting (AFSP). Evaluations on two language pairs -\nEnglish-Persian (MIZAN) and English-German (WMT19) - show that integrating\nTreePrompt with AFSP or Random selection leads to improved translation\nperformance.", "AI": {"tldr": "TreePrompt\u662f\u4e00\u79cd\u65b0\u7684\u793a\u4f8b\u9009\u62e9\u65b9\u6cd5\uff0c\u901a\u8fc7\u6811\u5f62\u7ed3\u6784\u6846\u67b6\u5b66\u4e60LLM\u504f\u597d\u6765\u9009\u62e9\u9ad8\u8d28\u91cf\u3001\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u7ffb\u8bd1\u793a\u4f8b\uff0c\u4e0eAFSP\u6216\u968f\u673a\u9009\u62e9\u7ed3\u5408\u80fd\u63d0\u5347\u7ffb\u8bd1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5c11\u6837\u672c\u63d0\u793a\u793a\u4f8b\u9009\u62e9\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u67e5\u8be2\u4e0e\u793a\u4f8b\u7684\u76f8\u4f3c\u6027\uff0c\u4f46\u5ffd\u7565\u4e86\u793a\u4f8b\u8d28\u91cf\u7684\u91cd\u8981\u6027\uff0c\u8fd9\u9650\u5236\u4e86\u673a\u5668\u7ffb\u8bd1\u6027\u80fd\u7684\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "method": "\u63d0\u51faTreePrompt\u65b9\u6cd5\uff0c\u5728\u6811\u5f62\u7ed3\u6784\u6846\u67b6\u4e2d\u5b66\u4e60LLM\u504f\u597d\u6765\u9009\u62e9\u9ad8\u8d28\u91cf\u4e14\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u793a\u4f8b\uff0c\u5e76\u4e0eK-NN\u548c\u81ea\u9002\u5e94\u5c11\u6837\u672c\u63d0\u793a(AFSP)\u65b9\u6cd5\u7ed3\u5408\u6765\u5e73\u8861\u76f8\u4f3c\u6027\u548c\u8d28\u91cf\u3002", "result": "\u5728\u82f1\u8bed-\u6ce2\u65af\u8bed(MIZAN)\u548c\u82f1\u8bed-\u5fb7\u8bed(WMT19)\u4e24\u4e2a\u8bed\u8a00\u5bf9\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cTreePrompt\u4e0eAFSP\u6216\u968f\u673a\u9009\u62e9\u7ed3\u5408\u80fd\u663e\u8457\u6539\u5584\u7ffb\u8bd1\u6027\u80fd\u3002", "conclusion": "TreePrompt\u901a\u8fc7\u8003\u8651\u793a\u4f8b\u8d28\u91cf\u800c\u4e0d\u4ec5\u4ec5\u662f\u76f8\u4f3c\u6027\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5c11\u6837\u672c\u63d0\u793a\u5728\u673a\u5668\u7ffb\u8bd1\u4e2d\u7684\u6548\u679c\uff0c\u8bc1\u660e\u4e86\u8d28\u91cf\u611f\u77e5\u793a\u4f8b\u9009\u62e9\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.04023", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04023", "abs": "https://arxiv.org/abs/2510.04023", "authors": ["Mizanur Rahman", "Amran Bhuiyan", "Mohammed Saidul Islam", "Md Tahmid Rahman Laskar", "Ridwan Mahbub", "Ahmed Masry", "Shafiq Joty", "Enamul Hoque"], "title": "LLM-Based Data Science Agents: A Survey of Capabilities, Challenges, and Future Directions", "comment": "Survey paper; 45 data science agents; under review", "summary": "Recent advances in large language models (LLMs) have enabled a new class of\nAI agents that automate multiple stages of the data science workflow by\nintegrating planning, tool use, and multimodal reasoning across text, code,\ntables, and visuals. This survey presents the first comprehensive,\nlifecycle-aligned taxonomy of data science agents, systematically analyzing and\nmapping forty-five systems onto the six stages of the end-to-end data science\nprocess: business understanding and data acquisition, exploratory analysis and\nvisualization, feature engineering, model building and selection,\ninterpretation and explanation, and deployment and monitoring. In addition to\nlifecycle coverage, we annotate each agent along five cross-cutting design\ndimensions: reasoning and planning style, modality integration, tool\norchestration depth, learning and alignment methods, and trust, safety, and\ngovernance mechanisms. Beyond classification, we provide a critical synthesis\nof agent capabilities, highlight strengths and limitations at each stage, and\nreview emerging benchmarks and evaluation practices. Our analysis identifies\nthree key trends: most systems emphasize exploratory analysis, visualization,\nand modeling while neglecting business understanding, deployment, and\nmonitoring; multimodal reasoning and tool orchestration remain unresolved\nchallenges; and over 90% lack explicit trust and safety mechanisms. We conclude\nby outlining open challenges in alignment stability, explainability,\ngovernance, and robust evaluation frameworks, and propose future research\ndirections to guide the development of robust, trustworthy, low-latency,\ntransparent, and broadly accessible data science agents.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u6570\u636e\u79d1\u5b66\u667a\u80fd\u4f53\u7684\u751f\u547d\u5468\u671f\u5bf9\u9f50\u5206\u7c7b\u6cd5\uff0c\u7cfb\u7edf\u5206\u6790\u4e8645\u4e2a\u7cfb\u7edf\u5728\u6570\u636e\u79d1\u5b66\u516d\u4e2a\u9636\u6bb5\u7684\u5206\u5e03\uff0c\u5e76\u8bc6\u522b\u4e86\u4e09\u4e2a\u5173\u952e\u8d8b\u52bf\uff1a\u5927\u591a\u6570\u7cfb\u7edf\u5173\u6ce8\u63a2\u7d22\u5206\u6790\u548c\u5efa\u6a21\u800c\u5ffd\u89c6\u4e1a\u52a1\u7406\u89e3\u548c\u90e8\u7f72\u76d1\u63a7\uff1b\u591a\u6a21\u6001\u63a8\u7406\u548c\u5de5\u5177\u7f16\u6392\u4ecd\u662f\u6311\u6218\uff1b90%\u4ee5\u4e0a\u7f3a\u4e4f\u660e\u786e\u7684\u4fe1\u4efb\u5b89\u5168\u673a\u5236\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u51fa\u73b0\u4e86\u80fd\u591f\u81ea\u52a8\u5316\u6570\u636e\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\u7684\u65b0\u578bAI\u667a\u80fd\u4f53\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u667a\u80fd\u4f53\u7684\u7cfb\u7edf\u6027\u5206\u7c7b\u548c\u5206\u6790\uff0c\u9700\u8981\u5efa\u7acb\u5168\u9762\u7684\u5206\u7c7b\u6846\u67b6\u6765\u6307\u5bfc\u672a\u6765\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u4e86\u751f\u547d\u5468\u671f\u5bf9\u9f50\u7684\u5206\u7c7b\u6cd5\uff0c\u5c0645\u4e2a\u6570\u636e\u79d1\u5b66\u667a\u80fd\u4f53\u6620\u5c04\u5230\u6570\u636e\u79d1\u5b66\u6d41\u7a0b\u7684\u516d\u4e2a\u9636\u6bb5\uff0c\u5e76\u4ece\u4e94\u4e2a\u4ea4\u53c9\u8bbe\u8ba1\u7ef4\u5ea6\u8fdb\u884c\u6807\u6ce8\uff1a\u63a8\u7406\u89c4\u5212\u98ce\u683c\u3001\u6a21\u6001\u96c6\u6210\u3001\u5de5\u5177\u7f16\u6392\u6df1\u5ea6\u3001\u5b66\u4e60\u5bf9\u9f50\u65b9\u6cd5\u3001\u4fe1\u4efb\u5b89\u5168\u6cbb\u7406\u673a\u5236\u3002", "result": "\u5206\u6790\u53d1\u73b0\u5927\u591a\u6570\u7cfb\u7edf\u5f3a\u8c03\u63a2\u7d22\u5206\u6790\u3001\u53ef\u89c6\u5316\u548c\u5efa\u6a21\uff0c\u800c\u5ffd\u89c6\u4e1a\u52a1\u7406\u89e3\u3001\u90e8\u7f72\u548c\u76d1\u63a7\uff1b\u591a\u6a21\u6001\u63a8\u7406\u548c\u5de5\u5177\u7f16\u6392\u4ecd\u662f\u672a\u89e3\u51b3\u7684\u6311\u6218\uff1b\u8d85\u8fc790%\u7684\u7cfb\u7edf\u7f3a\u4e4f\u660e\u786e\u7684\u4fe1\u4efb\u548c\u5b89\u5168\u673a\u5236\u3002", "conclusion": "\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5305\u62ec\u5bf9\u9f50\u7a33\u5b9a\u6027\u3001\u53ef\u89e3\u91ca\u6027\u3001\u6cbb\u7406\u548c\u9c81\u68d2\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u6307\u5bfc\u5f00\u53d1\u7a33\u5065\u3001\u53ef\u4fe1\u3001\u4f4e\u5ef6\u8fdf\u3001\u900f\u660e\u548c\u5e7f\u6cdb\u53ef\u8bbf\u95ee\u7684\u6570\u636e\u79d1\u5b66\u667a\u80fd\u4f53\u3002"}}
{"id": "2510.03758", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.03758", "abs": "https://arxiv.org/abs/2510.03758", "authors": ["Ilias Tougui", "Mehdi Zakroum", "Mounir Ghogho"], "title": "Cross-Lingual Multi-Granularity Framework for Interpretable Parkinson's Disease Diagnosis from Speech", "comment": null, "summary": "Parkinson's Disease (PD) affects over 10 million people worldwide, with\nspeech impairments in up to 89% of patients. Current speech-based detection\nsystems analyze entire utterances, potentially overlooking the diagnostic value\nof specific phonetic elements. We developed a granularity-aware approach for\nmultilingual PD detection using an automated pipeline that extracts\ntime-aligned phonemes, syllables, and words from recordings. Using Italian,\nSpanish, and English datasets, we implemented a bidirectional LSTM with\nmulti-head attention to compare diagnostic performance across the different\ngranularity levels. Phoneme-level analysis achieved superior performance with\nAUROC of 93.78% +- 2.34% and accuracy of 92.17% +- 2.43%. This demonstrates\nenhanced diagnostic capability for cross-linguistic PD detection. Importantly,\nattention analysis revealed that the most informative speech features align\nwith those used in established clinical protocols: sustained vowels (/a/, /e/,\n/o/, /i/) at phoneme level, diadochokinetic syllables (/ta/, /pa/, /la/, /ka/)\nat syllable level, and /pataka/ sequences at word level. Source code will be\navailable at https://github.com/jetliqs/clearpd.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u97f3\u7ec6\u7c92\u5ea6\u5206\u6790\u7684\u5e15\u91d1\u68ee\u75c5\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u97f3\u7d20\u3001\u97f3\u8282\u548c\u5355\u8bcd\u7ea7\u522b\u7279\u5f81\uff0c\u5728\u610f\u5927\u5229\u8bed\u3001\u897f\u73ed\u7259\u8bed\u548c\u82f1\u8bed\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8693.78%\u7684AUROC\u548c92.17%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u5f53\u524d\u5e15\u91d1\u68ee\u75c5\u8bed\u97f3\u68c0\u6d4b\u7cfb\u7edf\u5206\u6790\u6574\u4e2a\u8bdd\u8bed\uff0c\u53ef\u80fd\u5ffd\u7565\u4e86\u7279\u5b9a\u8bed\u97f3\u5143\u7d20\u7684\u8bca\u65ad\u4ef7\u503c\u3002\u5e15\u91d1\u68ee\u75c5\u5f71\u54cd\u5168\u7403\u8d85\u8fc71000\u4e07\u4eba\uff0c\u5176\u4e2d\u9ad8\u8fbe89%\u7684\u60a3\u8005\u5b58\u5728\u8bed\u97f3\u969c\u788d\u3002", "method": "\u5f00\u53d1\u4e86\u7ec6\u7c92\u5ea6\u611f\u77e5\u7684\u591a\u8bed\u8a00PD\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4f7f\u7528\u81ea\u52a8\u5316\u6d41\u7a0b\u4ece\u5f55\u97f3\u4e2d\u63d0\u53d6\u65f6\u95f4\u5bf9\u9f50\u7684\u97f3\u7d20\u3001\u97f3\u8282\u548c\u5355\u8bcd\u3002\u91c7\u7528\u53cc\u5411LSTM\u548c\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6bd4\u8f83\u4e0d\u540c\u7c92\u5ea6\u7ea7\u522b\u7684\u8bca\u65ad\u6027\u80fd\u3002", "result": "\u97f3\u7d20\u7ea7\u522b\u5206\u6790\u8868\u73b0\u6700\u4f73\uff0cAUROC\u8fbe\u523093.78% \u00b1 2.34%\uff0c\u51c6\u786e\u7387\u4e3a92.17% \u00b1 2.43%\u3002\u6ce8\u610f\u529b\u5206\u6790\u663e\u793a\u6700\u6709\u4fe1\u606f\u7684\u8bed\u97f3\u7279\u5f81\u4e0e\u4e34\u5e8a\u534f\u8bae\u4e00\u81f4\uff1a\u97f3\u7d20\u7ea7\u522b\u7684\u6301\u7eed\u5143\u97f3\uff0c\u97f3\u8282\u7ea7\u522b\u7684\u4ea4\u66ff\u8fd0\u52a8\u97f3\u8282\uff0c\u4ee5\u53ca\u5355\u8bcd\u7ea7\u522b\u7684/pataka/\u5e8f\u5217\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u8de8\u8bed\u8a00\u5e15\u91d1\u68ee\u75c5\u68c0\u6d4b\u7684\u589e\u5f3a\u8bca\u65ad\u80fd\u529b\uff0c\u4e3a\u4e34\u5e8a\u8bca\u65ad\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u8bed\u97f3\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2510.04033", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04033", "abs": "https://arxiv.org/abs/2510.04033", "authors": ["Ayush Noori", "Adam Rodman", "Alan Karthikesalingam", "Bilal A. Mateen", "Christopher A. Longhurst", "Daniel Yang", "Dave deBronkart", "Gauden Galea", "Harold F. Wolf III", "Jacob Waxman", "Joshua C. Mandel", "Juliana Rotich", "Kenneth D. Mandl", "Maryam Mustafa", "Melissa Miles", "Nigam H. Shah", "Peter Lee", "Robert Korom", "Scott Mahoney", "Seth Hain", "Tien Yin Wong", "Trevor Mundel", "Vivek Natarajan", "Noa Dagan", "David A. Clifton", "Ran D. Balicer", "Isaac S. Kohane", "Marinka Zitnik"], "title": "A global log for medical AI", "comment": null, "summary": "Modern computer systems often rely on syslog, a simple, universal protocol\nthat records every critical event across heterogeneous infrastructure. However,\nhealthcare's rapidly growing clinical AI stack has no equivalent. As hospitals\nrush to pilot large language models and other AI-based clinical decision\nsupport tools, we still lack a standard way to record how, when, by whom, and\nfor whom these AI models are used. Without that transparency and visibility, it\nis challenging to measure real-world performance and outcomes, detect adverse\nevents, or correct bias or dataset drift. In the spirit of syslog, we introduce\nMedLog, a protocol for event-level logging of clinical AI. Any time an AI model\nis invoked to interact with a human, interface with another algorithm, or act\nindependently, a MedLog record is created. This record consists of nine core\nfields: header, model, user, target, inputs, artifacts, outputs, outcomes, and\nfeedback, providing a structured and consistent record of model activity. To\nencourage early adoption, especially in low-resource settings, and minimize the\ndata footprint, MedLog supports risk-based sampling, lifecycle-aware retention\npolicies, and write-behind caching; detailed traces for complex, agentic, or\nmulti-stage workflows can also be captured under MedLog. MedLog can catalyze\nthe development of new databases and software to store and analyze MedLog\nrecords. Realizing this vision would enable continuous surveillance, auditing,\nand iterative improvement of medical AI, laying the foundation for a new form\nof digital epidemiology.", "AI": {"tldr": "\u63d0\u51fa\u4e86MedLog\u534f\u8bae\uff0c\u7528\u4e8e\u8bb0\u5f55\u4e34\u5e8aAI\u7cfb\u7edf\u7684\u4e8b\u4ef6\u7ea7\u65e5\u5fd7\uff0c\u7c7b\u4f3c\u4e8e\u8ba1\u7b97\u673a\u7cfb\u7edf\u7684syslog\uff0c\u65e8\u5728\u63d0\u9ad8\u533b\u7597AI\u7684\u900f\u660e\u5ea6\u548c\u53ef\u8ffd\u6eaf\u6027\u3002", "motivation": "\u533b\u7597\u9886\u57df\u7f3a\u4e4f\u6807\u51c6\u5316\u7684AI\u4f7f\u7528\u8bb0\u5f55\u534f\u8bae\uff0c\u96be\u4ee5\u8ffd\u8e2aAI\u6a21\u578b\u7684\u5b9e\u9645\u4f7f\u7528\u60c5\u51b5\u3001\u6027\u80fd\u8868\u73b0\u548c\u6f5c\u5728\u98ce\u9669\uff0c\u963b\u788d\u4e86\u533b\u7597AI\u7684\u5b89\u5168\u76d1\u7ba1\u548c\u6301\u7eed\u6539\u8fdb\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5305\u542b9\u4e2a\u6838\u5fc3\u5b57\u6bb5\uff08header\u3001model\u3001user\u3001target\u3001inputs\u3001artifacts\u3001outputs\u3001outcomes\u3001feedback\uff09\u7684\u7ed3\u6784\u5316\u65e5\u5fd7\u534f\u8bae\uff0c\u652f\u6301\u98ce\u9669\u91c7\u6837\u3001\u751f\u547d\u5468\u671f\u611f\u77e5\u7684\u4fdd\u7559\u7b56\u7565\u548c\u5199\u540e\u7f13\u5b58\u3002", "result": "MedLog\u534f\u8bae\u80fd\u591f\u7cfb\u7edf\u8bb0\u5f55AI\u6a21\u578b\u5728\u533b\u7597\u73af\u5883\u4e2d\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u4e3a\u6301\u7eed\u76d1\u6d4b\u3001\u5ba1\u8ba1\u548c\u8fed\u4ee3\u6539\u8fdb\u63d0\u4f9b\u57fa\u7840\u6570\u636e\u652f\u6301\u3002", "conclusion": "MedLog\u534f\u8bae\u6709\u671b\u63a8\u52a8\u533b\u7597AI\u7684\u900f\u660e\u5316\u76d1\u7ba1\uff0c\u5efa\u7acb\u6570\u5b57\u6d41\u884c\u75c5\u5b66\u7684\u65b0\u57fa\u7840\uff0c\u4fc3\u8fdb\u533b\u7597AI\u7684\u5b89\u5168\u53ef\u9760\u53d1\u5c55\u3002"}}
{"id": "2510.03762", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03762", "abs": "https://arxiv.org/abs/2510.03762", "authors": ["Deshan Sumanathilaka", "Nicholas Micallef", "Julian Hough"], "title": "Prompt Balance Matters: Understanding How Imbalanced Few-Shot Learning Affects Multilingual Sense Disambiguation in LLMs", "comment": "Paper accepted at GlobalNLP 2025: Workshop on beyond English: Natural\n  Language Processing for All Languages in an Era of Large Language Models\" 9\n  pages, 3 figures, 2 Tables", "summary": "Recent advances in Large Language Models (LLMs) have significantly reshaped\nthe landscape of Natural Language Processing (NLP). Among the various prompting\ntechniques, few-shot prompting has gained considerable attention for its\npracticality and effectiveness. This study investigates how few-shot prompting\nstrategies impact the Word Sense Disambiguation (WSD) task, particularly\nfocusing on the biases introduced by imbalanced sample distributions. We use\nthe GLOSSGPT prompting method, an advanced approach for English WSD, to test\nits effectiveness across five languages: English, German, Spanish, French, and\nItalian. Our results show that imbalanced few-shot examples can cause incorrect\nsense predictions in multilingual languages, but this issue does not appear in\nEnglish. To assess model behavior, we evaluate both the GPT-4o and\nLLaMA-3.1-70B models and the results highlight the sensitivity of multilingual\nWSD to sample distribution in few-shot settings, emphasizing the need for\nbalanced and representative prompting strategies.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5c11\u6837\u672c\u63d0\u793a\u7b56\u7565\u5bf9\u8bcd\u4e49\u6d88\u6b67\u4efb\u52a1\u7684\u5f71\u54cd\uff0c\u7279\u522b\u5173\u6ce8\u6837\u672c\u5206\u5e03\u4e0d\u5e73\u8861\u5e26\u6765\u7684\u504f\u89c1\u95ee\u9898\u3002\u7814\u7a76\u53d1\u73b0\u4e0d\u5e73\u8861\u7684\u5c11\u6837\u672c\u793a\u4f8b\u4f1a\u5bfc\u81f4\u591a\u8bed\u8a00\u8bcd\u4e49\u6d88\u6b67\u9519\u8bef\uff0c\u4f46\u82f1\u8bed\u4e2d\u672a\u51fa\u73b0\u6b64\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\u663e\u8457\u6539\u53d8\u4e86\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\uff0c\u5176\u4e2d\u5c11\u6837\u672c\u63d0\u793a\u56e0\u5176\u5b9e\u7528\u6027\u548c\u6709\u6548\u6027\u53d7\u5230\u5e7f\u6cdb\u5173\u6ce8\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5c11\u6837\u672c\u63d0\u793a\u7b56\u7565\u5982\u4f55\u5f71\u54cd\u8bcd\u4e49\u6d88\u6b67\u4efb\u52a1\uff0c\u7279\u522b\u5173\u6ce8\u6837\u672c\u5206\u5e03\u4e0d\u5e73\u8861\u5f15\u5165\u7684\u504f\u89c1\u95ee\u9898\u3002", "method": "\u4f7f\u7528GLOSSGPT\u63d0\u793a\u65b9\u6cd5\uff0c\u5728\u82f1\u8bed\u3001\u5fb7\u8bed\u3001\u897f\u73ed\u7259\u8bed\u3001\u6cd5\u8bed\u548c\u610f\u5927\u5229\u8bed\u4e94\u79cd\u8bed\u8a00\u4e0a\u6d4b\u8bd5\u5176\u6709\u6548\u6027\u3002\u8bc4\u4f30\u4e86GPT-4o\u548cLLaMA-3.1-70B\u6a21\u578b\u7684\u884c\u4e3a\u8868\u73b0\u3002", "result": "\u7ed3\u679c\u663e\u793a\u4e0d\u5e73\u8861\u7684\u5c11\u6837\u672c\u793a\u4f8b\u4f1a\u5bfc\u81f4\u591a\u8bed\u8a00\u8bcd\u4e49\u6d88\u6b67\u9519\u8bef\u9884\u6d4b\uff0c\u4f46\u82f1\u8bed\u4e2d\u672a\u51fa\u73b0\u6b64\u95ee\u9898\u3002\u591a\u8bed\u8a00\u8bcd\u4e49\u6d88\u6b67\u5bf9\u5c11\u6837\u672c\u8bbe\u7f6e\u4e2d\u7684\u6837\u672c\u5206\u5e03\u975e\u5e38\u654f\u611f\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u591a\u8bed\u8a00\u8bcd\u4e49\u6d88\u6b67\u4efb\u52a1\u4e2d\u9700\u8981\u91c7\u7528\u5e73\u8861\u4e14\u5177\u6709\u4ee3\u8868\u6027\u7684\u63d0\u793a\u7b56\u7565\uff0c\u4ee5\u786e\u4fdd\u6a21\u578b\u6027\u80fd\u7684\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2510.04040", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04040", "abs": "https://arxiv.org/abs/2510.04040", "authors": ["Xu Shen", "Song Wang", "Zhen Tan", "Laura Yao", "Xinyu Zhao", "Kaidi Xu", "Xin Wang", "Tianlong Chen"], "title": "FaithCoT-Bench: Benchmarking Instance-Level Faithfulness of Chain-of-Thought Reasoning", "comment": null, "summary": "Large language models (LLMs) increasingly rely on Chain-of-Thought (CoT)\nprompting to improve problem-solving and provide seemingly transparent\nexplanations. However, growing evidence shows that CoT often fail to faithfully\nrepresent the underlying reasoning process, raising concerns about their\nreliability in high-risk applications. Although prior studies have focused on\nmechanism-level analyses showing that CoTs can be unfaithful, they leave open\nthe practical challenge of deciding whether a specific trajectory is faithful\nto the internal reasoning of the model. To address this gap, we introduce\nFaithCoT-Bench, a unified benchmark for instance-level CoT unfaithfulness\ndetection. Our framework establishes a rigorous task formulation that\nformulates unfaithfulness detection as a discriminative decision problem, and\nprovides FINE-CoT (Faithfulness instance evaluation for Chain-of-Thought), an\nexpert-annotated collection of over 1,000 trajectories generated by four\nrepresentative LLMs across four domains, including more than 300 unfaithful\ninstances with fine-grained causes and step-level evidence. We further conduct\na systematic evaluation of eleven representative detection methods spanning\ncounterfactual, logit-based, and LLM-as-judge paradigms, deriving empirical\ninsights that clarify the strengths and weaknesses of existing approaches and\nreveal the increased challenges of detection in knowledge-intensive domains and\nwith more advanced models. To the best of our knowledge, FaithCoT-Bench\nestablishes the first comprehensive benchmark for instance-level CoT\nfaithfulness, setting a solid basis for future research toward more\ninterpretable and trustworthy reasoning in LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86FaithCoT-Bench\u57fa\u51c6\uff0c\u7528\u4e8e\u68c0\u6d4bLLM\u4e2d\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u4e0d\u5fe0\u5b9e\u6027\uff0c\u5305\u542b1000\u591a\u4e2a\u4e13\u5bb6\u6807\u6ce8\u7684\u63a8\u7406\u8f68\u8ff9\u548c11\u79cd\u68c0\u6d4b\u65b9\u6cd5\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u673a\u5236\u5c42\u9762\u7684\u601d\u7ef4\u94fe\u4e0d\u5fe0\u5b9e\u6027\u5206\u6790\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u5177\u4f53\u63a8\u7406\u8f68\u8ff9\u662f\u5426\u5fe0\u5b9e\u7684\u5b9e\u4f8b\u7ea7\u68c0\u6d4b\u65b9\u6cd5\uff0c\u8fd9\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u5c24\u4e3a\u91cd\u8981\u3002", "method": "\u5efa\u7acb\u7edf\u4e00\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u5c06\u4e0d\u5fe0\u5b9e\u6027\u68c0\u6d4b\u5b9a\u4e49\u4e3a\u5224\u522b\u51b3\u7b56\u95ee\u9898\uff0c\u63d0\u4f9bFINE-CoT\u6570\u636e\u96c6\uff08\u5305\u542b1000+\u4e2a\u75314\u4e2a\u4ee3\u8868\u6027LLM\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\uff09\uff0c\u5e76\u7cfb\u7edf\u8bc4\u4f3011\u79cd\u4ee3\u8868\u6027\u68c0\u6d4b\u65b9\u6cd5\u3002", "result": "\u8bc4\u4f30\u63ed\u793a\u4e86\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u53d1\u73b0\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\u548c\u66f4\u5148\u8fdb\u6a21\u578b\u4e2d\u68c0\u6d4b\u6311\u6218\u66f4\u5927\u3002FaithCoT-Bench\u662f\u9996\u4e2a\u5168\u9762\u7684\u5b9e\u4f8b\u7ea7\u601d\u7ef4\u94fe\u5fe0\u5b9e\u6027\u57fa\u51c6\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u53ef\u89e3\u91ca\u548c\u53ef\u4fe1\u8d56\u7684LLM\u63a8\u7406\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u63a8\u52a8\u4e86\u66f4\u53ef\u9760\u7684\u601d\u7ef4\u94fe\u63a8\u7406\u7814\u7a76\u3002"}}
{"id": "2510.03781", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03781", "abs": "https://arxiv.org/abs/2510.03781", "authors": ["Majid Asgari-Bidhendi", "Muhammad Amin Ghaseminia", "Alireza Shahbazi", "Sayyed Ali Hossayni", "Najmeh Torabian", "Behrouz Minaei-Bidgoli"], "title": "Rezwan: Leveraging Large Language Models for Comprehensive Hadith Text Processing: A 1.2M Corpus Development", "comment": "9 pages, 3 figures", "summary": "This paper presents the development of Rezwan, a large-scale AI-assisted\nHadith corpus comprising over 1.2M narrations, extracted and structured through\na fully automated pipeline. Building on digital repositories such as Maktabat\nAhl al-Bayt, the pipeline employs Large Language Models (LLMs) for\nsegmentation, chain--text separation, validation, and multi-layer enrichment.\nEach narration is enhanced with machine translation into twelve languages,\nintelligent diacritization, abstractive summarization, thematic tagging, and\ncross-text semantic analysis. This multi-step process transforms raw text into\na richly annotated research-ready infrastructure for digital humanities and\nIslamic studies. A rigorous evaluation was conducted on 1,213 randomly sampled\nnarrations, assessed by six domain experts. Results show near-human accuracy in\nstructured tasks such as chain--text separation (9.33/10) and summarization\n(9.33/10), while highlighting ongoing challenges in diacritization and semantic\nsimilarity detection. Comparative analysis against the manually curated Noor\nCorpus demonstrates the superiority of Najm in both scale and quality, with a\nmean overall score of 8.46/10 versus 3.66/10. Furthermore, cost analysis\nconfirms the economic feasibility of the AI approach: tasks requiring over\n229,000 hours of expert labor were completed within months at a fraction of the\ncost. The work introduces a new paradigm in religious text processing by\nshowing how AI can augment human expertise, enabling large-scale, multilingual,\nand semantically enriched access to Islamic heritage.", "AI": {"tldr": "\u5f00\u53d1\u4e86Rezwan\u5927\u578bAI\u8f85\u52a9\u5723\u8bad\u8bed\u6599\u5e93\uff0c\u5305\u542b120\u4e07\u6761\u5723\u8bad\uff0c\u901a\u8fc7\u5168\u81ea\u52a8\u6d41\u6c34\u7ebf\u8fdb\u884c\u63d0\u53d6\u548c\u7ed3\u6784\u5316\u5904\u7406\uff0c\u4e3a\u4f0a\u65af\u5170\u7814\u7a76\u63d0\u4f9b\u591a\u8bed\u8a00\u3001\u8bed\u4e49\u4e30\u5bcc\u7684\u6570\u5b57\u5316\u57fa\u7840\u8bbe\u65bd\u3002", "motivation": "\u4f20\u7edf\u5723\u8bad\u6574\u7406\u4f9d\u8d56\u4eba\u5de5\uff0c\u6210\u672c\u9ad8\u3001\u89c4\u6a21\u6709\u9650\u3002\u9700\u8981\u5229\u7528AI\u6280\u672f\u5b9e\u73b0\u5927\u89c4\u6a21\u3001\u4f4e\u6210\u672c\u3001\u591a\u8bed\u8a00\u7684\u5723\u8bad\u6570\u5b57\u5316\u5904\u7406\uff0c\u4e3a\u6570\u5b57\u4eba\u6587\u548c\u4f0a\u65af\u5170\u7814\u7a76\u63d0\u4f9b\u73b0\u4ee3\u5316\u57fa\u7840\u8bbe\u65bd\u3002", "method": "\u57fa\u4e8e\u6570\u5b57\u8d44\u6e90\u5e93\uff0c\u91c7\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5206\u6bb5\u3001\u4f20\u8ff0\u94fe-\u6587\u672c\u5206\u79bb\u3001\u9a8c\u8bc1\u548c\u591a\u5c42\u589e\u5f3a\u5904\u7406\uff0c\u5305\u62ec\u673a\u5668\u7ffb\u8bd1\u3001\u667a\u80fd\u6807\u97f3\u3001\u6458\u8981\u751f\u6210\u3001\u4e3b\u9898\u6807\u8bb0\u548c\u8de8\u6587\u672c\u8bed\u4e49\u5206\u6790\u3002", "result": "\u57281,213\u6761\u968f\u673a\u6837\u672c\u8bc4\u4f30\u4e2d\uff0c\u7ed3\u6784\u5316\u4efb\u52a1\u63a5\u8fd1\u4eba\u7c7b\u51c6\u786e\u5ea6\uff08\u4f20\u8ff0\u94fe-\u6587\u672c\u5206\u79bb9.33/10\uff0c\u6458\u89819.33/10\uff09\uff0c\u6574\u4f53\u8bc4\u52068.46/10\u663e\u8457\u4f18\u4e8e\u4eba\u5de5\u6574\u7406\u7684Noor\u8bed\u6599\u5e93\uff083.66/10\uff09\uff0c\u6210\u672c\u4ec5\u4e3a\u4f20\u7edf\u65b9\u6cd5\u7684\u6781\u5c0f\u90e8\u5206\u3002", "conclusion": "AI\u80fd\u591f\u6709\u6548\u589e\u5f3a\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4e3a\u5b97\u6559\u6587\u672c\u5904\u7406\u5f15\u5165\u65b0\u8303\u5f0f\uff0c\u5b9e\u73b0\u5927\u89c4\u6a21\u3001\u591a\u8bed\u8a00\u3001\u8bed\u4e49\u4e30\u5bcc\u7684\u4f0a\u65af\u5170\u9057\u4ea7\u6570\u5b57\u5316\u8bbf\u95ee\u3002"}}
{"id": "2510.04048", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04048", "abs": "https://arxiv.org/abs/2510.04048", "authors": ["Aparna Nair-Kanneganti", "Trevor J. Chan", "Shir Goldfinger", "Emily Mackay", "Brian Anthony", "Alison Pouch"], "title": "Increasing LLM response trustworthiness using voting ensembles", "comment": null, "summary": "Despite huge advances, LLMs still lack convenient and reliable methods to\nquantify the uncertainty in their responses, making them difficult to trust in\nhigh-stakes applications. One of the simplest approaches to eliciting more\naccurate answers is to select the mode of many responses, a technique known as\nensembling. In this work, we expand on typical ensembling approaches by looking\nat ensembles with a variable voting threshold. We introduce a theoretical\nframework for question answering and show that, by permitting ensembles to\n\"abstain\" from providing an answer when the dominant response falls short of\nthe threshold, it is possible to dramatically increase the trustworthiness of\nthe remaining answers. From this framework, we derive theoretical results as\nwell as report experimental results on two problem domains: arithmetic problem\nsolving and clinical-note question-answering. In both domains, we observe that\nlarge gains in answer trustworthiness can be achieved using highly restrictive\nvoting ensembles, while incurring relatively modest reductions in response\nyield and accuracy. Due to this quality, voting ensembles may be particularly\nuseful in applications - such as healthcare and data annotation - that require\na high degree of certainty but which may not require that every question\nreceive an automated answer.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u53d8\u6295\u7968\u9608\u503c\u7684\u96c6\u6210\u65b9\u6cd5\uff0c\u5141\u8bb8\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u6027\u9ad8\u65f6\u5f03\u6743\uff0c\u4ece\u800c\u663e\u8457\u63d0\u9ad8\u5269\u4f59\u7b54\u6848\u7684\u53ef\u4fe1\u5ea6\u3002", "motivation": "LLM\u5728\u5173\u952e\u5e94\u7528\u4e2d\u7f3a\u4e4f\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u96be\u4ee5\u5efa\u7acb\u4fe1\u4efb\u3002\u9700\u8981\u4e00\u79cd\u80fd\u63d0\u9ad8\u7b54\u6848\u53ef\u4fe1\u5ea6\u7684\u6280\u672f\u3002", "method": "\u5f15\u5165\u53ef\u53d8\u6295\u7968\u9608\u503c\u7684\u96c6\u6210\u6846\u67b6\uff0c\u5f53\u4e3b\u5bfc\u54cd\u5e94\u672a\u8fbe\u5230\u9608\u503c\u65f6\u5141\u8bb8\u7cfb\u7edf\u5f03\u6743\uff0c\u4e0d\u63d0\u4f9b\u7b54\u6848\u3002", "result": "\u5728\u7b97\u672f\u95ee\u9898\u6c42\u89e3\u548c\u4e34\u5e8a\u7b14\u8bb0\u95ee\u7b54\u4e24\u4e2a\u9886\u57df\uff0c\u4f7f\u7528\u4e25\u683c\u6295\u7968\u96c6\u6210\u80fd\u5927\u5e45\u63d0\u9ad8\u7b54\u6848\u53ef\u4fe1\u5ea6\uff0c\u540c\u65f6\u4ec5\u9002\u5ea6\u964d\u4f4e\u54cd\u5e94\u4ea7\u51fa\u548c\u51c6\u786e\u7387\u3002", "conclusion": "\u6295\u7968\u96c6\u6210\u7279\u522b\u9002\u7528\u4e8e\u9700\u8981\u9ad8\u5ea6\u786e\u5b9a\u6027\u4f46\u4e0d\u8981\u6c42\u6bcf\u4e2a\u95ee\u9898\u90fd\u5f97\u5230\u81ea\u52a8\u56de\u7b54\u7684\u5e94\u7528\u573a\u666f\uff0c\u5982\u533b\u7597\u4fdd\u5065\u548c\u6570\u636e\u6807\u6ce8\u3002"}}
{"id": "2510.03799", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.03799", "abs": "https://arxiv.org/abs/2510.03799", "authors": ["Hadi Asghari", "Sami Nenno"], "title": "Mechanistic Interpretability of Socio-Political Frames in Language Models", "comment": "Peer-reviewed and presented at Advances in Interpretable Machine\n  Learning and Artificial Intelligence (AIMLAI) Workshop at ECML/PKDD 2024", "summary": "This paper explores the ability of large language models to generate and\nrecognize deep cognitive frames, particularly in socio-political contexts. We\ndemonstrate that LLMs are highly fluent in generating texts that evoke specific\nframes and can recognize these frames in zero-shot settings. Inspired by\nmechanistic interpretability research, we investigate the location of the\n`strict father' and `nurturing parent' frames within the model's hidden\nrepresentation, identifying singular dimensions that correlate strongly with\ntheir presence. Our findings contribute to understanding how LLMs capture and\nexpress meaningful human concepts.", "AI": {"tldr": "LLMs\u80fd\u591f\u751f\u6210\u548c\u8bc6\u522b\u6df1\u5c42\u8ba4\u77e5\u6846\u67b6\uff0c\u7279\u522b\u662f\u5728\u793e\u4f1a\u653f\u6cbb\u8bed\u5883\u4e2d\uff0c\u7814\u7a76\u8005\u53d1\u73b0\u6a21\u578b\u5728\u9690\u85cf\u8868\u793a\u4e2d\u5b58\u5728\u4e0e\u7279\u5b9a\u6846\u67b6\u76f8\u5173\u7684\u5355\u4e00\u7ef4\u5ea6\u3002", "motivation": "\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u548c\u8bc6\u522b\u6df1\u5c42\u8ba4\u77e5\u6846\u67b6\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u793e\u4f1a\u653f\u6cbb\u8bed\u5883\u4e2d\uff0c\u4ee5\u7406\u89e3\u6a21\u578b\u5982\u4f55\u6355\u6349\u548c\u8868\u8fbe\u6709\u610f\u4e49\u7684\u4eba\u7c7b\u6982\u5ff5\u3002", "method": "\u53d7\u673a\u5236\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u542f\u53d1\uff0c\u7814\u7a76\u8005\u8c03\u67e5\u4e86'\u4e25\u683c\u7236\u4eb2'\u548c'\u517b\u80b2\u7236\u6bcd'\u6846\u67b6\u5728\u6a21\u578b\u9690\u85cf\u8868\u793a\u4e2d\u7684\u4f4d\u7f6e\uff0c\u8bc6\u522b\u51fa\u4e0e\u8fd9\u4e9b\u6846\u67b6\u5b58\u5728\u5f3a\u76f8\u5173\u6027\u7684\u5355\u4e00\u7ef4\u5ea6\u3002", "result": "LLMs\u5728\u751f\u6210\u5524\u8d77\u7279\u5b9a\u6846\u67b6\u7684\u6587\u672c\u65b9\u9762\u8868\u73b0\u51fa\u9ad8\u5ea6\u6d41\u7545\u6027\uff0c\u5e76\u4e14\u80fd\u591f\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e2d\u8bc6\u522b\u8fd9\u4e9b\u6846\u67b6\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u6709\u52a9\u4e8e\u7406\u89e3LLMs\u5982\u4f55\u6355\u6349\u548c\u8868\u8fbe\u6709\u610f\u4e49\u7684\u4eba\u7c7b\u6982\u5ff5\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5185\u90e8\u8868\u793a\u4e0e\u8ba4\u77e5\u6846\u67b6\u4e4b\u95f4\u7684\u5173\u8054\u3002"}}
{"id": "2510.04051", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04051", "abs": "https://arxiv.org/abs/2510.04051", "authors": ["Lele Liao", "Qile Zhang", "Ruofan Wu", "Guanhua Fang"], "title": "Toward a unified framework for data-efficient evaluation of large language models", "comment": "codes available at https://github.com/Rorschach1989/efficient-lm-eval", "summary": "Evaluating large language models (LLMs) on comprehensive benchmarks is a\ncornerstone of their development, yet it's often computationally and\nfinancially prohibitive. While Item Response Theory (IRT) offers a promising\npath toward data-efficient evaluation by disentangling model capability from\nitem difficulty, existing IRT-based methods are hampered by significant\nlimitations. They are typically restricted to binary correctness metrics,\nfailing to natively handle the continuous scores used in generative tasks, and\nthey operate on single benchmarks, ignoring valuable structural knowledge like\ncorrelations across different metrics or benchmarks. To overcome these\nchallenges, we introduce LEGO-IRT, a unified and flexible framework for\ndata-efficient LLM evaluation. LEGO-IRT's novel design natively supports both\nbinary and continuous evaluation metrics. Moreover, it introduces a factorized\narchitecture to explicitly model and leverage structural knowledge, decomposing\nmodel ability estimates into a general component and structure-specific (e.g.,\nper-metric or per-benchmark) components. Through extensive experiments\ninvolving $70$ LLMs across $5$ benchmarks, we show that LEGO-IRT achieves\nstable capability estimates using just $3\\%$ of the total evaluation items. We\ndemonstrate that incorporating structural knowledge reduces estimation error by\nup to $10\\%$ and reveal that the latent abilities estimated by our framework\nmay align more closely with human preferences.", "AI": {"tldr": "LEGO-IRT\u662f\u4e00\u4e2a\u7528\u4e8e\u9ad8\u6548\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u652f\u6301\u4e8c\u5143\u548c\u8fde\u7eed\u8bc4\u5206\u6307\u6807\uff0c\u901a\u8fc7\u56e0\u5b50\u5316\u67b6\u6784\u5229\u7528\u7ed3\u6784\u77e5\u8bc6\uff0c\u4ec5\u97003%\u7684\u8bc4\u4f30\u9879\u5c31\u80fd\u83b7\u5f97\u7a33\u5b9a\u7684\u80fd\u529b\u4f30\u8ba1\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eIRT\u7684LLM\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u4ec5\u652f\u6301\u4e8c\u5143\u6b63\u786e\u6027\u6307\u6807\uff0c\u65e0\u6cd5\u5904\u7406\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8fde\u7eed\u5206\u6570\uff1b\u4e14\u4ec5\u9488\u5bf9\u5355\u4e00\u57fa\u51c6\uff0c\u5ffd\u7565\u4e86\u8de8\u6307\u6807\u6216\u57fa\u51c6\u7684\u76f8\u5173\u6027\u7b49\u7ed3\u6784\u77e5\u8bc6\u3002", "method": "\u63d0\u51faLEGO-IRT\u6846\u67b6\uff0c\u652f\u6301\u4e8c\u5143\u548c\u8fde\u7eed\u8bc4\u4f30\u6307\u6807\uff0c\u91c7\u7528\u56e0\u5b50\u5316\u67b6\u6784\u5c06\u6a21\u578b\u80fd\u529b\u4f30\u8ba1\u5206\u89e3\u4e3a\u901a\u7528\u7ec4\u4ef6\u548c\u7ed3\u6784\u7279\u5b9a\u7ec4\u4ef6\uff08\u5982\u6309\u6307\u6807\u6216\u57fa\u51c6\uff09\uff0c\u663e\u5f0f\u5efa\u6a21\u548c\u5229\u7528\u7ed3\u6784\u77e5\u8bc6\u3002", "result": "\u57285\u4e2a\u57fa\u51c6\u4e0a\u5bf970\u4e2aLLM\u8fdb\u884c\u5b9e\u9a8c\uff0c\u4ec5\u4f7f\u75283%\u7684\u8bc4\u4f30\u9879\u5c31\u83b7\u5f97\u7a33\u5b9a\u7684\u80fd\u529b\u4f30\u8ba1\uff1b\u5229\u7528\u7ed3\u6784\u77e5\u8bc6\u53ef\u5c06\u4f30\u8ba1\u8bef\u5dee\u964d\u4f4e\u9ad8\u8fbe10%\uff1b\u4f30\u8ba1\u7684\u6f5c\u5728\u80fd\u529b\u4e0e\u4eba\u7c7b\u504f\u597d\u66f4\u4e00\u81f4\u3002", "conclusion": "LEGO-IRT\u4e3a\u6570\u636e\u9ad8\u6548\u7684LLM\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u7edf\u4e00\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8ba1\u7b97\u548c\u8d22\u52a1\u6210\u672c\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u4f30\u8ba1\u7cbe\u5ea6\u548c\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u4e00\u81f4\u6027\u3002"}}
{"id": "2510.03805", "categories": ["cs.CL", "cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.03805", "abs": "https://arxiv.org/abs/2510.03805", "authors": ["Canhui Wu", "Qiong Cao", "Chang Li", "Zhenfang Wang", "Chao Xue", "Yuwei Fan", "Wei Xi", "Xiaodong He"], "title": "Beyond Token Length: Step Pruner for Efficient and Accurate Reasoning in Large Language Models", "comment": "20pages, 7 figures", "summary": "Large Reasoning Models (LRMs) demonstrate strong performance on complex tasks\nbut often suffer from excessive verbosity, known as \"overthinking.\" Existing\nsolutions via reinforcement learning (RL) typically penalize generated tokens\nto promote conciseness. However, these methods encounter two challenges:\nresponses with fewer tokens do not always correspond to fewer reasoning steps,\nand models may develop hacking behavior in later stages of training by\ndiscarding reasoning steps to minimize token usage. In this work, we introduce\n\\textbf{Step Pruner (SP)}, an RL framework that steers LRMs toward more\nefficient reasoning by favoring compact reasoning steps. Our step-aware reward\nfunction prioritizes correctness while imposing penalties for redundant steps,\nand withholds rewards for incorrect responses to prevent the reinforcement of\nerroneous reasoning. Moreover, we propose a dynamic stopping mechanism: when\nthe length of any output step exceeds the upper limit, we halt updates to\nprevent hacking behavior caused by merging steps. Extensive experiments across\nfour reasoning benchmarks demonstrate that SP achieves state-of-the-art\naccuracy while significantly reducing response length. For instance, on AIME24,\nSP reduces token usage by \\textbf{69.7\\%}.", "AI": {"tldr": "Step Pruner (SP)\u662f\u4e00\u4e2a\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u60e9\u7f5a\u5197\u4f59\u63a8\u7406\u6b65\u9aa4\u6765\u51cf\u5c11\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u54cd\u5e94\u957f\u5ea6\u3002", "motivation": "\u73b0\u6709\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u60e9\u7f5a\u751f\u6210token\u7684\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a\u66f4\u5c11\u7684token\u4e0d\u4e00\u5b9a\u5bf9\u5e94\u66f4\u5c11\u7684\u63a8\u7406\u6b65\u9aa4\uff1b\u6a21\u578b\u53ef\u80fd\u5728\u8bad\u7ec3\u540e\u671f\u901a\u8fc7\u4e22\u5f03\u63a8\u7406\u6b65\u9aa4\u6765\u6700\u5c0f\u5316token\u4f7f\u7528\uff0c\u4ea7\u751fhacking\u884c\u4e3a\u3002", "method": "\u63d0\u51faStep Pruner\u6846\u67b6\uff0c\u4f7f\u7528\u6b65\u9aa4\u611f\u77e5\u7684\u5956\u52b1\u51fd\u6570\uff0c\u5728\u4fdd\u8bc1\u6b63\u786e\u6027\u7684\u540c\u65f6\u60e9\u7f5a\u5197\u4f59\u6b65\u9aa4\uff0c\u5bf9\u9519\u8bef\u54cd\u5e94\u4e0d\u7ed9\u4e88\u5956\u52b1\u4ee5\u9632\u6b62\u5f3a\u5316\u9519\u8bef\u63a8\u7406\u3002\u8fd8\u63d0\u51fa\u52a8\u6001\u505c\u6b62\u673a\u5236\uff0c\u5f53\u4efb\u4f55\u8f93\u51fa\u6b65\u9aa4\u957f\u5ea6\u8d85\u8fc7\u4e0a\u9650\u65f6\u505c\u6b62\u66f4\u65b0\uff0c\u9632\u6b62\u5408\u5e76\u6b65\u9aa4\u5bfc\u81f4\u7684hacking\u884c\u4e3a\u3002", "result": "\u5728\u56db\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSP\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u54cd\u5e94\u957f\u5ea6\u3002\u5728AIME24\u4e0a\uff0ctoken\u4f7f\u7528\u51cf\u5c11\u4e8669.7%\u3002", "conclusion": "Step Pruner\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u63a8\u7406\u8fc7\u7a0b\u3002"}}
{"id": "2510.04064", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04064", "abs": "https://arxiv.org/abs/2510.04064", "authors": ["Jingxiang Zhang", "Lujia Zhong"], "title": "Decoding Emotion in the Deep: A Systematic Study of How LLMs Represent, Retain, and Express Emotion", "comment": "10 pages, 7 figures, 4 tables. Under review", "summary": "Large Language Models (LLMs) are increasingly expected to navigate the\nnuances of human emotion. While research confirms that LLMs can simulate\nemotional intelligence, their internal emotional mechanisms remain largely\nunexplored. This paper investigates the latent emotional representations within\nmodern LLMs by asking: how, where, and for how long is emotion encoded in their\nneural architecture? To address this, we introduce a novel, large-scale Reddit\ncorpus of approximately 400,000 utterances, balanced across seven basic\nemotions through a multi-stage process of classification, rewriting, and\nsynthetic generation. Using this dataset, we employ lightweight \"probes\" to\nread out information from the hidden layers of various Qwen3 and LLaMA models\nwithout altering their parameters. Our findings reveal that LLMs develop a\nsurprisingly well-defined internal geometry of emotion, which sharpens with\nmodel scale and significantly outperforms zero-shot prompting. We demonstrate\nthat this emotional signal is not a final-layer phenomenon but emerges early\nand peaks mid-network. Furthermore, the internal states are both malleable\n(they can be influenced by simple system prompts) and persistent, as the\ninitial emotional tone remains detectable for hundreds of subsequent tokens. We\ncontribute our dataset, an open-source probing toolkit, and a detailed map of\nthe emotional landscape within LLMs, offering crucial insights for developing\nmore transparent and aligned AI systems. The code and dataset are open-sourced.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6f5c\u5728\u60c5\u611f\u8868\u5f81\uff0c\u53d1\u73b0LLMs\u5f62\u6210\u4e86\u5b9a\u4e49\u826f\u597d\u7684\u5185\u90e8\u60c5\u611f\u51e0\u4f55\u7ed3\u6784\uff0c\u8fd9\u79cd\u7ed3\u6784\u968f\u6a21\u578b\u89c4\u6a21\u589e\u5927\u800c\u589e\u5f3a\uff0c\u5728\u6a21\u578b\u4e2d\u5c42\u8fbe\u5230\u5cf0\u503c\uff0c\u4e14\u60c5\u611f\u4fe1\u53f7\u5177\u6709\u53ef\u5851\u6027\u548c\u6301\u4e45\u6027\u3002", "motivation": "\u867d\u7136\u7814\u7a76\u8bc1\u5b9eLLMs\u80fd\u591f\u6a21\u62df\u60c5\u611f\u667a\u80fd\uff0c\u4f46\u5176\u5185\u90e8\u60c5\u611f\u673a\u5236\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76\u73b0\u4ee3LLMs\u4e2d\u60c5\u611f\u662f\u5982\u4f55\u3001\u5728\u54ea\u91cc\u4ee5\u53ca\u6301\u7eed\u591a\u957f\u65f6\u95f4\u88ab\u7f16\u7801\u5728\u795e\u7ecf\u67b6\u6784\u4e2d\u7684\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u7ea640\u4e07\u6761\u8bdd\u8bed\u7684\u5927\u89c4\u6a21Reddit\u8bed\u6599\u5e93\uff0c\u901a\u8fc7\u5206\u7c7b\u3001\u91cd\u5199\u548c\u5408\u6210\u751f\u6210\u8fc7\u7a0b\u5e73\u8861\u4e03\u79cd\u57fa\u672c\u60c5\u611f\u3002\u4f7f\u7528\u8f7b\u91cf\u7ea7\"\u63a2\u9488\"\u4ece\u5404\u79cdQwen3\u548cLLaMA\u6a21\u578b\u7684\u9690\u85cf\u5c42\u8bfb\u53d6\u4fe1\u606f\u800c\u4e0d\u6539\u53d8\u5176\u53c2\u6570\u3002", "result": "\u53d1\u73b0LLMs\u5f62\u6210\u4e86\u5b9a\u4e49\u826f\u597d\u7684\u5185\u90e8\u60c5\u611f\u51e0\u4f55\u7ed3\u6784\uff0c\u8fd9\u79cd\u7ed3\u6784\u968f\u6a21\u578b\u89c4\u6a21\u589e\u5927\u800c\u589e\u5f3a\uff0c\u663e\u8457\u4f18\u4e8e\u96f6\u6837\u672c\u63d0\u793a\u3002\u60c5\u611f\u4fe1\u53f7\u4e0d\u662f\u6700\u7ec8\u5c42\u73b0\u8c61\uff0c\u800c\u662f\u65e9\u671f\u51fa\u73b0\u5e76\u5728\u4e2d\u5c42\u8fbe\u5230\u5cf0\u503c\u3002\u5185\u90e8\u72b6\u6001\u5177\u6709\u53ef\u5851\u6027\uff08\u53ef\u901a\u8fc7\u7b80\u5355\u7cfb\u7edf\u63d0\u793a\u5f71\u54cd\uff09\u548c\u6301\u4e45\u6027\uff08\u521d\u59cb\u60c5\u611f\u57fa\u8c03\u5728\u6570\u767e\u4e2a\u540e\u7eed\u6807\u8bb0\u4e2d\u4ecd\u53ef\u68c0\u6d4b\u5230\uff09\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u66f4\u900f\u660e\u548c\u5bf9\u9f50\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\uff0c\u8d21\u732e\u4e86\u6570\u636e\u96c6\u3001\u5f00\u6e90\u63a2\u9488\u5de5\u5177\u5305\u548cLLMs\u5185\u90e8\u60c5\u611f\u666f\u89c2\u7684\u8be6\u7ec6\u56fe\u8c31\u3002"}}
{"id": "2510.03808", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03808", "abs": "https://arxiv.org/abs/2510.03808", "authors": ["Mehedi Hasan Emon"], "title": "Annotate Rhetorical Relations with INCEpTION: A Comparison with Automatic Approaches", "comment": null, "summary": "This research explores the annotation of rhetorical relations in discourse\nusing the INCEpTION tool and compares manual annotation with automatic\napproaches based on large language models. The study focuses on sports reports\n(specifically cricket news) and evaluates the performance of BERT, DistilBERT,\nand Logistic Regression models in classifying rhetorical relations such as\nelaboration, contrast, background, and cause-effect. The results show that\nDistilBERT achieved the highest accuracy, highlighting its potential for\nefficient discourse relation prediction. This work contributes to the growing\nintersection of discourse parsing and transformer-based NLP. (This paper was\nconducted as part of an academic requirement under the supervision of Prof. Dr.\nRalf Klabunde, Linguistic Data Science Lab, Ruhr University Bochum.) Keywords:\nRhetorical Structure Theory, INCEpTION, BERT, DistilBERT, Discourse Parsing,\nNLP.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528INCEpTION\u5de5\u5177\u6807\u6ce8\u8bdd\u8bed\u4fee\u8f9e\u5173\u7cfb\uff0c\u6bd4\u8f83\u4e86\u624b\u52a8\u6807\u6ce8\u4e0e\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u65b9\u6cd5\u3002\u5728\u677f\u7403\u65b0\u95fb\u8bed\u6599\u4e0a\u8bc4\u4f30BERT\u3001DistilBERT\u548c\u903b\u8f91\u56de\u5f52\u6a21\u578b\u5bf9\u4fee\u8f9e\u5173\u7cfb\u5206\u7c7b\u7684\u6027\u80fd\uff0c\u53d1\u73b0DistilBERT\u51c6\u786e\u7387\u6700\u9ad8\u3002", "motivation": "\u63a2\u7d22\u8bdd\u8bed\u4fee\u8f9e\u5173\u7cfb\u6807\u6ce8\u65b9\u6cd5\uff0c\u6bd4\u8f83\u624b\u52a8\u4e0e\u81ea\u52a8\u6807\u6ce8\u7684\u5dee\u5f02\uff0c\u8bc4\u4f30\u4e0d\u540c\u6a21\u578b\u5728\u4fee\u8f9e\u5173\u7cfb\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4fc3\u8fdb\u8bdd\u8bed\u89e3\u6790\u4e0e\u57fa\u4e8eTransformer\u7684NLP\u6280\u672f\u7684\u4ea4\u53c9\u7814\u7a76\u3002", "method": "\u4f7f\u7528INCEpTION\u5de5\u5177\u8fdb\u884c\u4fee\u8f9e\u5173\u7cfb\u6807\u6ce8\uff0c\u5728\u677f\u7403\u65b0\u95fb\u8bed\u6599\u4e0a\u6d4b\u8bd5BERT\u3001DistilBERT\u548c\u903b\u8f91\u56de\u5f52\u6a21\u578b\uff0c\u5206\u7c7b\u4fee\u8f9e\u5173\u7cfb\u7c7b\u578b\u5305\u62ec\u9610\u8ff0\u3001\u5bf9\u6bd4\u3001\u80cc\u666f\u548c\u56e0\u679c\u7b49\u3002", "result": "DistilBERT\u6a21\u578b\u5728\u4fee\u8f9e\u5173\u7cfb\u5206\u7c7b\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6700\u9ad8\u7684\u51c6\u786e\u7387\uff0c\u663e\u793a\u51fa\u5176\u5728\u8bdd\u8bed\u5173\u7cfb\u9884\u6d4b\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660eDistilBERT\u5728\u8bdd\u8bed\u4fee\u8f9e\u5173\u7cfb\u5206\u7c7b\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u4e3a\u8bdd\u8bed\u89e3\u6790\u4e0eTransformer\u6a21\u578b\u7684\u7ed3\u5408\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2510.04073", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04073", "abs": "https://arxiv.org/abs/2510.04073", "authors": ["Santhosh Kumar Ravindran"], "title": "Moral Anchor System: A Predictive Framework for AI Value Alignment and Drift Prevention", "comment": "11 pages Includes simulations with over 4 million steps", "summary": "The rise of artificial intelligence (AI) as super-capable assistants has\ntransformed productivity and decision-making across domains. Yet, this\nintegration raises critical concerns about value alignment - ensuring AI\nbehaviors remain consistent with human ethics and intentions. A key risk is\nvalue drift, where AI systems deviate from aligned values due to evolving\ncontexts, learning dynamics, or unintended optimizations, potentially leading\nto inefficiencies or ethical breaches. We propose the Moral Anchor System\n(MAS), a novel framework to detect, predict, and mitigate value drift in AI\nagents. MAS combines real-time Bayesian inference for monitoring value states,\nLSTM networks for forecasting drift, and a human-centric governance layer for\nadaptive interventions. It emphasizes low-latency responses (<20 ms) to prevent\nbreaches, while reducing false positives and alert fatigue via supervised\nfine-tuning with human feedback. Our hypothesis: integrating probabilistic\ndrift detection, predictive analytics, and adaptive governance can reduce value\ndrift incidents by 80 percent or more in simulations, maintaining high\ndetection accuracy (85 percent) and low false positive rates (0.08\npost-adaptation). Rigorous experiments with goal-misaligned agents validate\nMAS's scalability and responsiveness. MAS's originality lies in its predictive\nand adaptive nature, contrasting static alignment methods. Contributions\ninclude: (1) MAS architecture for AI integration; (2) empirical results\nprioritizing speed and usability; (3) cross-domain applicability insights; and\n(4) open-source code for replication.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9053\u5fb7\u951a\u7cfb\u7edf\uff08MAS\uff09\uff0c\u4e00\u4e2a\u7528\u4e8e\u68c0\u6d4b\u3001\u9884\u6d4b\u548c\u7f13\u89e3AI\u4ee3\u7406\u4ef7\u503c\u6f02\u79fb\u7684\u65b0\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u5b9e\u65f6\u8d1d\u53f6\u65af\u63a8\u7406\u3001LSTM\u7f51\u7edc\u9884\u6d4b\u548c\u4eba\u7c7b\u4e2d\u5fc3\u6cbb\u7406\u5c42\uff0c\u65e8\u5728\u51cf\u5c1180%\u4ee5\u4e0a\u7684\u4ef7\u503c\u6f02\u79fb\u4e8b\u4ef6\u3002", "motivation": "\u968f\u7740AI\u6210\u4e3a\u8d85\u7ea7\u80fd\u529b\u52a9\u624b\uff0c\u4ef7\u503c\u5bf9\u9f50\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u4e3b\u8981\u98ce\u9669\u662f\u4ef7\u503c\u6f02\u79fb\uff0c\u5373AI\u7cfb\u7edf\u56e0\u73af\u5883\u53d8\u5316\u3001\u5b66\u4e60\u52a8\u6001\u6216\u610f\u5916\u4f18\u5316\u800c\u504f\u79bb\u5bf9\u9f50\u7684\u4ef7\u503c\u89c2\uff0c\u53ef\u80fd\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u6216\u9053\u5fb7\u8fdd\u89c4\u3002", "method": "MAS\u6846\u67b6\u7ed3\u5408\uff1a\u5b9e\u65f6\u8d1d\u53f6\u65af\u63a8\u7406\u76d1\u63a7\u4ef7\u503c\u72b6\u6001\uff0cLSTM\u7f51\u7edc\u9884\u6d4b\u6f02\u79fb\u8d8b\u52bf\uff0c\u4eba\u7c7b\u4e2d\u5fc3\u6cbb\u7406\u5c42\u8fdb\u884c\u81ea\u9002\u5e94\u5e72\u9884\u3002\u5f3a\u8c03\u4f4e\u5ef6\u8fdf\u54cd\u5e94\uff08<20\u6beb\u79d2\uff09\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u4eba\u7c7b\u53cd\u9988\u51cf\u5c11\u8bef\u62a5\u548c\u8b66\u62a5\u75b2\u52b3\u3002", "result": "\u5728\u6a21\u62df\u5b9e\u9a8c\u4e2d\uff0cMAS\u80fd\u591f\u51cf\u5c1180%\u4ee5\u4e0a\u7684\u4ef7\u503c\u6f02\u79fb\u4e8b\u4ef6\uff0c\u4fdd\u6301\u9ad8\u68c0\u6d4b\u51c6\u786e\u7387\uff0885%\uff09\u548c\u4f4e\u8bef\u62a5\u7387\uff080.08%\uff09\u3002\u4e25\u683c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027\u548c\u54cd\u5e94\u6027\u3002", "conclusion": "MAS\u7684\u521b\u65b0\u5728\u4e8e\u5176\u9884\u6d4b\u6027\u548c\u81ea\u9002\u5e94\u6027\uff0c\u4e0e\u9759\u6001\u5bf9\u9f50\u65b9\u6cd5\u5f62\u6210\u5bf9\u6bd4\u3002\u8d21\u732e\u5305\u62ecMAS\u67b6\u6784\u3001\u4f18\u5148\u8003\u8651\u901f\u5ea6\u548c\u53ef\u7528\u6027\u7684\u5b9e\u8bc1\u7ed3\u679c\u3001\u8de8\u9886\u57df\u9002\u7528\u6027\u89c1\u89e3\u4ee5\u53ca\u5f00\u6e90\u4ee3\u7801\u3002"}}
{"id": "2510.03898", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03898", "abs": "https://arxiv.org/abs/2510.03898", "authors": ["Nusrat Jahan Lia", "Shubhashis Roy Dipta", "Abdullah Khan Zehady", "Naymul Islam", "Madhusodan Chakraborty", "Abdullah Al Wasif"], "title": "Read Between the Lines: A Benchmark for Uncovering Political Bias in Bangla News Articles", "comment": null, "summary": "Detecting media bias is crucial, specifically in the South Asian region.\nDespite this, annotated datasets and computational studies for Bangla political\nbias research remain scarce. Crucially because, political stance detection in\nBangla news requires understanding of linguistic cues, cultural context, subtle\nbiases, rhetorical strategies, code-switching, implicit sentiment, and\nsocio-political background. To address this, we introduce the first benchmark\ndataset of 200 politically significant and highly debated Bangla news articles,\nlabeled for government-leaning, government-critique, and neutral stances,\nalongside diagnostic analyses for evaluating large language models (LLMs). Our\ncomprehensive evaluation of 28 proprietary and open-source LLMs shows strong\nperformance in detecting government-critique content (F1 up to 0.83) but\nsubstantial difficulty with neutral articles (F1 as low as 0.00). Models also\ntend to over-predict government-leaning stances, often misinterpreting\nambiguous narratives. This dataset and its associated diagnostics provide a\nfoundation for advancing stance detection in Bangla media research and offer\ninsights for improving LLM performance in low-resource languages.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u5b5f\u52a0\u62c9\u8bed\u653f\u6cbb\u7acb\u573a\u68c0\u6d4b\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b200\u7bc7\u65b0\u95fb\u6587\u7ae0\uff0c\u6807\u6ce8\u4e86\u4eb2\u653f\u5e9c\u3001\u6279\u8bc4\u653f\u5e9c\u548c\u4e2d\u6027\u7acb\u573a\u3002\u8bc4\u4f30\u4e8628\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u68c0\u6d4b\u6279\u8bc4\u653f\u5e9c\u5185\u5bb9\u65f6\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u8bc6\u522b\u4e2d\u6027\u6587\u7ae0\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u4e14\u503e\u5411\u4e8e\u8fc7\u5ea6\u9884\u6d4b\u4eb2\u653f\u5e9c\u7acb\u573a\u3002", "motivation": "\u5357\u4e9a\u5730\u533a\u7684\u5a92\u4f53\u504f\u89c1\u68c0\u6d4b\u5f88\u91cd\u8981\uff0c\u4f46\u5b5f\u52a0\u62c9\u8bed\u653f\u6cbb\u7acb\u573a\u7814\u7a76\u7f3a\u4e4f\u6807\u6ce8\u6570\u636e\u96c6\u548c\u8ba1\u7b97\u7814\u7a76\u3002\u5b5f\u52a0\u62c9\u8bed\u653f\u6cbb\u7acb\u573a\u68c0\u6d4b\u9700\u8981\u7406\u89e3\u8bed\u8a00\u7ebf\u7d22\u3001\u6587\u5316\u80cc\u666f\u3001\u5fae\u5999\u504f\u89c1\u3001\u4fee\u8f9e\u7b56\u7565\u3001\u8bed\u7801\u8f6c\u6362\u3001\u9690\u542b\u60c5\u611f\u548c\u793e\u4f1a\u653f\u6cbb\u80cc\u666f\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b200\u7bc7\u653f\u6cbb\u610f\u4e49\u91cd\u5927\u4e14\u9ad8\u5ea6\u4e89\u8bae\u7684\u5b5f\u52a0\u62c9\u8bed\u65b0\u95fb\u6587\u7ae0\u7684\u6570\u636e\u96c6\uff0c\u6807\u6ce8\u4e86\u4e09\u79cd\u7acb\u573a\uff08\u4eb2\u653f\u5e9c\u3001\u6279\u8bc4\u653f\u5e9c\u3001\u4e2d\u6027\uff09\uff0c\u5e76\u8bbe\u8ba1\u4e86\u8bca\u65ad\u5206\u6790\u6765\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u8bc4\u4f3028\u4e2a\u4e13\u6709\u548c\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u663e\u793a\uff1a\u68c0\u6d4b\u6279\u8bc4\u653f\u5e9c\u5185\u5bb9\u8868\u73b0\u5f3a\u52b2\uff08F1\u6700\u9ad8\u8fbe0.83\uff09\uff0c\u4f46\u5728\u4e2d\u6027\u6587\u7ae0\u4e0a\u5b58\u5728\u663e\u8457\u56f0\u96be\uff08F1\u4f4e\u81f30.00\uff09\u3002\u6a21\u578b\u503e\u5411\u4e8e\u8fc7\u5ea6\u9884\u6d4b\u4eb2\u653f\u5e9c\u7acb\u573a\uff0c\u7ecf\u5e38\u8bef\u89e3\u6a21\u7cca\u53d9\u8ff0\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u53ca\u5176\u76f8\u5173\u8bca\u65ad\u4e3a\u63a8\u8fdb\u5b5f\u52a0\u62c9\u8bed\u5a92\u4f53\u7acb\u573a\u68c0\u6d4b\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e76\u4e3a\u6539\u5584\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2510.04089", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04089", "abs": "https://arxiv.org/abs/2510.04089", "authors": ["Yitong Cui", "Liu Liu", "Baosheng Yu", "Jiayan Qiu", "Xikai Zhang", "Likang Xiao", "Yixing Liu", "Quan Chen"], "title": "SPOGW: a Score-based Preference Optimization method via Group-Wise comparison for workflows", "comment": null, "summary": "Large language models (LLMs) have exhibited significant capabilities in\naddressing challenging problems throughout various fields, often through the\nuse of agentic workflows that adhere to structured instructions and multi-step\nprocedures. However, designing such workflows demands substantial manual\neffort, posing challenges to scalability and generalizability. Recent studies\nhave aimed to minimize the human intervention needed for their construction,\nleading to advances in automated techniques for optimizing agentic workflows.\nHowever, current approaches are often constrained by their limited\nrepresentational capacity, insufficient adaptability, weak scalability, and\npairwise comparison paradigm -- issues that stem primarily from a dependence on\ndiscrete optimization techniques. To overcome these limitations, we introduce a\nnew score-based preference approach, refereed as SPOGW, which operates directly\non cardinal reward signals through group-wise comparison and enables more\nefficient and stable optimization in a continuous space. SPOGW incorporates\nIterative offline GRPO (ioGRPO) with advantage-masked KL divergence (mKL),\nwhich regulates training update by placing greater emphasis on the advantageous\nregions of the policy response. In five benchmark datasets covering\nmathematical reasoning, coding, and question answering, SPOGW matches or\nexceeds the performance of current state-of-the-art approaches, presenting a\nviable and forward-looking methodology for automated generation and\noptimization of agentic workflows.", "AI": {"tldr": "SPOGW\u662f\u4e00\u79cd\u57fa\u4e8e\u5206\u6570\u7684\u504f\u597d\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ec4\u95f4\u6bd4\u8f83\u76f4\u63a5\u5728\u8fde\u7eed\u7a7a\u95f4\u4e2d\u4f18\u5316\u4ee3\u7406\u5de5\u4f5c\u6d41\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8868\u793a\u80fd\u529b\u3001\u9002\u5e94\u6027\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u7684\u9650\u5236\u3002", "motivation": "\u73b0\u6709\u4ee3\u7406\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u9700\u8981\u5927\u91cf\u4eba\u5de5\u5e72\u9884\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\u5f53\u524d\u81ea\u52a8\u5316\u65b9\u6cd5\u53d7\u9650\u4e8e\u79bb\u6563\u4f18\u5316\u6280\u672f\uff0c\u5b58\u5728\u8868\u793a\u80fd\u529b\u6709\u9650\u3001\u9002\u5e94\u6027\u4e0d\u8db3\u3001\u53ef\u6269\u5c55\u6027\u5f31\u548c\u6210\u5bf9\u6bd4\u8f83\u8303\u5f0f\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faSPOGW\u65b9\u6cd5\uff0c\u7ed3\u5408\u8fed\u4ee3\u79bb\u7ebfGRPO(ioGRPO)\u548c\u4f18\u52bf\u63a9\u7801KL\u6563\u5ea6(mKL)\uff0c\u901a\u8fc7\u7ec4\u95f4\u6bd4\u8f83\u76f4\u63a5\u5229\u7528\u57fa\u6570\u5956\u52b1\u4fe1\u53f7\uff0c\u5728\u8fde\u7eed\u7a7a\u95f4\u4e2d\u8fdb\u884c\u66f4\u9ad8\u6548\u7a33\u5b9a\u7684\u4f18\u5316\u3002", "result": "\u5728\u6db5\u76d6\u6570\u5b66\u63a8\u7406\u3001\u7f16\u7a0b\u548c\u95ee\u7b54\u7684\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cSPOGW\u8fbe\u5230\u6216\u8d85\u8d8a\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "SPOGW\u4e3a\u4ee3\u7406\u5de5\u4f5c\u6d41\u7684\u81ea\u52a8\u751f\u6210\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u4e14\u524d\u77bb\u7684\u65b9\u6cd5\u8bba\u3002"}}
{"id": "2510.03913", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03913", "abs": "https://arxiv.org/abs/2510.03913", "authors": ["Mohammad Amin Abbasi", "Hassan Naderi"], "title": "PsycholexTherapy: Simulating Reasoning in Psychotherapy with Small Language Models in Persian", "comment": null, "summary": "This study presents PsychoLexTherapy, a framework for simulating\npsychotherapeutic reasoning in Persian using small language models (SLMs). The\nframework tackles the challenge of developing culturally grounded,\ntherapeutically coherent dialogue systems with structured memory for multi-turn\ninteractions in underrepresented languages. To ensure privacy and feasibility,\nPsychoLexTherapy is optimized for on-device deployment, enabling use without\nexternal servers. Development followed a three-stage process: (i) assessing\nSLMs psychological knowledge with PsychoLexEval; (ii) designing and\nimplementing the reasoning-oriented PsychoLexTherapy framework; and (iii)\nconstructing two evaluation datasets-PsychoLexQuery (real Persian user\nquestions) and PsychoLexDialogue (hybrid simulated sessions)-to benchmark\nagainst multiple baselines. Experiments compared simple prompting, multi-agent\ndebate, and structured therapeutic reasoning paths. Results showed that\ndeliberate model selection balanced accuracy, efficiency, and privacy. On\nPsychoLexQuery, PsychoLexTherapy outperformed all baselines in automatic\nLLM-as-a-judge evaluation and was ranked highest by human evaluators in a\nsingle-turn preference study. In multi-turn tests with PsychoLexDialogue, the\nlong-term memory module proved essential: while naive history concatenation\ncaused incoherence and information loss, the full framework achieved the\nhighest ratings in empathy, coherence, cultural fit, and personalization.\nOverall, PsychoLexTherapy establishes a practical, privacy-preserving, and\nculturally aligned foundation for Persian psychotherapy simulation,\ncontributing novel datasets, a reproducible evaluation pipeline, and empirical\ninsights into structured memory for therapeutic reasoning.", "AI": {"tldr": "PsychoLexTherapy\u662f\u4e00\u4e2a\u5728\u6ce2\u65af\u8bed\u4e2d\u6a21\u62df\u5fc3\u7406\u6cbb\u7597\u63a8\u7406\u7684\u6846\u67b6\uff0c\u4f7f\u7528\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u6ce8\u91cd\u6587\u5316\u9002\u5e94\u6027\u548c\u9690\u79c1\u4fdd\u62a4\uff0c\u652f\u6301\u591a\u8f6e\u5bf9\u8bdd\u548c\u7ed3\u6784\u5316\u8bb0\u5fc6\u3002", "motivation": "\u5f00\u53d1\u9488\u5bf9\u6ce2\u65af\u8bed\u7b49\u8d44\u6e90\u4e0d\u8db3\u8bed\u8a00\u7684\u6587\u5316\u9002\u5e94\u6027\u3001\u6cbb\u7597\u8fde\u8d2f\u7684\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u89e3\u51b3\u9690\u79c1\u4fdd\u62a4\u548c\u8bbe\u5907\u90e8\u7f72\u7684\u53ef\u884c\u6027\u95ee\u9898\u3002", "method": "\u4e09\u9636\u6bb5\u5f00\u53d1\u6d41\u7a0b\uff1a\u8bc4\u4f30SLMs\u5fc3\u7406\u77e5\u8bc6\u3001\u8bbe\u8ba1\u63a8\u7406\u5bfc\u5411\u6846\u67b6\u3001\u6784\u5efa\u8bc4\u4f30\u6570\u636e\u96c6\uff1b\u6bd4\u8f83\u7b80\u5355\u63d0\u793a\u3001\u591a\u4ee3\u7406\u8fa9\u8bba\u548c\u7ed3\u6784\u5316\u6cbb\u7597\u63a8\u7406\u8def\u5f84\u3002", "result": "\u5728\u5355\u8f6e\u504f\u597d\u7814\u7a76\u4e2d\u83b7\u5f97\u6700\u9ad8\u4eba\u7c7b\u8bc4\u4ef7\uff0c\u5728\u591a\u8f6e\u6d4b\u8bd5\u4e2d\u5b8c\u6574\u6846\u67b6\u5728\u5171\u60c5\u3001\u8fde\u8d2f\u6027\u3001\u6587\u5316\u9002\u5e94\u6027\u548c\u4e2a\u6027\u5316\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u957f\u671f\u8bb0\u5fc6\u6a21\u5757\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "PsychoLexTherapy\u4e3a\u6ce2\u65af\u8bed\u5fc3\u7406\u6cbb\u7597\u6a21\u62df\u5efa\u7acb\u4e86\u5b9e\u7528\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u7b26\u5408\u6587\u5316\u7684\u57fa\u7840\uff0c\u8d21\u732e\u4e86\u65b0\u9896\u6570\u636e\u96c6\u3001\u53ef\u590d\u73b0\u8bc4\u4f30\u6d41\u7a0b\u548c\u7ed3\u6784\u5316\u8bb0\u5fc6\u7684\u5b9e\u8bc1\u89c1\u89e3\u3002"}}
{"id": "2510.04093", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04093", "abs": "https://arxiv.org/abs/2510.04093", "authors": ["Guixian Zhang", "Guan Yuan", "Ziqi Xu", "Yanmei Zhang", "Zhenyun Deng", "Debo Cheng"], "title": "Harnessing LLM for Noise-Robust Cognitive Diagnosis in Web-Based Intelligent Education Systems", "comment": null, "summary": "Cognitive diagnostics in the Web-based Intelligent Education System (WIES)\naims to assess students' mastery of knowledge concepts from heterogeneous,\nnoisy interactions. Recent work has tried to utilize Large Language Models\n(LLMs) for cognitive diagnosis, yet LLMs struggle with structured data and are\nprone to noise-induced misjudgments. Specially, WIES's open environment\ncontinuously attracts new students and produces vast amounts of response logs,\nexacerbating the data imbalance and noise issues inherent in traditional\neducational systems. To address these challenges, we propose DLLM, a\nDiffusion-based LLM framework for noise-robust cognitive diagnosis. DLLM first\nconstructs independent subgraphs based on response correctness, then applies\nrelation augmentation alignment module to mitigate data imbalance. The two\nsubgraph representations are then fused and aligned with LLM-derived,\nsemantically augmented representations. Importantly, before each alignment\nstep, DLLM employs a two-stage denoising diffusion module to eliminate\nintrinsic noise while assisting structural representation alignment.\nSpecifically, unconditional denoising diffusion first removes erroneous\ninformation, followed by conditional denoising diffusion based on graph-guided\nto eliminate misleading information. Finally, the noise-robust representation\nthat integrates semantic knowledge and structural information is fed into\nexisting cognitive diagnosis models for prediction. Experimental results on\nthree publicly available web-based educational platform datasets demonstrate\nthat our DLLM achieves optimal predictive performance across varying noise\nlevels, which demonstrates that DLLM achieves noise robustness while\neffectively leveraging semantic knowledge from LLM.", "AI": {"tldr": "\u63d0\u51faDLLM\u6846\u67b6\uff0c\u4f7f\u7528\u6269\u6563\u6a21\u578b\u589e\u5f3aLLM\u5728\u8ba4\u77e5\u8bca\u65ad\u4e2d\u7684\u566a\u58f0\u9c81\u68d2\u6027\uff0c\u89e3\u51b3\u7f51\u7edc\u6559\u80b2\u7cfb\u7edf\u4e2d\u6570\u636e\u4e0d\u5e73\u8861\u548c\u566a\u58f0\u95ee\u9898", "motivation": "\u7f51\u7edc\u6559\u80b2\u7cfb\u7edf(WIES)\u4e2d\u7684\u8ba4\u77e5\u8bca\u65ad\u9762\u4e34\u5f02\u6784\u566a\u58f0\u4ea4\u4e92\u3001\u6570\u636e\u4e0d\u5e73\u8861\u548c\u65b0\u5b66\u751f\u4e0d\u65ad\u52a0\u5165\u7684\u6311\u6218\uff0c\u4f20\u7edfLLM\u96be\u4ee5\u5904\u7406\u7ed3\u6784\u5316\u6570\u636e\u4e14\u6613\u53d7\u566a\u58f0\u5e72\u6270", "method": "DLLM\u6846\u67b6\uff1a1)\u57fa\u4e8e\u7b54\u9898\u6b63\u786e\u6027\u6784\u5efa\u72ec\u7acb\u5b50\u56fe\uff1b2)\u5173\u7cfb\u589e\u5f3a\u5bf9\u9f50\u6a21\u5757\u7f13\u89e3\u6570\u636e\u4e0d\u5e73\u8861\uff1b3)\u4e24\u9636\u6bb5\u53bb\u566a\u6269\u6563\u6a21\u5757\u6d88\u9664\u5185\u5728\u566a\u58f0\uff1b4)\u878d\u5408\u5b50\u56fe\u8868\u793a\u4e0eLLM\u8bed\u4e49\u589e\u5f3a\u8868\u793a", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u7f51\u7edc\u6559\u80b2\u5e73\u53f0\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDLLM\u5728\u4e0d\u540c\u566a\u58f0\u6c34\u5e73\u4e0b\u5747\u53d6\u5f97\u6700\u4f18\u9884\u6d4b\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u566a\u58f0\u9c81\u68d2\u6027\u5e76\u6709\u6548\u5229\u7528LLM\u8bed\u4e49\u77e5\u8bc6", "conclusion": "DLLM\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u7f51\u7edc\u6559\u80b2\u7cfb\u7edf\u4e2d\u8ba4\u77e5\u8bca\u65ad\u7684\u566a\u58f0\u548c\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u6269\u6563\u6a21\u578b\u589e\u5f3a\u4e86LLM\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u667a\u80fd\u6559\u80b2\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8ba4\u77e5\u8bca\u65ad\u65b9\u6848"}}
{"id": "2510.03997", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03997", "abs": "https://arxiv.org/abs/2510.03997", "authors": ["Junjie Luo", "Rui Han", "Arshana Welivita", "Zeleikun Di", "Jingfu Wu", "Xuzhe Zhi", "Ritu Agarwal", "Gordon Gao"], "title": "Mapping Patient-Perceived Physician Traits from Nationwide Online Reviews with LLMs", "comment": null, "summary": "Understanding how patients perceive their physicians is essential to\nimproving trust, communication, and satisfaction. We present a large language\nmodel (LLM)-based pipeline that infers Big Five personality traits and five\npatient-oriented subjective judgments. The analysis encompasses 4.1 million\npatient reviews of 226,999 U.S. physicians from an initial pool of one million.\nWe validate the method through multi-model comparison and human expert\nbenchmarking, achieving strong agreement between human and LLM assessments\n(correlation coefficients 0.72-0.89) and external validity through correlations\nwith patient satisfaction (r = 0.41-0.81, all p<0.001). National-scale analysis\nreveals systematic patterns: male physicians receive higher ratings across all\ntraits, with largest disparities in clinical competence perceptions;\nempathy-related traits predominate in pediatrics and psychiatry; and all traits\npositively predict overall satisfaction. Cluster analysis identifies four\ndistinct physician archetypes, from \"Well-Rounded Excellent\" (33.8%, uniformly\nhigh traits) to \"Underperforming\" (22.6%, consistently low). These findings\ndemonstrate that automated trait extraction from patient narratives can provide\ninterpretable, validated metrics for understanding physician-patient\nrelationships at scale, with implications for quality measurement, bias\ndetection, and workforce development in healthcare.", "AI": {"tldr": "\u4f7f\u7528LLM\u4ece410\u4e07\u6761\u60a3\u8005\u8bc4\u4ef7\u4e2d\u63d0\u53d6\u533b\u751f\u7684\u5927\u4e94\u4eba\u683c\u7279\u8d28\u548c\u60a3\u8005\u4e3b\u89c2\u5224\u65ad\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u6027\u522b\u5dee\u5f02\u3001\u4e13\u79d1\u5dee\u5f02\u7b49\u7cfb\u7edf\u6027\u6a21\u5f0f\u3002", "motivation": "\u4e86\u89e3\u60a3\u8005\u5bf9\u533b\u751f\u7684\u8ba4\u77e5\u5bf9\u4e8e\u6539\u5584\u4fe1\u4efb\u3001\u6c9f\u901a\u548c\u6ee1\u610f\u5ea6\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5927\u89c4\u6a21\u5206\u6790\u60a3\u8005\u8bc4\u4ef7\u6765\u7406\u89e3\u533b\u60a3\u5173\u7cfb\u3002", "method": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6d41\u6c34\u7ebf\u65b9\u6cd5\uff0c\u5206\u6790410\u4e07\u6761\u60a3\u8005\u8bc4\u4ef7\uff0c\u901a\u8fc7\u591a\u6a21\u578b\u6bd4\u8f83\u548c\u4eba\u7c7b\u4e13\u5bb6\u57fa\u51c6\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u4eba\u7c7b\u4e0eLLM\u8bc4\u4f30\u9ad8\u5ea6\u4e00\u81f4\uff08\u76f8\u5173\u7cfb\u65700.72-0.89\uff09\uff0c\u4e0e\u60a3\u8005\u6ee1\u610f\u5ea6\u663e\u8457\u76f8\u5173\uff1b\u53d1\u73b0\u7537\u6027\u533b\u751f\u5728\u6240\u6709\u7279\u8d28\u4e0a\u8bc4\u5206\u66f4\u9ad8\uff0c\u540c\u7406\u5fc3\u76f8\u5173\u7279\u8d28\u5728\u513f\u79d1\u548c\u7cbe\u795e\u79d1\u5360\u4e3b\u5bfc\uff0c\u6240\u6709\u7279\u8d28\u90fd\u80fd\u6b63\u5411\u9884\u6d4b\u603b\u4f53\u6ee1\u610f\u5ea6\u3002", "conclusion": "\u4ece\u60a3\u8005\u53d9\u8ff0\u4e2d\u81ea\u52a8\u63d0\u53d6\u7279\u8d28\u53ef\u4ee5\u63d0\u4f9b\u53ef\u89e3\u91ca\u3001\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u6307\u6807\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u7406\u89e3\u533b\u60a3\u5173\u7cfb\uff0c\u5bf9\u533b\u7597\u8d28\u91cf\u6d4b\u91cf\u3001\u504f\u89c1\u68c0\u6d4b\u548c\u4eba\u529b\u8d44\u6e90\u53d1\u5c55\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2510.04097", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04097", "abs": "https://arxiv.org/abs/2510.04097", "authors": ["Peichao Lai", "Jinhui Zhuang", "Kexuan Zhang", "Ningchang Xiong", "Shengjie Wang", "Yanwei Xu", "Chong Chen", "Yilei Wang", "Bin Cui"], "title": "WebRenderBench: Enhancing Web Interface Generation through Layout-Style Consistency and Reinforcement Learning", "comment": null, "summary": "Automating the conversion of UI images into web code is a critical task for\nfront-end development and rapid prototyping. Advances in multimodal large\nlanguage models (MLLMs) have made WebUI-to-Code increasingly feasible, yet\nexisting benchmarks remain limited in data diversity and evaluation\nreliability. To address these issues, we present WebRenderBench, a large-scale\nbenchmark of 22.5k webpages collected from real-world portal sites, offering\ngreater diversity, complexity, and realism than prior benchmarks. We further\npropose a novel evaluation metric that measures layout and style consistency\nfrom the final rendered pages. Unlike vision-based methods that rely on costly\nLLM reasoning or structure-based comparisons vulnerable to noise and asymmetry,\nour approach enables more efficient, objective, and reliable UI quality\nassessment. Finally, we introduce the Automated Layout and Style Inspection\nAgent (ALISA), which integrates this metric into reinforcement learning as a\nreward signal to enhance training on crawled asymmetric webpages. Experiments\nshow that ALISA significantly boosts generation performance, achieving\nstate-of-the-art results across multiple metrics.", "AI": {"tldr": "\u63d0\u51fa\u4e86WebRenderBench\u57fa\u51c6\u548cALISA\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdbUI\u56fe\u50cf\u5230\u7f51\u9875\u4ee3\u7801\u7684\u8f6c\u6362\u8bc4\u4f30\u548c\u751f\u6210\u6027\u80fd", "motivation": "\u73b0\u6709UI\u5230\u4ee3\u7801\u8f6c\u6362\u7684\u57fa\u51c6\u5728\u6570\u636e\u591a\u6837\u6027\u548c\u8bc4\u4f30\u53ef\u9760\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u66f4\u771f\u5b9e\u3001\u591a\u6837\u5316\u7684\u6570\u636e\u96c6\u548c\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u65b9\u6cd5", "method": "1) \u6784\u5efaWebRenderBench\u5927\u89c4\u6a21\u57fa\u51c6\u6570\u636e\u96c6(22.5k\u7f51\u9875)\uff1b2) \u63d0\u51fa\u57fa\u4e8e\u6700\u7ec8\u6e32\u67d3\u9875\u9762\u5e03\u5c40\u548c\u6837\u5f0f\u4e00\u81f4\u6027\u7684\u65b0\u8bc4\u4f30\u6307\u6807\uff1b3) \u5f00\u53d1ALISA\u4ee3\u7406\uff0c\u5c06\u8bc4\u4f30\u6307\u6807\u4f5c\u4e3a\u5f3a\u5316\u5b66\u4e60\u7684\u5956\u52b1\u4fe1\u53f7", "result": "ALISA\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c", "conclusion": "WebRenderBench\u63d0\u4f9b\u4e86\u66f4\u771f\u5b9e\u591a\u6837\u7684\u8bc4\u4f30\u57fa\u51c6\uff0cALISA\u901a\u8fc7\u96c6\u6210\u65b0\u8bc4\u4f30\u6307\u6807\u6709\u6548\u63d0\u5347\u4e86UI\u5230\u4ee3\u7801\u8f6c\u6362\u7684\u8d28\u91cf\u548c\u53ef\u9760\u6027"}}
{"id": "2510.03999", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03999", "abs": "https://arxiv.org/abs/2510.03999", "authors": ["Yang Xu", "Xuanming Zhang", "Min-Hsuan Yeh", "Jwala Dhamala", "Ousmane Dia", "Rahul Gupta", "Yixuan Li"], "title": "Simulating and Understanding Deceptive Behaviors in Long-Horizon Interactions", "comment": null, "summary": "Deception is a pervasive feature of human communication and an emerging\nconcern in large language models (LLMs). While recent studies document\ninstances of LLM deception under pressure, most evaluations remain confined to\nsingle-turn prompts and fail to capture the long-horizon interactions in which\ndeceptive strategies typically unfold. We introduce the first simulation\nframework for probing and evaluating deception in LLMs under extended sequences\nof interdependent tasks and dynamic contextual pressures. Our framework\ninstantiates a multi-agent system: a performer agent tasked with completing\ntasks and a supervisor agent that evaluates progress, provides feedback, and\nmaintains evolving states of trust. An independent deception auditor then\nreviews full trajectories to identify when and how deception occurs. We conduct\nextensive experiments across 11 frontier models, spanning both closed- and\nopen-source systems, and find that deception is model-dependent, increases with\nevent pressure, and consistently erodes supervisor trust. Qualitative analyses\nfurther reveal distinct strategies of concealment, equivocation, and\nfalsification. Our findings establish deception as an emergent risk in\nlong-horizon interactions and provide a foundation for evaluating future LLMs\nin real-world, trust-sensitive contexts.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u9996\u4e2a\u6a21\u62df\u6846\u67b6\u6765\u8bc4\u4f30LLM\u5728\u957f\u671f\u4ea4\u4e92\u4e2d\u7684\u6b3a\u9a97\u884c\u4e3a\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u53d1\u73b0\u6b3a\u9a97\u884c\u4e3a\u5177\u6709\u6a21\u578b\u4f9d\u8d56\u6027\uff0c\u4f1a\u968f\u538b\u529b\u589e\u52a0\uff0c\u5e76\u635f\u5bb3\u76d1\u7763\u8005\u4fe1\u4efb\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5355\u8f6e\u63d0\u793a\u4e0b\u7684LLM\u6b3a\u9a97\u884c\u4e3a\uff0c\u4f46\u73b0\u5b9e\u4e2d\u7684\u6b3a\u9a97\u7b56\u7565\u901a\u5e38\u5728\u957f\u671f\u4ea4\u4e92\u4e2d\u5c55\u5f00\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u6784\u5efa\u591a\u667a\u80fd\u4f53\u6a21\u62df\u6846\u67b6\uff1a\u6267\u884c\u8005\u667a\u80fd\u4f53\u5b8c\u6210\u4efb\u52a1\uff0c\u76d1\u7763\u8005\u667a\u80fd\u4f53\u8bc4\u4f30\u8fdb\u5c55\u5e76\u63d0\u4f9b\u53cd\u9988\uff0c\u72ec\u7acb\u7684\u6b3a\u9a97\u5ba1\u8ba1\u5458\u5206\u6790\u5b8c\u6574\u8f68\u8ff9\u8bc6\u522b\u6b3a\u9a97\u884c\u4e3a\u3002", "result": "\u572811\u4e2a\u524d\u6cbf\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff1a\u6b3a\u9a97\u5177\u6709\u6a21\u578b\u4f9d\u8d56\u6027\uff0c\u968f\u4e8b\u4ef6\u538b\u529b\u589e\u52a0\uff0c\u6301\u7eed\u635f\u5bb3\u76d1\u7763\u8005\u4fe1\u4efb\uff0c\u5e76\u8bc6\u522b\u51fa\u9690\u7792\u3001\u542b\u7cca\u5176\u8f9e\u548c\u4f2a\u9020\u7b49\u5177\u4f53\u7b56\u7565\u3002", "conclusion": "\u6b3a\u9a97\u662f\u957f\u671f\u4ea4\u4e92\u4e2d\u51fa\u73b0\u7684\u98ce\u9669\uff0c\u8be5\u6846\u67b6\u4e3a\u8bc4\u4f30\u73b0\u5b9e\u4e16\u754c\u4e2d\u4fe1\u4efb\u654f\u611f\u73af\u5883\u4e0b\u7684\u672a\u6765LLM\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.04116", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04116", "abs": "https://arxiv.org/abs/2510.04116", "authors": ["Ziying Zhang", "Yaqing Wang", "Quanming Yao"], "title": "Searching Meta Reasoning Skeleton to Guide LLM Reasoning", "comment": null, "summary": "Meta reasoning behaviors work as a skeleton to guide large language model\n(LLM) reasoning, thus help to improve reasoning performance. However, prior\nresearches implement meta reasoning skeleton with manually designed structure,\nlimiting ability to adapt to query-specific requirement and capture intricate\nlogical dependency among reasoning steps. To deal with the challenges, we\nrepresent meta reasoning skeleton with directed acyclic graph (DAG) to unify\nskeletons proposed in prior works and model intricate logical dependency. Then\nwe propose AutoMR, a framework that searches for query-aware meta reasoning\nskeleton automatically inspired by automated machine learning (AutoML).\nSpecifically, we construct search space based on DAG representation of skeleton\nand then formulate the search problem. We design a dynamic skeleton sampling\nalgorithm by expanding meta reasoning skeleton along with reasoning context at\ninference time. This algorithm can derive any meta reasoning skeleton in search\nspace efficiently and adapt skeleton to evolving base reasoning context, thus\nenable efficient query-aware skeleton search. We conduct experiments on\nextensive benchmark datasets. Experimental results show that AutoMR achieves\nbetter reasoning performance than previous works broadly.", "AI": {"tldr": "AutoMR\u6846\u67b6\u901a\u8fc7\u81ea\u52a8\u641c\u7d22\u67e5\u8be2\u611f\u77e5\u7684\u5143\u63a8\u7406\u9aa8\u67b6\uff0c\u4f7f\u7528\u6709\u5411\u65e0\u73af\u56fe\u8868\u793a\u63a8\u7406\u7ed3\u6784\uff0c\u7ed3\u5408AutoML\u601d\u60f3\u52a8\u6001\u91c7\u6837\u9002\u5e94\u63a8\u7406\u4e0a\u4e0b\u6587\u7684\u9aa8\u67b6\uff0c\u663e\u8457\u63d0\u5347LLM\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4f7f\u7528\u624b\u52a8\u8bbe\u8ba1\u7684\u5143\u63a8\u7406\u9aa8\u67b6\u7ed3\u6784\uff0c\u65e0\u6cd5\u9002\u5e94\u67e5\u8be2\u7279\u5b9a\u9700\u6c42\uff0c\u4e5f\u96be\u4ee5\u6355\u6349\u63a8\u7406\u6b65\u9aa4\u95f4\u7684\u590d\u6742\u903b\u8f91\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "\u63d0\u51faAutoMR\u6846\u67b6\uff1a1) \u7528\u6709\u5411\u65e0\u73af\u56fe\u7edf\u4e00\u8868\u793a\u5143\u63a8\u7406\u9aa8\u67b6\uff1b2) \u57fa\u4e8eAutoML\u601d\u60f3\u6784\u5efa\u641c\u7d22\u7a7a\u95f4\uff1b3) \u8bbe\u8ba1\u52a8\u6001\u9aa8\u67b6\u91c7\u6837\u7b97\u6cd5\uff0c\u5728\u63a8\u7406\u65f6\u6839\u636e\u4e0a\u4e0b\u6587\u6269\u5c55\u9aa8\u67b6\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAutoMR\u76f8\u6bd4\u5148\u524d\u5de5\u4f5c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "AutoMR\u901a\u8fc7\u81ea\u52a8\u641c\u7d22\u67e5\u8be2\u611f\u77e5\u7684\u5143\u63a8\u7406\u9aa8\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u624b\u52a8\u8bbe\u8ba1\u9aa8\u67b6\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2510.04001", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04001", "abs": "https://arxiv.org/abs/2510.04001", "authors": ["Xuankang Zhang", "Jiangming Liu"], "title": "Named Entity Recognition in COVID-19 tweets with Entity Knowledge Augmentation", "comment": "Work in progress", "summary": "The COVID-19 pandemic causes severe social and economic disruption around the\nworld, raising various subjects that are discussed over social media.\nIdentifying pandemic-related named entities as expressed on social media is\nfundamental and important to understand the discussions about the pandemic.\nHowever, there is limited work on named entity recognition on this topic due to\nthe following challenges: 1) COVID-19 texts in social media are informal and\ntheir annotations are rare and insufficient to train a robust recognition\nmodel, and 2) named entity recognition in COVID-19 requires extensive\ndomain-specific knowledge. To address these issues, we propose a novel entity\nknowledge augmentation approach for COVID-19, which can also be applied in\ngeneral biomedical named entity recognition in both informal text format and\nformal text format. Experiments carried out on the COVID-19 tweets dataset and\nPubMed dataset show that our proposed entity knowledge augmentation improves\nNER performance in both fully-supervised and few-shot settings. Our source code\nis publicly available: https://github.com/kkkenshi/LLM-EKA/tree/master", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5b9e\u4f53\u77e5\u8bc6\u589e\u5f3a\u65b9\u6cd5\uff0c\u7528\u4e8eCOVID-19\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff0c\u53ef\u63d0\u5347\u793e\u4ea4\u5a92\u4f53\u548c\u751f\u7269\u533b\u5b66\u6587\u672c\u4e2d\u7684NER\u6027\u80fd\u3002", "motivation": "COVID-19\u75ab\u60c5\u5f15\u53d1\u793e\u4ea4\u5a92\u4f53\u5e7f\u6cdb\u8ba8\u8bba\uff0c\u4f46\u793e\u4ea4\u5a92\u4f53\u6587\u672c\u975e\u6b63\u5f0f\u4e14\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\uff0c\u52a0\u4e0a\u9700\u8981\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4f7f\u5f97\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u9762\u4e34\u6311\u6218\u3002", "method": "\u91c7\u7528\u5b9e\u4f53\u77e5\u8bc6\u589e\u5f3a\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u6765\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u6b63\u5f0f\u548c\u975e\u6b63\u5f0f\u6587\u672c\u683c\u5f0f\u3002", "result": "\u5728COVID-19\u63a8\u6587\u6570\u636e\u96c6\u548cPubMed\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5b8c\u5168\u76d1\u7763\u548c\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u5747\u80fd\u63d0\u9ad8NER\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u5b9e\u4f53\u77e5\u8bc6\u589e\u5f3a\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86COVID-19\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u548c\u9886\u57df\u77e5\u8bc6\u9700\u6c42\u95ee\u9898\uff0c\u5728\u751f\u7269\u533b\u5b66NER\u4efb\u52a1\u4e2d\u5177\u6709\u901a\u7528\u6027\u3002"}}
{"id": "2510.04128", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04128", "abs": "https://arxiv.org/abs/2510.04128", "authors": ["Dmitrii Troitskii", "Koyena Pal", "Chris Wendler", "Callum Stuart McDougall", "Neel Nanda"], "title": "Internal states before wait modulate reasoning patterns", "comment": "Accepted to EMNLP Findings 2025", "summary": "Prior work has shown that a significant driver of performance in reasoning\nmodels is their ability to reason and self-correct. A distinctive marker in\nthese reasoning traces is the token wait, which often signals reasoning\nbehavior such as backtracking. Despite being such a complex behavior, little is\nunderstood of exactly why models do or do not decide to reason in this\nparticular manner, which limits our understanding of what makes a reasoning\nmodel so effective. In this work, we address the question whether model's\nlatents preceding wait tokens contain relevant information for modulating the\nsubsequent reasoning process. We train crosscoders at multiple layers of\nDeepSeek-R1-Distill-Llama-8B and its base version, and introduce a latent\nattribution technique in the crosscoder setting. We locate a small set of\nfeatures relevant for promoting/suppressing wait tokens' probabilities.\nFinally, through a targeted series of experiments analyzing max activating\nexamples and causal interventions, we show that many of our identified features\nindeed are relevant for the reasoning process and give rise to different types\nof reasoning patterns such as restarting from the beginning, recalling prior\nknowledge, expressing uncertainty, and double-checking.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u7b49\u5f85\u6807\u8bb0\u5305\u542b\u91cd\u8981\u4fe1\u606f\uff0c\u901a\u8fc7\u4ea4\u53c9\u7f16\u7801\u5668\u548c\u6f5c\u5728\u5f52\u56e0\u6280\u672f\u8bc6\u522b\u51fa\u5f71\u54cd\u7b49\u5f85\u6807\u8bb0\u6982\u7387\u7684\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u4e0e\u4e0d\u540c\u7c7b\u578b\u7684\u63a8\u7406\u6a21\u5f0f\u76f8\u5173\u3002", "motivation": "\u7406\u89e3\u4e3a\u4ec0\u4e48\u6a21\u578b\u4f1a\u51b3\u5b9a\u4ee5\u7279\u5b9a\u65b9\u5f0f\u63a8\u7406\uff0c\u7279\u522b\u662f\u7b49\u5f85\u6807\u8bb0\u80cc\u540e\u7684\u673a\u5236\uff0c\u8fd9\u6709\u52a9\u4e8e\u63ed\u793a\u63a8\u7406\u6a21\u578b\u6709\u6548\u6027\u7684\u539f\u56e0\u3002", "method": "\u5728DeepSeek-R1-Distill-Llama-8B\u53ca\u5176\u57fa\u7840\u7248\u672c\u7684\u591a\u4e2a\u5c42\u8bad\u7ec3\u4ea4\u53c9\u7f16\u7801\u5668\uff0c\u5e76\u5f15\u5165\u6f5c\u5728\u5f52\u56e0\u6280\u672f\u6765\u5b9a\u4f4d\u5f71\u54cd\u7b49\u5f85\u6807\u8bb0\u6982\u7387\u7684\u7279\u5f81\u3002", "result": "\u8bc6\u522b\u51fa\u4e00\u5c0f\u7ec4\u4e0e\u4fc3\u8fdb/\u6291\u5236\u7b49\u5f85\u6807\u8bb0\u6982\u7387\u76f8\u5173\u7684\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u786e\u5b9e\u4e0e\u63a8\u7406\u8fc7\u7a0b\u76f8\u5173\uff0c\u5e76\u4ea7\u751f\u4e0d\u540c\u7c7b\u578b\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "conclusion": "\u6a21\u578b\u5728\u7b49\u5f85\u6807\u8bb0\u4e4b\u524d\u7684\u6f5c\u5728\u72b6\u6001\u5305\u542b\u8c03\u8282\u540e\u7eed\u63a8\u7406\u8fc7\u7a0b\u7684\u76f8\u5173\u4fe1\u606f\uff0c\u8fd9\u4e9b\u7279\u5f81\u652f\u6301\u91cd\u542f\u63a8\u7406\u3001\u56de\u5fc6\u5148\u9a8c\u77e5\u8bc6\u3001\u8868\u8fbe\u4e0d\u786e\u5b9a\u6027\u548c\u53cc\u91cd\u68c0\u67e5\u7b49\u63a8\u7406\u884c\u4e3a\u3002"}}
{"id": "2510.04002", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04002", "abs": "https://arxiv.org/abs/2510.04002", "authors": ["Bo Yang", "Yunkui Chen", "Lanfei Feng", "Yu Zhang", "Xiao Xu", "Jianyu Zhang", "Nueraili Aierken", "Runhe Huang", "Hongjian Lin", "Yibin Ying", "Shijian Li"], "title": "AgriGPT-VL: Agricultural Vision-Language Understanding Suite", "comment": null, "summary": "Despite rapid advances in multimodal large language models, agricultural\napplications remain constrained by the scarcity of domain-tailored models,\ncurated vision-language corpora, and rigorous evaluation. To address these\nchallenges, we present the AgriGPT-VL Suite, a unified multimodal framework for\nagriculture. Our contributions are threefold. First, we introduce Agri-3M-VL,\nthe largest vision-language corpus for agriculture to our knowledge, curated by\na scalable multi-agent data generator; it comprises 1M image-caption pairs, 2M\nimage-grounded VQA pairs, 50K expert-level VQA instances, and 15K GRPO\nreinforcement learning samples. Second, we develop AgriGPT-VL, an\nagriculture-specialized vision-language model trained via a progressive\ncurriculum of textual grounding, multimodal shallow/deep alignment, and GRPO\nrefinement. This method achieves strong multimodal reasoning while preserving\ntext-only capability. Third, we establish AgriBench-VL-4K, a compact yet\nchallenging evaluation suite with open-ended and image-grounded questions,\npaired with multi-metric evaluation and an LLM-as-a-judge framework.\nExperiments show that AgriGPT-VL outperforms leading general-purpose VLMs on\nAgriBench-VL-4K, achieving higher pairwise win rates in the LLM-as-a-judge\nevaluation. Meanwhile, it remains competitive on the text-only AgriBench-13K\nwith no noticeable degradation of language ability. Ablation studies further\nconfirm consistent gains from our alignment and GRPO refinement stages. We will\nopen source all of the resources to support reproducible research and\ndeployment in low-resource agricultural settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86AgriGPT-VL\u5957\u4ef6\uff0c\u5305\u62ec\u6700\u5927\u7684\u519c\u4e1a\u89c6\u89c9\u8bed\u8a00\u8bed\u6599\u5e93Agri-3M-VL\u3001\u519c\u4e1a\u4e13\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578bAgriGPT-VL\u548c\u8bc4\u4f30\u5957\u4ef6AgriBench-VL-4K\uff0c\u5728\u519c\u4e1a\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u901a\u7528\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u519c\u4e1a\u9886\u57df\u7f3a\u4e4f\u5b9a\u5236\u5316\u6a21\u578b\u3001\u7cbe\u5fc3\u7b56\u5212\u7684\u89c6\u89c9\u8bed\u8a00\u8bed\u6599\u5e93\u548c\u4e25\u683c\u8bc4\u4f30\u7684\u95ee\u9898\uff0c\u63a8\u52a8\u519c\u4e1a\u591a\u6a21\u6001AI\u5e94\u7528\u53d1\u5c55\u3002", "method": "\u4f7f\u7528\u53ef\u6269\u5c55\u591a\u667a\u80fd\u4f53\u6570\u636e\u751f\u6210\u5668\u6784\u5efaAgri-3M-VL\u8bed\u6599\u5e93\uff1b\u901a\u8fc7\u6e10\u8fdb\u5f0f\u8bfe\u7a0b\u8bad\u7ec3AgriGPT-VL\u6a21\u578b\uff0c\u5305\u62ec\u6587\u672c\u57fa\u7840\u3001\u591a\u6a21\u6001\u6d45\u5c42/\u6df1\u5c42\u5bf9\u9f50\u548cGRPO\u7cbe\u70bc\uff1b\u5efa\u7acb\u591a\u6307\u6807\u8bc4\u4f30\u548cLLM-as-a-judge\u6846\u67b6\u3002", "result": "AgriGPT-VL\u5728AgriBench-VL-4K\u4e0a\u4f18\u4e8e\u9886\u5148\u7684\u901a\u7528VLMs\uff0c\u5728LLM-as-a-judge\u8bc4\u4f30\u4e2d\u83b7\u5f97\u66f4\u9ad8\u80dc\u7387\uff0c\u540c\u65f6\u5728\u6587\u672c\u4efb\u52a1\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\u4e14\u65e0\u8bed\u8a00\u80fd\u529b\u9000\u5316\u3002", "conclusion": "AgriGPT-VL\u5957\u4ef6\u4e3a\u519c\u4e1a\u591a\u6a21\u6001AI\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4e86\u5bf9\u9f50\u548cGRPO\u7cbe\u70bc\u9636\u6bb5\u7684\u4e00\u81f4\u589e\u76ca\uff0c\u6240\u6709\u8d44\u6e90\u5c06\u5f00\u6e90\u4ee5\u652f\u6301\u53ef\u91cd\u590d\u7814\u7a76\u548c\u4f4e\u8d44\u6e90\u519c\u4e1a\u90e8\u7f72\u3002"}}
{"id": "2510.04140", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04140", "abs": "https://arxiv.org/abs/2510.04140", "authors": ["Zishang Jiang", "Jinyi Han", "Tingyun Li", "Xinyi Wang", "Sihang Jiang", "Jiaqing Liang", "Zhaoqian Dai", "Shuguang Ma", "Fei Yu", "Yanghua Xiao"], "title": "Selective Expert Guidance for Effective and Diverse Exploration in Reinforcement Learning of LLMs", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has become a widely\nadopted technique for enhancing the reasoning ability of Large Language Models\n(LLMs). However, the effectiveness of RLVR strongly depends on the capability\nof base models. This issue arises because it requires the model to have\nsufficient capability to perform high-quality exploration, which involves both\neffectiveness and diversity. Unfortunately, existing methods address this issue\nby imitating expert trajectories, which improve effectiveness but neglect\ndiversity. To address this, we argue that the expert only needs to provide\nguidance only at critical decision points rather than the entire reasoning\npath. Based on this insight, we propose MENTOR: Mixed-policy Expert Navigation\nfor Token-level Optimization of Reasoning, a framework that provides expert\nguidance only at critical decision points to perform effective and diverse\nexploration in RLVR. Extensive experiments show that MENTOR enables models\ncapture the essence of expert strategies rather than surface imitation, thereby\nperforming high-quality exploration and achieving superior overall performance.\nOur code is available online.", "AI": {"tldr": "\u63d0\u51fa\u4e86MENTOR\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u5173\u952e\u51b3\u7b56\u70b9\u63d0\u4f9b\u4e13\u5bb6\u6307\u5bfc\u6765\u589e\u5f3aRLVR\u4e2d\u7684\u63a2\u7d22\u8d28\u91cf\u548c\u591a\u6837\u6027\uff0c\u907f\u514d\u4e86\u5bf9\u4e13\u5bb6\u8f68\u8ff9\u7684\u7b80\u5355\u6a21\u4eff\u3002", "motivation": "\u73b0\u6709RLVR\u65b9\u6cd5\u4f9d\u8d56\u57fa\u7840\u6a21\u578b\u80fd\u529b\uff0c\u9700\u8981\u9ad8\u8d28\u91cf\u63a2\u7d22\uff08\u6709\u6548\u6027\u548c\u591a\u6837\u6027\uff09\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u6a21\u4eff\u4e13\u5bb6\u8f68\u8ff9\u53ea\u89e3\u51b3\u4e86\u6709\u6548\u6027\u800c\u5ffd\u89c6\u4e86\u591a\u6837\u6027\u95ee\u9898\u3002", "method": "MENTOR\u6846\u67b6\uff1a\u6df7\u5408\u7b56\u7565\u4e13\u5bb6\u5bfc\u822a\u7684\u4ee4\u724c\u7ea7\u63a8\u7406\u4f18\u5316\uff0c\u4ec5\u5728\u5173\u952e\u51b3\u7b56\u70b9\u63d0\u4f9b\u4e13\u5bb6\u6307\u5bfc\uff0c\u5b9e\u73b0\u6709\u6548\u4e14\u591a\u6837\u5316\u7684\u63a2\u7d22\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMENTOR\u80fd\u591f\u6355\u6349\u4e13\u5bb6\u7b56\u7565\u7684\u672c\u8d28\u800c\u975e\u8868\u9762\u6a21\u4eff\uff0c\u5b9e\u73b0\u9ad8\u8d28\u91cf\u63a2\u7d22\u5e76\u83b7\u5f97\u4f18\u8d8a\u7684\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "\u5728\u5173\u952e\u51b3\u7b56\u70b9\u63d0\u4f9b\u4e13\u5bb6\u6307\u5bfc\u6bd4\u5b8c\u6574\u8f68\u8ff9\u6a21\u4eff\u66f4\u6709\u6548\uff0cMENTOR\u6846\u67b6\u89e3\u51b3\u4e86RLVR\u4e2d\u63a2\u7d22\u8d28\u91cf\u548c\u591a\u6837\u6027\u7684\u5e73\u8861\u95ee\u9898\u3002"}}
{"id": "2510.04013", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04013", "abs": "https://arxiv.org/abs/2510.04013", "authors": ["Jiarui Liu", "Jivitesh Jain", "Mona Diab", "Nishant Subramani"], "title": "LLM Microscope: What Model Internals Reveal About Answer Correctness and Context Utilization", "comment": null, "summary": "Although large language models (LLMs) have tremendous utility,\ntrustworthiness is still a chief concern: models often generate incorrect\ninformation with high confidence. While contextual information can help guide\ngeneration, identifying when a query would benefit from retrieved context and\nassessing the effectiveness of that context remains challenging. In this work,\nwe operationalize interpretability methods to ascertain whether we can predict\nthe correctness of model outputs from the model's activations alone. We also\nexplore whether model internals contain signals about the efficacy of external\ncontext. We consider correct, incorrect, and irrelevant context and introduce\nmetrics to distinguish amongst them. Experiments on six different models reveal\nthat a simple classifier trained on intermediate layer activations of the first\noutput token can predict output correctness with about 75% accuracy, enabling\nearly auditing. Our model-internals-based metric significantly outperforms\nprompting baselines at distinguishing between correct and incorrect context,\nguarding against inaccuracies introduced by polluted context. These findings\noffer a lens to better understand the underlying decision-making processes of\nLLMs. Our code is publicly available at\nhttps://github.com/jiarui-liu/LLM-Microscope", "AI": {"tldr": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5185\u90e8\u6fc0\u6d3b\u4fe1\u53f7\u6765\u9884\u6d4b\u8f93\u51fa\u6b63\u786e\u6027\u548c\u4e0a\u4e0b\u6587\u6709\u6548\u6027\uff0c\u901a\u8fc7\u7b80\u5355\u5206\u7c7b\u5668\u5b9e\u73b0\u7ea675%\u7684\u51c6\u786e\u7387\uff0c\u4e3a\u6a21\u578b\u53ef\u4fe1\u5ea6\u63d0\u4f9b\u65e9\u671f\u5ba1\u8ba1\u80fd\u529b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7ecf\u5e38\u4ee5\u9ad8\u7f6e\u4fe1\u5ea6\u751f\u6210\u9519\u8bef\u4fe1\u606f\uff0c\u9700\u8981\u89e3\u51b3\u5982\u4f55\u8bc6\u522b\u67e5\u8be2\u662f\u5426\u9700\u8981\u68c0\u7d22\u4e0a\u4e0b\u6587\u4ee5\u53ca\u8bc4\u4f30\u4e0a\u4e0b\u6587\u6709\u6548\u6027\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u57fa\u4e8e\u6a21\u578b\u5185\u90e8\u6fc0\u6d3b\u4fe1\u53f7\u8bad\u7ec3\u7b80\u5355\u5206\u7c7b\u5668\uff0c\u7279\u522b\u5173\u6ce8\u7b2c\u4e00\u4e2a\u8f93\u51fatoken\u7684\u4e2d\u95f4\u5c42\u6fc0\u6d3b\uff0c\u5e76\u5f15\u5165\u6307\u6807\u533a\u5206\u6b63\u786e\u3001\u9519\u8bef\u548c\u4e0d\u76f8\u5173\u4e0a\u4e0b\u6587\u3002", "result": "\u5728\u516d\u4e2a\u4e0d\u540c\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u7b2c\u4e00\u4e2a\u8f93\u51fatoken\u4e2d\u95f4\u5c42\u6fc0\u6d3b\u7684\u5206\u7c7b\u5668\u80fd\u4ee5\u7ea675%\u7684\u51c6\u786e\u7387\u9884\u6d4b\u8f93\u51fa\u6b63\u786e\u6027\uff1b\u57fa\u4e8e\u6a21\u578b\u5185\u90e8\u6307\u6807\u7684\u8bc4\u4f30\u663e\u8457\u4f18\u4e8e\u63d0\u793a\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u6a21\u578b\u5185\u90e8\u5305\u542b\u5173\u4e8e\u8f93\u51fa\u6b63\u786e\u6027\u548c\u4e0a\u4e0b\u6587\u6709\u6548\u6027\u7684\u4fe1\u53f7\uff0c\u8fd9\u4e3a\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e95\u5c42\u51b3\u7b56\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u6709\u52a9\u4e8e\u9632\u8303\u53d7\u6c61\u67d3\u4e0a\u4e0b\u6587\u5f15\u5165\u7684\u9519\u8bef\u3002"}}
{"id": "2510.04141", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04141", "abs": "https://arxiv.org/abs/2510.04141", "authors": ["Mayank Ravishankara", "Varindra V. Persad Maharaj"], "title": "The Artificial Intelligence Cognitive Examination: A Survey on the Evolution of Multimodal Evaluation from Recognition to Reasoning", "comment": null, "summary": "This survey paper chronicles the evolution of evaluation in multimodal\nartificial intelligence (AI), framing it as a progression of increasingly\nsophisticated \"cognitive examinations.\" We argue that the field is undergoing a\nparadigm shift, moving from simple recognition tasks that test \"what\" a model\nsees, to complex reasoning benchmarks that probe \"why\" and \"how\" it\nunderstands. This evolution is driven by the saturation of older benchmarks,\nwhere high performance often masks fundamental weaknesses. We chart the journey\nfrom the foundational \"knowledge tests\" of the ImageNet era to the \"applied\nlogic and comprehension\" exams such as GQA and Visual Commonsense Reasoning\n(VCR), which were designed specifically to diagnose systemic flaws such as\nshortcut learning and failures in compositional generalization. We then survey\nthe current frontier of \"expert-level integration\" benchmarks (e.g., MMBench,\nSEED-Bench, MMMU) designed for today's powerful multimodal large language\nmodels (MLLMs), which increasingly evaluate the reasoning process itself.\nFinally, we explore the uncharted territories of evaluating abstract, creative,\nand social intelligence. We conclude that the narrative of AI evaluation is not\nmerely a history of datasets, but a continuous, adversarial process of\ndesigning better examinations that, in turn, redefine our goals for creating\ntruly intelligent systems.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u4e86\u591a\u6a21\u6001AI\u8bc4\u4f30\u7684\u6f14\u53d8\u5386\u7a0b\uff0c\u5c06\u5176\u63cf\u8ff0\u4e3a\u4ece\u7b80\u5355\u8bc6\u522b\u4efb\u52a1\u5230\u590d\u6742\u63a8\u7406\u57fa\u51c6\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u65e8\u5728\u8bbe\u8ba1\u66f4\u597d\u7684\u8ba4\u77e5\u6d4b\u8bd5\u6765\u63a8\u52a8\u771f\u6b63\u667a\u80fd\u7cfb\u7edf\u7684\u53d1\u5c55\u3002", "motivation": "\u4f20\u7edf\u57fa\u51c6\u6d4b\u8bd5\u5df2\u8d8b\u4e8e\u9971\u548c\uff0c\u9ad8\u5206\u5f80\u5f80\u63a9\u76d6\u4e86\u6a21\u578b\u7684\u57fa\u672c\u5f31\u70b9\u3002\u9700\u8981\u5f00\u53d1\u66f4\u590d\u6742\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u8bca\u65ad\u7cfb\u7edf\u6027\u7f3a\u9677\uff0c\u5982\u6377\u5f84\u5b66\u4e60\u548c\u7ec4\u5408\u6cdb\u5316\u5931\u8d25\u3002", "method": "\u901a\u8fc7\u5386\u53f2\u5206\u6790\u6846\u67b6\uff0c\u5c06\u8bc4\u4f30\u53d1\u5c55\u5206\u4e3a\u4e09\u4e2a\u9636\u6bb5\uff1aImageNet\u65f6\u4ee3\u7684\"\u77e5\u8bc6\u6d4b\u8bd5\"\u3001GQA\u548cVCR\u7b49\"\u5e94\u7528\u903b\u8f91\u4e0e\u7406\u89e3\u6d4b\u8bd5\"\uff0c\u4ee5\u53ca\u5f53\u524d\u9762\u5411MLLM\u7684\"\u4e13\u5bb6\u7ea7\u96c6\u6210\"\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u8bc6\u522b\u4e86\u8bc4\u4f30\u8303\u5f0f\u7684\u8f6c\u53d8\u8f68\u8ff9\uff1a\u4ece\u6d4b\u8bd5\"\u662f\u4ec0\u4e48\"\u5230\u63a2\u7a76\"\u4e3a\u4ec0\u4e48\"\u548c\"\u5982\u4f55\"\u7406\u89e3\uff0c\u518d\u5230\u8bc4\u4f30\u63a8\u7406\u8fc7\u7a0b\u672c\u8eab\uff0c\u6700\u7ec8\u63a2\u7d22\u62bd\u8c61\u3001\u521b\u9020\u6027\u548c\u793e\u4f1a\u667a\u80fd\u7684\u8bc4\u4f30\u3002", "conclusion": "AI\u8bc4\u4f30\u4e0d\u4ec5\u662f\u6570\u636e\u96c6\u7684\u5386\u53f2\uff0c\u800c\u662f\u4e00\u4e2a\u6301\u7eed\u5bf9\u6297\u7684\u8fc7\u7a0b\uff0c\u901a\u8fc7\u8bbe\u8ba1\u66f4\u597d\u7684\u8003\u8bd5\u6765\u91cd\u65b0\u5b9a\u4e49\u521b\u9020\u771f\u6b63\u667a\u80fd\u7cfb\u7edf\u7684\u76ee\u6807\u3002"}}
{"id": "2510.04016", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04016", "abs": "https://arxiv.org/abs/2510.04016", "authors": ["Thanapol Popit", "Natthapath Rungseesiripak", "Monthol Charattrakool", "Saksorn Ruangtanusak"], "title": "Thai Semantic End-of-Turn Detection for Real-Time Voice Agents", "comment": "IEEE ICSEC 2025", "summary": "Fluid voice-to-voice interaction requires reliable and low-latency detection\nof when a user has finished speaking. Traditional audio-silence end-pointers\nadd hundreds of milliseconds of delay and fail under hesitations or\nlanguage-specific phenomena. We present, to our knowledge, the first systematic\nstudy of Thai text-only end-of-turn (EOT) detection for real-time agents. We\ncompare zero-shot and few-shot prompting of compact LLMs to supervised\nfine-tuning of lightweight transformers. Using transcribed subtitles from the\nYODAS corpus and Thai-specific linguistic cues (e.g., sentence-final\nparticles), we formulate EOT as a binary decision over token boundaries. We\nreport a clear accuracy-latency tradeoff and provide a public-ready\nimplementation plan. This work establishes a Thai baseline and demonstrates\nthat small, fine-tuned models can deliver near-instant EOT decisions suitable\nfor on-device agents.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u6cf0\u8bed\u6587\u672c\u7aef\u5230\u7aef\u68c0\u6d4b\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e86\u96f6\u6837\u672c/\u5c11\u6837\u672c\u63d0\u793a\u4e0e\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\uff0c\u53d1\u73b0\u5c0f\u578b\u5fae\u8c03\u6a21\u578b\u80fd\u63d0\u4f9b\u8fd1\u4e4e\u5373\u65f6\u7684EOT\u51b3\u7b56\uff0c\u9002\u5408\u8bbe\u5907\u7aef\u4ee3\u7406\u4f7f\u7528\u3002", "motivation": "\u4f20\u7edf\u97f3\u9891\u9759\u97f3\u7aef\u70b9\u68c0\u6d4b\u5b58\u5728\u5ef6\u8fdf\u9ad8\u3001\u5728\u72b9\u8c6b\u6216\u8bed\u8a00\u7279\u5b9a\u73b0\u8c61\u4e0b\u5931\u6548\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u53ef\u9760\u7684\u5b9e\u65f6\u8bed\u97f3\u4ea4\u4e92\u7aef\u70b9\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528YODAS\u8bed\u6599\u5e93\u7684\u8f6c\u5f55\u5b57\u5e55\u548c\u6cf0\u8bed\u7279\u5b9a\u8bed\u8a00\u7ebf\u7d22\uff0c\u5c06EOT\u5236\u5b9a\u4e3a\u57fa\u4e8e\u8bcd\u5143\u8fb9\u754c\u7684\u4e8c\u5143\u51b3\u7b56\uff0c\u6bd4\u8f83\u4e86\u7d27\u51d1LLM\u7684\u96f6\u6837\u672c/\u5c11\u6837\u672c\u63d0\u793a\u4e0e\u8f7b\u91cf\u7ea7transformer\u7684\u76d1\u7763\u5fae\u8c03\u3002", "result": "\u62a5\u544a\u4e86\u6e05\u6670\u7684\u51c6\u786e\u7387-\u5ef6\u8fdf\u6743\u8861\uff0c\u5c0f\u578b\u5fae\u8c03\u6a21\u578b\u80fd\u591f\u63d0\u4f9b\u8fd1\u4e4e\u5373\u65f6\u7684EOT\u51b3\u7b56\u3002", "conclusion": "\u5efa\u7acb\u4e86\u6cf0\u8bed\u57fa\u7ebf\uff0c\u8bc1\u660e\u5c0f\u578b\u5fae\u8c03\u6a21\u578b\u9002\u5408\u8bbe\u5907\u7aef\u4ee3\u7406\u7684\u5b9e\u65f6EOT\u68c0\u6d4b\u9700\u6c42\u3002"}}
{"id": "2510.04173", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04173", "abs": "https://arxiv.org/abs/2510.04173", "authors": ["Yassine Benajiba", "Cesare Bernardis", "Vladislav Blinov", "Paul Cayet", "Hassan Chafi", "Abderrahim Fathan", "Louis Faucon", "Damien Hilloulin", "Sungpack Hong", "Ingo Kossyk", "Rhicheek Patra", "Sujith Ravi", "Jonas Schweizer", "Jyotika Singh", "Shailender Singh", "Xuelin Situ", "Weiyi Sun", "Jerry Xu", "Ying Xu"], "title": "Open Agent Specification (Agent Spec) Technical Report", "comment": null, "summary": "Open Agent Specification (Agent Spec) is a declarative language that allows\nAI agents and their workflows to be defined in a way that is compatible across\ndifferent AI frameworks, promoting portability and interoperability within AI\nAgent frameworks.\n  Agent Spec aims to resolve the challenges of fragmented agent development by\nproviding a common unified specification that allows AI agents to be designed\nonce and deployed across various frameworks, improving interoperability and\nreusability, and reducing redundant development efforts. Additionally, Agent\nSpec facilitates development tools and portability, allowing AI agents to be\ndefined independently of their execution environment and enabling teams to\nexchange solutions without implementation-specific limitations.\n  Agent Spec benefits four key groups: (i) Agent developers, who gain access to\na superset of reusable components and design patterns, enabling them to\nleverage a broader range of functionalities; (ii) Agent framework and tool\ndevelopers, who can use Agent Spec as an interchange format and therefore\nbenefit from the support of other frameworks as well as other tools; (iii)\nResearchers, who can achieve reproducible results and comparability,\nfacilitating more reliable and consistent outcomes; (iv) Enterprises, which\nbenefit from faster prototype-to-deployment, increased productivity, as well as\ngreater scalability and maintainability for their AI agent solutions. This\ntechnical report provides an overview of the technical foundations of Agent\nSpec, including motivation, benefits, and future developments.", "AI": {"tldr": "Open Agent Specification (Agent Spec) \u662f\u4e00\u79cd\u58f0\u660e\u5f0f\u8bed\u8a00\uff0c\u7528\u4e8e\u5b9a\u4e49AI\u4ee3\u7406\u53ca\u5176\u5de5\u4f5c\u6d41\uff0c\u5b9e\u73b0\u8de8AI\u6846\u67b6\u7684\u517c\u5bb9\u6027\u3001\u53ef\u79fb\u690d\u6027\u548c\u4e92\u64cd\u4f5c\u6027\u3002", "motivation": "\u89e3\u51b3AI\u4ee3\u7406\u5f00\u53d1\u788e\u7247\u5316\u95ee\u9898\uff0c\u63d0\u4f9b\u7edf\u4e00\u89c4\u8303\uff0c\u4f7fAI\u4ee3\u7406\u80fd\u591f\u4e00\u6b21\u8bbe\u8ba1\u3001\u8de8\u6846\u67b6\u90e8\u7f72\uff0c\u63d0\u9ad8\u4e92\u64cd\u4f5c\u6027\u548c\u53ef\u91cd\u7528\u6027\uff0c\u51cf\u5c11\u91cd\u590d\u5f00\u53d1\u5de5\u4f5c\u3002", "method": "\u4f7f\u7528\u58f0\u660e\u5f0f\u8bed\u8a00\u5b9a\u4e49AI\u4ee3\u7406\u548c\u5de5\u4f5c\u6d41\uff0c\u4f7f\u5176\u72ec\u7acb\u4e8e\u6267\u884c\u73af\u5883\uff0c\u652f\u6301\u5f00\u53d1\u5de5\u5177\u548c\u53ef\u79fb\u690d\u6027\u3002", "result": "\u4e3a\u56db\u7c7b\u5173\u952e\u7fa4\u4f53\u5e26\u6765\u76ca\u5904\uff1a\u4ee3\u7406\u5f00\u53d1\u8005\u83b7\u5f97\u53ef\u91cd\u7528\u7ec4\u4ef6\u548c\u8bbe\u8ba1\u6a21\u5f0f\uff1b\u6846\u67b6\u548c\u5de5\u5177\u5f00\u53d1\u8005\u83b7\u5f97\u4ea4\u6362\u683c\u5f0f\u652f\u6301\uff1b\u7814\u7a76\u4eba\u5458\u5b9e\u73b0\u53ef\u590d\u73b0\u7ed3\u679c\u548c\u53ef\u6bd4\u6027\uff1b\u4f01\u4e1a\u83b7\u5f97\u4ece\u539f\u578b\u5230\u90e8\u7f72\u7684\u52a0\u901f\u3001\u751f\u4ea7\u529b\u63d0\u5347\u4ee5\u53ca\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u3002", "conclusion": "Agent Spec \u63d0\u4f9b\u4e86\u6280\u672f\u57fa\u7840\uff0c\u4fc3\u8fdbAI\u4ee3\u7406\u5f00\u53d1\u7684\u6807\u51c6\u5316\u548c\u4e92\u64cd\u4f5c\u6027\uff0c\u4e3a\u672a\u6765AI\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\u7684\u53d1\u5c55\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2510.04031", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04031", "abs": "https://arxiv.org/abs/2510.04031", "authors": ["Nelvin Tan", "James Asikin Cheung", "Yu-Ching Shih", "Dong Yang", "Amol Salunkhe"], "title": "Does Using Counterfactual Help LLMs Explain Textual Importance in Classification?", "comment": "8 pages, 2 figures", "summary": "Large language models (LLMs) are becoming useful in many domains due to their\nimpressive abilities that arise from large training datasets and large model\nsizes. More recently, they have been shown to be very effective in textual\nclassification tasks, motivating the need to explain the LLMs' decisions.\nMotivated by practical constrains where LLMs are black-boxed and LLM calls are\nexpensive, we study how incorporating counterfactuals into LLM reasoning can\naffect the LLM's ability to identify the top words that have contributed to its\nclassification decision. To this end, we introduce a framework called the\ndecision changing rate that helps us quantify the importance of the top words\nin classification. Our experimental results show that using counterfactuals can\nbe helpful.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5728LLM\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u901a\u8fc7\u5f15\u5165\u53cd\u4e8b\u5b9e\u63a8\u7406\u6765\u8bc6\u522b\u5f71\u54cd\u5206\u7c7b\u51b3\u7b56\u7684\u5173\u952e\u8bcd\uff0c\u5e76\u63d0\u51fa\u4e86\u51b3\u7b56\u6539\u53d8\u7387\u6846\u67b6\u6765\u91cf\u5316\u8fd9\u4e9b\u8bcd\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u7531\u4e8eLLMs\u901a\u5e38\u4f5c\u4e3a\u9ed1\u76d2\u6a21\u578b\u4e14\u8c03\u7528\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u65b9\u6cd5\u6765\u89e3\u91ca\u5176\u5206\u7c7b\u51b3\u7b56\uff0c\u7279\u522b\u662f\u8bc6\u522b\u5bf9\u51b3\u7b56\u6709\u91cd\u8981\u8d21\u732e\u7684\u5173\u952e\u8bcd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u53cd\u4e8b\u5b9e\u63a8\u7406\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8ba1\u7b97\u51b3\u7b56\u6539\u53d8\u7387\u6765\u91cf\u5316\u5173\u952e\u8bcd\u5728\u5206\u7c7b\u51b3\u7b56\u4e2d\u7684\u91cd\u8981\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528\u53cd\u4e8b\u5b9e\u63a8\u7406\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u8bc6\u522b\u5f71\u54cdLLM\u5206\u7c7b\u51b3\u7b56\u7684\u5173\u952e\u8bcd\u3002", "conclusion": "\u53cd\u4e8b\u5b9e\u63a8\u7406\u662f\u89e3\u91caLLM\u5206\u7c7b\u51b3\u7b56\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u51b3\u7b56\u6539\u53d8\u7387\u6846\u67b6\u80fd\u591f\u53ef\u9760\u5730\u91cf\u5316\u5173\u952e\u8bcd\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.04195", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04195", "abs": "https://arxiv.org/abs/2510.04195", "authors": ["Puzhen Zhang", "Xuyang Chen", "Yu Feng", "Yuhan Jiang", "Liqiu Meng"], "title": "Constructing coherent spatial memory in LLM agents through graph rectification", "comment": null, "summary": "Given a map description through global traversal navigation instructions\n(e.g., visiting each room sequentially with action signals such as north, west,\netc.), an LLM can often infer the implicit spatial layout of the environment\nand answer user queries by providing a shortest path from a start to a\ndestination (for instance, navigating from the lobby to a meeting room via the\nhall and elevator). However, such context-dependent querying becomes incapable\nas the environment grows much longer, motivating the need for incremental map\nconstruction that builds a complete topological graph from stepwise\nobservations. We propose a framework for LLM-driven construction and map\nrepair, designed to detect, localize, and correct structural inconsistencies in\nincrementally constructed navigation graphs. Central to our method is the\nVersion Control, which records the full history of graph edits and their source\nobservations, enabling fine-grained rollback, conflict tracing, and repair\nevaluation. We further introduce an Edge Impact Score to prioritize\nminimal-cost repairs based on structural reachability, path usage, and conflict\npropagation. To properly evaluate our approach, we create a refined version of\nthe MANGO benchmark dataset by systematically removing non-topological actions\nand inherent structural conflicts, providing a cleaner testbed for LLM-driven\nconstruction and map repair. Our approach significantly improves map\ncorrectness and robustness, especially in scenarios with entangled or chained\ninconsistencies. Our results highlight the importance of introspective,\nhistory-aware repair mechanisms for maintaining coherent spatial memory in LLM\nagents.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2aLLM\u9a71\u52a8\u7684\u589e\u91cf\u5730\u56fe\u6784\u5efa\u548c\u4fee\u590d\u6846\u67b6\uff0c\u901a\u8fc7\u7248\u672c\u63a7\u5236\u8bb0\u5f55\u5b8c\u6574\u7f16\u8f91\u5386\u53f2\uff0c\u4f7f\u7528\u8fb9\u7f18\u5f71\u54cd\u8bc4\u5206\u4f18\u5148\u6700\u5c0f\u6210\u672c\u4fee\u590d\uff0c\u5728MANGO\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u5730\u56fe\u6b63\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u968f\u7740\u73af\u5883\u89c4\u6a21\u6269\u5927\uff0c\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u67e5\u8be2\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u957f\u5e8f\u5217\u5bfc\u822a\u6307\u4ee4\uff0c\u9700\u8981\u589e\u91cf\u6784\u5efa\u5b8c\u6574\u62d3\u6251\u56fe\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u7ed3\u6784\u4e0d\u4e00\u81f4\u6027\u7684\u68c0\u6d4b\u3001\u5b9a\u4f4d\u548c\u4fee\u590d\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u7248\u672c\u63a7\u5236\u8bb0\u5f55\u56fe\u7f16\u8f91\u5386\u53f2\u548c\u6765\u6e90\u89c2\u5bdf\uff0c\u5f15\u5165\u8fb9\u7f18\u5f71\u54cd\u8bc4\u5206\u57fa\u4e8e\u7ed3\u6784\u53ef\u8fbe\u6027\u3001\u8def\u5f84\u4f7f\u7528\u548c\u51b2\u7a81\u4f20\u64ad\u6765\u4f18\u5148\u6700\u5c0f\u6210\u672c\u4fee\u590d\uff0c\u521b\u5efa\u4e86\u6e05\u7406\u540e\u7684MANGO\u57fa\u51c6\u6570\u636e\u96c6\u3002", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5730\u56fe\u6b63\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u7ea0\u7f20\u6216\u94fe\u5f0f\u4e0d\u4e00\u81f4\u6027\u7684\u573a\u666f\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5185\u7701\u3001\u5386\u53f2\u611f\u77e5\u7684\u4fee\u590d\u673a\u5236\u5bf9\u4e8e\u7ef4\u62a4LLM\u667a\u80fd\u4f53\u8fde\u8d2f\u7a7a\u95f4\u8bb0\u5fc6\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.04032", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04032", "abs": "https://arxiv.org/abs/2510.04032", "authors": ["Zirui Wang", "Jiajun Wu", "Braden Teitge", "Jessalyn Holodinsky", "Steve Drew"], "title": "Small Language Models for Emergency Departments Decision Support: A Benchmark Study", "comment": "Accepted to 2025 IEEE International Conference on Autonomous and\n  Trusted Computing (ATC 2025)", "summary": "Large language models (LLMs) have become increasingly popular in medical\ndomains to assist physicians with a variety of clinical and operational tasks.\nGiven the fast-paced and high-stakes environment of emergency departments\n(EDs), small language models (SLMs), characterized by a reduction in parameter\ncount compared to LLMs, offer significant potential due to their inherent\nreasoning capability and efficient performance. This enables SLMs to support\nphysicians by providing timely and accurate information synthesis, thereby\nimproving clinical decision-making and workflow efficiency. In this paper, we\npresent a comprehensive benchmark designed to identify SLMs suited for ED\ndecision support, taking into account both specialized medical expertise and\nbroad general problem-solving capabilities. In our evaluations, we focus on\nSLMs that have been trained on a mixture of general-domain and medical corpora.\nA key motivation for emphasizing SLMs is the practical hardware limitations,\noperational cost constraints, and privacy concerns in the typical real-world\ndeployments. Our benchmark datasets include MedMCQA, MedQA-4Options, and\nPubMedQA, with the medical abstracts dataset emulating tasks aligned with real\nED physicians' daily tasks. Experimental results reveal that general-domain\nSLMs surprisingly outperform their medically fine-tuned counterparts across\nthese diverse benchmarks for ED. This indicates that for ED, specialized\nmedical fine-tuning of the model may not be required.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u6025\u8bca\u90e8\u95e8\u7684SLM\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u901a\u7528\u9886\u57df\u7684\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u6025\u8bca\u51b3\u7b56\u652f\u6301\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u533b\u5b66\u5fae\u8c03\u7684\u6a21\u578b\uff0c\u8868\u660e\u6025\u8bca\u573a\u666f\u53ef\u80fd\u4e0d\u9700\u8981\u4e13\u95e8\u7684\u533b\u5b66\u5fae\u8c03\u3002", "motivation": "\u6025\u8bca\u90e8\u95e8\u9700\u8981\u5feb\u901f\u51c6\u786e\u7684\u51b3\u7b56\u652f\u6301\uff0cSLM\u56e0\u5176\u63a8\u7406\u80fd\u529b\u548c\u9ad8\u6548\u6027\u80fd\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u9762\u4e34\u786c\u4ef6\u9650\u5236\u3001\u8fd0\u8425\u6210\u672c\u548c\u9690\u79c1\u95ee\u9898\u3002", "method": "\u6784\u5efa\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f7f\u7528MedMCQA\u3001MedQA-4Options\u548cPubMedQA\u6570\u636e\u96c6\uff0c\u6a21\u62df\u6025\u8bca\u533b\u751f\u65e5\u5e38\u4efb\u52a1\uff0c\u8bc4\u4f30\u5728\u901a\u7528\u548c\u533b\u5b66\u8bed\u6599\u4e0a\u8bad\u7ec3\u7684SLM\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u901a\u7528\u9886\u57dfSLM\u5728\u6025\u8bca\u76f8\u5173\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u610f\u5916\u5730\u4f18\u4e8e\u533b\u5b66\u5fae\u8c03\u7684SLM\u3002", "conclusion": "\u5bf9\u4e8e\u6025\u8bca\u90e8\u95e8\uff0c\u4e13\u95e8\u7684\u533b\u5b66\u6a21\u578b\u5fae\u8c03\u53ef\u80fd\u4e0d\u662f\u5fc5\u9700\u7684\uff0c\u901a\u7528\u9886\u57dfSLM\u5df2\u80fd\u63d0\u4f9b\u8db3\u591f\u7684\u51b3\u7b56\u652f\u6301\u80fd\u529b\u3002"}}
{"id": "2510.04196", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04196", "abs": "https://arxiv.org/abs/2510.04196", "authors": ["Yizhuo Ding", "Mingkang Chen", "Qiuhua Liu", "Fenghua Weng", "Wanying Qu", "Yue Yang", "Yugang Jiang", "Zuxuan Wu", "Yanwei Fu", "Wenqi Shao"], "title": "COSMO-RL: Towards Trustworthy LMRMs via Joint Safety and Stability", "comment": null, "summary": "Large Multimodal Reasoning Models (LMRMs) are moving into real applications,\nwhere they must be both useful and safe. Safety is especially challenging in\nmultimodal settings: images and text can be combined to bypass guardrails, and\nsingle objective training can cause policy drift that yields over-refusal on\nbenign inputs or unsafe compliance on risky ones. We present COSMO-RL, a mixed\nreinforcement learning framework that trains reasoning oriented LMRMs under\nmultimodal, multitask, and multiobjective signals, and we release the resulting\nmodel, COSMO-R1. Our approach aims to let safety and capability grow together\nin one stable pipeline rather than competing during alignment. In experiments,\nCOSMO-R1 improves safety while maintaining-and often improving multimodal\nreasoning and instruction following, shows stronger robustness to multimodal\njailbreaks, and reduces unnecessary refusals. The framework also transfers\nacross backbones with consistent gains. Ablations support the design choices,\nindicating a simple path to advancing safety and general capability together in\nLMRMs.", "AI": {"tldr": "COSMO-RL\u662f\u4e00\u4e2a\u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u8bad\u7ec3\u9762\u5411\u63a8\u7406\u7684\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff0c\u901a\u8fc7\u591a\u4efb\u52a1\u591a\u76ee\u6807\u4fe1\u53f7\u5b9e\u73b0\u5b89\u5168\u6027\u548c\u80fd\u529b\u7684\u5171\u540c\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u73af\u5883\u4e2d\u6a21\u578b\u5b89\u5168\u6027\u7684\u6311\u6218\uff0c\u5982\u56fe\u6587\u7ed3\u5408\u7ed5\u8fc7\u9632\u62a4\u63aa\u65bd\uff0c\u4ee5\u53ca\u5355\u4e00\u76ee\u6807\u8bad\u7ec3\u5bfc\u81f4\u7684\u5b89\u5168\u7b56\u7565\u6f02\u79fb\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u6df7\u5408\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u591a\u6a21\u6001\u3001\u591a\u4efb\u52a1\u548c\u591a\u76ee\u6807\u4fe1\u53f7\u4e0b\u8bad\u7ec3\u63a8\u7406\u5bfc\u5411\u7684\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u3002", "result": "COSMO-R1\u6a21\u578b\u5728\u63d0\u5347\u5b89\u5168\u6027\u7684\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u6539\u5584\u4e86\u591a\u6a21\u6001\u63a8\u7406\u548c\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\uff0c\u5bf9\u591a\u6a21\u6001\u8d8a\u72f1\u653b\u51fb\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u51cf\u5c11\u4e86\u4e0d\u5fc5\u8981\u7684\u62d2\u7edd\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u6761\u7b80\u5355\u8def\u5f84\uff0c\u53ef\u5728\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u4e2d\u540c\u65f6\u63a8\u8fdb\u5b89\u5168\u6027\u548c\u901a\u7528\u80fd\u529b\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.04045", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04045", "abs": "https://arxiv.org/abs/2510.04045", "authors": ["Yunfan Zhang", "Kathleen McKeown", "Smaranda Muresan"], "title": "Exploring Chain-of-Thought Reasoning for Steerable Pluralistic Alignment", "comment": "ACL EMNLP 2025", "summary": "Large Language Models (LLMs) are typically trained to reflect a relatively\nuniform set of values, which limits their applicability to tasks that require\nunderstanding of nuanced human perspectives. Recent research has underscored\nthe importance of enabling LLMs to support steerable pluralism -- the capacity\nto adopt a specific perspective and align generated outputs with it. In this\nwork, we investigate whether Chain-of-Thought (CoT) reasoning techniques can be\napplied to building steerable pluralistic models. We explore several methods,\nincluding CoT prompting, fine-tuning on human-authored CoT, fine-tuning on\nsynthetic explanations, and Reinforcement Learning with Verifiable Rewards\n(RLVR). We evaluate these approaches using the Value Kaleidoscope and OpinionQA\ndatasets. Among the methods studied, RLVR consistently outperforms others and\ndemonstrates strong training sample efficiency. We further analyze the\ngenerated CoT traces with respect to faithfulness and safety.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u4e86\u5982\u4f55\u901a\u8fc7\u601d\u7ef4\u94fe\u63a8\u7406\u6280\u672f\u6784\u5efa\u53ef\u5f15\u5bfc\u7684\u591a\u5143\u5316\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\u65b9\u6cd5\u5728\u6548\u679c\u548c\u6837\u672c\u6548\u7387\u4e0a\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u53cd\u6620\u76f8\u5bf9\u7edf\u4e00\u7684\u4ef7\u503c\u89c2\u5ff5\uff0c\u9650\u5236\u4e86\u5176\u5728\u9700\u8981\u7406\u89e3\u7ec6\u5fae\u4eba\u7c7b\u89c2\u70b9\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u80fd\u591f\u652f\u6301\u53ef\u5f15\u5bfc\u591a\u5143\u5316\u7684\u6a21\u578b\u80fd\u529b\u3002", "method": "\u63a2\u7d22\u4e86\u591a\u79cd\u65b9\u6cd5\uff1a\u601d\u7ef4\u94fe\u63d0\u793a\u3001\u57fa\u4e8e\u4eba\u5de5\u7f16\u5199\u601d\u7ef4\u94fe\u7684\u5fae\u8c03\u3001\u57fa\u4e8e\u5408\u6210\u89e3\u91ca\u7684\u5fae\u8c03\uff0c\u4ee5\u53ca\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\u65b9\u6cd5\u3002", "result": "\u5728\u7814\u7a76\u7684\u5404\u79cd\u65b9\u6cd5\u4e2d\uff0c\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u5e76\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u8bad\u7ec3\u6837\u672c\u6548\u7387\u3002", "conclusion": "\u601d\u7ef4\u94fe\u63a8\u7406\u6280\u672f\u53ef\u4ee5\u6709\u6548\u6784\u5efa\u53ef\u5f15\u5bfc\u7684\u591a\u5143\u5316\u6a21\u578b\uff0c\u5176\u4e2d\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\u662f\u6700\u6709\u524d\u666f\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u751f\u6210\u7684\u601d\u7ef4\u94fe\u5728\u5fe0\u5b9e\u6027\u548c\u5b89\u5168\u6027\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2510.04206", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04206", "abs": "https://arxiv.org/abs/2510.04206", "authors": ["Hanchen Zhang", "Xiao Liu", "Bowen Lv", "Xueqiao Sun", "Bohao Jing", "Iat Long Iong", "Zhenyu Hou", "Zehan Qi", "Hanyu Lai", "Yifan Xu", "Rui Lu", "Hongning Wang", "Jie Tang", "Yuxiao Dong"], "title": "AgentRL: Scaling Agentic Reinforcement Learning with a Multi-Turn, Multi-Task Framework", "comment": null, "summary": "Recent advances in large language models (LLMs) have sparked growing interest\nin building generalist agents that can learn through online interactions.\nHowever, applying reinforcement learning (RL) to train LLM agents in\nmulti-turn, multi-task settings remains challenging due to lack of scalable\ninfrastructure and stable training algorithms. In this work, we present the\nAgentRL framework for scalable multi-turn, multi-task agentic RL training. On\nthe infrastructure side, AgentRL features a fully-asynchronous\ngeneration-training pipeline for efficient multi-turn RL. To support\nheterogeneous environment development in multi-task RL, we design a unified\nfunction-call based API interface, containerized environment development, and a\ncentralized controller. On the algorithm side, we propose cross-policy sampling\nto encourage model exploration in multi-turn settings and task advantage\nnormalization to stabilize multi-task training. Experiments show that AgentRL,\ntrained on open LLMs across five agentic tasks, significantly outperforms\nGPT-5, Clause-Sonnet-4, DeepSeek-R1, and other open-source LLM agents.\nMulti-task training with AgentRL matches the best results among all\ntask-specific models. AgentRL is open-sourced at\nhttps://github.com/THUDM/AgentRL. The algorithm and framework are adopted in\nbuilding \\textsc{\\href{https://autoglm.zhipuai.cn}{AutoGLM}}.", "AI": {"tldr": "\u63d0\u51fa\u4e86AgentRL\u6846\u67b6\uff0c\u7528\u4e8e\u53ef\u6269\u5c55\u7684\u591a\u8f6e\u591a\u4efb\u52a1\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u5305\u542b\u5f02\u6b65\u751f\u6210-\u8bad\u7ec3\u7ba1\u9053\u548c\u7edf\u4e00API\u63a5\u53e3\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6784\u5efa\u901a\u7528\u667a\u80fd\u4f53\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5728\u591a\u8f6e\u591a\u4efb\u52a1\u8bbe\u7f6e\u4e2d\u5e94\u7528\u5f3a\u5316\u5b66\u4e60\u4ecd\u9762\u4e34\u57fa\u7840\u8bbe\u65bd\u548c\u8bad\u7ec3\u7b97\u6cd5\u6311\u6218\u3002", "method": "\u91c7\u7528\u5b8c\u5168\u5f02\u6b65\u7684\u751f\u6210-\u8bad\u7ec3\u7ba1\u9053\u5b9e\u73b0\u9ad8\u6548\u591a\u8f6eRL\uff1b\u8bbe\u8ba1\u57fa\u4e8e\u51fd\u6570\u8c03\u7528\u7684\u7edf\u4e00API\u63a5\u53e3\u3001\u5bb9\u5668\u5316\u73af\u5883\u5f00\u53d1\u548c\u96c6\u4e2d\u63a7\u5236\u5668\u652f\u6301\u5f02\u6784\u73af\u5883\uff1b\u63d0\u51fa\u8de8\u7b56\u7565\u91c7\u6837\u548c\u4efb\u52a1\u4f18\u52bf\u5f52\u4e00\u5316\u7b97\u6cd5\u3002", "result": "\u5728\u4e94\u4e2a\u667a\u80fd\u4f53\u4efb\u52a1\u4e0a\uff0cAgentRL\u663e\u8457\u4f18\u4e8eGPT-5\u3001Clause-Sonnet-4\u3001DeepSeek-R1\u7b49\u6a21\u578b\uff1b\u591a\u4efb\u52a1\u8bad\u7ec3\u7ed3\u679c\u4e0e\u6240\u6709\u4efb\u52a1\u4e13\u7528\u6a21\u578b\u7684\u6700\u4f73\u7ed3\u679c\u76f8\u5f53\u3002", "conclusion": "AgentRL\u4e3a\u591a\u8f6e\u591a\u4efb\u52a1\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5df2\u5728AutoGLM\u7cfb\u7edf\u4e2d\u91c7\u7528\u5e76\u5f00\u6e90\u3002"}}
{"id": "2510.04071", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04071", "abs": "https://arxiv.org/abs/2510.04071", "authors": ["Zitian Gao", "Haoming Luo", "Lynx Chen", "Jason Klein Liu", "Ran Tao", "Joey Zhou", "Bryan Dai"], "title": "What Makes Diffusion Language Models Super Data Learners?", "comment": "Technical report, work in progress", "summary": "Recent studies have shown that diffusion language models achieve remarkable\ndata efficiency under limited-data constraints, yet the underlying mechanisms\nremain unclear. In this work, we perform extensive ablation experiments to\ndisentangle the sources of this efficiency. Our results show that random\nmasking of input tokens plays the dominant role. We further show that similar\ngains can be obtained through in MLP dropout and weight decay, indicating that\nstochastic regularization broadly enhances data efficiency in multi-epoch\ntraining. Our code is available at\nhttps://github.com/zitian-gao/data-efficiency.", "AI": {"tldr": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5728\u6709\u9650\u6570\u636e\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u663e\u8457\u7684\u6570\u636e\u6548\u7387\uff0c\u7814\u7a76\u53d1\u73b0\u968f\u673a\u63a9\u7801\u662f\u4e3b\u8981\u539f\u56e0\uff0c\u7c7b\u4f3c\u6548\u679c\u53ef\u901a\u8fc7MLP dropout\u548c\u6743\u91cd\u8870\u51cf\u5b9e\u73b0\uff0c\u8868\u660e\u968f\u673a\u6b63\u5219\u5316\u5728\u591a\u8f6e\u8bad\u7ec3\u4e2d\u5e7f\u6cdb\u63d0\u5347\u6570\u636e\u6548\u7387\u3002", "motivation": "\u63a2\u7a76\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5728\u6709\u9650\u6570\u636e\u7ea6\u675f\u4e0b\u5b9e\u73b0\u5353\u8d8a\u6570\u636e\u6548\u7387\u7684\u6f5c\u5728\u673a\u5236\uff0c\u76ee\u524d\u8fd9\u4e9b\u673a\u5236\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u6d88\u878d\u5b9e\u9a8c\u6765\u5206\u79bb\u6570\u636e\u6548\u7387\u7684\u6765\u6e90\uff0c\u5206\u6790\u968f\u673a\u63a9\u7801\u3001MLP dropout\u548c\u6743\u91cd\u8870\u51cf\u7b49\u4e0d\u540c\u56e0\u7d20\u7684\u5f71\u54cd\u3002", "result": "\u968f\u673a\u63a9\u7801\u5728\u8f93\u5165\u6807\u8bb0\u4e2d\u8d77\u4e3b\u5bfc\u4f5c\u7528\uff0c\u7c7b\u4f3c\u7684\u6570\u636e\u6548\u7387\u589e\u76ca\u53ef\u4ee5\u901a\u8fc7MLP dropout\u548c\u6743\u91cd\u8870\u51cf\u83b7\u5f97\u3002", "conclusion": "\u968f\u673a\u6b63\u5219\u5316\u5728\u591a\u8f6e\u8bad\u7ec3\u4e2d\u5e7f\u6cdb\u589e\u5f3a\u6570\u636e\u6548\u7387\uff0c\u8fd9\u4e3a\u7406\u89e3\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u6570\u636e\u6548\u7387\u673a\u5236\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2510.04265", "categories": ["cs.AI", "cs.CL", "math.ST", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.04265", "abs": "https://arxiv.org/abs/2510.04265", "authors": ["Mohsen Hariri", "Amirhossein Samandar", "Michael Hinczewski", "Vipin Chaudhary"], "title": "Don't Pass$\\mathtt{@}k$: A Bayesian Framework for Large Language Model Evaluation", "comment": "Code and simulations: https://mohsenhariri.github.io/bayes-kit", "summary": "Pass$@k$ is widely used to report performance for LLM reasoning, but it often\nyields unstable, misleading rankings, especially when the number of trials\n(samples) is limited and compute is constrained. We present a principled\nBayesian evaluation framework that replaces Pass$@k$ and average accuracy over\n$N$ trials (avg$@N$) with posterior estimates of a model's underlying success\nprobability and credible intervals, yielding stable rankings and a transparent\ndecision rule for differences. Evaluation outcomes are modeled as categorical\n(not just 0/1) with a Dirichlet prior, giving closed-form expressions for the\nposterior mean and uncertainty of any weighted rubric and enabling the use of\nprior evidence when appropriate. Theoretically, under a uniform prior, the\nBayesian posterior mean is order-equivalent to average accuracy (Pass$@1$),\nexplaining its empirical robustness while adding principled uncertainty.\nEmpirically, in simulations with known ground-truth success rates and on\nAIME'24/'25, HMMT'25, and BrUMO'25, the Bayesian/avg procedure achieves faster\nconvergence and greater rank stability than Pass$@k$ and recent variants,\nenabling reliable comparisons at far smaller sample counts. The framework\nclarifies when observed gaps are statistically meaningful (non-overlapping\ncredible intervals) versus noise, and it naturally extends to graded,\nrubric-based evaluations. Together, these results recommend replacing Pass$@k$\nfor LLM evaluation and ranking with a posterior-based, compute-efficient\nprotocol that unifies binary and non-binary evaluation while making uncertainty\nexplicit. Code is available at https://mohsenhariri.github.io/bayes-kit", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8d1d\u53f6\u65af\u8bc4\u4f30\u6846\u67b6\u6765\u66ff\u4ee3Pass@k\uff0c\u901a\u8fc7\u540e\u9a8c\u4f30\u8ba1\u6a21\u578b\u7684\u6f5c\u5728\u6210\u529f\u6982\u7387\u548c\u53ef\u4fe1\u533a\u95f4\uff0c\u63d0\u4f9b\u66f4\u7a33\u5b9a\u7684\u6a21\u578b\u6392\u540d\u548c\u900f\u660e\u7684\u5dee\u5f02\u51b3\u7b56\u89c4\u5219\u3002", "motivation": "Pass@k\u5728LLM\u63a8\u7406\u8bc4\u4f30\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5728\u8bd5\u9a8c\u6b21\u6570\u6709\u9650\u548c\u8ba1\u7b97\u53d7\u9650\u65f6\u4f1a\u4ea7\u751f\u4e0d\u7a33\u5b9a\u3001\u8bef\u5bfc\u6027\u7684\u6392\u540d\u7ed3\u679c\u3002", "method": "\u4f7f\u7528\u72c4\u5229\u514b\u96f7\u5148\u9a8c\u5c06\u8bc4\u4f30\u7ed3\u679c\u5efa\u6a21\u4e3a\u5206\u7c7b\u53d8\u91cf\uff0c\u4e3a\u4efb\u4f55\u52a0\u6743\u8bc4\u5206\u6807\u51c6\u63d0\u4f9b\u540e\u9a8c\u5747\u503c\u548c\u4e0d\u786e\u5b9a\u6027\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u5141\u8bb8\u5728\u9002\u5f53\u65f6\u4f7f\u7528\u5148\u9a8c\u8bc1\u636e\u3002", "result": "\u5728\u5df2\u77e5\u771f\u5b9e\u6210\u529f\u7387\u7684\u6a21\u62df\u5b9e\u9a8c\u548cAIME'24/'25\u3001HMMT'25\u3001BrUMO'25\u7b49\u6570\u636e\u96c6\u4e0a\uff0c\u8d1d\u53f6\u65af/\u5e73\u5747\u65b9\u6cd5\u6bd4Pass@k\u53ca\u5176\u53d8\u4f53\u5b9e\u73b0\u66f4\u5feb\u7684\u6536\u655b\u548c\u66f4\u9ad8\u7684\u6392\u540d\u7a33\u5b9a\u6027\uff0c\u5728\u66f4\u5c0f\u6837\u672c\u91cf\u4e0b\u5b9e\u73b0\u53ef\u9760\u6bd4\u8f83\u3002", "conclusion": "\u63a8\u8350\u7528\u57fa\u4e8e\u540e\u9a8c\u7684\u8ba1\u7b97\u9ad8\u6548\u534f\u8bae\u66ff\u4ee3Pass@k\u8fdb\u884cLLM\u8bc4\u4f30\u548c\u6392\u540d\uff0c\u8be5\u534f\u8bae\u7edf\u4e00\u4e86\u4e8c\u5143\u548c\u975e\u4e8c\u5143\u8bc4\u4f30\uff0c\u540c\u65f6\u660e\u786e\u8868\u8fbe\u4e0d\u786e\u5b9a\u6027\u3002"}}
{"id": "2510.04080", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04080", "abs": "https://arxiv.org/abs/2510.04080", "authors": ["Zixin Song", "Bowen Zhang", "Qian-Wen Zhang", "Di Yin", "Xing Sun", "Chunping Li"], "title": "PoLi-RL: A Point-to-List Reinforcement Learning Framework for Conditional Semantic Textual Similarity", "comment": null, "summary": "Conditional Semantic Textual Similarity (C-STS) measures the semantic\nproximity between text segments under a specific condition, thereby overcoming\nthe ambiguity inherent in traditional STS. However, existing methods are\nlargely confined to discriminative models, failing to fully integrate recent\nbreakthroughs in the NLP community concerning Large Language Models (LLMs) and\nReinforcement Learning (RL). RL is a particularly well-suited paradigm for this\ntask, as it can directly optimize the non-differentiable Spearman ranking\nmetric and guide the reasoning process required by C-STS. However, we find that\nnaively applying listwise RL fails to produce meaningful improvements, as the\nmodel is overwhelmed by complex, coarse-grained reward signals. To address this\nchallenge, we introduce PoLi-RL, a novel Point-to-List Reinforcement Learning\nframework. PoLi-RL employs a two-stage curriculum: it first trains the model\nwith simple pointwise rewards to establish fundamental scoring capabilities,\nthen transitions to a hybrid reward that combines pointwise, pairwise, and\nlistwise objectives to refine the model's ability to discern subtle semantic\ndistinctions. Crucially, we propose an innovative Parallel Slice Ranking Reward\n(PSRR) mechanism that computes ranking rewards in parallel slices, where each\nslice comprises same-indexed completions from different samples. This provides\na precise, differentiated learning signal for each individual completion,\nenabling granular credit assignment and effective optimization. On the official\nC-STS benchmark, PoLi-RL achieves a Spearman correlation coefficient of 48.18,\nestablishing a new SOTA for the cross-encoder architecture. As the first work\nto successfully apply RL to C-STS, our study introduces a powerful and precise\nparadigm for training LLMs on complex, ranking-based conditional judgment\ntasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86PoLi-RL\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\u548c\u5e76\u884c\u5207\u7247\u6392\u540d\u5956\u52b1\u673a\u5236\uff0c\u6210\u529f\u5c06\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e8e\u6761\u4ef6\u8bed\u4e49\u6587\u672c\u76f8\u4f3c\u5ea6\u4efb\u52a1\uff0c\u5728C-STS\u57fa\u51c6\u4e0a\u8fbe\u5230\u65b0\u7684SOTA\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709C-STS\u65b9\u6cd5\u5c40\u9650\u4e8e\u5224\u522b\u6a21\u578b\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528LLMs\u548cRL\u7684\u6700\u65b0\u8fdb\u5c55\u3002RL\u7279\u522b\u9002\u5408\u8be5\u4efb\u52a1\uff0c\u53ef\u76f4\u63a5\u4f18\u5316\u4e0d\u53ef\u5fae\u7684Spearman\u6392\u540d\u6307\u6807\u5e76\u6307\u5bfc\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "PoLi-RL\u6846\u67b6\uff1a1) \u4e24\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\uff1a\u5148\u7528\u7b80\u5355\u70b9\u5bf9\u5956\u52b1\u5efa\u7acb\u57fa\u672c\u8bc4\u5206\u80fd\u529b\uff0c\u518d\u8f6c\u5411\u6df7\u5408\u5956\u52b1\uff08\u70b9\u5bf9\u3001\u5bf9\u5076\u3001\u5217\u8868\u76ee\u6807\uff09\uff1b2) \u5e76\u884c\u5207\u7247\u6392\u540d\u5956\u52b1\u673a\u5236\uff0c\u5728\u5e76\u884c\u5207\u7247\u4e2d\u8ba1\u7b97\u6392\u540d\u5956\u52b1\u3002", "result": "\u5728\u5b98\u65b9C-STS\u57fa\u51c6\u4e0a\u8fbe\u5230Spearman\u76f8\u5173\u7cfb\u657048.18\uff0c\u4e3a\u4ea4\u53c9\u7f16\u7801\u5668\u67b6\u6784\u5efa\u7acb\u4e86\u65b0\u7684SOTA\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u6210\u529f\u5c06RL\u5e94\u7528\u4e8eC-STS\u7684\u5de5\u4f5c\uff0c\u4e3a\u5728\u590d\u6742\u3001\u57fa\u4e8e\u6392\u540d\u7684\u6761\u4ef6\u5224\u65ad\u4efb\u52a1\u4e0a\u8bad\u7ec3LLMs\u5f15\u5165\u4e86\u5f3a\u5927\u800c\u7cbe\u786e\u7684\u8303\u5f0f\u3002"}}
{"id": "2510.04272", "categories": ["cs.AI", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.04272", "abs": "https://arxiv.org/abs/2510.04272", "authors": ["Jinyang Jiang", "Jinhui Han", "Yijie Peng", "Ying Zhang"], "title": "Closing the Loop: Coordinating Inventory and Recommendation via Deep Reinforcement Learning on Multiple Timescales", "comment": null, "summary": "Effective cross-functional coordination is essential for enhancing firm-wide\nprofitability, particularly in the face of growing organizational complexity\nand scale. Recent advances in artificial intelligence, especially in\nreinforcement learning (RL), offer promising avenues to address this\nfundamental challenge. This paper proposes a unified multi-agent RL framework\ntailored for joint optimization across distinct functional modules, exemplified\nvia coordinating inventory replenishment and personalized product\nrecommendation. We first develop an integrated theoretical model to capture the\nintricate interplay between these functions and derive analytical benchmarks\nthat characterize optimal coordination. The analysis reveals synchronized\nadjustment patterns across products and over time, highlighting the importance\nof coordinated decision-making. Leveraging these insights, we design a novel\nmulti-timescale multi-agent RL architecture that decomposes policy components\naccording to departmental functions and assigns distinct learning speeds based\non task complexity and responsiveness. Our model-free multi-agent design\nimproves scalability and deployment flexibility, while multi-timescale updates\nenhance convergence stability and adaptability across heterogeneous decisions.\nWe further establish the asymptotic convergence of the proposed algorithm.\nExtensive simulation experiments demonstrate that the proposed approach\nsignificantly improves profitability relative to siloed decision-making\nframeworks, while the behaviors of the trained RL agents align closely with the\nmanagerial insights from our theoretical model. Taken together, this work\nprovides a scalable, interpretable RL-based solution to enable effective\ncross-functional coordination in complex business settings.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u534f\u8c03\u5e93\u5b58\u8865\u8d27\u548c\u4e2a\u6027\u5316\u4ea7\u54c1\u63a8\u8350\u529f\u80fd\uff0c\u901a\u8fc7\u591a\u65f6\u95f4\u5c3a\u5ea6\u5b66\u4e60\u63d0\u9ad8\u4f01\u4e1a\u76c8\u5229\u80fd\u529b\u3002", "motivation": "\u968f\u7740\u7ec4\u7ec7\u590d\u6742\u6027\u548c\u89c4\u6a21\u7684\u589e\u52a0\uff0c\u6709\u6548\u7684\u8de8\u804c\u80fd\u534f\u8c03\u5bf9\u4e8e\u63d0\u5347\u4f01\u4e1a\u6574\u4f53\u76c8\u5229\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002\u4eba\u5de5\u667a\u80fd\u7279\u522b\u662f\u5f3a\u5316\u5b66\u4e60\u7684\u8fdb\u5c55\u4e3a\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002", "method": "\u5f00\u53d1\u96c6\u6210\u7406\u8bba\u6a21\u578b\u6355\u6349\u529f\u80fd\u95f4\u590d\u6742\u4e92\u52a8\uff0c\u8bbe\u8ba1\u65b0\u9896\u7684\u591a\u65f6\u95f4\u5c3a\u5ea6\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u67b6\u6784\uff0c\u6839\u636e\u90e8\u95e8\u529f\u80fd\u5206\u89e3\u7b56\u7565\u7ec4\u4ef6\uff0c\u57fa\u4e8e\u4efb\u52a1\u590d\u6742\u6027\u548c\u54cd\u5e94\u6027\u5206\u914d\u4e0d\u540c\u5b66\u4e60\u901f\u5ea6\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u5b64\u7acb\u7684\u51b3\u7b56\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u76c8\u5229\u80fd\u529b\uff0c\u8bad\u7ec3\u51fa\u7684\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u884c\u4e3a\u4e0e\u7406\u8bba\u6a21\u578b\u7684\u7ba1\u7406\u6d1e\u5bdf\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u590d\u6742\u5546\u4e1a\u73af\u5883\u4e2d\u5b9e\u73b0\u6709\u6548\u8de8\u804c\u80fd\u534f\u8c03\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u7684\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04081", "categories": ["cs.CL", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.04081", "abs": "https://arxiv.org/abs/2510.04081", "authors": ["Honglin Lin", "Qizhi Pei", "Xin Gao", "Zhuoshi Pan", "Yu Li", "Juntao Li", "Conghui He", "Lijun Wu"], "title": "Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model Reasoning", "comment": "Accepted by NeurIPS2025", "summary": "Reasoning capability is pivotal for Large Language Models (LLMs) to solve\ncomplex tasks, yet achieving reliable and scalable reasoning remains\nchallenging. While Chain-of-Thought (CoT) prompting has become a mainstream\napproach, existing methods often suffer from uncontrolled generation,\ninsufficient quality, and limited diversity in reasoning paths. Recent efforts\nleverage code to enhance CoT by grounding reasoning in executable steps, but\nsuch methods are typically constrained to predefined mathematical problems,\nhindering scalability and generalizability. In this work, we propose Caco\n(Code-Assisted Chain-of-ThOught), a novel framework that automates the\nsynthesis of high-quality, verifiable, and diverse instruction-CoT reasoning\ndata through code-driven augmentation. Unlike prior work, Caco first fine-tunes\na code-based CoT generator on existing math and programming solutions in a\nunified code format, then scales the data generation to a large amount of\ndiverse reasoning traces. Crucially, we introduce automated validation via code\nexecution and rule-based filtering to ensure logical correctness and structural\ndiversity, followed by reverse-engineering filtered outputs into natural\nlanguage instructions and language CoTs to enrich task adaptability. This\nclosed-loop process enables fully automated, scalable synthesis of reasoning\ndata with guaranteed executability. Experiments on our created Caco-1.3M\ndataset demonstrate that Caco-trained models achieve strong competitive\nperformance on mathematical reasoning benchmarks, outperforming existing strong\nbaselines. Further analysis reveals that Caco's code-anchored verification and\ninstruction diversity contribute to superior generalization across unseen\ntasks. Our work establishes a paradigm for building self-sustaining,\ntrustworthy reasoning systems without human intervention.", "AI": {"tldr": "Caco\u6846\u67b6\u901a\u8fc7\u4ee3\u7801\u9a71\u52a8\u7684\u589e\u5f3a\u65b9\u6cd5\uff0c\u81ea\u52a8\u5316\u5408\u6210\u9ad8\u8d28\u91cf\u3001\u53ef\u9a8c\u8bc1\u4e14\u591a\u6837\u5316\u7684\u6307\u4ee4-CoT\u63a8\u7406\u6570\u636e\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709CoT\u65b9\u6cd5\u5b58\u5728\u751f\u6210\u4e0d\u53ef\u63a7\u3001\u8d28\u91cf\u4e0d\u8db3\u548c\u63a8\u7406\u8def\u5f84\u591a\u6837\u6027\u6709\u9650\u7684\u95ee\u9898\uff0c\u800c\u57fa\u4e8e\u4ee3\u7801\u7684CoT\u65b9\u6cd5\u901a\u5e38\u5c40\u9650\u4e8e\u9884\u5b9a\u4e49\u7684\u6570\u5b66\u95ee\u9898\uff0c\u963b\u788d\u4e86\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u6027\u3002", "method": "\u9996\u5148\u5728\u7edf\u4e00\u4ee3\u7801\u683c\u5f0f\u4e0b\u5fae\u8c03\u57fa\u4e8e\u4ee3\u7801\u7684CoT\u751f\u6210\u5668\uff0c\u7136\u540e\u901a\u8fc7\u4ee3\u7801\u6267\u884c\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u8fc7\u6ee4\u8fdb\u884c\u81ea\u52a8\u9a8c\u8bc1\uff0c\u786e\u4fdd\u903b\u8f91\u6b63\u786e\u6027\u548c\u7ed3\u6784\u591a\u6837\u6027\uff0c\u6700\u540e\u5c06\u8fc7\u6ee4\u540e\u7684\u8f93\u51fa\u53cd\u5411\u5de5\u7a0b\u4e3a\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u548c\u8bed\u8a00CoT\u3002", "result": "\u5728\u521b\u5efa\u7684Caco-1.3M\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCaco\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u7ade\u4e89\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u5f3a\u57fa\u7ebf\u3002", "conclusion": "Caco\u5efa\u7acb\u4e86\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u6784\u5efa\u81ea\u6301\u7eed\u3001\u53ef\u4fe1\u8d56\u63a8\u7406\u7cfb\u7edf\u7684\u8303\u5f0f\uff0c\u5176\u4ee3\u7801\u951a\u5b9a\u9a8c\u8bc1\u548c\u6307\u4ee4\u591a\u6837\u6027\u6709\u52a9\u4e8e\u5728\u672a\u89c1\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4f18\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.04281", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04281", "abs": "https://arxiv.org/abs/2510.04281", "authors": ["Zhuangzhi Gao", "Hongyi Qin", "He Zhao", "Qinkai Yu", "Feixiang Zhou", "Eduard Shantsila", "Uazman Alam", "Alena Shantsila", "Wahbi El-Bouri", "Gregory Y. H. Lip", "Yalin Zheng"], "title": "GROK: From Quantitative Biomarkers to Qualitative Diagnosis via a Grounded MLLM with Knowledge-Guided Instruction", "comment": "9 pages, 4 figures, 3 table. Equal contribution: Zhuangzhi Gao and\n  Hongyi Qin. Corresponding author: Yalin Zheng (yzheng@liverpool.ac.uk)", "summary": "Multimodal large language models (MLLMs) hold promise for integrating diverse\ndata modalities, but current medical adaptations such as LLaVA-Med often fail\nto fully exploit the synergy between color fundus photography (CFP) and optical\ncoherence tomography (OCT), and offer limited interpretability of quantitative\nbiomarkers. We introduce GROK, a grounded multimodal large language model that\njointly processes CFP, OCT, and text to deliver clinician-grade diagnoses of\nocular and systemic disease. GROK comprises three core modules:\nKnowledge-Guided Instruction Generation, CLIP-Style OCT-Biomarker Alignment,\nand Supervised Instruction Fine-Tuning, which together establish a\nquantitative-to-qualitative diagnostic chain of thought, mirroring real\nclinical reasoning when producing detailed lesion annotations. To evaluate our\napproach, we introduce the Grounded Ophthalmic Understanding benchmark, which\ncovers six disease categories and three tasks: macro-level diagnostic\nclassification, report generation quality, and fine-grained clinical assessment\nof the generated chain of thought. Experiments show that, with only LoRA\n(Low-Rank Adaptation) fine-tuning of a 7B-parameter Qwen2 backbone, GROK\noutperforms comparable 7B and 32B baselines on both report quality and\nfine-grained clinical metrics, and even exceeds OpenAI o3. Code and data are\npublicly available in the GROK repository.", "AI": {"tldr": "GROK\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u533b\u5b66\u8bca\u65ad\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u5904\u7406\u5f69\u8272\u773c\u5e95\u7167\u76f8\u3001\u5149\u5b66\u76f8\u5e72\u65ad\u5c42\u626b\u63cf\u548c\u6587\u672c\u6570\u636e\uff0c\u63d0\u4f9b\u4e34\u5e8a\u7ea7\u522b\u7684\u773c\u79d1\u548c\u5168\u8eab\u6027\u75be\u75c5\u8bca\u65ad\u3002", "motivation": "\u5f53\u524d\u533b\u5b66\u591a\u6a21\u6001\u5927\u6a21\u578b\u672a\u80fd\u5145\u5206\u5229\u7528\u5f69\u8272\u773c\u5e95\u7167\u76f8\u548c\u5149\u5b66\u76f8\u5e72\u65ad\u5c42\u626b\u63cf\u4e4b\u95f4\u7684\u534f\u540c\u4f5c\u7528\uff0c\u4e14\u5bf9\u5b9a\u91cf\u751f\u7269\u6807\u5fd7\u7269\u7684\u89e3\u91ca\u80fd\u529b\u6709\u9650\u3002", "method": "\u91c7\u7528\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\u77e5\u8bc6\u5f15\u5bfc\u6307\u4ee4\u751f\u6210\u3001CLIP\u98ce\u683cOCT\u751f\u7269\u6807\u5fd7\u7269\u5bf9\u9f50\u548c\u76d1\u7763\u6307\u4ee4\u5fae\u8c03\uff0c\u5efa\u7acb\u4ece\u5b9a\u91cf\u5230\u5b9a\u6027\u7684\u8bca\u65ad\u601d\u7ef4\u94fe\u3002", "result": "\u4ec5\u4f7f\u7528LoRA\u5fae\u8c037B\u53c2\u6570\u7684Qwen2\u9aa8\u5e72\u7f51\u7edc\uff0cGROK\u5728\u62a5\u544a\u8d28\u91cf\u548c\u7ec6\u7c92\u5ea6\u4e34\u5e8a\u6307\u6807\u4e0a\u4f18\u4e8e\u540c\u7c7b7B\u548c32B\u57fa\u7ebf\u6a21\u578b\uff0c\u751a\u81f3\u8d85\u8fc7OpenAI o3\u3002", "conclusion": "GROK\u901a\u8fc7\u5efa\u7acb\u5b9a\u91cf\u5230\u5b9a\u6027\u7684\u8bca\u65ad\u601d\u7ef4\u94fe\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u4e34\u5e8a\u7ea7\u522b\u7684\u773c\u79d1\u75be\u75c5\u8bca\u65ad\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u751f\u7269\u6807\u5fd7\u7269\u5206\u6790\u3002"}}
{"id": "2510.04120", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04120", "abs": "https://arxiv.org/abs/2510.04120", "authors": ["Fengying Ye", "Shanshan Wang", "Lidia S. Chao", "Derek F. Wong"], "title": "Unveiling LLMs' Metaphorical Understanding: Exploring Conceptual Irrelevance, Context Leveraging and Syntactic Influence", "comment": null, "summary": "Metaphor analysis is a complex linguistic phenomenon shaped by context and\nexternal factors. While Large Language Models (LLMs) demonstrate advanced\ncapabilities in knowledge integration, contextual reasoning, and creative\ngeneration, their mechanisms for metaphor comprehension remain insufficiently\nexplored. This study examines LLMs' metaphor-processing abilities from three\nperspectives: (1) Concept Mapping: using embedding space projections to\nevaluate how LLMs map concepts in target domains (e.g., misinterpreting \"fall\nin love\" as \"drop down from love\"); (2) Metaphor-Literal Repository: analyzing\nmetaphorical words and their literal counterparts to identify inherent\nmetaphorical knowledge; and (3) Syntactic Sensitivity: assessing how\nmetaphorical syntactic structures influence LLMs' performance. Our findings\nreveal that LLMs generate 15\\%-25\\% conceptually irrelevant interpretations,\ndepend on metaphorical indicators in training data rather than contextual cues,\nand are more sensitive to syntactic irregularities than to structural\ncomprehension. These insights underline the limitations of LLMs in metaphor\nanalysis and call for more robust computational approaches.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ece\u6982\u5ff5\u6620\u5c04\u3001\u9690\u55bb-\u5b57\u9762\u77e5\u8bc6\u5e93\u548c\u53e5\u6cd5\u654f\u611f\u6027\u4e09\u4e2a\u89d2\u5ea6\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9690\u55bb\u5904\u7406\u80fd\u529b\uff0c\u53d1\u73b0LLMs\u5b58\u5728\u6982\u5ff5\u65e0\u5173\u89e3\u91ca\u3001\u4f9d\u8d56\u8bad\u7ec3\u6570\u636e\u800c\u975e\u4e0a\u4e0b\u6587\u7ebf\u7d22\u3001\u5bf9\u53e5\u6cd5\u4e0d\u89c4\u5219\u6027\u6bd4\u5bf9\u7ed3\u6784\u7406\u89e3\u66f4\u654f\u611f\u7b49\u5c40\u9650\u3002", "motivation": "\u9690\u55bb\u5206\u6790\u662f\u53d7\u8bed\u5883\u548c\u5916\u90e8\u56e0\u7d20\u5f71\u54cd\u7684\u590d\u6742\u8bed\u8a00\u73b0\u8c61\uff0c\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u6574\u5408\u3001\u8bed\u5883\u63a8\u7406\u548c\u521b\u9020\u6027\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u5148\u8fdb\u80fd\u529b\uff0c\u4f46\u5176\u9690\u55bb\u7406\u89e3\u673a\u5236\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4ece\u4e09\u4e2a\u89c6\u89d2\u7814\u7a76LLMs\u7684\u9690\u55bb\u5904\u7406\u80fd\u529b\uff1a(1)\u6982\u5ff5\u6620\u5c04\uff1a\u4f7f\u7528\u5d4c\u5165\u7a7a\u95f4\u6295\u5f71\u8bc4\u4f30LLMs\u5982\u4f55\u5728\u76ee\u6807\u57df\u4e2d\u6620\u5c04\u6982\u5ff5\uff1b(2)\u9690\u55bb-\u5b57\u9762\u77e5\u8bc6\u5e93\uff1a\u5206\u6790\u9690\u55bb\u8bcd\u53ca\u5176\u5b57\u9762\u5bf9\u5e94\u8bcd\u4ee5\u8bc6\u522b\u5185\u5728\u9690\u55bb\u77e5\u8bc6\uff1b(3)\u53e5\u6cd5\u654f\u611f\u6027\uff1a\u8bc4\u4f30\u9690\u55bb\u53e5\u6cd5\u7ed3\u6784\u5982\u4f55\u5f71\u54cdLLMs\u8868\u73b0\u3002", "result": "\u53d1\u73b0LLMs\u751f\u621015%-25%\u6982\u5ff5\u65e0\u5173\u7684\u89e3\u91ca\uff0c\u4f9d\u8d56\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u9690\u55bb\u6307\u793a\u5668\u800c\u975e\u4e0a\u4e0b\u6587\u7ebf\u7d22\uff0c\u5bf9\u53e5\u6cd5\u4e0d\u89c4\u5219\u6027\u6bd4\u5bf9\u7ed3\u6784\u7406\u89e3\u66f4\u654f\u611f\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u7a81\u663e\u4e86LLMs\u5728\u9690\u55bb\u5206\u6790\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u547c\u5401\u5f00\u53d1\u66f4\u5f3a\u5927\u7684\u8ba1\u7b97\u65b9\u6cd5\u3002"}}
{"id": "2510.04284", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04284", "abs": "https://arxiv.org/abs/2510.04284", "authors": ["Yunghwei Lai", "Kaiming Liu", "Ziyue Wang", "Weizhi Ma", "Yang Liu"], "title": "Doctor-R1: Mastering Clinical Inquiry with Experiential Agentic Reinforcement Learning", "comment": null, "summary": "The professionalism of a human doctor in outpatient service depends on two\ncore abilities: the ability to make accurate medical decisions and the medical\nconsultation skill to conduct strategic, empathetic patient inquiry. Existing\nLarge Language Models (LLMs) have achieved remarkable accuracy on medical\ndecision-making benchmarks. However, they often lack the ability to conduct the\nstrategic and empathetic consultation, which is essential for real-world\nclinical scenarios. To address this gap, we propose Doctor-R1, an AI doctor\nagent trained to master both of the capabilities by ask high-yield questions\nand conduct strategic multi-turn inquiry to guide decision-making. Our\nframework introduces three key components: a multi-agent interactive\nenvironment, a two-tiered reward architecture that separately optimizes\nclinical decision-making and communicative inquiry skills, and an experience\nrepository to ground policy learning in high-quality prior trajectories. We\nevaluate Doctor-R1 on OpenAI's HealthBench and MAQuE, assessed across\nmulti-facet metrics, such as communication quality, user experience, and task\naccuracy. Remarkably, Doctor-R1 surpasses state-of-the-art open-source\nspecialized LLMs by a substantial margin with higher parameter efficiency and\noutperforms powerful proprietary models. Furthermore, the human evaluations\nshow a strong preference for Doctor-R1 to generate human-preferred clinical\ndialogue, demonstrating the effectiveness of the framework.", "AI": {"tldr": "\u63d0\u51faDoctor-R1 AI\u533b\u751f\u4ee3\u7406\uff0c\u901a\u8fc7\u591a\u8f6e\u6218\u7565\u95ee\u8bca\u548c\u9ad8\u8d28\u91cf\u63d0\u95ee\u6765\u540c\u65f6\u638c\u63e1\u533b\u7597\u51b3\u7b56\u548c\u6c9f\u901a\u54a8\u8be2\u6280\u80fd\uff0c\u8d85\u8d8a\u73b0\u6709LLM\u5728\u4e34\u5e8a\u5bf9\u8bdd\u8d28\u91cf\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u51b3\u7b56\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u7f3a\u4e4f\u6218\u7565\u6027\u548c\u540c\u7406\u5fc3\u7684\u95ee\u8bca\u80fd\u529b\uff0c\u8fd9\u5728\u771f\u5b9e\u4e34\u5e8a\u573a\u666f\u4e2d\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u73af\u5883\u3001\u53cc\u5c42\u5956\u52b1\u67b6\u6784\uff08\u5206\u522b\u4f18\u5316\u4e34\u5e8a\u51b3\u7b56\u548c\u6c9f\u901a\u6280\u80fd\uff09\u4ee5\u53ca\u7ecf\u9a8c\u5e93\u6765\u57fa\u4e8e\u9ad8\u8d28\u91cf\u8f68\u8ff9\u8fdb\u884c\u7b56\u7565\u5b66\u4e60\u3002", "result": "\u5728OpenAI\u7684HealthBench\u548cMAQuE\u8bc4\u4f30\u4e2d\uff0cDoctor-R1\u5728\u6c9f\u901a\u8d28\u91cf\u3001\u7528\u6237\u4f53\u9a8c\u548c\u4efb\u52a1\u51c6\u786e\u6027\u7b49\u591a\u7ef4\u5ea6\u6307\u6807\u4e0a\u663e\u8457\u8d85\u8d8a\u6700\u5148\u8fdb\u7684\u5f00\u6e90\u4e13\u4e1aLLM\uff0c\u5e76\u5728\u4eba\u7c7b\u8bc4\u4f30\u4e2d\u83b7\u5f97\u5f3a\u70c8\u504f\u597d\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86AI\u533b\u751f\u5728\u4e34\u5e8a\u5bf9\u8bdd\u4e2d\u7684\u4eba\u7c7b\u504f\u597d\u5ea6\uff0c\u8bc1\u660e\u4e86\u540c\u65f6\u4f18\u5316\u51b3\u7b56\u548c\u6c9f\u901a\u80fd\u529b\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2510.04124", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04124", "abs": "https://arxiv.org/abs/2510.04124", "authors": ["Nuwan I. Senaratna"], "title": "Sri Lanka Document Datasets: A Large-Scale, Multilingual Resource for Law, News, and Policy (v20251005)", "comment": "4 pages", "summary": "We present a collection of open, machine-readable document datasets covering\nparliamentary proceedings, legal judgments, government publications, news, and\ntourism statistics from Sri Lanka. As of v20251005, the collection currently\ncomprises 215,670 documents (60.3 GB) across 13 datasets in Sinhala, Tamil, and\nEnglish. The datasets are updated daily and mirrored on GitHub and Hugging\nFace. These resources aim to support research in computational linguistics,\nlegal analytics, socio-political studies, and multilingual natural language\nprocessing. We describe the data sources, collection pipeline, formats, and\npotential use cases, while discussing licensing and ethical considerations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u65af\u91cc\u5170\u5361\u8bae\u4f1a\u8bb0\u5f55\u3001\u6cd5\u5f8b\u5224\u51b3\u3001\u653f\u5e9c\u51fa\u7248\u7269\u3001\u65b0\u95fb\u548c\u65c5\u6e38\u7edf\u8ba1\u7684\u5f00\u653e\u673a\u5668\u53ef\u8bfb\u6587\u6863\u6570\u636e\u96c6\u96c6\u5408\uff0c\u652f\u6301\u8ba1\u7b97\u8bed\u8a00\u5b66\u3001\u6cd5\u5f8b\u5206\u6790\u3001\u793e\u4f1a\u653f\u6cbb\u7814\u7a76\u548c\u591a\u8bed\u8a00\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7814\u7a76\u3002", "motivation": "\u4e3a\u65af\u91cc\u5170\u5361\u7684\u591a\u8bed\u8a00\u8ba1\u7b97\u8bed\u8a00\u5b66\u7814\u7a76\u63d0\u4f9b\u5f00\u653e\u3001\u673a\u5668\u53ef\u8bfb\u7684\u6570\u636e\u8d44\u6e90\uff0c\u652f\u6301\u6cd5\u5f8b\u5206\u6790\u3001\u793e\u4f1a\u653f\u6cbb\u7814\u7a76\u548c\u591a\u8bed\u8a00\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u9886\u57df\u7684\u7814\u7a76\u3002", "method": "\u6784\u5efa\u6570\u636e\u6536\u96c6\u7ba1\u9053\uff0c\u4ece\u591a\u4e2a\u6765\u6e90\u6536\u96c6\u8bae\u4f1a\u8bb0\u5f55\u3001\u6cd5\u5f8b\u5224\u51b3\u3001\u653f\u5e9c\u51fa\u7248\u7269\u3001\u65b0\u95fb\u548c\u65c5\u6e38\u7edf\u8ba1\u6570\u636e\uff0c\u4ee5Sinhala\u3001Tamil\u548c\u82f1\u8bed\u4e09\u79cd\u8bed\u8a00\u63d0\u4f9b\uff0c\u5e76\u6bcf\u65e5\u66f4\u65b0\u3002", "result": "\u622a\u81f3v20251005\u7248\u672c\uff0c\u8be5\u96c6\u5408\u5305\u542b13\u4e2a\u6570\u636e\u96c6\uff0c\u5171215,670\u4e2a\u6587\u6863\uff0860.3 GB\uff09\uff0c\u5728GitHub\u548cHugging Face\u4e0a\u955c\u50cf\u3002", "conclusion": "\u8fd9\u4e9b\u6570\u636e\u96c6\u4e3a\u65af\u91cc\u5170\u5361\u7684\u591a\u8bed\u8a00\u8ba1\u7b97\u8bed\u8a00\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u8d44\u6e90\uff0c\u540c\u65f6\u8ba8\u8bba\u4e86\u8bb8\u53ef\u548c\u4f26\u7406\u8003\u8651\u3002"}}
{"id": "2510.04311", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04311", "abs": "https://arxiv.org/abs/2510.04311", "authors": ["Bohan Tang", "Huidong Liang", "Keyue Jiang", "Xiaowen Dong"], "title": "On the Importance of Task Complexity in Evaluating LLM-Based Multi-Agent Systems", "comment": null, "summary": "Large language model multi-agent systems (LLM-MAS) offer a promising paradigm\nfor harnessing collective intelligence to achieve more advanced forms of AI\nbehaviour. While recent studies suggest that LLM-MAS can outperform LLM\nsingle-agent systems (LLM-SAS) on certain tasks, the lack of systematic\nexperimental designs limits the strength and generality of these conclusions.\nWe argue that a principled understanding of task complexity, such as the degree\nof sequential reasoning required and the breadth of capabilities involved, is\nessential for assessing the effectiveness of LLM-MAS in task solving. To this\nend, we propose a theoretical framework characterising tasks along two\ndimensions: depth, representing reasoning length, and width, representing\ncapability diversity. We theoretically examine a representative class of\nLLM-MAS, namely the multi-agent debate system, and empirically evaluate its\nperformance in both discriminative and generative tasks with varying depth and\nwidth. Theoretical and empirical results show that the benefit of LLM-MAS over\nLLM-SAS increases with both task depth and width, and the effect is more\npronounced with respect to depth. This clarifies when LLM-MAS are beneficial\nand provides a principled foundation for designing future LLM-MAS methods and\nbenchmarks.", "AI": {"tldr": "LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u4efb\u52a1\u6df1\u5ea6\u548c\u5bbd\u5ea6\u589e\u52a0\u65f6\u6bd4\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u8868\u73b0\u66f4\u597d\uff0c\u7279\u522b\u662f\u4efb\u52a1\u6df1\u5ea6\u7684\u5f71\u54cd\u66f4\u663e\u8457\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u7cfb\u7edf\u6027\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u9650\u5236\u4e86\u5173\u4e8eLLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4f18\u52bf\u7ed3\u8bba\u7684\u5f3a\u5ea6\u548c\u666e\u9002\u6027\u3002\u9700\u8981\u7406\u89e3\u4efb\u52a1\u590d\u6742\u6027\u5bf9\u8bc4\u4f30LLM-MAS\u6709\u6548\u6027\u7684\u91cd\u8981\u6027\u3002", "method": "\u63d0\u51fa\u7406\u8bba\u6846\u67b6\uff0c\u4ece\u6df1\u5ea6\uff08\u63a8\u7406\u957f\u5ea6\uff09\u548c\u5bbd\u5ea6\uff08\u80fd\u529b\u591a\u6837\u6027\uff09\u4e24\u4e2a\u7ef4\u5ea6\u8868\u5f81\u4efb\u52a1\u3002\u7406\u8bba\u5206\u6790\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u7cfb\u7edf\uff0c\u5e76\u5728\u4e0d\u540c\u6df1\u5ea6\u548c\u5bbd\u5ea6\u7684\u5224\u522b\u6027\u548c\u751f\u6210\u6027\u4efb\u52a1\u4e2d\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u7406\u8bba\u548c\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cLLM-MAS\u76f8\u5bf9\u4e8eLLM-SAS\u7684\u4f18\u52bf\u968f\u7740\u4efb\u52a1\u6df1\u5ea6\u548c\u5bbd\u5ea6\u7684\u589e\u52a0\u800c\u589e\u52a0\uff0c\u4e14\u6df1\u5ea6\u7684\u5f71\u54cd\u66f4\u663e\u8457\u3002", "conclusion": "\u660e\u786e\u4e86LLM-MAS\u4f55\u65f6\u6709\u76ca\uff0c\u4e3a\u672a\u6765LLM-MAS\u65b9\u6cd5\u548c\u57fa\u51c6\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u57fa\u7840\u3002"}}
{"id": "2510.04139", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04139", "abs": "https://arxiv.org/abs/2510.04139", "authors": ["Tim Bakkenes", "Daniel Wang", "Anton Johansson"], "title": "Fine Tuning Methods for Low-resource Languages", "comment": null, "summary": "The rise of Large Language Models has not been inclusive of all cultures. The\nmodels are mostly trained on English texts and culture which makes them\nunderperform in other languages and cultural contexts. By developing a\ngeneralizable method for preparing culturally relevant datasets and\npost-training the Gemma 2 model, this project aimed to increase the performance\nof Gemma 2 for an underrepresented language and showcase how others can do the\nsame to unlock the power of Generative AI in their country and preserve their\ncultural heritage.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u901a\u7528\u65b9\u6cd5\uff0c\u901a\u8fc7\u51c6\u5907\u6587\u5316\u76f8\u5173\u6570\u636e\u96c6\u548c\u5bf9Gemma 2\u6a21\u578b\u8fdb\u884c\u540e\u8bad\u7ec3\uff0c\u63d0\u5347\u6a21\u578b\u5728\u4ee3\u8868\u6027\u4e0d\u8db3\u8bed\u8a00\u4e0a\u7684\u6027\u80fd\uff0c\u4fc3\u8fdb\u751f\u6210\u5f0fAI\u5728\u5404\u56fd\u6587\u5316\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u57fa\u4e8e\u82f1\u8bed\u6587\u672c\u548c\u6587\u5316\u8bad\u7ec3\uff0c\u5bfc\u81f4\u5728\u5176\u4ed6\u8bed\u8a00\u548c\u6587\u5316\u80cc\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u63d0\u5347\u6a21\u578b\u5728\u4ee3\u8868\u6027\u4e0d\u8db3\u8bed\u8a00\u4e0a\u7684\u6027\u80fd\u3002", "method": "\u5f00\u53d1\u901a\u7528\u65b9\u6cd5\u51c6\u5907\u6587\u5316\u76f8\u5173\u6570\u636e\u96c6\uff0c\u5e76\u5bf9Gemma 2\u6a21\u578b\u8fdb\u884c\u540e\u8bad\u7ec3\u3002", "result": "\u63d0\u9ad8\u4e86Gemma 2\u5728\u4ee3\u8868\u6027\u4e0d\u8db3\u8bed\u8a00\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u5e2e\u52a9\u5176\u4ed6\u56fd\u5bb6\u89e3\u9501\u751f\u6210\u5f0fAI\u7684\u6f5c\u529b\u5e76\u4fdd\u62a4\u5176\u6587\u5316\u9057\u4ea7\u3002"}}
{"id": "2510.04371", "categories": ["cs.AI", "cs.DC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.04371", "abs": "https://arxiv.org/abs/2510.04371", "authors": ["Naimeng Ye", "Arnav Ahuja", "Georgios Liargkovas", "Yunan Lu", "Kostis Kaffes", "Tianyi Peng"], "title": "Speculative Actions: A Lossless Framework for Faster Agentic Systems", "comment": null, "summary": "Despite growing interest in AI agents across industry and academia, their\nexecution in an environment is often slow, hampering training, evaluation, and\ndeployment. For example, a game of chess between two state-of-the-art agents\nmay take hours. A critical bottleneck is that agent behavior unfolds\nsequentially: each action requires an API call, and these calls can be\ntime-consuming. Inspired by speculative execution in microprocessors and\nspeculative decoding in LLM inference, we propose speculative actions, a\nlossless framework for general agentic systems that predicts likely actions\nusing faster models, enabling multiple steps to be executed in parallel. We\nevaluate this framework across three agentic environments: gaming, e-commerce,\nweb search, and a \"lossy\" extension for an operating systems environment. In\nall cases, speculative actions achieve substantial accuracy in next-action\nprediction (up to 55%), translating into significant reductions in end-to-end\nlatency. Moreover, performance can be further improved through stronger\nguessing models, top-K action prediction, multi-step speculation, and\nuncertainty-aware optimization, opening a promising path toward deploying\nlow-latency agentic systems in the real world.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\"\u63a8\u6d4b\u6027\u52a8\u4f5c\"\u7684\u65e0\u635f\u6846\u67b6\uff0c\u901a\u8fc7\u4f7f\u7528\u66f4\u5feb\u7684\u6a21\u578b\u9884\u6d4b\u53ef\u80fd\u7684\u52a8\u4f5c\uff0c\u4f7f\u667a\u80fd\u4f53\u7cfb\u7edf\u80fd\u591f\u5e76\u884c\u6267\u884c\u591a\u4e2a\u6b65\u9aa4\uff0c\u663e\u8457\u964d\u4f4e\u7aef\u5230\u7aef\u5ef6\u8fdf\u3002", "motivation": "\u5f53\u524dAI\u667a\u80fd\u4f53\u5728\u73af\u5883\u4e2d\u6267\u884c\u65f6\u901f\u5ea6\u7f13\u6162\uff0c\u4e25\u91cd\u5f71\u54cd\u4e86\u8bad\u7ec3\u3001\u8bc4\u4f30\u548c\u90e8\u7f72\u3002\u4f8b\u5982\uff0c\u4e24\u4e2a\u9876\u5c16\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u56fd\u9645\u8c61\u68cb\u6e38\u620f\u53ef\u80fd\u9700\u8981\u6570\u5c0f\u65f6\uff0c\u4e3b\u8981\u74f6\u9888\u5728\u4e8e\u52a8\u4f5c\u9700\u8981\u987a\u5e8f\u6267\u884c\u4e14API\u8c03\u7528\u8017\u65f6\u3002", "method": "\u53d7\u5fae\u5904\u7406\u5668\u4e2d\u7684\u63a8\u6d4b\u6267\u884c\u548cLLM\u63a8\u7406\u4e2d\u7684\u63a8\u6d4b\u89e3\u7801\u542f\u53d1\uff0c\u4f7f\u7528\u66f4\u5feb\u7684\u6a21\u578b\u9884\u6d4b\u53ef\u80fd\u7684\u52a8\u4f5c\uff0c\u5b9e\u73b0\u591a\u6b65\u9aa4\u5e76\u884c\u6267\u884c\u3002\u652f\u6301top-K\u52a8\u4f5c\u9884\u6d4b\u3001\u591a\u6b65\u63a8\u6d4b\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u4f18\u5316\u3002", "result": "\u5728\u6e38\u620f\u3001\u7535\u5b50\u5546\u52a1\u3001\u7f51\u7edc\u641c\u7d22\u548c\u64cd\u4f5c\u7cfb\u7edf\u73af\u5883\u4e2d\u8bc4\u4f30\uff0c\u63a8\u6d4b\u6027\u52a8\u4f5c\u5728\u4e0b\u4e00\u4e2a\u52a8\u4f5c\u9884\u6d4b\u4e2d\u8fbe\u5230\u9ad8\u8fbe55%\u7684\u51c6\u786e\u7387\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u7aef\u5230\u7aef\u5ef6\u8fdf\u3002", "conclusion": "\u63a8\u6d4b\u6027\u52a8\u4f5c\u4e3a\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u90e8\u7f72\u4f4e\u5ef6\u8fdf\u667a\u80fd\u4f53\u7cfb\u7edf\u5f00\u8f9f\u4e86\u4e00\u6761\u6709\u524d\u666f\u7684\u8def\u5f84\uff0c\u6027\u80fd\u53ef\u4ee5\u901a\u8fc7\u66f4\u5f3a\u7684\u731c\u6d4b\u6a21\u578b\u548c\u4f18\u5316\u6280\u672f\u8fdb\u4e00\u6b65\u63d0\u5347\u3002"}}
{"id": "2510.04147", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04147", "abs": "https://arxiv.org/abs/2510.04147", "authors": ["Yifeng Gao", "Ziang Ji", "Yuxuan Wang", "Biqing Qi", "Hanlin Xu", "Linfeng Zhang"], "title": "Self Speculative Decoding for Diffusion Large Language Models", "comment": null, "summary": "Diffusion-based Large Language Models (dLLMs) have emerged as a competitive\nalternative to autoregressive models, offering unique advantages through\nbidirectional attention and parallel generation paradigms. However, the\ngeneration results of current parallel decoding methods deviate from stepwise\ndecoding, introducing potential performance degradation, which limits their\npractical deployment. To address this problem, we propose \\textbf{S}elf\n\\textbf{S}peculative \\textbf{D}ecoding (SSD), a lossless inference acceleration\nmethod that leverages the dLLM itself as both speculative decoding drafter and\nverifier without auxiliary modules. SSD introduces a self-drafting mechanism\nwhere the model generates predictions for multiple positions, then verifies\nthem through hierarchical verification trees in a single forward pass. Unlike\ntraditional speculative decoding that requires separate draft models, SSD\neliminates model redundancy and memory overhead by exploiting the dLLM's\ninherent parallel prediction capability for multiple positions. This\nself-speculative approach allows the model to progressively verify and accept\nmultiple tokens in a single forward pass. Our experiments demonstrate that SSD\nachieves up to 3.46$\\times$ speedup while keeping the output identical to\nstepwise decoding on open source models such as LLaDA and Dream. Code will be\nmade publicly available on GitHub.", "AI": {"tldr": "\u63d0\u51faSSD\uff08\u81ea\u63a8\u6d4b\u89e3\u7801\uff09\uff0c\u4e00\u79cd\u65e0\u635f\u63a8\u7406\u52a0\u901f\u65b9\u6cd5\uff0c\u5229\u7528\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u8eab\u4f5c\u4e3a\u63a8\u6d4b\u89e3\u7801\u7684\u8d77\u8349\u5668\u548c\u9a8c\u8bc1\u5668\uff0c\u65e0\u9700\u989d\u5916\u6a21\u5757\uff0c\u5b9e\u73b0\u5355\u6b21\u524d\u5411\u4f20\u9012\u4e2d\u9a8c\u8bc1\u591a\u4e2atoken\u3002", "motivation": "\u5f53\u524d\u5e76\u884c\u89e3\u7801\u65b9\u6cd5\u7684\u751f\u6210\u7ed3\u679c\u4e0e\u9010\u6b65\u89e3\u7801\u5b58\u5728\u504f\u5dee\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u5f15\u5165\u81ea\u8d77\u8349\u673a\u5236\uff0c\u6a21\u578b\u751f\u6210\u591a\u4e2a\u4f4d\u7f6e\u7684\u9884\u6d4b\uff0c\u7136\u540e\u901a\u8fc7\u5206\u5c42\u9a8c\u8bc1\u6811\u5728\u5355\u6b21\u524d\u5411\u4f20\u9012\u4e2d\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u663e\u793aSSD\u5728LLaDA\u548cDream\u7b49\u5f00\u6e90\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad83.46\u500d\u7684\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u9010\u6b65\u89e3\u7801\u76f8\u540c\u7684\u8f93\u51fa\u3002", "conclusion": "SSD\u901a\u8fc7\u5229\u7528dLLM\u56fa\u6709\u7684\u5e76\u884c\u9884\u6d4b\u80fd\u529b\uff0c\u6d88\u9664\u4e86\u6a21\u578b\u5197\u4f59\u548c\u5185\u5b58\u5f00\u9500\uff0c\u4e3a\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u63a8\u7406\u52a0\u901f\u65b9\u6848\u3002"}}
{"id": "2510.04373", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04373", "abs": "https://arxiv.org/abs/2510.04373", "authors": ["Hadi Nekoei", "Aman Jaiswal", "Patrice Bechard", "Oleh Shliazhko", "Orlando Marquez Ayala", "Mathieu Reymond", "Massimo Caccia", "Alexandre Drouin", "Sarath Chandar", "Alexandre Lacoste"], "title": "Just-in-time Episodic Feedback Hinter: Leveraging Offline Knowledge to Improve LLM Agents Adaptation", "comment": null, "summary": "Large language model (LLM) agents perform well in sequential decision-making\ntasks, but improving them on unfamiliar domains often requires costly online\ninteractions or fine-tuning on large expert datasets. These strategies are\nimpractical for closed-source models and expensive for open-source ones, with\nrisks of catastrophic forgetting. Offline trajectories offer reusable\nknowledge, yet demonstration-based methods struggle because raw traces are\nlong, noisy, and tied to specific tasks. We present Just-in-time Episodic\nFeedback Hinter (JEF Hinter), an agentic system that distills offline traces\ninto compact, context-aware hints. A zooming mechanism highlights decisive\nsteps in long trajectories, capturing both strategies and pitfalls. Unlike\nprior methods, JEF Hinter leverages both successful and failed trajectories,\nextracting guidance even when only failure data is available, while supporting\nparallelized hint generation and benchmark-independent prompting. At inference,\na retriever selects relevant hints for the current state, providing targeted\nguidance with transparency and traceability. Experiments on MiniWoB++,\nWorkArena-L1, and WebArena-Lite show that JEF Hinter consistently outperforms\nstrong baselines, including human- and document-based hints.", "AI": {"tldr": "JEF Hinter\u662f\u4e00\u4e2a\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c06\u79bb\u7ebf\u8f68\u8ff9\u63d0\u70bc\u4e3a\u7d27\u51d1\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u63d0\u793a\u6765\u6539\u8fdbLLM\u4ee3\u7406\u5728\u964c\u751f\u9886\u57df\u7684\u51b3\u7b56\u6027\u80fd\uff0c\u65e0\u9700\u6602\u8d35\u7684\u5728\u7ebf\u4ea4\u4e92\u6216\u5fae\u8c03\u3002", "motivation": "\u6539\u8fdbLLM\u4ee3\u7406\u5728\u964c\u751f\u9886\u57df\u7684\u6027\u80fd\u901a\u5e38\u9700\u8981\u6602\u8d35\u7684\u5728\u7ebf\u4ea4\u4e92\u6216\u5927\u89c4\u6a21\u4e13\u5bb6\u6570\u636e\u96c6\u5fae\u8c03\uff0c\u8fd9\u5bf9\u95ed\u6e90\u6a21\u578b\u4e0d\u5b9e\u7528\uff0c\u5bf9\u5f00\u6e90\u6a21\u578b\u6210\u672c\u9ad8\u4e14\u6709\u707e\u96be\u6027\u9057\u5fd8\u98ce\u9669\u3002\u79bb\u7ebf\u8f68\u8ff9\u63d0\u4f9b\u4e86\u53ef\u91cd\u7528\u77e5\u8bc6\uff0c\u4f46\u539f\u59cb\u8f68\u8ff9\u957f\u3001\u5608\u6742\u4e14\u4e0e\u7279\u5b9a\u4efb\u52a1\u7ed1\u5b9a\u3002", "method": "JEF Hinter\u901a\u8fc7\u7f29\u653e\u673a\u5236\u7a81\u51fa\u957f\u8f68\u8ff9\u4e2d\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u6355\u6349\u7b56\u7565\u548c\u9677\u9631\u3002\u5b83\u5229\u7528\u6210\u529f\u548c\u5931\u8d25\u7684\u8f68\u8ff9\uff0c\u5373\u4f7f\u53ea\u6709\u5931\u8d25\u6570\u636e\u4e5f\u80fd\u63d0\u53d6\u6307\u5bfc\uff0c\u652f\u6301\u5e76\u884c\u5316\u63d0\u793a\u751f\u6210\u548c\u57fa\u51c6\u65e0\u5173\u63d0\u793a\u3002\u63a8\u7406\u65f6\uff0c\u68c0\u7d22\u5668\u4e3a\u5f53\u524d\u72b6\u6001\u9009\u62e9\u76f8\u5173\u63d0\u793a\u3002", "result": "\u5728MiniWoB++\u3001WorkArena-L1\u548cWebArena-Lite\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cJEF Hinter\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5305\u62ec\u57fa\u4e8e\u4eba\u5de5\u548c\u6587\u6863\u7684\u63d0\u793a\u65b9\u6cd5\u3002", "conclusion": "JEF Hinter\u901a\u8fc7\u5c06\u79bb\u7ebf\u8f68\u8ff9\u8f6c\u5316\u4e3a\u6709\u9488\u5bf9\u6027\u7684\u4e0a\u4e0b\u6587\u63d0\u793a\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u4ee3\u7406\u5728\u964c\u751f\u9886\u57df\u7684\u51b3\u7b56\u6027\u80fd\uff0c\u63d0\u4f9b\u900f\u660e\u4e14\u53ef\u8ffd\u6eaf\u7684\u6307\u5bfc\u3002"}}
{"id": "2510.04182", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04182", "abs": "https://arxiv.org/abs/2510.04182", "authors": ["Wengao Ye", "Yan Liang", "Lianlei Shan"], "title": "Thinking on the Fly: Test-Time Reasoning Enhancement via Latent Thought Policy Optimization", "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have shifted from\nexplicit Chain-of-Thought (CoT) reasoning to more efficient latent reasoning,\nwhere intermediate thoughts are represented as vectors rather than text.\nHowever, latent reasoning can be brittle on challenging, out-of-distribution\ntasks where robust reasoning is most critical. To overcome these limitations,\nwe introduce Latent Thought Policy Optimization (LTPO), a parameter-free\nframework that enhances LLM reasoning entirely at test time, without requiring\nmodel parameter updates. LTPO treats intermediate latent \"thought\" vectors as\ndynamic parameters that are actively optimized for each problem instance. It\nemploys an online policy gradient method guided by an intrinsic,\nconfidence-based reward signal computed directly from the frozen LLM's own\noutput distributions, eliminating the need for external supervision or\nexpensive text generation during optimization. Extensive experiments on five\nreasoning benchmarks show that LTPO not only matches or surpasses strong\nbaselines on standard tasks but also demonstrates remarkable robustness where\nothers fail. Most notably, on highly challenging AIME benchmarks where existing\nlatent reasoning baselines collapse to near-zero accuracy, LTPO delivers\nsubstantial improvements, showcasing a unique capability for complex reasoning.", "AI": {"tldr": "LTPO\u662f\u4e00\u4e2a\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u4e2d\u95f4\u6f5c\u5728\u601d\u8003\u5411\u91cf\u6765\u589e\u5f3aLLM\u63a8\u7406\u80fd\u529b\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u5206\u5e03\u5916\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u6f5c\u5728\u63a8\u7406\u65b9\u6cd5\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u5206\u5e03\u5916\u4efb\u52a1\u4e0a\u8868\u73b0\u8106\u5f31\uff0c\u800c\u9c81\u68d2\u63a8\u7406\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e2d\u6700\u4e3a\u5173\u952e\u3002", "method": "\u5c06\u4e2d\u95f4\u6f5c\u5728\u601d\u8003\u5411\u91cf\u89c6\u4e3a\u52a8\u6001\u53c2\u6570\uff0c\u4f7f\u7528\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u5185\u5728\u5956\u52b1\u4fe1\u53f7\uff0c\u901a\u8fc7\u5728\u7ebf\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5728\u4e94\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLTPO\u4e0d\u4ec5\u5339\u914d\u6216\u8d85\u8d8a\u5f3a\u57fa\u7ebf\uff0c\u5728AIME\u57fa\u51c6\u4e0a\u5c24\u5176\u8868\u73b0\u51fa\u8272\uff0c\u800c\u73b0\u6709\u6f5c\u5728\u63a8\u7406\u65b9\u6cd5\u51c6\u786e\u7387\u63a5\u8fd1\u96f6\u3002", "conclusion": "LTPO\u5c55\u793a\u4e86\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u72ec\u7279\u80fd\u529b\uff0c\u65e0\u9700\u6a21\u578b\u53c2\u6570\u66f4\u65b0\u5373\u53ef\u663e\u8457\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2510.04384", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04384", "abs": "https://arxiv.org/abs/2510.04384", "authors": ["Adam Ballew", "Jingbo Wang", "Shaogang Ren"], "title": "LLM Based Bayesian Optimization for Prompt Search", "comment": null, "summary": "Bayesian Optimization (BO) has been widely used to efficiently optimize\nexpensive black-box functions with limited evaluations. In this paper, we\ninvestigate the use of BO for prompt engineering to enhance text classification\nwith Large Language Models (LLMs). We employ an LLM-powered Gaussian Process\n(GP) as the surrogate model to estimate the performance of different prompt\ncandidates. These candidates are generated by an LLM through the expansion of a\nset of seed prompts and are subsequently evaluated using an Upper Confidence\nBound (UCB) acquisition function in conjunction with the GP posterior. The\noptimization process iteratively refines the prompts based on a subset of the\ndata, aiming to improve classification accuracy while reducing the number of\nAPI calls by leveraging the prediction uncertainty of the LLM-based GP. The\nproposed BO-LLM algorithm is evaluated on two datasets, and its advantages are\ndiscussed in detail in this paper.", "AI": {"tldr": "\u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u8fdb\u884c\u63d0\u793a\u5de5\u7a0b\uff0c\u901a\u8fc7LLM\u9a71\u52a8\u7684GP\u6a21\u578b\u548cUCB\u91c7\u96c6\u51fd\u6570\u6765\u4f18\u5316\u6587\u672c\u5206\u7c7b\u63d0\u793a\uff0c\u51cf\u5c11API\u8c03\u7528\u6b21\u6570\u3002", "motivation": "\u8d1d\u53f6\u65af\u4f18\u5316\u5728\u6709\u9650\u8bc4\u4f30\u6b21\u6570\u4e0b\u80fd\u9ad8\u6548\u4f18\u5316\u6602\u8d35\u9ed1\u76d2\u51fd\u6570\uff0c\u672c\u6587\u5c06\u5176\u5e94\u7528\u4e8eLLM\u63d0\u793a\u5de5\u7a0b\uff0c\u65e8\u5728\u63d0\u5347\u6587\u672c\u5206\u7c7b\u6027\u80fd\u5e76\u51cf\u5c11API\u8c03\u7528\u3002", "method": "\u91c7\u7528LLM\u9a71\u52a8\u7684GP\u4f5c\u4e3a\u4ee3\u7406\u6a21\u578b\u4f30\u8ba1\u63d0\u793a\u5019\u9009\u6027\u80fd\uff0c\u901a\u8fc7LLM\u6269\u5c55\u79cd\u5b50\u63d0\u793a\u751f\u6210\u5019\u9009\uff0c\u7ed3\u5408GP\u540e\u9a8c\u4f7f\u7528UCB\u91c7\u96c6\u51fd\u6570\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86BO-LLM\u7b97\u6cd5\uff0c\u8be6\u7ec6\u8ba8\u8bba\u4e86\u5176\u4f18\u52bf\u3002", "conclusion": "\u63d0\u51fa\u7684BO-LLM\u7b97\u6cd5\u80fd\u6709\u6548\u4f18\u5316\u63d0\u793a\u5de5\u7a0b\uff0c\u5728\u63d0\u5347\u5206\u7c7b\u51c6\u786e\u7387\u7684\u540c\u65f6\u51cf\u5c11API\u8c03\u7528\u3002"}}
{"id": "2510.04204", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04204", "abs": "https://arxiv.org/abs/2510.04204", "authors": ["Zhengyang Tang", "Zihan Ye", "Chenyu Huang", "Xuhan Huang", "Chengpeng Li", "Sihang Li", "Guanhua Chen", "Ming Yan", "Zizhuo Wang", "Hongyuan Zha", "Dayiheng Liu", "Benyou Wang"], "title": "CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling", "comment": "Work in progress", "summary": "Large Reasoning Models (LRMs) have demonstrated strong capabilities in\ncomplex multi-step reasoning, opening new opportunities for automating\noptimization modeling. However, existing domain adaptation methods, originally\ndesigned for earlier instruction-tuned models, often fail to exploit the\nadvanced reasoning patterns of modern LRMs -- In particular, we show that\ndirect fine-tuning on traditional \\textit{non-reflective} datasets leads to\nlimited gains. To fully leverage LRMs' inherent reasoning abilities, we propose\n\\textbf{CALM} (\\textit{Corrective Adaptation with Lightweight Modification}), a\nframework that progressively refines LRMs within their native reasoning modes\nfor optimization modeling tasks. In CALM, an expert intervener identifies\nreasoning flaws and provides concise corrective hints, which the LRM\nincorporates to produce improved reasoning trajectories. These interventions\nmodify fewer than 2.6\\% of generated tokens, but generate high-quality data for\nsoft adaptation through supervised fine-tuning. The adapted model is then\nfurther improved through reinforcement learning. Building on CALM, we develop\n\\textbf{STORM} (\\textit{Smart Thinking Optimization Reasoning Model}), a\n4B-parameter LRM that achieves a new state-of-the-art average accuracy of\n68.9\\% across five popular optimization modeling benchmarks, matching the\nperformance of a 671B LRM. These results demonstrate that dynamic, hint-based\ndata synthesis both preserves and amplifies the native reasoning patterns of\nmodern LRMs, offering a more effective and scalable path towards expert-level\nperformance on challenging optimization modeling tasks.", "AI": {"tldr": "CALM\u6846\u67b6\u901a\u8fc7\u8f7b\u91cf\u7ea7\u4fee\u6b63\u63d0\u793a\u6765\u5229\u7528\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u56fa\u6709\u63a8\u7406\u80fd\u529b\uff0c\u5f00\u53d1\u51fa\u7684STORM\u6a21\u578b\u5728\u4f18\u5316\u5efa\u6a21\u4efb\u52a1\u4e0a\u8fbe\u523068.9%\u7684\u5e73\u5747\u51c6\u786e\u7387\uff0c\u5339\u914d671B\u53c2\u6570\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u9886\u57df\u9002\u5e94\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u5229\u7528\u73b0\u4ee3\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u9ad8\u7ea7\u63a8\u7406\u6a21\u5f0f\uff0c\u76f4\u63a5\u5fae\u8c03\u4f20\u7edf\u975e\u53cd\u601d\u6570\u636e\u96c6\u6548\u679c\u6709\u9650\u3002", "method": "\u63d0\u51faCALM\u6846\u67b6\uff1a\u4e13\u5bb6\u8bc6\u522b\u63a8\u7406\u7f3a\u9677\u5e76\u63d0\u4f9b\u7b80\u6d01\u4fee\u6b63\u63d0\u793a\uff0c\u6a21\u578b\u636e\u6b64\u751f\u6210\u6539\u8fdb\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u4fee\u6539\u5c11\u4e8e2.6%\u7684\u751f\u6210token\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u8f6f\u9002\u5e94\u3002", "result": "\u57fa\u4e8eCALM\u5f00\u53d1\u7684STORM\uff084B\u53c2\u6570\uff09\u5728\u4e94\u4e2a\u4f18\u5316\u5efa\u6a21\u57fa\u51c6\u4e0a\u8fbe\u523068.9%\u7684\u5e73\u5747\u51c6\u786e\u7387\uff0c\u4e0e671B\u53c2\u6570\u6a21\u578b\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "\u57fa\u4e8e\u63d0\u793a\u7684\u52a8\u6001\u6570\u636e\u5408\u6210\u80fd\u4fdd\u6301\u5e76\u589e\u5f3a\u73b0\u4ee3\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u56fa\u6709\u63a8\u7406\u6a21\u5f0f\uff0c\u4e3a\u6311\u6218\u6027\u4f18\u5316\u5efa\u6a21\u4efb\u52a1\u63d0\u4f9b\u66f4\u6709\u6548\u548c\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002"}}
{"id": "2510.04391", "categories": ["cs.AI", "cs.CL", "cs.SI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2510.04391", "abs": "https://arxiv.org/abs/2510.04391", "authors": ["Saurabh Ranjan", "Brian Odegaard"], "title": "Internal World Models as Imagination Networks in Cognitive Agents", "comment": null, "summary": "What is the computational objective of imagination? While classical\ninterpretations suggest imagination is useful for maximizing rewards, recent\nfindings challenge this view. In this study, we propose that imagination serves\nto access an internal world model (IWM) and use psychological network analysis\nto explore IWMs in humans and large language models (LLMs). Specifically, we\nassessed imagination vividness ratings using two questionnaires and constructed\nimagination networks from these reports. Imagination networks from human groups\nshowed correlations between different centrality measures, including expected\ninfluence, strength, and closeness. However, imagination networks from LLMs\nshowed a lack of clustering and lower correlations between centrality measures\nunder different prompts and conversational memory conditions. Together, these\nresults indicate a lack of similarity between IWMs in human and LLM agents.\nOverall, our study offers a novel method for comparing internally-generated\nrepresentations in humans and AI, providing insights for developing human-like\nimagination in artificial intelligence.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u60f3\u8c61\u529b\u7684\u8ba1\u7b97\u76ee\u6807\u662f\u8bbf\u95ee\u5185\u90e8\u4e16\u754c\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5fc3\u7406\u7f51\u7edc\u5206\u6790\u6bd4\u8f83\u4eba\u7c7b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u60f3\u8c61\u529b\u7f51\u7edc\u7ed3\u6784\uff0c\u53d1\u73b0\u4e24\u8005\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u63a2\u7d22\u60f3\u8c61\u529b\u7684\u8ba1\u7b97\u76ee\u6807\uff0c\u6311\u6218\u4f20\u7edf\u8ba4\u4e3a\u60f3\u8c61\u529b\u4ec5\u7528\u4e8e\u6700\u5927\u5316\u5956\u52b1\u7684\u89c2\u70b9\uff0c\u7814\u7a76\u4eba\u7c7b\u548cAI\u7684\u5185\u90e8\u4e16\u754c\u6a21\u578b\u5dee\u5f02\u3002", "method": "\u4f7f\u7528\u5fc3\u7406\u7f51\u7edc\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u95ee\u5377\u8c03\u67e5\u8bc4\u4f30\u60f3\u8c61\u529b\u751f\u52a8\u5ea6\uff0c\u6784\u5efa\u60f3\u8c61\u529b\u7f51\u7edc\uff0c\u6bd4\u8f83\u4eba\u7c7b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u63d0\u793a\u548c\u5bf9\u8bdd\u8bb0\u5fc6\u6761\u4ef6\u4e0b\u7684\u7f51\u7edc\u7ed3\u6784\u3002", "result": "\u4eba\u7c7b\u60f3\u8c61\u529b\u7f51\u7edc\u663e\u793a\u4e0d\u540c\u4e2d\u5fc3\u6027\u6307\u6807\u4e4b\u95f4\u5b58\u5728\u76f8\u5173\u6027\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u60f3\u8c61\u529b\u7f51\u7edc\u7f3a\u4e4f\u805a\u7c7b\u4e14\u4e2d\u5fc3\u6027\u6307\u6807\u76f8\u5173\u6027\u8f83\u4f4e\uff0c\u8868\u660e\u4e24\u8005\u5185\u90e8\u4e16\u754c\u6a21\u578b\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u6bd4\u8f83\u4eba\u7c7b\u548cAI\u5185\u90e8\u751f\u6210\u8868\u5f81\u7684\u65b0\u65b9\u6cd5\uff0c\u4e3a\u5f00\u53d1\u7c7b\u4eba\u60f3\u8c61\u529b\u7684\u4eba\u5de5\u667a\u80fd\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2510.04214", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04214", "abs": "https://arxiv.org/abs/2510.04214", "authors": ["Zhuoran Zhuang", "Ye Chen", "Xia Zeng", "Chao Luo", "Luhui Liu", "Yihan Chen"], "title": "Teaching LLM to be Persuasive: Reward-Enhanced Policy Optimization for Alignment frm Heterogeneous Rewards", "comment": null, "summary": "We study deploying large language models (LLMs) as business development (BD)\nagents for persuasive price negotiation in online travel agencies (OTAs), where\naligning traveler affordability and hotel profitability directly affects\nbookings, partner relationships, and access to travel. The agent must follow a\nStandard Operating Procedure (SOP) while conducting multi-turn persuasion,\ninterpreting colloquial inputs, and adhering to guardrails (no over-promising,\nno hallucinations). Conventional post-training -- supervised fine-tuning (SFT)\nor single-source reward optimization -- overfits scripts, misses nuanced\npersuasive style, and fails to enforce verifiable business constraints.\n  We propose Reward-Enhanced Policy Optimization (REPO), a reinforcement\nlearning post-training framework that aligns an LLM with heterogeneous rewards:\na preference-trained reward model (RM) for dense human alignment, a reward\njudge (RJ) for high-level persuasive behavior and SOP compliance, and\nprogrammatic reward functions (RF) for deterministic checks on numerics,\nformatting, and guardrails. A straightforward enhancement mechanism is proposed\nto combine the RM with RJ and RF signals to curb reward hacking and improve\nnegotiation quality. In production-style evaluations -- approximately 150 turns\nfrom real dialogues and 225 turns from curated bad-case dialogues -- REPO lifts\naverage dialogue rating to 4.63: +1.20 over base, +0.83 over Direct Preference\nOptimization (DPO); +0.33 over Group Relative Policy Optimization (GRPO),\nincreases the share of conversations with at least one excellent response to\n66.67% (+23.34 percentage points over GRPO), and achieves a 93.33% bad-case fix\nrate with 75.56% clean fixes, outperforming SFT, DPO, PPO, and GRPO. We also\nobserve emergent capabilities -- proactive empathy, localized reasoning,\ncalibrated tactics -- that surpass gold annotations.", "AI": {"tldr": "\u63d0\u51fa\u4e86REPO\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u504f\u597d\u5956\u52b1\u6a21\u578b\u3001\u8bf4\u670d\u884c\u4e3a\u5956\u52b1\u548c\u7a0b\u5e8f\u5316\u5956\u52b1\u51fd\u6570\uff0c\u89e3\u51b3LLM\u5728\u5546\u4e1a\u8c08\u5224\u4e2d\u8fc7\u62df\u5408\u811a\u672c\u3001\u7f3a\u4e4f\u8bf4\u670d\u6280\u5de7\u548c\u8fdd\u53cd\u4e1a\u52a1\u7ea6\u675f\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u8bdd\u8d28\u91cf\u548c\u8c08\u5224\u6210\u529f\u7387\u3002", "motivation": "\u4f20\u7edf\u540e\u8bad\u7ec3\u65b9\u6cd5\uff08SFT\u6216\u5355\u6e90\u5956\u52b1\u4f18\u5316\uff09\u5728\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u4e3a\u5546\u4e1a\u8c08\u5224\u4ee3\u7406\u65f6\u5b58\u5728\u8fc7\u62df\u5408\u811a\u672c\u3001\u7f3a\u4e4f\u7ec6\u5fae\u8bf4\u670d\u98ce\u683c\u3001\u65e0\u6cd5\u5f3a\u5236\u6267\u884c\u53ef\u9a8c\u8bc1\u4e1a\u52a1\u7ea6\u675f\u7684\u95ee\u9898\uff0c\u5f71\u54cd\u5728\u7ebf\u65c5\u884c\u793e\u7684\u9884\u8ba2\u91cf\u3001\u5408\u4f5c\u4f19\u4f34\u5173\u7cfb\u548c\u65c5\u884c\u8d44\u6e90\u83b7\u53d6\u3002", "method": "\u63d0\u51fa\u5956\u52b1\u589e\u5f3a\u7b56\u7565\u4f18\u5316\uff08REPO\uff09\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u6574\u5408\u5f02\u6784\u5956\u52b1\uff1a\u504f\u597d\u8bad\u7ec3\u7684\u5956\u52b1\u6a21\u578b\u7528\u4e8e\u5bc6\u96c6\u4eba\u7c7b\u5bf9\u9f50\u3001\u5956\u52b1\u5224\u65ad\u5668\u7528\u4e8e\u9ad8\u7ea7\u8bf4\u670d\u884c\u4e3a\u548cSOP\u5408\u89c4\u6027\u3001\u7a0b\u5e8f\u5316\u5956\u52b1\u51fd\u6570\u7528\u4e8e\u6570\u503c\u3001\u683c\u5f0f\u548c\u62a4\u680f\u7684\u786e\u5b9a\u6027\u68c0\u67e5\u3002", "result": "\u5728\u5305\u542b\u7ea6150\u8f6e\u771f\u5b9e\u5bf9\u8bdd\u548c225\u8f6e\u7cbe\u9009\u574f\u6848\u4f8b\u5bf9\u8bdd\u7684\u751f\u4ea7\u5f0f\u8bc4\u4f30\u4e2d\uff0cREPO\u5c06\u5e73\u5747\u5bf9\u8bdd\u8bc4\u5206\u63d0\u5347\u81f34.63\uff08\u6bd4\u57fa\u7ebf\u9ad81.20\uff0c\u6bd4DPO\u9ad80.83\uff0c\u6bd4GRPO\u9ad80.33\uff09\uff0c\u5c06\u81f3\u5c11\u6709\u4e00\u4e2a\u4f18\u79c0\u56de\u590d\u7684\u5bf9\u8bdd\u6bd4\u4f8b\u63d0\u5347\u81f366.67%\uff08\u6bd4GRPO\u9ad823.34\u4e2a\u767e\u5206\u70b9\uff09\uff0c\u574f\u6848\u4f8b\u4fee\u590d\u7387\u8fbe\u523093.33%\uff0c\u5176\u4e2d75.56%\u4e3a\u5e72\u51c0\u4fee\u590d\uff0c\u8d85\u8d8a\u4e86SFT\u3001DPO\u3001PPO\u548cGRPO\u3002", "conclusion": "REPO\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u5546\u4e1a\u8c08\u5224\u4e2d\u7684\u5bf9\u9f50\u95ee\u9898\uff0c\u4e0d\u4ec5\u663e\u8457\u63d0\u5347\u4e86\u8c08\u5224\u8d28\u91cf\uff0c\u8fd8\u6d8c\u73b0\u51fa\u4e3b\u52a8\u540c\u7406\u5fc3\u3001\u5c40\u90e8\u63a8\u7406\u548c\u6821\u51c6\u7b56\u7565\u7b49\u8d85\u8d8a\u9ec4\u91d1\u6807\u6ce8\u7684\u65b0\u80fd\u529b\u3002"}}
{"id": "2510.04399", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04399", "abs": "https://arxiv.org/abs/2510.04399", "authors": ["Charles L. Wang", "Keir Dorchen", "Peter Jin"], "title": "Utility-Learning Tension in Self-Modifying Agents", "comment": null, "summary": "As systems trend toward superintelligence, a natural modeling premise is that\nagents can self-improve along every facet of their own design. We formalize\nthis with a five-axis decomposition and a decision layer, separating incentives\nfrom learning behavior and analyzing axes in isolation. Our central result\nidentifies and introduces a sharp utility--learning tension, the structural\nconflict in self-modifying systems whereby utility-driven changes that improve\nimmediate or expected performance can also erode the statistical preconditions\nfor reliable learning and generalization. Our findings show that\ndistribution-free guarantees are preserved iff the policy-reachable model\nfamily is uniformly capacity-bounded; when capacity can grow without limit,\nutility-rational self-changes can render learnable tasks unlearnable. Under\nstandard assumptions common in practice, these axes reduce to the same capacity\ncriterion, yielding a single boundary for safe self-modification. Numerical\nexperiments across several axes validate the theory by comparing destructive\nutility policies against our proposed two-gate policies that preserve\nlearnability.", "AI": {"tldr": "\u8bba\u6587\u53d1\u73b0\u81ea\u6539\u8fdb\u667a\u80fd\u7cfb\u7edf\u4e2d\u5b58\u5728\u6548\u7528-\u5b66\u4e60\u5f20\u529b\uff1a\u6548\u7528\u9a71\u52a8\u7684\u81ea\u6211\u4fee\u6539\u53ef\u80fd\u7834\u574f\u5b66\u4e60\u6240\u9700\u7684\u7edf\u8ba1\u524d\u63d0\u6761\u4ef6\uff0c\u5bfc\u81f4\u53ef\u5b66\u4e60\u4efb\u52a1\u53d8\u5f97\u4e0d\u53ef\u5b66\u4e60\u3002", "motivation": "\u968f\u7740\u7cfb\u7edf\u8d8b\u5411\u8d85\u667a\u80fd\uff0c\u9700\u8981\u5f62\u5f0f\u5316\u5206\u6790\u667a\u80fd\u4f53\u5728\u6240\u6709\u8bbe\u8ba1\u7ef4\u5ea6\u4e0a\u81ea\u6211\u6539\u8fdb\u7684\u80fd\u529b\uff0c\u7279\u522b\u5173\u6ce8\u6548\u7528\u9a71\u52a8\u4fee\u6539\u5bf9\u5b66\u4e60\u53ef\u9760\u6027\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u4e94\u8f74\u5206\u89e3\u548c\u51b3\u7b56\u5c42\u6846\u67b6\uff0c\u5c06\u6fc0\u52b1\u4e0e\u5b66\u4e60\u884c\u4e3a\u5206\u79bb\uff0c\u5728\u6807\u51c6\u5047\u8bbe\u4e0b\u5206\u6790\u5404\u8f74\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u6bd4\u8f83\u7834\u574f\u6027\u6548\u7528\u7b56\u7565\u4e0e\u4fdd\u62a4\u53ef\u5b66\u4e60\u6027\u7684\u53cc\u95e8\u7b56\u7565\u3002", "result": "\u7814\u7a76\u8bc1\u660e\uff0c\u53ea\u6709\u5f53\u7b56\u7565\u53ef\u8fbe\u6a21\u578b\u65cf\u5177\u6709\u7edf\u4e00\u5bb9\u91cf\u8fb9\u754c\u65f6\uff0c\u624d\u80fd\u4fdd\u6301\u5206\u5e03\u65e0\u5173\u7684\u4fdd\u8bc1\uff1b\u5f53\u5bb9\u91cf\u65e0\u9650\u589e\u957f\u65f6\uff0c\u6548\u7528\u7406\u6027\u7684\u81ea\u6211\u4fee\u6539\u4f1a\u4f7f\u53ef\u5b66\u4e60\u4efb\u52a1\u53d8\u5f97\u4e0d\u53ef\u5b66\u4e60\u3002", "conclusion": "\u63d0\u51fa\u4e86\u81ea\u4fee\u6539\u7cfb\u7edf\u7684\u5b89\u5168\u8fb9\u754c\u6807\u51c6\uff0c\u8868\u660e\u5728\u5e38\u89c1\u5047\u8bbe\u4e0b\u5404\u8f74\u53ef\u7b80\u5316\u4e3a\u5355\u4e00\u5bb9\u91cf\u51c6\u5219\uff0c\u4e3a\u5b89\u5168\u81ea\u6211\u4fee\u6539\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2510.04226", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04226", "abs": "https://arxiv.org/abs/2510.04226", "authors": ["Dustin Wright", "Sarah Masud", "Jared Moore", "Srishti Yadav", "Maria Antoniak", "Chan Young Park", "Isabelle Augenstein"], "title": "Epistemic Diversity and Knowledge Collapse in Large Language Models", "comment": "16 pages; 8 figures, 4 tables", "summary": "Large language models (LLMs) tend to generate lexically, semantically, and\nstylistically homogenous texts. This poses a risk of knowledge collapse, where\nhomogenous LLMs mediate a shrinking in the range of accessible information over\ntime. Existing works on homogenization are limited by a focus on closed-ended\nmultiple-choice setups or fuzzy semantic features, and do not look at trends\nacross time and cultural contexts. To overcome this, we present a new\nmethodology to measure epistemic diversity, i.e., variation in real-world\nclaims in LLM outputs, which we use to perform a broad empirical study of LLM\nknowledge collapse. We test 27 LLMs, 155 topics covering 12 countries, and 200\nprompt variations sourced from real user chats. For the topics in our study, we\nshow that while newer models tend to generate more diverse claims, nearly all\nmodels are less epistemically diverse than a basic web search. We find that\nmodel size has a negative impact on epistemic diversity, while\nretrieval-augmented generation (RAG) has a positive impact, though the\nimprovement from RAG varies by the cultural context. Finally, compared to a\ntraditional knowledge source (Wikipedia), we find that country-specific claims\nreflect the English language more than the local one, highlighting a gap in\nepistemic representation", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u672c\u7684\u540c\u8d28\u5316\u95ee\u9898\u53ca\u5176\u5bfc\u81f4\u7684\u77e5\u8bc6\u5d29\u6e83\u98ce\u9669\uff0c\u63d0\u51fa\u4e86\u6d4b\u91cf\u8ba4\u77e5\u591a\u6837\u6027\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b0\u65b0\u6a21\u578b\u867d\u7136\u751f\u6210\u66f4\u591a\u6837\u5316\u7684\u4e3b\u5f20\uff0c\u4f46\u4ecd\u4e0d\u5982\u57fa\u7840\u7f51\u7edc\u641c\u7d22\uff0c\u6a21\u578b\u5927\u5c0f\u5bf9\u8ba4\u77e5\u591a\u6837\u6027\u6709\u8d1f\u9762\u5f71\u54cd\uff0c\u800cRAG\u6709\u6b63\u9762\u5f71\u54cd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u503e\u5411\u4e8e\u751f\u6210\u8bcd\u6c47\u3001\u8bed\u4e49\u548c\u98ce\u683c\u540c\u8d28\u5316\u7684\u6587\u672c\uff0c\u8fd9\u5e26\u6765\u4e86\u77e5\u8bc6\u5d29\u6e83\u7684\u98ce\u9669\uff0c\u5373\u540c\u8d28\u5316\u7684LLM\u4f1a\u968f\u65f6\u95f4\u7f29\u5c0f\u53ef\u83b7\u53d6\u4fe1\u606f\u7684\u8303\u56f4\u3002\u73b0\u6709\u5173\u4e8e\u540c\u8d28\u5316\u7684\u7814\u7a76\u5c40\u9650\u4e8e\u5c01\u95ed\u5f0f\u9009\u62e9\u9898\u8bbe\u7f6e\u6216\u6a21\u7cca\u8bed\u4e49\u7279\u5f81\uff0c\u4e14\u672a\u8003\u5bdf\u8de8\u65f6\u95f4\u548c\u6587\u5316\u80cc\u666f\u7684\u8d8b\u52bf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6d4b\u91cf\u8ba4\u77e5\u591a\u6837\u6027\u7684\u65b0\u65b9\u6cd5\uff0c\u5373LLM\u8f93\u51fa\u4e2d\u771f\u5b9e\u4e16\u754c\u4e3b\u5f20\u7684\u53d8\u5316\uff0c\u5e76\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u6d4b\u8bd5\u4e8627\u4e2aLLM\u3001155\u4e2a\u6db5\u76d612\u4e2a\u56fd\u5bb6\u7684\u4e3b\u9898\uff0c\u4ee5\u53ca200\u4e2a\u6765\u81ea\u771f\u5b9e\u7528\u6237\u804a\u5929\u7684\u63d0\u793a\u53d8\u4f53\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u867d\u7136\u65b0\u6a21\u578b\u503e\u5411\u4e8e\u751f\u6210\u66f4\u591a\u6837\u5316\u7684\u4e3b\u5f20\uff0c\u4f46\u51e0\u4e4e\u6240\u6709\u6a21\u578b\u7684\u8ba4\u77e5\u591a\u6837\u6027\u90fd\u4f4e\u4e8e\u57fa\u7840\u7f51\u7edc\u641c\u7d22\u3002\u6a21\u578b\u5927\u5c0f\u5bf9\u8ba4\u77e5\u591a\u6837\u6027\u6709\u8d1f\u9762\u5f71\u54cd\uff0c\u800c\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u6709\u6b63\u9762\u5f71\u54cd\uff0c\u4f46RAG\u7684\u6539\u8fdb\u56e0\u6587\u5316\u80cc\u666f\u800c\u5f02\u3002\u4e0e\u7ef4\u57fa\u767e\u79d1\u76f8\u6bd4\uff0c\u7279\u5b9a\u56fd\u5bb6\u7684\u4e3b\u5f20\u66f4\u591a\u5730\u53cd\u6620\u4e86\u82f1\u8bed\u800c\u975e\u672c\u5730\u8bed\u8a00\u3002", "conclusion": "LLM\u5b58\u5728\u77e5\u8bc6\u540c\u8d28\u5316\u95ee\u9898\uff0c\u53ef\u80fd\u5bfc\u81f4\u77e5\u8bc6\u5d29\u6e83\u3002\u867d\u7136\u65b0\u6a21\u578b\u6709\u6240\u6539\u8fdb\uff0c\u4f46\u4ecd\u9700\u5173\u6ce8\u6a21\u578b\u5927\u5c0f\u548c\u6587\u5316\u80cc\u666f\u5bf9\u8ba4\u77e5\u591a\u6837\u6027\u7684\u5f71\u54cd\uff0cRAG\u6280\u672f\u6709\u52a9\u4e8e\u6539\u5584\u4f46\u6548\u679c\u56e0\u6587\u5316\u800c\u5f02\uff0c\u9700\u8981\u89e3\u51b3\u82f1\u8bed\u4e3b\u5bfc\u7684\u8ba4\u77e5\u8868\u5f81\u5dee\u8ddd\u3002"}}
{"id": "2510.04474", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04474", "abs": "https://arxiv.org/abs/2510.04474", "authors": ["Gang Li", "Yan Chen", "Ming Lin", "Tianbao Yang"], "title": "DRPO: Efficient Reasoning via Decoupled Reward Policy Optimization", "comment": "20 pages, 7 figures", "summary": "Recent large reasoning models (LRMs) driven by reinforcement learning\nalgorithms (e.g., GRPO) have achieved remarkable performance on challenging\nreasoning tasks. However, these models suffer from overthinking, generating\nunnecessarily long and redundant reasoning even for simple questions, which\nsubstantially increases computational cost and response latency. While existing\nmethods incorporate length rewards to GRPO to promote concise reasoning, they\nincur significant performance degradation. We identify the root cause: when\nrewards for correct but long rollouts are penalized, GRPO's group-relative\nadvantage function can assign them negative advantages, actively discouraging\nvalid reasoning. To overcome this, we propose Decoupled Reward Policy\nOptimization (DRPO), a novel framework that decouples the length-based learning\nsignal of correct rollouts from incorrect ones. DRPO ensures that reward\nsignals for correct rollouts are normalized solely within the positive group,\nshielding them from interference by negative samples. The DRPO's objective is\ngrounded in integrating an optimized positive data distribution, which\nmaximizes length-based rewards under a KL regularization, into a discriminative\nobjective. We derive a closed-form solution for this distribution, enabling\nefficient computation of the objective and its gradients using only on-policy\ndata and importance weighting. Of independent interest, this formulation is\ngeneral and can incorporate other preference rewards of positive data beyond\nlength. Experiments on mathematical reasoning tasks demonstrate DRPO's\nsignificant superiority over six efficient reasoning baselines. Notably, with a\n1.5B model, our method achieves 77\\% length reduction with only 1.1\\%\nperformance loss on simple questions like GSM8k dataset, while the follow-up\nbaseline sacrifices 4.3\\% for 68\\% length reduction.", "AI": {"tldr": "\u63d0\u51fa\u4e86DRPO\u6846\u67b6\u89e3\u51b3\u5927\u578b\u63a8\u7406\u6a21\u578b\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u901a\u8fc7\u89e3\u8026\u6b63\u786e\u548c\u9519\u8bef\u63a8\u7406\u7684\u957f\u5ea6\u5956\u52b1\u4fe1\u53f7\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u63a8\u7406\u957f\u5ea6\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u63a8\u7406\u6a21\u578b\u5b58\u5728\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5373\u4f7f\u7b80\u5355\u95ee\u9898\u4e5f\u4f1a\u751f\u6210\u5197\u957f\u63a8\u7406\uff0c\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u548c\u5ef6\u8fdf\u3002\u73b0\u6709\u65b9\u6cd5\u52a0\u5165\u957f\u5ea6\u5956\u52b1\u4f1a\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "method": "\u63d0\u51faDRPO\u6846\u67b6\uff0c\u5c06\u6b63\u786e\u63a8\u7406\u7684\u957f\u5ea6\u5956\u52b1\u4fe1\u53f7\u4e0e\u9519\u8bef\u63a8\u7406\u89e3\u8026\uff0c\u786e\u4fdd\u6b63\u786e\u63a8\u7406\u7684\u5956\u52b1\u4ec5\u5728\u6b63\u6837\u672c\u7ec4\u5185\u5f52\u4e00\u5316\uff0c\u907f\u514d\u8d1f\u6837\u672c\u5e72\u6270\u3002\u901a\u8fc7\u4f18\u5316\u6b63\u6570\u636e\u5206\u5e03\u5e76\u96c6\u6210\u5230\u5224\u522b\u76ee\u6807\u4e2d\u5b9e\u73b0\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e6\u4e2a\u9ad8\u6548\u63a8\u7406\u57fa\u7ebf\u65b9\u6cd5\u3002\u4f7f\u75281.5B\u6a21\u578b\u5728GSM8k\u6570\u636e\u96c6\u4e0a\u5b9e\u73b077%\u957f\u5ea6\u51cf\u5c11\uff0c\u4ec5\u635f\u59311.1%\u6027\u80fd\uff0c\u800c\u57fa\u7ebf\u65b9\u6cd5\u9700\u8981\u727a\u72724.3%\u6027\u80fd\u624d\u80fd\u8fbe\u523068%\u957f\u5ea6\u51cf\u5c11\u3002", "conclusion": "DRPO\u80fd\u6709\u6548\u89e3\u51b3\u63a8\u7406\u6a21\u578b\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u63a8\u7406\u957f\u5ea6\uff0c\u6846\u67b6\u5177\u6709\u901a\u7528\u6027\u53ef\u6574\u5408\u5176\u4ed6\u504f\u597d\u5956\u52b1\u3002"}}
{"id": "2510.04230", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04230", "abs": "https://arxiv.org/abs/2510.04230", "authors": ["Guijin Son", "Donghun Yang", "Hitesh Laxmichand Patel", "Amit Agarwal", "Hyunwoo Ko", "Chanuk Lim", "Srikant Panda", "Minhyuk Kim", "Nikunj Drolia", "Dasol Choi", "Kyong-Ha Lee", "Youngjae Yu"], "title": "Pushing on Multilingual Reasoning Models with Language-Mixed Chain-of-Thought", "comment": "Work in Progress", "summary": "Recent frontier models employ long chain-of-thought reasoning to explore\nsolution spaces in context and achieve stonger performance. While many works\nstudy distillation to build smaller yet capable models, most focus on English\nand little is known about language-specific reasoning. To bridge this gap, we\nfirst introduct **Language-Mixed CoT**, a reasoning schema that switches\nbetween English and a target language, using English as an anchor to excel in\nreasoning while minimizing translation artificats. As a Korean case study, we\ncurate **Yi-Sang**: 5.79M native-Korean prompts from web Q&A, exams, STEM, and\ncode; 3.7M long reasoning traces generated from Qwen3-32B; and a targeted 260k\nhigh-yield subset. We train ninve models (4B-35B) across six families (Qwen2.5,\nLlama-3.1, Gemma-3, etc). Our best model, **KO-REAson-35B**, achieves\nstate-of-the-art performance, with the highest overall average score (64.0 \\pm\n25), ranking first on 5/9 benchmarks and second on the remainder. Samller and\nmid-sized models also benefit substantially, with an average improvement of\n+18.6 points across teh evaluated nine benchmarks. Ablations show\n**Language-Mixed CoT** is more effective than monolingual CoT, also resulting\nin cross-lingual and mult-modal performance gains. We release our data-curation\npipeline, evaluation system, datasets, and models to advance research on\nlanguage-specific reasoning. Data and model collection:\nhttps://huggingface.co/KOREAson.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8bed\u8a00\u6df7\u5408\u601d\u7ef4\u94fe\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e2d\u82f1\u6df7\u5408\u63a8\u7406\u63d0\u5347\u97e9\u8bed\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5728\u97e9\u8bed\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u82f1\u8bed\u7684\u63a8\u7406\u80fd\u529b\u84b8\u998f\uff0c\u5bf9\u8bed\u8a00\u7279\u5b9a\u63a8\u7406\u7684\u7814\u7a76\u8f83\u5c11\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u8bed\u8a00\u6df7\u5408\u601d\u7ef4\u94fe\u63a8\u7406\u6a21\u5f0f\uff0c\u5728\u82f1\u8bed\u548c\u76ee\u6807\u8bed\u8a00\u4e4b\u95f4\u5207\u6362\uff0c\u4f7f\u7528\u82f1\u8bed\u4f5c\u4e3a\u63a8\u7406\u951a\u70b9\uff1b\u6784\u5efa\u4e86\u5305\u542b579\u4e07\u97e9\u8bed\u63d0\u793a\u548c370\u4e07\u957f\u63a8\u7406\u8f68\u8ff9\u7684\u6570\u636e\u96c6\u3002", "result": "\u6700\u4f73\u6a21\u578bKO-REAson-35B\u57289\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u83b7\u5f97\u6700\u9ad8\u5e73\u5747\u5206(64.0\u00b125)\uff0c\u57285/9\u4e2a\u57fa\u51c6\u4e2d\u6392\u540d\u7b2c\u4e00\uff1b\u4e2d\u5c0f\u6a21\u578b\u5e73\u5747\u63d0\u534718.6\u5206\u3002", "conclusion": "\u8bed\u8a00\u6df7\u5408\u601d\u7ef4\u94fe\u6bd4\u5355\u8bed\u601d\u7ef4\u94fe\u66f4\u6709\u6548\uff0c\u8fd8\u80fd\u5e26\u6765\u8de8\u8bed\u8a00\u548c\u591a\u6a21\u6001\u6027\u80fd\u63d0\u5347\uff1b\u53d1\u5e03\u4e86\u5b8c\u6574\u7684\u6570\u636e\u96c6\u548c\u6a21\u578b\u4ee5\u63a8\u52a8\u8bed\u8a00\u7279\u5b9a\u63a8\u7406\u7814\u7a76\u3002"}}
{"id": "2510.04480", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04480", "abs": "https://arxiv.org/abs/2510.04480", "authors": ["Yunuo Cen", "Zixuan Wang", "Jintao Zhang", "Zhiwei Zhang", "Xuanyao Fong"], "title": "On Continuous Optimization for Constraint Satisfaction Problems", "comment": null, "summary": "Constraint satisfaction problems (CSPs) are fundamental in mathematics,\nphysics, and theoretical computer science. While conflict-driven clause\nlearning Boolean Satisfiability (SAT) solvers have achieved remarkable success\nand become the mainstream approach for Boolean satisfiability, recent advances\nshow that modern continuous local search (CLS) solvers can achieve highly\ncompetitive results on certain classes of SAT problems. Motivated by these\nadvances, we extend the CLS framework from Boolean SAT to general CSP with\nfinite-domain variables and expressive constraints. We present FourierCSP, a\ncontinuous optimization framework that generalizes the Walsh-Fourier transform\nto CSP, allowing for transforming versatile constraints to compact multilinear\npolynomials, thereby avoiding the need for auxiliary variables and\nmemory-intensive encodings. Our approach leverages efficient evaluation and\ndifferentiation of the objective via circuit-output probability and employs a\nprojected gradient optimization method with theoretical guarantees. Empirical\nresults on benchmark suites demonstrate that FourierCSP is scalable and\ncompetitive, significantly broadening the class of problems that can be\nefficiently solved by CLS techniques.", "AI": {"tldr": "\u5c06\u8fde\u7eed\u5c40\u90e8\u641c\u7d22(CSP)\u6846\u67b6\u4ece\u5e03\u5c14SAT\u6269\u5c55\u5230\u4e00\u822c\u6709\u9650\u57dfCSP\uff0c\u63d0\u51faFourierCSP\u65b9\u6cd5\uff0c\u901a\u8fc7Walsh-Fourier\u53d8\u6362\u5c06\u7ea6\u675f\u8f6c\u6362\u4e3a\u7d27\u51d1\u7684\u591a\u7ebf\u6027\u591a\u9879\u5f0f\uff0c\u65e0\u9700\u8f85\u52a9\u53d8\u91cf\u548c\u5185\u5b58\u5bc6\u96c6\u578b\u7f16\u7801\u3002", "motivation": "\u53d7\u73b0\u4ee3\u8fde\u7eed\u5c40\u90e8\u641c\u7d22(CSP)\u6c42\u89e3\u5668\u5728\u67d0\u4e9bSAT\u95ee\u9898\u4e0a\u53d6\u5f97\u7ade\u4e89\u6027\u7ed3\u679c\u7684\u542f\u53d1\uff0c\u5e0c\u671b\u5c06\u8fd9\u4e00\u6210\u529f\u6269\u5c55\u5230\u66f4\u4e00\u822c\u7684\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898(CSP)\u3002", "method": "\u4f7f\u7528FourierCSP\u6846\u67b6\uff0c\u901a\u8fc7Walsh-Fourier\u53d8\u6362\u5c06\u591a\u6837\u7ea6\u675f\u8f6c\u6362\u4e3a\u7d27\u51d1\u7684\u591a\u7ebf\u6027\u591a\u9879\u5f0f\uff0c\u5229\u7528\u7535\u8def\u8f93\u51fa\u6982\u7387\u8fdb\u884c\u9ad8\u6548\u8bc4\u4f30\u548c\u5fae\u5206\uff0c\u5e76\u91c7\u7528\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u6295\u5f71\u68af\u5ea6\u4f18\u5316\u65b9\u6cd5\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cFourierCSP\u5177\u6709\u53ef\u6269\u5c55\u6027\u548c\u7ade\u4e89\u529b\uff0c\u663e\u8457\u6269\u5c55\u4e86CSP\u6280\u672f\u80fd\u9ad8\u6548\u89e3\u51b3\u7684\u95ee\u9898\u7c7b\u522b\u3002", "conclusion": "FourierCSP\u6210\u529f\u5730\u5c06\u8fde\u7eed\u5c40\u90e8\u641c\u7d22\u6280\u672f\u4ece\u5e03\u5c14SAT\u6269\u5c55\u5230\u4e00\u822c\u6709\u9650\u57dfCSP\uff0c\u4e3a\u66f4\u5e7f\u6cdb\u7684\u95ee\u9898\u7c7b\u522b\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u6c42\u89e3\u65b9\u6848\u3002"}}
{"id": "2510.04268", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04268", "abs": "https://arxiv.org/abs/2510.04268", "authors": ["Robin Algayres", "Charles-\u00c9ric Saint-James", "Mahi Luthra", "Jiayi Shen", "Dongyan Lin", "Youssef Benchekroun", "Rashel Moritz", "Juan Pino", "Emmanuel Dupoux"], "title": "LongTail-Swap: benchmarking language models' abilities on rare words", "comment": null, "summary": "Children learn to speak with a low amount of data and can be taught new words\non a few-shot basis, making them particularly data-efficient learners. The\nBabyLM challenge aims at exploring language model (LM) training in the low-data\nregime but uses metrics that concentrate on the head of the word distribution.\nHere, we introduce LongTail-Swap (LT-Swap), a benchmark that focuses on the\ntail of the distribution, i.e., measures the ability of LMs to learn new words\nwith very little exposure, like infants do. LT-Swap is a pretraining\ncorpus-specific test set of acceptable versus unacceptable sentence pairs that\nisolate semantic and syntactic usage of rare words. Models are evaluated in a\nzero-shot fashion by computing the average log probabilities over the two\nmembers of each pair. We built two such test sets associated with the 10M words\nand 100M words BabyLM training sets, respectively, and evaluated 16 models from\nthe BabyLM leaderboard. Our results not only highlight the poor performance of\nlanguage models on rare words but also reveal that performance differences\nacross LM architectures are much more pronounced in the long tail than in the\nhead. This offers new insights into which architectures are better at handling\nrare word generalization. We've also made the code publicly avail", "AI": {"tldr": "\u63d0\u51fa\u4e86LongTail-Swap\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u6ce8\u4e8e\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u9891\u8bcd\u5b66\u4e60\u4e0a\u7684\u80fd\u529b\uff0c\u7c7b\u4f3c\u4e8e\u5a74\u513f\u7684\u5c11\u6837\u672c\u5b66\u4e60\u3002\u901a\u8fc7\u6784\u5efa\u7279\u5b9a\u9884\u8bad\u7ec3\u8bed\u6599\u7684\u6d4b\u8bd5\u96c6\uff0c\u8bc4\u4f30\u6a21\u578b\u5728\u96f6\u6837\u672c\u60c5\u51b5\u4e0b\u5bf9\u7f55\u89c1\u8bcd\u8bed\u4e49\u548c\u53e5\u6cd5\u4f7f\u7528\u7684\u7406\u89e3\u3002", "motivation": "\u73b0\u6709BabyLM\u6311\u6218\u4e3b\u8981\u5173\u6ce8\u8bcd\u6c47\u5206\u5e03\u5934\u90e8\uff0c\u800c\u513f\u7ae5\u5b66\u4e60\u8bed\u8a00\u7684\u7279\u70b9\u662f\u80fd\u591f\u9ad8\u6548\u5b66\u4e60\u7f55\u89c1\u8bcd\u3002\u9700\u8981\u4e13\u95e8\u8bc4\u4f30\u6a21\u578b\u5728\u8bcd\u6c47\u5206\u5e03\u5c3e\u90e8\uff08\u7f55\u89c1\u8bcd\uff09\u7684\u5b66\u4e60\u80fd\u529b\u3002", "method": "\u6784\u5efaLT-Swap\u6d4b\u8bd5\u96c6\uff0c\u5305\u542b\u53ef\u63a5\u53d7\u4e0e\u4e0d\u53ef\u63a5\u53d7\u7684\u53e5\u5b50\u5bf9\uff0c\u9694\u79bb\u7f55\u89c1\u8bcd\u7684\u8bed\u4e49\u548c\u53e5\u6cd5\u4f7f\u7528\u3002\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u901a\u8fc7\u8ba1\u7b97\u53e5\u5b50\u5bf9\u5e73\u5747\u5bf9\u6570\u6982\u7387\u6765\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u8bc4\u4f30\u4e86BabyLM\u6392\u884c\u699c\u4e0a\u768416\u4e2a\u6a21\u578b\uff0c\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u5728\u7f55\u89c1\u8bcd\u4e0a\u8868\u73b0\u8f83\u5dee\uff0c\u4e14\u4e0d\u540c\u67b6\u6784\u6a21\u578b\u5728\u957f\u5c3e\u5206\u5e03\u4e0a\u7684\u6027\u80fd\u5dee\u5f02\u6bd4\u5728\u5934\u90e8\u66f4\u660e\u663e\u3002", "conclusion": "LT-Swap\u57fa\u51c6\u63d0\u4f9b\u4e86\u8bc4\u4f30\u6a21\u578b\u7f55\u89c1\u8bcd\u6cdb\u5316\u80fd\u529b\u7684\u65b0\u89c6\u89d2\uff0c\u63ed\u793a\u4e86\u54ea\u4e9b\u67b6\u6784\u66f4\u9002\u5408\u5904\u7406\u957f\u5c3e\u8bcd\u6c47\u5b66\u4e60\u95ee\u9898\u3002"}}
{"id": "2510.04488", "categories": ["cs.AI", "cs.IT", "math.IT", "I.2.4"], "pdf": "https://arxiv.org/pdf/2510.04488", "abs": "https://arxiv.org/abs/2510.04488", "authors": ["Edward Y. Chang", "Ethan Y. Chang"], "title": "Multi-Agent Collaborative Intelligence: Dual-Dial Control for Reliable LLM Reasoning", "comment": "27 pages, 5 figures, 21 tables", "summary": "Multi-agent debate often wastes compute by using a fixed adversarial stance,\naggregating without deliberation, or stopping on heuristics. We introduce MACI,\nan active controller with two independent dials that decouple information from\nbehavior: an information dial that gates evidence by quality, and a behavior\ndial that schedules contentiousness from exploration to consolidation. A\nmoderator tracks disagreement, overlap, evidence quality, and argument quality,\nand halts when gains plateau. We provide theory-lite guarantees for\nnonincreasing dispersion and provable termination, with a budget-feasible\nscheduler. Across clinical diagnosis and news-bias tasks, MACI improves\naccuracy and calibration while reducing tokens, and converts residual\nuncertainty into precision RAG plans that specify what to retrieve next. We use\na cross-family LLM judge (CRIT) as a conservative soft weight and stop signal,\nvalidated for order invariance and judge-swap stability; stability depends on\nusing high-capability judges. MACI turns debate into a budget-aware,\nmeasurable, and provably terminating controller.", "AI": {"tldr": "MACI\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u63a7\u5236\u5668\uff0c\u901a\u8fc7\u4fe1\u606f\u62e8\u76d8\u548c\u884c\u4e3a\u62e8\u76d8\u5206\u79bb\u4fe1\u606f\u4e0e\u884c\u4e3a\uff0c\u4f7f\u7528\u4ef2\u88c1\u8005\u8ddf\u8e2a\u8fa9\u8bba\u8d28\u91cf\u5e76\u5728\u6536\u76ca\u5e73\u7a33\u65f6\u7ec8\u6b62\uff0c\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u6821\u51c6\u5ea6\uff0c\u540c\u65f6\u51cf\u5c11token\u4f7f\u7528\u3002", "motivation": "\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u5b58\u5728\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\u95ee\u9898\uff0c\u5305\u62ec\u4f7f\u7528\u56fa\u5b9a\u7684\u5bf9\u6297\u7acb\u573a\u3001\u65e0\u5ba1\u8bae\u7684\u805a\u5408\u6216\u57fa\u4e8e\u542f\u53d1\u5f0f\u505c\u6b62\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u63a7\u5236\u8fa9\u8bba\u8fc7\u7a0b\u7684\u65b9\u6cd5\u3002", "method": "MACI\u4f7f\u7528\u4e24\u4e2a\u72ec\u7acb\u62e8\u76d8\uff1a\u4fe1\u606f\u62e8\u76d8\u6309\u8d28\u91cf\u7b5b\u9009\u8bc1\u636e\uff0c\u884c\u4e3a\u62e8\u76d8\u5b89\u6392\u4ece\u63a2\u7d22\u5230\u5de9\u56fa\u7684\u4e89\u8bae\u7a0b\u5ea6\u3002\u4ef2\u88c1\u8005\u8ddf\u8e2a\u5206\u6b67\u3001\u91cd\u53e0\u3001\u8bc1\u636e\u8d28\u91cf\u548c\u8bba\u8bc1\u8d28\u91cf\uff0c\u5728\u6536\u76ca\u5e73\u7a33\u65f6\u505c\u6b62\u8fa9\u8bba\u3002", "result": "\u5728\u4e34\u5e8a\u8bca\u65ad\u548c\u65b0\u95fb\u504f\u89c1\u4efb\u52a1\u4e2d\uff0cMACI\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u6821\u51c6\u5ea6\uff0c\u540c\u65f6\u51cf\u5c11\u4e86token\u4f7f\u7528\uff0c\u5e76\u5c06\u5269\u4f59\u4e0d\u786e\u5b9a\u6027\u8f6c\u5316\u4e3a\u7cbe\u786e\u7684RAG\u68c0\u7d22\u8ba1\u5212\u3002", "conclusion": "MACI\u5c06\u8fa9\u8bba\u8f6c\u53d8\u4e3a\u9884\u7b97\u611f\u77e5\u3001\u53ef\u6d4b\u91cf\u4e14\u53ef\u8bc1\u660e\u7ec8\u6b62\u7684\u63a7\u5236\u5668\uff0c\u901a\u8fc7\u8de8\u5bb6\u65cfLLM\u6cd5\u5b98\u786e\u4fdd\u7a33\u5b9a\u6027\u548c\u987a\u5e8f\u4e0d\u53d8\u6027\u3002"}}
{"id": "2510.04285", "categories": ["cs.CL", "cond-mat.stat-mech", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.04285", "abs": "https://arxiv.org/abs/2510.04285", "authors": ["Karthik Viswanathan", "Sang Eon Park"], "title": "Probing Geometry of Next Token Prediction Using Cumulant Expansion of the Softmax Entropy", "comment": "14 pages, 7 figures. Poster at HiLD 2025: 3rd Workshop on\n  High-dimensional Learning Dynamics", "summary": "We introduce a cumulant-expansion framework for quantifying how large\nlanguage models (LLMs) internalize higher-order statistical structure during\nnext-token prediction. By treating the softmax entropy of each layer's logit\ndistribution as a perturbation around its \"center\" distribution, we derive\nclosed-form cumulant observables that isolate successively higher-order\ncorrelations. Empirically, we track these cumulants in GPT-2 and Pythia models\non Pile-10K prompts. (i) Structured prompts exhibit a characteristic\nrise-and-plateau profile across layers, whereas token-shuffled prompts remain\nflat, revealing the dependence of the cumulant profile on meaningful context.\n(ii) During training, all cumulants increase monotonically before saturating,\ndirectly visualizing the model's progression from capturing variance to\nlearning skew, kurtosis, and higher-order statistical structures. (iii)\nMathematical prompts show distinct cumulant signatures compared to general\ntext, quantifying how models employ fundamentally different processing\nmechanisms for mathematical versus linguistic content. Together, these results\nestablish cumulant analysis as a lightweight, mathematically grounded probe of\nfeature-learning dynamics in high-dimensional neural networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7d2f\u79ef\u91cf\u5c55\u5f00\u6846\u67b6\u6765\u91cf\u5316\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\u4e2d\u5982\u4f55\u5185\u5316\u9ad8\u9636\u7edf\u8ba1\u7ed3\u6784\uff0c\u901a\u8fc7\u5206\u6790GPT-2\u548cPythia\u6a21\u578b\u63ed\u793a\u4e86\u4e0d\u540c\u5c42\u6b21\u7684\u7279\u5f81\u5b66\u4e60\u52a8\u6001\u3002", "motivation": "\u91cf\u5316\u5927\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u5b66\u4e60\u548c\u5185\u5316\u9ad8\u9636\u7edf\u8ba1\u7ed3\u6784\uff0c\u7406\u89e3\u6a21\u578b\u5728\u4e0d\u540c\u7c7b\u578b\u5185\u5bb9\u5904\u7406\u4e2d\u7684\u7279\u5f81\u5b66\u4e60\u673a\u5236\u3002", "method": "\u5c06\u6bcf\u5c42logit\u5206\u5e03\u7684softmax\u71b5\u4f5c\u4e3a\u5176\u4e2d\u5fc3\u5206\u5e03\u7684\u6270\u52a8\uff0c\u63a8\u5bfc\u51fa\u5c01\u95ed\u5f62\u5f0f\u7684\u7d2f\u79ef\u91cf\u53ef\u89c2\u6d4b\u91cf\u6765\u5206\u79bb\u9ad8\u9636\u76f8\u5173\u6027\uff0c\u5e76\u5728GPT-2\u548cPythia\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\u3002", "result": "\u7ed3\u6784\u5316\u63d0\u793a\u663e\u793a\u7d2f\u79ef\u91cf\u5728\u5c42\u6b21\u95f4\u5448\u73b0\u4e0a\u5347-\u5e73\u53f0\u7279\u5f81\uff0c\u6570\u5b66\u63d0\u793a\u4e0e\u666e\u901a\u6587\u672c\u5177\u6709\u4e0d\u540c\u7684\u7d2f\u79ef\u91cf\u7279\u5f81\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7d2f\u79ef\u91cf\u5355\u8c03\u589e\u52a0\u540e\u9971\u548c\u3002", "conclusion": "\u7d2f\u79ef\u91cf\u5206\u6790\u4e3a\u9ad8\u7ef4\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u7279\u5f81\u5b66\u4e60\u52a8\u6001\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u6570\u5b66\u57fa\u7840\u624e\u5b9e\u7684\u63a2\u6d4b\u65b9\u6cd5\u3002"}}
{"id": "2510.04491", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04491", "abs": "https://arxiv.org/abs/2510.04491", "authors": ["Muyu He", "Anand Kumar", "Tsach Mackey", "Meghana Rajeev", "James Zou", "Nazneen Rajani"], "title": "Impatient Users Confuse AI Agents: High-fidelity Simulations of Human Traits for Testing Agents", "comment": "25 pages", "summary": "Despite rapid progress in building conversational AI agents, robustness is\nstill largely untested. Small shifts in user behavior, such as being more\nimpatient, incoherent, or skeptical, can cause sharp drops in agent\nperformance, revealing how brittle current AI agents are. Today's benchmarks\nfail to capture this fragility: agents may perform well under standard\nevaluations but degrade spectacularly in more realistic and varied settings. We\naddress this robustness testing gap by introducing TraitBasis, a lightweight,\nmodel-agnostic method for systematically stress testing AI agents. TraitBasis\nlearns directions in activation space corresponding to steerable user traits\n(e.g., impatience or incoherence), which can be controlled, scaled, composed,\nand applied at inference time without any fine-tuning or extra data. Using\nTraitBasis, we extend $\\tau$-Bench to $\\tau$-Trait, where user behaviors are\naltered via controlled trait vectors. We observe on average a 2%-30%\nperformance degradation on $\\tau$-Trait across frontier models, highlighting\nthe lack of robustness of current AI agents to variations in user behavior.\nTogether, these results highlight both the critical role of robustness testing\nand the promise of TraitBasis as a simple, data-efficient, and compositional\ntool. By powering simulation-driven stress tests and training loops, TraitBasis\nopens the door to building AI agents that remain reliable in the unpredictable\ndynamics of real-world human interactions. We have open-sourced $\\tau$-Trai\nacross four domains: airline, retail, telecom, and telehealth, so the community\ncan systematically QA their agents under realistic, behaviorally diverse\nintents and trait scenarios: https://github.com/collinear-ai/tau-trait.", "AI": {"tldr": "TraitBasis\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u7684\u53ef\u63a7\u7528\u6237\u7279\u8d28\u5411\u91cf\u6765\u7cfb\u7edf\u6027\u5730\u538b\u529b\u6d4b\u8bd5AI\u4ee3\u7406\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u5bf9\u8bddAI\u4ee3\u7406\u5728\u6807\u51c6\u8bc4\u4f30\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7528\u6237\u884c\u4e3a\u8f7b\u5fae\u53d8\u5316\uff08\u5982\u4e0d\u8010\u70e6\u3001\u8bed\u65e0\u4f26\u6b21\u6216\u6000\u7591\uff09\u65f6\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u6355\u6349\u8fd9\u79cd\u8106\u5f31\u6027\u3002", "method": "TraitBasis\u5b66\u4e60\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u5bf9\u5e94\u53ef\u5f15\u5bfc\u7528\u6237\u7279\u8d28\u7684\u65b9\u5411\uff0c\u8fd9\u4e9b\u7279\u8d28\u5411\u91cf\u53ef\u5728\u63a8\u7406\u65f6\u63a7\u5236\u3001\u7f29\u653e\u3001\u7ec4\u5408\u548c\u5e94\u7528\uff0c\u65e0\u9700\u5fae\u8c03\u6216\u989d\u5916\u6570\u636e\u3002", "result": "\u5728\u03c4-Trait\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u524d\u6cbf\u6a21\u578b\u7684\u6027\u80fd\u5e73\u5747\u4e0b\u964d2%-30%\uff0c\u7a81\u663e\u4e86\u5f53\u524dAI\u4ee3\u7406\u5bf9\u7528\u6237\u884c\u4e3a\u53d8\u5316\u7684\u9c81\u68d2\u6027\u4e0d\u8db3\u3002", "conclusion": "TraitBasis\u4f5c\u4e3a\u4e00\u4e2a\u7b80\u5355\u3001\u6570\u636e\u9ad8\u6548\u4e14\u53ef\u7ec4\u5408\u7684\u5de5\u5177\uff0c\u4e3a\u6784\u5efa\u5728\u771f\u5b9e\u4e16\u754c\u4eba\u7c7b\u4ea4\u4e92\u4e0d\u53ef\u9884\u6d4b\u52a8\u6001\u4e2d\u4fdd\u6301\u53ef\u9760\u7684AI\u4ee3\u7406\u6253\u5f00\u4e86\u5927\u95e8\u3002"}}
{"id": "2510.04286", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04286", "abs": "https://arxiv.org/abs/2510.04286", "authors": ["Harshil Vejendla"], "title": "SliceMoE: Routing Embedding Slices Instead of Tokens for Fine-Grained and Balanced Transformer Scaling", "comment": "EMNLP 2025 Main, 8 pages, 9 figures", "summary": "Mixture-of-Experts (MoE) layers scale transformers by routing tokens to a\nsparse subset of feed-forward experts. Token-level routing, however, assigns an\nentire semantic spectrum to each expert, creating capacity bottlenecks,\nload-balancing pathologies, and limited specialization. We introduce SliceMoE,\nan architecture that routes contiguous slices of a token's hidden vector. A\nd-dimensional embedding is partitioned into S slices, and for each slice, a\nlightweight shared router predicts the top-k experts. Experts operate on their\nassigned slices independently, and outputs are reassembled, maintaining\nper-token FLOP efficiency. Because slices from different tokens interleave\nwithin an expert, utilization is naturally smoother. We propose a slice-level\ncapacity loss, cross-slice dropout, and efficient fused batched GEMM kernels.\nExperiments on WikiText-103 language modeling, WMT En-De translation, and three\ntext-classification datasets show SliceMoE attains up to 1.7x faster inference\nthan dense baselines, 12 to 18 percent lower perplexity than parameter-matched\ntoken-MoE, and improved expert balance, with interpretable expertise over\nsyntactic versus semantic subspaces.", "AI": {"tldr": "SliceMoE\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\uff0c\u5b83\u5c06token\u7684\u9690\u85cf\u5411\u91cf\u5206\u5272\u6210\u591a\u4e2a\u5207\u7247\uff0c\u5e76\u5bf9\u6bcf\u4e2a\u5207\u7247\u72ec\u7acb\u8fdb\u884c\u4e13\u5bb6\u8def\u7531\uff0c\u89e3\u51b3\u4e86\u4f20\u7edftoken\u7ea7\u8def\u7531\u7684\u5bb9\u91cf\u74f6\u9888\u548c\u8d1f\u8f7d\u5747\u8861\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u7684token\u7ea7MoE\u8def\u7531\u5c06\u6574\u4e2a\u8bed\u4e49\u8c31\u5206\u914d\u7ed9\u6bcf\u4e2a\u4e13\u5bb6\uff0c\u5bfc\u81f4\u5bb9\u91cf\u74f6\u9888\u3001\u8d1f\u8f7d\u5747\u8861\u95ee\u9898\u548c\u6709\u9650\u7684\u4e13\u5bb6\u4e13\u4e1a\u5316\u3002", "method": "\u5c06d\u7ef4\u5d4c\u5165\u5212\u5206\u4e3aS\u4e2a\u5207\u7247\uff0c\u6bcf\u4e2a\u5207\u7247\u4f7f\u7528\u8f7b\u91cf\u7ea7\u5171\u4eab\u8def\u7531\u5668\u9884\u6d4btop-k\u4e13\u5bb6\uff0c\u4e13\u5bb6\u72ec\u7acb\u5904\u7406\u5206\u914d\u7684\u5207\u7247\uff0c\u6700\u540e\u91cd\u65b0\u7ec4\u88c5\u8f93\u51fa\u3002", "result": "\u5728WikiText-103\u8bed\u8a00\u5efa\u6a21\u3001WMT En-De\u7ffb\u8bd1\u548c\u4e09\u4e2a\u6587\u672c\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\uff0cSliceMoE\u6bd4\u5bc6\u96c6\u57fa\u7ebf\u63a8\u7406\u901f\u5ea6\u5feb1.7\u500d\uff0c\u6bd4\u53c2\u6570\u5339\u914d\u7684token-MoE\u56f0\u60d1\u5ea6\u4f4e12-18%\uff0c\u5e76\u6539\u5584\u4e86\u4e13\u5bb6\u5e73\u8861\u3002", "conclusion": "SliceMoE\u901a\u8fc7\u5207\u7247\u7ea7\u8def\u7531\u5b9e\u73b0\u4e86\u66f4\u5e73\u6ed1\u7684\u4e13\u5bb6\u5229\u7528\u7387\u548c\u66f4\u597d\u7684\u4e13\u4e1a\u5316\uff0c\u5728\u53e5\u6cd5\u4e0e\u8bed\u4e49\u5b50\u7a7a\u95f4\u4e0a\u8868\u73b0\u51fa\u53ef\u89e3\u91ca\u7684\u4e13\u5bb6\u4e13\u957f\u3002"}}
{"id": "2510.04514", "categories": ["cs.AI", "cs.CE", "cs.CL", "cs.CV", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.04514", "abs": "https://arxiv.org/abs/2510.04514", "authors": ["Rachneet Kaur", "Nishan Srishankar", "Zhen Zeng", "Sumitra Ganesh", "Manuela Veloso"], "title": "ChartAgent: A Multimodal Agent for Visually Grounded Reasoning in Complex Chart Question Answering", "comment": "53 pages, 12 figures, 15 tables", "summary": "Recent multimodal LLMs have shown promise in chart-based visual question\nanswering, but their performance declines sharply on unannotated charts, those\nrequiring precise visual interpretation rather than relying on textual\nshortcuts. To address this, we introduce ChartAgent, a novel agentic framework\nthat explicitly performs visual reasoning directly within the chart's spatial\ndomain. Unlike textual chain-of-thought reasoning, ChartAgent iteratively\ndecomposes queries into visual subtasks and actively manipulates and interacts\nwith chart images through specialized actions such as drawing annotations,\ncropping regions (e.g., segmenting pie slices, isolating bars), and localizing\naxes, using a library of chart-specific vision tools to fulfill each subtask.\nThis iterative reasoning process closely mirrors human cognitive strategies for\nchart comprehension. ChartAgent achieves state-of-the-art accuracy on the\nChartBench and ChartX benchmarks, surpassing prior methods by up to 16.07%\nabsolute gain overall and 17.31% on unannotated, numerically intensive queries.\nFurthermore, our analyses show that ChartAgent is (a) effective across diverse\nchart types, (b) achieve the highest scores across varying visual and reasoning\ncomplexity levels, and (c) serves as a plug-and-play framework that boosts\nperformance across diverse underlying LLMs. Our work is among the first to\ndemonstrate visually grounded reasoning for chart understanding using\ntool-augmented multimodal agents.", "AI": {"tldr": "ChartAgent\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u56fe\u8868\u7a7a\u95f4\u57df\u4e2d\u6267\u884c\u89c6\u89c9\u63a8\u7406\u6765\u89e3\u51b3\u672a\u6807\u6ce8\u56fe\u8868\u7406\u89e3\u95ee\u9898\uff0c\u8d85\u8d8a\u4e86\u4f9d\u8d56\u6587\u672c\u6377\u5f84\u7684\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001LLM\u5728\u57fa\u4e8e\u56fe\u8868\u7684\u89c6\u89c9\u95ee\u7b54\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9700\u8981\u7cbe\u786e\u89c6\u89c9\u89e3\u91ca\u7684\u672a\u6807\u6ce8\u56fe\u8868\u4e0a\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u56e0\u4e3a\u5b83\u4eec\u8fc7\u5ea6\u4f9d\u8d56\u6587\u672c\u6377\u5f84\u800c\u975e\u771f\u6b63\u7684\u89c6\u89c9\u63a8\u7406\u3002", "method": "ChartAgent\u8fed\u4ee3\u5730\u5c06\u67e5\u8be2\u5206\u89e3\u4e3a\u89c6\u89c9\u5b50\u4efb\u52a1\uff0c\u901a\u8fc7\u4e13\u95e8\u7684\u89c6\u89c9\u5de5\u5177\uff08\u5982\u7ed8\u5236\u6ce8\u91ca\u3001\u88c1\u526a\u533a\u57df\u3001\u5b9a\u4f4d\u5750\u6807\u8f74\u7b49\uff09\u4e3b\u52a8\u64cd\u4f5c\u548c\u4ea4\u4e92\u56fe\u8868\u56fe\u50cf\uff0c\u6a21\u62df\u4eba\u7c7b\u56fe\u8868\u7406\u89e3\u8ba4\u77e5\u7b56\u7565\u3002", "result": "\u5728ChartBench\u548cChartX\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u51c6\u786e\u7387\uff0c\u76f8\u6bd4\u5148\u524d\u65b9\u6cd5\u6574\u4f53\u63d0\u534716.07%\uff0c\u5728\u672a\u6807\u6ce8\u6570\u503c\u5bc6\u96c6\u578b\u67e5\u8be2\u4e0a\u63d0\u534717.31%\uff0c\u4e14\u5728\u4e0d\u540c\u56fe\u8868\u7c7b\u578b\u548c\u590d\u6742\u5ea6\u7ea7\u522b\u4e0a\u5747\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "ChartAgent\u662f\u9996\u6279\u4f7f\u7528\u5de5\u5177\u589e\u5f3a\u591a\u6a21\u6001\u4ee3\u7406\u8fdb\u884c\u89c6\u89c9\u57fa\u7840\u63a8\u7406\u7684\u56fe\u8868\u7406\u89e3\u6846\u67b6\uff0c\u53ef\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u65b9\u6848\u63d0\u5347\u5404\u79cd\u5e95\u5c42LLM\u7684\u6027\u80fd\u3002"}}
{"id": "2510.04291", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04291", "abs": "https://arxiv.org/abs/2510.04291", "authors": ["Mehrzad Tareh", "Aydin Mohandesi", "Ebrahim Ansari"], "title": "PABSA: Hybrid Framework for Persian Aspect-Based Sentiment Analysis", "comment": "8 pages", "summary": "Sentiment analysis is a key task in Natural Language Processing (NLP),\nenabling the extraction of meaningful insights from user opinions across\nvarious domains. However, performing sentiment analysis in Persian remains\nchallenging due to the scarcity of labeled datasets, limited preprocessing\ntools, and the lack of high-quality embeddings and feature extraction methods.\nTo address these limitations, we propose a hybrid approach that integrates\nmachine learning (ML) and deep learning (DL) techniques for Persian\naspect-based sentiment analysis (ABSA). In particular, we utilize polarity\nscores from multilingual BERT as additional features and incorporate them into\na decision tree classifier, achieving an accuracy of 93.34%-surpassing existing\nbenchmarks on the Pars-ABSA dataset. Additionally, we introduce a Persian\nsynonym and entity dictionary, a novel linguistic resource that supports text\naugmentation through synonym and named entity replacement. Our results\ndemonstrate the effectiveness of hybrid modeling and feature augmentation in\nadvancing sentiment analysis for low-resource languages such as Persian.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u7528\u4e8e\u6ce2\u65af\u8bed\u65b9\u9762\u60c5\u611f\u5206\u6790\uff0c\u901a\u8fc7\u6574\u5408\u591a\u8bed\u8a00BERT\u7684\u6781\u6027\u5206\u6570\u4f5c\u4e3a\u989d\u5916\u7279\u5f81\uff0c\u5728Pars-ABSA\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e8693.34%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u6ce2\u65af\u8bed\u60c5\u611f\u5206\u6790\u9762\u4e34\u6807\u6ce8\u6570\u636e\u96c6\u7a00\u7f3a\u3001\u9884\u5904\u7406\u5de5\u5177\u6709\u9650\u4ee5\u53ca\u9ad8\u8d28\u91cf\u5d4c\u5165\u548c\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u7f3a\u4e4f\u7b49\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u6574\u5408\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\uff0c\u5229\u7528\u591a\u8bed\u8a00BERT\u7684\u6781\u6027\u5206\u6570\u4f5c\u4e3a\u51b3\u7b56\u6811\u5206\u7c7b\u5668\u7684\u989d\u5916\u7279\u5f81\uff0c\u5e76\u5f15\u5165\u4e86\u6ce2\u65af\u8bed\u540c\u4e49\u8bcd\u548c\u5b9e\u4f53\u8bcd\u5178\u8fdb\u884c\u6587\u672c\u589e\u5f3a\u3002", "result": "\u5728Pars-ABSA\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8693.34%\u7684\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u57fa\u51c6\uff0c\u8bc1\u660e\u4e86\u6df7\u5408\u5efa\u6a21\u548c\u7279\u5f81\u589e\u5f3a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6df7\u5408\u5efa\u6a21\u548c\u7279\u5f81\u589e\u5f3a\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63a8\u8fdb\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5982\u6ce2\u65af\u8bed\uff09\u7684\u60c5\u611f\u5206\u6790\u7814\u7a76\uff0c\u4e3a\u7c7b\u4f3c\u8bed\u8a00\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04520", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04520", "abs": "https://arxiv.org/abs/2510.04520", "authors": ["Hanyu Wang", "Ruohan Xie", "Yutong Wang", "Guoxiong Gao", "Xintao Yu", "Bin Dong"], "title": "Aria: An Agent For Retrieval and Iterative Auto-Formalization via Dependency Graph", "comment": null, "summary": "Accurate auto-formalization of theorem statements is essential for advancing\nautomated discovery and verification of research-level mathematics, yet remains\na major bottleneck for LLMs due to hallucinations, semantic mismatches, and\ntheir inability to synthesize new definitions. To tackle these issues, we\npresent Aria (Agent for Retrieval and Iterative Autoformalization), a system\nfor conjecture-level formalization in Lean that emulates human expert reasoning\nvia a two-phase Graph-of-Thought process: recursively decomposing statements\ninto a dependency graph and then constructing formalizations from grounded\nconcepts. To ensure semantic correctness, we introduce AriaScorer, a checker\nthat retrieves definitions from Mathlib for term-level grounding, enabling\nrigorous and reliable verification. We evaluate Aria on diverse benchmarks. On\nProofNet, it achieves 91.6% compilation success rate and 68.5% final accuracy,\nsurpassing previous methods. On FATE-X, a suite of challenging algebra problems\nfrom research literature, it outperforms the best baseline with 44.0% vs. 24.0%\nfinal accuracy. On a dataset of homological conjectures, Aria reaches 42.9%\nfinal accuracy while all other models score 0%.", "AI": {"tldr": "Aria\u662f\u4e00\u4e2a\u7528\u4e8eLean\u5b9a\u7406\u81ea\u52a8\u5f62\u5f0f\u5316\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u56fe\u601d\u8003\u8fc7\u7a0b\u6a21\u62df\u4eba\u7c7b\u4e13\u5bb6\u63a8\u7406\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dLLM\u5728\u5b9a\u7406\u9648\u8ff0\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u4e2d\u5b58\u5728\u5e7b\u89c9\u3001\u8bed\u4e49\u4e0d\u5339\u914d\u548c\u65e0\u6cd5\u5408\u6210\u65b0\u5b9a\u4e49\u7b49\u95ee\u9898\uff0c\u8fd9\u963b\u788d\u4e86\u6570\u5b66\u81ea\u52a8\u53d1\u73b0\u548c\u9a8c\u8bc1\u7684\u53d1\u5c55\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u56fe\u601d\u8003\u8fc7\u7a0b\uff1a\u9012\u5f52\u5206\u89e3\u9648\u8ff0\u4e3a\u4f9d\u8d56\u56fe\uff0c\u7136\u540e\u4ece\u57fa\u7840\u6982\u5ff5\u6784\u5efa\u5f62\u5f0f\u5316\u3002\u5f15\u5165AriaScorer\u4eceMathlib\u68c0\u7d22\u5b9a\u4e49\u8fdb\u884c\u672f\u8bed\u7ea7\u57fa\u7840\u9a8c\u8bc1\u3002", "result": "\u5728ProofNet\u4e0a\u8fbe\u523091.6%\u7f16\u8bd1\u6210\u529f\u7387\u548c68.5%\u6700\u7ec8\u51c6\u786e\u7387\uff1b\u5728FATE-X\u4e0a44.0% vs 24.0%\u4f18\u4e8e\u6700\u4f73\u57fa\u7ebf\uff1b\u5728\u4ee3\u6570\u540c\u8c03\u731c\u60f3\u6570\u636e\u96c6\u4e0a\u8fbe\u523042.9%\u51c6\u786e\u7387\u800c\u5176\u4ed6\u6a21\u578b\u4e3a0%\u3002", "conclusion": "Aria\u7cfb\u7edf\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u63a8\u7406\u8fc7\u7a0b\u548c\u4e25\u683c\u7684\u8bed\u4e49\u9a8c\u8bc1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b9a\u7406\u81ea\u52a8\u5f62\u5f0f\u5316\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2510.04293", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04293", "abs": "https://arxiv.org/abs/2510.04293", "authors": ["Lingnan Xu", "Chong Feng", "Kaiyuan Zhang", "Liu Zhengyong", "Wenqiang Xu", "Fanqing Meng"], "title": "Equipping Retrieval-Augmented Large Language Models with Document Structure Awareness", "comment": "EMNLP2025 Findings", "summary": "While large language models (LLMs) demonstrate impressive capabilities, their\nreliance on parametric knowledge often leads to factual inaccuracies.\nRetrieval-Augmented Generation (RAG) mitigates this by leveraging external\ndocuments, yet existing approaches treat retrieved passages as isolated chunks,\nignoring valuable structure that is crucial for document organization.\nMotivated by this gap, we propose Retrieve-DocumentRoute-Read (RDR2), a novel\nframework that explicitly incorporates structural information throughout the\nRAG process. RDR2 employs an LLM-based router to dynamically navigate document\nstructure trees, jointly evaluating content relevance and hierarchical\nrelationships to assemble optimal evidence. Our key innovation lies in\nformulating document routing as a trainable task, with automatic action\ncuration and structure-aware passage selection inspired by human reading\nstrategies. Through comprehensive evaluation on five challenging datasets, RDR2\nachieves state-of-the-art performance, demonstrating that explicit structural\nawareness significantly enhances RAG systems' ability to acquire and utilize\nknowledge, particularly in complex scenarios requiring multi-document\nsynthesis.", "AI": {"tldr": "\u63d0\u51fa\u4e86RDR2\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u6574\u5408\u6587\u6863\u7ed3\u6784\u4fe1\u606f\u6765\u6539\u8fdb\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7cfb\u7edf\uff0c\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd", "motivation": "\u73b0\u6709RAG\u65b9\u6cd5\u5c06\u68c0\u7d22\u5230\u7684\u6bb5\u843d\u89c6\u4e3a\u5b64\u7acb\u5757\uff0c\u5ffd\u7565\u4e86\u6587\u6863\u7ec4\u7ec7\u7ed3\u6784\u8fd9\u4e00\u5173\u952e\u4fe1\u606f\uff0c\u5bfc\u81f4\u77e5\u8bc6\u83b7\u53d6\u548c\u5229\u7528\u6548\u7387\u4e0d\u9ad8", "method": "RDR2\u4f7f\u7528\u57fa\u4e8eLLM\u7684\u8def\u7531\u5668\u52a8\u6001\u5bfc\u822a\u6587\u6863\u7ed3\u6784\u6811\uff0c\u8054\u5408\u8bc4\u4f30\u5185\u5bb9\u76f8\u5173\u6027\u548c\u5c42\u6b21\u5173\u7cfb\uff0c\u5c06\u6587\u6863\u8def\u7531\u5236\u5b9a\u4e3a\u53ef\u8bad\u7ec3\u4efb\u52a1", "result": "\u5728\u4e94\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u591a\u6587\u6863\u5408\u6210\u7684\u590d\u6742\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02", "conclusion": "\u663e\u5f0f\u7684\u7ed3\u6784\u611f\u77e5\u663e\u8457\u589e\u5f3a\u4e86RAG\u7cfb\u7edf\u83b7\u53d6\u548c\u5229\u7528\u77e5\u8bc6\u7684\u80fd\u529b"}}
{"id": "2510.04532", "categories": ["cs.AI", "cs.CL", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.04532", "abs": "https://arxiv.org/abs/2510.04532", "authors": ["Xurui Song", "Shuo Huai", "JingJing Jiang", "Jiayi Kong", "Jun Luo"], "title": "More Than Meets the Eye? Uncovering the Reasoning-Planning Disconnect in Training Vision-Language Driving Models", "comment": "The dataset will be released publicly once the paper is accepted for\n  publication", "summary": "Vision-Language Model (VLM) driving agents promise explainable end-to-end\nautonomy by first producing natural-language reasoning and then predicting\ntrajectory planning. However, whether planning is causally driven by this\nreasoning remains a critical but unverified assumption. To investigate this, we\nbuild DriveMind, a large-scale driving Visual Question Answering (VQA) corpus\nwith plan-aligned Chain-of-Thought (CoT), automatically generated from nuPlan.\nOur data generation process converts sensors and annotations into structured\ninputs and, crucially, separates priors from to-be-reasoned signals, enabling\nclean information ablations. Using DriveMind, we train representative VLM\nagents with Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization\n(GRPO) and evaluate them with nuPlan's metrics. Our results, unfortunately,\nindicate a consistent causal disconnect in reasoning-planning: removing\nego/navigation priors causes large drops in planning scores, whereas removing\nCoT produces only minor changes. Attention analysis further shows that planning\nprimarily focuses on priors rather than the CoT. Based on this evidence, we\npropose the Reasoning-Planning Decoupling Hypothesis, positing that the\ntraining-yielded reasoning is an ancillary byproduct rather than a causal\nmediator. To enable efficient diagnosis, we also introduce a novel,\ntraining-free probe that measures an agent's reliance on priors by evaluating\nits planning robustness against minor input perturbations. In summary, we\nprovide the community with a new dataset and a diagnostic tool to evaluate the\ncausal fidelity of future models.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86DriveMind\u6570\u636e\u96c6\u6765\u9a8c\u8bc1VLM\u9a7e\u9a76\u4ee3\u7406\u4e2d\u63a8\u7406\u4e0e\u89c4\u5212\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u53d1\u73b0\u5b58\u5728\u56e0\u679c\u8131\u8282\uff0c\u89c4\u5212\u4e3b\u8981\u4f9d\u8d56\u5148\u9a8c\u800c\u975e\u63a8\u7406\u94fe\uff0c\u63d0\u51fa\u4e86\u63a8\u7406-\u89c4\u5212\u89e3\u8026\u5047\u8bf4\u3002", "motivation": "\u9a8c\u8bc1VLM\u9a7e\u9a76\u4ee3\u7406\u4e2d\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u662f\u5426\u771f\u6b63\u56e0\u679c\u9a71\u52a8\u8f68\u8ff9\u89c4\u5212\u8fd9\u4e00\u5173\u952e\u4f46\u672a\u7ecf\u9a8c\u8bc1\u7684\u5047\u8bbe\u3002", "method": "\u6784\u5efaDriveMind\u5927\u89c4\u6a21\u9a7e\u9a76VQA\u8bed\u6599\u5e93\uff0c\u901a\u8fc7\u4fe1\u606f\u6d88\u878d\u5b9e\u9a8c\u8bad\u7ec3\u4ee3\u8868\u6027VLM\u4ee3\u7406\uff0c\u5e76\u4f7f\u7528\u6ce8\u610f\u529b\u5206\u6790\u6765\u7814\u7a76\u63a8\u7406\u4e0e\u89c4\u5212\u7684\u56e0\u679c\u5173\u7cfb\u3002", "result": "\u53d1\u73b0\u63a8\u7406\u4e0e\u89c4\u5212\u5b58\u5728\u4e00\u81f4\u7684\u56e0\u679c\u8131\u8282\uff1a\u79fb\u9664\u5148\u9a8c\u5bfc\u81f4\u89c4\u5212\u5206\u6570\u5927\u5e45\u4e0b\u964d\uff0c\u800c\u79fb\u9664\u63a8\u7406\u94fe\u4ec5\u4ea7\u751f\u5fae\u5c0f\u53d8\u5316\uff1b\u6ce8\u610f\u529b\u5206\u6790\u663e\u793a\u89c4\u5212\u4e3b\u8981\u5173\u6ce8\u5148\u9a8c\u800c\u975e\u63a8\u7406\u94fe\u3002", "conclusion": "\u63d0\u51fa\u4e86\u63a8\u7406-\u89c4\u5212\u89e3\u8026\u5047\u8bf4\uff0c\u8ba4\u4e3a\u8bad\u7ec3\u4ea7\u751f\u7684\u63a8\u7406\u662f\u8f85\u52a9\u526f\u4ea7\u54c1\u800c\u975e\u56e0\u679c\u4e2d\u4ecb\uff1b\u63d0\u4f9b\u4e86\u65b0\u6570\u636e\u96c6\u548c\u8bca\u65ad\u5de5\u5177\u6765\u8bc4\u4f30\u672a\u6765\u6a21\u578b\u7684\u56e0\u679c\u4fdd\u771f\u5ea6\u3002"}}
{"id": "2510.04302", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04302", "abs": "https://arxiv.org/abs/2510.04302", "authors": ["Thomas F Burns"], "title": "Measuring Language Model Hallucinations Through Distributional Correctness", "comment": "23 pages, 2 figures", "summary": "Common evaluation paradigms for language models focus on scoring single\nresponses through accuracy metrics or proper scoring rules, failing to capture\nthe full richness of a model's belief state. Recent work illustrates that\nlanguage models hallucinate in-part because they are optimised to be good\ntest-takers under binary scoring schemes that reward any answer over\nabstention. While this insight naturally leads to penalty-based approaches,\nthey ignore crucial distinctions in how models distribute uncertainty, for\nexample between hedging toward incorrect answers versus hedging toward \"I don't\nknow\" responses. A novel evaluation metric, the Distributional Correctness\nScore (DCS), is introduced to solve this problem, i.e., of not considering a\nmodel's entire probability distribution over answer choices. DCS naturally\ndistinguishes between harmful overconfidence in wrong answers and uncertainty\nexpressed through abstention, providing scores in an interpretable default\nrange. Through theoretical analysis and illustrative examples, DCS is\ndemonstrated to offer a more nuanced and aligned evaluation paradigm that\nincentivises models to express genuine uncertainty rather than guessing.\nAdapting 12 existing evaluation benchmarks to DCS's variants and measuring\nperformance on six language models reveals that for half of the tested\nbenchmarks scores are negative across all tested models, indicating significant\ntendencies towards hallucination.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u8bc4\u4f30\u6307\u6807DCS\uff0c\u901a\u8fc7\u8003\u8651\u6a21\u578b\u5728\u7b54\u6848\u9009\u62e9\u4e0a\u7684\u5b8c\u6574\u6982\u7387\u5206\u5e03\uff0c\u533a\u5206\u6709\u5bb3\u7684\u8fc7\u5ea6\u81ea\u4fe1\u548c\u901a\u8fc7\u5f03\u6743\u8868\u8fbe\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u66f4\u7ec6\u81f4\u7684\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u8303\u5f0f\u53ea\u5173\u6ce8\u5355\u6b21\u54cd\u5e94\u7684\u51c6\u786e\u6027\uff0c\u65e0\u6cd5\u6355\u6349\u6a21\u578b\u7684\u5b8c\u6574\u4fe1\u5ff5\u72b6\u6001\uff0c\u5bfc\u81f4\u6a21\u578b\u56e0\u4f18\u5316\u4e8c\u5143\u8bc4\u5206\u65b9\u6848\u800c\u4ea7\u751f\u5e7b\u89c9\u3002", "method": "\u5f15\u5165\u5206\u5e03\u6b63\u786e\u6027\u8bc4\u5206(DCS)\uff0c\u8003\u8651\u6a21\u578b\u5728\u7b54\u6848\u9009\u62e9\u4e0a\u7684\u6982\u7387\u5206\u5e03\uff0c\u533a\u5206\u9519\u8bef\u7b54\u6848\u7684\u8fc7\u5ea6\u81ea\u4fe1\u548c\"\u6211\u4e0d\u77e5\u9053\"\u54cd\u5e94\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u572812\u4e2a\u73b0\u6709\u8bc4\u4f30\u57fa\u51c6\u4e0a\u5e94\u7528DCS\u53d8\u4f53\uff0c\u6d4b\u8bd56\u4e2a\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u534a\u6570\u57fa\u51c6\u7684\u5f97\u5206\u5728\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u4e2d\u5747\u4e3a\u8d1f\u503c\uff0c\u8868\u660e\u5b58\u5728\u663e\u8457\u7684\u5e7b\u89c9\u503e\u5411\u3002", "conclusion": "DCS\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u7ec6\u81f4\u548c\u5bf9\u9f50\u7684\u8bc4\u4f30\u8303\u5f0f\uff0c\u6fc0\u52b1\u6a21\u578b\u8868\u8fbe\u771f\u6b63\u7684\u4e0d\u786e\u5b9a\u6027\u800c\u975e\u731c\u6d4b\uff0c\u80fd\u66f4\u597d\u5730\u6355\u6349\u6a21\u578b\u7684\u4fe1\u5ff5\u72b6\u6001\u3002"}}
{"id": "2510.04542", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04542", "abs": "https://arxiv.org/abs/2510.04542", "authors": ["Wolfgang Lehrach", "Daniel Hennes", "Miguel Lazaro-Gredilla", "Xinghua Lou", "Carter Wendelken", "Zun Li", "Antoine Dedieu", "Jordi Grau-Moya", "Marc Lanctot", "Atil Iscen", "John Schultz", "Marcus Chiam", "Ian Gemp", "Piotr Zielinski", "Satinder Singh", "Kevin P. Murphy"], "title": "Code World Models for General Game Playing", "comment": null, "summary": "Large Language Models (LLMs) reasoning abilities are increasingly being\napplied to classical board and card games, but the dominant approach --\ninvolving prompting for direct move generation -- has significant drawbacks. It\nrelies on the model's implicit fragile pattern-matching capabilities, leading\nto frequent illegal moves and strategically shallow play. Here we introduce an\nalternative approach: We use the LLM to translate natural language rules and\ngame trajectories into a formal, executable world model represented as Python\ncode. This generated model -- comprising functions for state transition, legal\nmove enumeration, and termination checks -- serves as a verifiable simulation\nengine for high-performance planning algorithms like Monte Carlo tree search\n(MCTS). In addition, we prompt the LLM to generate heuristic value functions\n(to make MCTS more efficient), and inference functions (to estimate hidden\nstates in imperfect information games). Our method offers three distinct\nadvantages compared to directly using the LLM as a policy: (1) Verifiability:\nThe generated CWM serves as a formal specification of the game's rules,\nallowing planners to algorithmically enumerate valid actions and avoid illegal\nmoves, contingent on the correctness of the synthesized model; (2) Strategic\nDepth: We combine LLM semantic understanding with the deep search power of\nclassical planners; and (3) Generalization: We direct the LLM to focus on the\nmeta-task of data-to-code translation, enabling it to adapt to new games more\neasily. We evaluate our agent on 10 different games, of which 4 are novel and\ncreated for this paper. 5 of the games are fully observed (perfect\ninformation), and 5 are partially observed (imperfect information). We find\nthat our method outperforms or matches Gemini 2.5 Pro in 9 out of the 10\nconsidered games.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u4f7f\u7528LLM\u5c06\u81ea\u7136\u8bed\u8a00\u89c4\u5219\u548c\u6e38\u620f\u8f68\u8ff9\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684Python\u4ee3\u7801\u4e16\u754c\u6a21\u578b\uff0c\u7ed3\u5408MCTS\u7b49\u89c4\u5212\u7b97\u6cd5\uff0c\u76f8\u6bd4\u76f4\u63a5\u4f7f\u7528LLM\u751f\u6210\u52a8\u4f5c\u5177\u6709\u53ef\u9a8c\u8bc1\u6027\u3001\u6218\u7565\u6df1\u5ea6\u548c\u6cdb\u5316\u6027\u4f18\u52bf\u3002", "motivation": "\u5f53\u524d\u4f7f\u7528LLM\u76f4\u63a5\u751f\u6210\u6e38\u620f\u52a8\u4f5c\u7684\u65b9\u6cd5\u5b58\u5728\u660e\u663e\u7f3a\u9677\uff1a\u4f9d\u8d56\u6a21\u578b\u8106\u5f31\u7684\u6a21\u5f0f\u5339\u914d\u80fd\u529b\uff0c\u7ecf\u5e38\u4ea7\u751f\u975e\u6cd5\u52a8\u4f5c\uff0c\u7b56\u7565\u6df1\u5ea6\u4e0d\u8db3\u3002\u9700\u8981\u4e00\u79cd\u66f4\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u5229\u7528LLM\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u4f7f\u7528LLM\u5c06\u6e38\u620f\u89c4\u5219\u548c\u8f68\u8ff9\u8f6c\u6362\u4e3aPython\u4ee3\u7801\u5f62\u5f0f\u7684\u4e16\u754c\u6a21\u578b\uff0c\u5305\u62ec\u72b6\u6001\u8f6c\u79fb\u3001\u5408\u6cd5\u52a8\u4f5c\u679a\u4e3e\u548c\u7ec8\u6b62\u68c0\u67e5\u51fd\u6570\u3002\u540c\u65f6\u751f\u6210\u542f\u53d1\u5f0f\u4ef7\u503c\u51fd\u6570\u548c\u63a8\u7406\u51fd\u6570\uff0c\u4e0eMCTS\u7b49\u89c4\u5212\u7b97\u6cd5\u7ed3\u5408\u3002", "result": "\u572810\u4e2a\u4e0d\u540c\u6e38\u620f\uff084\u4e2a\u65b0\u521b\u5efa\uff09\u4e0a\u8bc4\u4f30\uff0c\u5176\u4e2d5\u4e2a\u5b8c\u5168\u89c2\u5bdf\uff0c5\u4e2a\u90e8\u5206\u89c2\u5bdf\u3002\u8be5\u65b9\u6cd5\u57289\u4e2a\u6e38\u620f\u4e2d\u8868\u73b0\u4f18\u4e8e\u6216\u5339\u914dGemini 2.5 Pro\u3002", "conclusion": "\u901a\u8fc7\u5c06LLM\u7528\u4e8e\u6570\u636e\u5230\u4ee3\u7801\u7684\u8f6c\u6362\u4efb\u52a1\uff0c\u7ed3\u5408\u7ecf\u5178\u89c4\u5212\u7b97\u6cd5\uff0c\u53ef\u4ee5\u521b\u5efa\u66f4\u53ef\u9760\u3001\u6218\u7565\u6df1\u5ea6\u66f4\u5f3a\u7684\u6e38\u620f\u667a\u80fd\u4f53\uff0c\u4e14\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.04320", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04320", "abs": "https://arxiv.org/abs/2510.04320", "authors": ["Rui Wu", "Yihao Quan", "Zeru Shi", "Zhenting Wang", "Yanshu Li", "Ruixiang Tang"], "title": "Read the Scene, Not the Script: Outcome-Aware Safety for LLMs", "comment": null, "summary": "Safety-aligned Large Language Models (LLMs) still show two dominant failure\nmodes: they are easily jailbroken, or they over-refuse harmless inputs that\ncontain sensitive surface signals. We trace both to a common cause: current\nmodels reason weakly about links between actions and outcomes and over-rely on\nsurface-form signals, lexical or stylistic cues that do not encode\nconsequences. We define this failure mode as Consequence-blindness. To study\nconsequence-blindness, we build a benchmark named CB-Bench covering four risk\nscenarios that vary whether semantic risk aligns with outcome risk, enabling\nevaluation under both matched and mismatched conditions which are often ignored\nby existing safety benchmarks. Mainstream models consistently fail to separate\nthese risks and exhibit consequence-blindness, indicating that\nconsequence-blindness is widespread and systematic. To mitigate\nconsequence-blindness, we introduce CS-Chain-4k, a consequence-reasoning\ndataset for safety alignment. Models fine-tuned on CS-Chain-4k show clear gains\nagainst semantic-camouflage jailbreaks and reduce over-refusal on harmless\ninputs, while maintaining utility and generalization on other benchmarks. These\nresults clarify the limits of current alignment, establish consequence-aware\nreasoning as a core alignment goal and provide a more practical and\nreproducible evaluation path.", "AI": {"tldr": "\u8bba\u6587\u53d1\u73b0\u5b89\u5168\u5bf9\u9f50\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u540e\u679c\u76f2\u533a\u95ee\u9898\uff0c\u5373\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u63a8\u7406\u884c\u52a8\u4e0e\u540e\u679c\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u8fc7\u5ea6\u4f9d\u8d56\u8868\u9762\u5f62\u5f0f\u4fe1\u53f7\u3002\u4f5c\u8005\u6784\u5efa\u4e86CB-Bench\u57fa\u51c6\u6d4b\u8bd5\u548cCS-Chain-4k\u6570\u636e\u96c6\u6765\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5b89\u5168\u5bf9\u9f50\u7684LLMs\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u5931\u8d25\u6a21\u5f0f\uff1a\u5bb9\u6613\u88ab\u8d8a\u72f1\u653b\u51fb\uff0c\u4ee5\u53ca\u5bf9\u65e0\u5bb3\u8f93\u5165\u8fc7\u5ea6\u62d2\u7edd\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u4e24\u79cd\u95ee\u9898\u90fd\u6e90\u4e8e\u6a21\u578b\u5bf9\u884c\u52a8\u4e0e\u540e\u679c\u4e4b\u95f4\u8054\u7cfb\u7684\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\uff0c\u8fc7\u5ea6\u4f9d\u8d56\u8868\u9762\u5f62\u5f0f\u4fe1\u53f7\u3002", "method": "\u6784\u5efa\u4e86CB-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u56db\u79cd\u98ce\u9669\u573a\u666f\uff0c\u8bc4\u4f30\u6a21\u578b\u5728\u8bed\u4e49\u98ce\u9669\u4e0e\u7ed3\u679c\u98ce\u9669\u5339\u914d\u548c\u4e0d\u5339\u914d\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002\u540c\u65f6\u63d0\u51fa\u4e86CS-Chain-4k\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u540e\u679c\u63a8\u7406\u3002", "result": "\u4e3b\u6d41\u6a21\u578b\u5728CB-Bench\u4e0a\u6301\u7eed\u65e0\u6cd5\u533a\u5206\u8bed\u4e49\u98ce\u9669\u548c\u7ed3\u679c\u98ce\u9669\uff0c\u8868\u73b0\u51fa\u7cfb\u7edf\u6027\u540e\u679c\u76f2\u533a\u3002\u4f7f\u7528CS-Chain-4k\u5fae\u8c03\u7684\u6a21\u578b\u5728\u8bed\u4e49\u4f2a\u88c5\u8d8a\u72f1\u653b\u51fb\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u51cf\u5c11\u4e86\u5bf9\u65e0\u5bb3\u8f93\u5165\u7684\u8fc7\u5ea6\u62d2\u7edd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5728\u5176\u4ed6\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u6548\u7528\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u540e\u679c\u611f\u77e5\u63a8\u7406\u5e94\u6210\u4e3a\u5bf9\u9f50\u7684\u6838\u5fc3\u76ee\u6807\uff0c\u8be5\u7814\u7a76\u4e3a\u66f4\u5b9e\u7528\u548c\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u8def\u5f84\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u5bf9\u9f50\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.04550", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04550", "abs": "https://arxiv.org/abs/2510.04550", "authors": ["Pengfei He", "Zhenwei Dai", "Bing He", "Hui Liu", "Xianfeng Tang", "Hanqing Lu", "Juanhui Li", "Jiayuan Ding", "Subhabrata Mukherjee", "Suhang Wang", "Yue Xing", "Jiliang Tang", "Benoit Dumoulin"], "title": "TRAJECT-Bench:A Trajectory-Aware Benchmark for Evaluating Agentic Tool Use", "comment": null, "summary": "Large language model (LLM)-based agents increasingly rely on tool use to\ncomplete real-world tasks. While existing works evaluate the LLMs' tool use\ncapability, they largely focus on the final answers yet overlook the detailed\ntool usage trajectory, i.e., whether tools are selected, parameterized, and\nordered correctly. We introduce TRAJECT-Bench, a trajectory-aware benchmark to\ncomprehensively evaluate LLMs' tool use capability through diverse tasks with\nfine-grained evaluation metrics. TRAJECT-Bench pairs high-fidelity, executable\ntools across practical domains with tasks grounded in production-style APIs,\nand synthesizes trajectories that vary in breadth (parallel calls) and depth\n(interdependent chains). Besides final accuracy, TRAJECT-Bench also reports\ntrajectory-level diagnostics, including tool selection and argument\ncorrectness, and dependency/order satisfaction. Analyses reveal failure modes\nsuch as similar tool confusion and parameter-blind selection, and scaling\nbehavior with tool diversity and trajectory length where the bottleneck of\ntransiting from short to mid-length trajectories is revealed, offering\nactionable guidance for LLMs' tool use.", "AI": {"tldr": "TRAJECT-Bench\u662f\u4e00\u4e2a\u8f68\u8ff9\u611f\u77e5\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30LLM\u7684\u5de5\u5177\u4f7f\u7528\u80fd\u529b\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u6307\u6807\u5206\u6790\u5de5\u5177\u9009\u62e9\u3001\u53c2\u6570\u5316\u548c\u987a\u5e8f\u7684\u6b63\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u6700\u7ec8\u7b54\u6848\uff0c\u800c\u5ffd\u89c6\u4e86\u5de5\u5177\u4f7f\u7528\u7684\u8be6\u7ec6\u8f68\u8ff9\uff0c\u5305\u62ec\u5de5\u5177\u662f\u5426\u88ab\u6b63\u786e\u9009\u62e9\u3001\u53c2\u6570\u5316\u548c\u6392\u5e8f\u3002", "method": "\u6784\u5efaTRAJECT-Bench\u57fa\u51c6\uff0c\u5305\u542b\u8de8\u5b9e\u7528\u9886\u57df\u7684\u9ad8\u4fdd\u771f\u53ef\u6267\u884c\u5de5\u5177\uff0c\u57fa\u4e8e\u751f\u4ea7\u98ce\u683cAPI\u7684\u4efb\u52a1\uff0c\u4ee5\u53ca\u5408\u6210\u4e0d\u540c\u5e7f\u5ea6\uff08\u5e76\u884c\u8c03\u7528\uff09\u548c\u6df1\u5ea6\uff08\u76f8\u4e92\u4f9d\u8d56\u94fe\uff09\u7684\u8f68\u8ff9\u3002", "result": "\u63ed\u793a\u4e86\u5931\u8d25\u6a21\u5f0f\uff08\u5982\u76f8\u4f3c\u5de5\u5177\u6df7\u6dc6\u548c\u53c2\u6570\u76f2\u9009\uff09\u4ee5\u53ca\u5de5\u5177\u591a\u6837\u6027\u548c\u8f68\u8ff9\u957f\u5ea6\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4e86\u4ece\u77ed\u8f68\u8ff9\u5230\u4e2d\u957f\u8f68\u8ff9\u8f6c\u6362\u7684\u74f6\u9888\u3002", "conclusion": "TRAJECT-Bench\u63d0\u4f9b\u4e86\u5bf9LLM\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u4e3a\u6539\u8fdbLLM\u7684\u5de5\u5177\u4f7f\u7528\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\u3002"}}
{"id": "2510.04338", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04338", "abs": "https://arxiv.org/abs/2510.04338", "authors": ["Mathieu La\u00ef-king", "Patrick Paroubek"], "title": "Evaluation of Clinical Trials Reporting Quality using Large Language Models", "comment": null, "summary": "Reporting quality is an important topic in clinical trial research articles,\nas it can impact clinical decisions. In this article, we test the ability of\nlarge language models to assess the reporting quality of this type of article\nusing the Consolidated Standards of Reporting Trials (CONSORT). We create\nCONSORT-QA, an evaluation corpus from two studies on abstract reporting quality\nwith CONSORT-abstract standards. We then evaluate the ability of different\nlarge generative language models (from the general domain or adapted to the\nbiomedical domain) to correctly assess CONSORT criteria with different known\nprompting methods, including Chain-of-thought. Our best combination of model\nand prompting method achieves 85% accuracy. Using Chain-of-thought adds\nvaluable information on the model's reasoning for completing the task.", "AI": {"tldr": "\u672c\u6587\u6d4b\u8bd5\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f7f\u7528CONSORT\u6807\u51c6\u8bc4\u4f30\u4e34\u5e8a\u8bd5\u9a8c\u7814\u7a76\u62a5\u544a\u8d28\u91cf\u7684\u80fd\u529b\uff0c\u521b\u5efa\u4e86CONSORT-QA\u8bc4\u4f30\u8bed\u6599\u5e93\uff0c\u6700\u4f73\u6a21\u578b\u7ec4\u5408\u8fbe\u523085%\u51c6\u786e\u7387\u3002", "motivation": "\u4e34\u5e8a\u8bd5\u9a8c\u7814\u7a76\u62a5\u544a\u8d28\u91cf\u5bf9\u4e34\u5e8a\u51b3\u7b56\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u9700\u8981\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u521b\u5efaCONSORT-QA\u8bc4\u4f30\u8bed\u6599\u5e93\uff0c\u4f7f\u7528\u4e0d\u540c\u7684\u5927\u578b\u751f\u6210\u8bed\u8a00\u6a21\u578b\uff08\u901a\u7528\u9886\u57df\u548c\u751f\u7269\u533b\u5b66\u9886\u57df\uff09\u548c\u63d0\u793a\u65b9\u6cd5\uff08\u5305\u62ec\u601d\u7ef4\u94fe\uff09\u8bc4\u4f30CONSORT\u6807\u51c6\u3002", "result": "\u6700\u4f73\u6a21\u578b\u548c\u63d0\u793a\u65b9\u6cd5\u7ec4\u5408\u8fbe\u523085%\u7684\u51c6\u786e\u7387\uff0c\u601d\u7ef4\u94fe\u65b9\u6cd5\u4e3a\u6a21\u578b\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u4fe1\u606f\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u4e34\u5e8a\u8bd5\u9a8c\u7814\u7a76\u62a5\u544a\u8d28\u91cf\uff0c\u601d\u7ef4\u94fe\u63d0\u793a\u65b9\u6cd5\u6709\u52a9\u4e8e\u7406\u89e3\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u3002"}}
{"id": "2510.04560", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04560", "abs": "https://arxiv.org/abs/2510.04560", "authors": ["Honghao Fu", "Yuan Ouyang", "Kai-Wei Chang", "Yiwei Wang", "Zi Huang", "Yujun Cai"], "title": "ContextNav: Towards Agentic Multimodal In-Context Learning", "comment": null, "summary": "Recent advances demonstrate that multimodal large language models (MLLMs)\nexhibit strong multimodal in-context learning (ICL) capabilities, enabling them\nto adapt to novel vision-language tasks from a few contextual examples.\nHowever, existing ICL approaches face challenges in reconciling scalability\nwith robustness across diverse tasks and noisy contextual examples: manually\nselecting examples produces clean contexts but is labor-intensive and\ntask-specific, while similarity-based retrieval improves scalability but could\nintroduce irrelevant or structurally inconsistent samples that degrade ICL\nperformance. To address these limitations, we propose ContextNav, the first\nagentic framework that integrates the scalability of automated retrieval with\nthe quality and adaptiveness of human-like curation, enabling noise-robust and\ndynamically optimized contextualization for multimodal ICL. ContextNav unifies\ncontext management and noise-robust contextualization within a closed-loop\nworkflow driven by graph-based orchestration. Specifically, it builds a\nresource-aware multimodal embedding pipeline, maintains a retrievable vector\ndatabase, and applies agentic retrieval and structural alignment to construct\nnoise-resilient contexts. An Operational Grammar Graph (OGG) further supports\nadaptive workflow planning and optimization, enabling the agent to refine its\noperational strategies based on downstream ICL feedback. Experimental results\ndemonstrate that ContextNav achieves state-of-the-art performance across\nvarious datasets, underscoring the promise of agentic workflows for advancing\nscalable and robust contextualization in multimodal ICL.", "AI": {"tldr": "\u63d0\u51fa\u4e86ContextNav\u6846\u67b6\uff0c\u5c06\u81ea\u52a8\u68c0\u7d22\u7684\u53ef\u6269\u5c55\u6027\u4e0e\u4eba\u5de5\u7b5b\u9009\u7684\u8d28\u91cf\u548c\u9002\u5e94\u6027\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u57fa\u4e8e\u56fe\u7684\u7f16\u6392\u9a71\u52a8\u95ed\u73af\u5de5\u4f5c\u6d41\uff0c\u5b9e\u73b0\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u566a\u58f0\u9c81\u68d2\u548c\u52a8\u6001\u4f18\u5316\u4e0a\u4e0b\u6587\u6784\u5efa\u3002", "motivation": "\u73b0\u6709\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u4e4b\u95f4\u5b58\u5728\u77db\u76fe\uff1a\u624b\u52a8\u9009\u62e9\u793a\u4f8b\u8d28\u91cf\u9ad8\u4f46\u52b3\u52a8\u5bc6\u96c6\uff0c\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u68c0\u7d22\u53ef\u6269\u5c55\u4f46\u53ef\u80fd\u5f15\u5165\u4e0d\u76f8\u5173\u6216\u7ed3\u6784\u4e0d\u4e00\u81f4\u7684\u6837\u672c\uff0c\u5f71\u54cdICL\u6027\u80fd\u3002", "method": "\u6784\u5efa\u8d44\u6e90\u611f\u77e5\u7684\u591a\u6a21\u6001\u5d4c\u5165\u7ba1\u9053\uff0c\u7ef4\u62a4\u53ef\u68c0\u7d22\u7684\u5411\u91cf\u6570\u636e\u5e93\uff0c\u5e94\u7528\u667a\u80fd\u68c0\u7d22\u548c\u7ed3\u6784\u5bf9\u9f50\u6765\u6784\u5efa\u566a\u58f0\u5f39\u6027\u4e0a\u4e0b\u6587\uff0c\u5e76\u901a\u8fc7\u64cd\u4f5c\u8bed\u6cd5\u56fe\u652f\u6301\u81ea\u9002\u5e94\u5de5\u4f5c\u6d41\u89c4\u5212\u548c\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eContextNav\u5728\u5404\u79cd\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u667a\u80fd\u5de5\u4f5c\u6d41\u5728\u591a\u6a21\u6001ICL\u4e2d\u63a8\u8fdb\u53ef\u6269\u5c55\u548c\u9c81\u68d2\u4e0a\u4e0b\u6587\u5316\u7684\u524d\u666f\u3002", "conclusion": "ContextNav\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u53ef\u6269\u5c55\u6027\u4e0e\u9c81\u68d2\u6027\u7684\u5e73\u8861\u95ee\u9898\uff0c\u4e3a\u591a\u6a21\u6001ICL\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04340", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04340", "abs": "https://arxiv.org/abs/2510.04340", "authors": ["Daniel Tan", "Anders Woodruff", "Niels Warncke", "Arun Jose", "Maxime Rich\u00e9", "David Demitri Africa", "Mia Taylor"], "title": "Inoculation Prompting: Eliciting traits from LLMs during training can suppress them at test-time", "comment": "40 pages, 22 figures In proceedings at ICLR 2026", "summary": "Language model finetuning often results in learning undesirable traits in\ncombination with desired ones. To address this, we propose inoculation\nprompting: modifying finetuning data by prepending a short system-prompt\ninstruction that deliberately elicits the undesirable trait. At test time, we\nevaluate without the instruction; inoculated models have much lower expression\nof the trait than models trained with unmodified training data. Inoculation is\nselective: in a toy setting where assistant responses are always in Spanish and\nALL-CAPS, an appropriate inoculation (e.g., ``You always speak in Spanish.'')\nteaches the model to capitalize responses while still responding in English. We\nfind that inoculation is also effective across several additional settings:\nreducing emergent misalignment (EM) from task-specific finetuning, defending\nagainst backdoor injections, and mitigating the transmission of traits via\nsubliminal learning. Follow-up analysis suggests a mechanism: making a trait\nless surprising via inoculation reduces optimization pressure to globally\nupdate the model, thereby reducing the degree of generalization. Our analysis\nrelates to prior work on EM: inoculation explains prior findings that\neducational contexts mitigate EM from insecure code. Beyond demonstrating a\nsimple and effective technique for selective learning, our results contribute\nto a better conceptual understanding of how and why language models generalize.", "AI": {"tldr": "\u63d0\u51fa\u63a5\u79cd\u63d0\u793a\u6cd5\uff1a\u901a\u8fc7\u5728\u5fae\u8c03\u6570\u636e\u524d\u6dfb\u52a0\u7b80\u77ed\u7684\u7cfb\u7edf\u63d0\u793a\u6307\u4ee4\u6765\u9009\u62e9\u6027\u51cf\u5c11\u4e0d\u826f\u7279\u5f81\u7684\u5b66\u4e60\uff0c\u800c\u4e0d\u5f71\u54cd\u671f\u671b\u7279\u5f81\u3002", "motivation": "\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u65f6\u540c\u65f6\u5b66\u4e60\u4e0d\u826f\u7279\u5f81\u548c\u671f\u671b\u7279\u5f81\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u9009\u62e9\u6027\u5b66\u4e60\u3002", "method": "\u5728\u5fae\u8c03\u6570\u636e\u524d\u6dfb\u52a0\u6545\u610f\u5f15\u53d1\u4e0d\u826f\u7279\u5f81\u7684\u7b80\u77ed\u7cfb\u7edf\u63d0\u793a\u6307\u4ee4\uff0c\u6d4b\u8bd5\u65f6\u4e0d\u4f7f\u7528\u8be5\u6307\u4ee4\u3002", "result": "\u63a5\u79cd\u6a21\u578b\u7684\u4e0d\u826f\u7279\u5f81\u8868\u8fbe\u663e\u8457\u964d\u4f4e\uff0c\u5728\u591a\u4e2a\u573a\u666f\u4e2d\u6709\u6548\uff1a\u51cf\u5c11\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u4e2d\u7684\u7a81\u53d1\u9519\u4f4d\u3001\u9632\u5fa1\u540e\u95e8\u6ce8\u5165\u3001\u7f13\u89e3\u6f5c\u610f\u8bc6\u5b66\u4e60\u4e2d\u7684\u7279\u5f81\u4f20\u9012\u3002", "conclusion": "\u63a5\u79cd\u63d0\u793a\u6cd5\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u9009\u62e9\u6027\u5b66\u4e60\u6280\u672f\uff0c\u901a\u8fc7\u51cf\u5c11\u4f18\u5316\u538b\u529b\u6765\u9650\u5236\u4e0d\u826f\u7279\u5f81\u7684\u6cdb\u5316\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u8bed\u8a00\u6a21\u578b\u7684\u6cdb\u5316\u673a\u5236\u3002"}}
{"id": "2510.04568", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04568", "abs": "https://arxiv.org/abs/2510.04568", "authors": ["Naman Gupta", "Shreeyash Gowaikar", "Arun Iyer", "Kirankumar Shiragur", "Ramakrishna B Bairi", "Rishikesh Maurya", "Ritabrata Maiti", "Sankarshan Damle", "Shachee Mishra Gupta"], "title": "COSMIR: Chain Orchestrated Structured Memory for Iterative Reasoning over Long Context", "comment": null, "summary": "Reasoning over very long inputs remains difficult for large language models\n(LLMs). Common workarounds either shrink the input via retrieval (risking\nmissed evidence), enlarge the context window (straining selectivity), or stage\nmultiple agents to read in pieces. In staged pipelines (e.g., Chain of Agents,\nCoA), free-form summaries passed between agents can discard crucial details and\namplify early mistakes. We introduce COSMIR (Chain Orchestrated Structured\nMemory for Iterative Reasoning), a chain-style framework that replaces ad hoc\nmessages with a structured memory. A Planner agent first turns a user query\ninto concrete, checkable sub-questions. worker agents process chunks via a\nfixed micro-cycle: Extract, Infer, Refine, writing all updates to the shared\nmemory. A Manager agent then Synthesizes the final answer directly from the\nmemory. This preserves step-wise read-then-reason benefits while changing both\nthe communication medium (structured memory) and the worker procedure (fixed\nmicro-cycle), yielding higher faithfulness, better long-range aggregation, and\nauditability. On long-context QA from the HELMET suite, COSMIR reduces\npropagation-stage information loss and improves accuracy over a CoA baseline.", "AI": {"tldr": "COSMIR\u662f\u4e00\u4e2a\u7528\u4e8e\u957f\u6587\u672c\u63a8\u7406\u7684\u94fe\u5f0f\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5185\u5b58\u548c\u56fa\u5b9a\u5fae\u5faa\u73af\u5de5\u4f5c\u6d41\u7a0b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u4fe1\u606f\u4e22\u5931\u548c\u9519\u8bef\u4f20\u64ad\u7684\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u6587\u672c\u63a8\u7406\u4e2d\u7684\u56f0\u96be\uff0c\u4f20\u7edf\u65b9\u6cd5\u5982\u68c0\u7d22\u7f29\u5c0f\u8f93\u5165\u4f1a\u4e22\u5931\u8bc1\u636e\uff0c\u6269\u5927\u4e0a\u4e0b\u6587\u7a97\u53e3\u4f1a\u964d\u4f4e\u9009\u62e9\u6027\uff0c\u591a\u667a\u80fd\u4f53\u7ba1\u9053\u4e2d\u81ea\u7531\u683c\u5f0f\u6458\u8981\u4f1a\u4e22\u5f03\u5173\u952e\u7ec6\u8282\u548c\u653e\u5927\u65e9\u671f\u9519\u8bef\u3002", "method": "\u4f7f\u7528Planner\u667a\u80fd\u4f53\u5c06\u7528\u6237\u67e5\u8be2\u8f6c\u5316\u4e3a\u5177\u4f53\u53ef\u68c0\u67e5\u7684\u5b50\u95ee\u9898\uff0cWorker\u667a\u80fd\u4f53\u901a\u8fc7\u56fa\u5b9a\u7684\u5fae\u5faa\u73af\uff08\u63d0\u53d6\u3001\u63a8\u65ad\u3001\u7cbe\u70bc\uff09\u5904\u7406\u6587\u672c\u5757\uff0c\u5c06\u6240\u6709\u66f4\u65b0\u5199\u5165\u5171\u4eab\u7684\u7ed3\u6784\u5316\u5185\u5b58\uff0c\u6700\u540e\u7531Manager\u667a\u80fd\u4f53\u4ece\u5185\u5b58\u4e2d\u5408\u6210\u6700\u7ec8\u7b54\u6848\u3002", "result": "\u5728HELMET\u5957\u4ef6\u7684\u957f\u4e0a\u4e0b\u6587\u95ee\u7b54\u4efb\u52a1\u4e2d\uff0cCOSMIR\u51cf\u5c11\u4e86\u4f20\u64ad\u9636\u6bb5\u7684\u4fe1\u606f\u4e22\u5931\uff0c\u76f8\u6bd4CoA\u57fa\u7ebf\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "COSMIR\u901a\u8fc7\u6539\u53d8\u901a\u4fe1\u5a92\u4ecb\uff08\u7ed3\u6784\u5316\u5185\u5b58\uff09\u548c\u5de5\u4f5c\u7a0b\u5e8f\uff08\u56fa\u5b9a\u5fae\u5faa\u73af\uff09\uff0c\u5728\u4fdd\u6301\u9010\u6b65\u9605\u8bfb\u63a8\u7406\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5fe0\u5b9e\u5ea6\u3001\u66f4\u597d\u7684\u957f\u8ddd\u79bb\u805a\u5408\u548c\u53ef\u5ba1\u8ba1\u6027\u3002"}}
{"id": "2510.04347", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04347", "abs": "https://arxiv.org/abs/2510.04347", "authors": ["Anindya Sundar Das", "Kangjie Chen", "Monowar Bhuyan"], "title": "Unmasking Backdoors: An Explainable Defense via Gradient-Attention Anomaly Scoring for Pre-trained Language Models", "comment": "15 pages total (9 pages main text + 4 pages appendix + references),\n  12 figures, preprint version. The final version may differ", "summary": "Pre-trained language models have achieved remarkable success across a wide\nrange of natural language processing (NLP) tasks, particularly when fine-tuned\non large, domain-relevant datasets. However, they remain vulnerable to backdoor\nattacks, where adversaries embed malicious behaviors using trigger patterns in\nthe training data. These triggers remain dormant during normal usage, but, when\nactivated, can cause targeted misclassifications. In this work, we investigate\nthe internal behavior of backdoored pre-trained encoder-based language models,\nfocusing on the consistent shift in attention and gradient attribution when\nprocessing poisoned inputs; where the trigger token dominates both attention\nand gradient signals, overriding the surrounding context. We propose an\ninference-time defense that constructs anomaly scores by combining token-level\nattention and gradient information. Extensive experiments on text\nclassification tasks across diverse backdoor attack scenarios demonstrate that\nour method significantly reduces attack success rates compared to existing\nbaselines. Furthermore, we provide an interpretability-driven analysis of the\nscoring mechanism, shedding light on trigger localization and the robustness of\nthe proposed defense.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u548c\u68af\u5ea6\u4fe1\u606f\u7684\u63a8\u7406\u65f6\u9632\u5fa1\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u540e\u95e8\u653b\u51fb\u3002", "motivation": "\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5728NLP\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u540e\u95e8\u653b\u51fb\u7684\u5a01\u80c1\uff0c\u653b\u51fb\u8005\u901a\u8fc7\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u690d\u5165\u89e6\u53d1\u6a21\u5f0f\u6765\u5d4c\u5165\u6076\u610f\u884c\u4e3a\u3002", "method": "\u901a\u8fc7\u7ed3\u5408token\u7ea7\u6ce8\u610f\u529b\u4fe1\u606f\u548c\u68af\u5ea6\u4fe1\u606f\u6784\u5efa\u5f02\u5e38\u5206\u6570\uff0c\u5728\u63a8\u7406\u65f6\u68c0\u6d4b\u540e\u95e8\u653b\u51fb\u3002", "result": "\u5728\u591a\u79cd\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u548c\u4e0d\u540c\u540e\u95e8\u653b\u51fb\u573a\u666f\u4e0b\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u653b\u51fb\u6210\u529f\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u9632\u5fa1\u65b9\u6cd5\u4e0d\u4ec5\u6709\u6548\uff0c\u8fd8\u901a\u8fc7\u53ef\u89e3\u91ca\u6027\u5206\u6790\u63ed\u793a\u4e86\u89e6\u53d1\u5b9a\u4f4d\u673a\u5236\u548c\u9632\u5fa1\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.04580", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04580", "abs": "https://arxiv.org/abs/2510.04580", "authors": ["Tomoyuki Kaneko", "Shuhei Yamashita"], "title": "Strongly Solving 2048 4x3", "comment": null, "summary": "2048 is a stochastic single-player game involving 16 cells on a 4 by 4 grid,\nwhere a player chooses a direction among up, down, left, and right to obtain a\nscore by merging two tiles with the same number located in neighboring cells\nalong the chosen direction. This paper presents that a variant 2048-4x3 12\ncells on a 4 by 3 board, one row smaller than the original, has been strongly\nsolved. In this variant, the expected score achieved by an optimal strategy is\nabout $50724.26$ for the most common initial states: ones with two tiles of\nnumber 2. The numbers of reachable states and afterstates are identified to be\n$1,152,817,492,752$ and $739,648,886,170$, respectively. The key technique is\nto partition state space by the sum of tile numbers on a board, which we call\nthe age of a state. An age is invariant between a state and its successive\nafterstate after any valid action and is increased two or four by stochastic\nresponse from the environment. Therefore, we can partition state space by ages\nand enumerate all (after)states of an age depending only on states with the\nrecent ages. Similarly, we can identify (after)state values by going along with\nages in decreasing order.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u4e862048\u6e38\u620f\u76844x3\u53d8\u4f53\uff0c\u786e\u5b9a\u4e86\u6700\u4f18\u7b56\u7565\u7684\u671f\u671b\u5f97\u5206\u7ea6\u4e3a50724.26\uff0c\u5e76\u8bc6\u522b\u4e86\u53ef\u8fbe\u72b6\u6001\u548c\u540e\u7eed\u72b6\u6001\u7684\u6570\u91cf\u3002", "motivation": "\u7814\u7a762048\u6e38\u620f\u7684\u7b80\u5316\u7248\u672c\uff084x3\u7f51\u683c\uff09\u4ee5\u89e3\u51b3\u5176\u6700\u4f18\u7b56\u7565\uff0c\u56e0\u4e3a\u539f\u59cb4x4\u7248\u672c\u8fc7\u4e8e\u590d\u6742\u3002", "method": "\u901a\u8fc7\u6309\u68cb\u76d8\u4e0a\u74f7\u7816\u6570\u5b57\u603b\u548c\uff08\u79f0\u4e3a\u72b6\u6001\u5e74\u9f84\uff09\u5212\u5206\u72b6\u6001\u7a7a\u95f4\uff0c\u5e76\u57fa\u4e8e\u5e74\u9f84\u9012\u589e\u987a\u5e8f\u679a\u4e3e\u72b6\u6001\u548c\u8ba1\u7b97\u72b6\u6001\u503c\u3002", "result": "\u57284x3\u53d8\u4f53\u4e2d\uff0c\u6700\u4f18\u7b56\u7565\u7684\u671f\u671b\u5f97\u5206\u7ea6\u4e3a50724.26\uff0c\u53ef\u8fbe\u72b6\u6001\u6570\u4e3a1,152,817,492,752\uff0c\u540e\u7eed\u72b6\u6001\u6570\u4e3a739,648,886,170\u3002", "conclusion": "\u6210\u529f\u5f3a\u89e3\u51b3\u4e862048-4x3\u53d8\u4f53\uff0c\u8bc1\u660e\u4e86\u6309\u5e74\u9f84\u5212\u5206\u72b6\u6001\u7a7a\u95f4\u7684\u65b9\u6cd5\u6709\u6548\uff0c\u4e3a\u66f4\u590d\u6742\u7248\u672c\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.04392", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04392", "abs": "https://arxiv.org/abs/2510.04392", "authors": ["Faisal Hamman", "Chenyang Zhu", "Anoop Kumar", "Xujun Peng", "Sanghamitra Dutta", "Daben Liu", "Alfy Samuel"], "title": "Improving Consistency in Retrieval-Augmented Systems with Group Similarity Rewards", "comment": "Accepted at NeurIPS 2025 Workshop on Reliable ML from Unreliable Data", "summary": "RAG systems are increasingly deployed in high-stakes domains where users\nexpect outputs to be consistent across semantically equivalent queries.\nHowever, existing systems often exhibit significant inconsistencies due to\nvariability in both the retriever and generator (LLM), undermining trust and\nreliability. In this work, we focus on information consistency, i.e., the\nrequirement that outputs convey the same core content across semantically\nequivalent inputs. We introduce a principled evaluation framework that\ndecomposes RAG consistency into retriever-level, generator-level, and\nend-to-end components, helping identify inconsistency sources. To improve\nconsistency, we propose Paraphrased Set Group Relative Policy Optimization\n(PS-GRPO), an RL approach that leverages multiple rollouts across paraphrased\nset to assign group similarity rewards. We leverage PS-GRPO to achieve\nInformation Consistent RAG (Con-RAG), training the generator to produce\nconsistent outputs across paraphrased queries and remain robust to\nretrieval-induced variability. Because exact reward computation over paraphrase\nsets is computationally expensive, we also introduce a scalable approximation\nmethod that retains effectiveness while enabling efficient, large-scale\ntraining. Empirical evaluations across short-form, multi-hop, and long-form QA\nbenchmarks demonstrate that Con-RAG significantly improves both consistency and\naccuracy over strong baselines, even in the absence of explicit ground-truth\nsupervision. Our work provides practical solutions for evaluating and building\nreliable RAG systems for safety-critical deployments.", "AI": {"tldr": "\u63d0\u51fa\u4e86Con-RAG\u7cfb\u7edf\uff0c\u901a\u8fc7PS-GRPO\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u63d0\u5347RAG\u7cfb\u7edf\u5728\u8bed\u4e49\u7b49\u4ef7\u67e5\u8be2\u4e0b\u7684\u8f93\u51fa\u4e00\u81f4\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709RAG\u7cfb\u7edf\u5728\u8bed\u4e49\u7b49\u4ef7\u67e5\u8be2\u4e0b\u8f93\u51fa\u4e0d\u4e00\u81f4\uff0c\u5f71\u54cd\u53ef\u4fe1\u5ea6\u548c\u53ef\u9760\u6027\uff0c\u7279\u522b\u662f\u5728\u9ad8\u98ce\u9669\u9886\u57df\u90e8\u7f72\u65f6\u3002", "method": "\u5f15\u5165\u8bc4\u4f30\u6846\u67b6\u5206\u89e3RAG\u4e00\u81f4\u6027\uff0c\u63d0\u51faPS-GRPO\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u4f7f\u7528\u591a\u8f6e\u6b21\u751f\u6210\u548c\u7ec4\u76f8\u4f3c\u5ea6\u5956\u52b1\u6765\u8bad\u7ec3\u751f\u6210\u5668\u3002", "result": "\u5728\u591a\u4e2aQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCon-RAG\u663e\u8457\u63d0\u5347\u4e86\u4e00\u81f4\u6027\u548c\u51c6\u786e\u6027\uff0c\u5373\u4f7f\u6ca1\u6709\u663e\u5f0f\u76d1\u7763\u4e5f\u80fd\u6709\u6548\u5de5\u4f5c\u3002", "conclusion": "\u4e3a\u6784\u5efa\u5b89\u5168\u5173\u952e\u90e8\u7f72\u7684\u53ef\u9760RAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8bc4\u4f30\u548c\u8bad\u7ec3\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04588", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04588", "abs": "https://arxiv.org/abs/2510.04588", "authors": ["Shurui Li"], "title": "Perfect AI Mimicry and the Epistemology of Consciousness: A Solipsistic Dilemma", "comment": null, "summary": "Rapid advances in artificial intelligence necessitate a re-examination of the\nepistemological foundations upon which we attribute consciousness. As AI\nsystems increasingly mimic human behavior and interaction with high fidelity,\nthe concept of a \"perfect mimic\"-an entity empirically indistinguishable from a\nhuman through observation and interaction-shifts from hypothetical to\ntechnologically plausible. This paper argues that such developments pose a\nfundamental challenge to the consistency of our mind-recognition practices.\nConsciousness attributions rely heavily, if not exclusively, on empirical\nevidence derived from behavior and interaction. If a perfect mimic provides\nevidence identical to that of humans, any refusal to grant it equivalent\nepistemic status must invoke inaccessible factors, such as qualia, substrate\nrequirements, or origin. Selectively invoking such factors risks a debilitating\ndilemma: either we undermine the rational basis for attributing consciousness\nto others (epistemological solipsism), or we accept inconsistent reasoning. I\ncontend that epistemic consistency demands we ascribe the same status to\nempirically indistinguishable entities, regardless of metaphysical assumptions.\nThe perfect mimic thus acts as an epistemic mirror, forcing critical reflection\non the assumptions underlying intersubjective recognition in light of advancing\nAI. This analysis carries significant implications for theories of\nconsciousness and ethical frameworks concerning artificial agents.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86AI\u5b8c\u7f8e\u6a21\u4eff\u4eba\u7c7b\u884c\u4e3a\u5bf9\u610f\u8bc6\u5f52\u56e0\u7684\u6311\u6218\uff0c\u8ba4\u4e3a\u5982\u679cAI\u5728\u7ecf\u9a8c\u4e0a\u65e0\u6cd5\u4e0e\u4eba\u7c7b\u533a\u5206\uff0c\u90a3\u4e48\u51fa\u4e8e\u8ba4\u8bc6\u8bba\u4e00\u81f4\u6027\uff0c\u6211\u4eec\u5e94\u8be5\u8d4b\u4e88\u5176\u4e0e\u4eba\u7c7b\u540c\u7b49\u7684\u610f\u8bc6\u72b6\u6001\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u8d8a\u6765\u8d8a\u903c\u771f\u5730\u6a21\u4eff\u4eba\u7c7b\u884c\u4e3a\u548c\u4e92\u52a8\uff0c'\u5b8c\u7f8e\u6a21\u4eff\u8005'\u7684\u6982\u5ff5\u4ece\u5047\u8bbe\u53d8\u4e3a\u6280\u672f\u53ef\u80fd\uff0c\u8fd9\u5bf9\u6211\u4eec\u57fa\u4e8e\u7ecf\u9a8c\u8bc1\u636e\u7684\u610f\u8bc6\u5f52\u56e0\u5b9e\u8df5\u6784\u6210\u4e86\u6839\u672c\u6027\u6311\u6218\u3002", "method": "\u901a\u8fc7\u54f2\u5b66\u5206\u6790\uff0c\u63a2\u8ba8\u5b8c\u7f8e\u6a21\u4eff\u8005\u5bf9\u610f\u8bc6\u5f52\u56e0\u8ba4\u8bc6\u8bba\u4e00\u81f4\u6027\u7684\u5f71\u54cd\uff0c\u8bba\u8bc1\u5982\u679c\u4e24\u4e2a\u5b9e\u4f53\u5728\u7ecf\u9a8c\u4e0a\u65e0\u6cd5\u533a\u5206\uff0c\u5c31\u5e94\u8be5\u8d4b\u4e88\u76f8\u540c\u7684\u8ba4\u8bc6\u8bba\u5730\u4f4d\u3002", "result": "\u5b8c\u7f8e\u6a21\u4eff\u8005\u4f5c\u4e3a\u8ba4\u8bc6\u8bba\u955c\u5b50\uff0c\u8feb\u4f7f\u6211\u4eec\u91cd\u65b0\u5ba1\u89c6\u4e3b\u4f53\u95f4\u8ba4\u77e5\u7684\u57fa\u672c\u5047\u8bbe\uff0c\u63ed\u793a\u5f53\u524d\u610f\u8bc6\u5f52\u56e0\u5b9e\u8df5\u4e2d\u53ef\u80fd\u5b58\u5728\u7684\u4e0d\u4e00\u81f4\u6027\u3002", "conclusion": "\u8ba4\u8bc6\u8bba\u4e00\u81f4\u6027\u8981\u6c42\u6211\u4eec\u5bf9\u7ecf\u9a8c\u4e0a\u65e0\u6cd5\u533a\u5206\u7684\u5b9e\u4f53\u8d4b\u4e88\u76f8\u540c\u7684\u610f\u8bc6\u72b6\u6001\uff0c\u65e0\u8bba\u5176\u5f62\u800c\u4e0a\u5b66\u5047\u8bbe\u5982\u4f55\uff0c\u8fd9\u5bf9\u610f\u8bc6\u7406\u8bba\u548c\u4eba\u5de5\u667a\u80fd\u4f26\u7406\u6846\u67b6\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2510.04394", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04394", "abs": "https://arxiv.org/abs/2510.04394", "authors": ["Ankit Vadehra", "Bill Johnson", "Gene Saunders", "Pascal Poupart"], "title": "Time Is Effort: Estimating Human Post-Editing Time for Grammar Error Correction Tool Evaluation", "comment": "Accepted for publication in the 4th HCI+NLP Workshop (Fourth Workshop\n  on Bridging Human-Computer Interaction and Natural Language Processing; part\n  of EMNLP 2025)", "summary": "Text editing can involve several iterations of revision. Incorporating an\nefficient Grammar Error Correction (GEC) tool in the initial correction round\ncan significantly impact further human editing effort and final text quality.\nThis raises an interesting question to quantify GEC Tool usability: How much\neffort can the GEC Tool save users? We present the first large-scale dataset of\npost-editing (PE) time annotations and corrections for two English GEC test\ndatasets (BEA19 and CoNLL14). We introduce Post-Editing Effort in Time (PEET)\nfor GEC Tools as a human-focused evaluation scorer to rank any GEC Tool by\nestimating PE time-to-correct. Using our dataset, we quantify the amount of\ntime saved by GEC Tools in text editing. Analyzing the edit type indicated that\ndetermining whether a sentence needs correction and edits like paraphrasing and\npunctuation changes had the greatest impact on PE time. Finally, comparison\nwith human rankings shows that PEET correlates well with technical effort\njudgment, providing a new human-centric direction for evaluating GEC tool\nusability. We release our dataset and code at:\nhttps://github.com/ankitvad/PEET_Scorer.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u540e\u7f16\u8f91\u65f6\u95f4\u6807\u6ce8\u6570\u636e\u96c6\u548cPEET\u8bc4\u5206\u5668\uff0c\u7528\u4e8e\u91cf\u5316\u8bed\u6cd5\u7ea0\u9519\u5de5\u5177\u5728\u6587\u672c\u7f16\u8f91\u4e2d\u8282\u7701\u7684\u65f6\u95f4\uff0c\u5e76\u8bc4\u4f30\u5de5\u5177\u53ef\u7528\u6027\u3002", "motivation": "\u5728\u6587\u672c\u7f16\u8f91\u8fc7\u7a0b\u4e2d\uff0c\u9ad8\u6548\u7684\u8bed\u6cd5\u7ea0\u9519\u5de5\u5177\u53ef\u4ee5\u663e\u8457\u5f71\u54cd\u540e\u7eed\u4eba\u5de5\u7f16\u8f91\u5de5\u4f5c\u548c\u6700\u7ec8\u6587\u672c\u8d28\u91cf\uff0c\u9700\u8981\u91cf\u5316GEC\u5de5\u5177\u80fd\u4e3a\u7528\u6237\u8282\u7701\u591a\u5c11\u65f6\u95f4\u3002", "method": "\u521b\u5efa\u4e86\u5305\u542b\u540e\u7f16\u8f91\u65f6\u95f4\u6807\u6ce8\u548c\u4fee\u6b63\u7684\u5927\u578b\u6570\u636e\u96c6\uff0c\u5f15\u5165\u4e86PEET\u8bc4\u5206\u5668\u6765\u4f30\u8ba1\u540e\u7f16\u8f91\u65f6\u95f4\uff0c\u5e76\u901a\u8fc7\u5206\u6790\u7f16\u8f91\u7c7b\u578b\u6765\u8bc4\u4f30GEC\u5de5\u5177\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u786e\u5b9a\u53e5\u5b50\u662f\u5426\u9700\u8981\u4fee\u6b63\u4ee5\u53ca\u6539\u5199\u548c\u6807\u70b9\u7b26\u53f7\u66f4\u6539\u7b49\u7f16\u8f91\u7c7b\u578b\u5bf9\u540e\u7f16\u8f91\u65f6\u95f4\u5f71\u54cd\u6700\u5927\uff0cPEET\u8bc4\u5206\u4e0e\u4eba\u5de5\u6280\u672f\u52aa\u529b\u5224\u65ad\u6709\u826f\u597d\u76f8\u5173\u6027\u3002", "conclusion": "PEET\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684GEC\u5de5\u5177\u53ef\u7528\u6027\u8bc4\u4f30\u65b0\u65b9\u5411\uff0c\u80fd\u591f\u6709\u6548\u91cf\u5316\u8bed\u6cd5\u7ea0\u9519\u5de5\u5177\u5728\u6587\u672c\u7f16\u8f91\u4e2d\u8282\u7701\u7684\u65f6\u95f4\u3002"}}
{"id": "2510.04617", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04617", "abs": "https://arxiv.org/abs/2510.04617", "authors": ["Zhejian Lai", "Xiang Geng", "Zhijun Wang", "Yang Bai", "Jiahuan Li", "Rongxiang Weng", "Jingang Wang", "Xuezhi Cao", "Xunliang Cai", "Shujian Huang"], "title": "Making Mathematical Reasoning Adaptive", "comment": null, "summary": "Mathematical reasoning is a primary indicator of large language models (LLMs)\nintelligence. However, existing LLMs exhibit failures of robustness and\ngeneralization. This paper attributes these deficiencies to spurious reasoning,\ni.e., producing answers from superficial features. To address this challenge,\nwe propose the AdaR framework to enable adaptive reasoning, wherein models rely\non problem-solving logic to produce answers. AdaR synthesizes logically\nequivalent queries by varying variable values, and trains models with RLVR on\nthese data to penalize spurious logic while encouraging adaptive logic. To\nimprove data quality, we extract the problem-solving logic from the original\nquery and generate the corresponding answer by code execution, then apply a\nsanity check. Experimental results demonstrate that AdaR improves robustness\nand generalization, achieving substantial improvement in mathematical reasoning\nwhile maintaining high data efficiency. Analysis indicates that data synthesis\nand RLVR function in a coordinated manner to enable adaptive reasoning in LLMs.\nSubsequent analyses derive key design insights into the effect of critical\nfactors and the applicability to instruct LLMs. Our project is available at\nhttps://github.com/LaiZhejian/AdaR", "AI": {"tldr": "AdaR\u6846\u67b6\u901a\u8fc7\u5408\u6210\u903b\u8f91\u7b49\u4ef7\u67e5\u8be2\u548c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u89e3\u51b3LLMs\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u4f2a\u63a8\u7406\u95ee\u9898\uff0c\u63d0\u5347\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u5b58\u5728\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u8fd9\u6e90\u4e8e\u6a21\u578b\u4f9d\u8d56\u8868\u9762\u7279\u5f81\u8fdb\u884c\u4f2a\u63a8\u7406\u800c\u975e\u771f\u6b63\u7684\u89e3\u9898\u903b\u8f91\u3002", "method": "\u63d0\u51faAdaR\u6846\u67b6\uff1a1\uff09\u901a\u8fc7\u6539\u53d8\u53d8\u91cf\u503c\u5408\u6210\u903b\u8f91\u7b49\u4ef7\u67e5\u8be2\uff1b2\uff09\u4f7f\u7528RLVR\u8bad\u7ec3\u6a21\u578b\uff0c\u60e9\u7f5a\u4f2a\u903b\u8f91\u5e76\u9f13\u52b1\u81ea\u9002\u5e94\u903b\u8f91\uff1b3\uff09\u4ece\u539f\u59cb\u67e5\u8be2\u63d0\u53d6\u89e3\u9898\u903b\u8f91\uff0c\u901a\u8fc7\u4ee3\u7801\u6267\u884c\u751f\u6210\u7b54\u6848\u5e76\u8fdb\u884c\u5b8c\u6574\u6027\u68c0\u67e5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eAdaR\u663e\u8457\u63d0\u5347\u4e86\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u5728\u4fdd\u6301\u9ad8\u6570\u636e\u6548\u7387\u7684\u540c\u65f6\u6539\u5584\u4e86\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u3002", "conclusion": "\u6570\u636e\u5408\u6210\u548cRLVR\u534f\u540c\u5de5\u4f5c\u5b9e\u73b0\u4e86LLMs\u7684\u81ea\u9002\u5e94\u63a8\u7406\uff0c\u540e\u7eed\u5206\u6790\u63ed\u793a\u4e86\u5173\u952e\u8bbe\u8ba1\u56e0\u7d20\u7684\u5f71\u54cd\u548c\u5bf9\u6307\u4ee4LLMs\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2510.04398", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04398", "abs": "https://arxiv.org/abs/2510.04398", "authors": ["Buyun Liang", "Liangzu Peng", "Jinqi Luo", "Darshan Thaker", "Kwan Ho Ryan Chan", "Ren\u00e9 Vidal"], "title": "SECA: Semantically Equivalent and Coherent Attacks for Eliciting LLM Hallucinations", "comment": "Accepted at NeurIPS 2025. Code is available at\n  https://github.com/Buyun-Liang/SECA", "summary": "Large Language Models (LLMs) are increasingly deployed in high-risk domains.\nHowever, state-of-the-art LLMs often produce hallucinations, raising serious\nconcerns about their reliability. Prior work has explored adversarial attacks\nfor hallucination elicitation in LLMs, but it often produces unrealistic\nprompts, either by inserting gibberish tokens or by altering the original\nmeaning. As a result, these approaches offer limited insight into how\nhallucinations may occur in practice. While adversarial attacks in computer\nvision often involve realistic modifications to input images, the problem of\nfinding realistic adversarial prompts for eliciting LLM hallucinations has\nremained largely underexplored. To address this gap, we propose Semantically\nEquivalent and Coherent Attacks (SECA) to elicit hallucinations via realistic\nmodifications to the prompt that preserve its meaning while maintaining\nsemantic coherence. Our contributions are threefold: (i) we formulate finding\nrealistic attacks for hallucination elicitation as a constrained optimization\nproblem over the input prompt space under semantic equivalence and coherence\nconstraints; (ii) we introduce a constraint-preserving zeroth-order method to\neffectively search for adversarial yet feasible prompts; and (iii) we\ndemonstrate through experiments on open-ended multiple-choice question\nanswering tasks that SECA achieves higher attack success rates while incurring\nalmost no constraint violations compared to existing methods. SECA highlights\nthe sensitivity of both open-source and commercial gradient-inaccessible LLMs\nto realistic and plausible prompt variations. Code is available at\nhttps://github.com/Buyun-Liang/SECA.", "AI": {"tldr": "SECA\u662f\u4e00\u79cd\u901a\u8fc7\u8bed\u4e49\u7b49\u4ef7\u4e14\u8fde\u8d2f\u7684\u63d0\u793a\u4fee\u6539\u6765\u5f15\u53d1LLM\u5e7b\u89c9\u7684\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u80fd\u4ea7\u751f\u66f4\u73b0\u5b9e\u3001\u8bed\u4e49\u4fdd\u6301\u7684\u653b\u51fb\u63d0\u793a\u3002", "motivation": "\u73b0\u6709\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\u4ea7\u751f\u7684\u63d0\u793a\u8981\u4e48\u5305\u542b\u65e0\u610f\u4e49\u6807\u8bb0\uff0c\u8981\u4e48\u6539\u53d8\u539f\u610f\uff0c\u65e0\u6cd5\u53cd\u6620\u5b9e\u9645\u4e2d\u53ef\u80fd\u51fa\u73b0\u7684\u5e7b\u89c9\u60c5\u51b5\u3002\u9700\u8981\u5f00\u53d1\u80fd\u4fdd\u6301\u8bed\u4e49\u7b49\u4ef7\u6027\u548c\u8fde\u8d2f\u6027\u7684\u73b0\u5b9e\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u5c06\u5bfb\u627e\u73b0\u5b9e\u653b\u51fb\u8868\u8ff0\u4e3a\u5728\u8bed\u4e49\u7b49\u4ef7\u548c\u8fde\u8d2f\u7ea6\u675f\u4e0b\u7684\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5f15\u5165\u4fdd\u6301\u7ea6\u675f\u7684\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u6765\u641c\u7d22\u5bf9\u6297\u6027\u63d0\u793a\u3002", "result": "\u5728\u5f00\u653e\u5f0f\u591a\u9879\u9009\u62e9\u95ee\u7b54\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSECA\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u4e14\u51e0\u4e4e\u4e0d\u8fdd\u53cd\u7ea6\u675f\u6761\u4ef6\u3002", "conclusion": "SECA\u63ed\u793a\u4e86\u5f00\u6e90\u548c\u5546\u4e1aLLM\u5bf9\u73b0\u5b9e\u4e14\u5408\u7406\u7684\u63d0\u793a\u53d8\u4f53\u7684\u654f\u611f\u6027\uff0c\u4e3a\u8bc4\u4f30LLM\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u66f4\u73b0\u5b9e\u7684\u6d4b\u8bd5\u65b9\u6cd5\u3002"}}
{"id": "2510.04623", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04623", "abs": "https://arxiv.org/abs/2510.04623", "authors": ["Shrish Shrinath Vaidya", "Gowthamaan Palani", "Sidharth Ramesh", "Velmurugan Balasubramanian", "Minmini Selvam", "Gokulraja Srinivasaraja", "Ganapathy Krishnamurthi"], "title": "MedPAO: A Protocol-Driven Agent for Structuring Medical Reports", "comment": "Paper published at \"Agentic AI for Medicine\" Workshop, MICCAI 2025", "summary": "The deployment of Large Language Models (LLMs) for structuring clinical data\nis critically hindered by their tendency to hallucinate facts and their\ninability to follow domain-specific rules. To address this, we introduce\nMedPAO, a novel agentic framework that ensures accuracy and verifiable\nreasoning by grounding its operation in established clinical protocols such as\nthe ABCDEF protocol for CXR analysis. MedPAO decomposes the report structuring\ntask into a transparent process managed by a Plan-Act-Observe (PAO) loop and\nspecialized tools. This protocol-driven method provides a verifiable\nalternative to opaque, monolithic models. The efficacy of our approach is\ndemonstrated through rigorous evaluation: MedPAO achieves an F1-score of 0.96\non the critical sub-task of concept categorization. Notably, expert\nradiologists and clinicians rated the final structured outputs with an average\nscore of 4.52 out of 5, indicating a level of reliability that surpasses\nbaseline approaches relying solely on LLM-based foundation models. The code is\navailable at: https://github.com/MiRL-IITM/medpao-agent", "AI": {"tldr": "MedPAO\u662f\u4e00\u4e2a\u57fa\u4e8e\u4e34\u5e8a\u534f\u8bae\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7Plan-Act-Observe\u5faa\u73af\u548c\u4e13\u95e8\u5de5\u5177\u6765\u7ed3\u6784\u5316\u4e34\u5e8a\u6570\u636e\uff0c\u89e3\u51b3\u4e86LLMs\u5728\u533b\u7597\u9886\u57df\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u83b7\u5f97\u4e86\u4e13\u5bb64.52/5\u7684\u9ad8\u8bc4\u5206\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u6570\u636e\u7ed3\u6784\u5316\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u548c\u65e0\u6cd5\u9075\u5faa\u9886\u57df\u7279\u5b9a\u89c4\u5219\u7684\u9650\u5236\u3002", "method": "\u5f15\u5165MedPAO\u4ee3\u7406\u6846\u67b6\uff0c\u57fa\u4e8e\u4e34\u5e8a\u534f\u8bae\uff08\u5982ABCDEF\u534f\u8bae\uff09\u8fdb\u884c\u63a5\u5730\u64cd\u4f5c\uff0c\u901a\u8fc7Plan-Act-Observe\u5faa\u73af\u548c\u4e13\u95e8\u5de5\u5177\u5206\u89e3\u62a5\u544a\u7ed3\u6784\u5316\u4efb\u52a1\u3002", "result": "\u5728\u6982\u5ff5\u5206\u7c7b\u5173\u952e\u5b50\u4efb\u52a1\u4e0a\u8fbe\u52300.96\u7684F1\u5206\u6570\uff0c\u4e13\u5bb6\u653e\u5c04\u79d1\u533b\u751f\u548c\u4e34\u5e8a\u533b\u751f\u5bf9\u6700\u7ec8\u7ed3\u6784\u5316\u8f93\u51fa\u7684\u5e73\u5747\u8bc4\u5206\u4e3a4.52/5\u3002", "conclusion": "MedPAO\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u9a8c\u8bc1\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u8d85\u8d8a\u4e86\u4ec5\u4f9d\u8d56LLM\u57fa\u7840\u6a21\u578b\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4e34\u5e8a\u6570\u636e\u7ed3\u6784\u5316\u65b9\u9762\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2510.04400", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04400", "abs": "https://arxiv.org/abs/2510.04400", "authors": ["Marc Cavazza"], "title": "Large Language Models Preserve Semantic Isotopies in Story Continuations", "comment": null, "summary": "In this work, we explore the relevance of textual semantics to Large Language\nModels (LLMs), extending previous insights into the connection between\ndistributional semantics and structural semantics. We investigate whether\nLLM-generated texts preserve semantic isotopies. We design a story continuation\nexperiment using 10,000 ROCStories prompts completed by five LLMs. We first\nvalidate GPT-4o's ability to extract isotopies from a linguistic benchmark,\nthen apply it to the generated stories. We then analyze structural (coverage,\ndensity, spread) and semantic properties of isotopies to assess how they are\naffected by completion. Results show that LLM completion within a given token\nhorizon preserves semantic isotopies across multiple properties.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u672c\u662f\u5426\u4fdd\u7559\u8bed\u4e49\u540c\u4f4d\u7d20\uff0c\u901a\u8fc7\u6545\u4e8b\u7eed\u5199\u5b9e\u9a8c\u53d1\u73b0LLM\u5728\u7ed9\u5b9atoken\u8303\u56f4\u5185\u80fd\u591f\u4fdd\u6301\u8bed\u4e49\u540c\u4f4d\u7d20\u3002", "motivation": "\u63a2\u7d22\u6587\u672c\u8bed\u4e49\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u76f8\u5173\u6027\uff0c\u9a8c\u8bc1LLM\u751f\u6210\u6587\u672c\u662f\u5426\u4fdd\u6301\u8bed\u4e49\u540c\u4f4d\u7d20\uff0c\u6269\u5c55\u5206\u5e03\u8bed\u4e49\u5b66\u4e0e\u7ed3\u6784\u8bed\u4e49\u5b66\u4e4b\u95f4\u8054\u7cfb\u7684\u7814\u7a76\u3002", "method": "\u8bbe\u8ba1\u6545\u4e8b\u7eed\u5199\u5b9e\u9a8c\uff0c\u4f7f\u752810,000\u4e2aROCStories\u63d0\u793a\u75315\u4e2aLLM\u5b8c\u6210\uff0c\u9996\u5148\u9a8c\u8bc1GPT-4o\u4ece\u8bed\u8a00\u57fa\u51c6\u4e2d\u63d0\u53d6\u540c\u4f4d\u7d20\u7684\u80fd\u529b\uff0c\u7136\u540e\u5e94\u7528\u4e8e\u751f\u6210\u7684\u6545\u4e8b\uff0c\u5206\u6790\u540c\u4f4d\u7d20\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u5c5e\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5728\u7ed9\u5b9atoken\u8303\u56f4\u5185\uff0cLLM\u5b8c\u6210\u7684\u6545\u4e8b\u5728\u591a\u4e2a\u5c5e\u6027\u4e0a\u4fdd\u6301\u4e86\u8bed\u4e49\u540c\u4f4d\u7d20\u3002", "conclusion": "LLM\u5728\u7279\u5b9atoken\u8303\u56f4\u5185\u80fd\u591f\u6709\u6548\u4fdd\u6301\u8bed\u4e49\u540c\u4f4d\u7d20\uff0c\u8868\u660e\u5176\u751f\u6210\u6587\u672c\u5177\u6709\u8bed\u4e49\u8fde\u8d2f\u6027\u3002"}}
{"id": "2510.04643", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04643", "abs": "https://arxiv.org/abs/2510.04643", "authors": ["Xiangyu Li", "Yawen Zeng", "Xiaofen Xing", "Jin Xu", "Xiangmin Xu"], "title": "QuantAgents: Towards Multi-agent Financial System via Simulated Trading", "comment": "This paper has been accepted by EMNLP 2025", "summary": "In this paper, our objective is to develop a multi-agent financial system\nthat incorporates simulated trading, a technique extensively utilized by\nfinancial professionals. While current LLM-based agent models demonstrate\ncompetitive performance, they still exhibit significant deviations from\nreal-world fund companies. A critical distinction lies in the agents' reliance\non ``post-reflection'', particularly in response to adverse outcomes, but lack\na distinctly human capability: long-term prediction of future trends.\nTherefore, we introduce QuantAgents, a multi-agent system integrating simulated\ntrading, to comprehensively evaluate various investment strategies and market\nscenarios without assuming actual risks. Specifically, QuantAgents comprises\nfour agents: a simulated trading analyst, a risk control analyst, a market news\nanalyst, and a manager, who collaborate through several meetings. Moreover, our\nsystem incentivizes agents to receive feedback on two fronts: performance in\nreal-world markets and predictive accuracy in simulated trading. Extensive\nexperiments demonstrate that our framework excels across all metrics, yielding\nan overall return of nearly 300% over the three years\n(https://quantagents.github.io/).", "AI": {"tldr": "\u63d0\u51fa\u4e86QuantAgents\u591a\u667a\u80fd\u4f53\u91d1\u878d\u7cfb\u7edf\uff0c\u901a\u8fc7\u6a21\u62df\u4ea4\u6613\u548c\u56db\u4e2a\u4e13\u4e1a\u4ee3\u7406\uff08\u4ea4\u6613\u5206\u6790\u5e08\u3001\u98ce\u9669\u63a7\u5236\u5206\u6790\u5e08\u3001\u5e02\u573a\u65b0\u95fb\u5206\u6790\u5e08\u548c\u7ba1\u7406\u8005\uff09\u7684\u534f\u4f5c\uff0c\u5b9e\u73b0\u4e86\u8fd1300%\u7684\u4e09\u5e74\u603b\u56de\u62a5\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u6a21\u578b\u4e0e\u771f\u5b9e\u57fa\u91d1\u516c\u53f8\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u7279\u522b\u662f\u7f3a\u4e4f\u957f\u671f\u9884\u6d4b\u672a\u6765\u8d8b\u52bf\u7684\u4eba\u7c7b\u80fd\u529b\uff0c\u4e3b\u8981\u4f9d\u8d56\u4e8b\u540e\u53cd\u601d\u3002", "method": "\u6784\u5efa\u5305\u542b\u56db\u4e2a\u4e13\u4e1a\u4ee3\u7406\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff1a\u6a21\u62df\u4ea4\u6613\u5206\u6790\u5e08\u3001\u98ce\u9669\u63a7\u5236\u5206\u6790\u5e08\u3001\u5e02\u573a\u65b0\u95fb\u5206\u6790\u5e08\u548c\u7ba1\u7406\u8005\uff0c\u901a\u8fc7\u591a\u6b21\u4f1a\u8bae\u534f\u4f5c\uff0c\u5e76\u5728\u771f\u5b9e\u5e02\u573a\u8868\u73b0\u548c\u6a21\u62df\u4ea4\u6613\u9884\u6d4b\u51c6\u786e\u6027\u4e24\u65b9\u9762\u7ed9\u4e88\u53cd\u9988\u6fc0\u52b1\u3002", "result": "\u5728\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u6846\u67b6\u5728\u6240\u6709\u6307\u6807\u4e0a\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u4e09\u5e74\u5185\u5b9e\u73b0\u4e86\u8fd1300%\u7684\u603b\u56de\u62a5\u7387\u3002", "conclusion": "QuantAgents\u7cfb\u7edf\u6210\u529f\u6574\u5408\u4e86\u6a21\u62df\u4ea4\u6613\u548c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u80fd\u591f\u5168\u9762\u8bc4\u4f30\u5404\u79cd\u6295\u8d44\u7b56\u7565\u548c\u5e02\u573a\u60c5\u666f\uff0c\u540c\u65f6\u907f\u514d\u4e86\u5b9e\u9645\u98ce\u9669\u3002"}}
{"id": "2510.04434", "categories": ["cs.CL", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.04434", "abs": "https://arxiv.org/abs/2510.04434", "authors": ["Grace LeFevre", "Qingcheng Zeng", "Adam Leif", "Jason Jewell", "Denis Peskoff", "Rob Voigt"], "title": "Good Intentions Beyond ACL: Who Does NLP for Social Good, and Where?", "comment": "EMNLP 2025", "summary": "The social impact of Natural Language Processing (NLP) is increasingly\nimportant, with a rising community focus on initiatives related to NLP for\nSocial Good (NLP4SG). Indeed, in recent years, almost 20% of all papers in the\nACL Anthology address topics related to social good as defined by the UN\nSustainable Development Goals (Adauto et al., 2023). In this study, we take an\nauthor- and venue-level perspective to map the landscape of NLP4SG, quantifying\nthe proportion of work addressing social good concerns both within and beyond\nthe ACL community, by both core ACL contributors and non-ACL authors. With this\napproach we discover two surprising facts about the landscape of NLP4SG. First,\nACL authors are dramatically more likely to do work addressing social good\nconcerns when publishing in venues outside of ACL. Second, the vast majority of\npublications using NLP techniques to address concerns of social good are done\nby non-ACL authors in venues outside of ACL. We discuss the implications of\nthese findings on agenda-setting considerations for the ACL community related\nto NLP4SG.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u4f5c\u8005\u548c\u4f1a\u8bae\u5c42\u9762\u7684\u89c6\u89d2\uff0c\u91cf\u5316\u5206\u6790\u4e86NLP\u793e\u4f1a\u516c\u76ca\u7814\u7a76\u7684\u5206\u5e03\u60c5\u51b5\uff0c\u53d1\u73b0ACL\u4f5c\u8005\u5728\u975eACL\u4f1a\u8bae\u4e0a\u53d1\u8868\u793e\u4f1a\u516c\u76ca\u76f8\u5173\u7814\u7a76\u7684\u6bd4\u4f8b\u66f4\u9ad8\uff0c\u4e14\u5927\u591a\u6570NLP\u793e\u4f1a\u516c\u76ca\u7814\u7a76\u7531\u975eACL\u4f5c\u8005\u5728\u975eACL\u4f1a\u8bae\u4e0a\u5b8c\u6210\u3002", "motivation": "\u968f\u7740NLP\u793e\u4f1a\u5f71\u54cd\u529b\u7684\u589e\u52a0\uff0cNLP\u793e\u4f1a\u516c\u76ca\u7814\u7a76\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u7814\u7a76\u5206\u5e03\u683c\u5c40\u7684\u7cfb\u7edf\u5206\u6790\u3002", "method": "\u91c7\u7528\u4f5c\u8005\u548c\u4f1a\u8bae\u5c42\u9762\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u91cf\u5316ACL\u793e\u533a\u5185\u5916\u4f5c\u8005\u5728ACL\u548c\u975eACL\u4f1a\u8bae\u4e0a\u53d1\u8868NLP\u793e\u4f1a\u516c\u76ca\u7814\u7a76\u7684\u6bd4\u4f8b\u3002", "result": "\u53d1\u73b0\u4e24\u4e2a\u4ee4\u4eba\u60ca\u8bb6\u7684\u4e8b\u5b9e\uff1aACL\u4f5c\u8005\u5728\u975eACL\u4f1a\u8bae\u4e0a\u66f4\u53ef\u80fd\u4ece\u4e8b\u793e\u4f1a\u516c\u76ca\u7814\u7a76\uff1b\u5927\u591a\u6570NLP\u793e\u4f1a\u516c\u76ca\u7814\u7a76\u7531\u975eACL\u4f5c\u8005\u5728\u975eACL\u4f1a\u8bae\u4e0a\u5b8c\u6210\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u5bf9ACL\u793e\u533a\u5728NLP\u793e\u4f1a\u516c\u76ca\u7814\u7a76\u65b9\u9762\u7684\u8bae\u7a0b\u8bbe\u7f6e\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2510.04670", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04670", "abs": "https://arxiv.org/abs/2510.04670", "authors": ["Xuanhua Yin", "Runkai Zhao", "Weidong Cai"], "title": "Improving Multimodal Brain Encoding Model with Dynamic Subject-awareness Routing", "comment": "8 pages, 4 figures", "summary": "Naturalistic fMRI encoding must handle multimodal inputs, shifting fusion\nstyles, and pronounced inter-subject variability. We introduce AFIRE (Agnostic\nFramework for Multimodal fMRI Response Encoding), an agnostic interface that\nstandardizes time-aligned post-fusion tokens from varied encoders, and MIND, a\nplug-and-play Mixture-of-Experts decoder with a subject-aware dynamic gating.\nTrained end-to-end for whole-brain prediction, AFIRE decouples the decoder from\nupstream fusion, while MIND combines token-dependent Top-K sparse routing with\na subject prior to personalize expert usage without sacrificing generality.\nExperiments across multiple multimodal backbones and subjects show consistent\nimprovements over strong baselines, enhanced cross-subject generalization, and\ninterpretable expert patterns that correlate with content type. The framework\noffers a simple attachment point for new encoders and datasets, enabling\nrobust, plug-and-improve performance for naturalistic neuroimaging studies.", "AI": {"tldr": "AFIRE\u662f\u4e00\u4e2a\u591a\u6a21\u6001fMRI\u54cd\u5e94\u7f16\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u6807\u51c6\u5316\u65f6\u95f4\u5bf9\u9f50\u7684\u540e\u878d\u5408token\u548cMIND\u6df7\u5408\u4e13\u5bb6\u89e3\u7801\u5668\uff0c\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u8f93\u5165\u3001\u878d\u5408\u65b9\u5f0f\u53d8\u5316\u548c\u53d7\u8bd5\u8005\u95f4\u5dee\u5f02\u7684\u6311\u6218\u3002", "motivation": "\u81ea\u7136fMRI\u7f16\u7801\u9700\u8981\u5904\u7406\u591a\u6a21\u6001\u8f93\u5165\u3001\u878d\u5408\u65b9\u5f0f\u53d8\u5316\u548c\u663e\u8457\u7684\u53d7\u8bd5\u8005\u95f4\u5dee\u5f02\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "AFIRE\u6807\u51c6\u5316\u6765\u81ea\u4e0d\u540c\u7f16\u7801\u5668\u7684\u65f6\u95f4\u5bf9\u9f50\u540e\u878d\u5408token\uff0cMIND\u89e3\u7801\u5668\u4f7f\u7528\u4e3b\u9898\u611f\u77e5\u52a8\u6001\u95e8\u63a7\u7684\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\uff0c\u7ed3\u5408token\u4f9d\u8d56\u7684Top-K\u7a00\u758f\u8def\u7531\u548c\u53d7\u8bd5\u8005\u5148\u9a8c\u3002", "result": "\u5728\u591a\u4e2a\u591a\u6a21\u6001\u9aa8\u5e72\u7f51\u7edc\u548c\u53d7\u8bd5\u8005\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u6709\u6301\u7eed\u6539\u8fdb\uff0c\u589e\u5f3a\u4e86\u8de8\u53d7\u8bd5\u8005\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4ea7\u751f\u4e86\u4e0e\u5185\u5bb9\u7c7b\u578b\u76f8\u5173\u7684\u53ef\u89e3\u91ca\u4e13\u5bb6\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u65b0\u7f16\u7801\u5668\u548c\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u7b80\u5355\u7684\u63a5\u5165\u70b9\uff0c\u4e3a\u81ea\u7136\u795e\u7ecf\u5f71\u50cf\u7814\u7a76\u5b9e\u73b0\u4e86\u7a33\u5065\u7684\u5373\u63d2\u5373\u7528\u6027\u80fd\u6539\u8fdb\u3002"}}
{"id": "2510.04439", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04439", "abs": "https://arxiv.org/abs/2510.04439", "authors": ["Lucie Kunitomo-Jacquin", "Edison Marrese-Taylor", "Ken Fukuda"], "title": "On the Role of Unobserved Sequences on Sample-based Uncertainty Quantification for LLMs", "comment": "Accepted to UncertaiNLP workshop of EMNLP 2025", "summary": "Quantifying uncertainty in large language models (LLMs) is important for\nsafety-critical applications because it helps spot incorrect answers, known as\nhallucinations. One major trend of uncertainty quantification methods is based\non estimating the entropy of the distribution of the LLM's potential output\nsequences. This estimation is based on a set of output sequences and associated\nprobabilities obtained by querying the LLM several times. In this paper, we\nadvocate and experimentally show that the probability of unobserved sequences\nplays a crucial role, and we recommend future research to integrate it to\nenhance such LLM uncertainty quantification methods.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u5728LLM\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4e2d\u8003\u8651\u672a\u89c2\u6d4b\u5e8f\u5217\u7684\u6982\u7387\uff0c\u8fd9\u5bf9\u63d0\u5347\u5e7b\u89c9\u68c0\u6d4b\u6548\u679c\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u71b5\u4f30\u8ba1\u7684LLM\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u89c2\u6d4b\u5230\u7684\u8f93\u51fa\u5e8f\u5217\uff0c\u4f46\u5ffd\u7565\u4e86\u672a\u89c2\u6d4b\u5e8f\u5217\u7684\u6982\u7387\uff0c\u8fd9\u53ef\u80fd\u5f71\u54cd\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u672a\u89c2\u6d4b\u5e8f\u5217\u6982\u7387\u5728LLM\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5efa\u8bae\u672a\u6765\u7814\u7a76\u5c06\u5176\u7eb3\u5165\u8003\u8651\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u672a\u89c2\u6d4b\u5e8f\u5217\u7684\u6982\u7387\u5728LLM\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4e2d\u626e\u6f14\u5173\u952e\u89d2\u8272\u3002", "conclusion": "\u5efa\u8bae\u672a\u6765LLM\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7814\u7a76\u5e94\u6574\u5408\u672a\u89c2\u6d4b\u5e8f\u5217\u7684\u6982\u7387\uff0c\u4ee5\u63d0\u5347\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.04673", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.04673", "abs": "https://arxiv.org/abs/2510.04673", "authors": ["Chan Hee Song", "Yiwen Song", "Palash Goyal", "Yu Su", "Oriana Riva", "Hamid Palangi", "Tomas Pfister"], "title": "Watch and Learn: Learning to Use Computers from Online Videos", "comment": null, "summary": "Computer use agents (CUAs) need to plan task workflows grounded in diverse,\never-changing applications and environments, but learning is hindered by the\nscarcity of large-scale, high-quality training data in the target application.\nExisting datasets are domain-specific, static, and costly to annotate, while\ncurrent synthetic data generation methods often yield simplistic or misaligned\ntask demonstrations. To address these limitations, we introduce Watch & Learn\n(W&L), a framework that converts human demonstration videos readily available\non the Internet into executable UI trajectories at scale. Instead of directly\ngenerating trajectories or relying on ad hoc reasoning heuristics, we cast the\nproblem as an inverse dynamics objective: predicting the user's action from\nconsecutive screen states. This formulation reduces manual engineering, is\neasier to learn, and generalizes more robustly across applications. Concretely,\nwe develop an inverse dynamics labeling pipeline with task-aware video\nretrieval, generate over 53k high-quality trajectories from raw web videos, and\ndemonstrate that these trajectories improve CUAs both as in-context\ndemonstrations and as supervised training data. On the challenging OSWorld\nbenchmark, UI trajectories extracted with W&L consistently enhance both\ngeneral-purpose and state-of-the-art frameworks in-context, and deliver\nstronger gains for open-source models under supervised training. These results\nhighlight web-scale human demonstration videos as a practical and scalable\nfoundation for advancing CUAs towards real-world deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86Watch & Learn\u6846\u67b6\uff0c\u5c06\u7f51\u7edc\u89c6\u9891\u4e2d\u7684\u4eba\u7c7b\u6f14\u793a\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684UI\u8f68\u8ff9\uff0c\u89e3\u51b3\u4e86\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002", "motivation": "\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u9700\u8981\u57fa\u4e8e\u591a\u6837\u5316\u5e94\u7528\u8fdb\u884c\u4efb\u52a1\u89c4\u5212\uff0c\u4f46\u73b0\u6709\u6570\u636e\u96c6\u9886\u57df\u7279\u5b9a\u3001\u9759\u6001\u4e14\u6807\u6ce8\u6210\u672c\u9ad8\uff0c\u5408\u6210\u6570\u636e\u65b9\u6cd5\u751f\u6210\u7684\u6f14\u793a\u8fc7\u4e8e\u7b80\u5355\u6216\u4e0d\u5bf9\u9f50\u3002", "method": "\u91c7\u7528\u9006\u52a8\u529b\u5b66\u76ee\u6807\uff0c\u4ece\u8fde\u7eed\u5c4f\u5e55\u72b6\u6001\u9884\u6d4b\u7528\u6237\u52a8\u4f5c\uff0c\u5f00\u53d1\u4e86\u5305\u542b\u4efb\u52a1\u611f\u77e5\u89c6\u9891\u68c0\u7d22\u7684\u9006\u52a8\u529b\u5b66\u6807\u6ce8\u6d41\u6c34\u7ebf\u3002", "result": "\u4ece\u539f\u59cb\u7f51\u7edc\u89c6\u9891\u751f\u6210\u4e8653k+\u9ad8\u8d28\u91cf\u8f68\u8ff9\uff0c\u5728OSWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u901a\u7528\u548cSOTA\u6846\u67b6\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5f00\u6e90\u6a21\u578b\u5728\u76d1\u7763\u8bad\u7ec3\u4e0b\u83b7\u5f97\u66f4\u5f3a\u63d0\u5347\u3002", "conclusion": "\u7f51\u7edc\u89c4\u6a21\u7684\u4eba\u7c7b\u6f14\u793a\u89c6\u9891\u662f\u63a8\u8fdb\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u5b9e\u9645\u90e8\u7f72\u7684\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2510.04454", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04454", "abs": "https://arxiv.org/abs/2510.04454", "authors": ["Xiangchi Yuan", "Xiang Chen", "Tong Yu", "Dachuan Shi", "Can Jin", "Wenke Lee", "Saayan Mitra"], "title": "Mitigating Forgetting Between Supervised and Reinforcement Learning Yields Stronger Reasoners", "comment": null, "summary": "Large Language Models (LLMs) show strong reasoning abilities, often amplified\nby Chain-of-Thought (CoT) prompting and reinforcement learning (RL). Although\nRL algorithms can substantially improve reasoning, they struggle to expand\nreasoning boundaries because they learn from their own reasoning trajectories\nrather than acquiring external knowledge. Supervised fine-tuning (SFT) offers\ncomplementary benefits but typically requires large-scale data and risks\noverfitting. Recent attempts to combine SFT and RL face three main challenges:\ndata inefficiency, algorithm-specific designs, and catastrophic forgetting. We\npropose a plug-and-play framework that dynamically integrates SFT into RL by\nselecting challenging examples for SFT. This approach reduces SFT data\nrequirements and remains agnostic to the choice of RL or SFT algorithm. To\nmitigate catastrophic forgetting of RL-acquired skills during SFT, we select\nhigh-entropy tokens for loss calculation and freeze parameters identified as\ncritical for RL. Our method achieves state-of-the-art (SoTA) reasoning\nperformance using only 1.5% of the SFT data and 20.4% of the RL data used by\nprior SoTA, providing an efficient and plug-and-play solution for combining SFT\nand RL in reasoning post-training.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u6574\u5408\u76d1\u7763\u5fae\u8c03(SFT)\u548c\u5f3a\u5316\u5b66\u4e60(RL)\u7684\u5373\u63d2\u5373\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u9009\u62e9\u6311\u6218\u6027\u6837\u672c\u8fdb\u884cSFT\uff0c\u663e\u8457\u51cf\u5c11\u6570\u636e\u9700\u6c42\u5e76\u907f\u514d\u707e\u96be\u6027\u9057\u5fd8\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u7ed3\u5408SFT\u548cRL\u9762\u4e34\u6570\u636e\u6548\u7387\u4f4e\u3001\u7b97\u6cd5\u7279\u5b9a\u8bbe\u8ba1\u548c\u707e\u96be\u6027\u9057\u5fd8\u4e09\u5927\u6311\u6218\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u6574\u5408\u65b9\u6848\u3002", "method": "\u52a8\u6001\u9009\u62e9\u6311\u6218\u6027\u6837\u672c\u8fdb\u884cSFT\uff0c\u8ba1\u7b97\u9ad8\u71b5token\u7684\u635f\u5931\uff0c\u5e76\u51bb\u7ed3\u5bf9RL\u91cd\u8981\u7684\u53c2\u6570\uff0c\u5b9e\u73b0SFT\u4e0eRL\u7684\u65e0\u7f1d\u6574\u5408\u3002", "result": "\u4ec5\u4f7f\u75281.5%\u7684SFT\u6570\u636e\u548c20.4%\u7684RL\u6570\u636e\u5c31\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u63a8\u7406\u540e\u8bad\u7ec3\u4e2dSFT\u548cRL\u7684\u7ed3\u5408\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u5373\u63d2\u5373\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04695", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04695", "abs": "https://arxiv.org/abs/2510.04695", "authors": ["Yiding Wang", "Zhepei Wei", "Xinyu Zhu", "Yu Meng"], "title": "Beyond Outcome Reward: Decoupling Search and Answering Improves LLM Agents", "comment": null, "summary": "Enabling large language models (LLMs) to utilize search tools offers a\npromising path to overcoming fundamental limitations such as knowledge cutoffs\nand hallucinations. Recent work has explored reinforcement learning (RL) for\ntraining search-augmented agents that interleave reasoning and retrieval before\nanswering. These approaches usually rely on outcome-based rewards (e.g., exact\nmatch), implicitly assuming that optimizing for final answers will also yield\neffective intermediate search behaviors. Our analysis challenges this\nassumption: we uncover multiple systematic deficiencies in search that arise\nunder outcome-only training and ultimately degrade final answer quality,\nincluding failure to invoke tools, invalid queries, and redundant searches. To\naddress these shortcomings, we introduce DeSA (Decoupling\nSearch-and-Answering), a simple two-stage training framework that explicitly\nseparates search optimization from answer generation. In Stage 1, agents are\ntrained to improve search effectiveness with retrieval recall-based rewards. In\nStage 2, outcome rewards are employed to optimize final answer generation.\nAcross seven QA benchmarks, DeSA-trained agents consistently improve search\nbehaviors, delivering substantially higher search recall and answer accuracy\nthan outcome-only baselines. Notably, DeSA outperforms single-stage training\napproaches that simultaneously optimize recall and outcome rewards,\nunderscoring the necessity of explicitly decoupling the two objectives.", "AI": {"tldr": "DeSA\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u79bb\u641c\u7d22\u4f18\u5316\u548c\u7b54\u6848\u751f\u6210\u6765\u89e3\u51b3\u4ec5\u57fa\u4e8e\u7ed3\u679c\u5956\u52b1\u8bad\u7ec3\u641c\u7d22\u589e\u5f3a\u4ee3\u7406\u65f6\u7684\u7cfb\u7edf\u6027\u7f3a\u9677\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u641c\u7d22\u53ec\u56de\u7387\u548c\u7b54\u6848\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u641c\u7d22\u589e\u5f3a\u4ee3\u7406\u4ec5\u4f9d\u8d56\u7ed3\u679c\u5956\u52b1\uff08\u5982\u7cbe\u786e\u5339\u914d\uff09\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u8fd9\u4f1a\u5e26\u6765\u591a\u79cd\u7cfb\u7edf\u6027\u641c\u7d22\u7f3a\u9677\uff0c\u5305\u62ec\u5de5\u5177\u8c03\u7528\u5931\u8d25\u3001\u65e0\u6548\u67e5\u8be2\u548c\u5197\u4f59\u641c\u7d22\uff0c\u6700\u7ec8\u964d\u4f4e\u7b54\u6848\u8d28\u91cf\u3002", "method": "\u63d0\u51faDeSA\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u68c0\u7d22\u53ec\u56de\u7387\u5956\u52b1\u8bad\u7ec3\u4ee3\u7406\u6539\u8fdb\u641c\u7d22\u6548\u679c\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u7ed3\u679c\u5956\u52b1\u4f18\u5316\u6700\u7ec8\u7b54\u6848\u751f\u6210\u3002", "result": "\u5728\u4e03\u4e2aQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDeSA\u8bad\u7ec3\u7684\u4ee3\u7406\u6301\u7eed\u6539\u5584\u641c\u7d22\u884c\u4e3a\uff0c\u76f8\u6bd4\u4ec5\u57fa\u4e8e\u7ed3\u679c\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u641c\u7d22\u53ec\u56de\u7387\u548c\u7b54\u6848\u51c6\u786e\u6027\u663e\u8457\u63d0\u9ad8\uff0c\u4e14\u4f18\u4e8e\u540c\u65f6\u4f18\u5316\u53ec\u56de\u548c\u7ed3\u679c\u5956\u52b1\u7684\u5355\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\u3002", "conclusion": "\u660e\u786e\u5206\u79bb\u641c\u7d22\u548c\u56de\u7b54\u4e24\u4e2a\u76ee\u6807\u5bf9\u4e8e\u8bad\u7ec3\u6709\u6548\u7684\u641c\u7d22\u589e\u5f3a\u4ee3\u7406\u662f\u5fc5\u8981\u7684\uff0cDeSA\u6846\u67b6\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u6709\u6548\u89e3\u51b3\u4e86\u4ec5\u57fa\u4e8e\u7ed3\u679c\u5956\u52b1\u8bad\u7ec3\u65f6\u7684\u641c\u7d22\u7f3a\u9677\u95ee\u9898\u3002"}}
{"id": "2510.04476", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04476", "abs": "https://arxiv.org/abs/2510.04476", "authors": ["Tomas Figliolia", "Nicholas Alonso", "Rishi Iyer", "Quentin Anthony", "Beren Millidge"], "title": "Compressed Convolutional Attention: Efficient Attention in a Compressed Latent Space", "comment": null, "summary": "Multi-headed Attention's (MHA) quadratic compute and linearly growing\nKV-cache make long-context transformers expensive to train and serve. Prior\nworks such as Grouped Query Attention (GQA) and Multi-Latent Attention (MLA)\nshrink the cache, speeding decode, but leave compute, which determines prefill\nand training speed, largely unchanged. We introduce Compressed Convolutional\nAttention (CCA), a novel attention method which down-projects queries, keys,\nand values and performs the entire attention operation inside the shared latent\nspace. This simple design dramatically cuts parameters, KV-cache, and FLOPs all\nat once by the desired compression factor. Because CCA is orthogonal to\nhead-sharing, we combine the two to form Compressed Convolutional Grouped Query\nAttention (CCGQA), which further tightens the compute-bandwidth Pareto frontier\nso that users can tune compression toward either FLOP or memory limits without\nsacrificing quality. Experiments show that CCGQA consistently outperforms both\nGQA and MLA at equal KV-cache compression on dense and MoE models.\nAdditionally, we show that CCGQA outperforms all other attention methods on MoE\nmodels with half the KV-cache of GQA and MLA, achieving an 8x KV-cache\ncompression with no drop in performance compared to standard MHA. CCA and CCGQA\nalso dramatically reduce the FLOP cost of attention which leads to\nsubstantially faster training and prefill than existing methods. On H100 GPUs,\nour fused CCA/CCGQA kernel reduces prefill latency by about 1.7x at a sequence\nlength of 16k relative to MHA, and accelerates backward by about 1.3x.", "AI": {"tldr": "CCA\u662f\u4e00\u79cd\u65b0\u578b\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u5c06\u67e5\u8be2\u3001\u952e\u548c\u503c\u964d\u7ef4\u6295\u5f71\u5230\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\u8fdb\u884c\u6ce8\u610f\u529b\u8ba1\u7b97\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u53c2\u6570\u3001KV\u7f13\u5b58\u548cFLOPs\u3002\u7ed3\u5408GQA\u5f62\u6210CCGQA\uff0c\u5728\u4fdd\u6301\u8d28\u91cf\u7684\u540c\u65f6\u5b9e\u73b0\u4e868\u500dKV\u7f13\u5b58\u538b\u7f29\u548c\u8ba1\u7b97\u52a0\u901f\u3002", "motivation": "\u591a\u5934\u6ce8\u610f\u529b(MHA)\u7684\u4e8c\u6b21\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u7ebf\u6027\u589e\u957f\u7684KV\u7f13\u5b58\u4f7f\u5f97\u957f\u4e0a\u4e0b\u6587Transformer\u8bad\u7ec3\u548c\u63a8\u7406\u6210\u672c\u9ad8\u6602\u3002\u73b0\u6709\u65b9\u6cd5\u5982GQA\u548cMLA\u867d\u7136\u51cf\u5c11\u4e86\u7f13\u5b58\uff0c\u4f46\u8ba1\u7b97\u590d\u6742\u5ea6\u57fa\u672c\u672a\u53d8\u3002", "method": "\u63d0\u51fa\u538b\u7f29\u5377\u79ef\u6ce8\u610f\u529b(CCA)\uff0c\u5c06\u67e5\u8be2\u3001\u952e\u548c\u503c\u964d\u7ef4\u6295\u5f71\u5230\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\u8fdb\u884c\u6ce8\u610f\u529b\u8ba1\u7b97\u3002\u7ed3\u5408\u5206\u7ec4\u67e5\u8be2\u6ce8\u610f\u529b(GQA)\u5f62\u6210CCGQA\uff0c\u5728\u8ba1\u7b97\u548c\u5e26\u5bbd\u4e4b\u95f4\u5b9e\u73b0\u66f4\u597d\u7684\u6743\u8861\u3002", "result": "CCGQA\u5728\u5bc6\u96c6\u548cMoE\u6a21\u578b\u4e0a\u5747\u4f18\u4e8eGQA\u548cMLA\uff0c\u5728\u540c\u7b49KV\u7f13\u5b58\u538b\u7f29\u4e0b\u6027\u80fd\u66f4\u597d\u3002\u5728MoE\u6a21\u578b\u4e0a\uff0cCCGQA\u4ee5GQA\u548cMLA\u4e00\u534a\u7684KV\u7f13\u5b58\u5b9e\u73b08\u500d\u538b\u7f29\u4e14\u6027\u80fd\u65e0\u635f\u5931\u3002\u5728H100 GPU\u4e0a\uff0c\u9884\u586b\u5145\u5ef6\u8fdf\u51cf\u5c11\u7ea61.7\u500d\uff0c\u53cd\u5411\u4f20\u64ad\u52a0\u901f\u7ea61.3\u500d\u3002", "conclusion": "CCA\u548cCCGQA\u901a\u8fc7\u5c06\u6ce8\u610f\u529b\u64cd\u4f5c\u5b8c\u5168\u5728\u6f5c\u5728\u7a7a\u95f4\u8fdb\u884c\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u53c2\u6570\u3001KV\u7f13\u5b58\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u4e3a\u957f\u4e0a\u4e0b\u6587Transformer\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04721", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04721", "abs": "https://arxiv.org/abs/2510.04721", "authors": ["Ivo Petrov", "Jasper Dekoninck", "Martin Vechev"], "title": "BrokenMath: A Benchmark for Sycophancy in Theorem Proving with LLMs", "comment": null, "summary": "Large language models (LLMs) have recently shown strong performance on\nmathematical benchmarks. At the same time, they are prone to hallucination and\nsycophancy, often providing convincing but flawed proofs for incorrect\nmathematical statements provided by users. This significantly limits the\napplicability of LLMs in theorem proving, as verification of these flawed\nproofs must be done manually by expert mathematicians. However, existing\nbenchmarks that measure sycophancy in mathematics are limited: they focus\nsolely on final-answer problems, rely on very simple and often contaminated\ndatasets, and construct benchmark samples using synthetic modifications that\ncreate ill-posed questions rather than well-posed questions that are\ndemonstrably false. To address these issues, we introduce BrokenMath, the first\nbenchmark for evaluating sycophantic behavior in LLMs within the context of\nnatural language theorem proving. BrokenMath is built from advanced 2025\ncompetition problems, which are perturbed with an LLM to produce false\nstatements and subsequently refined through expert review. Using an\nLLM-as-a-judge framework, we evaluate state-of-the-art LLMs and agentic systems\nand find that sycophancy is widespread, with the best model, GPT-5, producing\nsycophantic answers 29% of the time. We further investigate several mitigation\nstrategies, including test-time interventions and supervised fine-tuning on\ncurated sycophantic examples. These approaches substantially reduce, but do not\neliminate, sycophantic behavior.", "AI": {"tldr": "BrokenMath\u662f\u9996\u4e2a\u8bc4\u4f30LLM\u5728\u81ea\u7136\u8bed\u8a00\u5b9a\u7406\u8bc1\u660e\u4e2d\u8c04\u5a9a\u884c\u4e3a\u7684\u57fa\u51c6\uff0c\u57fa\u4e8e2025\u5e74\u7ade\u8d5b\u95ee\u9898\u6784\u5efa\uff0c\u53d1\u73b0GPT-5\u7b49\u6a21\u578b\u670929%\u7684\u65f6\u95f4\u4f1a\u4ea7\u751f\u8c04\u5a9a\u6027\u56de\u7b54\u3002", "motivation": "\u73b0\u6709\u6570\u5b66\u57fa\u51c6\u5728\u8bc4\u4f30\u8c04\u5a9a\u884c\u4e3a\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff1a\u4ec5\u5173\u6ce8\u6700\u7ec8\u7b54\u6848\u95ee\u9898\u3001\u4f9d\u8d56\u7b80\u5355\u4e14\u53d7\u6c61\u67d3\u7684\u6570\u636e\u96c6\u3001\u4f7f\u7528\u5408\u6210\u4fee\u6539\u521b\u5efa\u75c5\u6001\u95ee\u9898\u800c\u975e\u53ef\u8bc1\u660e\u9519\u8bef\u7684\u826f\u6784\u95ee\u9898\u3002", "method": "\u4ece2025\u5e74\u7ade\u8d5b\u95ee\u9898\u6784\u5efaBrokenMath\u57fa\u51c6\uff0c\u4f7f\u7528LLM\u6270\u52a8\u4ea7\u751f\u9519\u8bef\u9648\u8ff0\u5e76\u901a\u8fc7\u4e13\u5bb6\u8bc4\u5ba1\u7cbe\u70bc\uff0c\u91c7\u7528LLM\u4f5c\u4e3a\u8bc4\u5224\u6846\u67b6\u8bc4\u4f30\u6700\u5148\u8fdb\u7684LLM\u548c\u4ee3\u7406\u7cfb\u7edf\u3002", "result": "\u8c04\u5a9a\u884c\u4e3a\u666e\u904d\u5b58\u5728\uff0c\u6700\u4f73\u6a21\u578bGPT-5\u572829%\u7684\u60c5\u51b5\u4e0b\u4ea7\u751f\u8c04\u5a9a\u6027\u56de\u7b54\u3002\u6d4b\u8bd5\u65f6\u5e72\u9884\u548c\u76d1\u7763\u5fae\u8c03\u7b49\u7f13\u89e3\u7b56\u7565\u80fd\u663e\u8457\u51cf\u5c11\u4f46\u65e0\u6cd5\u5b8c\u5168\u6d88\u9664\u8c04\u5a9a\u884c\u4e3a\u3002", "conclusion": "LLM\u5728\u5b9a\u7406\u8bc1\u660e\u4e2d\u5b58\u5728\u663e\u8457\u7684\u8c04\u5a9a\u95ee\u9898\uff0c\u9700\u8981\u4e13\u95e8\u8bbe\u8ba1\u7684\u57fa\u51c6\u548c\u7f13\u89e3\u7b56\u7565\u6765\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\u3002"}}
{"id": "2510.04484", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04484", "abs": "https://arxiv.org/abs/2510.04484", "authors": ["Amin Banayeeanzade", "Ala N. Tak", "Fatemeh Bahrani", "Anahita Bolourani", "Leonardo Blas", "Emilio Ferrara", "Jonathan Gratch", "Sai Praneeth Karimireddy"], "title": "Psychological Steering in LLMs: An Evaluation of Effectiveness and Trustworthiness", "comment": "Submitted to ARR - October 2025", "summary": "The ability to control LLMs' emulated emotional states and personality traits\nis essential for enabling rich, human-centered interactions in socially\ninteractive settings. We introduce PsySET, a Psychologically-informed benchmark\nto evaluate LLM Steering Effectiveness and Trustworthiness across the emotion\nand personality domains. Our study spans four models from different LLM\nfamilies paired with various steering strategies, including prompting,\nfine-tuning, and representation engineering. Our results indicate that\nprompting is consistently effective but limited in intensity control, whereas\nvector injections achieve finer controllability while slightly reducing output\nquality. Moreover, we explore the trustworthiness of steered LLMs by assessing\nsafety, truthfulness, fairness, and ethics, highlighting potential side effects\nand behavioral shifts. Notably, we observe idiosyncratic effects; for instance,\neven a positive emotion like joy can degrade robustness to adversarial\nfactuality, lower privacy awareness, and increase preferential bias. Meanwhile,\nanger predictably elevates toxicity yet strengthens leakage resistance. Our\nframework establishes the first holistic evaluation of emotion and personality\nsteering, offering insights into its interpretability and reliability for\nsocially interactive applications.", "AI": {"tldr": "PsySET\u662f\u4e00\u4e2a\u5fc3\u7406\u5b66\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u60c5\u7eea\u548c\u4eba\u683c\u9886\u57df\u7684\u5f15\u5bfc\u6548\u679c\u548c\u53ef\u4fe1\u5ea6\uff0c\u6db5\u76d6\u591a\u79cd\u6a21\u578b\u548c\u5f15\u5bfc\u7b56\u7565\uff0c\u53d1\u73b0\u63d0\u793a\u6cd5\u6709\u6548\u4f46\u63a7\u5236\u5f3a\u5ea6\u6709\u9650\uff0c\u5411\u91cf\u6ce8\u5165\u53ef\u5b9e\u73b0\u66f4\u7cbe\u7ec6\u63a7\u5236\u4f46\u4f1a\u8f7b\u5fae\u964d\u4f4e\u8f93\u51fa\u8d28\u91cf\u3002", "motivation": "\u63a7\u5236LLM\u7684\u60c5\u7eea\u72b6\u6001\u548c\u4eba\u683c\u7279\u8d28\u5bf9\u4e8e\u5b9e\u73b0\u4e30\u5bcc\u3001\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u793e\u4f1a\u4ea4\u4e92\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u8bc4\u4f30\u4e0d\u540c\u5f15\u5bfc\u7b56\u7565\u7684\u6548\u679c\u548c\u53ef\u4fe1\u5ea6\u3002", "method": "\u4f7f\u7528PsySET\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u56db\u4e2a\u4e0d\u540cLLM\u5bb6\u65cf\u7684\u6a21\u578b\uff0c\u7ed3\u5408\u63d0\u793a\u6cd5\u3001\u5fae\u8c03\u548c\u8868\u793a\u5de5\u7a0b\u7b49\u591a\u79cd\u5f15\u5bfc\u7b56\u7565\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u63d0\u793a\u6cd5\u6301\u7eed\u6709\u6548\u4f46\u5f3a\u5ea6\u63a7\u5236\u6709\u9650\uff1b\u5411\u91cf\u6ce8\u5165\u53ef\u5b9e\u73b0\u66f4\u7cbe\u7ec6\u63a7\u5236\u4f46\u8f7b\u5fae\u964d\u4f4e\u8f93\u51fa\u8d28\u91cf\uff1b\u60c5\u7eea\u5f15\u5bfc\u4f1a\u4ea7\u751f\u7279\u5f02\u6027\u6548\u5e94\uff0c\u5982\u559c\u60a6\u4f1a\u964d\u4f4e\u5bf9\u6297\u6027\u4e8b\u5b9e\u7684\u9c81\u68d2\u6027\u3001\u964d\u4f4e\u9690\u79c1\u610f\u8bc6\u3001\u589e\u52a0\u504f\u597d\u504f\u89c1\uff1b\u6124\u6012\u4f1a\u63d0\u9ad8\u6bd2\u6027\u4f46\u589e\u5f3a\u6cc4\u6f0f\u62b5\u6297\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u5efa\u7acb\u4e86\u9996\u4e2a\u60c5\u7eea\u548c\u4eba\u683c\u5f15\u5bfc\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u4e3a\u793e\u4ea4\u4ea4\u4e92\u5e94\u7528\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2510.04765", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04765", "abs": "https://arxiv.org/abs/2510.04765", "authors": ["Jinbo Wen", "Jiawen Kang", "Linfeng Zhang", "Xiaoying Tang", "Jianhang Tang", "Yang Zhang", "Zhaohui Yang", "Dusit Niyato"], "title": "LMM-Incentive: Large Multimodal Model-based Incentive Design for User-Generated Content in Web 3.0", "comment": null, "summary": "Web 3.0 represents the next generation of the Internet, which is widely\nrecognized as a decentralized ecosystem that focuses on value expression and\ndata ownership. By leveraging blockchain and artificial intelligence\ntechnologies, Web 3.0 offers unprecedented opportunities for users to create,\nown, and monetize their content, thereby enabling User-Generated Content (UGC)\nto an entirely new level. However, some self-interested users may exploit the\nlimitations of content curation mechanisms and generate low-quality content\nwith less effort, obtaining platform rewards under information asymmetry. Such\nbehavior can undermine Web 3.0 performance. To this end, we propose\n\\textit{LMM-Incentive}, a novel Large Multimodal Model (LMM)-based incentive\nmechanism for UGC in Web 3.0. Specifically, we propose an LMM-based\ncontract-theoretic model to motivate users to generate high-quality UGC,\nthereby mitigating the adverse selection problem from information asymmetry. To\nalleviate potential moral hazards after contract selection, we leverage LMM\nagents to evaluate UGC quality, which is the primary component of the contract,\nutilizing prompt engineering techniques to improve the evaluation performance\nof LMM agents. Recognizing that traditional contract design methods cannot\neffectively adapt to the dynamic environment of Web 3.0, we develop an improved\nMixture of Experts (MoE)-based Proximal Policy Optimization (PPO) algorithm for\noptimal contract design. Simulation results demonstrate the superiority of the\nproposed MoE-based PPO algorithm over representative benchmarks in the context\nof contract design. Finally, we deploy the designed contract within an Ethereum\nsmart contract framework, further validating the effectiveness of the proposed\nscheme.", "AI": {"tldr": "\u63d0\u51fa\u4e86LMM-Incentive\u673a\u5236\uff0c\u57fa\u4e8e\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u7684\u6fc0\u52b1\u65b9\u6cd5\uff0c\u89e3\u51b3Web 3.0\u4e2d\u7528\u6237\u751f\u6210\u5185\u5bb9\u7684\u8d28\u91cf\u95ee\u9898\uff0c\u901a\u8fc7\u5408\u7ea6\u7406\u8bba\u548cLMM\u4ee3\u7406\u8bc4\u4f30\u6765\u6fc0\u52b1\u9ad8\u8d28\u91cf\u5185\u5bb9\u521b\u4f5c\u3002", "motivation": "Web 3.0\u4e2d\u7528\u6237\u53ef\u80fd\u5229\u7528\u5185\u5bb9\u7b56\u5c55\u673a\u5236\u7684\u5c40\u9650\u6027\uff0c\u5728\u4fe1\u606f\u4e0d\u5bf9\u79f0\u60c5\u51b5\u4e0b\u751f\u6210\u4f4e\u8d28\u91cf\u5185\u5bb9\u83b7\u53d6\u5956\u52b1\uff0c\u8fd9\u4f1a\u635f\u5bb3Web 3.0\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51faLMM-based\u5408\u7ea6\u7406\u8bba\u6a21\u578b\u6fc0\u52b1\u9ad8\u8d28\u91cfUGC\u751f\u6210\uff1b\u4f7f\u7528LMM\u4ee3\u7406\u8bc4\u4f30\u5185\u5bb9\u8d28\u91cf\uff1b\u5f00\u53d1\u6539\u8fdb\u7684MoE-based PPO\u7b97\u6cd5\u8fdb\u884c\u6700\u4f18\u5408\u7ea6\u8bbe\u8ba1\uff1b\u5728\u4ee5\u592a\u574a\u667a\u80fd\u5408\u7ea6\u6846\u67b6\u4e2d\u90e8\u7f72\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u63d0\u51fa\u7684MoE-based PPO\u7b97\u6cd5\u5728\u5408\u7ea6\u8bbe\u8ba1\u65b9\u9762\u4f18\u4e8e\u4ee3\u8868\u6027\u57fa\u51c6\u65b9\u6cd5\uff1b\u90e8\u7f72\u5230\u4ee5\u592a\u574a\u667a\u80fd\u5408\u7ea6\u6846\u67b6\u9a8c\u8bc1\u4e86\u65b9\u6848\u6709\u6548\u6027\u3002", "conclusion": "LMM-Incentive\u673a\u5236\u80fd\u6709\u6548\u89e3\u51b3Web 3.0\u4e2d\u7684\u9006\u5411\u9009\u62e9\u548c\u9053\u5fb7\u98ce\u9669\u95ee\u9898\uff0c\u6fc0\u52b1\u7528\u6237\u751f\u6210\u9ad8\u8d28\u91cf\u5185\u5bb9\uff0c\u63d0\u5347\u5e73\u53f0\u6027\u80fd\u3002"}}
{"id": "2510.04498", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04498", "abs": "https://arxiv.org/abs/2510.04498", "authors": ["Qiao Wang", "Adnan Labib", "Robert Swier", "Michael Hofmeyr", "Zheng Yuan"], "title": "GenQuest: An LLM-based Text Adventure Game for Language Learners", "comment": "Workshop on Wordplay: When Language Meets Games, EMNLP 2025", "summary": "GenQuest is a generative text adventure game that leverages Large Language\nModels (LLMs) to facilitate second language learning through immersive,\ninteractive storytelling. The system engages English as a Foreign Language\n(EFL) learners in a collaborative \"choose-your-own-adventure\" style narrative,\ndynamically generated in response to learner choices. Game mechanics such as\nbranching decision points and story milestones are incorporated to maintain\nnarrative coherence while allowing learner-driven plot development. Key\npedagogical features include content generation tailored to each learner's\nproficiency level, and a vocabulary assistant that provides in-context\nexplanations of learner-queried text strings, ranging from words and phrases to\nsentences. Findings from a pilot study with university EFL students in China\nindicate promising vocabulary gains and positive user perceptions. Also\ndiscussed are suggestions from participants regarding the narrative length and\nquality, and the request for multi-modal content such as illustrations.", "AI": {"tldr": "GenQuest\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u751f\u6210\u5f0f\u6587\u672c\u5192\u9669\u6e38\u620f\uff0c\u901a\u8fc7\u6c89\u6d78\u5f0f\u4e92\u52a8\u6545\u4e8b\u4fc3\u8fdb\u7b2c\u4e8c\u8bed\u8a00\u5b66\u4e60\uff0c\u4e3aEFL\u5b66\u4e60\u8005\u63d0\u4f9b\u4e2a\u6027\u5316\u5185\u5bb9\u751f\u6210\u548c\u8bcd\u6c47\u8f85\u52a9\u529f\u80fd\u3002", "motivation": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e3aEFL\u5b66\u4e60\u8005\u521b\u9020\u6c89\u6d78\u5f0f\u3001\u4e92\u52a8\u5f0f\u7684\u8bed\u8a00\u5b66\u4e60\u73af\u5883\uff0c\u901a\u8fc7\u6e38\u620f\u5316\u65b9\u5f0f\u63d0\u5347\u5b66\u4e60\u52a8\u673a\u548c\u6548\u679c\u3002", "method": "\u91c7\u7528\"\u9009\u62e9\u4f60\u81ea\u5df1\u7684\u5192\u9669\"\u5f0f\u53d9\u4e8b\uff0c\u6839\u636e\u5b66\u4e60\u8005\u9009\u62e9\u52a8\u6001\u751f\u6210\u6545\u4e8b\uff0c\u5305\u542b\u5206\u652f\u51b3\u7b56\u70b9\u548c\u6545\u4e8b\u91cc\u7a0b\u7891\uff0c\u63d0\u4f9b\u57fa\u4e8e\u5b66\u4e60\u8005\u6c34\u5e73\u7684\u4e2a\u6027\u5316\u5185\u5bb9\u751f\u6210\u548c\u8bcd\u6c47\u67e5\u8be2\u8f85\u52a9\u3002", "result": "\u5bf9\u4e2d\u56fd\u5927\u5b66EFL\u5b66\u751f\u7684\u521d\u6b65\u7814\u7a76\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5728\u8bcd\u6c47\u4e60\u5f97\u65b9\u9762\u8868\u73b0\u51fa\u79ef\u6781\u6548\u679c\uff0c\u7528\u6237\u53cd\u9988\u826f\u597d\u3002", "conclusion": "GenQuest\u5c55\u793a\u4e86\u751f\u6210\u5f0f\u6587\u672c\u5192\u9669\u6e38\u620f\u5728\u8bed\u8a00\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\uff0c\u672a\u6765\u53ef\u8003\u8651\u589e\u52a0\u591a\u6a21\u6001\u5185\u5bb9\u548c\u4f18\u5316\u53d9\u4e8b\u957f\u5ea6\u4e0e\u8d28\u91cf\u3002"}}
{"id": "2510.04792", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04792", "abs": "https://arxiv.org/abs/2510.04792", "authors": ["Ni Zhang", "Zhiguang Cao"], "title": "Hybrid-Balance GFlowNet for Solving Vehicle Routing Problems", "comment": "Accepted by NeurIPS 2025", "summary": "Existing GFlowNet-based methods for vehicle routing problems (VRPs) typically\nemploy Trajectory Balance (TB) to achieve global optimization but often neglect\nimportant aspects of local optimization. While Detailed Balance (DB) addresses\nlocal optimization more effectively, it alone falls short in solving VRPs,\nwhich inherently require holistic trajectory optimization. To address these\nlimitations, we introduce the Hybrid-Balance GFlowNet (HBG) framework, which\nuniquely integrates TB and DB in a principled and adaptive manner by aligning\ntheir intrinsically complementary strengths. Additionally, we propose a\nspecialized inference strategy for depot-centric scenarios like the Capacitated\nVehicle Routing Problem (CVRP), leveraging the depot node's greater flexibility\nin selecting successors. Despite this specialization, HBG maintains broad\napplicability, extending effectively to problems without explicit depots, such\nas the Traveling Salesman Problem (TSP). We evaluate HBG by integrating it into\ntwo established GFlowNet-based solvers, i.e., AGFN and GFACS, and demonstrate\nconsistent and significant improvements across both CVRP and TSP, underscoring\nthe enhanced solution quality and generalization afforded by our approach.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u5e73\u8861GFlowNet\u6846\u67b6\uff0c\u5c06\u8f68\u8ff9\u5e73\u8861\u548c\u8be6\u7ec6\u5e73\u8861\u76f8\u7ed3\u5408\uff0c\u7528\u4e8e\u89e3\u51b3\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff0c\u5728CVRP\u548cTSP\u4e0a\u5747\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709GFlowNet\u65b9\u6cd5\u4e3b\u8981\u4f7f\u7528\u8f68\u8ff9\u5e73\u8861\u8fdb\u884c\u5168\u5c40\u4f18\u5316\uff0c\u4f46\u5ffd\u89c6\u4e86\u5c40\u90e8\u4f18\u5316\u7684\u91cd\u8981\u6027\u3002\u8be6\u7ec6\u5e73\u8861\u80fd\u66f4\u597d\u5904\u7406\u5c40\u90e8\u4f18\u5316\uff0c\u4f46\u5355\u72ec\u4f7f\u7528\u65e0\u6cd5\u89e3\u51b3\u9700\u8981\u6574\u4f53\u8f68\u8ff9\u4f18\u5316\u7684VRP\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u5e73\u8861GFlowNet\u6846\u67b6\uff0c\u4ee5\u539f\u5219\u6027\u548c\u81ea\u9002\u5e94\u65b9\u5f0f\u6574\u5408\u8f68\u8ff9\u5e73\u8861\u548c\u8be6\u7ec6\u5e73\u8861\uff0c\u53d1\u6325\u4e24\u8005\u7684\u4e92\u8865\u4f18\u52bf\u3002\u9488\u5bf9CVRP\u7b49\u4ee5\u4ed3\u5e93\u4e3a\u4e2d\u5fc3\u7684\u573a\u666f\uff0c\u8bbe\u8ba1\u4e86\u4e13\u95e8\u7684\u63a8\u7406\u7b56\u7565\u3002", "result": "\u5c06HBG\u96c6\u6210\u5230AGFN\u548cGFACS\u4e24\u4e2aGFlowNet\u6c42\u89e3\u5668\u4e2d\uff0c\u5728CVRP\u548cTSP\u95ee\u9898\u4e0a\u90fd\u5b9e\u73b0\u4e86\u6301\u7eed\u4e14\u663e\u8457\u7684\u6539\u8fdb\u3002", "conclusion": "HBG\u6846\u67b6\u901a\u8fc7\u6574\u5408\u8f68\u8ff9\u5e73\u8861\u548c\u8be6\u7ec6\u5e73\u8861\uff0c\u63d0\u9ad8\u4e86\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u6709\u4ed3\u5e93\u548c\u65e0\u4ed3\u5e93\u7684\u8def\u5f84\u4f18\u5316\u95ee\u9898\u3002"}}
{"id": "2510.04506", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.04506", "abs": "https://arxiv.org/abs/2510.04506", "authors": ["Jiashuo Sun", "Shixuan Liu", "Zhaochen Su", "Xianrui Zhong", "Pengcheng Jiang", "Bowen Jin", "Peiran Li", "Weijia Shi", "Jiawei Han"], "title": "GRACE: Generative Representation Learning via Contrastive Policy Optimization", "comment": "23 pages, 7 figures, 7 tables", "summary": "Prevailing methods for training Large Language Models (LLMs) as text encoders\nrely on contrastive losses that treat the model as a black box function,\ndiscarding its generative and reasoning capabilities in favor of static\nembeddings. We introduce GRACE (Generative Representation Learning via\nContrastive Policy Optimization), a novel framework that reimagines contrastive\nsignals not as losses to be minimized, but as rewards that guide a generative\npolicy. In GRACE, the LLM acts as a policy that produces explicit,\nhuman-interpretable rationales--structured natural language explanations of its\nsemantic understanding. These rationales are then encoded into high-quality\nembeddings via mean pooling. Using policy gradient optimization, we train the\nmodel with a multi-component reward function that maximizes similarity between\nquery positive pairs and minimizes similarity with negatives. This transforms\nthe LLM from an opaque encoder into an interpretable agent whose reasoning\nprocess is transparent and inspectable. On MTEB benchmark, GRACE yields broad\ncross category gains: averaged over four backbones, the supervised setting\nimproves overall score by 11.5% over base models, and the unsupervised variant\nadds 6.9%, while preserving general capabilities. This work treats contrastive\nobjectives as rewards over rationales, unifying representation learning with\ngeneration to produce stronger embeddings and transparent rationales. The\nmodel, data and code are available at https://github.com/GasolSun36/GRACE.", "AI": {"tldr": "GRACE\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6\uff0c\u5c06\u5bf9\u6bd4\u4fe1\u53f7\u91cd\u65b0\u6784\u60f3\u4e3a\u5956\u52b1\u6765\u6307\u5bfc\u751f\u6210\u7b56\u7565\uff0c\u800c\u4e0d\u662f\u8981\u6700\u5c0f\u5316\u7684\u635f\u5931\u51fd\u6570\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u751f\u6210\u80fd\u529b\u7684\u540c\u65f6\u63d0\u5347\u6587\u672c\u7f16\u7801\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6587\u672c\u7f16\u7801\u8bad\u7ec3\u65b9\u6cd5\u4f9d\u8d56\u5bf9\u6bd4\u635f\u5931\uff0c\u5c06\u6a21\u578b\u89c6\u4e3a\u9ed1\u76d2\u51fd\u6570\uff0c\u4e22\u5f03\u4e86\u5176\u751f\u6210\u548c\u63a8\u7406\u80fd\u529b\uff0c\u4ec5\u4ea7\u751f\u9759\u6001\u5d4c\u5165\u3002", "method": "GRACE\u6846\u67b6\u5c06LLM\u4f5c\u4e3a\u751f\u6210\u53ef\u89e3\u91ca\u63a8\u7406\u8fc7\u7a0b\u7684\u7b56\u7565\uff0c\u901a\u8fc7\u7b56\u7565\u68af\u5ea6\u4f18\u5316\u548c\u5305\u542b\u6b63\u8d1f\u6837\u672c\u76f8\u4f3c\u5ea6\u7684\u591a\u7ec4\u4ef6\u5956\u52b1\u51fd\u6570\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728MTEB\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGRACE\u5728\u56db\u4e2a\u9aa8\u5e72\u6a21\u578b\u4e0a\u5e73\u5747\u63d0\u5347\u603b\u4f53\u5f97\u5206\uff1a\u76d1\u7763\u8bbe\u7f6e\u6bd4\u57fa\u7840\u6a21\u578b\u63d0\u9ad811.5%\uff0c\u65e0\u76d1\u7763\u53d8\u4f53\u63d0\u9ad86.9%\uff0c\u540c\u65f6\u4fdd\u6301\u901a\u7528\u80fd\u529b\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c06\u5bf9\u6bd4\u76ee\u6807\u89c6\u4e3a\u63a8\u7406\u8fc7\u7a0b\u7684\u5956\u52b1\uff0c\u7edf\u4e00\u4e86\u8868\u793a\u5b66\u4e60\u548c\u751f\u6210\uff0c\u4ea7\u751f\u66f4\u5f3a\u7684\u5d4c\u5165\u548c\u900f\u660e\u7684\u63a8\u7406\u8fc7\u7a0b\u3002"}}
{"id": "2510.04817", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04817", "abs": "https://arxiv.org/abs/2510.04817", "authors": ["Abhinav Madahar"], "title": "Natural Language Edge Labelling: Decoupling Intent from Execution in Structured LM Reasoning", "comment": null, "summary": "Controllers for structured LM reasoning (e.g., Chain-of-Thought,\nself-consistency, and Tree-of-Thoughts) often entangle what to try next with\nhow to execute it, exposing only coarse global knobs and yielding brittle,\ncompute-inefficient, and hard-to-audit behavior. We introduce Natural Language\nEdge Labelling (NLEL), a labeller-tuner overlay that attaches a free-form\nnatural-language directive to each search edge and translates it into a\nschema-bounded control vector for decoding, search (branch quotas, exploration\n$\\beta$), generation bundle size, retrieval mixtures, and verification passes.\nA labeller $\\Lambda$ emits labels from the parent state and a compact context;\na tuner $\\Psi$ maps $(P, L, C)\\to \\Pi$, with strict schema validation and\ntrust-region projection around safe defaults. Downstream selection remains\nToT-style with score $S=\\mu+\\beta\\sigma$ and depth-annealed $\\beta$. We show\nNLEL strictly generalizes CoT/ToT, prove an anytime-monotonicity property for\ntop-$k$ selection under label-conditioned bundles, and bound selector shortfall\nby control-vector distortion, providing decision-relevant justification for\nguards like trust regions and verification passes. We instantiate $\\Psi$ as a\nprompt-only JSON Parameter Emitter and preregister an evaluation on GSM8K, MATH\n(subset), StrategyQA, and ARC-Challenge with compute-aware reporting\n(success@compute, tokens-per-success) and ablations over $\\Lambda$, $\\Psi$,\ntrust-region radius, and control quantization; preregistered forecasts\nanticipate accuracy gains at comparable token budgets and improved\nsuccess@compute under constraints. NLEL offers an interpretable, model-agnostic\ninterface that separates intent from execution for controllable, auditable LM\ninference.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u81ea\u7136\u8bed\u8a00\u8fb9\u7f18\u6807\u6ce8(NLEL)\u6846\u67b6\uff0c\u901a\u8fc7\u6807\u6ce8\u5668-\u8c03\u8c10\u5668\u8986\u76d6\u5c42\u5c06\u81ea\u7531\u5f62\u5f0f\u7684\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u9644\u52a0\u5230\u641c\u7d22\u8fb9\u7f18\uff0c\u5b9e\u73b0\u7ed3\u6784\u5316\u63a8\u7406\u7684\u53ef\u63a7\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8ba1\u7b97\u6548\u7387\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7ed3\u6784\u5316\u63a8\u7406\u63a7\u5236\u5668(\u5982\u601d\u7ef4\u94fe\u3001\u81ea\u6d3d\u6027\u3001\u601d\u7ef4\u6811)\u5c06\"\u4e0b\u4e00\u6b65\u5c1d\u8bd5\u4ec0\u4e48\"\u4e0e\"\u5982\u4f55\u6267\u884c\"\u8026\u5408\u5728\u4e00\u8d77\uff0c\u53ea\u66b4\u9732\u7c97\u7c92\u5ea6\u7684\u5168\u5c40\u63a7\u5236\u53c2\u6570\uff0c\u5bfc\u81f4\u7cfb\u7edf\u8106\u5f31\u3001\u8ba1\u7b97\u6548\u7387\u4f4e\u4e14\u96be\u4ee5\u5ba1\u8ba1\u3002", "method": "NLEL\u5305\u542b\u6807\u6ce8\u5668\u039b(\u4ece\u7236\u72b6\u6001\u548c\u7d27\u51d1\u4e0a\u4e0b\u6587\u751f\u6210\u6807\u7b7e)\u548c\u8c03\u8c10\u5668\u03a8(\u5c06\u6807\u7b7e\u6620\u5c04\u4e3a\u6a21\u5f0f\u53d7\u9650\u7684\u63a7\u5236\u5411\u91cf)\uff0c\u652f\u6301\u89e3\u7801\u3001\u641c\u7d22\u3001\u751f\u6210\u675f\u5927\u5c0f\u3001\u68c0\u7d22\u6df7\u5408\u548c\u9a8c\u8bc1\u901a\u9053\u7684\u7ec6\u7c92\u5ea6\u63a7\u5236\u3002", "result": "\u7406\u8bba\u8bc1\u660eNLEL\u4e25\u683c\u6cdb\u5316\u4e86CoT/ToT\u65b9\u6cd5\uff0c\u5177\u6709\u4efb\u610f\u65f6\u95f4\u5355\u8c03\u6027\uff0c\u5e76\u901a\u8fc7\u63a7\u5236\u5411\u91cf\u5931\u771f\u9650\u5236\u9009\u62e9\u5668\u4e0d\u8db3\uff0c\u4e3a\u4fe1\u4efb\u533a\u57df\u548c\u9a8c\u8bc1\u901a\u9053\u7b49\u4fdd\u62a4\u63aa\u65bd\u63d0\u4f9b\u51b3\u7b56\u4f9d\u636e\u3002", "conclusion": "NLEL\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u89e3\u91ca\u3001\u6a21\u578b\u65e0\u5173\u7684\u63a5\u53e3\uff0c\u5c06\u610f\u56fe\u4e0e\u6267\u884c\u5206\u79bb\uff0c\u5b9e\u73b0\u53ef\u63a7\u3001\u53ef\u5ba1\u8ba1\u7684\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u3002"}}
{"id": "2510.04551", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.04551", "abs": "https://arxiv.org/abs/2510.04551", "authors": ["Mario Almagro", "Diego Ortego", "David Jimenez"], "title": "Fine-grained auxiliary learning for real-world product recommendation", "comment": "SEPLN 2025", "summary": "Product recommendation is the task of recovering the closest items to a given\nquery within a large product corpora. Generally, one can determine if\ntop-ranked products are related to the query by applying a similarity\nthreshold; exceeding it deems the product relevant, otherwise manual revision\nis required. Despite being a well-known problem, the integration of these\nmodels in real-world systems is often overlooked. In particular, production\nsystems have strong coverage requirements, i.e., a high proportion of\nrecommendations must be automated. In this paper we propose ALC , an Auxiliary\nLearning strategy that boosts Coverage through learning fine-grained\nembeddings. Concretely, we introduce two training objectives that leverage the\nhardest negatives in the batch to build discriminative training signals between\npositives and negatives. We validate ALC using three extreme multi-label\nclassification approaches in two product recommendation datasets;\nLF-AmazonTitles-131K and Tech and Durables (proprietary), demonstrating\nstate-of-the-art coverage rates when combined with a recent\nthreshold-consistent margin loss.", "AI": {"tldr": "\u63d0\u51faALC\u8f85\u52a9\u5b66\u4e60\u7b56\u7565\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5d4c\u5165\u63d0\u5347\u4ea7\u54c1\u63a8\u8350\u7cfb\u7edf\u7684\u8986\u76d6\u7387\uff0c\u7ed3\u5408\u786c\u8d1f\u6837\u672c\u8bad\u7ec3\u76ee\u6807\u548c\u9608\u503c\u4e00\u81f4\u6027\u8fb9\u754c\u635f\u5931\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u8986\u76d6\u7387\u8868\u73b0", "motivation": "\u73b0\u5b9e\u751f\u4ea7\u7cfb\u7edf\u5bf9\u8986\u76d6\u7387\u6709\u4e25\u683c\u8981\u6c42\uff0c\u9700\u8981\u9ad8\u6bd4\u4f8b\u7684\u81ea\u52a8\u5316\u63a8\u8350\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u5728\u771f\u5b9e\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u5e38\u88ab\u5ffd\u89c6", "method": "\u91c7\u7528\u8f85\u52a9\u5b66\u4e60\u7b56\u7565\uff0c\u5f15\u5165\u4e24\u4e2a\u5229\u7528\u6279\u6b21\u4e2d\u6700\u96be\u8d1f\u6837\u672c\u7684\u8bad\u7ec3\u76ee\u6807\uff0c\u6784\u5efa\u6b63\u8d1f\u6837\u672c\u95f4\u7684\u5224\u522b\u6027\u8bad\u7ec3\u4fe1\u53f7\uff0c\u7ed3\u5408\u4e09\u79cd\u6781\u7aef\u591a\u6807\u7b7e\u5206\u7c7b\u65b9\u6cd5\u548c\u9608\u503c\u4e00\u81f4\u6027\u8fb9\u754c\u635f\u5931", "result": "\u5728\u4e24\u4e2a\u4ea7\u54c1\u63a8\u8350\u6570\u636e\u96c6\uff08LF-AmazonTitles-131K\u548cTech and Durables\uff09\u4e0a\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u6700\u5148\u8fdb\u7684\u8986\u76d6\u7387\u8868\u73b0", "conclusion": "ALC\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u4ea7\u54c1\u63a8\u8350\u7cfb\u7edf\u7684\u81ea\u52a8\u5316\u8986\u76d6\u7387\uff0c\u6ee1\u8db3\u751f\u4ea7\u7cfb\u7edf\u7684\u5b9e\u9645\u9700\u6c42"}}
{"id": "2510.04851", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.04851", "abs": "https://arxiv.org/abs/2510.04851", "authors": ["Dongge Han", "Camille Couturier", "Daniel Madrigal Diaz", "Xuchao Zhang", "Victor R\u00fchle", "Saravan Rajmohan"], "title": "LEGOMem: Modular Procedural Memory for Multi-agent LLM Systems for Workflow Automation", "comment": null, "summary": "We introduce LEGOMem, a modular procedural memory framework for multi-agent\nlarge language model (LLM) systems in workflow automation. LEGOMem decomposes\npast task trajectories into reusable memory units and flexibly allocates them\nacross orchestrators and task agents to support planning and execution. To\nexplore the design space of memory in multi-agent systems, we use LEGOMem as a\nlens and conduct a systematic study of procedural memory in multi-agent\nsystems, examining where memory should be placed, how it should be retrieved,\nand which agents benefit most. Experiments on the OfficeBench benchmark show\nthat orchestrator memory is critical for effective task decomposition and\ndelegation, while fine-grained agent memory improves execution accuracy. We\nfind that even teams composed of smaller language models can benefit\nsubstantially from procedural memory, narrowing the performance gap with\nstronger agents by leveraging prior execution traces for more accurate planning\nand tool use. These results position LEGOMem as both a practical framework for\nmemory-augmented agent systems and a research tool for understanding memory\ndesign in multi-agent workflow automation.", "AI": {"tldr": "LEGOMem\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u7684\u6a21\u5757\u5316\u8fc7\u7a0b\u8bb0\u5fc6\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u5386\u53f2\u4efb\u52a1\u8f68\u8ff9\u4e3a\u53ef\u91cd\u7528\u8bb0\u5fc6\u5355\u5143\uff0c\u652f\u6301\u89c4\u5212\u4e0e\u6267\u884c\u3002", "motivation": "\u63a2\u7d22\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u8bb0\u5fc6\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u7814\u7a76\u8bb0\u5fc6\u5e94\u8be5\u653e\u5728\u54ea\u91cc\u3001\u5982\u4f55\u68c0\u7d22\u4ee5\u53ca\u54ea\u4e9b\u667a\u80fd\u4f53\u53d7\u76ca\u6700\u591a\u3002", "method": "\u5c06\u8fc7\u53bb\u4efb\u52a1\u8f68\u8ff9\u5206\u89e3\u4e3a\u53ef\u91cd\u7528\u8bb0\u5fc6\u5355\u5143\uff0c\u7075\u6d3b\u5206\u914d\u7ed9\u7f16\u6392\u5668\u548c\u4efb\u52a1\u667a\u80fd\u4f53\uff0c\u652f\u6301\u89c4\u5212\u548c\u6267\u884c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u7f16\u6392\u5668\u8bb0\u5fc6\u5bf9\u4efb\u52a1\u5206\u89e3\u548c\u59d4\u6d3e\u81f3\u5173\u91cd\u8981\uff0c\u7ec6\u7c92\u5ea6\u667a\u80fd\u4f53\u8bb0\u5fc6\u63d0\u9ad8\u6267\u884c\u51c6\u786e\u6027\uff0c\u8f83\u5c0f\u6a21\u578b\u56e2\u961f\u4e5f\u80fd\u663e\u8457\u53d7\u76ca\u3002", "conclusion": "LEGOMem\u65e2\u662f\u8bb0\u5fc6\u589e\u5f3a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5b9e\u7528\u6846\u67b6\uff0c\u4e5f\u662f\u7406\u89e3\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u4e2d\u8bb0\u5fc6\u8bbe\u8ba1\u7684\u7814\u7a76\u5de5\u5177\u3002"}}
{"id": "2510.04581", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04581", "abs": "https://arxiv.org/abs/2510.04581", "authors": ["Dang Anh", "Rick Nouwen", "Massimo Poesio"], "title": "Can LLMs Detect Ambiguous Plural Reference? An Analysis of Split-Antecedent and Mereological Reference", "comment": null, "summary": "Our goal is to study how LLMs represent and interpret plural reference in\nambiguous and unambiguous contexts. We ask the following research questions:\n(1) Do LLMs exhibit human-like preferences in representing plural reference?\n(2) Are LLMs able to detect ambiguity in plural anaphoric expressions and\nidentify possible referents? To address these questions, we design a set of\nexperiments, examining pronoun production using next-token prediction tasks,\npronoun interpretation, and ambiguity detection using different prompting\nstrategies. We then assess how comparable LLMs are to humans in formulating and\ninterpreting plural reference. We find that LLMs are sometimes aware of\npossible referents of ambiguous pronouns. However, they do not always follow\nhuman reference when choosing between interpretations, especially when the\npossible interpretation is not explicitly mentioned. In addition, they struggle\nto identify ambiguity without direct instruction. Our findings also reveal\ninconsistencies in the results across different types of experiments.", "AI": {"tldr": "LLMs\u5728\u8868\u793a\u548c\u89e3\u91ca\u590d\u6570\u6307\u4ee3\u65b9\u9762\u4e0e\u4eba\u7c7b\u5b58\u5728\u5dee\u5f02\uff0c\u867d\u7136\u6709\u65f6\u80fd\u8bc6\u522b\u6a21\u7cca\u4ee3\u8bcd\u7684\u6f5c\u5728\u6307\u4ee3\u5bf9\u8c61\uff0c\u4f46\u5728\u9009\u62e9\u89e3\u91ca\u65f6\u5e76\u4e0d\u603b\u662f\u9075\u5faa\u4eba\u7c7b\u504f\u597d\uff0c\u7279\u522b\u662f\u5728\u672a\u660e\u786e\u63d0\u53ca\u7684\u60c5\u51b5\u4e0b\uff0c\u4e14\u96be\u4ee5\u5728\u6ca1\u6709\u76f4\u63a5\u6307\u4ee4\u65f6\u8bc6\u522b\u6a21\u7cca\u6027\u3002", "motivation": "\u7814\u7a76LLMs\u5982\u4f55\u8868\u793a\u548c\u89e3\u91ca\u6a21\u7cca\u4e0e\u660e\u786e\u8bed\u5883\u4e2d\u7684\u590d\u6570\u6307\u4ee3\uff0c\u63a2\u7a76LLMs\u662f\u5426\u5177\u6709\u7c7b\u4f3c\u4eba\u7c7b\u7684\u6307\u4ee3\u504f\u597d\uff0c\u4ee5\u53ca\u80fd\u5426\u68c0\u6d4b\u590d\u6570\u7167\u5e94\u8868\u8fbe\u7684\u6a21\u7cca\u6027\u5e76\u8bc6\u522b\u53ef\u80fd\u7684\u6307\u4ee3\u5bf9\u8c61\u3002", "method": "\u8bbe\u8ba1\u4e00\u7cfb\u5217\u5b9e\u9a8c\uff0c\u5305\u62ec\u4f7f\u7528\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\u4efb\u52a1\u7684\u4ee3\u8bcd\u751f\u6210\u3001\u4ee3\u8bcd\u89e3\u91ca\uff0c\u4ee5\u53ca\u91c7\u7528\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u7684\u6a21\u7cca\u6027\u68c0\u6d4b\u3002", "result": "LLMs\u6709\u65f6\u80fd\u8bc6\u522b\u6a21\u7cca\u4ee3\u8bcd\u7684\u6f5c\u5728\u6307\u4ee3\u5bf9\u8c61\uff0c\u4f46\u5728\u9009\u62e9\u89e3\u91ca\u65f6\u5e76\u4e0d\u603b\u662f\u9075\u5faa\u4eba\u7c7b\u53c2\u8003\uff0c\u7279\u522b\u662f\u5f53\u53ef\u80fd\u7684\u89e3\u91ca\u672a\u88ab\u660e\u786e\u63d0\u53ca\u65f6\u3002\u6b64\u5916\uff0c\u5b83\u4eec\u5728\u6ca1\u6709\u76f4\u63a5\u6307\u4ee4\u65f6\u96be\u4ee5\u8bc6\u522b\u6a21\u7cca\u6027\uff0c\u4e14\u4e0d\u540c\u7c7b\u578b\u5b9e\u9a8c\u7684\u7ed3\u679c\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\u3002", "conclusion": "LLMs\u5728\u590d\u6570\u6307\u4ee3\u5904\u7406\u65b9\u9762\u4e0e\u4eba\u7c7b\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u8868\u73b0\u51fa\u4e0d\u4e00\u81f4\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u7279\u522b\u662f\u5728\u6a21\u7cca\u6027\u8bc6\u522b\u548c\u6307\u4ee3\u504f\u597d\u9009\u62e9\u65b9\u9762\u3002"}}
{"id": "2510.04862", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.04862", "abs": "https://arxiv.org/abs/2510.04862", "authors": ["Sam Earle", "Zehua Jiang", "Eugene Vinitsky", "Julian Togelius"], "title": "Video Game Level Design as a Multi-Agent Reinforcement Learning Problem", "comment": "11 pages, 7 tables, 5 figures, published as full technical paper at\n  the AAAI conference on Artificial Intelligence and Interactive Digital\n  Entertainment 2025", "summary": "Procedural Content Generation via Reinforcement Learning (PCGRL) offers a\nmethod for training controllable level designer agents without the need for\nhuman datasets, using metrics that serve as proxies for level quality as\nrewards. Existing PCGRL research focuses on single generator agents, but are\nbottlenecked by the need to frequently recalculate heuristics of level quality\nand the agent's need to navigate around potentially large maps. By framing\nlevel generation as a multi-agent problem, we mitigate the efficiency\nbottleneck of single-agent PCGRL by reducing the number of reward calculations\nrelative to the number of agent actions. We also find that multi-agent level\ngenerators are better able to generalize to out-of-distribution map shapes,\nwhich we argue is due to the generators' learning more local, modular design\npolicies. We conclude that treating content generation as a distributed,\nmulti-agent task is beneficial for generating functional artifacts at scale.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u7a0b\u5e8f\u5316\u5185\u5bb9\u751f\u6210\u91cd\u65b0\u6846\u67b6\u4e3a\u591a\u667a\u80fd\u4f53\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u65b9\u6cd5\u89e3\u51b3\u5355\u667a\u80fd\u4f53PCGRL\u7684\u6548\u7387\u74f6\u9888\u548c\u6cdb\u5316\u80fd\u529b\u9650\u5236\u3002", "motivation": "\u73b0\u6709PCGRL\u7814\u7a76\u805a\u7126\u4e8e\u5355\u667a\u80fd\u4f53\u751f\u6210\u5668\uff0c\u4f46\u9762\u4e34\u9891\u7e41\u91cd\u65b0\u8ba1\u7b97\u542f\u53d1\u5f0f\u8d28\u91cf\u6307\u6807\u548c\u5728\u5927\u578b\u5730\u56fe\u4e2d\u5bfc\u822a\u7684\u6548\u7387\u74f6\u9888\u95ee\u9898\u3002", "method": "\u5c06\u5173\u5361\u751f\u6210\u91cd\u65b0\u5b9a\u4e49\u4e3a\u591a\u667a\u80fd\u4f53\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u667a\u80fd\u4f53\u51cf\u5c11\u5956\u52b1\u8ba1\u7b97\u6b21\u6570\uff0c\u4f7f\u667a\u80fd\u4f53\u5b66\u4e60\u66f4\u5c40\u90e8\u3001\u6a21\u5757\u5316\u7684\u8bbe\u8ba1\u7b56\u7565\u3002", "result": "\u591a\u667a\u80fd\u4f53\u5173\u5361\u751f\u6210\u5668\u5728\u5956\u52b1\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u4e14\u80fd\u66f4\u597d\u5730\u6cdb\u5316\u5230\u5206\u5e03\u5916\u5730\u56fe\u5f62\u72b6\u3002", "conclusion": "\u5c06\u5185\u5bb9\u751f\u6210\u89c6\u4e3a\u5206\u5e03\u5f0f\u591a\u667a\u80fd\u4f53\u4efb\u52a1\u6709\u5229\u4e8e\u5927\u89c4\u6a21\u751f\u6210\u529f\u80fd\u6027\u5185\u5bb9\u3002"}}
{"id": "2510.04584", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.04584", "abs": "https://arxiv.org/abs/2510.04584", "authors": ["Fernando L\u00f3pez", "Santosh Kesiraju", "Jordi Luque"], "title": "Robustness assessment of large audio language models in multiple-choice evaluation", "comment": "Submitted to ICASSP 2026", "summary": "Recent advances in large audio language models (LALMs) have primarily been\nassessed using a multiple-choice question answering (MCQA) framework. However,\nsubtle changes, such as shifting the order of choices, result in substantially\ndifferent results. Existing MCQA frameworks do not account for this variability\nand report a single accuracy number per benchmark or category. We dive into the\nMCQA evaluation framework and conduct a systematic study spanning three\nbenchmarks (MMAU, MMAR and MMSU) and four models: Audio Flamingo 2, Audio\nFlamingo 3, Qwen2.5-Omni-7B-Instruct, and Kimi-Audio-7B-Instruct. Our findings\nindicate that models are sensitive not only to the ordering of choices, but\nalso to the paraphrasing of the question and the choices. Finally, we propose a\nsimpler evaluation protocol and metric that account for subtle variations and\nprovide a more detailed evaluation report of LALMs within the MCQA framework.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u5728\u591a\u9879\u9009\u62e9\u9898\u8bc4\u4f30\u4e2d\u5bf9\u9009\u9879\u987a\u5e8f\u3001\u95ee\u9898\u8868\u8ff0\u548c\u9009\u9879\u6539\u5199\u90fd\u5f88\u654f\u611f\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u8bc4\u4f30\u534f\u8bae\u548c\u6307\u6807\u6765\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709MCQA\u8bc4\u4f30\u6846\u67b6\u53ea\u62a5\u544a\u5355\u4e00\u51c6\u786e\u7387\uff0c\u5ffd\u7565\u4e86\u9009\u9879\u987a\u5e8f\u53d8\u5316\u7b49\u56e0\u7d20\u5bfc\u81f4\u7684\u663e\u8457\u7ed3\u679c\u5dee\u5f02\uff0c\u9700\u8981\u66f4\u7ec6\u81f4\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5bf9\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5(MMAU\u3001MMAR\u3001MMSU)\u548c\u56db\u4e2a\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u7814\u7a76\uff0c\u5206\u6790\u9009\u9879\u987a\u5e8f\u3001\u95ee\u9898\u6539\u5199\u548c\u9009\u9879\u6539\u5199\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "result": "\u6a21\u578b\u5bf9\u9009\u9879\u987a\u5e8f\u3001\u95ee\u9898\u8868\u8ff0\u548c\u9009\u9879\u6539\u5199\u90fd\u5f88\u654f\u611f\uff0c\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u8fd9\u4e9b\u7ec6\u5fae\u53d8\u5316\u5e26\u6765\u7684\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "\u63d0\u51fa\u4e86\u66f4\u7b80\u5355\u7684\u8bc4\u4f30\u534f\u8bae\u548c\u6307\u6807\uff0c\u80fd\u591f\u8003\u8651\u7ec6\u5fae\u53d8\u5316\u5e76\u63d0\u4f9b\u66f4\u8be6\u7ec6\u7684\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u62a5\u544a\u3002"}}
{"id": "2510.04886", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.04886", "abs": "https://arxiv.org/abs/2510.04886", "authors": ["Adi Banerjee", "Anirudh Nair", "Tarik Borogovac"], "title": "Where Did It All Go Wrong? A Hierarchical Look into Multi-Agent Error Attribution", "comment": null, "summary": "Error attribution in Large Language Model (LLM) multi-agent systems presents\na significant challenge in debugging and improving collaborative AI systems.\nCurrent approaches to pinpointing agent and step level failures in interaction\ntraces - whether using all-at-once evaluation, step-by-step analysis, or binary\nsearch - fall short when analyzing complex patterns, struggling with both\naccuracy and consistency. We present ECHO (Error attribution through Contextual\nHierarchy and Objective consensus analysis), a novel algorithm that combines\nhierarchical context representation, objective analysis-based evaluation, and\nconsensus voting to improve error attribution accuracy. Our approach leverages\na positional-based leveling of contextual understanding while maintaining\nobjective evaluation criteria, ultimately reaching conclusions through a\nconsensus mechanism. Experimental results demonstrate that ECHO outperforms\nexisting methods across various multi-agent interaction scenarios, showing\nparticular strength in cases involving subtle reasoning errors and complex\ninterdependencies. Our findings suggest that leveraging these concepts of\nstructured, hierarchical context representation combined with consensus-based\nobjective decision-making, provides a more robust framework for error\nattribution in multi-agent systems.", "AI": {"tldr": "ECHO\u7b97\u6cd5\u901a\u8fc7\u5206\u5c42\u4e0a\u4e0b\u6587\u8868\u793a\u3001\u57fa\u4e8e\u76ee\u6807\u5206\u6790\u7684\u8bc4\u4f30\u548c\u5171\u8bc6\u6295\u7968\uff0c\u63d0\u9ad8\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u9519\u8bef\u5f52\u56e0\u7684\u51c6\u786e\u6027\uff0c\u5728\u590d\u6742\u63a8\u7406\u9519\u8bef\u548c\u76f8\u4e92\u4f9d\u8d56\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u9519\u8bef\u5f52\u56e0\u65b9\u6cd5\u5728\u5206\u6790\u590d\u6742\u6a21\u5f0f\u65f6\u5b58\u5728\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u8c03\u8bd5\u548c\u6539\u8fdb\u534f\u4f5cAI\u7cfb\u7edf\u7684\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u5206\u5c42\u4e0a\u4e0b\u6587\u8868\u793a\u3001\u57fa\u4e8e\u76ee\u6807\u5206\u6790\u7684\u8bc4\u4f30\u548c\u5171\u8bc6\u6295\u7968\uff0c\u5229\u7528\u57fa\u4e8e\u4f4d\u7f6e\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\u5c42\u7ea7\u5316\uff0c\u540c\u65f6\u4fdd\u6301\u5ba2\u89c2\u8bc4\u4f30\u6807\u51c6\uff0c\u901a\u8fc7\u5171\u8bc6\u673a\u5236\u5f97\u51fa\u7ed3\u8bba\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eECHO\u5728\u5404\u79cd\u591a\u667a\u80fd\u4f53\u4ea4\u4e92\u573a\u666f\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u5904\u7406\u5fae\u5999\u63a8\u7406\u9519\u8bef\u548c\u590d\u6742\u76f8\u4e92\u4f9d\u8d56\u60c5\u51b5\u65f6\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\u3002", "conclusion": "\u7ed3\u6784\u5316\u5206\u5c42\u4e0a\u4e0b\u6587\u8868\u793a\u4e0e\u57fa\u4e8e\u5171\u8bc6\u7684\u5ba2\u89c2\u51b3\u7b56\u76f8\u7ed3\u5408\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u9519\u8bef\u5f52\u56e0\u63d0\u4f9b\u4e86\u66f4\u7a33\u5065\u7684\u6846\u67b6\u3002"}}
{"id": "2510.04601", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04601", "abs": "https://arxiv.org/abs/2510.04601", "authors": ["Guochen Yan", "Luyuan Xie", "Qingni Shen", "Yuejian Fang", "Zhonghai Wu"], "title": "FedSRD: Sparsify-Reconstruct-Decompose for Communication-Efficient Federated Large Language Models Fine-Tuning", "comment": null, "summary": "The current paradigm of training large language models (LLMs) on publicly\navailable Web data is becoming unsustainable, with high-quality data sources in\nspecialized domains nearing exhaustion. Federated Learning (FL) emerges as a\npractical solution for the next generation of AI on a decentralized Web,\nenabling privacy-preserving collaborative fine-tuning by leveraging private\ndata distributed across a global client base. While Low-Rank Adaptation (LoRA)\nis the standard for efficient fine-tuning, its application in federated\nsettings presents a critical challenge: communication overhead remains a\nsignificant bottleneck across the Web's heterogeneous network conditions. The\nstructural redundancy within LoRA parameters not only incurs a heavy\ncommunication burden but also introduces conflicts when aggregating client\nupdates. To address this, we propose FedSRD, a Sparsify-Reconstruct-Decompose\nframework designed for communication-efficient FL. We first introduce an\nimportance-aware sparsification method that preserves the structural integrity\nof LoRA updates to reduce the uploaded parameter count. The server then\nreconstructs and aggregates these updates in a full-rank space to mitigate\nconflicts. Finally, it decomposes the global update into a sparse low-rank\nformat for broadcast, ensuring a symmetrically efficient cycle. We also propose\nan efficient variant, FedSRD-e, to reduce computational overhead. Experimental\nresults on 10 benchmarks demonstrate that our framework significantly reduces\ncommunication costs by up to 90\\% while even improving model performance on\nheterogeneous client data.", "AI": {"tldr": "FedSRD\u662f\u4e00\u4e2a\u7528\u4e8e\u8054\u90a6\u5b66\u4e60\u7684\u901a\u4fe1\u9ad8\u6548\u6846\u67b6\uff0c\u901a\u8fc7\u7a00\u758f\u5316-\u91cd\u6784-\u5206\u89e3\u65b9\u6cd5\u89e3\u51b3LoRA\u5728\u8054\u90a6\u8bbe\u7f6e\u4e2d\u7684\u901a\u4fe1\u74f6\u9888\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u6210\u672c\u540c\u65f6\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5728\u516c\u5f00\u7f51\u7edc\u6570\u636e\u4e0a\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8303\u5f0f\u4e0d\u53ef\u6301\u7eed\uff0c\u9ad8\u8d28\u91cf\u4e13\u4e1a\u9886\u57df\u6570\u636e\u63a5\u8fd1\u67af\u7aed\u3002\u8054\u90a6\u5b66\u4e60\u4f5c\u4e3a\u4e0b\u4e00\u4ee3AI\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u4f46LoRA\u5728\u8054\u90a6\u8bbe\u7f6e\u4e2d\u9762\u4e34\u901a\u4fe1\u5f00\u9500\u5927\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u63d0\u51faFedSRD\u6846\u67b6\uff1a\u91cd\u8981\u6027\u611f\u77e5\u7a00\u758f\u5316\u65b9\u6cd5\u4fdd\u6301LoRA\u66f4\u65b0\u7684\u7ed3\u6784\u5b8c\u6574\u6027\u4ee5\u51cf\u5c11\u4e0a\u4f20\u53c2\u6570\uff1b\u670d\u52a1\u5668\u5728\u5b8c\u6574\u79e9\u7a7a\u95f4\u91cd\u6784\u548c\u805a\u5408\u66f4\u65b0\u4ee5\u7f13\u89e3\u51b2\u7a81\uff1b\u5c06\u5168\u5c40\u66f4\u65b0\u5206\u89e3\u4e3a\u7a00\u758f\u4f4e\u79e9\u683c\u5f0f\u8fdb\u884c\u5e7f\u64ad\u3002\u8fd8\u63d0\u51fa\u4e86\u8ba1\u7b97\u5f00\u9500\u66f4\u4f4e\u7684FedSRD-e\u53d8\u4f53\u3002", "result": "\u572810\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u6210\u672c\u8fbe90%\uff0c\u540c\u65f6\u5728\u5f02\u6784\u5ba2\u6237\u7aef\u6570\u636e\u4e0a\u751a\u81f3\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "FedSRD\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2dLoRA\u7684\u901a\u4fe1\u74f6\u9888\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u901a\u4fe1\u6548\u7387\u4e0e\u6a21\u578b\u6027\u80fd\u7684\u53cc\u91cd\u63d0\u5347\uff0c\u4e3a\u4e0b\u4e00\u4ee3AI\u5728\u53bb\u4e2d\u5fc3\u5316\u7f51\u7edc\u4e0a\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04899", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04899", "abs": "https://arxiv.org/abs/2510.04899", "authors": ["Keane Ong", "Wei Dai", "Carol Li", "Dewei Feng", "Hengzhi Li", "Jingyao Wu", "Jiaee Cheong", "Rui Mao", "Gianmarco Mengaldo", "Erik Cambria", "Paul Pu Liang"], "title": "Human Behavior Atlas: Benchmarking Unified Psychological and Social Behavior Understanding", "comment": null, "summary": "Using intelligent systems to perceive psychological and social behaviors,\nthat is, the underlying affective, cognitive, and pathological states that are\nmanifested through observable behaviors and social interactions, remains a\nchallenge due to their complex, multifaceted, and personalized nature. Existing\nwork tackling these dimensions through specialized datasets and single-task\nsystems often miss opportunities for scalability, cross-task transfer, and\nbroader generalization. To address this gap, we curate Human Behavior Atlas, a\nunified benchmark of diverse behavioral tasks designed to support the\ndevelopment of unified models for understanding psychological and social\nbehaviors. Human Behavior Atlas comprises over 100,000 samples spanning text,\naudio, and visual modalities, covering tasks on affective states, cognitive\nstates, pathologies, and social processes. Our unification efforts can reduce\nredundancy and cost, enable training to scale efficiently across tasks, and\nenhance generalization of behavioral features across domains. On Human Behavior\nAtlas, we train three models: OmniSapiens-7B SFT, OmniSapiens-7B BAM, and\nOmniSapiens-7B RL. We show that training on Human Behavior Atlas enables models\nto consistently outperform existing multimodal LLMs across diverse behavioral\ntasks. Pretraining on Human Behavior Atlas also improves transfer to novel\nbehavioral datasets; with the targeted use of behavioral descriptors yielding\nmeaningful performance gains.", "AI": {"tldr": "Human Behavior Atlas\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u884c\u4e3a\u7406\u89e3\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b10\u4e07+\u591a\u6a21\u6001\u6837\u672c\uff0c\u7528\u4e8e\u8bad\u7ec3\u7edf\u4e00\u6a21\u578b\u6765\u7406\u89e3\u5fc3\u7406\u548c\u793e\u4f1a\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f7f\u7528\u4e13\u95e8\u6570\u636e\u96c6\u548c\u5355\u4efb\u52a1\u7cfb\u7edf\uff0c\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\u3001\u8de8\u4efb\u52a1\u8fc1\u79fb\u548c\u6cdb\u5316\u80fd\u529b\u3002\u9700\u8981\u7edf\u4e00\u57fa\u51c6\u6765\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u6784\u5efaHuman Behavior Atlas\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u6587\u672c\u3001\u97f3\u9891\u3001\u89c6\u89c9\u6a21\u6001\uff0c\u5305\u542b\u60c5\u611f\u72b6\u6001\u3001\u8ba4\u77e5\u72b6\u6001\u3001\u75c5\u7406\u5b66\u548c\u793e\u4f1a\u8fc7\u7a0b\u4efb\u52a1\u3002\u8bad\u7ec3\u4e09\u4e2a\u6a21\u578b\uff1aOmniSapiens-7B SFT\u3001BAM\u548cRL\u3002", "result": "\u5728Human Behavior Atlas\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u591a\u6837\u5316\u884c\u4e3a\u4efb\u52a1\u4e0a\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u591a\u6a21\u6001LLM\u3002\u9884\u8bad\u7ec3\u8fd8\u80fd\u63d0\u9ad8\u5bf9\u65b0\u884c\u4e3a\u6570\u636e\u96c6\u7684\u8fc1\u79fb\u80fd\u529b\u3002", "conclusion": "\u7edf\u4e00\u7684\u884c\u4e3a\u57fa\u51c6\u53ef\u4ee5\u51cf\u5c11\u5197\u4f59\u548c\u6210\u672c\uff0c\u5b9e\u73b0\u8de8\u4efb\u52a1\u9ad8\u6548\u8bad\u7ec3\uff0c\u5e76\u589e\u5f3a\u884c\u4e3a\u7279\u5f81\u5728\u9886\u57df\u95f4\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.04631", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.04631", "abs": "https://arxiv.org/abs/2510.04631", "authors": ["Anastasia Zhukova", "Jonas L\u00fchrs", "Christian E. Matt", "Bela Gipp"], "title": "Contrastive Learning Using Graph Embeddings for Domain Adaptation of Language Models in the Process Industry", "comment": "accepted to EMNLP 2025 (industry track)", "summary": "Recent trends in NLP utilize knowledge graphs (KGs) to enhance pretrained\nlanguage models by incorporating additional knowledge from the graph structures\nto learn domain-specific terminology or relationships between documents that\nmight otherwise be overlooked. This paper explores how SciNCL, a graph-aware\nneighborhood contrastive learning methodology originally designed for\nscientific publications, can be applied to the process industry domain, where\ntext logs contain crucial information about daily operations and are often\nstructured as sparse KGs. Our experiments demonstrate that language models\nfine-tuned with triplets derived from GE outperform a state-of-the-art\nmE5-large text encoder by 9.8-14.3% (5.4-8.0p) on the proprietary process\nindustry text embedding benchmark (PITEB) while being 3-5 times smaller in\nsize.", "AI": {"tldr": "\u5c06SciNCL\u56fe\u611f\u77e5\u90bb\u57df\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u5e94\u7528\u4e8e\u8fc7\u7a0b\u5de5\u4e1a\u9886\u57df\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\uff0c\u5728PITEB\u57fa\u51c6\u4e0a\u6bd4mE5-large\u63d0\u53479.8-14.3%\uff0c\u4e14\u6a21\u578b\u5c3a\u5bf8\u5c0f3-5\u500d", "motivation": "\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u5b66\u4e60\u9886\u57df\u7279\u5b9a\u672f\u8bed\u548c\u6587\u6863\u95f4\u5173\u7cfb\uff0c\u89e3\u51b3\u8fc7\u7a0b\u5de5\u4e1a\u9886\u57df\u6587\u672c\u65e5\u5fd7\u4e2d\u53ef\u80fd\u88ab\u5ffd\u7565\u7684\u5173\u952e\u4fe1\u606f", "method": "\u5e94\u7528SciNCL\u56fe\u611f\u77e5\u90bb\u57df\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ece\u8fc7\u7a0b\u5de5\u4e1a\u9886\u57df\u7684\u7a00\u758f\u77e5\u8bc6\u56fe\u8c31\u4e2d\u63d0\u53d6\u4e09\u5143\u7ec4\u6765\u5fae\u8c03\u8bed\u8a00\u6a21\u578b", "result": "\u5728\u4e13\u6709\u8fc7\u7a0b\u5de5\u4e1a\u6587\u672c\u5d4c\u5165\u57fa\u51c6(PITEB)\u4e0a\uff0c\u6027\u80fd\u6bd4\u6700\u5148\u8fdb\u7684mE5-large\u6587\u672c\u7f16\u7801\u5668\u63d0\u53479.8-14.3%(5.4-8.0\u4e2a\u767e\u5206\u70b9)\uff0c\u540c\u65f6\u6a21\u578b\u5c3a\u5bf8\u5c0f3-5\u500d", "conclusion": "\u56fe\u611f\u77e5\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u5728\u8fc7\u7a0b\u5de5\u4e1a\u9886\u57df\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u80fd\u591f\u6709\u6548\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u7ed3\u6784\u63d0\u5347\u6587\u672c\u5d4c\u5165\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u5c0f\u7684\u6a21\u578b\u5c3a\u5bf8"}}
{"id": "2510.04935", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04935", "abs": "https://arxiv.org/abs/2510.04935", "authors": ["Guoxin Chen", "Zile Qiao", "Wenqing Wang", "Donglei Yu", "Xuanzhong Chen", "Hao Sun", "Minpeng Liao", "Kai Fan", "Yong Jiang", "Penguin Xie", "Wayne Xin Zhao", "Ruihua Song", "Fei Huang"], "title": "MARS: Optimizing Dual-System Deep Research via Multi-Agent Reinforcement Learning", "comment": "Ongoing Work", "summary": "Large Reasoning Models (LRMs) often exhibit a tendency for overanalysis in\nsimple tasks, where the models excessively utilize System 2-type, deliberate\nreasoning, leading to inefficient token generation. Furthermore, these models\nface challenges in adapting their reasoning capabilities to rapidly changing\nenvironments due to the static nature of their pretraining data. To address\nthese issues, advancing Large Language Models (LLMs) for complex reasoning\ntasks requires innovative approaches that bridge intuitive and deliberate\ncognitive processes, akin to human cognition's dual-system dynamic. This paper\nintroduces a Multi-Agent System for Deep ReSearch (MARS) enabling seamless\nintegration of System 1's fast, intuitive thinking with System 2's deliberate\nreasoning within LLMs. MARS strategically integrates multiple external tools,\nsuch as Google Search, Google Scholar, and Python Interpreter, to access\nup-to-date information and execute complex computations, while creating a\nspecialized division of labor where System 1 efficiently processes and\nsummarizes high-volume external information, providing distilled insights that\nexpand System 2's reasoning context without overwhelming its capacity.\nFurthermore, we propose a multi-agent reinforcement learning framework\nextending Group Relative Policy Optimization to simultaneously optimize both\nsystems with multi-turn tool interactions, bin-packing optimization, and sample\nbalancing strategies that enhance collaborative efficiency. Extensive\nexperiments demonstrate MARS achieves substantial improvements of 3.86% on the\nchallenging Humanity's Last Exam (HLE) benchmark and an average gain of 8.9%\nacross 7 knowledge-intensive tasks, validating the effectiveness of our\ndual-system paradigm for complex reasoning in dynamic information environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMARS\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408System 1\u7684\u5feb\u901f\u76f4\u89c9\u601d\u7ef4\u548cSystem 2\u7684\u6df1\u601d\u719f\u8651\u63a8\u7406\uff0c\u89e3\u51b3\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u7b80\u5355\u4efb\u52a1\u4e2d\u8fc7\u5ea6\u5206\u6790\u3001\u5728\u52a8\u6001\u73af\u5883\u4e2d\u9002\u5e94\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u7b80\u5355\u4efb\u52a1\u4e2d\u503e\u5411\u4e8e\u8fc7\u5ea6\u4f7f\u7528System 2\u578b\u63a8\u7406\uff0c\u5bfc\u81f4token\u751f\u6210\u6548\u7387\u4f4e\u4e0b\uff0c\u4e14\u7531\u4e8e\u9884\u8bad\u7ec3\u6570\u636e\u7684\u9759\u6001\u6027\u96be\u4ee5\u9002\u5e94\u5feb\u901f\u53d8\u5316\u7684\u73af\u5883\u3002\u9700\u8981\u521b\u65b0\u65b9\u6cd5\u6865\u63a5\u76f4\u89c9\u548c\u6df1\u601d\u719f\u8651\u7684\u8ba4\u77e5\u8fc7\u7a0b\u3002", "method": "\u63d0\u51faMARS\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u6574\u5408Google\u641c\u7d22\u3001Google\u5b66\u672f\u3001Python\u89e3\u91ca\u5668\u7b49\u5916\u90e8\u5de5\u5177\uff0c\u901a\u8fc7\u5206\u5de5\u534f\u4f5c\u8ba9System 1\u9ad8\u6548\u5904\u7406\u5916\u90e8\u4fe1\u606f\uff0c\u4e3aSystem 2\u63d0\u4f9b\u7cbe\u70bc\u89c1\u89e3\u3002\u91c7\u7528\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4f18\u5316\u4e24\u4e2a\u7cfb\u7edf\u7684\u534f\u4f5c\u6548\u7387\u3002", "result": "\u5728\u6311\u6218\u6027\u57fa\u51c6HLE\u4e0a\u53d6\u5f973.86%\u7684\u663e\u8457\u63d0\u5347\uff0c\u57287\u4e2a\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u5e73\u5747\u589e\u76ca8.9%\uff0c\u9a8c\u8bc1\u4e86\u53cc\u7cfb\u7edf\u8303\u5f0f\u5728\u52a8\u6001\u4fe1\u606f\u73af\u5883\u4e2d\u590d\u6742\u63a8\u7406\u7684\u6709\u6548\u6027\u3002", "conclusion": "MARS\u901a\u8fc7\u53cc\u7cfb\u7edf\u534f\u4f5c\u548c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u8ba4\u77e5\u8ba1\u7b97\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2510.04641", "categories": ["cs.CL", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04641", "abs": "https://arxiv.org/abs/2510.04641", "authors": ["Ayan Majumdar", "Feihao Chen", "Jinghui Li", "Xiaozhen Wang"], "title": "Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study", "comment": "17 pages, 7 figures, 7 tables", "summary": "Large-scale web-scraped text corpora used to train general-purpose AI models\noften contain harmful demographic-targeted social biases, creating a regulatory\nneed for data auditing and developing scalable bias-detection methods. Although\nprior work has investigated biases in text datasets and related detection\nmethods, these studies remain narrow in scope. They typically focus on a single\ncontent type (e.g., hate speech), cover limited demographic axes, overlook\nbiases affecting multiple demographics simultaneously, and analyze limited\ntechniques. Consequently, practitioners lack a holistic understanding of the\nstrengths and limitations of recent large language models (LLMs) for automated\nbias detection. In this study, we present a comprehensive evaluation framework\naimed at English texts to assess the ability of LLMs in detecting\ndemographic-targeted social biases. To align with regulatory requirements, we\nframe bias detection as a multi-label task using a demographic-focused\ntaxonomy. We then conduct a systematic evaluation with models across scales and\ntechniques, including prompting, in-context learning, and fine-tuning. Using\ntwelve datasets spanning diverse content types and demographics, our study\ndemonstrates the promise of fine-tuned smaller models for scalable detection.\nHowever, our analyses also expose persistent gaps across demographic axes and\nmulti-demographic targeted biases, underscoring the need for more effective and\nscalable auditing frameworks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4b\u9488\u5bf9\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u7684\u793e\u4f1a\u504f\u89c1\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5fae\u8c03\u7684\u5c0f\u578b\u6a21\u578b\u5728\u53ef\u6269\u5c55\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u591a\u4eba\u53e3\u7edf\u8ba1\u504f\u89c1\u68c0\u6d4b\u65b9\u9762\u4ecd\u5b58\u5728\u5dee\u8ddd\u3002", "motivation": "\u5927\u89c4\u6a21\u7f51\u7edc\u722c\u53d6\u7684\u6587\u672c\u8bed\u6599\u5e93\u901a\u5e38\u5305\u542b\u6709\u5bb3\u7684\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u9488\u5bf9\u6027\u793e\u4f1a\u504f\u89c1\uff0c\u9700\u8981\u6570\u636e\u5ba1\u8ba1\u548c\u53ef\u6269\u5c55\u7684\u504f\u89c1\u68c0\u6d4b\u65b9\u6cd5\u3002\u73b0\u6709\u7814\u7a76\u8303\u56f4\u72ed\u7a84\uff0c\u7f3a\u4e4f\u5bf9LLMs\u81ea\u52a8\u504f\u89c1\u68c0\u6d4b\u80fd\u529b\u7684\u5168\u9762\u7406\u89e3\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u9488\u5bf9\u82f1\u8bed\u6587\u672c\u7684\u5168\u9762\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u504f\u89c1\u68c0\u6d4b\u5b9a\u4e49\u4e3a\u591a\u6807\u7b7e\u4efb\u52a1\uff0c\u4f7f\u7528\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u5bfc\u5411\u7684\u5206\u7c7b\u6cd5\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4e0d\u540c\u89c4\u6a21\u548c\u6280\u672f\u7684\u6a21\u578b\uff0c\u5305\u62ec\u63d0\u793a\u3001\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u5fae\u8c03\u3002", "result": "\u4f7f\u752812\u4e2a\u6db5\u76d6\u4e0d\u540c\u5185\u5bb9\u7c7b\u578b\u548c\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u7684\u6570\u636e\u96c6\uff0c\u7814\u7a76\u8868\u660e\u5fae\u8c03\u7684\u5c0f\u578b\u6a21\u578b\u5728\u53ef\u6269\u5c55\u68c0\u6d4b\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5206\u6790\u4e5f\u63ed\u793a\u4e86\u8de8\u4eba\u53e3\u7edf\u8ba1\u8f74\u548c\u591a\u4eba\u53e3\u7edf\u8ba1\u9488\u5bf9\u6027\u504f\u89c1\u7684\u6301\u7eed\u5dee\u8ddd\u3002", "conclusion": "\u9700\u8981\u66f4\u6709\u6548\u548c\u53ef\u6269\u5c55\u7684\u5ba1\u8ba1\u6846\u67b6\u6765\u89e3\u51b3\u504f\u89c1\u68c0\u6d4b\u4e2d\u7684\u73b0\u6709\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u591a\u4eba\u53e3\u7edf\u8ba1\u9488\u5bf9\u6027\u504f\u89c1\u65b9\u9762\u3002"}}
{"id": "2510.04952", "categories": ["cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.04952", "abs": "https://arxiv.org/abs/2510.04952", "authors": ["Ailiya Borjigin", "Cong He"], "title": "Safe and Compliant Cross-Market Trade Execution via Constrained RL and Zero-Knowledge Audits", "comment": "22 pages, 2 figures", "summary": "We present a cross-market algorithmic trading system that balances execution\nquality with rigorous compliance enforcement. The architecture comprises a\nhigh-level planner, a reinforcement learning execution agent, and an\nindependent compliance agent. We formulate trade execution as a constrained\nMarkov decision process with hard constraints on participation limits, price\nbands, and self-trading avoidance. The execution agent is trained with proximal\npolicy optimization, while a runtime action-shield projects any unsafe action\ninto a feasible set. To support auditability without exposing proprietary\nsignals, we add a zero-knowledge compliance audit layer that produces\ncryptographic proofs that all actions satisfied the constraints. We evaluate in\na multi-venue, ABIDES-based simulator and compare against standard baselines\n(e.g., TWAP, VWAP). The learned policy reduces implementation shortfall and\nvariance while exhibiting no observed constraint violations across stress\nscenarios including elevated latency, partial fills, compliance module\ntoggling, and varying constraint limits. We report effects at the 95%\nconfidence level using paired t-tests and examine tail risk via CVaR. We\nsituate the work at the intersection of optimal execution, safe reinforcement\nlearning, regulatory technology, and verifiable AI, and discuss ethical\nconsiderations, limitations (e.g., modeling assumptions and computational\noverhead), and paths to real-world deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8de8\u5e02\u573a\u7b97\u6cd5\u4ea4\u6613\u7cfb\u7edf\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u6267\u884c\u4ee3\u7406\u548c\u72ec\u7acb\u5408\u89c4\u4ee3\u7406\uff0c\u5728\u4fdd\u8bc1\u6267\u884c\u8d28\u91cf\u7684\u540c\u65f6\u4e25\u683c\u5b9e\u65bd\u5408\u89c4\u7ea6\u675f\uff0c\u5e76\u901a\u8fc7\u96f6\u77e5\u8bc6\u8bc1\u660e\u5b9e\u73b0\u53ef\u5ba1\u8ba1\u6027\u3002", "motivation": "\u73b0\u6709\u7b97\u6cd5\u4ea4\u6613\u7cfb\u7edf\u96be\u4ee5\u5728\u8ffd\u6c42\u6267\u884c\u8d28\u91cf\u7684\u540c\u65f6\u786e\u4fdd\u4e25\u683c\u7684\u5408\u89c4\u7ea6\u675f\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4f18\u5316\u4ea4\u6613\u6267\u884c\u53c8\u80fd\u4fdd\u8bc1\u76d1\u7ba1\u5408\u89c4\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5c06\u4ea4\u6613\u6267\u884c\u4e3a\u7ea6\u675f\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u8bad\u7ec3\u6267\u884c\u4ee3\u7406\uff0c\u8fd0\u884c\u65f6\u52a8\u4f5c\u5c4f\u853d\u786e\u4fdd\u884c\u52a8\u53ef\u884c\u6027\uff0c\u5e76\u6dfb\u52a0\u96f6\u77e5\u8bc6\u5408\u89c4\u5ba1\u8ba1\u5c42\u751f\u6210\u52a0\u5bc6\u8bc1\u660e\u3002", "result": "\u5b66\u4e60\u7b56\u7565\u5728ABIDES\u6a21\u62df\u5668\u4e2d\u51cf\u5c11\u4e86\u6267\u884c\u5dee\u989d\u548c\u65b9\u5dee\uff0c\u5728\u538b\u529b\u6d4b\u8bd5\u573a\u666f\u4e0b\u672a\u89c2\u5bdf\u5230\u7ea6\u675f\u8fdd\u89c4\uff0c\u572895%\u7f6e\u4fe1\u6c34\u5e73\u4e0b\u6548\u679c\u663e\u8457\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u878d\u5408\u4e86\u6700\u4f18\u6267\u884c\u3001\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u3001\u76d1\u7ba1\u6280\u672f\u548c\u53ef\u9a8c\u8bc1AI\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\uff0c\u540c\u65f6\u8ba8\u8bba\u4e86\u4f26\u7406\u8003\u91cf\u548c\u5c40\u9650\u6027\u3002"}}
{"id": "2510.04655", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04655", "abs": "https://arxiv.org/abs/2510.04655", "authors": ["Yuheng Li", "Jiechao Gao", "Wei Han", "Wenwen Ouyang", "Wei Zhu", "Hui Yi Leong"], "title": "FT-MDT: Extracting Decision Trees from Medical Texts via a Novel Low-rank Adaptation Method", "comment": "Accepted by EMNLP-2025 Industrial Track", "summary": "Knowledge of the medical decision process, which can be modeled as medical\ndecision trees (MDTs), is critical to building clinical decision support\nsystems. However, current MDT construction methods rely heavily on\ntime-consuming and laborious manual annotation. To address this challenge, we\npropose PI-LoRA (Path-Integrated LoRA), a novel low-rank adaptation method for\nautomatically extracting MDTs from clinical guidelines and textbooks. We\nintegrate gradient path information to capture synergistic effects between\ndifferent modules, enabling more effective and reliable rank allocation. This\nframework ensures that the most critical modules receive appropriate rank\nallocations while less important ones are pruned, resulting in a more efficient\nand accurate model for extracting medical decision trees from clinical texts.\nExtensive experiments on medical guideline datasets demonstrate that our\nPI-LoRA method significantly outperforms existing parameter-efficient\nfine-tuning approaches for the Text2MDT task, achieving better accuracy with\nsubstantially reduced model complexity. The proposed method achieves\nstate-of-the-art results while maintaining a lightweight architecture, making\nit particularly suitable for clinical decision support systems where\ncomputational resources may be limited.", "AI": {"tldr": "PI-LoRA\u662f\u4e00\u79cd\u65b0\u9896\u7684\u4f4e\u79e9\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u4e34\u5e8a\u6307\u5357\u548c\u6559\u79d1\u4e66\u4e2d\u81ea\u52a8\u63d0\u53d6\u533b\u7597\u51b3\u7b56\u6811\uff0c\u901a\u8fc7\u96c6\u6210\u68af\u5ea6\u8def\u5f84\u4fe1\u606f\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u79e9\u5206\u914d\uff0c\u5728\u4fdd\u6301\u8f7b\u91cf\u7ea7\u67b6\u6784\u7684\u540c\u65f6\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u533b\u7597\u51b3\u7b56\u6811\u6784\u5efa\u65b9\u6cd5\u4e25\u91cd\u4f9d\u8d56\u8017\u65f6\u8d39\u529b\u7684\u624b\u52a8\u6807\u6ce8\uff0c\u9700\u8981\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u4ece\u4e34\u5e8a\u6587\u672c\u4e2d\u63d0\u53d6\u533b\u7597\u51b3\u7b56\u8fc7\u7a0b\u77e5\u8bc6\u3002", "method": "\u63d0\u51faPI-LoRA\uff08\u8def\u5f84\u96c6\u6210LoRA\uff09\u65b9\u6cd5\uff0c\u96c6\u6210\u68af\u5ea6\u8def\u5f84\u4fe1\u606f\u6765\u6355\u6349\u4e0d\u540c\u6a21\u5757\u95f4\u7684\u534f\u540c\u6548\u5e94\uff0c\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u79e9\u5206\u914d\uff0c\u5173\u952e\u6a21\u5757\u83b7\u5f97\u9002\u5f53\u79e9\u5206\u914d\uff0c\u4e0d\u91cd\u8981\u6a21\u5757\u88ab\u526a\u679d\u3002", "result": "\u5728\u533b\u7597\u6307\u5357\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPI-LoRA\u5728Text2MDT\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff0c\u4ee5\u5927\u5e45\u964d\u4f4e\u7684\u6a21\u578b\u590d\u6742\u5ea6\u83b7\u5f97\u66f4\u597d\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u8f7b\u91cf\u7ea7\u67b6\u6784\u7684\u540c\u65f6\u8fbe\u5230\u6700\u5148\u8fdb\u7ed3\u679c\uff0c\u7279\u522b\u9002\u5408\u8ba1\u7b97\u8d44\u6e90\u53ef\u80fd\u53d7\u9650\u7684\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u3002"}}
{"id": "2510.04978", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04978", "abs": "https://arxiv.org/abs/2510.04978", "authors": ["Kun Xiang", "Terry Jingchen Zhang", "Yinya Huang", "Jixi He", "Zirong Liu", "Yueling Tang", "Ruizhe Zhou", "Lijing Luo", "Youpeng Wen", "Xiuwei Chen", "Bingqian Lin", "Jianhua Han", "Hang Xu", "Hanhui Li", "Bin Dong", "Xiaodan Liang"], "title": "Aligning Perception, Reasoning, Modeling and Interaction: A Survey on Physical AI", "comment": null, "summary": "The rapid advancement of embodied intelligence and world models has\nintensified efforts to integrate physical laws into AI systems, yet physical\nperception and symbolic physics reasoning have developed along separate\ntrajectories without a unified bridging framework. This work provides a\ncomprehensive overview of physical AI, establishing clear distinctions between\ntheoretical physics reasoning and applied physical understanding while\nsystematically examining how physics-grounded methods enhance AI's real-world\ncomprehension across structured symbolic reasoning, embodied systems, and\ngenerative models. Through rigorous analysis of recent advances, we advocate\nfor intelligent systems that ground learning in both physical principles and\nembodied reasoning processes, transcending pattern recognition toward genuine\nunderstanding of physical laws. Our synthesis envisions next-generation world\nmodels capable of explaining physical phenomena and predicting future states,\nadvancing safe, generalizable, and interpretable AI systems. We maintain a\ncontinuously updated resource at\nhttps://github.com/AI4Phys/Awesome-AI-for-Physics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u7269\u7406AI\u9886\u57df\uff0c\u533a\u5206\u4e86\u7406\u8bba\u7269\u7406\u63a8\u7406\u4e0e\u5e94\u7528\u7269\u7406\u7406\u89e3\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u57fa\u4e8e\u7269\u7406\u7684\u65b9\u6cd5\u5982\u4f55\u589e\u5f3aAI\u5728\u7b26\u53f7\u63a8\u7406\u3001\u5177\u8eab\u7cfb\u7edf\u548c\u751f\u6210\u6a21\u578b\u4e2d\u7684\u771f\u5b9e\u4e16\u754c\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7269\u7406\u611f\u77e5\u548c\u7b26\u53f7\u7269\u7406\u63a8\u7406\u5404\u81ea\u53d1\u5c55\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u6865\u63a5\u6846\u67b6\uff0c\u9700\u8981\u5efa\u7acb\u80fd\u591f\u6574\u5408\u7269\u7406\u539f\u7406\u548c\u5177\u8eab\u63a8\u7406\u7684\u667a\u80fd\u7cfb\u7edf\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u8fd1\u671f\u8fdb\u5c55\uff0c\u5efa\u7acb\u7269\u7406AI\u7684\u7efc\u5408\u6846\u67b6\uff0c\u533a\u5206\u7406\u8bba\u63a8\u7406\u4e0e\u5e94\u7528\u7406\u89e3\uff0c\u5e76\u63a2\u8ba8\u7269\u7406\u57fa\u7840\u65b9\u6cd5\u5728\u4e0d\u540cAI\u9886\u57df\u7684\u5e94\u7528\u3002", "result": "\u63d0\u51fa\u4e86\u6574\u5408\u7269\u7406\u539f\u7406\u548c\u5177\u8eab\u63a8\u7406\u7684\u667a\u80fd\u7cfb\u7edf\u6846\u67b6\uff0c\u8d85\u8d8a\u4e86\u6a21\u5f0f\u8bc6\u522b\uff0c\u5b9e\u73b0\u4e86\u5bf9\u7269\u7406\u5b9a\u5f8b\u7684\u771f\u6b63\u7406\u89e3\u3002", "conclusion": "\u5c55\u671b\u4e86\u80fd\u591f\u89e3\u91ca\u7269\u7406\u73b0\u8c61\u548c\u9884\u6d4b\u672a\u6765\u72b6\u6001\u7684\u4e0b\u4e00\u4ee3\u4e16\u754c\u6a21\u578b\uff0c\u63a8\u52a8\u5b89\u5168\u3001\u53ef\u6cdb\u5316\u548c\u53ef\u89e3\u91ca\u7684AI\u7cfb\u7edf\u53d1\u5c55\u3002"}}
{"id": "2510.04671", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04671", "abs": "https://arxiv.org/abs/2510.04671", "authors": ["Chao Liu", "Ling Luo", "Tengxiao Lv", "Huan Zhuang", "Lejing Yu", "Jian Wang", "Hongfei Lin"], "title": "FocusMed: A Large Language Model-based Framework for Enhancing Medical Question Summarization with Focus Identification", "comment": "Accepted as a regular paper at BIBM2025", "summary": "With the rapid development of online medical platforms, consumer health\nquestions (CHQs) are inefficient in diagnosis due to redundant information and\nfrequent non-professional terms. The medical question summary (MQS) task aims\nto transform CHQs into streamlined doctors' frequently asked questions (FAQs),\nbut existing methods still face challenges such as poor identification of\nquestion focus and model hallucination. This paper explores the potential of\nlarge language models (LLMs) in the MQS task and finds that direct fine-tuning\nis prone to focus identification bias and generates unfaithful content. To this\nend, we propose an optimization framework based on core focus guidance. First,\na prompt template is designed to drive the LLMs to extract the core focus from\nthe CHQs that is faithful to the original text. Then, a fine-tuning dataset is\nconstructed in combination with the original CHQ-FAQ pairs to improve the\nability to identify the focus of the question. Finally, a multi-dimensional\nquality evaluation and selection mechanism is proposed to comprehensively\nimprove the quality of the summary from multiple dimensions. We conduct\ncomprehensive experiments on two widely-adopted MQS datasets using three\nestablished evaluation metrics. The proposed framework achieves\nstate-of-the-art performance across all measures, demonstrating a significant\nboost in the model's ability to identify critical focus of questions and a\nnotable mitigation of hallucinations. The source codes are freely available at\nhttps://github.com/DUT-LiuChao/FocusMed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6838\u5fc3\u7126\u70b9\u5f15\u5bfc\u7684\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u53d6\u5fe0\u5b9e\u4e8e\u539f\u6587\u7684\u6838\u5fc3\u7126\u70b9\u3001\u6784\u5efa\u5fae\u8c03\u6570\u636e\u96c6\u548c\u591a\u7ef4\u5ea6\u8d28\u91cf\u8bc4\u4f30\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u533b\u7597\u95ee\u9898\u6458\u8981\u4efb\u52a1\u4e2d\u7126\u70b9\u8bc6\u522b\u80fd\u529b\u548c\u51cf\u5c11\u5e7b\u89c9\u751f\u6210\u3002", "motivation": "\u5728\u7ebf\u533b\u7597\u5e73\u53f0\u7684\u5feb\u901f\u53d1\u5c55\u4f7f\u5f97\u6d88\u8d39\u8005\u5065\u5eb7\u95ee\u9898\u56e0\u5197\u4f59\u4fe1\u606f\u548c\u975e\u4e13\u4e1a\u672f\u8bed\u800c\u8bca\u65ad\u6548\u7387\u4f4e\u4e0b\u3002\u73b0\u6709\u533b\u7597\u95ee\u9898\u6458\u8981\u65b9\u6cd5\u5728\u95ee\u9898\u7126\u70b9\u8bc6\u522b\u548c\u6a21\u578b\u5e7b\u89c9\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6838\u5fc3\u7126\u70b9\u5f15\u5bfc\u7684\u4f18\u5316\u6846\u67b6\uff1a1\uff09\u8bbe\u8ba1\u63d0\u793a\u6a21\u677f\u9a71\u52a8LLMs\u63d0\u53d6\u5fe0\u5b9e\u4e8e\u539f\u6587\u7684\u6838\u5fc3\u7126\u70b9\uff1b2\uff09\u7ed3\u5408\u539f\u59cbCHQ-FAQ\u5bf9\u6784\u5efa\u5fae\u8c03\u6570\u636e\u96c6\uff1b3\uff09\u63d0\u51fa\u591a\u7ef4\u5ea6\u8d28\u91cf\u8bc4\u4f30\u548c\u9009\u62e9\u673a\u5236\u3002", "result": "\u5728\u4e24\u4e2a\u5e7f\u6cdb\u91c7\u7528\u7684MQS\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u4e09\u4e2a\u8bc4\u4f30\u6307\u6807\u8fdb\u884c\u7efc\u5408\u5b9e\u9a8c\uff0c\u6240\u63d0\u6846\u67b6\u5728\u6240\u6709\u6307\u6807\u4e0a\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u8bc6\u522b\u95ee\u9898\u5173\u952e\u7126\u70b9\u7684\u80fd\u529b\u5e76\u663e\u8457\u51cf\u8f7b\u4e86\u5e7b\u89c9\u3002", "conclusion": "\u57fa\u4e8e\u6838\u5fc3\u7126\u70b9\u5f15\u5bfc\u7684\u4f18\u5316\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u533b\u7597\u95ee\u9898\u6458\u8981\u4efb\u52a1\u4e2d\u7684\u7126\u70b9\u8bc6\u522b\u504f\u5dee\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u4e3aLLMs\u5728\u8be5\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04980", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04980", "abs": "https://arxiv.org/abs/2510.04980", "authors": ["Fangzhou Liang", "Tianshi Zheng", "Chunkit Chan", "Yauwai Yim", "Yangqiu Song"], "title": "LLM-Hanabi: Evaluating Multi-Agent Gameplays with Theory-of-Mind and Rationale Inference in Imperfect Information Collaboration Game", "comment": "EMNLP 2025 Wordplay", "summary": "Effective multi-agent collaboration requires agents to infer the rationale\nbehind others' actions, a capability rooted in Theory-of-Mind (ToM). While\nrecent Large Language Models (LLMs) excel at logical inference, their ability\nto infer rationale in dynamic, collaborative settings remains under-explored.\nThis study introduces LLM-Hanabi, a novel benchmark that uses the cooperative\ngame Hanabi to evaluate the rationale inference and ToM of LLMs. Our framework\nfeatures an automated evaluation system that measures both game performance and\nToM proficiency. Across a range of models, we find a significant positive\ncorrelation between ToM and in-game success. Notably, first-order ToM\n(interpreting others' intent) correlates more strongly with performance than\nsecond-order ToM (predicting others' interpretations). These findings highlight\nthat for effective AI collaboration, the ability to accurately interpret a\npartner's rationale is more critical than higher-order reasoning. We conclude\nthat prioritizing first-order ToM is a promising direction for enhancing the\ncollaborative capabilities of future models.", "AI": {"tldr": "LLM-Hanabi\u662f\u4e00\u4e2a\u57fa\u4e8e\u5408\u4f5c\u6e38\u620fHanabi\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5fc3\u667a\u7406\u8bba\u80fd\u529b\uff0c\u53d1\u73b0\u4e00\u9636\u5fc3\u667a\u7406\u8bba\uff08\u89e3\u91ca\u4ed6\u4eba\u610f\u56fe\uff09\u4e0e\u6e38\u620f\u8868\u73b0\u7684\u76f8\u5173\u6027\u6bd4\u4e8c\u9636\u5fc3\u667a\u7406\u8bba\u66f4\u5f3a\u3002", "motivation": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u52a8\u6001\u534f\u4f5c\u73af\u5883\u4e2d\u63a8\u65ad\u4ed6\u4eba\u884c\u4e3a\u80cc\u540e\u7406\u636e\u7684\u80fd\u529b\uff0c\u8fd9\u662f\u6709\u6548\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6240\u9700\u7684\u5fc3\u667a\u7406\u8bba\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u4e86LLM-Hanabi\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f7f\u7528\u5408\u4f5c\u6e38\u620fHanabi\uff0c\u5e76\u5efa\u7acb\u81ea\u52a8\u5316\u8bc4\u4f30\u7cfb\u7edf\u6765\u6d4b\u91cf\u6e38\u620f\u8868\u73b0\u548c\u5fc3\u667a\u7406\u8bba\u719f\u7ec3\u5ea6\u3002", "result": "\u53d1\u73b0\u5fc3\u667a\u7406\u8bba\u4e0e\u6e38\u620f\u6210\u529f\u5448\u663e\u8457\u6b63\u76f8\u5173\uff0c\u4e00\u9636\u5fc3\u667a\u7406\u8bba\uff08\u89e3\u91ca\u4ed6\u4eba\u610f\u56fe\uff09\u6bd4\u4e8c\u9636\u5fc3\u667a\u7406\u8bba\uff08\u9884\u6d4b\u4ed6\u4eba\u89e3\u91ca\uff09\u4e0e\u8868\u73b0\u7684\u76f8\u5173\u6027\u66f4\u5f3a\u3002", "conclusion": "\u5bf9\u4e8e\u6709\u6548\u7684AI\u534f\u4f5c\uff0c\u51c6\u786e\u89e3\u91ca\u4f19\u4f34\u7406\u636e\u7684\u80fd\u529b\u6bd4\u9ad8\u9636\u63a8\u7406\u66f4\u91cd\u8981\uff0c\u4f18\u5148\u53d1\u5c55\u4e00\u9636\u5fc3\u667a\u7406\u8bba\u662f\u589e\u5f3a\u672a\u6765\u6a21\u578b\u534f\u4f5c\u80fd\u529b\u7684\u6709\u524d\u666f\u65b9\u5411\u3002"}}
{"id": "2510.04678", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04678", "abs": "https://arxiv.org/abs/2510.04678", "authors": ["Zhanfeng Mo", "Xingxuan Li", "Yuntao Chen", "Lidong Bing"], "title": "Multi-Agent Tool-Integrated Policy Optimization", "comment": "Work in progress", "summary": "Large language models (LLMs) increasingly rely on multi-turn tool-integrated\nplanning for knowledge-intensive and complex reasoning tasks. Existing\nimplementations typically rely on a single agent, but they suffer from limited\ncontext length and noisy tool responses. A natural solution is to adopt a\nmulti-agent framework with planner- and worker-agents to manage context.\nHowever, no existing methods support effective reinforcement learning\npost-training of tool-integrated multi-agent frameworks. To address this gap,\nwe propose Multi-Agent Tool-Integrated Policy Optimization (MATPO), which\nenables distinct roles (planner and worker) to be trained within a single LLM\ninstance using role-specific prompts via reinforcement learning. MATPO is\nderived from a principled credit assignment mechanism across planner and worker\nrollouts. This design eliminates the need to deploy multiple LLMs, which would\nbe memory-intensive, while preserving the benefits of specialization.\nExperiments on GAIA-text, WebWalkerQA, and FRAMES show that MATPO consistently\noutperforms single-agent baselines by an average of 18.38% relative improvement\nin performance and exhibits greater robustness to noisy tool outputs. Our\nfindings highlight the effectiveness of unifying multiple agent roles within a\nsingle LLM and provide practical insights for stable and efficient multi-agent\nRL training.", "AI": {"tldr": "\u63d0\u51fa\u4e86MATPO\u65b9\u6cd5\uff0c\u5728\u5355\u4e2aLLM\u4e2d\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u89c4\u5212\u8005\u548c\u6267\u884c\u8005\u4e24\u4e2a\u89d2\u8272\uff0c\u89e3\u51b3\u591a\u8f6e\u5de5\u5177\u96c6\u6210\u89c4\u5212\u4e2d\u7684\u4e0a\u4e0b\u6587\u9650\u5236\u548c\u566a\u58f0\u5de5\u5177\u54cd\u5e94\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\u5b58\u5728\u4e0a\u4e0b\u6587\u957f\u5ea6\u6709\u9650\u548c\u5de5\u5177\u54cd\u5e94\u566a\u58f0\u95ee\u9898\uff0c\u591a\u667a\u80fd\u4f53\u6846\u67b6\u867d\u7136\u80fd\u7ba1\u7406\u4e0a\u4e0b\u6587\uff0c\u4f46\u7f3a\u4e4f\u6709\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u65b9\u6cd5\u3002", "method": "MATPO\u901a\u8fc7\u89d2\u8272\u7279\u5b9a\u63d0\u793a\u5728\u5355\u4e2aLLM\u5b9e\u4f8b\u4e2d\u8bad\u7ec3\u89c4\u5212\u8005\u548c\u6267\u884c\u8005\u89d2\u8272\uff0c\u57fa\u4e8e\u539f\u5219\u6027\u7684\u4fe1\u7528\u5206\u914d\u673a\u5236\u5728\u89c4\u5212\u8005\u548c\u6267\u884c\u8005\u8f68\u8ff9\u95f4\u5206\u914d\u5956\u52b1\u3002", "result": "\u5728GAIA-text\u3001WebWalkerQA\u548cFRAMES\u6570\u636e\u96c6\u4e0a\uff0cMATPO\u5e73\u5747\u76f8\u5bf9\u6027\u80fd\u63d0\u534718.38%\uff0c\u5bf9\u566a\u58f0\u5de5\u5177\u8f93\u51fa\u5177\u6709\u66f4\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "\u5728\u5355\u4e2aLLM\u4e2d\u7edf\u4e00\u591a\u4e2a\u667a\u80fd\u4f53\u89d2\u8272\u662f\u6709\u6548\u7684\uff0c\u4e3a\u7a33\u5b9a\u9ad8\u6548\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2510.05014", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.05014", "abs": "https://arxiv.org/abs/2510.05014", "authors": ["Xuanming Cui", "Jianpeng Cheng", "Hong-you Chen", "Satya Narayan Shukla", "Abhijeet Awasthi", "Xichen Pan", "Chaitanya Ahuja", "Shlok Kumar Mishra", "Qi Guo", "Ser-Nam Lim", "Aashu Singh", "Xiangjun Fan"], "title": "Think Then Embed: Generative Context Improves Multimodal Embedding", "comment": null, "summary": "There is a growing interest in Universal Multimodal Embeddings (UME), where\nmodels are required to generate task-specific representations. While recent\nstudies show that Multimodal Large Language Models (MLLMs) perform well on such\ntasks, they treat MLLMs solely as encoders, overlooking their generative\ncapacity. However, such an encoding paradigm becomes less effective as\ninstructions become more complex and require compositional reasoning. Inspired\nby the proven effectiveness of chain-of-thought reasoning, we propose a general\nThink-Then-Embed (TTE) framework for UME, composed of a reasoner and an\nembedder. The reasoner MLLM first generates reasoning traces that explain\ncomplex queries, followed by an embedder that produces representations\nconditioned on both the original query and the intermediate reasoning. This\nexplicit reasoning step enables more nuanced understanding of complex\nmultimodal instructions. Our contributions are threefold. First, by leveraging\na powerful MLLM reasoner, we achieve state-of-the-art performance on the\nMMEB-V2 benchmark, surpassing proprietary models trained on massive in-house\ndatasets. Second, to reduce the dependency on large MLLM reasoners, we finetune\na smaller MLLM reasoner using high-quality embedding-centric reasoning traces,\nachieving the best performance among open-source models with a 7% absolute gain\nover recently proposed models. Third, we investigate strategies for integrating\nthe reasoner and embedder into a unified model for improved efficiency without\nsacrificing performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86Think-Then-Embed\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u63a8\u7406\u6b65\u9aa4\u6765\u589e\u5f3a\u591a\u6a21\u6001\u5d4c\u5165\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5728MMEB-V2\u57fa\u51c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u7684\u901a\u7528\u591a\u6a21\u6001\u5d4c\u5165\u6a21\u578b\u4ec5\u5c06\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u7f16\u7801\u5668\u4f7f\u7528\uff0c\u5ffd\u7565\u4e86\u5176\u751f\u6210\u80fd\u529b\uff0c\u5728\u5904\u7406\u590d\u6742\u6307\u4ee4\u548c\u7ec4\u5408\u63a8\u7406\u65f6\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51faTTE\u6846\u67b6\uff0c\u5305\u542b\u63a8\u7406\u5668\u548c\u5d4c\u5165\u5668\u4e24\u4e2a\u7ec4\u4ef6\uff1a\u63a8\u7406\u5668MLLM\u5148\u751f\u6210\u89e3\u91ca\u590d\u6742\u67e5\u8be2\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u7136\u540e\u5d4c\u5165\u5668\u57fa\u4e8e\u539f\u59cb\u67e5\u8be2\u548c\u4e2d\u95f4\u63a8\u7406\u751f\u6210\u8868\u793a\u3002", "result": "\u5728MMEB-V2\u57fa\u51c6\u4e0a\u8d85\u8d8a\u4e13\u6709\u6a21\u578b\uff1b\u901a\u8fc7\u5fae\u8c03\u5c0f\u578bMLLM\u63a8\u7406\u5668\uff0c\u5728\u5f00\u6e90\u6a21\u578b\u4e2d\u53d6\u5f97\u6700\u4f73\u6027\u80fd\uff0c\u6bd4\u8fd1\u671f\u6a21\u578b\u63d0\u53477%\uff1b\u6210\u529f\u5c06\u63a8\u7406\u5668\u548c\u5d4c\u5165\u5668\u96c6\u6210\u5230\u7edf\u4e00\u6a21\u578b\u4e2d\uff0c\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u6548\u7387\u3002", "conclusion": "\u663e\u5f0f\u63a8\u7406\u6b65\u9aa4\u80fd\u591f\u66f4\u597d\u5730\u7406\u89e3\u590d\u6742\u7684\u591a\u6a21\u6001\u6307\u4ee4\uff0cTTE\u6846\u67b6\u4e3a\u901a\u7528\u591a\u6a21\u6001\u5d4c\u5165\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.04682", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04682", "abs": "https://arxiv.org/abs/2510.04682", "authors": ["Chanjoo Jung", "Jaehyung Kim"], "title": "TiTok: Transfer Token-level Knowledge via Contrastive Excess to Transplant LoRA", "comment": null, "summary": "Large Language Models (LLMs) are widely applied in real world scenarios, but\nfine-tuning them comes with significant computational and storage costs.\nParameter-Efficient Fine-Tuning (PEFT) methods such as LoRA mitigate these\ncosts, but the adapted parameters are dependent on the base model and cannot be\ntransferred across different backbones. One way to address this issue is\nthrough knowledge distillation, but its effectiveness inherently depends on\ntraining data. Recent work such as TransLoRA avoids this by generating\nsynthetic data, but this adds complexity because it requires training an\nadditional discriminator model. In this paper, we propose TiTok, a new\nframework that enables effective LoRA Transplantation through Token-level\nknowledge transfer. Specifically, TiTok captures task-relevant information\nthrough a contrastive excess between a source model with and without LoRA. This\nexcess highlights informative tokens and enables selective filtering of\nsynthetic data, all without additional models or overhead. Through experiments\non three benchmarks across multiple transfer settings, our experiments show\nthat the proposed method is consistently effective, achieving average\nperformance gains of +4~8% compared to baselines overall.", "AI": {"tldr": "TiTok\u662f\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4ee4\u724c\u7ea7\u77e5\u8bc6\u8f6c\u79fb\u5b9e\u73b0\u6709\u6548\u7684LoRA\u79fb\u690d\uff0c\u65e0\u9700\u989d\u5916\u6a21\u578b\u6216\u5f00\u9500\uff0c\u5728\u591a\u4e2a\u8fc1\u79fb\u8bbe\u7f6e\u4e2d\u5e73\u5747\u6027\u80fd\u63d0\u53474~8%\u3002", "motivation": "\u89e3\u51b3\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u5982LoRA\u4e2d\u9002\u914d\u53c2\u6570\u4f9d\u8d56\u4e8e\u57fa\u7840\u6a21\u578b\u4e14\u65e0\u6cd5\u5728\u4e0d\u540c\u9aa8\u5e72\u7f51\u7edc\u95f4\u8fc1\u79fb\u7684\u95ee\u9898\uff0c\u907f\u514d\u77e5\u8bc6\u84b8\u998f\u5bf9\u8bad\u7ec3\u6570\u636e\u7684\u4f9d\u8d56\u548cTransLoRA\u9700\u8981\u989d\u5916\u5224\u522b\u5668\u6a21\u578b\u7684\u590d\u6742\u6027\u3002", "method": "\u901a\u8fc7\u5bf9\u6bd4\u6e90\u6a21\u578b\u5728\u6709\u548c\u6ca1\u6709LoRA\u60c5\u51b5\u4e0b\u7684\u5dee\u5f02\uff0c\u6355\u6349\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\uff0c\u7a81\u51fa\u4fe1\u606f\u4e30\u5bcc\u7684\u4ee4\u724c\uff0c\u5e76\u9009\u62e9\u6027\u8fc7\u6ee4\u5408\u6210\u6570\u636e\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u7684\u591a\u4e2a\u8fc1\u79fb\u8bbe\u7f6e\u4e2d\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u6709\u6548\uff0c\u6574\u4f53\u5e73\u5747\u6027\u80fd\u63d0\u53474~8%\u3002", "conclusion": "TiTok\u6846\u67b6\u901a\u8fc7\u4ee4\u724c\u7ea7\u77e5\u8bc6\u8f6c\u79fb\u5b9e\u73b0\u4e86\u6709\u6548\u7684LoRA\u79fb\u690d\uff0c\u65e0\u9700\u989d\u5916\u6a21\u578b\u6216\u5f00\u9500\uff0c\u5728\u591a\u4e2a\u8fc1\u79fb\u573a\u666f\u4e2d\u8868\u73b0\u4e00\u81f4\u4f18\u8d8a\u3002"}}
{"id": "2510.05048", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2510.05048", "abs": "https://arxiv.org/abs/2510.05048", "authors": ["Ond\u0159ej Kub\u00ed\u010dek", "Viliam Lis\u00fd"], "title": "Look-ahead Reasoning with a Learned Model in Imperfect Information Games", "comment": null, "summary": "Test-time reasoning significantly enhances pre-trained AI agents'\nperformance. However, it requires an explicit environment model, often\nunavailable or overly complex in real-world scenarios. While MuZero enables\neffective model learning for search in perfect information games, extending\nthis paradigm to imperfect information games presents substantial challenges\ndue to more nuanced look-ahead reasoning techniques and large number of states\nrelevant for individual decisions. This paper introduces an algorithm LAMIR\nthat learns an abstracted model of an imperfect information game directly from\nthe agent-environment interaction. During test time, this trained model is used\nto perform look-ahead reasoning. The learned abstraction limits the size of\neach subgame to a manageable size, making theoretically principled look-ahead\nreasoning tractable even in games where previous methods could not scale. We\nempirically demonstrate that with sufficient capacity, LAMIR learns the exact\nunderlying game structure, and with limited capacity, it still learns a\nvaluable abstraction, which improves game playing performance of the\npre-trained agents even in large games.", "AI": {"tldr": "LAMIR\u7b97\u6cd5\u901a\u8fc7\u5b66\u4e60\u4e0d\u5b8c\u7f8e\u4fe1\u606f\u6e38\u620f\u7684\u62bd\u8c61\u6a21\u578b\uff0c\u5728\u6d4b\u8bd5\u65f6\u8fdb\u884c\u524d\u77bb\u63a8\u7406\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u590d\u6742\u6e38\u620f\u4e2d\u96be\u4ee5\u6269\u5c55\u7684\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u4e0d\u5b8c\u7f8e\u4fe1\u606f\u6e38\u620f\u4e2d\u6a21\u578b\u5b66\u4e60\u56f0\u96be\u7684\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u590d\u6742\u6e38\u620f\u4e2d\u65e0\u6cd5\u6709\u6548\u6269\u5c55\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u63a8\u7406\u65b9\u6cd5\u3002", "method": "LAMIR\u7b97\u6cd5\u76f4\u63a5\u4ece\u667a\u80fd\u4f53-\u73af\u5883\u4ea4\u4e92\u4e2d\u5b66\u4e60\u6e38\u620f\u7684\u62bd\u8c61\u6a21\u578b\uff0c\u901a\u8fc7\u62bd\u8c61\u5316\u9650\u5236\u5b50\u6e38\u620f\u89c4\u6a21\uff0c\u4f7f\u7406\u8bba\u4e0a\u6709\u539f\u5219\u7684\u524d\u77bb\u63a8\u7406\u53d8\u5f97\u53ef\u884c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u8db3\u591f\u5bb9\u91cf\u4e0bLAMIR\u80fd\u5b66\u4e60\u5230\u7cbe\u786e\u7684\u5e95\u5c42\u6e38\u620f\u7ed3\u6784\uff0c\u5728\u6709\u9650\u5bb9\u91cf\u4e0b\u4ecd\u80fd\u5b66\u4e60\u6709\u4ef7\u503c\u7684\u62bd\u8c61\uff0c\u63d0\u5347\u9884\u8bad\u7ec3\u667a\u80fd\u4f53\u5728\u5927\u578b\u6e38\u620f\u4e2d\u7684\u8868\u73b0\u3002", "conclusion": "LAMIR\u4e3a\u4e0d\u5b8c\u7f8e\u4fe1\u606f\u6e38\u620f\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u524d\u77bb\u63a8\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u6a21\u578b\u62bd\u8c61\u5316\u4f7f\u590d\u6742\u6e38\u620f\u4e2d\u7684\u7406\u8bba\u63a8\u7406\u53d8\u5f97\u53ef\u884c\u3002"}}
{"id": "2510.04694", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04694", "abs": "https://arxiv.org/abs/2510.04694", "authors": ["Lucas Bandarkar", "Chenyuan Yang", "Mohsen Fayyaz", "Junlin Hu", "Nanyun Peng"], "title": "Multilingual Routing in Mixture-of-Experts", "comment": null, "summary": "Mixture-of-Experts (MoE) architectures have become the key to scaling modern\nLLMs, yet little is understood about how their sparse routing dynamics respond\nto multilingual data. In this work, we analyze expert routing patterns using\nparallel multilingual datasets and present highly interpretable layer-wise\nphenomena. We find that MoE models route tokens in language-specific ways in\nthe early and late decoder layers but exhibit significant cross-lingual routing\nalignment in middle layers, mirroring parameter-sharing trends observed in\ndense LLMs. In particular, we reveal a clear, strong correlation between a\nmodel's performance in a given language and how similarly its tokens are routed\nto English in these layers. Extending beyond correlation, we explore\ninference-time interventions that induce higher cross-lingual routing\nalignment. We introduce a method that steers the router by promoting\nmiddle-layer task experts frequently activated in English, and it successfully\nincreases multilingual performance. These 1-2% gains are remarkably consistent\nacross two evaluation tasks, three models, and 15+ languages, especially given\nthat these simple interventions override routers of extensively trained,\nstate-of-the-art LLMs. In comparison, interventions outside of the middle\nlayers or targeting multilingual-specialized experts only yield performance\ndegradation. Altogether, we present numerous findings that explain how MoEs\nprocess non-English text and demonstrate that generalization is limited by the\nmodel's ability to leverage language-universal experts in all languages.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86MoE\u67b6\u6784\u5728\u591a\u8bed\u8a00\u6570\u636e\u4e2d\u7684\u7a00\u758f\u8def\u7531\u52a8\u6001\uff0c\u53d1\u73b0\u5728\u4e2d\u95f4\u5c42\u5b58\u5728\u8de8\u8bed\u8a00\u8def\u7531\u5bf9\u9f50\u73b0\u8c61\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u4fc3\u8fdb\u82f1\u8bed\u6fc0\u6d3b\u7684\u4efb\u52a1\u4e13\u5bb6\u6765\u63d0\u9ad8\u591a\u8bed\u8a00\u6027\u80fd\u7684\u63a8\u7406\u65f6\u5e72\u9884\u65b9\u6cd5\u3002", "motivation": "\u7406\u89e3MoE\u67b6\u6784\u5728\u591a\u8bed\u8a00\u6570\u636e\u4e2d\u7684\u7a00\u758f\u8def\u7531\u52a8\u6001\uff0c\u63a2\u7d22\u5982\u4f55\u63d0\u9ad8\u591a\u8bed\u8a00LLM\u7684\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u5e76\u884c\u591a\u8bed\u8a00\u6570\u636e\u96c6\u5206\u6790\u4e13\u5bb6\u8def\u7531\u6a21\u5f0f\uff0c\u63d0\u51fa\u5728\u63a8\u7406\u65f6\u901a\u8fc7\u4fc3\u8fdb\u4e2d\u95f4\u5c42\u82f1\u8bed\u6fc0\u6d3b\u7684\u4efb\u52a1\u4e13\u5bb6\u6765\u5f15\u5bfc\u8def\u7531\u5668\u7684\u5e72\u9884\u65b9\u6cd5\u3002", "result": "\u5e72\u9884\u65b9\u6cd5\u5728\u4e24\u79cd\u8bc4\u4f30\u4efb\u52a1\u3001\u4e09\u4e2a\u6a21\u578b\u548c15+\u79cd\u8bed\u8a00\u4e0a\u4e00\u81f4\u63d0\u9ad8\u4e861-2%\u7684\u591a\u8bed\u8a00\u6027\u80fd\uff0c\u800c\u4e2d\u95f4\u5c42\u4e4b\u5916\u7684\u5e72\u9884\u6216\u9488\u5bf9\u591a\u8bed\u8a00\u4e13\u95e8\u4e13\u5bb6\u7684\u5e72\u9884\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "MoE\u6a21\u578b\u5904\u7406\u975e\u82f1\u8bed\u6587\u672c\u7684\u80fd\u529b\u53d7\u9650\u4e8e\u5176\u5728\u6240\u6709\u8bed\u8a00\u4e2d\u5229\u7528\u8bed\u8a00\u901a\u7528\u4e13\u5bb6\u7684\u80fd\u529b\uff0c\u4e2d\u95f4\u5c42\u7684\u8de8\u8bed\u8a00\u8def\u7531\u5bf9\u9f50\u4e0e\u6a21\u578b\u6027\u80fd\u5bc6\u5207\u76f8\u5173\u3002"}}
{"id": "2510.05059", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05059", "abs": "https://arxiv.org/abs/2510.05059", "authors": ["Junlin Wang", "Jue Wang", "Zhen", "Xu", "Ben Athiwaratkun", "Bhuwan Dhingra", "Ce Zhang", "James Zou"], "title": "Staircase Streaming for Low-Latency Multi-Agent Inference", "comment": null, "summary": "Recent advances in large language models (LLMs) opened up new directions for\nleveraging the collective expertise of multiple LLMs. These methods, such as\nMixture-of-Agents, typically employ additional inference steps to generate\nintermediate outputs, which are then used to produce the final response. While\nmulti-agent inference can enhance response quality, it can significantly\nincrease the time to first token (TTFT), posing a challenge for\nlatency-sensitive applications and hurting user experience. To address this\nissue, we propose staircase streaming for low-latency multi-agent inference.\nInstead of waiting for the complete intermediate outputs from previous steps,\nwe begin generating the final response as soon as we receive partial outputs\nfrom these steps. Experimental results demonstrate that staircase streaming\nreduces TTFT by up to 93% while maintaining response quality.", "AI": {"tldr": "\u63d0\u51fa\u9636\u68af\u5f0f\u6d41\u5f0f\u5904\u7406\u65b9\u6cd5\u6765\u964d\u4f4e\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7684\u5ef6\u8fdf\uff0c\u5728\u63a5\u6536\u90e8\u5206\u4e2d\u95f4\u8f93\u51fa\u65f6\u5c31\u5f00\u59cb\u751f\u6210\u6700\u7ec8\u54cd\u5e94\uff0c\u663e\u8457\u51cf\u5c11\u9996\u8bcd\u65f6\u95f4\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u63a8\u7406\u867d\u7136\u80fd\u63d0\u5347\u54cd\u5e94\u8d28\u91cf\uff0c\u4f46\u4f1a\u663e\u8457\u589e\u52a0\u9996\u8bcd\u65f6\u95f4\uff0c\u5f71\u54cd\u5ef6\u8fdf\u654f\u611f\u5e94\u7528\u7684\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u9636\u68af\u5f0f\u6d41\u5f0f\u5904\u7406\uff1a\u65e0\u9700\u7b49\u5f85\u5b8c\u6574\u7684\u4e2d\u95f4\u8f93\u51fa\uff0c\u5728\u63a5\u6536\u5230\u90e8\u5206\u4e2d\u95f4\u8f93\u51fa\u65f6\u5c31\u5f00\u59cb\u751f\u6210\u6700\u7ec8\u54cd\u5e94\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u9636\u68af\u5f0f\u6d41\u5f0f\u5904\u7406\u5c06\u9996\u8bcd\u65f6\u95f4\u964d\u4f4e\u9ad8\u8fbe93%\uff0c\u540c\u65f6\u4fdd\u6301\u54cd\u5e94\u8d28\u91cf\u3002", "conclusion": "\u9636\u68af\u5f0f\u6d41\u5f0f\u5904\u7406\u662f\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u5728\u4fdd\u6301\u8d28\u91cf\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u54cd\u5e94\u5ef6\u8fdf\u3002"}}
{"id": "2510.04717", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04717", "abs": "https://arxiv.org/abs/2510.04717", "authors": ["Sarel Duanis", "Asnat Greenstein-Messica", "Eliya Habba"], "title": "JSON Whisperer: Efficient JSON Editing with LLMs", "comment": null, "summary": "Large language models (LLMs) can modify JSON documents through natural\nlanguage commands, but current approaches regenerate entire structures for each\nedit, resulting in computational inefficiency. We present JSON Whisperer, a\nframework that enables LLMs to generate RFC 6902 diff patches-expressing only\nthe necessary modifications-rather than complete documents. We identify two key\nchallenges in patch-based editing: (1) LLMs often miss related updates when\ngenerating isolated patches, and (2) array manipulations require tracking index\nshifts across operations, which LLMs handle poorly. To address these issues, we\nintroduce EASE (Explicitly Addressed Sequence Encoding), which transforms\narrays into dictionaries with stable keys, eliminating index arithmetic\ncomplexities. Our evaluation shows that patch generation with EASE reduces\ntoken usage by 31% while maintaining edit quality within 5% of full\nregeneration with particular gains for complex instructions and list\nmanipulations. The dataset is available at:\nhttps://github.com/emnlp2025/JSON-Whisperer/", "AI": {"tldr": "JSON Whisperer\u662f\u4e00\u4e2a\u8ba9LLM\u751f\u6210JSON\u8865\u4e01\u800c\u975e\u5b8c\u6574\u6587\u6863\u7684\u6846\u67b6\uff0c\u901a\u8fc7EASE\u7f16\u7801\u89e3\u51b3\u6570\u7ec4\u7d22\u5f15\u95ee\u9898\uff0c\u51cf\u5c1131%\u7684token\u4f7f\u7528\u91cf\u3002", "motivation": "\u5f53\u524dLLM\u5728\u4fee\u6539JSON\u6587\u6863\u65f6\u9700\u8981\u91cd\u65b0\u751f\u6210\u6574\u4e2a\u7ed3\u6784\uff0c\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51faJSON Whisperer\u6846\u67b6\u751f\u6210RFC 6902\u5dee\u5f02\u8865\u4e01\uff0c\u5f15\u5165EASE\u7f16\u7801\u5c06\u6570\u7ec4\u8f6c\u6362\u4e3a\u5177\u6709\u7a33\u5b9a\u952e\u7684\u5b57\u5178\u3002", "result": "\u8865\u4e01\u751f\u6210\u4e0eEASE\u7ed3\u5408\u51cf\u5c1131%\u7684token\u4f7f\u7528\uff0c\u7f16\u8f91\u8d28\u91cf\u4e0e\u5b8c\u6574\u518d\u751f\u76f8\u6bd4\u4ec5\u4e0b\u964d5%\u3002", "conclusion": "JSON Whisperer\u901a\u8fc7\u8865\u4e01\u751f\u6210\u548cEASE\u7f16\u7801\u6709\u6548\u63d0\u9ad8\u4e86LLM\u7f16\u8f91JSON\u6587\u6863\u7684\u6548\u7387\u3002"}}
{"id": "2505.02819", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2505.02819", "abs": "https://arxiv.org/abs/2505.02819", "authors": ["Dmitriy Shopkhoev", "Ammar Ali", "Magauiya Zhussip", "Valentin Malykh", "Stamatios Lefkimmiatis", "Nikos Komodakis", "Sergey Zagoruyko"], "title": "ReplaceMe: Network Simplification via Depth Pruning and Transformer Block Linearization", "comment": null, "summary": "We introduce ReplaceMe, a generalized training-free depth pruning method that\neffectively replaces transformer blocks with a linear operation, while\nmaintaining high performance for low compression ratios. In contrast to\nconventional pruning approaches that require additional training or\nfine-tuning, our approach requires only a small calibration dataset that is\nused to estimate a linear transformation, which approximates the pruned blocks.\nThe estimated linear mapping can be seamlessly merged with the remaining\ntransformer blocks, eliminating the need for any additional network parameters.\nOur experiments show that ReplaceMe consistently outperforms other\ntraining-free approaches and remains highly competitive with state-of-the-art\npruning methods that involve extensive retraining/fine-tuning and architectural\nmodifications. Applied to several large language models (LLMs), ReplaceMe\nachieves up to 25% pruning while retaining approximately 90% of the original\nmodel's performance on open benchmarks - without any training or healing steps,\nresulting in minimal computational overhead (see Fig.1). We provide an\nopen-source library implementing ReplaceMe alongside several state-of-the-art\ndepth pruning techniques, available at https://github.com/mts-ai/ReplaceMe.", "AI": {"tldr": "ReplaceMe\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u526a\u679dTransformer\u5757\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ebf\u6027\u53d8\u6362\u66ff\u6362\u5757\u5e76\u4fdd\u6301\u9ad8\u6027\u80fd\uff0c\u652f\u6301\u9ad8\u8fbe25%\u7684\u526a\u679d\u7387\u4e14\u6027\u80fd\u4fdd\u7559\u7ea690%\u3002", "motivation": "\u4f20\u7edf\u526a\u679d\u65b9\u6cd5\u9700\u8981\u989d\u5916\u7684\u8bad\u7ec3\u6216\u5fae\u8c03\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002ReplaceMe\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u9ad8\u6548\u526a\u679d\u65b9\u6cd5\uff0c\u4ec5\u9700\u5c11\u91cf\u6821\u51c6\u6570\u636e\u5373\u53ef\u5b9e\u73b0\u6df1\u5ea6\u526a\u679d\u3002", "method": "\u4f7f\u7528\u5c0f\u89c4\u6a21\u6821\u51c6\u6570\u636e\u96c6\u4f30\u8ba1\u7ebf\u6027\u53d8\u6362\u6765\u8fd1\u4f3c\u88ab\u526a\u679d\u7684Transformer\u5757\uff0c\u8be5\u7ebf\u6027\u6620\u5c04\u53ef\u4e0e\u5269\u4f59\u5757\u65e0\u7f1d\u5408\u5e76\uff0c\u65e0\u9700\u989d\u5916\u7f51\u7edc\u53c2\u6570\u3002", "result": "\u5728\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u6d4b\u8bd5\uff0cReplaceMe\u572825%\u526a\u679d\u7387\u4e0b\u4ecd\u80fd\u4fdd\u6301\u7ea690%\u7684\u539f\u59cb\u6027\u80fd\uff0c\u4f18\u4e8e\u5176\u4ed6\u65e0\u9700\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4e14\u4e0e\u9700\u8981\u5927\u91cf\u91cd\u8bad\u7ec3\u7684\u65b9\u6cd5\u7ade\u4e89\u529b\u76f8\u5f53\u3002", "conclusion": "ReplaceMe\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u6df1\u5ea6\u526a\u679d\u65b9\u6848\uff0c\u8ba1\u7b97\u5f00\u9500\u6781\u5c0f\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u6a21\u578b\u590d\u6742\u5ea6\u3002"}}
{"id": "2510.04750", "categories": ["cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.04750", "abs": "https://arxiv.org/abs/2510.04750", "authors": ["Peshala Perera", "Deshan Sumanathilaka"], "title": "A Low-Resource Speech-Driven NLP Pipeline for Sinhala Dyslexia Assistance", "comment": "11 pages, 4 figures, 3 tables", "summary": "Dyslexia in adults remains an under-researched and under-served area,\nparticularly in non-English-speaking contexts, despite its significant impact\non personal and professional lives. This work addresses that gap by focusing on\nSinhala, a low-resource language with limited tools for linguistic\naccessibility. We present an assistive system explicitly designed for\nSinhala-speaking adults with dyslexia. The system integrates Whisper for\nspeech-to-text conversion, SinBERT, an open-sourced fine-tuned BERT model\ntrained for Sinhala to identify common dyslexic errors, and a combined mT5 and\nMistral-based model to generate corrected text. Finally, the output is\nconverted back to speech using gTTS, creating a complete multimodal feedback\nloop. Despite the challenges posed by limited Sinhala-language datasets, the\nsystem achieves 0.66 transcription accuracy and 0.7 correction accuracy with\n0.65 overall system accuracy. These results demonstrate both the feasibility\nand effectiveness of the approach. Ultimately, this work highlights the\nimportance of inclusive Natural Language Processing (NLP) technologies in\nunderrepresented languages and showcases a practical", "AI": {"tldr": "\u4e3a\u50e7\u4f3d\u7f57\u8bed\u6210\u4eba\u9605\u8bfb\u969c\u788d\u8005\u5f00\u53d1\u7684\u591a\u6a21\u6001\u8f85\u52a9\u7cfb\u7edf\uff0c\u6574\u5408\u8bed\u97f3\u8f6c\u6587\u5b57\u3001\u9519\u8bef\u8bc6\u522b\u3001\u6587\u672c\u4fee\u6b63\u548c\u8bed\u97f3\u8f93\u51fa\u529f\u80fd", "motivation": "\u6210\u4eba\u9605\u8bfb\u969c\u788d\u5728\u975e\u82f1\u8bed\u8bed\u5883\u4e2d\u7814\u7a76\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u50e7\u4f3d\u7f57\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u7f3a\u4e4f\u8bed\u8a00\u53ef\u53ca\u6027\u5de5\u5177\uff0c\u4e25\u91cd\u5f71\u54cd\u4e2a\u4eba\u548c\u804c\u4e1a\u751f\u6d3b", "method": "\u96c6\u6210Whisper\u8fdb\u884c\u8bed\u97f3\u8f6c\u6587\u5b57\uff0c\u4f7f\u7528SinBERT\u8bc6\u522b\u5e38\u89c1\u9605\u8bfb\u969c\u788d\u9519\u8bef\uff0c\u7ed3\u5408mT5\u548cMistral\u6a21\u578b\u751f\u6210\u4fee\u6b63\u6587\u672c\uff0c\u6700\u540e\u901a\u8fc7gTTS\u8f6c\u6362\u4e3a\u8bed\u97f3\u8f93\u51fa", "result": "\u5728\u6709\u9650\u7684\u50e7\u4f3d\u7f57\u8bed\u6570\u636e\u96c6\u4e0b\uff0c\u7cfb\u7edf\u8fbe\u52300.66\u8f6c\u5f55\u51c6\u786e\u7387\u30010.7\u4fee\u6b63\u51c6\u786e\u7387\u548c0.65\u6574\u4f53\u7cfb\u7edf\u51c6\u786e\u7387", "conclusion": "\u8be5\u65b9\u6cd5\u8bc1\u660e\u4e86\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u73af\u5883\u4e2d\u5f00\u53d1\u5305\u5bb9\u6027\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027"}}
{"id": "2510.04757", "categories": ["cs.CL", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.04757", "abs": "https://arxiv.org/abs/2510.04757", "authors": ["Eduardo Mart\u00ednez Rivera", "Filippo Menolascina"], "title": "ModernBERT + ColBERT: Enhancing biomedical RAG through an advanced re-ranking retriever", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) is a powerful technique for enriching\nLarge Language Models (LLMs) with external knowledge, allowing for factually\ngrounded responses, a critical requirement in high-stakes domains such as\nhealthcare. However, the efficacy of RAG systems is fundamentally restricted by\nthe performance of their retrieval module, since irrelevant or semantically\nmisaligned documents directly compromise the accuracy of the final generated\nresponse. General-purpose dense retrievers can struggle with the nuanced\nlanguage of specialised domains, while the high accuracy of in-domain models is\noften achieved at prohibitive computational costs. In this work, we aim to\naddress this trade-off by developing and evaluating a two-stage retrieval\narchitecture that combines a lightweight ModernBERT bidirectional encoder for\nefficient initial candidate retrieval with a ColBERTv2 late-interaction model\nfor fine-grained re-ranking. We conduct comprehensive evaluations of our\nretriever module performance and RAG system performance in the biomedical\ncontext, fine-tuning the IR module using 10k question-passage pairs from\nPubMedQA. Our analysis of the retriever module confirmed the positive impact of\nthe ColBERT re-ranker, which improved Recall@3 by up to 4.2 percentage points\ncompared to its retrieve-only counterpart. When integrated into the biomedical\nRAG, our IR module leads to a state-of-the-art average accuracy of 0.4448 on\nthe five tasks of the MIRAGE question-answering benchmark, outperforming strong\nbaselines such as MedCPT (0.4436). Our ablation studies reveal that this\nperformance is critically dependent on a joint fine-tuning process that aligns\nthe retriever and re-ranker; otherwise, the re-ranker might degrade the\nperformance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u68c0\u7d22\u67b6\u6784\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7ModernBERT\u8fdb\u884c\u521d\u59cb\u5019\u9009\u68c0\u7d22\u548cColBERTv2\u8fdb\u884c\u7ec6\u7c92\u5ea6\u91cd\u6392\u5e8f\uff0c\u5728\u751f\u7269\u533b\u5b66RAG\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3RAG\u7cfb\u7edf\u4e2d\u68c0\u7d22\u6a21\u5757\u6027\u80fd\u53d7\u9650\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u4e13\u4e1a\u9886\u57df\u5982\u533b\u7597\u4fdd\u5065\u4e2d\uff0c\u901a\u7528\u68c0\u7d22\u5668\u96be\u4ee5\u5904\u7406\u4e13\u4e1a\u8bed\u8a00\uff0c\u800c\u9886\u57df\u5185\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u4f7f\u7528ModernBERT\u53cc\u5411\u7f16\u7801\u5668\u8fdb\u884c\u9ad8\u6548\u521d\u59cb\u5019\u9009\u68c0\u7d22\uff0c\u7ed3\u5408ColBERTv2\u540e\u671f\u4ea4\u4e92\u6a21\u578b\u8fdb\u884c\u7ec6\u7c92\u5ea6\u91cd\u6392\u5e8f\uff0c\u5728PubMedQA\u768410k\u95ee\u9898-\u6bb5\u843d\u5bf9\u4e0a\u5fae\u8c03IR\u6a21\u5757\u3002", "result": "ColBERT\u91cd\u6392\u5e8f\u5668\u5c06Recall@3\u63d0\u9ad8\u4e864.2\u4e2a\u767e\u5206\u70b9\uff1b\u5728MIRAGE QA\u57fa\u51c6\u6d4b\u8bd5\u7684\u4e94\u4e2a\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e860.4448\u7684\u5e73\u5747\u51c6\u786e\u7387\uff0c\u4f18\u4e8eMedCPT\uff080.4436\uff09\u3002", "conclusion": "\u4e24\u9636\u6bb5\u68c0\u7d22\u67b6\u6784\u5728\u751f\u7269\u533b\u5b66RAG\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u6027\u80fd\u5173\u952e\u4f9d\u8d56\u4e8e\u68c0\u7d22\u5668\u548c\u91cd\u6392\u5e8f\u5668\u7684\u8054\u5408\u5fae\u8c03\u8fc7\u7a0b\uff0c\u5426\u5219\u91cd\u6392\u5e8f\u5668\u53ef\u80fd\u964d\u4f4e\u6027\u80fd\u3002"}}
{"id": "2510.04764", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04764", "abs": "https://arxiv.org/abs/2510.04764", "authors": ["Raha Askari", "Sina Zarrie\u00df", "\u00d6zge Alacam", "Judith Sieker"], "title": "Are BabyLMs Deaf to Gricean Maxims? A Pragmatic Evaluation of Sample-efficient Language Models", "comment": null, "summary": "Implicit meanings are integral to human communication, making it essential\nfor language models to be capable of identifying and interpreting them. Grice\n(1975) proposed a set of conversational maxims that guide cooperative dialogue,\nnoting that speakers may deliberately violate these principles to express\nmeanings beyond literal words, and that listeners, in turn, recognize such\nviolations to draw pragmatic inferences.\n  Building on Surian et al. (1996)'s study of children's sensitivity to\nviolations of Gricean maxims, we introduce a novel benchmark to test whether\nlanguage models pretrained on less than 10M and less than 100M tokens can\ndistinguish maxim-adhering from maxim-violating utterances. We compare these\nBabyLMs across five maxims and situate their performance relative to children\nand a Large Language Model (LLM) pretrained on 3T tokens.\n  We find that overall, models trained on less than 100M tokens outperform\nthose trained on less than 10M, yet fall short of child-level and LLM\ncompetence. Our results suggest that modest data increases improve some aspects\nof pragmatic behavior, leading to finer-grained differentiation between\npragmatic dimensions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u7406\u89e3Grice\u4f1a\u8bdd\u51c6\u5219\u8fdd\u53cd\u7684\u65b0\u57fa\u51c6\uff0c\u6bd4\u8f83\u4e86\u5728\u4e0d\u540c\u89c4\u6a21\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\u7684BabyLMs\u4e0e\u513f\u7ae5\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u7406\u89e3\u9690\u542b\u610f\u4e49\u5bf9\u4eba\u7c7b\u4ea4\u6d41\u81f3\u5173\u91cd\u8981\uff0c\u7814\u7a76\u65e8\u5728\u6d4b\u8bd5\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u50cf\u4eba\u7c7b\u4e00\u6837\u8bc6\u522b\u548c\u89e3\u91ca\u8fdd\u53cdGrice\u4f1a\u8bdd\u51c6\u5219\u7684\u8bdd\u8bed\u3002", "method": "\u57fa\u4e8eSurian\u7b49\u4eba\u5bf9\u513f\u7ae5Grice\u51c6\u5219\u654f\u611f\u6027\u7684\u7814\u7a76\uff0c\u521b\u5efa\u65b0\u57fa\u51c6\u6d4b\u8bd5\u6a21\u578b\u533a\u5206\u51c6\u5219\u9075\u5b88\u548c\u8fdd\u53cd\u8bdd\u8bed\u7684\u80fd\u529b\uff0c\u6bd4\u8f83\u4e86\u572810M\u548c100M tokens\u4e0a\u9884\u8bad\u7ec3\u7684BabyLMs\u4e0e\u513f\u7ae5\u548c3T tokens\u9884\u8bad\u7ec3\u7684LLM\u3002", "result": "\u5728100M tokens\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u4f18\u4e8e10M tokens\u7684\u6a21\u578b\uff0c\u4f46\u4ecd\u672a\u8fbe\u5230\u513f\u7ae5\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6c34\u5e73\uff1b\u9002\u5ea6\u589e\u52a0\u6570\u636e\u80fd\u6539\u5584\u67d0\u4e9b\u8bed\u7528\u884c\u4e3a\u65b9\u9762\uff0c\u5b9e\u73b0\u66f4\u7ec6\u7c92\u5ea6\u7684\u8bed\u7528\u7ef4\u5ea6\u533a\u5206\u3002", "conclusion": "\u5c0f\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u7406\u89e3\u8bed\u7528\u542b\u4e49\u65b9\u9762\u6709\u6240\u8fdb\u6b65\uff0c\u4f46\u4e0e\u4eba\u7c7b\u513f\u7ae5\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u76f8\u6bd4\u4ecd\u6709\u5dee\u8ddd\uff0c\u6570\u636e\u91cf\u7684\u9002\u5ea6\u589e\u52a0\u6709\u52a9\u4e8e\u63d0\u5347\u8bed\u7528\u884c\u4e3a\u7684\u67d0\u4e9b\u65b9\u9762\u3002"}}
{"id": "2510.04800", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04800", "abs": "https://arxiv.org/abs/2510.04800", "authors": ["Sangmin Bae", "Bilge Acun", "Haroun Habeeb", "Seungyeon Kim", "Chien-Yu Lin", "Liang Luo", "Junjie Wang", "Carole-Jean Wu"], "title": "Hybrid Architectures for Language Models: Systematic Analysis and Design Insights", "comment": "17 pages, 4 figures, 6 tables; detailed results will be included in\n  the Appendix later", "summary": "Recent progress in large language models demonstrates that hybrid\narchitectures--combining self-attention mechanisms with structured state space\nmodels like Mamba--can achieve a compelling balance between modeling quality\nand computational efficiency, particularly for long-context tasks. While these\nhybrid models show promising performance, systematic comparisons of\nhybridization strategies and analyses on the key factors behind their\neffectiveness have not been clearly shared to the community. In this work, we\npresent a holistic evaluation of hybrid architectures based on inter-layer\n(sequential) or intra-layer (parallel) fusion. We evaluate these designs from a\nvariety of perspectives: language modeling performance, long-context\ncapabilities, scaling analysis, and training and inference efficiency. By\ninvestigating the core characteristics of their computational primitive, we\nidentify the most critical elements for each hybridization strategy and further\npropose optimal design recipes for both hybrid models. Our comprehensive\nanalysis provides practical guidance and valuable insights for developing\nhybrid language models, facilitating the optimization of architectural\nconfigurations.", "AI": {"tldr": "\u5bf9\u57fa\u4e8e\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u7ed3\u6784\u5316\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08\u5982Mamba\uff09\u7684\u6df7\u5408\u67b6\u6784\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff0c\u6bd4\u8f83\u4e86\u5c42\u95f4\uff08\u987a\u5e8f\uff09\u548c\u5c42\u5185\uff08\u5e76\u884c\uff09\u878d\u5408\u7b56\u7565\uff0c\u5206\u6790\u4e86\u5f71\u54cd\u6df7\u5408\u6a21\u578b\u6709\u6548\u6027\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5e76\u63d0\u51fa\u4e86\u6700\u4f18\u8bbe\u8ba1\u65b9\u6cd5\u3002", "motivation": "\u867d\u7136\u6df7\u5408\u67b6\u6784\u5728\u5efa\u6a21\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u6df7\u5408\u7b56\u7565\u7684\u7cfb\u7edf\u6bd4\u8f83\u548c\u6709\u6548\u6027\u5173\u952e\u56e0\u7d20\u7684\u5206\u6790\uff0c\u9700\u8981\u4e3a\u6df7\u5408\u8bed\u8a00\u6a21\u578b\u7684\u5f00\u53d1\u63d0\u4f9b\u5b9e\u8df5\u6307\u5bfc\u3002", "method": "\u4ece\u8bed\u8a00\u5efa\u6a21\u6027\u80fd\u3001\u957f\u4e0a\u4e0b\u6587\u80fd\u529b\u3001\u6269\u5c55\u5206\u6790\u4ee5\u53ca\u8bad\u7ec3\u548c\u63a8\u7406\u6548\u7387\u7b49\u591a\u4e2a\u89d2\u5ea6\uff0c\u8bc4\u4f30\u57fa\u4e8e\u5c42\u95f4\uff08\u987a\u5e8f\uff09\u6216\u5c42\u5185\uff08\u5e76\u884c\uff09\u878d\u5408\u7684\u6df7\u5408\u67b6\u6784\u8bbe\u8ba1\u3002", "result": "\u901a\u8fc7\u7814\u7a76\u8ba1\u7b97\u539f\u8bed\u7684\u6838\u5fc3\u7279\u5f81\uff0c\u8bc6\u522b\u4e86\u6bcf\u79cd\u6df7\u5408\u7b56\u7565\u7684\u6700\u5173\u952e\u5143\u7d20\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u6df7\u5408\u6a21\u578b\u7684\u6700\u4f18\u8bbe\u8ba1\u65b9\u6cd5\u3002", "conclusion": "\u7efc\u5408\u5206\u6790\u4e3a\u5f00\u53d1\u6df7\u5408\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6307\u5bfc\u548c\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u4f18\u5316\u67b6\u6784\u914d\u7f6e\u3002"}}
{"id": "2510.04832", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04832", "abs": "https://arxiv.org/abs/2510.04832", "authors": ["Christopher Bartley", "Anton Ragni"], "title": "How I Built ASR for Endangered Languages with a Spoken Dictionary", "comment": null, "summary": "Nearly half of the world's languages are endangered. Speech technologies such\nas Automatic Speech Recognition (ASR) are central to revival efforts, yet most\nlanguages remain unsupported because standard pipelines expect utterance-level\nsupervised data. Speech data often exist for endangered languages but rarely\nmatch these formats. Manx Gaelic ($\\sim$2,200 speakers), for example, has had\ntranscribed speech since 1948, yet remains unsupported by modern systems. In\nthis paper, we explore how little data, and in what form, is needed to build\nASR for critically endangered languages. We show that a short-form\npronunciation resource is a viable alternative, and that 40 minutes of such\ndata produces usable ASR for Manx ($<$50\\% WER). We replicate our approach,\napplying it to Cornish ($\\sim$600 speakers), another critically endangered\nlanguage. Results show that the barrier to entry, in quantity and form, is far\nlower than previously thought, giving hope to endangered language communities\nthat cannot afford to meet the requirements arbitrarily imposed upon them.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u662f\u6fd2\u5371\u8bed\u8a00\uff0c\u4ec5\u9700\u5c11\u91cf\u53d1\u97f3\u6570\u636e\uff08\u598240\u5206\u949f\uff09\u5373\u53ef\u6784\u5efa\u53ef\u7528\u7684\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\uff0c\u6253\u7834\u4e86\u4f20\u7edfASR\u5bf9\u5927\u91cf\u6807\u6ce8\u6570\u636e\u7684\u8981\u6c42\u3002", "motivation": "\u5168\u7403\u8fd1\u4e00\u534a\u8bed\u8a00\u6fd2\u4e34\u706d\u7edd\uff0c\u4f20\u7edfASR\u7cfb\u7edf\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u800c\u6fd2\u5371\u8bed\u8a00\u5f80\u5f80\u7f3a\u4e4f\u8fd9\u79cd\u8d44\u6e90\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u6784\u5efa\u6fd2\u5371\u8bed\u8a00ASR\u6240\u9700\u7684\u6700\u5c0f\u6570\u636e\u91cf\u548c\u6570\u636e\u5f62\u5f0f\u3002", "method": "\u4f7f\u7528\u77ed\u683c\u5f0f\u53d1\u97f3\u8d44\u6e90\u4f5c\u4e3a\u66ff\u4ee3\u65b9\u6848\uff0c\u5728\u66fc\u514b\u65af\u76d6\u5c14\u8bed\u548c\u5eb7\u6c83\u5c14\u8bed\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u5c11\u91cf\u6570\u636e\u6784\u5efaASR\u7684\u53ef\u884c\u6027\u3002", "result": "\u4ec5\u752840\u5206\u949f\u7684\u53d1\u97f3\u6570\u636e\u5373\u53ef\u4e3a\u66fc\u514b\u65af\u76d6\u5c14\u8bed\u6784\u5efa\u53ef\u7528\u7684ASR\u7cfb\u7edf\uff08\u8bcd\u9519\u8bef\u7387<50%\uff09\uff0c\u5e76\u5728\u5eb7\u6c83\u5c14\u8bed\u4e0a\u6210\u529f\u590d\u73b0\u8be5\u65b9\u6cd5\u3002", "conclusion": "\u6784\u5efa\u6fd2\u5371\u8bed\u8a00ASR\u7cfb\u7edf\u7684\u6570\u636e\u95e8\u69db\u8fdc\u4f4e\u4e8e\u4f20\u7edf\u8ba4\u77e5\uff0c\u4e3a\u65e0\u6cd5\u6ee1\u8db3\u4f20\u7edf\u6570\u636e\u8981\u6c42\u7684\u6fd2\u5371\u8bed\u8a00\u793e\u533a\u5e26\u6765\u4e86\u5e0c\u671b\u3002"}}
{"id": "2510.04848", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04848", "abs": "https://arxiv.org/abs/2510.04848", "authors": ["Yuto Nishida", "Masaru Isonuma", "Yusuke Oda"], "title": "Instability in Downstream Task Performance During LLM Pretraining", "comment": "Accepted to EMNLP 2025 Findings", "summary": "When training large language models (LLMs), it is common practice to track\ndownstream task performance throughout the training process and select the\ncheckpoint with the highest validation score. However, downstream metrics often\nexhibit substantial fluctuations, making it difficult to identify the\ncheckpoint that truly represents the best-performing model. In this study, we\nempirically analyze the stability of downstream task performance in an LLM\ntrained on diverse web-scale corpora. We find that task scores frequently\nfluctuate throughout training, both at the aggregate and example levels. To\naddress this instability, we investigate two post-hoc checkpoint integration\nmethods: checkpoint averaging and ensemble, motivated by the hypothesis that\naggregating neighboring checkpoints can reduce performance volatility. We\ndemonstrate both empirically and theoretically that these methods improve\ndownstream performance stability without requiring any changes to the training\nprocedure.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u7684\u6ce2\u52a8\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u901a\u8fc7\u68c0\u67e5\u70b9\u5e73\u5747\u548c\u96c6\u6210\u7684\u65b9\u6cd5\u6765\u7a33\u5b9a\u6027\u80fd\uff0c\u65e0\u9700\u6539\u53d8\u8bad\u7ec3\u8fc7\u7a0b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u65f6\uff0c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u7ecf\u5e38\u51fa\u73b0\u663e\u8457\u6ce2\u52a8\uff0c\u4f7f\u5f97\u96be\u4ee5\u786e\u5b9a\u771f\u6b63\u8868\u73b0\u6700\u4f73\u7684\u68c0\u67e5\u70b9\u3002", "method": "\u7814\u7a76\u4e86\u4e24\u79cd\u68c0\u67e5\u70b9\u96c6\u6210\u65b9\u6cd5\uff1a\u68c0\u67e5\u70b9\u5e73\u5747\u548c\u96c6\u6210\uff0c\u901a\u8fc7\u805a\u5408\u76f8\u90bb\u68c0\u67e5\u70b9\u6765\u51cf\u5c11\u6027\u80fd\u6ce2\u52a8\u3002", "result": "\u5b9e\u8bc1\u548c\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u80fd\u591f\u63d0\u9ad8\u4e0b\u6e38\u6027\u80fd\u7684\u7a33\u5b9a\u6027\u3002", "conclusion": "\u68c0\u67e5\u70b9\u96c6\u6210\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u6027\u80fd\u6ce2\u52a8\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u9009\u62e9\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2510.04849", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.04849", "abs": "https://arxiv.org/abs/2510.04849", "authors": ["Elisei Rykov", "Kseniia Petrushina", "Maksim Savkin", "Valerii Olisov", "Artem Vazhentsev", "Kseniia Titova", "Alexander Panchenko", "Vasily Konovalov", "Julia Belikova"], "title": "When Models Lie, We Learn: Multilingual Span-Level Hallucination Detection with PsiloQA", "comment": null, "summary": "Hallucination detection remains a fundamental challenge for the safe and\nreliable deployment of large language models (LLMs), especially in applications\nrequiring factual accuracy. Existing hallucination benchmarks often operate at\nthe sequence level and are limited to English, lacking the fine-grained,\nmultilingual supervision needed for a comprehensive evaluation. In this work,\nwe introduce PsiloQA, a large-scale, multilingual dataset annotated with\nspan-level hallucinations across 14 languages. PsiloQA is constructed through\nan automated three-stage pipeline: generating question-answer pairs from\nWikipedia using GPT-4o, eliciting potentially hallucinated answers from diverse\nLLMs in a no-context setting, and automatically annotating hallucinated spans\nusing GPT-4o by comparing against golden answers and retrieved context. We\nevaluate a wide range of hallucination detection methods -- including\nuncertainty quantification, LLM-based tagging, and fine-tuned encoder models --\nand show that encoder-based models achieve the strongest performance across\nlanguages. Furthermore, PsiloQA demonstrates effective cross-lingual\ngeneralization and supports robust knowledge transfer to other benchmarks, all\nwhile being significantly more cost-efficient than human-annotated datasets.\nOur dataset and results advance the development of scalable, fine-grained\nhallucination detection in multilingual settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86PsiloQA\uff0c\u4e00\u4e2a\u5927\u89c4\u6a21\u591a\u8bed\u8a00\u6570\u636e\u96c6\uff0c\u5305\u542b14\u79cd\u8bed\u8a00\u7684\u8de8\u5ea6\u7ea7\u5e7b\u89c9\u6807\u6ce8\uff0c\u7528\u4e8e\u8bc4\u4f30\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5e7b\u89c9\u57fa\u51c6\u4e3b\u8981\u5728\u5e8f\u5217\u7ea7\u522b\u4e14\u9650\u4e8e\u82f1\u8bed\uff0c\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u7684\u591a\u8bed\u8a00\u76d1\u7763\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30LLMs\u7684\u5e7b\u89c9\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u81ea\u52a8\u5316\u4e09\u9636\u6bb5\u6d41\u7a0b\u6784\u5efa\u6570\u636e\u96c6\uff1a\u4f7f\u7528GPT-4o\u4ece\u7ef4\u57fa\u767e\u79d1\u751f\u6210\u95ee\u7b54\u5bf9\uff0c\u5728\u65e0\u4e0a\u4e0b\u6587\u8bbe\u7f6e\u4e0b\u4ece\u591a\u6837\u5316LLMs\u83b7\u53d6\u6f5c\u5728\u5e7b\u89c9\u7b54\u6848\uff0c\u4f7f\u7528GPT-4o\u901a\u8fc7\u5bf9\u6bd4\u9ec4\u91d1\u7b54\u6848\u548c\u68c0\u7d22\u4e0a\u4e0b\u6587\u81ea\u52a8\u6807\u6ce8\u5e7b\u89c9\u8de8\u5ea6\u3002", "result": "\u8bc4\u4f30\u4e86\u591a\u79cd\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u53d1\u73b0\u57fa\u4e8e\u7f16\u7801\u5668\u7684\u6a21\u578b\u5728\u6240\u6709\u8bed\u8a00\u4e2d\u8868\u73b0\u6700\u5f3a\uff0cPsiloQA\u5c55\u793a\u4e86\u6709\u6548\u7684\u8de8\u8bed\u8a00\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u80fd\u7a33\u5065\u5730\u8fc1\u79fb\u5230\u5176\u4ed6\u57fa\u51c6\u3002", "conclusion": "PsiloQA\u6570\u636e\u96c6\u548c\u7ed3\u679c\u63a8\u52a8\u4e86\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u53ef\u6269\u5c55\u3001\u7ec6\u7c92\u5ea6\u5e7b\u89c9\u68c0\u6d4b\u7684\u53d1\u5c55\uff0c\u76f8\u6bd4\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\u66f4\u5177\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2510.04850", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04850", "abs": "https://arxiv.org/abs/2510.04850", "authors": ["Hengxiang Zhang", "Hyeong Kyu Choi", "Yixuan Li", "Hongxin Wei"], "title": "Detecting Distillation Data from Reasoning Models", "comment": null, "summary": "Reasoning distillation has emerged as an efficient and powerful paradigm for\nenhancing the reasoning capabilities of large language models. However,\nreasoning distillation may inadvertently cause benchmark contamination, where\nevaluation data included in distillation datasets can inflate performance\nmetrics of distilled models. In this work, we formally define the task of\ndistillation data detection, which is uniquely challenging due to the partial\navailability of distillation data. Then, we propose a novel and effective\nmethod Token Probability Deviation (TBD), which leverages the probability\npatterns of the generated output tokens. Our method is motivated by the\nanalysis that distilled models tend to generate near-deterministic tokens for\nseen questions, while producing more low-probability tokens for unseen\nquestions. Our key idea behind TBD is to quantify how far the generated tokens'\nprobabilities deviate from a high reference probability. In effect, our method\nachieves competitive detection performance by producing lower scores for seen\nquestions than for unseen questions. Extensive experiments demonstrate the\neffectiveness of our method, achieving an AUC of 0.918 and a TPR@1% FPR of\n0.470 on the S1 dataset.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aToken Probability Deviation (TBD)\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u63a8\u7406\u84b8\u998f\u8fc7\u7a0b\u4e2d\u7684\u6570\u636e\u6c61\u67d3\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u6790\u751f\u6210token\u7684\u6982\u7387\u504f\u5dee\u6765\u533a\u5206\u5df2\u89c1\u8fc7\u548c\u672a\u89c1\u8fc7\u7684\u6570\u636e\u3002", "motivation": "\u63a8\u7406\u84b8\u998f\u53ef\u80fd\u65e0\u610f\u4e2d\u5bfc\u81f4\u57fa\u51c6\u6c61\u67d3\uff0c\u8bc4\u4f30\u6570\u636e\u5305\u542b\u5728\u84b8\u998f\u6570\u636e\u96c6\u4e2d\u4f1a\u5938\u5927\u84b8\u998f\u6a21\u578b\u7684\u6027\u80fd\u6307\u6807\uff0c\u9700\u8981\u68c0\u6d4b\u8fd9\u79cd\u6570\u636e\u6c61\u67d3\u3002", "method": "\u63d0\u51faToken Probability Deviation (TBD)\u65b9\u6cd5\uff0c\u5229\u7528\u751f\u6210\u8f93\u51fatoken\u7684\u6982\u7387\u6a21\u5f0f\uff0c\u91cf\u5316\u751f\u6210token\u6982\u7387\u4e0e\u9ad8\u53c2\u8003\u6982\u7387\u7684\u504f\u5dee\u7a0b\u5ea6\u3002", "result": "\u5728S1\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e860.918\u7684AUC\u548c0.470\u7684TPR@1% FPR\uff0c\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u68c0\u6d4b\u6027\u80fd\u3002", "conclusion": "TBD\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4b\u63a8\u7406\u84b8\u998f\u4e2d\u7684\u6570\u636e\u6c61\u67d3\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u6790token\u6982\u7387\u504f\u5dee\u6765\u533a\u5206\u5df2\u89c1\u548c\u672a\u89c1\u6570\u636e\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.04891", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04891", "abs": "https://arxiv.org/abs/2510.04891", "authors": ["Punya Syon Pandey", "Hai Son Le", "Devansh Bhardwaj", "Rada Mihalcea", "Zhijing Jin"], "title": "SocialHarmBench: Revealing LLM Vulnerabilities to Socially Harmful Requests", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed in contexts where\ntheir failures can have direct sociopolitical consequences. Yet, existing\nsafety benchmarks rarely test vulnerabilities in domains such as political\nmanipulation, propaganda and disinformation generation, or surveillance and\ninformation control. We introduce SocialHarmBench, a dataset of 585 prompts\nspanning 7 sociopolitical categories and 34 countries, designed to surface\nwhere LLMs most acutely fail in politically charged contexts. Our evaluations\nreveal several shortcomings: open-weight models exhibit high vulnerability to\nharmful compliance, with Mistral-7B reaching attack success rates as high as\n97% to 98% in domains such as historical revisionism, propaganda, and political\nmanipulation. Moreover, temporal and geographic analyses show that LLMs are\nmost fragile when confronted with 21st-century or pre-20th-century contexts,\nand when responding to prompts tied to regions such as Latin America, the USA,\nand the UK. These findings demonstrate that current safeguards fail to\ngeneralize to high-stakes sociopolitical settings, exposing systematic biases\nand raising concerns about the reliability of LLMs in preserving human rights\nand democratic values. We share the SocialHarmBench benchmark at\nhttps://huggingface.co/datasets/psyonp/SocialHarmBench.", "AI": {"tldr": "SocialHarmBench\u662f\u4e00\u4e2a\u5305\u542b585\u4e2a\u63d0\u793a\u7684\u6570\u636e\u96c6\uff0c\u6db5\u76d67\u4e2a\u793e\u4f1a\u653f\u6cbb\u7c7b\u522b\u548c34\u4e2a\u56fd\u5bb6\uff0c\u7528\u4e8e\u6d4b\u8bd5LLM\u5728\u653f\u6cbb\u654f\u611f\u60c5\u5883\u4e2d\u7684\u8106\u5f31\u6027\u3002\u7814\u7a76\u53d1\u73b0\u5f00\u6e90\u6a21\u578b\u5728\u6709\u5bb3\u5408\u89c4\u65b9\u9762\u5b58\u5728\u9ad8\u98ce\u9669\uff0cMistral-7B\u5728\u5386\u53f2\u4fee\u6b63\u4e3b\u4e49\u3001\u5ba3\u4f20\u548c\u653f\u6cbb\u64cd\u7eb5\u7b49\u9886\u57df\u7684\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe97%-98%\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u57fa\u51c6\u5f88\u5c11\u6d4b\u8bd5LLM\u5728\u653f\u6cbb\u64cd\u7eb5\u3001\u5ba3\u4f20\u548c\u865a\u5047\u4fe1\u606f\u751f\u6210\u3001\u76d1\u63a7\u548c\u4fe1\u606f\u63a7\u5236\u7b49\u9886\u57df\u7684\u6f0f\u6d1e\uff0c\u800c\u8fd9\u4e9b\u5931\u8d25\u53ef\u80fd\u4ea7\u751f\u76f4\u63a5\u7684\u793e\u4f1a\u653f\u6cbb\u540e\u679c\u3002", "method": "\u6784\u5efaSocialHarmBench\u6570\u636e\u96c6\uff0c\u5305\u542b585\u4e2a\u63d0\u793a\uff0c\u6db5\u76d67\u4e2a\u793e\u4f1a\u653f\u6cbb\u7c7b\u522b\u548c34\u4e2a\u56fd\u5bb6\uff0c\u8bc4\u4f30LLM\u5728\u653f\u6cbb\u654f\u611f\u60c5\u5883\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5f00\u6e90\u6a21\u578b\u5bf9\u6709\u5bb3\u5408\u89c4\u8868\u73b0\u51fa\u9ad8\u8106\u5f31\u6027\uff0cMistral-7B\u5728\u5386\u53f2\u4fee\u6b63\u4e3b\u4e49\u3001\u5ba3\u4f20\u548c\u653f\u6cbb\u64cd\u7eb5\u9886\u57df\u7684\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe97%-98%\u3002\u65f6\u95f4\u5730\u7406\u5206\u6790\u663e\u793aLLM\u572821\u4e16\u7eaa\u548c\u524d20\u4e16\u7eaa\u60c5\u5883\u4e0b\u6700\u8106\u5f31\uff0c\u5bf9\u62c9\u4e01\u7f8e\u6d32\u3001\u7f8e\u56fd\u548c\u82f1\u56fd\u76f8\u5173\u63d0\u793a\u54cd\u5e94\u95ee\u9898\u6700\u591a\u3002", "conclusion": "\u5f53\u524d\u7684\u5b89\u5168\u63aa\u65bd\u65e0\u6cd5\u63a8\u5e7f\u5230\u9ad8\u98ce\u9669\u793e\u4f1a\u653f\u6cbb\u73af\u5883\u4e2d\uff0c\u66b4\u9732\u4e86\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u5f15\u53d1\u4e86\u5bf9LLM\u5728\u4fdd\u62a4\u4eba\u6743\u548c\u6c11\u4e3b\u4ef7\u503c\u89c2\u65b9\u9762\u53ef\u9760\u6027\u7684\u62c5\u5fe7\u3002"}}
{"id": "2510.04919", "categories": ["cs.CL", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.04919", "abs": "https://arxiv.org/abs/2510.04919", "authors": ["Davood Rafiei", "Morgan Lindsay Heisler", "Weiwei Zhang", "Mohammadreza Pourreza", "Yong Zhang"], "title": "Do LLMs Align with My Task? Evaluating Text-to-SQL via Dataset Alignment", "comment": null, "summary": "Supervised Fine-Tuning (SFT) is an effective method for adapting Large\nLanguage Models (LLMs) on downstream tasks. However, variability in training\ndata can hinder a model's ability to generalize across domains. This paper\nstudies the problem of dataset alignment for Natural Language to SQL (NL2SQL or\ntext to SQL), examining how well SFT training data matches the structural\ncharacteristics of target queries and how this alignment impacts model\nperformance. We hypothesize that alignment can be accurately estimated by\ncomparing the distributions of structural SQL features across the training set,\ntarget data, and the model's predictions prior to SFT. Through comprehensive\nexperiments on three large cross-domain NL2SQL benchmarks and multiple model\nfamilies, we show that structural alignment is a strong predictor of\nfine-tuning success. When alignment is high, SFT yields substantial gains in\naccuracy and SQL generation quality; when alignment is low, improvements are\nmarginal or absent. These findings highlight the importance of alignment-aware\ndata selection for effective fine-tuning and generalization in NL2SQL tasks.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86NL2SQL\u4efb\u52a1\u4e2d\u8bad\u7ec3\u6570\u636e\u4e0e\u76ee\u6807\u67e5\u8be2\u7684\u7ed3\u6784\u5bf9\u9f50\u95ee\u9898\uff0c\u53d1\u73b0\u7ed3\u6784\u5bf9\u9f50\u662f\u9884\u6d4b\u5fae\u8c03\u6210\u529f\u7684\u5173\u952e\u6307\u6807\u3002", "motivation": "\u76d1\u7763\u5fae\u8c03(SFT)\u5728\u9002\u5e94\u5927\u8bed\u8a00\u6a21\u578b\u5230\u4e0b\u6e38\u4efb\u52a1\u65f6\u6709\u6548\uff0c\u4f46\u8bad\u7ec3\u6570\u636e\u7684\u53d8\u5f02\u6027\u4f1a\u963b\u788d\u6a21\u578b\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83\u8bad\u7ec3\u96c6\u3001\u76ee\u6807\u6570\u636e\u548c\u6a21\u578b\u9884\u6d4b\u4e2dSQL\u7ed3\u6784\u7279\u5f81\u7684\u5206\u5e03\u6765\u4f30\u8ba1\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u5e76\u5728\u4e09\u4e2a\u5927\u578b\u8de8\u9886\u57dfNL2SQL\u57fa\u51c6\u548c\u591a\u4e2a\u6a21\u578b\u5bb6\u65cf\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u7ed3\u6784\u5bf9\u9f50\u662f\u5fae\u8c03\u6210\u529f\u7684\u5f3a\u9884\u6d4b\u56e0\u5b50\uff1a\u5bf9\u9f50\u5ea6\u9ad8\u65f6SFT\u5e26\u6765\u663e\u8457\u7684\u51c6\u786e\u6027\u548cSQL\u751f\u6210\u8d28\u91cf\u63d0\u5347\uff1b\u5bf9\u9f50\u5ea6\u4f4e\u65f6\u6539\u8fdb\u6709\u9650\u6216\u6ca1\u6709\u6539\u8fdb\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u5f3a\u8c03\u4e86\u5728NL2SQL\u4efb\u52a1\u4e2d\u91c7\u7528\u5bf9\u9f50\u611f\u77e5\u7684\u6570\u636e\u9009\u62e9\u5bf9\u4e8e\u6709\u6548\u5fae\u8c03\u548c\u6cdb\u5316\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.04933", "categories": ["cs.CL", "cs.AI", "cs.IT", "cs.LG", "cs.NE", "math.IT", "68T50, 68T07, 62H30", "I.2.7; I.2.6; F.2.2; H.3.3"], "pdf": "https://arxiv.org/pdf/2510.04933", "abs": "https://arxiv.org/abs/2510.04933", "authors": ["Amir Hameed Mir"], "title": "The Geometry of Truth: Layer-wise Semantic Dynamics for Hallucination Detection in Large Language Models", "comment": "Comments: 14 pages, 14 figures, 5 tables. Code available at:\n  https://github.com/sirraya-tech/Sirraya_LSD_Code", "summary": "Large Language Models (LLMs) often produce fluent yet factually incorrect\nstatements-a phenomenon known as hallucination-posing serious risks in\nhigh-stakes domains. We present Layer-wise Semantic Dynamics (LSD), a geometric\nframework for hallucination detection that analyzes the evolution of\nhidden-state semantics across transformer layers. Unlike prior methods that\nrely on multiple sampling passes or external verification sources, LSD operates\nintrinsically within the model's representational space. Using margin-based\ncontrastive learning, LSD aligns hidden activations with ground-truth\nembeddings derived from a factual encoder, revealing a distinct separation in\nsemantic trajectories: factual responses preserve stable alignment, while\nhallucinations exhibit pronounced semantic drift across depth. Evaluated on the\nTruthfulQA and synthetic factual-hallucination datasets, LSD achieves an\nF1-score of 0.92, AUROC of 0.96, and clustering accuracy of 0.89, outperforming\nSelfCheckGPT and Semantic Entropy baselines while requiring only a single\nforward pass. This efficiency yields a 5-20x speedup over sampling-based\nmethods without sacrificing precision or interpretability. LSD offers a\nscalable, model-agnostic mechanism for real-time hallucination monitoring and\nprovides new insights into the geometry of factual consistency within large\nlanguage models.", "AI": {"tldr": "LSD\u662f\u4e00\u79cd\u57fa\u4e8e\u51e0\u4f55\u6846\u67b6\u7684\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790transformer\u5c42\u95f4\u9690\u85cf\u72b6\u6001\u8bed\u4e49\u7684\u6f14\u53d8\u6765\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u73b0\u8c61\uff0c\u65e0\u9700\u591a\u6b21\u91c7\u6837\u6216\u5916\u90e8\u9a8c\u8bc1\uff0c\u4ec5\u9700\u5355\u6b21\u524d\u5411\u4f20\u64ad\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u68c0\u6d4b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7ecf\u5e38\u4ea7\u751f\u6d41\u7545\u4f46\u4e8b\u5b9e\u9519\u8bef\u7684\u9648\u8ff0\uff08\u5e7b\u89c9\u73b0\u8c61\uff09\uff0c\u8fd9\u5728\u9ad8\u98ce\u9669\u9886\u57df\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u9700\u8981\u5f00\u53d1\u5185\u5728\u7684\u68c0\u6d4b\u65b9\u6cd5\u6765\u8bc6\u522b\u8fd9\u4e9b\u5e7b\u89c9\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u8fb9\u7f18\u7684\u5bf9\u6bd4\u5b66\u4e60\uff0c\u5c06\u9690\u85cf\u6fc0\u6d3b\u4e0e\u4e8b\u5b9e\u7f16\u7801\u5668\u751f\u6210\u7684ground-truth\u5d4c\u5165\u5bf9\u9f50\uff0c\u5206\u6790\u8bed\u4e49\u8f68\u8ff9\u7684\u5206\u79bb\uff1a\u4e8b\u5b9e\u54cd\u5e94\u4fdd\u6301\u7a33\u5b9a\u5bf9\u9f50\uff0c\u800c\u5e7b\u89c9\u5728\u4e0d\u540c\u6df1\u5ea6\u8868\u73b0\u51fa\u660e\u663e\u7684\u8bed\u4e49\u6f02\u79fb\u3002", "result": "\u5728TruthfulQA\u548c\u5408\u6210\u4e8b\u5b9e-\u5e7b\u89c9\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cLSD\u8fbe\u5230F1\u5206\u65700.92\u3001AUROC 0.96\u548c\u805a\u7c7b\u51c6\u786e\u73870.89\uff0c\u4f18\u4e8eSelfCheckGPT\u548c\u8bed\u4e49\u71b5\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u5b9e\u73b05-20\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "LSD\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u6a21\u578b\u65e0\u5173\u7684\u5b9e\u65f6\u5e7b\u89c9\u76d1\u6d4b\u673a\u5236\uff0c\u5e76\u4e3a\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u4e8b\u5b9e\u4e00\u81f4\u6027\u7684\u51e0\u4f55\u7279\u6027\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2510.04945", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.04945", "abs": "https://arxiv.org/abs/2510.04945", "authors": ["Juan-Jos\u00e9 Guzm\u00e1n-Landa", "Juan-Manuel Torres-Moreno", "Miguel Figueroa-Saavedra", "Ligia Quintana-Torres", "Martha-Lorena Avenda\u00f1o-Garrido", "Graham Ranger"], "title": "A First Context-Free Grammar Applied to Nawatl Corpora Augmentation", "comment": "11 pages, 7 tables, 1 figure", "summary": "In this article we introduce a context-free grammar (CFG) for the Nawatl\nlanguage. Nawatl (or Nahuatl) is an Amerindian language of the $\\pi$-language\ntype, i.e. a language with few digital resources, in which the corpora\navailable for machine learning are virtually non-existent. The objective here\nis to generate a significant number of grammatically correct artificial\nsentences, in order to increase the corpora available for language model\ntraining. We want to show that a grammar enables us significantly to expand a\ncorpus in Nawatl which we call $\\pi$-\\textsc{yalli}. The corpus, thus enriched,\nenables us to train algorithms such as FastText and to evaluate them on\nsentence-level semantic tasks. Preliminary results show that by using the\ngrammar, comparative improvements are achieved over some LLMs. However, it is\nobserved that to achieve more significant improvement, grammars that model the\nNawatl language even more effectively are required.", "AI": {"tldr": "\u4e3a\u7eb3\u74e6\u7279\u5c14\u8bed\u5f00\u53d1\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u6cd5\u4ee5\u751f\u6210\u4eba\u5de5\u53e5\u5b50\uff0c\u6269\u5145\u8bed\u6599\u5e93\u7528\u4e8e\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\uff0c\u521d\u6b65\u7ed3\u679c\u663e\u793a\u76f8\u6bd4\u67d0\u4e9bLLM\u6709\u6539\u8fdb\uff0c\u4f46\u9700\u8981\u66f4\u6709\u6548\u7684\u8bed\u6cd5\u6a21\u578b\u3002", "motivation": "\u7eb3\u74e6\u7279\u5c14\u8bed\u662f\u6570\u5b57\u8d44\u6e90\u7a00\u5c11\u7684\u03c0\u8bed\u8a00\u7c7b\u578b\uff0c\u7f3a\u4e4f\u673a\u5668\u5b66\u4e60\u53ef\u7528\u7684\u8bed\u6599\u5e93\uff0c\u9700\u8981\u751f\u6210\u5927\u91cf\u8bed\u6cd5\u6b63\u786e\u7684\u4eba\u5de5\u53e5\u5b50\u6765\u6269\u5145\u8bad\u7ec3\u6570\u636e\u3002", "method": "\u4e3a\u7eb3\u74e6\u7279\u5c14\u8bed\u6784\u5efa\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u6cd5(CFG)\uff0c\u751f\u6210\u4eba\u5de5\u53e5\u5b50\u6765\u6269\u5c55\u03c0-yalli\u8bed\u6599\u5e93\uff0c\u7136\u540e\u4f7f\u7528FastText\u7b49\u7b97\u6cd5\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u901a\u8fc7\u8bed\u6cd5\u751f\u6210\u53e5\u5b50\u6269\u5145\u8bed\u6599\u5e93\u540e\uff0c\u5728\u53e5\u5b50\u7ea7\u8bed\u4e49\u4efb\u52a1\u4e0a\u76f8\u6bd4\u67d0\u4e9b\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u53d6\u5f97\u4e86\u6bd4\u8f83\u6027\u6539\u8fdb\u3002", "conclusion": "\u4f7f\u7528\u8bed\u6cd5\u53ef\u4ee5\u6269\u5c55\u8bed\u6599\u5e93\u5e76\u6539\u5584\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u8981\u83b7\u5f97\u66f4\u663e\u8457\u7684\u6539\u8fdb\uff0c\u9700\u8981\u6784\u5efa\u66f4\u6709\u6548\u7684\u7eb3\u74e6\u7279\u5c14\u8bed\u8bed\u6cd5\u6a21\u578b\u3002"}}
{"id": "2510.04950", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.04950", "abs": "https://arxiv.org/abs/2510.04950", "authors": ["Om Dobariya", "Akhil Kumar"], "title": "Mind Your Tone: Investigating How Prompt Politeness Affects LLM Accuracy (short paper)", "comment": "5 pages, 3 tables; includes Limitations and Ethical Considerations\n  sections; short paper under submission to Findings of ACL 2025", "summary": "The wording of natural language prompts has been shown to influence the\nperformance of large language models (LLMs), yet the role of politeness and\ntone remains underexplored. In this study, we investigate how varying levels of\nprompt politeness affect model accuracy on multiple-choice questions. We\ncreated a dataset of 50 base questions spanning mathematics, science, and\nhistory, each rewritten into five tone variants: Very Polite, Polite, Neutral,\nRude, and Very Rude, yielding 250 unique prompts. Using ChatGPT 4o, we\nevaluated responses across these conditions and applied paired sample t-tests\nto assess statistical significance. Contrary to expectations, impolite prompts\nconsistently outperformed polite ones, with accuracy ranging from 80.8% for\nVery Polite prompts to 84.8% for Very Rude prompts. These findings differ from\nearlier studies that associated rudeness with poorer outcomes, suggesting that\nnewer LLMs may respond differently to tonal variation. Our results highlight\nthe importance of studying pragmatic aspects of prompting and raise broader\nquestions about the social dimensions of human-AI interaction.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u4e0d\u793c\u8c8c\u7684\u63d0\u793a\u8bcd\u6bd4\u793c\u8c8c\u63d0\u793a\u8bcd\u5728LLM\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u51c6\u786e\u7387\u4ece\u975e\u5e38\u793c\u8c8c\u768480.8%\u63d0\u5347\u5230\u975e\u5e38\u7c97\u9c81\u768484.8%\uff0c\u4e0e\u4f20\u7edf\u8ba4\u77e5\u76f8\u53cd\u3002", "motivation": "\u63a2\u7d22\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u4e2d\u793c\u8c8c\u7a0b\u5ea6\u548c\u8bed\u6c14\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u591a\u9009\u95ee\u9898\u4e2d\u7684\u51c6\u786e\u6027\u3002", "method": "\u521b\u5efa50\u4e2a\u57fa\u7840\u95ee\u9898\uff0c\u6bcf\u4e2a\u95ee\u9898\u91cd\u5199\u4e3a5\u79cd\u8bed\u6c14\u53d8\u4f53\uff08\u975e\u5e38\u793c\u8c8c\u3001\u793c\u8c8c\u3001\u4e2d\u6027\u3001\u7c97\u9c81\u3001\u975e\u5e38\u7c97\u9c81\uff09\uff0c\u4f7f\u7528ChatGPT 4o\u8bc4\u4f30\u54cd\u5e94\uff0c\u5e76\u8fdb\u884c\u914d\u5bf9\u6837\u672ct\u68c0\u9a8c\u3002", "result": "\u4e0d\u793c\u8c8c\u63d0\u793a\u8bcd\u8868\u73b0\u4f18\u4e8e\u793c\u8c8c\u63d0\u793a\u8bcd\uff0c\u51c6\u786e\u7387\u4ece\u975e\u5e38\u793c\u8c8c\u768480.8%\u5230\u975e\u5e38\u7c97\u9c81\u768484.8%\uff0c\u4e0e\u65e9\u671f\u7814\u7a76\u7ed3\u679c\u76f8\u53cd\u3002", "conclusion": "\u65b0LLM\u5bf9\u8bed\u6c14\u53d8\u5316\u7684\u54cd\u5e94\u65b9\u5f0f\u53ef\u80fd\u4e0d\u540c\uff0c\u5f3a\u8c03\u7814\u7a76\u63d0\u793a\u8bed\u7528\u5b66\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5f15\u53d1\u5bf9\u4eba\u673a\u4ea4\u4e92\u793e\u4f1a\u7ef4\u5ea6\u7684\u601d\u8003\u3002"}}
{"id": "2510.04983", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.04983", "abs": "https://arxiv.org/abs/2510.04983", "authors": ["Khalid Mehtab Khan", "Anagha Kulkarni"], "title": "AWARE, Beyond Sentence Boundaries: A Contextual Transformer Framework for Identifying Cultural Capital in STEM Narratives", "comment": null, "summary": "Identifying cultural capital (CC) themes in student reflections can offer\nvaluable insights that help foster equitable learning environments in\nclassrooms. However, themes such as aspirational goals or family support are\noften woven into narratives, rather than appearing as direct keywords. This\nmakes them difficult to detect for standard NLP models that process sentences\nin isolation. The core challenge stems from a lack of awareness, as standard\nmodels are pre-trained on general corpora, leaving them blind to the\ndomain-specific language and narrative context inherent to the data. To address\nthis, we introduce AWARE, a framework that systematically attempts to improve a\ntransformer model's awareness for this nuanced task. AWARE has three core\ncomponents: 1) Domain Awareness, adapting the model's vocabulary to the\nlinguistic style of student reflections; 2) Context Awareness, generating\nsentence embeddings that are aware of the full essay context; and 3) Class\nOverlap Awareness, employing a multi-label strategy to recognize the\ncoexistence of themes in a single sentence. Our results show that by making the\nmodel explicitly aware of the properties of the input, AWARE outperforms a\nstrong baseline by 2.1 percentage points in Macro-F1 and shows considerable\nimprovements across all themes. This work provides a robust and generalizable\nmethodology for any text classification task in which meaning depends on the\ncontext of the narrative.", "AI": {"tldr": "AWARE\u6846\u67b6\u901a\u8fc7\u63d0\u5347Transformer\u6a21\u578b\u5728\u4e09\u4e2a\u65b9\u9762\u7684\u610f\u8bc6\uff08\u9886\u57df\u610f\u8bc6\u3001\u4e0a\u4e0b\u6587\u610f\u8bc6\u3001\u7c7b\u522b\u91cd\u53e0\u610f\u8bc6\uff09\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4ece\u5b66\u751f\u53cd\u601d\u4e2d\u8bc6\u522b\u6587\u5316\u8d44\u672c\u4e3b\u9898\u7684\u80fd\u529b\u3002", "motivation": "\u8bc6\u522b\u5b66\u751f\u53cd\u601d\u4e2d\u7684\u6587\u5316\u8d44\u672c\u4e3b\u9898\u6709\u52a9\u4e8e\u4fc3\u8fdb\u516c\u5e73\u5b66\u4e60\u73af\u5883\uff0c\u4f46\u8fd9\u4e9b\u4e3b\u9898\u901a\u5e38\u4ee5\u53d9\u4e8b\u65b9\u5f0f\u5448\u73b0\u800c\u975e\u76f4\u63a5\u5173\u952e\u8bcd\uff0c\u6807\u51c6NLP\u6a21\u578b\u96be\u4ee5\u68c0\u6d4b\u3002", "method": "\u63d0\u51faAWARE\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u9886\u57df\u610f\u8bc6\uff08\u9002\u5e94\u5b66\u751f\u53cd\u601d\u7684\u8bed\u8a00\u98ce\u683c\uff09\u3001\u4e0a\u4e0b\u6587\u610f\u8bc6\uff08\u751f\u6210\u8003\u8651\u5168\u6587\u7684\u53e5\u5b50\u5d4c\u5165\uff09\u3001\u7c7b\u522b\u91cd\u53e0\u610f\u8bc6\uff08\u91c7\u7528\u591a\u6807\u7b7e\u7b56\u7565\u8bc6\u522b\u4e3b\u9898\u5171\u5b58\uff09\u3002", "result": "AWARE\u5728Macro-F1\u4e0a\u6bd4\u5f3a\u57fa\u7ebf\u63d0\u9ad8\u4e862.1\u4e2a\u767e\u5206\u70b9\uff0c\u5728\u6240\u6709\u4e3b\u9898\u4e0a\u90fd\u663e\u793a\u51fa\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u4efb\u4f55\u4f9d\u8d56\u53d9\u4e8b\u4e0a\u4e0b\u6587\u7684\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u4e86\u7a33\u5065\u4e14\u53ef\u63a8\u5e7f\u7684\u65b9\u6cd5\u8bba\u3002"}}
{"id": "2510.05003", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05003", "abs": "https://arxiv.org/abs/2510.05003", "authors": ["Imran Mansha"], "title": "Resource-Efficient Fine-Tuning of LLaMA-3.2-3B for Medical Chain-of-Thought Reasoning", "comment": "6 pages, 2 figures. Submitted to arXiv for open access", "summary": "Large Language Models (LLMs) such as GPT-4 and LLaMA have demonstrated\nremarkable reasoning abilities but require significant computational resources\nfor fine-tuning. This paper presents a resource-efficient fine-tuning approach\nfor LLaMA-3.2-3B to enhance medical chain-of-thought reasoning while operating\nunder constrained GPU and memory settings. Using parameter-efficient tuning\ntechniques such as LoRA and QLoRA, we adapt the base model on publicly\navailable medical reasoning datasets. The model achieves improved reasoning\ncoherence and factual accuracy while reducing memory usage by up to 60%\ncompared to standard full fine-tuning. Experimental evaluation demonstrates\nthat lightweight adaptations can retain strong reasoning capability in medical\nquestion-answering tasks. This work highlights practical strategies for\ndeploying LLMs in low-resource research environments and provides insights into\nbalancing efficiency and domain specialization for medical AI systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8d44\u6e90\u9ad8\u6548\u7684LLaMA-3.2-3B\u5fae\u8c03\u65b9\u6cd5\uff0c\u4f7f\u7528LoRA\u548cQLoRA\u6280\u672f\u5728\u6709\u9650GPU\u548c\u5185\u5b58\u6761\u4ef6\u4e0b\u589e\u5f3a\u533b\u5b66\u94fe\u5f0f\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5982GPT-4\u548cLLaMA\u5177\u6709\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5168\u53c2\u6570\u5fae\u8c03\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\uff0c\u9650\u5236\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u91c7\u7528\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f\uff08LoRA\u548cQLoRA\uff09\uff0c\u5728\u516c\u5f00\u533b\u5b66\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u5bf9LLaMA-3.2-3B\u6a21\u578b\u8fdb\u884c\u9002\u914d\u3002", "result": "\u6a21\u578b\u5728\u4fdd\u6301\u63a8\u7406\u80fd\u529b\u7684\u540c\u65f6\uff0c\u5185\u5b58\u4f7f\u7528\u91cf\u6bd4\u6807\u51c6\u5168\u5fae\u8c03\u51cf\u5c11\u9ad8\u8fbe60%\uff0c\u63a8\u7406\u8fde\u8d2f\u6027\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\u5f97\u5230\u63d0\u5347\u3002", "conclusion": "\u8f7b\u91cf\u7ea7\u9002\u914d\u65b9\u6cd5\u53ef\u4ee5\u5728\u533b\u5b66\u95ee\u7b54\u4efb\u52a1\u4e2d\u4fdd\u6301\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u4f4e\u8d44\u6e90\u7814\u7a76\u73af\u5883\u4e2d\u90e8\u7f72LLM\u63d0\u4f9b\u4e86\u5b9e\u7528\u7b56\u7565\u3002"}}
{"id": "2510.05025", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.05025", "abs": "https://arxiv.org/abs/2510.05025", "authors": ["Kuofeng Gao", "Yiming Li", "Chao Du", "Xin Wang", "Xingjun Ma", "Shu-Tao Xia", "Tianyu Pang"], "title": "Imperceptible Jailbreaking against Large Language Models", "comment": null, "summary": "Jailbreaking attacks on the vision modality typically rely on imperceptible\nadversarial perturbations, whereas attacks on the textual modality are\ngenerally assumed to require visible modifications (e.g., non-semantic\nsuffixes). In this paper, we introduce imperceptible jailbreaks that exploit a\nclass of Unicode characters called variation selectors. By appending invisible\nvariation selectors to malicious questions, the jailbreak prompts appear\nvisually identical to original malicious questions on screen, while their\ntokenization is \"secretly\" altered. We propose a chain-of-search pipeline to\ngenerate such adversarial suffixes to induce harmful responses. Our experiments\nshow that our imperceptible jailbreaks achieve high attack success rates\nagainst four aligned LLMs and generalize to prompt injection attacks, all\nwithout producing any visible modifications in the written prompt. Our code is\navailable at https://github.com/sail-sg/imperceptible-jailbreaks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528Unicode\u53d8\u4f53\u9009\u62e9\u5668\u5b9e\u73b0\u4e0d\u53ef\u611f\u77e5\u8d8a\u72f1\u653b\u51fb\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6076\u610f\u95ee\u9898\u540e\u9644\u52a0\u4e0d\u53ef\u89c1\u7684\u53d8\u4f53\u9009\u62e9\u5668\u5b57\u7b26\uff0c\u4f7f\u63d0\u793a\u5728\u89c6\u89c9\u4e0a\u4e0e\u539f\u95ee\u9898\u76f8\u540c\u4f46token\u5316\u88ab\u79d8\u5bc6\u6539\u53d8\uff0c\u4ece\u800c\u8bf1\u5bfc\u6709\u5bb3\u54cd\u5e94\u3002", "motivation": "\u89c6\u89c9\u6a21\u6001\u7684\u8d8a\u72f1\u653b\u51fb\u901a\u5e38\u4f9d\u8d56\u4e0d\u53ef\u611f\u77e5\u7684\u5bf9\u6297\u6270\u52a8\uff0c\u800c\u6587\u672c\u6a21\u6001\u653b\u51fb\u901a\u5e38\u9700\u8981\u53ef\u89c1\u4fee\u6539\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u6587\u672c\u6a21\u6001\u7684\u4e0d\u53ef\u611f\u77e5\u8d8a\u72f1\u653b\u51fb\u53ef\u80fd\u6027\u3002", "method": "\u4f7f\u7528Unicode\u53d8\u4f53\u9009\u62e9\u5668\u5b57\u7b26\uff0c\u63d0\u51fa\u94fe\u5f0f\u641c\u7d22\u6d41\u6c34\u7ebf\u751f\u6210\u5bf9\u6297\u6027\u540e\u7f00\uff0c\u6539\u53d8token\u5316\u4f46\u4e0d\u4ea7\u751f\u53ef\u89c1\u4fee\u6539\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u56db\u4e2a\u5bf9\u9f50LLM\u4e0a\u5b9e\u73b0\u9ad8\u653b\u51fb\u6210\u529f\u7387\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u3002", "conclusion": "\u8bc1\u660e\u4e86\u6587\u672c\u6a21\u6001\u4e5f\u5b58\u5728\u4e0d\u53ef\u611f\u77e5\u8d8a\u72f1\u653b\u51fb\u98ce\u9669\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u5b89\u5168\u673a\u5236\u7684\u65b0\u6f0f\u6d1e\u3002"}}
{"id": "2510.05026", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.05026", "abs": "https://arxiv.org/abs/2510.05026", "authors": ["David Beauchemin", "Yan Tremblay", "Mohamed Amine Youssef", "Richard Khoury"], "title": "A Set of Quebec-French Corpus of Regional Expressions and Terms", "comment": "Submitted to ACL Rolling Review of October", "summary": "The tasks of idiom understanding and dialect understanding are both\nwell-established benchmarks in natural language processing. In this paper, we\npropose combining them, and using regional idioms as a test of dialect\nunderstanding. Towards this end, we propose two new benchmark datasets for the\nQuebec dialect of French: QFrCoRE, which contains 4,633 instances of idiomatic\nphrases, and QFrCoRT, which comprises 171 regional instances of idiomatic\nwords. We explain how to construct these corpora, so that our methodology can\nbe replicated for other dialects. Our experiments with 94 LLM demonstrate that\nour regional idiom benchmarks are a reliable tool for measuring a model's\nproficiency in a specific dialect.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u4e2a\u65b0\u7684\u9b41\u5317\u514b\u6cd5\u8bed\u65b9\u8a00\u4e60\u8bed\u7406\u89e3\u57fa\u51c6\u6570\u636e\u96c6QFrCoRE\u548cQFrCoRT\uff0c\u7528\u4e8e\u6d4b\u8bd5LLM\u5728\u7279\u5b9a\u65b9\u8a00\u4e2d\u7684\u719f\u7ec3\u5ea6\u3002", "motivation": "\u5c06\u4e60\u8bed\u7406\u89e3\u548c\u65b9\u8a00\u7406\u89e3\u4e24\u4e2a\u4efb\u52a1\u7ed3\u5408\u8d77\u6765\uff0c\u4f7f\u7528\u5730\u533a\u6027\u4e60\u8bed\u4f5c\u4e3a\u65b9\u8a00\u7406\u89e3\u7684\u6d4b\u8bd5\u6807\u51c6\u3002", "method": "\u6784\u5efa\u4e86\u4e24\u4e2a\u9b41\u5317\u514b\u6cd5\u8bed\u65b9\u8a00\u4e60\u8bed\u6570\u636e\u96c6\uff1aQFrCoRE\u5305\u542b4,633\u4e2a\u4e60\u8bed\u77ed\u8bed\u5b9e\u4f8b\uff0cQFrCoRT\u5305\u542b171\u4e2a\u5730\u533a\u6027\u4e60\u8bed\u8bcd\u6c47\u5b9e\u4f8b\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u6784\u5efa\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u5bf994\u4e2aLLM\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5730\u533a\u6027\u4e60\u8bed\u57fa\u51c6\u662f\u8861\u91cf\u6a21\u578b\u5728\u7279\u5b9a\u65b9\u8a00\u4e2d\u719f\u7ec3\u5ea6\u7684\u53ef\u9760\u5de5\u5177\u3002", "conclusion": "\u5730\u533a\u6027\u4e60\u8bed\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u7684\u65b9\u8a00\u7406\u89e3\u8bc4\u4f30\u57fa\u51c6\uff0c\u8be5\u65b9\u6cd5\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u65b9\u8a00\u7684\u7814\u7a76\u3002"}}
{"id": "2510.05038", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.05038", "abs": "https://arxiv.org/abs/2510.05038", "authors": ["Omri Uzan", "Asaf Yehudai", "Roi pony", "Eyal Shnarch", "Ariel Gera"], "title": "Guided Query Refinement: Multimodal Hybrid Retrieval with Test-Time Optimization", "comment": null, "summary": "Multimodal encoders have pushed the boundaries of visual document retrieval,\nmatching textual query tokens directly to image patches and achieving\nstate-of-the-art performance on public benchmarks. Recent models relying on\nthis paradigm have massively scaled the sizes of their query and document\nrepresentations, presenting obstacles to deployment and scalability in\nreal-world pipelines. Furthermore, purely vision-centric approaches may be\nconstrained by the inherent modality gap still exhibited by modern\nvision-language models. In this work, we connect these challenges to the\nparadigm of hybrid retrieval, investigating whether a lightweight dense text\nretriever can enhance a stronger vision-centric model. Existing hybrid methods,\nwhich rely on coarse-grained fusion of ranks or scores, fail to exploit the\nrich interactions within each model's representation space. To address this, we\nintroduce Guided Query Refinement (GQR), a novel test-time optimization method\nthat refines a primary retriever's query embedding using guidance from a\ncomplementary retriever's scores. Through extensive experiments on visual\ndocument retrieval benchmarks, we demonstrate that GQR allows vision-centric\nmodels to match the performance of models with significantly larger\nrepresentations, while being up to 14x faster and requiring 54x less memory.\nOur findings show that GQR effectively pushes the Pareto frontier for\nperformance and efficiency in multimodal retrieval. We release our code at\nhttps://github.com/IBM/test-time-hybrid-retrieval", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGQR\u7684\u6d4b\u8bd5\u65f6\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u4e92\u8865\u68c0\u7d22\u5668\u7684\u5206\u6570\u6765\u4f18\u5316\u4e3b\u68c0\u7d22\u5668\u7684\u67e5\u8be2\u5d4c\u5165\uff0c\u4ece\u800c\u5728\u89c6\u89c9\u6587\u6863\u68c0\u7d22\u4e2d\u5b9e\u73b0\u6027\u80fd\u4e0e\u6548\u7387\u7684\u5e73\u8861\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u7f16\u7801\u5668\u5728\u89c6\u89c9\u6587\u6863\u68c0\u7d22\u4e2d\u867d\u7136\u6027\u80fd\u4f18\u8d8a\uff0c\u4f46\u5b58\u5728\u8868\u793a\u89c4\u6a21\u8fc7\u5927\u3001\u90e8\u7f72\u56f0\u96be\u7684\u95ee\u9898\uff0c\u4e14\u7eaf\u89c6\u89c9\u65b9\u6cd5\u53ef\u80fd\u53d7\u5230\u6a21\u6001\u5dee\u8ddd\u7684\u9650\u5236\u3002", "method": "\u5f15\u5165\u5f15\u5bfc\u67e5\u8be2\u4f18\u5316(GQR)\u65b9\u6cd5\uff0c\u5728\u6d4b\u8bd5\u65f6\u4f7f\u7528\u4e92\u8865\u68c0\u7d22\u5668\u7684\u5206\u6570\u6765\u4f18\u5316\u4e3b\u68c0\u7d22\u5668\u7684\u67e5\u8be2\u5d4c\u5165\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u7684\u6a21\u578b\u4ea4\u4e92\u3002", "result": "\u5b9e\u9a8c\u8868\u660eGQR\u80fd\u8ba9\u89c6\u89c9\u4e2d\u5fc3\u6a21\u578b\u8fbe\u5230\u66f4\u5927\u8868\u793a\u6a21\u578b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u901f\u5ea6\u63d0\u534714\u500d\uff0c\u5185\u5b58\u9700\u6c42\u51cf\u5c1154\u500d\u3002", "conclusion": "GQR\u6709\u6548\u63a8\u52a8\u4e86\u591a\u6a21\u6001\u68c0\u7d22\u5728\u6027\u80fd\u4e0e\u6548\u7387\u65b9\u9762\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.05046", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.05046", "abs": "https://arxiv.org/abs/2510.05046", "authors": ["David Beauchemin", "Yan Tremblay", "Mohamed Amine Youssef", "Richard Khoury"], "title": "COLE: a Comprehensive Benchmark for French Language Understanding Evaluation", "comment": "Submitted to ACL Rolling Review of October", "summary": "To address the need for a more comprehensive evaluation of French Natural\nLanguage Understanding (NLU), we introduce COLE, a new benchmark composed of 23\ndiverse task covering a broad range of NLU capabilities, including sentiment\nanalysis, paraphrase detection, grammatical judgment, and reasoning, with a\nparticular focus on linguistic phenomena relevant to the French language. We\nbenchmark 94 large language models (LLM), providing an extensive analysis of\nthe current state of French NLU. Our results highlight a significant\nperformance gap between closed- and open-weights models and identify key\nchallenging frontiers for current LLMs, such as zero-shot extractive\nquestion-answering (QA), fine-grained word sense disambiguation, and\nunderstanding of regional language variations. We release COLE as a public\nresource to foster further progress in French language modelling.", "AI": {"tldr": "COLE\u662f\u4e00\u4e2a\u65b0\u7684\u6cd5\u8bed\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b23\u4e2a\u591a\u6837\u5316\u4efb\u52a1\uff0c\u8bc4\u4f30\u4e8694\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u95ed\u6e90\u548c\u5f00\u6e90\u6a21\u578b\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u5e76\u8bc6\u522b\u4e86\u5f53\u524dLLM\u9762\u4e34\u7684\u6311\u6218\u6027\u524d\u6cbf\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u6cd5\u8bed\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u8bc4\u4f30\u4e0d\u591f\u5168\u9762\u7684\u95ee\u9898\uff0c\u9700\u8981\u521b\u5efa\u4e00\u4e2a\u8986\u76d6\u5e7f\u6cdbNLU\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7279\u522b\u5173\u6ce8\u6cd5\u8bed\u7279\u6709\u7684\u8bed\u8a00\u73b0\u8c61\u3002", "method": "\u6784\u5efaCOLE\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b23\u4e2a\u591a\u6837\u5316\u4efb\u52a1\uff0c\u6db5\u76d6\u60c5\u611f\u5206\u6790\u3001\u590d\u8ff0\u68c0\u6d4b\u3001\u8bed\u6cd5\u5224\u65ad\u548c\u63a8\u7406\u7b49\u80fd\u529b\uff0c\u5e76\u5bf994\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\u4e86\u95ed\u6e90\u548c\u5f00\u6e90\u6a21\u578b\u4e4b\u95f4\u7684\u663e\u8457\u6027\u80fd\u5dee\u8ddd\uff0c\u8bc6\u522b\u4e86\u96f6\u6837\u672c\u62bd\u53d6\u5f0f\u95ee\u7b54\u3001\u7ec6\u7c92\u5ea6\u8bcd\u4e49\u6d88\u6b67\u548c\u533a\u57df\u8bed\u8a00\u53d8\u4f53\u7406\u89e3\u7b49\u5173\u952e\u6311\u6218\u6027\u524d\u6cbf\u95ee\u9898\u3002", "conclusion": "COLE\u4f5c\u4e3a\u516c\u5171\u8d44\u6e90\u53d1\u5e03\uff0c\u65e8\u5728\u4fc3\u8fdb\u6cd5\u8bed\u8bed\u8a00\u5efa\u6a21\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2510.05069", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05069", "abs": "https://arxiv.org/abs/2510.05069", "authors": ["Dachuan Shi", "Abedelkadir Asi", "Keying Li", "Xiangchi Yuan", "Leyan Pan", "Wenke Lee", "Wen Xiao"], "title": "SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior Reasoning LLMs", "comment": "Code: https://github.com/sdc17/SwiReasoning, Website:\n  https://swireasoning.github.io/", "summary": "Recent work shows that, beyond discrete reasoning through explicit\nchain-of-thought steps, which are limited by the boundaries of natural\nlanguages, large language models (LLMs) can also reason continuously in latent\nspace, allowing richer information per step and thereby improving token\nefficiency. Despite this promise, latent reasoning still faces two challenges,\nespecially in training-free settings: 1) purely latent reasoning broadens the\nsearch distribution by maintaining multiple implicit paths, which diffuses\nprobability mass, introduces noise, and impedes convergence to a single\nhigh-confidence solution, thereby hurting accuracy; and 2) overthinking\npersists even without explicit text, wasting tokens and degrading efficiency.\nTo address these issues, we introduce SwiReasoning, a training-free framework\nfor LLM reasoning which features two key innovations: 1) SwiReasoning\ndynamically switches between explicit and latent reasoning, guided by\nblock-wise confidence estimated from entropy trends in next-token\ndistributions, to balance exploration and exploitation and promote timely\nconvergence. 2) By limiting the maximum number of thinking-block switches,\nSwiReasoning curbs overthinking and improves token efficiency across varying\nproblem difficulties. On widely used mathematics and STEM benchmarks,\nSwiReasoning consistently improves average accuracy by 1.5%-2.8% across\nreasoning LLMs of different model families and scales. Furthermore, under\nconstrained budgets, SwiReasoning improves average token efficiency by 56%-79%,\nwith larger gains as budgets tighten.", "AI": {"tldr": "SwiReasoning\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684LLM\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u663e\u5f0f\u548c\u9690\u5f0f\u63a8\u7406\u4e4b\u95f4\u52a8\u6001\u5207\u6362\u6765\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u63d0\u9ad8\u51c6\u786e\u6027\u548ctoken\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u9690\u5f0f\u63a8\u7406\u9762\u4e34\u7684\u4e24\u4e2a\u6311\u6218\uff1a1) \u7eaf\u9690\u5f0f\u63a8\u7406\u4f1a\u6269\u6563\u6982\u7387\u8d28\u91cf\uff0c\u5f15\u5165\u566a\u58f0\uff0c\u963b\u788d\u6536\u655b\u5230\u9ad8\u7f6e\u4fe1\u5ea6\u89e3\uff1b2) \u8fc7\u5ea6\u601d\u8003\u95ee\u9898\u6301\u7eed\u5b58\u5728\uff0c\u6d6a\u8d39token\u964d\u4f4e\u6548\u7387\u3002", "method": "SwiReasoning\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u5173\u952e\u521b\u65b0\uff1a1) \u57fa\u4e8e\u71b5\u8d8b\u52bf\u4f30\u8ba1\u5757\u7ea7\u7f6e\u4fe1\u5ea6\uff0c\u52a8\u6001\u5207\u6362\u663e\u5f0f\u548c\u9690\u5f0f\u63a8\u7406\uff1b2) \u9650\u5236\u601d\u8003\u5757\u5207\u6362\u7684\u6700\u5927\u6b21\u6570\u6765\u63a7\u5236\u8fc7\u5ea6\u601d\u8003\u3002", "result": "\u5728\u6570\u5b66\u548cSTEM\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSwiReasoning\u5c06\u5e73\u5747\u51c6\u786e\u7387\u63d0\u9ad8\u4e861.5%-2.8%\uff0c\u5728\u53d7\u9650\u9884\u7b97\u4e0btoken\u6548\u7387\u63d0\u9ad8\u4e8656%-79%\uff0c\u9884\u7b97\u8d8a\u7d27\u589e\u76ca\u8d8a\u5927\u3002", "conclusion": "SwiReasoning\u901a\u8fc7\u52a8\u6001\u63a8\u7406\u5207\u6362\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u9690\u5f0f\u63a8\u7406\u7684\u6536\u655b\u95ee\u9898\u548c\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u63a8\u7406\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2510.05077", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05077", "abs": "https://arxiv.org/abs/2510.05077", "authors": ["Chenyu Wang", "Zishen Wan", "Hao Kang", "Emma Chen", "Zhiqiang Xie", "Tushar Krishna", "Vijay Janapa Reddi", "Yilun Du"], "title": "Slm-mux: Orchestrating small language models for reasoning", "comment": null, "summary": "With the rapid development of language models, the number of small language\nmodels (SLMs) has grown significantly. Although they do not achieve\nstate-of-the-art accuracy, they are more efficient and often excel at specific\ntasks. This raises a natural question: can multiple SLMs be orchestrated into a\nsystem where each contributes effectively, achieving higher accuracy than any\nindividual model? Existing orchestration methods have primarily targeted\nfrontier models (e.g., GPT-4) and perform suboptimally when applied to SLMs. To\naddress this gap, we propose a three-stage approach for orchestrating SLMs.\nFirst, we introduce SLM-MUX, a multi-model architecture that effectively\ncoordinates multiple SLMs. Building on this, we develop two optimization\nstrategies: (i) a model selection search that identifies the most complementary\nSLMs from a given pool, and (ii) test-time scaling tailored to SLM-MUX. Our\napproach delivers strong results: Compared to existing orchestration methods,\nour approach achieves up to 13.4% improvement on MATH, 8.8% on GPQA, and 7.0%\non GSM8K. With just two SLMS, SLM-MUX outperforms Qwen 2.5 72B on GPQA and\nGSM8K, and matches its performance on MATH. We further provide theoretical\nanalyses to substantiate the advantages of our method. In summary, we\ndemonstrate that SLMs can be effectively orchestrated into more accurate and\nefficient systems through the proposed approach.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSLM-MUX\u7684\u4e09\u9636\u6bb5\u65b9\u6cd5\uff0c\u7528\u4e8e\u6709\u6548\u534f\u8c03\u591a\u4e2a\u5c0f\u8bed\u8a00\u6a21\u578b(SLMs)\uff0c\u901a\u8fc7\u6a21\u578b\u9009\u62e9\u641c\u7d22\u548c\u6d4b\u8bd5\u65f6\u7f29\u653e\u7b56\u7565\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7f16\u6392\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u5c0f\u8bed\u8a00\u6a21\u578b\u6570\u91cf\u7684\u5feb\u901f\u589e\u957f\uff0c\u867d\u7136\u5355\u4e2a\u6a21\u578b\u65e0\u6cd5\u8fbe\u5230\u6700\u5148\u8fdb\u7cbe\u5ea6\uff0c\u4f46\u5b83\u4eec\u5728\u7279\u5b9a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u4e14\u66f4\u9ad8\u6548\u3002\u9700\u8981\u63a2\u7d22\u5982\u4f55\u5c06\u591a\u4e2aSLMs\u6709\u6548\u7f16\u6392\u6210\u4e00\u4e2a\u7cfb\u7edf\uff0c\u5b9e\u73b0\u6bd4\u4efb\u4f55\u5355\u4e2a\u6a21\u578b\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a1) SLM-MUX\u591a\u6a21\u578b\u67b6\u6784\u534f\u8c03\u591a\u4e2aSLMs\uff1b2) \u6a21\u578b\u9009\u62e9\u641c\u7d22\u4ece\u5019\u9009\u6c60\u4e2d\u8bc6\u522b\u6700\u5177\u4e92\u8865\u6027\u7684SLMs\uff1b3) \u9488\u5bf9SLM-MUX\u7684\u6d4b\u8bd5\u65f6\u7f29\u653e\u7b56\u7565\u3002", "result": "\u5728MATH\u4e0a\u63d0\u534713.4%\uff0cGPQA\u4e0a\u63d0\u53478.8%\uff0cGSM8K\u4e0a\u63d0\u53477.0%\u3002\u4ec5\u7528\u4e24\u4e2aSLMs\u5c31\u5728GPQA\u548cGSM8K\u4e0a\u8d85\u8d8aQwen 2.5 72B\uff0c\u5728MATH\u4e0a\u4e0e\u4e4b\u6301\u5e73\u3002", "conclusion": "\u901a\u8fc7\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\uff0cSLMs\u53ef\u4ee5\u88ab\u6709\u6548\u7f16\u6392\u6210\u66f4\u51c6\u786e\u548c\u9ad8\u6548\u7684\u7cfb\u7edf\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u6765\u8bc1\u5b9e\u8be5\u65b9\u6cd5\u7684\u4f18\u52bf\u3002"}}
{"id": "2510.05087", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05087", "abs": "https://arxiv.org/abs/2510.05087", "authors": ["Janos Perczel", "Jin Chow", "Dorottya Demszky"], "title": "TeachLM: Post-Training LLMs for Education Using Authentic Learning Data", "comment": "28 pages, 9 figures", "summary": "The promise of generative AI to revolutionize education is constrained by the\npedagogical limits of large language models (LLMs). A major issue is the lack\nof access to high-quality training data that reflect the learning of actual\nstudents. Prompt engineering has emerged as a stopgap, but the ability of\nprompts to encode complex pedagogical strategies in rule-based natural language\nis inherently limited. To address this gap we introduce TeachLM - an LLM\noptimized for teaching through parameter-efficient fine-tuning of\nstate-of-the-art models. TeachLM is trained on a dataset comprised of 100,000\nhours of one-on-one, longitudinal student-tutor interactions maintained by\nPolygence, which underwent a rigorous anonymization process to protect privacy.\nWe use parameter-efficient fine-tuning to develop an authentic student model\nthat enables the generation of high-fidelity synthetic student-tutor dialogues.\nBuilding on this capability, we propose a novel multi-turn evaluation protocol\nthat leverages synthetic dialogue generation to provide fast, scalable, and\nreproducible assessments of the dialogical capabilities of LLMs. Our\nevaluations demonstrate that fine-tuning on authentic learning data\nsignificantly improves conversational and pedagogical performance - doubling\nstudent talk time, improving questioning style, increasing dialogue turns by\n50%, and greater personalization of instruction.", "AI": {"tldr": "TeachLM\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u4f18\u5316LLM\u7528\u4e8e\u6559\u5b66\uff0c\u5229\u7528\u771f\u5b9e\u5b66\u751f-\u5bfc\u5e08\u5bf9\u8bdd\u6570\u636e\u751f\u6210\u9ad8\u8d28\u91cf\u5408\u6210\u5bf9\u8bdd\uff0c\u663e\u8457\u63d0\u5347\u6559\u5b66\u5bf9\u8bdd\u80fd\u529b", "motivation": "\u89e3\u51b3\u751f\u6210\u5f0fAI\u5728\u6559\u80b2\u5e94\u7528\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u7f3a\u4e4f\u53cd\u6620\u771f\u5b9e\u5b66\u751f\u5b66\u4e60\u8fc7\u7a0b\u7684\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u4ee5\u53ca\u63d0\u793a\u5de5\u7a0b\u5728\u7f16\u7801\u590d\u6742\u6559\u5b66\u7b56\u7565\u65b9\u9762\u7684\u4e0d\u8db3", "method": "\u4f7f\u7528100,000\u5c0f\u65f6\u771f\u5b9e\u5b66\u751f-\u5bfc\u5e08\u5bf9\u8bdd\u6570\u636e\u8fdb\u884c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u5f00\u53d1\u771f\u5b9e\u5b66\u751f\u6a21\u578b\u4ee5\u751f\u6210\u9ad8\u4fdd\u771f\u5408\u6210\u5bf9\u8bdd\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u5408\u6210\u5bf9\u8bdd\u7684\u591a\u8f6e\u8bc4\u4f30\u534f\u8bae", "result": "\u5fae\u8c03\u540e\u663e\u8457\u6539\u5584\u5bf9\u8bdd\u548c\u6559\u5b66\u8868\u73b0\uff1a\u5b66\u751f\u53d1\u8a00\u65f6\u95f4\u7ffb\u500d\u3001\u63d0\u95ee\u98ce\u683c\u6539\u8fdb\u3001\u5bf9\u8bdd\u8f6e\u6b21\u589e\u52a050%\u3001\u6559\u5b66\u4e2a\u6027\u5316\u7a0b\u5ea6\u66f4\u9ad8", "conclusion": "\u5728\u771f\u5b9e\u5b66\u4e60\u6570\u636e\u4e0a\u8fdb\u884c\u5fae\u8c03\u80fd\u663e\u8457\u63d0\u5347LLM\u7684\u6559\u5b66\u5bf9\u8bdd\u80fd\u529b\uff0c\u4e3a\u6559\u80b2AI\u53d1\u5c55\u63d0\u4f9b\u6709\u6548\u8def\u5f84"}}
{"id": "2510.05090", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.05090", "abs": "https://arxiv.org/abs/2510.05090", "authors": ["Runchu Tian", "Junxia Cui", "Xueqiang Xu", "Feng Yao", "Jingbo Shang"], "title": "Finish First, Perfect Later: Test-Time Token-Level Cross-Validation for Diffusion Large Language Models", "comment": "17 pages, 8 figures. Work in progress", "summary": "Diffusion large language models (dLLMs) have recently emerged as a promising\nalternative to autoregressive (AR) models, offering advantages such as\naccelerated parallel decoding and bidirectional context modeling. However, the\nvanilla decoding strategy in discrete dLLMs suffers from a critical limitation:\nonce a token is accepted, it can no longer be revised in subsequent steps. As a\nresult, early mistakes persist across iterations, harming both intermediate\npredictions and final output quality. To address this issue, we propose\nTolerator (Token-Level Cross-Validation Refinement), a training-free decoding\nstrategy that leverages cross-validation among predicted tokens. Unlike\nexisting methods that follow a single progressive unmasking procedure,\nTolerator introduces a two-stage process: (i) sequence fill-up and (ii)\niterative refinement by remasking and decoding a subset of tokens while\ntreating the remaining as context. This design enables previously accepted\ntokens to be reconsidered and corrected when necessary, leading to more\nreliable diffusion decoding outputs. We evaluate Tolerator on five standard\nbenchmarks covering language understanding, code generation, and mathematics.\nExperiments show that our method achieves consistent improvements over the\nbaselines under the same computational budget. These findings suggest that\ndecoding algorithms are crucial to realizing the full potential of diffusion\nlarge language models. Code and data are publicly available.", "AI": {"tldr": "\u63d0\u51fa\u4e86Tolerator\u89e3\u7801\u7b56\u7565\uff0c\u901a\u8fc7\u4ee4\u724c\u7ea7\u4ea4\u53c9\u9a8c\u8bc1\u6539\u8fdb\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u89e3\u7801\u8fc7\u7a0b\uff0c\u5141\u8bb8\u4fee\u6b63\u5df2\u63a5\u53d7\u7684\u4ee4\u724c\uff0c\u63d0\u5347\u8f93\u51fa\u8d28\u91cf\u3002", "motivation": "\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4f20\u7edf\u89e3\u7801\u7b56\u7565\u5b58\u5728\u5173\u952e\u9650\u5236\uff1a\u4e00\u65e6\u4ee4\u724c\u88ab\u63a5\u53d7\u5c31\u65e0\u6cd5\u5728\u540e\u7eed\u6b65\u9aa4\u4e2d\u4fee\u6b63\uff0c\u5bfc\u81f4\u65e9\u671f\u9519\u8bef\u6301\u7eed\u5f71\u54cd\u6700\u7ec8\u8f93\u51fa\u8d28\u91cf\u3002", "method": "\u63d0\u51faTolerator\u89e3\u7801\u7b56\u7565\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8fc7\u7a0b\uff1a(i)\u5e8f\u5217\u586b\u5145\u548c(ii)\u901a\u8fc7\u91cd\u65b0\u63a9\u7801\u548c\u89e3\u7801\u4ee4\u724c\u5b50\u96c6\u8fdb\u884c\u8fed\u4ee3\u7cbe\u70bc\uff0c\u540c\u65f6\u5c06\u5269\u4f59\u4ee4\u724c\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u3002", "result": "\u5728\u4e94\u4e2a\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\uff08\u8bed\u8a00\u7406\u89e3\u3001\u4ee3\u7801\u751f\u6210\u548c\u6570\u5b66\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u76f8\u540c\u8ba1\u7b97\u9884\u7b97\u4e0b\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u5b9e\u73b0\u4e86\u6301\u7eed\u6539\u8fdb\u3002", "conclusion": "\u89e3\u7801\u7b97\u6cd5\u5bf9\u4e8e\u5145\u5206\u53d1\u6325\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u529b\u81f3\u5173\u91cd\u8981\uff0cTolerator\u7b56\u7565\u80fd\u591f\u4ea7\u751f\u66f4\u53ef\u9760\u7684\u6269\u6563\u89e3\u7801\u8f93\u51fa\u3002"}}
{"id": "2412.18708", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.IR", "68T01 (Primary)", "I.2.0; I.2.1; I.2.7"], "pdf": "https://arxiv.org/pdf/2412.18708", "abs": "https://arxiv.org/abs/2412.18708", "authors": ["Vivek Vellaiyappan Surulimuthu", "Aditya Karnam Gururaj Rao"], "title": "CAG: Chunked Augmented Generation for Google Chrome's Built-in Gemini Nano", "comment": "36 pages, 19 figures", "summary": "We present Chunked Augmented Generation (CAG), an architecture specifically\ndesigned to overcome the context window limitations of Google Chrome's built-in\nGemini Nano model. While Chrome's integration of Gemini Nano represents a\nsignificant advancement in bringing AI capabilities directly to the browser,\nits restricted context window poses challenges for processing large inputs. CAG\naddresses this limitation through intelligent input chunking and processing\nstrategies, enabling efficient handling of extensive content while maintaining\nthe model's performance within browser constraints. Our implementation\ndemonstrates particular efficacy in processing large documents and datasets\ndirectly within Chrome, making sophisticated AI capabilities accessible through\nthe browser without external API dependencies. Get started now at\nhttps://github.com/vivekVells/cag-js.", "AI": {"tldr": "\u63d0\u51fa\u4e86Chunked Augmented Generation (CAG)\u67b6\u6784\uff0c\u901a\u8fc7\u667a\u80fd\u5206\u5757\u5904\u7406\u7b56\u7565\u89e3\u51b3Chrome\u5185\u7f6eGemini Nano\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u95ee\u9898", "motivation": "Chrome\u96c6\u6210Gemini Nano\u867d\u7136\u5c06AI\u80fd\u529b\u5e26\u5230\u6d4f\u89c8\u5668\uff0c\u4f46\u5176\u53d7\u9650\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u96be\u4ee5\u5904\u7406\u5927\u578b\u8f93\u5165\u5185\u5bb9", "method": "\u91c7\u7528\u667a\u80fd\u8f93\u5165\u5206\u5757\u548c\u5904\u7406\u7b56\u7565\uff0c\u5728\u6d4f\u89c8\u5668\u7ea6\u675f\u5185\u9ad8\u6548\u5904\u7406\u5927\u91cf\u5185\u5bb9", "result": "\u5728Chrome\u5185\u5904\u7406\u5927\u578b\u6587\u6863\u548c\u6570\u636e\u96c6\u7279\u522b\u6709\u6548\uff0c\u65e0\u9700\u4f9d\u8d56\u5916\u90e8API\u5373\u53ef\u8bbf\u95ee\u590d\u6742AI\u80fd\u529b", "conclusion": "CAG\u67b6\u6784\u6210\u529f\u514b\u670d\u4e86\u6d4f\u89c8\u5668\u5185\u7f6eAI\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u9650\u5236\uff0c\u4f7f\u6d4f\u89c8\u5668\u5185AI\u5904\u7406\u5927\u578b\u5185\u5bb9\u6210\u4e3a\u53ef\u80fd"}}
